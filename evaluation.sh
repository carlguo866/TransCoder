python XLM/train.py \
--n_heads 8 \
--bt_steps '' \
--max_vocab '-1'  \
--word_blank '0.1' \
--n_layers 6  \
--generate_hypothesis true \
--max_len 512 \
--bptt 256  \
--fp16 true \
--share_inout_emb true \
--tokens_per_batch 6000 \
--has_sentences_ids true \
--mlm_steps 'cpp,llvm' \
--eval_bleu true  \
--split_data false  \
--data_path '/home/carl/TransCoder/data/data_try3'  \
--eval_computation true \
--batch_size 32 \
--reload_model '/home/carl/TransCoder/output/mlm_cpp_llvm/bp5kf6zh4p/best-valid_mlm_ppl.pth, /home/carl/TransCoder/output/mlm_cpp_llvm/bp5kf6zh4p/best-valid_mlm_ppl.pth'  \
--amp 2  \
--max_batch_size 128 \
--ae_steps '' \
--emb_dim 1024 \
--eval_only True \
--beam_size 10 \
--retry_mistmatching_types 1 \
--dump_path '/tmp/' \
--exp_name='eval_final_model_wc_30' \
--lgs 'cpp-llvm' \
--encoder_only=True 