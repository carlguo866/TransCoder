private static File pathOfFileInDefaultFiles ( String filePath ) { return new File ( MultipleExtensionPluginWithPluginManagerIntegrationTest . class . getClassLoader ( ) . getResource ( " defaultFiles / " + filePath ) . getFile ( ) ) ; }
public static void main ( String [ ] args ) throws Exception { new HelloJDBIService ( ) . run ( args ) ; }
public static void main ( String [ ] args ) throws Exception { System . setProperty ( " es . logger . prefix " , " " ) ; BootstrapForTesting . ensureInitialized ( ) ; Random random = new Random ( ) ; Settings settings = settingsBuilder ( ) . put ( " index . refresh _ interval " , " - 1" ) . put ( SETTING_NUMBER_OF_SHARDS , 1 ) . put ( SETTING_NUMBER_OF_REPLICAS , 0 ) . put ( TransportModule . TRANSPORT_TYPE_KEY , " local " ) . build ( ) ; String clusterName = GlobalOrdinalsBenchmark . class . getSimpleName ( ) ; node = nodeBuilder ( ) . clusterName ( clusterName ) . settings ( settingsBuilder ( ) . put ( settings ) ) . node ( ) ; client = node . client ( ) ; try { client . admin ( ) . indices ( ) . prepareCreate ( INDEX_NAME ) . addMapping ( TYPE_NAME , jsonBuilder ( ) . startObject ( ) . startObject ( TYPE_NAME ) . startArray ( " dynamic _ templates " ) . startObject ( ) . startObject ( " default " ) . field ( " match " , " * " ) . field ( " match _ mapping _ type " , " string " ) . startObject ( " mapping " ) . field ( " type " , " string " ) . field ( " index " , " not _ analyzed " ) . startObject ( " fields " ) . startObject ( " doc _ values " ) . field ( " type " , " string " ) . field ( " index " , " no " ) . startObject ( " fielddata " ) . field ( " format " , " doc _ values " ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . endArray ( ) . endObject ( ) . endObject ( ) ) . get ( ) ; ObjectHashSet < String > uniqueTerms = new ObjectHashSet < > ( ) ; for ( int i = 0 ; i < FIELD_LIMIT ; i ++ ) { boolean added ; do { added = uniqueTerms . add ( RandomStrings . randomAsciiOfLength ( random , 16 ) ) ; } while ( ! added ) ; } String [ ] sValues = uniqueTerms . toArray ( String . class ) ; uniqueTerms = null ; BulkRequestBuilder builder = client . prepareBulk ( ) ; IntIntHashMap tracker = new IntIntHashMap ( ) ; for ( int i = 0 ; i < COUNT ; i ++ ) { Map < String , Object > fieldValues = new HashMap < > ( ) ; for ( int fieldSuffix = 1 ; fieldSuffix <= FIELD_LIMIT ; fieldSuffix <<= 1 ) { int index = tracker . putOrAdd ( fieldSuffix , 0 , 0 ) ; if ( index >= fieldSuffix ) { index = random . nextInt ( fieldSuffix ) ; fieldValues . put ( " field _ " + fieldSuffix , sValues [ index ] ) ; } else { fieldValues . put ( " field _ " + fieldSuffix , sValues [ index ] ) ; tracker . put ( fieldSuffix , ++ index ) ; } } builder . add ( client . prepareIndex ( INDEX_NAME , TYPE_NAME , String . valueOf ( i ) ) . setSource ( fieldValues ) ) ; if ( builder . numberOfActions ( ) >= 1000 ) { builder . get ( ) ; builder = client . prepareBulk ( ) ; } } if ( builder . numberOfActions ( ) > 0 ) { builder . get ( ) ; } } catch ( IndexAlreadyExistsException e ) { System . out . println ( " - - > ▁ Index ▁ already ▁ exists , ▁ ignoring ▁ indexing ▁ phase , ▁ waiting ▁ for ▁ green " ) ; ClusterHealthResponse clusterHealthResponse = client . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForGreenStatus ( ) . setTimeout ( "10m " ) . execute ( ) . actionGet ( ) ; if ( clusterHealthResponse . isTimedOut ( ) ) { System . err . println ( " - - > ▁ Timed ▁ out ▁ waiting ▁ for ▁ cluster ▁ health " ) ; } } client . admin ( ) . cluster ( ) . prepareUpdateSettings ( ) . setTransientSettings ( Settings . builder ( ) . put ( " logger . index . fielddata . ordinals " , " DEBUG " ) ) . get ( ) ; client . admin ( ) . indices ( ) . prepareRefresh ( INDEX_NAME ) . execute ( ) . actionGet ( ) ; COUNT = client . prepareCount ( INDEX_NAME ) . setQuery ( matchAllQuery ( ) ) . execute ( ) . actionGet ( ) . getCount ( ) ; System . out . println ( " - - > ▁ Number ▁ of ▁ docs ▁ in ▁ index : ▁ " + COUNT ) ; List < StatsResult > stats = new ArrayList < > ( ) ; for ( int fieldSuffix = FIELD_START ; fieldSuffix <= FIELD_LIMIT ; fieldSuffix <<= 1 ) { String fieldName = " field _ " + fieldSuffix ; String name = " global _ ordinals - " + fieldName ; if ( USE_DOC_VALUES ) { fieldName = fieldName + " . doc _ values " ; name = name + " _ doc _ values " ; } stats . add ( terms ( name , fieldName , " global _ ordinals _ low _ cardinality " ) ) ; } for ( int fieldSuffix = FIELD_START ; fieldSuffix <= FIELD_LIMIT ; fieldSuffix <<= 1 ) { String fieldName = " field _ " + fieldSuffix ; String name = " ordinals - " + fieldName ; if ( USE_DOC_VALUES ) { fieldName = fieldName + " . doc _ values " ; name = name + " _ doc _ values " ; } stats . add ( terms ( name , fieldName , " ordinals " ) ) ; } System . out . println ( " - - - - - - - - - - - - - - - - - - ▁ SUMMARY ▁ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - " ) ; System . out . format ( Locale . ENGLISH , " % 30s % 10s % 10s % 15s \n " , " name " , " took " , " millis " , " fieldata ▁ size " ) ; for ( StatsResult stat : stats ) { System . out . format ( Locale . ENGLISH , " % 30s % 10s % 10d % 15s \n " , stat . name , TimeValue . timeValueMillis ( stat . took ) , ( stat . took / QUERY_COUNT ) , stat . fieldDataMemoryUsed ) ; } System . out . println ( " - - - - - - - - - - - - - - - - - - ▁ SUMMARY ▁ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - " ) ; client . close ( ) ; node . close ( ) ; }
private static StatsResult terms ( String name , String field , String executionHint ) { long totalQueryTime ; client . admin ( ) . indices ( ) . prepareClearCache ( ) . setFieldDataCache ( true ) . execute ( ) . actionGet ( ) ; System . gc ( ) ; System . out . println ( " - - > ▁ Warmup ▁ ( " + name + " ) . . . " ) ; for ( int j = 0 ; j < QUERY_WARMUP ; j ++ ) { SearchResponse searchResponse = client . prepareSearch ( INDEX_NAME ) . setSize ( 0 ) . setQuery ( matchAllQuery ( ) ) . addAggregation ( AggregationBuilders . terms ( name ) . field ( field ) . executionHint ( executionHint ) ) . get ( ) ; if ( j == 0 ) { System . out . println ( " - - > ▁ Loading ▁ ( " + field + " ) : ▁ took : ▁ " + searchResponse . getTook ( ) ) ; } if ( searchResponse . getHits ( ) . totalHits ( ) != COUNT ) { System . err . println ( " - - > ▁ mismatch ▁ on ▁ hits " ) ; } } System . out . println ( " - - > ▁ Warmup ▁ ( " + name + " ) ▁ DONE " ) ; System . out . println ( " - - > ▁ Running ▁ ( " + name + " ) . . . " ) ; totalQueryTime = 0 ; for ( int j = 0 ; j < QUERY_COUNT ; j ++ ) { SearchResponse searchResponse = client . prepareSearch ( INDEX_NAME ) . setSize ( 0 ) . setQuery ( matchAllQuery ( ) ) . addAggregation ( AggregationBuilders . terms ( name ) . field ( field ) . executionHint ( executionHint ) ) . get ( ) ; if ( searchResponse . getHits ( ) . totalHits ( ) != COUNT ) { System . err . println ( " - - > ▁ mismatch ▁ on ▁ hits " ) ; } totalQueryTime += searchResponse . getTookInMillis ( ) ; } System . out . println ( " - - > ▁ Terms ▁ Agg ▁ ( " + name + " ) : ▁ " + ( totalQueryTime / QUERY_COUNT ) + " ms " ) ; String nodeId = node . injector ( ) . getInstance ( Discovery . class ) . localNode ( ) . getId ( ) ; ClusterStatsResponse clusterStateResponse = client . admin ( ) . cluster ( ) . prepareClusterStats ( ) . setNodesIds ( nodeId ) . get ( ) ; System . out . println ( " - - > ▁ Heap ▁ used : ▁ " + clusterStateResponse . getNodesStats ( ) . getJvm ( ) . getHeapUsed ( ) ) ; ByteSizeValue fieldDataMemoryUsed = clusterStateResponse . getIndicesStats ( ) . getFieldData ( ) . getMemorySize ( ) ; System . out . println ( " - - > ▁ Fielddata ▁ memory ▁ size : ▁ " + fieldDataMemoryUsed ) ; return new StatsResult ( name , totalQueryTime , fieldDataMemoryUsed ) ; }
