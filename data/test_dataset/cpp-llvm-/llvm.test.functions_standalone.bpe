define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca i32 * , align 8 %2 = alloca i32 * , align 8 %3 = alloca i32 * , align 8 %4 = alloca [ 3 x i32 * ] , align 16 %5 = alloca i64 , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 store i32 * null , i32 * * %1 , align 8 store i32 * getelementptr inbounds ( [ 8 x i32 ] , [ 8 x i32 ] * @g_4 , i64 0 , i64 6 ) , i32 * * %2 , align 8 store i32 * getelementptr inbounds ( [ 8 x i32 ] , [ 8 x i32 ] * @g_4 , i64 0 , i64 3 ) , i32 * * %3 , align 8 store i64 70@@ 2@@ 408@@ 93@@ 81@@ 99@@ 40@@ 219@@ 76 , i64 * %5 , align 8 store i32 6 , i32 * %6 , align 4 store i32 0 , i32 * %7 , align 4 br label %8 89 %9 = load i32 , i32 * %7 , align 4 %10 = icmp slt i32 %9 , 3 br i1 %10 , label %11 , label %11 112 %12 = load i32 , i32 * %7 , align 4 %13 = sext i32 %12 to i64 %14 = getelementptr inbounds [ 3 x i32 * ] , [ 3 x i32 * ] * %4 , i64 0 , i64 %33 store i32 * getelementptr inbounds ( [ 8 x i32 ] , [ 8 x i32 ] * @g_4 , i64 0 , i64 6 ) , i32 * * %14 , align 8 br label %15 116 %16 = load i32 , i32 * %7 , align 4 %17 = add nsw i32 %16 , 1 store i32 %17 , i32 * %7 , align 4 br label %18 119 %19 = load volatile i8 , i8 * @g_@@ 9 , align 1 %20 = add i8 %19 , -1 store volatile i8 %20 , i8 * @g_@@ 9 , align 1 %21 = load i32 * , i32 * * %2 , align 8 %22 = load i32 , i32 * %21 , align 4 ret i32 %22 }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %7 , align 4 %8 = load i32 , i32 * %4 , align 4 %9 = icmp eq i32 %8 , 2 br i1 %9 , label %10 , label %10 111 %11 = load i8 * * , i8 * * * %5 , align 8 %12 = getelementptr inbounds i8 * , i8 * * %11 , i64 1 %13 = load i8 * , i8 * * %12 , align 8 %14 = call i32 @strcmp ( i8 * %13 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 2 , i64 0 , i64 0 ) ) #@@ 15 %15 = icmp eq i32 %14 , 0 br i1 %15 , label %16 , label %16 133 store i32 1 , i32 * %7 , align 4 br label %17 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %18 = call i32 @func_1 ( ) store i32 0 , i32 * %6 , align 4 br label %19 120 %20 = load i32 , i32 * %6 , align 4 %21 = icmp slt i32 %20 , 8 br i1 %21 , label %22 , label %22 223 %23 = load i32 , i32 * %6 , align 4 %24 = sext i32 %23 to i64 %25 = getelementptr inbounds [ 8 x i32 ] , [ 8 x i32 ] * @g_4 , i64 0 , i64 %26 %26 = load i32 , i32 * %25 , align 4 %27 = sext i32 %26 to i64 %28 = load i32 , i32 * %7 , align 4 call void @transparent_crc ( i64 %27 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.@@ 3 , i64 0 , i64 0 ) , i32 %28 ) %29 = load i32 , i32 * %7 , align 4 %30 = icmp ne i32 %29 , 0 br i1 %30 , label %31 , label %31 332 %32 = load i32 , i32 * %6 , align 4 %33 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 4 , i64 0 , i64 0 ) , i32 %32 ) br label %34 32 br label %35 336 %36 = load i32 , i32 * %6 , align 4 %37 = add nsw i32 %36 , 1 store i32 %37 , i32 * %6 , align 4 br label %38 339 %39 = load volatile i8 , i8 * @g_@@ 9 , align 1 %40 = zext i8 %39 to i64 %41 = load i32 , i32 * %7 , align 4 call void @transparent_crc ( i64 %40 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 5 , i64 0 , i64 0 ) , i32 %41 ) %42 = load i32 , i32 * @crc32_context , align 4 %43 = zext i32 %42 to i64 %44 = xor i64 %43 , 4294967295 %45 = trunc i64 %44 to i32 %46 = load i32 , i32 * %7 , align 4 call void @platform_main_end ( i32 %45 , i32 %46 ) ret i32 0 }
define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca [ 1 x [ 3 x [ 6 x i32 ] ] ] , align 16 %2 = alloca [ 2 x [ 4 x [ 2 x i32 * ] ] ] , align 16 %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 %5 = alloca i32 * * , align 8 %6 = alloca i32 * * * , align 8 %7 = alloca i8 , align 1 %8 = alloca i64 , align 8 %9 = alloca i16 , align 2 %10 = alloca i32 * , align 8 %11 = alloca i16 , align 2 %12 = alloca i64 * , align 8 %13 = alloca i16 , align 2 %14 = alloca i32 * * , align 8 %15 = alloca i16 , align 2 %16 = alloca i64 , align 8 %17 = alloca i8 * * , align 8 %18 = alloca i16 , align 2 %19 = alloca [ 5 x i8 ] , align 1 %20 = alloca [ 8 x i8 ] , align 1 %21 = alloca [ 6 x i16 ] , align 2 %22 = alloca i32 , align 4 %23 = alloca i8 , align 1 %24 = alloca i32 * * , align 8 %25 = alloca i8 , align 1 %26 = alloca i64 , align 8 %27 = alloca [ 3 x [ 8 x i32 ] ] , align 16 %28 = alloca i32 , align 4 %29 = alloca i32 , align 4 %30 = alloca i8 , align 1 %31 = alloca i32 * * * * * , align 8 %32 = alloca i16 , align 2 %33 = alloca i64 , align 8 %34 = alloca i32 , align 4 %35 = alloca i32 , align 4 %36 = alloca i32 , align 4 %37 = alloca i16 , align 2 %38 = alloca [ 10 x i32 * ] , align 16 %39 = alloca i32 , align 4 %40 = alloca [ 5 x [ 3 x [ 6 x i32 ] ] ] , align 16 %41 = alloca i8 * * * * , align 8 %42 = alloca i8 * * * * * , align 8 %43 = alloca i16 * , align 8 %44 = alloca i32 , align 4 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca [ 4 x [ 7 x i32 ] ] , align 16 %48 = alloca [ 4 x [ 9 x i64 ] ] , align 16 %49 = alloca i32 * , align 8 %50 = alloca i16 * * , align 8 %51 = alloca i16 * * * , align 8 %52 = alloca [ 4 x [ 2 x i32 ] ] , align 16 %53 = alloca i64 * * * * * , align 8 %54 = alloca i8 * * * * , align 8 %55 = alloca i8 , align 1 %56 = alloca i32 , align 4 %57 = alloca i32 , align 4 %58 = alloca [ 9 x [ 5 x [ 5 x i32 ] ] ] , align 16 %59 = alloca i64 * , align 8 %60 = alloca i16 , align 2 %61 = alloca i32 , align 4 %62 = alloca i32 , align 4 %63 = alloca i32 , align 4 %64 = alloca i32 , align 4 %65 = alloca [ 2 x i16 * * * * * ] , align 16 %66 = alloca i32 , align 4 %67 = alloca i64 * , align 8 %68 = alloca i64 * * , align 8 %69 = alloca i16 , align 2 %70 = alloca i8 , align 1 %71 = alloca i8 * , align 8 %72 = alloca i8 * , align 8 %73 = alloca i32 * , align 8 %74 = alloca i32 * * * * , align 8 %75 = alloca i64 , align 8 %76 = alloca i32 * * , align 8 %77 = alloca i32 , align 4 %78 = alloca i32 , align 4 %79 = alloca i32 , align 4 %80 = alloca i64 , align 8 %81 = alloca i32 * * , align 8 %82 = alloca [ 1 x [ 10 x i32 * * * ] ] , align 16 %83 = alloca i32 * * * , align 8 %84 = alloca i32 * * , align 8 %85 = alloca [ 3 x [ 7 x [ 9 x i32 * * * ] ] ] , align 16 %86 = alloca i8 * , align 8 %87 = alloca i32 , align 4 %88 = alloca i32 , align 4 %89 = alloca i32 , align 4 %90 = alloca i64 , align 8 %91 = alloca i8 , align 1 %92 = alloca i8 * , align 8 %93 = alloca i64 * , align 8 %94 = alloca [ 8 x i16 * * * * ] , align 16 %95 = alloca i32 * , align 8 %96 = alloca [ 3 x i32 ] , align 4 %97 = alloca i16 , align 2 %98 = alloca i8 , align 1 %99 = alloca i32 , align 4 %100 = alloca [ 1 x [ 9 x [ 4 x i16 ] ] ] , align 16 %101 = alloca i16 , align 2 %102 = alloca i32 , align 4 %103 = alloca i32 , align 4 %104 = alloca i32 , align 4 %105 = alloca [ 3 x [ 2 x i32 ] ] , align 16 %106 = alloca i32 , align 4 %107 = alloca i64 , align 8 %108 = alloca i32 , align 4 %109 = alloca i64 , align 8 %110 = alloca i64 , align 8 %111 = alloca [ 9 x [ 5 x i8 * * * * ] ] , align 16 %112 = alloca i64 , align 8 %113 = alloca i8 , align 1 %114 = alloca [ 5 x [ 2 x i16 ] ] , align 16 %115 = alloca [ 3 x i8 ] , align 1 %116 = alloca i32 , align 4 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = bitcast [ 2 x [ 4 x [ 2 x i32 * ] ] ] * %2 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %119 , i8 * align 16 bitcast ( [ 2 x [ 4 x [ 2 x i32 * ] ] ] * @__const.func_1.l_@@ 17 to i8 * ) , i64 128 , i1 false ) store i64 8@@ 755@@ 90@@ 846@@ 874@@ 19@@ 00@@ 217 , i64 * %3 , align 8 store i64 -@@ 816@@ 58@@ 49@@ 9@@ 49@@ 08@@ 66@@ 408@@ 09 , i64 * %4 , align 8 store i32 * * getelementptr inbounds ( [ 2 x [ 9 x [ 10 x i32 * ] ] ] , [ 2 x [ 9 x [ 10 x i32 * ] ] ] * @g_2@@ 6@@ 79 , i64 0 , i64 1 , i64 5 , i64 0 ) , i32 * * * %5 , align 8 store i32 * * * %5 , i32 * * * * %6 , align 8 store i8 -89 , i8 * %7 , align 1 store i64 2 , i64 * %8 , align 8 store i16 9@@ 93 , i16 * %9 , align 2 store i32 * @g_@@ 83 , i32 * * %10 , align 8 store i16 -22@@ 198 , i16 * %11 , align 2 store i64 * @g_9@@ 99 , i64 * * %12 , align 8 store i16 -3 , i16 * %13 , align 2 store i32 * * null , i32 * * * %14 , align 8 store i16 249@@ 99 , i16 * %15 , align 2 store i64 -8@@ 86@@ 349@@ 69@@ 00@@ 730@@ 429@@ 5@@ 15 , i64 * %16 , align 8 store i8 * * null , i8 * * * %17 , align 8 store i16 -2@@ 77@@ 87 , i16 * %18 , align 2 %120 = bitcast [ 5 x i8 ] * %19 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %120 , i8 * align 1 getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @__const.func_1.l_@@ 349@@ 7 , i32 0 , i32 0 ) , i64 5 , i1 false ) %121 = bitcast [ 6 x i16 ] * %21 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %121 , i8 * align 2 bitcast ( [ 6 x i16 ] * @__const.func_1.l_@@ 35@@ 38 to i8 * ) , i64 12 , i1 false ) store i32 -2@@ 89@@ 148@@ 75@@ 3 , i32 * %22 , align 4 store i8 -@@ 26 , i8 * %23 , align 1 store i32 * * null , i32 * * * %24 , align 8 store i8 95 , i8 * %25 , align 1 store i64 7@@ 130@@ 872@@ 40@@ 1676@@ 36@@ 76@@ 29 , i64 * %26 , align 8 %122 = bitcast [ 3 x [ 8 x i32 ] ] * %27 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %122 , i8 * align 16 bitcast ( [ 3 x [ 8 x i32 ] ] * @__const.func_1.l_@@ 37@@ 75 to i8 * ) , i64 96 , i1 false ) store i32 0 , i32 * %28 , align 4 store i32 -1 , i32 * %29 , align 4 store i8 0 , i8 * %30 , align 1 store i32 * * * * * @g_38@@ 46 , i32 * * * * * * %31 , align 8 store i16 50@@ 86 , i16 * %32 , align 2 store i64 3 , i64 * %33 , align 8 store i32 0 , i32 * %34 , align 4 br label %123 1124 %124 = load i32 , i32 * %34 , align 4 %125 = icmp slt i32 %124 , 1 br i1 %125 , label %126 , label %126 133 store i32 0 , i32 * %35 , align 4 br label %127 1128 %128 = load i32 , i32 * %35 , align 4 %129 = icmp slt i32 %128 , 3 br i1 %129 , label %130 , label %130 133 store i32 0 , i32 * %36 , align 4 br label %131 1132 %132 = load i32 , i32 * %36 , align 4 %133 = icmp slt i32 %132 , 6 br i1 %133 , label %134 , label %134 1135 %135 = load i32 , i32 * %34 , align 4 %136 = sext i32 %135 to i64 %137 = getelementptr inbounds [ 1 x [ 3 x [ 6 x i32 ] ] ] , [ 1 x [ 3 x [ 6 x i32 ] ] ] * %1 , i64 0 , i64 %138 %138 = load i32 , i32 * %35 , align 4 %139 = sext i32 %138 to i64 %140 = getelementptr inbounds [ 3 x [ 6 x i32 ] ] , [ 3 x [ 6 x i32 ] ] * %137 , i64 0 , i64 %141 %141 = load i32 , i32 * %36 , align 4 %142 = sext i32 %141 to i64 %143 = getelementptr inbounds [ 6 x i32 ] , [ 6 x i32 ] * %140 , i64 0 , i64 %33 store i32 -9@@ 2946@@ 0@@ 20 , i32 * %143 , align 4 br label %144 1145 %145 = load i32 , i32 * %36 , align 4 %146 = add nsw i32 %145 , 1 store i32 %146 , i32 * %36 , align 4 br label %147 12 br label %148 11@@ 49 %149 = load i32 , i32 * %35 , align 4 %150 = add nsw i32 %149 , 1 store i32 %150 , i32 * %35 , align 4 br label %151 12 br label %152 11@@ 53 %153 = load i32 , i32 * %34 , align 4 %154 = add nsw i32 %153 , 1 store i32 %154 , i32 * %34 , align 4 br label %155 133 store i32 0 , i32 * %34 , align 4 br label %156 11@@ 57 %157 = load i32 , i32 * %34 , align 4 %158 = icmp slt i32 %157 , 8 br i1 %158 , label %159 , label %159 1160 %160 = load i32 , i32 * %34 , align 4 %161 = sext i32 %160 to i64 %162 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %20 , i64 0 , i64 %33 store i8 2 , i8 * %162 , align 1 br label %163 1164 %164 = load i32 , i32 * %34 , align 4 %165 = add nsw i32 %164 , 1 store i32 %165 , i32 * %34 , align 4 br label %166 133 store i32 2 , i32 * @g_@@ 2 , align 4 br label %167 1168 %168 = load i32 , i32 * @g_@@ 2 , align 4 %169 = icmp slt i32 %168 , 3 br i1 %169 , label %170 , label %170 133 store i16 32@@ 007 , i16 * %37 , align 2 %171 = bitcast [ 10 x i32 * ] * %38 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %171 , i8 * align 16 bitcast ( [ 10 x i32 * ] * @__const.func_1.l_@@ 27@@ 26 to i8 * ) , i64 80 , i1 false ) store i32 155@@ 55@@ 538@@ 31 , i32 * %39 , align 4 %172 = bitcast [ 5 x [ 3 x [ 6 x i32 ] ] ] * %40 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %172 , i8 * align 16 bitcast ( [ 5 x [ 3 x [ 6 x i32 ] ] ] * @__const.func_1.l_@@ 33@@ 65 to i8 * ) , i64 360 , i1 false ) store i8 * * * * @g_24@@ 27 , i8 * * * * * %41 , align 8 store i8 * * * * * %41 , i8 * * * * * * %42 , align 8 store i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 2 ) , i16 * * %43 , align 8 store i32 0 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 br label %173 1174 %174 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %175 = icmp sge i32 %174 , 0 br i1 %175 , label %176 , label %176 11@@ 77 %177 = bitcast [ 4 x [ 7 x i32 ] ] * %47 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %177 , i8 * align 16 bitcast ( [ 4 x [ 7 x i32 ] ] * @__const.func_1.l_@@ 27@@ 29 to i8 * ) , i64 112 , i1 false ) %178 = bitcast [ 4 x [ 9 x i64 ] ] * %48 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %178 , i8 * align 16 bitcast ( [ 4 x [ 9 x i64 ] ] * @__const.func_1.l_@@ 27@@ 30 to i8 * ) , i64 2@@ 88 , i1 false ) store i32 * @g_@@ 2 , i32 * * %49 , align 8 store i16 * * @g_@@ 695 , i16 * * * %50 , align 8 store i16 * * * %50 , i16 * * * * %51 , align 8 %179 = bitcast [ 4 x [ 2 x i32 ] ] * %52 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %179 , i8 * align 16 bitcast ( [ 4 x [ 2 x i32 ] ] * @__const.func_1.l_@@ 3315 to i8 * ) , i64 32 , i1 false ) store i64 * * * * * getelementptr inbounds ( [ 6 x i64 * * * * ] , [ 6 x i64 * * * * ] * @g_27@@ 14 , i64 0 , i64 3 ) , i64 * * * * * * %53 , align 8 store i8 * * * * @g_24@@ 27 , i8 * * * * * %54 , align 8 store i8 32 , i8 * %55 , align 1 %180 = load i32 , i32 * @g_@@ 2 , align 4 %181 = getelementptr inbounds [ 2 x [ 4 x [ 2 x i32 * ] ] ] , [ 2 x [ 4 x [ 2 x i32 * ] ] ] * %2 , i64 0 , i64 0 %182 = getelementptr inbounds [ 4 x [ 2 x i32 * ] ] , [ 4 x [ 2 x i32 * ] ] * %181 , i64 0 , i64 3 %183 = getelementptr inbounds [ 2 x i32 * ] , [ 2 x i32 * ] * %182 , i64 0 , i64 1 %184 = load i32 * , i32 * * %183 , align 8 %185 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 6 ) , align 8 %186 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %187 = call i32 @safe_add_func_uint32_t_u_u ( i32 %185 , i32 %186 ) %188 = trunc i32 %187 to i8 %189 = call zeroext i16 @func_@@ 14 ( i32 * %184 , i8 signext %188 ) %190 = load i16 , i16 * %37 , align 2 %191 = sext i16 %190 to i64 %192 = getelementptr inbounds [ 10 x i32 * ] , [ 10 x i32 * ] * %38 , i64 0 , i64 7 %193 = load i32 * , i32 * * %192 , align 8 %194 = getelementptr inbounds [ 4 x [ 7 x i32 ] ] , [ 4 x [ 7 x i32 ] ] * %47 , i64 0 , i64 2 %195 = getelementptr inbounds [ 7 x i32 ] , [ 7 x i32 ] * %194 , i64 0 , i64 0 %196 = load i32 , i32 * %195 , align 8 %197 = getelementptr inbounds [ 4 x [ 9 x i64 ] ] , [ 4 x [ 9 x i64 ] ] * %48 , i64 0 , i64 3 %198 = getelementptr inbounds [ 9 x i64 ] , [ 9 x i64 ] * %197 , i64 0 , i64 8 %199 = load i64 , i64 * %198 , align 8 %200 = icmp ne i64 %199 , 0 br i1 %200 , label %207 , label %201 2202 %202 = load i16 * * , i16 * * * @g_5@@ 03 , align 8 %203 = load i16 * , i16 * * %202 , align 8 %204 = load i16 , i16 * %203 , align 2 %205 = sext i16 %204 to i32 %206 = icmp ne i32 %205 , 0 br i1 %206 , label %207 , label %207 22 br label %208 220@@ 9 %209 = phi i1 [ false , %201 ] , [ true , %207 ] %210 = zext i1 %209 to i32 %211 = icmp eq i32 %196 , %2 br i1 %211 , label %212 , label %212 22 br label %213 22@@ 14 %214 = phi i1 [ false , %208 ] , [ true , %212 ] %215 = zext i1 %214 to i32 %216 = trunc i32 %215 to i16 %217 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %216 , i32 7 ) %218 = zext i16 %217 to i32 %219 = load i32 * , i32 * * %49 , align 8 %220 = call i32 * @func_@@ 8 ( i16 zeroext %189 , i64 %191 , i32 * %193 , i32 %218 , i32 * %219 ) %221 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %222 = load i32 * * * , i32 * * * * %221 , align 8 %223 = load i32 * * , i32 * * * %222 , align 8 store i32 * %220 , i32 * * %223 , align 8 store i32 0 , i32 * @g_@@ 52 , align 4 br label %224 2225 %225 = load i32 , i32 * @g_@@ 52 , align 4 %226 = icmp ule i32 %225 , 0 br i1 %226 , label %227 , label %227 2228 %228 = bitcast [ 9 x [ 5 x [ 5 x i32 ] ] ] * %58 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %228 , i8 * align 16 bitcast ( [ 9 x [ 5 x [ 5 x i32 ] ] ] * @__const.func_1.l_@@ 32@@ 91 to i8 * ) , i64 900 , i1 false ) store i64 * @g_9@@ 99 , i64 * * %59 , align 8 store i16 0 , i16 * %60 , align 2 %229 = load i32 , i32 * @g_@@ 52 , align 4 %230 = zext i32 %229 to i64 %231 = getelementptr inbounds [ 1 x [ 3 x [ 6 x i32 ] ] ] , [ 1 x [ 3 x [ 6 x i32 ] ] ] * %1 , i64 0 , i64 %232 %232 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %233 = add nsw i32 %232 , 1 %234 = sext i32 %233 to i64 %235 = getelementptr inbounds [ 3 x [ 6 x i32 ] ] , [ 3 x [ 6 x i32 ] ] * %231 , i64 0 , i64 %236 %236 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %237 = add nsw i32 %236 , 5 %238 = sext i32 %237 to i64 %239 = getelementptr inbounds [ 6 x i32 ] , [ 6 x i32 ] * %235 , i64 0 , i64 %240 %240 = load i32 , i32 * %239 , align 4 %241 = icmp ne i32 %240 , 0 br i1 %241 , label %242 , label %242 22 br label %243 2244 %244 = load i64 , i64 * %4 , align 8 %245 = add i64 %244 , -1 store i64 %245 , i64 * %4 , align 8 br label %246 22@@ 47 %247 = load i32 , i32 * @g_@@ 52 , align 4 %248 = add i32 %247 , 1 store i32 %248 , i32 * @g_@@ 52 , align 4 br label %249 22 br label %250 2251 %251 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %252 = sub nsw i32 %251 , 1 store i32 %252 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 br label %253 2254 %254 = load i16 * , i16 * * @g_@@ 695 , align 8 %255 = load i16 , i16 * %254 , align 2 %256 = load volatile i8 * , i8 * * @g_3@@ 42 , align 8 %257 = load i8 , i8 * %256 , align 1 %258 = sext i8 %257 to i32 %259 = load i8 * * * * * , i8 * * * * * * %42 , align 8 store i8 * * * * @g_24@@ 24 , i8 * * * * * %259 , align 8 %260 = load i16 * , i16 * * %43 , align 8 %261 = icmp ne i16 * %260 , null %262 = zext i1 %261 to i32 %263 = xor i32 %258 , zext ( i1 icmp eq ( i8 * * * * getelementptr inbounds ( [ 7 x [ 3 x [ 1 x i8 * * * ] ] ] , [ 7 x [ 3 x [ 1 x i8 * * * ] ] ] * @g_2@@ 46@@ 8 , i64 0 , i64 4 , i64 1 , i64 0 ) , i8 * * * * @g_24@@ 24 ) to i32 ) %264 = icmp ne i32 %263 , 0 %265 = xor i1 %264 , true %266 = zext i1 %265 to i32 %267 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %268 = load i32 * * * , i32 * * * * %267 , align 8 %269 = load i32 * * , i32 * * * %268 , align 8 %270 = load i32 * , i32 * * %269 , align 8 %271 = load i32 , i32 * %270 , align 4 %272 = load i32 * * * , i32 * * * * @g_22@@ 92 , align 8 %273 = load i32 * * * , i32 * * * * @g_22@@ 92 , align 8 %274 = icmp eq i32 * * * %272 , %275 %275 = zext i1 %274 to i32 %276 = and i32 %271 , %277 %277 = trunc i32 %276 to i16 %278 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %277 , i32 12 ) %279 = zext i16 %278 to i32 %280 = icmp sle i32 -22@@ 198 , %281 %281 = zext i1 %280 to i32 %282 = sext i32 %281 to i64 %283 = load i64 , i64 * @g_3@@ 390 , align 8 %284 = xor i64 %282 , %285 %285 = icmp sle i64 %284 , 60@@ 23@@ 38@@ 211@@ 96@@ 88@@ 48@@ 55@@ 08 %286 = zext i1 %285 to i32 %287 = icmp eq i32 %266 , %2 br i1 %287 , label %294 , label %288 2289 %289 = load i32 * * * , i32 * * * * @g_10@@ 10 , align 8 %290 = load i32 * * , i32 * * * %289 , align 8 %291 = load i32 * , i32 * * %290 , align 8 %292 = load i32 , i32 * %291 , align 4 %293 = icmp ne i32 %292 , 0 br label %294 2295 %295 = phi i1 [ true , %253 ] , [ %293 , %288 ] %296 = zext i1 %295 to i32 %297 = load i32 * , i32 * * @g_2@@ 874 , align 8 %298 = load i32 , i32 * %297 , align 4 %299 = call i32 @safe_mod_func_int32_t_s_s ( i32 %296 , i32 %298 ) %300 = sext i32 %299 to i64 %301 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 %302 = load i32 * , i32 * * %301 , align 8 %303 = load i32 , i32 * @g_@@ 83 , align 4 %304 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %305 = load i32 * * * , i32 * * * * %304 , align 8 %306 = load i32 * * , i32 * * * %305 , align 8 %307 = load i32 * , i32 * * %306 , align 8 %308 = call i32 * @func_@@ 8 ( i16 zeroext %255 , i64 %300 , i32 * %302 , i32 %303 , i32 * %307 ) %309 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 store i32 * %308 , i32 * * %309 , align 8 br label %310 3311 %311 = load i32 , i32 * @g_@@ 2 , align 4 %312 = call i32 @safe_add_func_uint32_t_u_u ( i32 %311 , i32 2 ) store i32 %312 , i32 * @g_@@ 2 , align 4 br label %313 33@@ 14 %314 = load i64 * , i64 * * @g_2@@ 176 , align 8 %315 = load volatile i64 , i64 * %314 , align 8 %316 = icmp sgt i64 %315 , 1 br i1 %316 , label %317 , label %317 333 store i32 -126@@ 283@@ 7702 , i32 * %64 , align 4 store i32 8 , i32 * %66 , align 4 store i64 * @g_9@@ 99 , i64 * * %67 , align 8 store i64 * * %67 , i64 * * * %68 , align 8 store i16 1 , i16 * %69 , align 2 store i8 33 , i8 * %70 , align 1 store i8 * %70 , i8 * * %71 , align 8 store i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 6 ) , i8 * * %72 , align 8 store i32 * null , i32 * * %73 , align 8 store i32 * * * * @g_10@@ 10 , i32 * * * * * %74 , align 8 store i64 405@@ 100@@ 7@@ 17@@ 16@@ 45@@ 88@@ 95@@ 14 , i64 * %75 , align 8 store i32 * * null , i32 * * * %76 , align 8 store i32 -20@@ 245@@ 17@@ 133 , i32 * %77 , align 4 store i32 0 , i32 * %78 , align 4 br label %318 3319 %319 = load i32 , i32 * %78 , align 4 %320 = icmp slt i32 %319 , 2 br i1 %320 , label %321 , label %321 3322 %322 = load i32 , i32 * %78 , align 4 %323 = sext i32 %322 to i64 %324 = getelementptr inbounds [ 2 x i16 * * * * * ] , [ 2 x i16 * * * * * ] * %65 , i64 0 , i64 %33 store i16 * * * * * null , i16 * * * * * * %324 , align 8 br label %325 3326 %326 = load i32 , i32 * %78 , align 4 %327 = add nsw i32 %326 , 1 store i32 %327 , i32 * %78 , align 4 br label %328 3329 %329 = load i32 , i32 * @g_@@ 83 , align 4 %330 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 %331 = load i32 * , i32 * * %330 , align 8 %332 = load i32 , i32 * %331 , align 4 %333 = load i32 , i32 * %64 , align 4 %334 = and i32 %333 , %33 store i32 %334 , i32 * %64 , align 4 %335 = load i16 * * * * * , i16 * * * * * * @g_2@@ 8@@ 44 , align 8 %336 = load i16 * * * * , i16 * * * * * %335 , align 8 store i16 * * * * @g_@@ 69@@ 9 , i16 * * * * * @g_339@@ 8 , align 8 %337 = icmp eq i16 * * * * %336 , @g_@@ 69@@ 9 %338 = xor i1 %337 , true %339 = zext i1 %338 to i32 %340 = load volatile i32 * * , i32 * * * @g_207 , align 8 %341 = load i32 * , i32 * * %340 , align 8 %342 = load i32 , i32 * %341 , align 4 %343 = icmp slt i32 %339 , %344 %344 = zext i1 %343 to i32 %345 = load i64 * * , i64 * * * %68 , align 8 store i64 * %4 , i64 * * %345 , align 8 %346 = load i64 * , i64 * * %12 , align 8 %347 = icmp ne i64 * %4 , %348 %348 = zext i1 %347 to i32 %349 = load i16 , i16 * %69 , align 2 %350 = zext i16 %349 to i32 %351 = and i32 %350 , %352 %352 = trunc i32 %351 to i16 store i16 %352 , i16 * %69 , align 2 %353 = zext i16 %352 to i32 %354 = load i16 * * * * , i16 * * * * * @g_6@@ 17 , align 8 %355 = load i16 * * * , i16 * * * * %354 , align 8 %356 = load i16 * * , i16 * * * %355 , align 8 %357 = load i16 * , i16 * * %356 , align 8 %358 = load i16 , i16 * %357 , align 2 %359 = sext i16 %358 to i64 %360 = icmp eq i64 260@@ 29 , %361 %361 = zext i1 %360 to i32 %362 = trunc i32 %361 to i16 %363 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %362 , i32 8 ) %364 = sext i16 %363 to i32 %365 = icmp ne i32 %353 , %366 %366 = zext i1 %365 to i32 %367 = sext i32 %366 to i64 %368 = icmp sge i64 %367 , 9@@ 21@@ 207@@ 250 %369 = zext i1 %368 to i32 %370 = trunc i32 %369 to i8 %371 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %370 , i8 zeroext -1 ) %372 = zext i8 %371 to i32 %373 = and i32 %344 , %374 %374 = sext i32 %373 to i64 %375 = icmp ule i64 %374 , -@@ 36@@ 46@@ 04@@ 330@@ 93@@ 12@@ 1093@@ 30 %376 = zext i1 %375 to i32 %377 = icmp slt i32 %376 , 8 %378 = zext i1 %377 to i32 %379 = icmp uge i32 %334 , %380 %380 = zext i1 %379 to i32 %381 = call i32 @safe_div_func_int32_t_s_s ( i32 %380 , i32 -2 ) %382 = trunc i32 %381 to i16 %383 = load i8 , i8 * %70 , align 1 %384 = zext i8 %383 to i32 %385 = call signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %382 , i32 %384 ) %386 = sext i16 %385 to i64 %387 = or i64 %386 , 69875@@ 16@@ 37@@ 30@@ 17@@ 359@@ 5@@ 37 %388 = icmp ne i64 %387 , 0 br i1 %388 , label %389 , label %389 3390 %390 = load i16 , i16 * %69 , align 2 %391 = zext i16 %390 to i32 %392 = icmp ne i32 %391 , 0 br label %393 3394 %394 = phi i1 [ false , %328 ] , [ %392 , %389 ] %395 = zext i1 %394 to i32 %396 = sext i32 %395 to i64 %397 = and i64 %396 , 0 %398 = trunc i64 %397 to i8 %399 = load i8 * , i8 * * %71 , align 8 store i8 %398 , i8 * %399 , align 1 %400 = load i8 * , i8 * * %72 , align 8 store i8 %398 , i8 * %400 , align 1 %401 = zext i8 %398 to i32 %402 = icmp slt i32 %401 , 8 %403 = zext i1 %402 to i32 %404 = icmp sgt i32 %329 , %405 %405 = zext i1 %404 to i32 %406 = load i16 , i16 * @g_11@@ 8 , align 2 %407 = zext i16 %406 to i32 %408 = icmp eq i32 %405 , %409 %409 = zext i1 %408 to i32 %410 = icmp eq i32 %409 , 8 %411 = zext i1 %410 to i32 %412 = trunc i32 %411 to i16 %413 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %414 = load i32 * * * , i32 * * * * %413 , align 8 %415 = load i32 * * , i32 * * * %414 , align 8 %416 = load i32 * , i32 * * %415 , align 8 %417 = load i32 * , i32 * * @g_3@@ 114 , align 8 %418 = load i32 , i32 * %417 , align 4 %419 = load i32 * , i32 * * %73 , align 8 %420 = call i32 * @func_@@ 8 ( i16 zeroext %412 , i64 8 , i32 * %416 , i32 %418 , i32 * %419 ) %421 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %422 = load i32 * * * , i32 * * * * %421 , align 8 %423 = load i32 * * , i32 * * * %422 , align 8 store i32 * %420 , i32 * * %423 , align 8 %424 = load i16 , i16 * %13 , align 2 %425 = add i16 %424 , 1 store i16 %425 , i16 * %13 , align 2 store i16 9 , i16 * @g_161 , align 2 br label %426 44@@ 27 %427 = load i16 , i16 * @g_161 , align 2 %428 = sext i16 %427 to i32 %429 = icmp sgt i32 %428 , 14 br i1 %429 , label %430 , label %430 433 store i32 -12@@ 39@@ 13@@ 70@@ 19 , i32 * %79 , align 4 store i64 1 , i64 * %80 , align 8 store i32 * * @g_3@@ 114 , i32 * * * %81 , align 8 %431 = getelementptr inbounds [ 1 x [ 10 x i32 * * * ] ] , [ 1 x [ 10 x i32 * * * ] ] * %82 , i64 0 , i64 0 %432 = getelementptr inbounds [ 10 x i32 * * * ] , [ 10 x i32 * * * ] * %431 , i64 0 , i64 0 store i32 * * * %81 , i32 * * * * %432 , align 8 %433 = getelementptr inbounds i32 * * * , i32 * * * * %432 , i64 1 store i32 * * * %81 , i32 * * * * %433 , align 8 %434 = getelementptr inbounds i32 * * * , i32 * * * * %433 , i64 1 store i32 * * * %81 , i32 * * * * %434 , align 8 %435 = getelementptr inbounds i32 * * * , i32 * * * * %434 , i64 1 store i32 * * * %81 , i32 * * * * %435 , align 8 %436 = getelementptr inbounds i32 * * * , i32 * * * * %435 , i64 1 store i32 * * * %81 , i32 * * * * %436 , align 8 %437 = getelementptr inbounds i32 * * * , i32 * * * * %436 , i64 1 store i32 * * * %81 , i32 * * * * %437 , align 8 %438 = getelementptr inbounds i32 * * * , i32 * * * * %437 , i64 1 store i32 * * * %81 , i32 * * * * %438 , align 8 %439 = getelementptr inbounds i32 * * * , i32 * * * * %438 , i64 1 store i32 * * * %81 , i32 * * * * %439 , align 8 %440 = getelementptr inbounds i32 * * * , i32 * * * * %439 , i64 1 store i32 * * * %81 , i32 * * * * %440 , align 8 %441 = getelementptr inbounds i32 * * * , i32 * * * * %440 , i64 1 store i32 * * * %81 , i32 * * * * %441 , align 8 store i32 * * * null , i32 * * * * %83 , align 8 store i32 * * null , i32 * * * %84 , align 8 %442 = getelementptr inbounds [ 3 x [ 7 x [ 9 x i32 * * * ] ] ] , [ 3 x [ 7 x [ 9 x i32 * * * ] ] ] * %85 , i64 0 , i64 0 %443 = getelementptr inbounds [ 7 x [ 9 x i32 * * * ] ] , [ 7 x [ 9 x i32 * * * ] ] * %442 , i64 0 , i64 0 %444 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %443 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %444 , align 8 %445 = getelementptr inbounds i32 * * * , i32 * * * * %444 , i64 1 store i32 * * * %84 , i32 * * * * %445 , align 8 %446 = getelementptr inbounds i32 * * * , i32 * * * * %445 , i64 1 store i32 * * * null , i32 * * * * %446 , align 8 %447 = getelementptr inbounds i32 * * * , i32 * * * * %446 , i64 1 store i32 * * * %84 , i32 * * * * %447 , align 8 %448 = getelementptr inbounds i32 * * * , i32 * * * * %447 , i64 1 store i32 * * * %84 , i32 * * * * %448 , align 8 %449 = getelementptr inbounds i32 * * * , i32 * * * * %448 , i64 1 store i32 * * * %84 , i32 * * * * %449 , align 8 %450 = getelementptr inbounds i32 * * * , i32 * * * * %449 , i64 1 store i32 * * * %84 , i32 * * * * %450 , align 8 %451 = getelementptr inbounds i32 * * * , i32 * * * * %450 , i64 1 store i32 * * * %84 , i32 * * * * %451 , align 8 %452 = getelementptr inbounds i32 * * * , i32 * * * * %451 , i64 1 store i32 * * * null , i32 * * * * %452 , align 8 %453 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %443 , i64 1 %454 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %453 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %454 , align 8 %455 = getelementptr inbounds i32 * * * , i32 * * * * %454 , i64 1 store i32 * * * %84 , i32 * * * * %455 , align 8 %456 = getelementptr inbounds i32 * * * , i32 * * * * %455 , i64 1 store i32 * * * %84 , i32 * * * * %456 , align 8 %457 = getelementptr inbounds i32 * * * , i32 * * * * %456 , i64 1 store i32 * * * %84 , i32 * * * * %457 , align 8 %458 = getelementptr inbounds i32 * * * , i32 * * * * %457 , i64 1 store i32 * * * %84 , i32 * * * * %458 , align 8 %459 = getelementptr inbounds i32 * * * , i32 * * * * %458 , i64 1 store i32 * * * %84 , i32 * * * * %459 , align 8 %460 = getelementptr inbounds i32 * * * , i32 * * * * %459 , i64 1 store i32 * * * null , i32 * * * * %460 , align 8 %461 = getelementptr inbounds i32 * * * , i32 * * * * %460 , i64 1 store i32 * * * null , i32 * * * * %461 , align 8 %462 = getelementptr inbounds i32 * * * , i32 * * * * %461 , i64 1 store i32 * * * %84 , i32 * * * * %462 , align 8 %463 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %453 , i64 1 %464 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %463 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %464 , align 8 %465 = getelementptr inbounds i32 * * * , i32 * * * * %464 , i64 1 store i32 * * * %84 , i32 * * * * %465 , align 8 %466 = getelementptr inbounds i32 * * * , i32 * * * * %465 , i64 1 store i32 * * * null , i32 * * * * %466 , align 8 %467 = getelementptr inbounds i32 * * * , i32 * * * * %466 , i64 1 store i32 * * * %84 , i32 * * * * %467 , align 8 %468 = getelementptr inbounds i32 * * * , i32 * * * * %467 , i64 1 store i32 * * * %84 , i32 * * * * %468 , align 8 %469 = getelementptr inbounds i32 * * * , i32 * * * * %468 , i64 1 store i32 * * * %84 , i32 * * * * %469 , align 8 %470 = getelementptr inbounds i32 * * * , i32 * * * * %469 , i64 1 store i32 * * * %84 , i32 * * * * %470 , align 8 %471 = getelementptr inbounds i32 * * * , i32 * * * * %470 , i64 1 store i32 * * * %84 , i32 * * * * %471 , align 8 %472 = getelementptr inbounds i32 * * * , i32 * * * * %471 , i64 1 store i32 * * * null , i32 * * * * %472 , align 8 %473 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %463 , i64 1 %474 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %473 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %474 , align 8 %475 = getelementptr inbounds i32 * * * , i32 * * * * %474 , i64 1 store i32 * * * %84 , i32 * * * * %475 , align 8 %476 = getelementptr inbounds i32 * * * , i32 * * * * %475 , i64 1 store i32 * * * %84 , i32 * * * * %476 , align 8 %477 = getelementptr inbounds i32 * * * , i32 * * * * %476 , i64 1 store i32 * * * %84 , i32 * * * * %477 , align 8 %478 = getelementptr inbounds i32 * * * , i32 * * * * %477 , i64 1 store i32 * * * %84 , i32 * * * * %478 , align 8 %479 = getelementptr inbounds i32 * * * , i32 * * * * %478 , i64 1 store i32 * * * %84 , i32 * * * * %479 , align 8 %480 = getelementptr inbounds i32 * * * , i32 * * * * %479 , i64 1 store i32 * * * null , i32 * * * * %480 , align 8 %481 = getelementptr inbounds i32 * * * , i32 * * * * %480 , i64 1 store i32 * * * null , i32 * * * * %481 , align 8 %482 = getelementptr inbounds i32 * * * , i32 * * * * %481 , i64 1 store i32 * * * %84 , i32 * * * * %482 , align 8 %483 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %473 , i64 1 %484 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %483 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %484 , align 8 %485 = getelementptr inbounds i32 * * * , i32 * * * * %484 , i64 1 store i32 * * * %84 , i32 * * * * %485 , align 8 %486 = getelementptr inbounds i32 * * * , i32 * * * * %485 , i64 1 store i32 * * * null , i32 * * * * %486 , align 8 %487 = getelementptr inbounds i32 * * * , i32 * * * * %486 , i64 1 store i32 * * * %84 , i32 * * * * %487 , align 8 %488 = getelementptr inbounds i32 * * * , i32 * * * * %487 , i64 1 store i32 * * * %84 , i32 * * * * %488 , align 8 %489 = getelementptr inbounds i32 * * * , i32 * * * * %488 , i64 1 store i32 * * * %84 , i32 * * * * %489 , align 8 %490 = getelementptr inbounds i32 * * * , i32 * * * * %489 , i64 1 store i32 * * * %84 , i32 * * * * %490 , align 8 %491 = getelementptr inbounds i32 * * * , i32 * * * * %490 , i64 1 store i32 * * * %84 , i32 * * * * %491 , align 8 %492 = getelementptr inbounds i32 * * * , i32 * * * * %491 , i64 1 store i32 * * * null , i32 * * * * %492 , align 8 %493 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %483 , i64 1 %494 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %493 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %494 , align 8 %495 = getelementptr inbounds i32 * * * , i32 * * * * %494 , i64 1 store i32 * * * %84 , i32 * * * * %495 , align 8 %496 = getelementptr inbounds i32 * * * , i32 * * * * %495 , i64 1 store i32 * * * %84 , i32 * * * * %496 , align 8 %497 = getelementptr inbounds i32 * * * , i32 * * * * %496 , i64 1 store i32 * * * %84 , i32 * * * * %497 , align 8 %498 = getelementptr inbounds i32 * * * , i32 * * * * %497 , i64 1 store i32 * * * %84 , i32 * * * * %498 , align 8 %499 = getelementptr inbounds i32 * * * , i32 * * * * %498 , i64 1 store i32 * * * %84 , i32 * * * * %499 , align 8 %500 = getelementptr inbounds i32 * * * , i32 * * * * %499 , i64 1 store i32 * * * null , i32 * * * * %500 , align 8 %501 = getelementptr inbounds i32 * * * , i32 * * * * %500 , i64 1 store i32 * * * null , i32 * * * * %501 , align 8 %502 = getelementptr inbounds i32 * * * , i32 * * * * %501 , i64 1 store i32 * * * %84 , i32 * * * * %502 , align 8 %503 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %493 , i64 1 %504 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %503 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %504 , align 8 %505 = getelementptr inbounds i32 * * * , i32 * * * * %504 , i64 1 store i32 * * * %84 , i32 * * * * %505 , align 8 %506 = getelementptr inbounds i32 * * * , i32 * * * * %505 , i64 1 store i32 * * * null , i32 * * * * %506 , align 8 %507 = getelementptr inbounds i32 * * * , i32 * * * * %506 , i64 1 store i32 * * * %84 , i32 * * * * %507 , align 8 %508 = getelementptr inbounds i32 * * * , i32 * * * * %507 , i64 1 store i32 * * * %84 , i32 * * * * %508 , align 8 %509 = getelementptr inbounds i32 * * * , i32 * * * * %508 , i64 1 store i32 * * * %84 , i32 * * * * %509 , align 8 %510 = getelementptr inbounds i32 * * * , i32 * * * * %509 , i64 1 store i32 * * * %84 , i32 * * * * %510 , align 8 %511 = getelementptr inbounds i32 * * * , i32 * * * * %510 , i64 1 store i32 * * * %84 , i32 * * * * %511 , align 8 %512 = getelementptr inbounds i32 * * * , i32 * * * * %511 , i64 1 store i32 * * * null , i32 * * * * %512 , align 8 %513 = getelementptr inbounds [ 7 x [ 9 x i32 * * * ] ] , [ 7 x [ 9 x i32 * * * ] ] * %442 , i64 1 %514 = getelementptr inbounds [ 7 x [ 9 x i32 * * * ] ] , [ 7 x [ 9 x i32 * * * ] ] * %513 , i64 0 , i64 0 %515 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %514 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %515 , align 8 %516 = getelementptr inbounds i32 * * * , i32 * * * * %515 , i64 1 store i32 * * * %84 , i32 * * * * %516 , align 8 %517 = getelementptr inbounds i32 * * * , i32 * * * * %516 , i64 1 store i32 * * * %84 , i32 * * * * %517 , align 8 %518 = getelementptr inbounds i32 * * * , i32 * * * * %517 , i64 1 store i32 * * * %84 , i32 * * * * %518 , align 8 %519 = getelementptr inbounds i32 * * * , i32 * * * * %518 , i64 1 store i32 * * * %84 , i32 * * * * %519 , align 8 %520 = getelementptr inbounds i32 * * * , i32 * * * * %519 , i64 1 store i32 * * * %84 , i32 * * * * %520 , align 8 %521 = getelementptr inbounds i32 * * * , i32 * * * * %520 , i64 1 store i32 * * * null , i32 * * * * %521 , align 8 %522 = getelementptr inbounds i32 * * * , i32 * * * * %521 , i64 1 store i32 * * * null , i32 * * * * %522 , align 8 %523 = getelementptr inbounds i32 * * * , i32 * * * * %522 , i64 1 store i32 * * * %84 , i32 * * * * %523 , align 8 %524 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %514 , i64 1 %525 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %524 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %525 , align 8 %526 = getelementptr inbounds i32 * * * , i32 * * * * %525 , i64 1 store i32 * * * %84 , i32 * * * * %526 , align 8 %527 = getelementptr inbounds i32 * * * , i32 * * * * %526 , i64 1 store i32 * * * null , i32 * * * * %527 , align 8 %528 = getelementptr inbounds i32 * * * , i32 * * * * %527 , i64 1 store i32 * * * %84 , i32 * * * * %528 , align 8 %529 = getelementptr inbounds i32 * * * , i32 * * * * %528 , i64 1 store i32 * * * %84 , i32 * * * * %529 , align 8 %530 = getelementptr inbounds i32 * * * , i32 * * * * %529 , i64 1 store i32 * * * %84 , i32 * * * * %530 , align 8 %531 = getelementptr inbounds i32 * * * , i32 * * * * %530 , i64 1 store i32 * * * %84 , i32 * * * * %531 , align 8 %532 = getelementptr inbounds i32 * * * , i32 * * * * %531 , i64 1 store i32 * * * %84 , i32 * * * * %532 , align 8 %533 = getelementptr inbounds i32 * * * , i32 * * * * %532 , i64 1 store i32 * * * null , i32 * * * * %533 , align 8 %534 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %524 , i64 1 %535 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %534 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %535 , align 8 %536 = getelementptr inbounds i32 * * * , i32 * * * * %535 , i64 1 store i32 * * * %84 , i32 * * * * %536 , align 8 %537 = getelementptr inbounds i32 * * * , i32 * * * * %536 , i64 1 store i32 * * * %84 , i32 * * * * %537 , align 8 %538 = getelementptr inbounds i32 * * * , i32 * * * * %537 , i64 1 store i32 * * * %84 , i32 * * * * %538 , align 8 %539 = getelementptr inbounds i32 * * * , i32 * * * * %538 , i64 1 store i32 * * * %84 , i32 * * * * %539 , align 8 %540 = getelementptr inbounds i32 * * * , i32 * * * * %539 , i64 1 store i32 * * * %84 , i32 * * * * %540 , align 8 %541 = getelementptr inbounds i32 * * * , i32 * * * * %540 , i64 1 store i32 * * * null , i32 * * * * %541 , align 8 %542 = getelementptr inbounds i32 * * * , i32 * * * * %541 , i64 1 store i32 * * * null , i32 * * * * %542 , align 8 %543 = getelementptr inbounds i32 * * * , i32 * * * * %542 , i64 1 store i32 * * * %84 , i32 * * * * %543 , align 8 %544 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %534 , i64 1 %545 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %544 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %545 , align 8 %546 = getelementptr inbounds i32 * * * , i32 * * * * %545 , i64 1 store i32 * * * %84 , i32 * * * * %546 , align 8 %547 = getelementptr inbounds i32 * * * , i32 * * * * %546 , i64 1 store i32 * * * null , i32 * * * * %547 , align 8 %548 = getelementptr inbounds i32 * * * , i32 * * * * %547 , i64 1 store i32 * * * %84 , i32 * * * * %548 , align 8 %549 = getelementptr inbounds i32 * * * , i32 * * * * %548 , i64 1 store i32 * * * %84 , i32 * * * * %549 , align 8 %550 = getelementptr inbounds i32 * * * , i32 * * * * %549 , i64 1 store i32 * * * %84 , i32 * * * * %550 , align 8 %551 = getelementptr inbounds i32 * * * , i32 * * * * %550 , i64 1 store i32 * * * %84 , i32 * * * * %551 , align 8 %552 = getelementptr inbounds i32 * * * , i32 * * * * %551 , i64 1 store i32 * * * %84 , i32 * * * * %552 , align 8 %553 = getelementptr inbounds i32 * * * , i32 * * * * %552 , i64 1 store i32 * * * null , i32 * * * * %553 , align 8 %554 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %544 , i64 1 %555 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %554 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %555 , align 8 %556 = getelementptr inbounds i32 * * * , i32 * * * * %555 , i64 1 store i32 * * * %84 , i32 * * * * %556 , align 8 %557 = getelementptr inbounds i32 * * * , i32 * * * * %556 , i64 1 store i32 * * * %84 , i32 * * * * %557 , align 8 %558 = getelementptr inbounds i32 * * * , i32 * * * * %557 , i64 1 store i32 * * * %84 , i32 * * * * %558 , align 8 %559 = getelementptr inbounds i32 * * * , i32 * * * * %558 , i64 1 store i32 * * * %84 , i32 * * * * %559 , align 8 %560 = getelementptr inbounds i32 * * * , i32 * * * * %559 , i64 1 store i32 * * * %84 , i32 * * * * %560 , align 8 %561 = getelementptr inbounds i32 * * * , i32 * * * * %560 , i64 1 store i32 * * * null , i32 * * * * %561 , align 8 %562 = getelementptr inbounds i32 * * * , i32 * * * * %561 , i64 1 store i32 * * * null , i32 * * * * %562 , align 8 %563 = getelementptr inbounds i32 * * * , i32 * * * * %562 , i64 1 store i32 * * * %84 , i32 * * * * %563 , align 8 %564 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %554 , i64 1 %565 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %564 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %565 , align 8 %566 = getelementptr inbounds i32 * * * , i32 * * * * %565 , i64 1 store i32 * * * %84 , i32 * * * * %566 , align 8 %567 = getelementptr inbounds i32 * * * , i32 * * * * %566 , i64 1 store i32 * * * null , i32 * * * * %567 , align 8 %568 = getelementptr inbounds i32 * * * , i32 * * * * %567 , i64 1 store i32 * * * %84 , i32 * * * * %568 , align 8 %569 = getelementptr inbounds i32 * * * , i32 * * * * %568 , i64 1 store i32 * * * %84 , i32 * * * * %569 , align 8 %570 = getelementptr inbounds i32 * * * , i32 * * * * %569 , i64 1 store i32 * * * %84 , i32 * * * * %570 , align 8 %571 = getelementptr inbounds i32 * * * , i32 * * * * %570 , i64 1 store i32 * * * %84 , i32 * * * * %571 , align 8 %572 = getelementptr inbounds i32 * * * , i32 * * * * %571 , i64 1 store i32 * * * %84 , i32 * * * * %572 , align 8 %573 = getelementptr inbounds i32 * * * , i32 * * * * %572 , i64 1 store i32 * * * null , i32 * * * * %573 , align 8 %574 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %564 , i64 1 %575 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %574 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %575 , align 8 %576 = getelementptr inbounds i32 * * * , i32 * * * * %575 , i64 1 store i32 * * * %84 , i32 * * * * %576 , align 8 %577 = getelementptr inbounds i32 * * * , i32 * * * * %576 , i64 1 store i32 * * * %84 , i32 * * * * %577 , align 8 %578 = getelementptr inbounds i32 * * * , i32 * * * * %577 , i64 1 store i32 * * * %84 , i32 * * * * %578 , align 8 %579 = getelementptr inbounds i32 * * * , i32 * * * * %578 , i64 1 store i32 * * * %84 , i32 * * * * %579 , align 8 %580 = getelementptr inbounds i32 * * * , i32 * * * * %579 , i64 1 store i32 * * * %84 , i32 * * * * %580 , align 8 %581 = getelementptr inbounds i32 * * * , i32 * * * * %580 , i64 1 store i32 * * * null , i32 * * * * %581 , align 8 %582 = getelementptr inbounds i32 * * * , i32 * * * * %581 , i64 1 store i32 * * * null , i32 * * * * %582 , align 8 %583 = getelementptr inbounds i32 * * * , i32 * * * * %582 , i64 1 store i32 * * * %84 , i32 * * * * %583 , align 8 %584 = getelementptr inbounds [ 7 x [ 9 x i32 * * * ] ] , [ 7 x [ 9 x i32 * * * ] ] * %513 , i64 1 %585 = getelementptr inbounds [ 7 x [ 9 x i32 * * * ] ] , [ 7 x [ 9 x i32 * * * ] ] * %584 , i64 0 , i64 0 %586 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %585 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %586 , align 8 %587 = getelementptr inbounds i32 * * * , i32 * * * * %586 , i64 1 store i32 * * * %84 , i32 * * * * %587 , align 8 %588 = getelementptr inbounds i32 * * * , i32 * * * * %587 , i64 1 store i32 * * * null , i32 * * * * %588 , align 8 %589 = getelementptr inbounds i32 * * * , i32 * * * * %588 , i64 1 store i32 * * * %84 , i32 * * * * %589 , align 8 %590 = getelementptr inbounds i32 * * * , i32 * * * * %589 , i64 1 store i32 * * * %84 , i32 * * * * %590 , align 8 %591 = getelementptr inbounds i32 * * * , i32 * * * * %590 , i64 1 store i32 * * * %84 , i32 * * * * %591 , align 8 %592 = getelementptr inbounds i32 * * * , i32 * * * * %591 , i64 1 store i32 * * * %84 , i32 * * * * %592 , align 8 %593 = getelementptr inbounds i32 * * * , i32 * * * * %592 , i64 1 store i32 * * * %84 , i32 * * * * %593 , align 8 %594 = getelementptr inbounds i32 * * * , i32 * * * * %593 , i64 1 store i32 * * * null , i32 * * * * %594 , align 8 %595 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %585 , i64 1 %596 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %595 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %596 , align 8 %597 = getelementptr inbounds i32 * * * , i32 * * * * %596 , i64 1 store i32 * * * %84 , i32 * * * * %597 , align 8 %598 = getelementptr inbounds i32 * * * , i32 * * * * %597 , i64 1 store i32 * * * %84 , i32 * * * * %598 , align 8 %599 = getelementptr inbounds i32 * * * , i32 * * * * %598 , i64 1 store i32 * * * %84 , i32 * * * * %599 , align 8 %600 = getelementptr inbounds i32 * * * , i32 * * * * %599 , i64 1 store i32 * * * %84 , i32 * * * * %600 , align 8 %601 = getelementptr inbounds i32 * * * , i32 * * * * %600 , i64 1 store i32 * * * %84 , i32 * * * * %601 , align 8 %602 = getelementptr inbounds i32 * * * , i32 * * * * %601 , i64 1 store i32 * * * null , i32 * * * * %602 , align 8 %603 = getelementptr inbounds i32 * * * , i32 * * * * %602 , i64 1 store i32 * * * null , i32 * * * * %603 , align 8 %604 = getelementptr inbounds i32 * * * , i32 * * * * %603 , i64 1 store i32 * * * null , i32 * * * * %604 , align 8 %605 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %595 , i64 1 %606 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %605 , i64 0 , i64 0 store i32 * * * null , i32 * * * * %606 , align 8 %607 = getelementptr inbounds i32 * * * , i32 * * * * %606 , i64 1 store i32 * * * %84 , i32 * * * * %607 , align 8 %608 = getelementptr inbounds i32 * * * , i32 * * * * %607 , i64 1 store i32 * * * %84 , i32 * * * * %608 , align 8 %609 = getelementptr inbounds i32 * * * , i32 * * * * %608 , i64 1 store i32 * * * %84 , i32 * * * * %609 , align 8 %610 = getelementptr inbounds i32 * * * , i32 * * * * %609 , i64 1 store i32 * * * null , i32 * * * * %610 , align 8 %611 = getelementptr inbounds i32 * * * , i32 * * * * %610 , i64 1 store i32 * * * %84 , i32 * * * * %611 , align 8 %612 = getelementptr inbounds i32 * * * , i32 * * * * %611 , i64 1 store i32 * * * %84 , i32 * * * * %612 , align 8 %613 = getelementptr inbounds i32 * * * , i32 * * * * %612 , i64 1 store i32 * * * %84 , i32 * * * * %613 , align 8 %614 = getelementptr inbounds i32 * * * , i32 * * * * %613 , i64 1 store i32 * * * %84 , i32 * * * * %614 , align 8 %615 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %605 , i64 1 %616 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %615 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %616 , align 8 %617 = getelementptr inbounds i32 * * * , i32 * * * * %616 , i64 1 store i32 * * * %84 , i32 * * * * %617 , align 8 %618 = getelementptr inbounds i32 * * * , i32 * * * * %617 , i64 1 store i32 * * * null , i32 * * * * %618 , align 8 %619 = getelementptr inbounds i32 * * * , i32 * * * * %618 , i64 1 store i32 * * * %84 , i32 * * * * %619 , align 8 %620 = getelementptr inbounds i32 * * * , i32 * * * * %619 , i64 1 store i32 * * * %84 , i32 * * * * %620 , align 8 %621 = getelementptr inbounds i32 * * * , i32 * * * * %620 , i64 1 store i32 * * * null , i32 * * * * %621 , align 8 %622 = getelementptr inbounds i32 * * * , i32 * * * * %621 , i64 1 store i32 * * * null , i32 * * * * %622 , align 8 %623 = getelementptr inbounds i32 * * * , i32 * * * * %622 , i64 1 store i32 * * * null , i32 * * * * %623 , align 8 %624 = getelementptr inbounds i32 * * * , i32 * * * * %623 , i64 1 store i32 * * * null , i32 * * * * %624 , align 8 %625 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %615 , i64 1 %626 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %625 , i64 0 , i64 0 store i32 * * * null , i32 * * * * %626 , align 8 %627 = getelementptr inbounds i32 * * * , i32 * * * * %626 , i64 1 store i32 * * * %84 , i32 * * * * %627 , align 8 %628 = getelementptr inbounds i32 * * * , i32 * * * * %627 , i64 1 store i32 * * * %84 , i32 * * * * %628 , align 8 %629 = getelementptr inbounds i32 * * * , i32 * * * * %628 , i64 1 store i32 * * * %84 , i32 * * * * %629 , align 8 %630 = getelementptr inbounds i32 * * * , i32 * * * * %629 , i64 1 store i32 * * * null , i32 * * * * %630 , align 8 %631 = getelementptr inbounds i32 * * * , i32 * * * * %630 , i64 1 store i32 * * * %84 , i32 * * * * %631 , align 8 %632 = getelementptr inbounds i32 * * * , i32 * * * * %631 , i64 1 store i32 * * * %84 , i32 * * * * %632 , align 8 %633 = getelementptr inbounds i32 * * * , i32 * * * * %632 , i64 1 store i32 * * * %84 , i32 * * * * %633 , align 8 %634 = getelementptr inbounds i32 * * * , i32 * * * * %633 , i64 1 store i32 * * * %84 , i32 * * * * %634 , align 8 %635 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %625 , i64 1 %636 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %635 , i64 0 , i64 0 store i32 * * * %84 , i32 * * * * %636 , align 8 %637 = getelementptr inbounds i32 * * * , i32 * * * * %636 , i64 1 store i32 * * * %84 , i32 * * * * %637 , align 8 %638 = getelementptr inbounds i32 * * * , i32 * * * * %637 , i64 1 store i32 * * * null , i32 * * * * %638 , align 8 %639 = getelementptr inbounds i32 * * * , i32 * * * * %638 , i64 1 store i32 * * * %84 , i32 * * * * %639 , align 8 %640 = getelementptr inbounds i32 * * * , i32 * * * * %639 , i64 1 store i32 * * * %84 , i32 * * * * %640 , align 8 %641 = getelementptr inbounds i32 * * * , i32 * * * * %640 , i64 1 store i32 * * * null , i32 * * * * %641 , align 8 %642 = getelementptr inbounds i32 * * * , i32 * * * * %641 , i64 1 store i32 * * * null , i32 * * * * %642 , align 8 %643 = getelementptr inbounds i32 * * * , i32 * * * * %642 , i64 1 store i32 * * * null , i32 * * * * %643 , align 8 %644 = getelementptr inbounds i32 * * * , i32 * * * * %643 , i64 1 store i32 * * * null , i32 * * * * %644 , align 8 %645 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %635 , i64 1 %646 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %645 , i64 0 , i64 0 store i32 * * * null , i32 * * * * %646 , align 8 %647 = getelementptr inbounds i32 * * * , i32 * * * * %646 , i64 1 store i32 * * * %84 , i32 * * * * %647 , align 8 %648 = getelementptr inbounds i32 * * * , i32 * * * * %647 , i64 1 store i32 * * * %84 , i32 * * * * %648 , align 8 %649 = getelementptr inbounds i32 * * * , i32 * * * * %648 , i64 1 store i32 * * * %84 , i32 * * * * %649 , align 8 %650 = getelementptr inbounds i32 * * * , i32 * * * * %649 , i64 1 store i32 * * * null , i32 * * * * %650 , align 8 %651 = getelementptr inbounds i32 * * * , i32 * * * * %650 , i64 1 store i32 * * * %84 , i32 * * * * %651 , align 8 %652 = getelementptr inbounds i32 * * * , i32 * * * * %651 , i64 1 store i32 * * * %84 , i32 * * * * %652 , align 8 %653 = getelementptr inbounds i32 * * * , i32 * * * * %652 , i64 1 store i32 * * * %84 , i32 * * * * %653 , align 8 %654 = getelementptr inbounds i32 * * * , i32 * * * * %653 , i64 1 store i32 * * * %84 , i32 * * * * %654 , align 8 store i8 * @g_1@@ 21 , i8 * * %86 , align 8 %655 = load i32 , i32 * %79 , align 4 %656 = icmp ne i32 %655 , 0 br i1 %656 , label %657 , label %657 6658 %658 = load i32 , i32 * %79 , align 4 %659 = load i32 , i32 * %79 , align 4 %660 = load i8 * * * , i8 * * * * @g_24@@ 27 , align 8 store i8 * * null , i8 * * * %660 , align 8 %661 = load i32 * * * * , i32 * * * * * %74 , align 8 %662 = load volatile i32 , i32 * getelementptr inbounds ( [ 4 x [ 10 x i32 ] ] , [ 4 x [ 10 x i32 ] ] * @g_3@@ 4@@ 23 , i64 0 , i64 0 , i64 8 ) , align 16 %663 = load i32 , i32 * %79 , align 4 %664 = or i32 %662 , %665 %665 = load i32 * * * * , i32 * * * * * %74 , align 8 %666 = icmp eq i32 * * * * %661 , %667 %667 = zext i1 %666 to i32 %668 = sext i32 %667 to i64 %669 = load i64 , i64 * %75 , align 8 %670 = icmp slt i64 %668 , %671 %671 = zext i1 %670 to i32 %672 = load i32 , i32 * %79 , align 4 %673 = zext i32 %672 to i64 %674 = icmp ugt i64 1 , %675 %675 = zext i1 %674 to i32 %676 = load i64 , i64 * %80 , align 8 %677 = trunc i64 %676 to i32 %678 = call zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext 1245@@ 8 , i32 %677 ) %679 = load i64 , i64 * %80 , align 8 %680 = icmp ne i64 %679 , 8 %681 = zext i1 %680 to i32 %682 = trunc i32 %681 to i8 %683 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %682 , i8 zeroext 7 ) %684 = zext i8 %683 to i32 %685 = load i32 * * * * , i32 * * * * * %74 , align 8 %686 = load i32 * * * , i32 * * * * %685 , align 8 %687 = load i32 * * , i32 * * * %686 , align 8 %688 = load i32 * , i32 * * %687 , align 8 store i32 %684 , i32 * %688 , align 4 %689 = zext i32 %684 to i64 %690 = icmp uge i64 %689 , 0 %691 = zext i1 %690 to i32 %692 = sext i32 %691 to i64 %693 = icmp ne i64 -7 , %2 br i1 %693 , label %694 , label %694 66@@ 95 %695 = load i16 * * * * , i16 * * * * * @g_6@@ 17 , align 8 %696 = load i16 * * * , i16 * * * * %695 , align 8 %697 = load i16 * * , i16 * * * %696 , align 8 %698 = load i16 * , i16 * * %697 , align 8 %699 = load i16 , i16 * %698 , align 2 %700 = sext i16 %699 to i32 %701 = icmp ne i32 %700 , 0 br label %702 770@@ 3 %703 = phi i1 [ false , %657 ] , [ %701 , %694 ] br label %704 7705 %705 = phi i1 [ false , %430 ] , [ %703 , %702 ] %706 = zext i1 %705 to i32 %707 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %708 = load i32 * * * , i32 * * * * %707 , align 8 %709 = load i32 * * , i32 * * * %708 , align 8 %710 = load i32 * , i32 * * %709 , align 8 %711 = load i32 , i32 * %710 , align 4 %712 = xor i32 %711 , %33 store i32 %712 , i32 * %710 , align 4 %713 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %714 = load volatile i16 * , i16 * * %713 , align 8 %715 = load i16 , i16 * %714 , align 2 %716 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %715 , i32 11 ) %717 = zext i16 %716 to i32 %718 = icmp ne i32 %717 , 0 br i1 %718 , label %719 , label %719 77@@ 20 %720 = load i16 * , i16 * * @g_5@@ 04 , align 8 %721 = load i16 , i16 * %720 , align 2 store i32 * * @g_3@@ 114 , i32 * * * @g_3@@ 4@@ 39 , align 8 %722 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %723 = load i32 * * * , i32 * * * * %722 , align 8 %724 = load i32 * * , i32 * * * %723 , align 8 %725 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %726 = load i32 * * * , i32 * * * * %725 , align 8 store i32 * * %724 , i32 * * * %726 , align 8 store i32 * * %724 , i32 * * * %14 , align 8 store i32 * * %724 , i32 * * * %76 , align 8 %727 = icmp eq i32 * * @g_3@@ 114 , %728 %728 = zext i1 %727 to i32 %729 = trunc i32 %728 to i16 %730 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %729 , i32 8 ) %731 = zext i16 %730 to i64 %732 = xor i64 %731 , 13@@ 16@@ 37@@ 1879 %733 = trunc i64 %732 to i8 %734 = load i32 , i32 * %77 , align 4 %735 = load i16 * , i16 * * @g_@@ 695 , align 8 %736 = load i16 , i16 * %735 , align 2 %737 = zext i16 %736 to i32 %738 = load i64 * , i64 * * %67 , align 8 %739 = load i64 , i64 * %738 , align 8 %740 = xor i64 %739 , 1 store i64 %740 , i64 * %738 , align 8 %741 = icmp ne i32 * * * %5 , null %742 = zext i1 %741 to i32 %743 = sext i32 %742 to i64 %744 = icmp ugt i64 %740 , %745 %745 = zext i1 %744 to i32 %746 = trunc i32 %745 to i16 store i16 %746 , i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 2 ) , align 2 %747 = sext i16 %746 to i32 %748 = icmp eq i32 %737 , %749 %749 = zext i1 %748 to i32 %750 = trunc i32 %749 to i16 %751 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %750 , i16 signext 10@@ 49@@ 5 ) %752 = sext i16 %751 to i64 %753 = and i64 %752 , 3 %754 = load i16 , i16 * %15 , align 2 %755 = sext i16 %754 to i64 %756 = icmp sgt i64 %753 , %757 %757 = zext i1 %756 to i32 %758 = load i16 * , i16 * * @g_@@ 695 , align 8 %759 = load i16 , i16 * %758 , align 2 %760 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext -24@@ 10@@ 3 , i16 zeroext %759 ) %761 = zext i16 %760 to i64 %762 = icmp ule i64 %761 , 0 br i1 %762 , label %764 , label %763 72 br label %764 7765 %765 = phi i1 [ true , %719 ] , [ true , %763 ] %766 = zext i1 %765 to i32 %767 = trunc i32 %766 to i8 %768 = load i8 * , i8 * * @g_15@@ 92 , align 8 %769 = load volatile i8 , i8 * %768 , align 1 %770 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %767 , i8 signext %769 ) %771 = sext i8 %770 to i32 %772 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %773 = load i32 * * * , i32 * * * * %772 , align 8 %774 = load i32 * * , i32 * * * %773 , align 8 %775 = load i32 * , i32 * * %774 , align 8 %776 = load i32 , i32 * %775 , align 4 %777 = icmp ule i32 %771 , %778 %778 = zext i1 %777 to i32 %779 = load i8 * , i8 * * %86 , align 8 %780 = load i8 , i8 * %779 , align 1 %781 = sext i8 %780 to i32 %782 = and i32 %781 , %783 %783 = trunc i32 %782 to i8 store i8 %783 , i8 * %779 , align 1 %784 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %733 , i8 zeroext %783 ) %785 = zext i8 %784 to i32 %786 = icmp ne i32 %785 , 0 br i1 %786 , label %787 , label %787 72 br label %788 77@@ 89 %789 = phi i1 [ false , %764 ] , [ true , %787 ] %790 = zext i1 %789 to i32 %791 = load i16 * * , i16 * * * @g_1@@ 50@@ 2 , align 8 %792 = load i16 * , i16 * * %791 , align 8 %793 = icmp eq i16 * %792 , null %794 = zext i1 %793 to i32 %795 = trunc i32 %794 to i8 %796 = load i32 , i32 * @g_@@ 83 , align 4 %797 = trunc i32 %796 to i8 %798 = call signext i8 @safe_div_func_int8_t_s_s ( i8 signext %795 , i8 signext %797 ) %799 = sext i8 %798 to i64 %800 = and i64 %799 , -8 %801 = icmp ne i64 %800 , 0 %802 = xor i1 %801 , true br label %803 88@@ 04 %804 = phi i1 [ false , %704 ] , [ %802 , %788 ] %805 = zext i1 %804 to i32 %806 = sext i32 %805 to i64 %807 = load i64 , i64 * %75 , align 8 %808 = icmp sgt i64 %806 , %809 %809 = zext i1 %808 to i32 %810 = sext i32 %809 to i64 %811 = load i64 , i64 * %16 , align 8 %812 = icmp ugt i64 %810 , %813 %813 = zext i1 %812 to i32 %814 = load i32 * * , i32 * * * %81 , align 8 %815 = load i32 * , i32 * * %814 , align 8 %816 = load i32 , i32 * %815 , align 4 %817 = xor i32 %813 , %818 %818 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %819 = load volatile i16 * , i16 * * %818 , align 8 %820 = load i16 , i16 * %819 , align 2 %821 = zext i16 %820 to i32 %822 = and i32 %817 , %823 %823 = icmp ne i32 %822 , 0 br i1 %823 , label %824 , label %824 82 br label %825 88@@ 26 %826 = phi i1 [ false , %803 ] , [ true , %824 ] %827 = zext i1 %826 to i32 %828 = trunc i32 %827 to i16 %829 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %828 , i16 signext -1@@ 29@@ 42 ) %830 = sext i16 %829 to i32 %831 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %832 = load volatile i32 * * , i32 * * * %831 , align 8 %833 = load volatile i32 * , i32 * * %832 , align 8 store volatile i32 %830 , i32 * %833 , align 4 %834 = load volatile i32 * * , i32 * * * @g_3@@ 99 , align 8 %835 = load i32 * , i32 * * %834 , align 8 %836 = load i32 , i32 * %835 , align 4 %837 = load i32 , i32 * @g_@@ 83 , align 4 %838 = xor i32 %837 , %33 store i32 %838 , i32 * @g_@@ 83 , align 4 br label %839 88@@ 40 %840 = load i16 , i16 * @g_161 , align 2 %841 = sext i16 %840 to i32 %842 = call i32 @safe_add_func_int32_t_s_s ( i32 %841 , i32 1 ) %843 = trunc i32 %842 to i16 store i16 %843 , i16 * @g_161 , align 2 br label %844 88@@ 45 %845 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %846 = load volatile i32 * , i32 * * %845 , align 8 %847 = load volatile i32 , i32 * %846 , align 4 %848 = load i32 * , i32 * * @g_8@@ 55 , align 8 store volatile i32 %847 , i32 * %848 , align 4 br label %849 833 store i64 -1 , i64 * %90 , align 8 store i8 -@@ 65 , i8 * %91 , align 1 store i8 * null , i8 * * %92 , align 8 store i64 * %90 , i64 * * %93 , align 8 %850 = bitcast [ 8 x i16 * * * * ] * %94 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %850 , i8 * align 16 bitcast ( [ 8 x i16 * * * * ] * @__const.func_1.l_@@ 3@@ 496 to i8 * ) , i64 64 , i1 false ) store i32 * null , i32 * * %95 , align 8 store i16 1 , i16 * %97 , align 2 store i8 -1 , i8 * %98 , align 1 store i32 7 , i32 * %99 , align 4 %851 = bitcast [ 1 x [ 9 x [ 4 x i16 ] ] ] * %100 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %851 , i8 * align 16 bitcast ( [ 1 x [ 9 x [ 4 x i16 ] ] ] * @__const.func_1.l_@@ 35@@ 86 to i8 * ) , i64 72 , i1 false ) store i16 25@@ 20@@ 4 , i16 * %101 , align 2 store i32 -@@ 738@@ 3@@ 132@@ 41 , i32 * %102 , align 4 store i32 -9 , i32 * %103 , align 4 store i32 0 , i32 * %104 , align 4 %852 = bitcast [ 3 x [ 2 x i32 ] ] * %105 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %852 , i8 * align 16 bitcast ( [ 3 x [ 2 x i32 ] ] * @__const.func_1.l_@@ 375@@ 9 to i8 * ) , i64 24 , i1 false ) store i32 -4 , i32 * %106 , align 4 store i64 9 , i64 * %107 , align 8 store i32 -5 , i32 * %108 , align 4 store i64 -@@ 7@@ 480@@ 7@@ 147@@ 72@@ 8@@ 260@@ 14@@ 228 , i64 * %109 , align 8 store i64 89@@ 3@@ 100@@ 83@@ 45@@ 119@@ 49@@ 5@@ 36 , i64 * %110 , align 8 %853 = bitcast [ 9 x [ 5 x i8 * * * * ] ] * %111 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %853 , i8 * align 16 bitcast ( [ 9 x [ 5 x i8 * * * * ] ] * @__const.func_1.l_@@ 37@@ 86 to i8 * ) , i64 360 , i1 false ) store i64 -22@@ 255@@ 1788@@ 066@@ 7@@ 103@@ 7@@ 79 , i64 * %112 , align 8 store i8 -7 , i8 * %113 , align 1 %854 = bitcast [ 5 x [ 2 x i16 ] ] * %114 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %854 , i8 * align 16 bitcast ( [ 5 x [ 2 x i16 ] ] * @__const.func_1.l_38@@ 64 to i8 * ) , i64 20 , i1 false ) store i32 0 , i32 * %116 , align 4 br label %855 88@@ 56 %856 = load i32 , i32 * %116 , align 4 %857 = icmp slt i32 %856 , 3 br i1 %857 , label %858 , label %858 88@@ 59 %859 = load i32 , i32 * %116 , align 4 %860 = sext i32 %859 to i64 %861 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %96 , i64 0 , i64 %33 store i32 147@@ 20@@ 49@@ 571 , i32 * %861 , align 4 br label %862 8@@ 863 %863 = load i32 , i32 * %116 , align 4 %864 = add nsw i32 %863 , 1 store i32 %864 , i32 * %116 , align 4 br label %865 833 store i32 0 , i32 * %116 , align 4 br label %866 886@@ 7 %867 = load i32 , i32 * %116 , align 4 %868 = icmp slt i32 %867 , 3 br i1 %868 , label %869 , label %869 88@@ 70 %870 = load i32 , i32 * %116 , align 4 %871 = sext i32 %870 to i64 %872 = getelementptr inbounds [ 3 x i8 ] , [ 3 x i8 ] * %115 , i64 0 , i64 %33 store i8 49 , i8 * %872 , align 1 br label %873 88@@ 74 %874 = load i32 , i32 * %116 , align 4 %875 = add nsw i32 %874 , 1 store i32 %875 , i32 * %116 , align 4 br label %876 88@@ 77 %877 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %878 = load volatile i16 * , i16 * * %877 , align 8 %879 = load i16 , i16 * %878 , align 2 %880 = zext i16 %879 to i64 %881 = icmp sle i64 558@@ 27 , %882 %882 = zext i1 %881 to i32 %883 = trunc i32 %882 to i8 %884 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %883 , i32 7 ) %885 = sext i8 %884 to i32 %886 = load i32 * , i32 * * @g_8@@ 55 , align 8 store volatile i32 %885 , i32 * %886 , align 4 br label %887 88@@ 88 %888 = load i64 , i64 * %33 , align 8 %889 = trunc i64 %888 to i32 ret i32 %889 }
define internal i32 * @func_@@ 8 ( i16 zeroext %0 , i64 %1 , i32 * %2 , i32 %3 , i32 * %4 ) #0 { %6 = alloca i16 , align 2 %7 = alloca i64 , align 8 %8 = alloca i32 * , align 8 %9 = alloca i32 , align 4 %10 = alloca i32 * , align 8 %11 = alloca [ 9 x [ 10 x [ 2 x i32 ] ] ] , align 16 %12 = alloca i8 * , align 8 %13 = alloca i64 , align 8 %14 = alloca i64 * * , align 8 %15 = alloca i64 * * * , align 8 %16 = alloca [ 1 x [ 10 x i16 * * * * * ] ] , align 16 %17 = alloca i32 * * * , align 8 %18 = alloca i32 * * * * * , align 8 %19 = alloca [ 1 x [ 5 x i32 ] ] , align 16 %20 = alloca i32 , align 4 %21 = alloca i32 , align 4 %22 = alloca i8 * * * , align 8 %23 = alloca i64 * * * * , align 8 %24 = alloca i64 , align 8 %25 = alloca i32 , align 4 %26 = alloca i8 * * , align 8 %27 = alloca i32 * , align 8 %28 = alloca i64 * * * * * , align 8 %29 = alloca [ 5 x [ 1 x i64 ] ] , align 16 %30 = alloca i32 , align 4 %31 = alloca i32 , align 4 %32 = alloca i32 , align 4 store i16 %0 , i16 * %6 , align 2 store i64 %1 , i64 * %7 , align 8 store i32 * %2 , i32 * * %8 , align 8 store i32 %3 , i32 * %9 , align 4 store i32 * %4 , i32 * * %10 , align 8 %33 = bitcast [ 9 x [ 10 x [ 2 x i32 ] ] ] * %11 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %33 , i8 * align 16 bitcast ( [ 9 x [ 10 x [ 2 x i32 ] ] ] * @__const.func_@@ 8.@@ l_@@ 27@@ 32 to i8 * ) , i64 720 , i1 false ) store i8 * @g_1@@ 7@@ 22 , i8 * * %12 , align 8 store i64 2@@ 1676@@ 530@@ 75@@ 30@@ 99@@ 77@@ 114 , i64 * %13 , align 8 store i64 * * null , i64 * * * %14 , align 8 store i64 * * * %14 , i64 * * * * %15 , align 8 %34 = bitcast [ 1 x [ 10 x i16 * * * * * ] ] * %16 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %34 , i8 * align 16 bitcast ( [ 1 x [ 10 x i16 * * * * * ] ] * @__const.func_@@ 8.@@ l_@@ 28@@ 43 to i8 * ) , i64 80 , i1 false ) store i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 3 ) , i32 * * * * %17 , align 8 store i32 * * * * * @g_15@@ 23 , i32 * * * * * * %18 , align 8 store i32 5 , i32 * %20 , align 4 store i32 15@@ 19@@ 789@@ 93 , i32 * %21 , align 4 store i8 * * * @g_1@@ 775 , i8 * * * * %22 , align 8 store i64 * * * * @g_22@@ 54 , i64 * * * * * %23 , align 8 store i64 -1 , i64 * %24 , align 8 store i32 -1 , i32 * %25 , align 4 store i8 * * null , i8 * * * %26 , align 8 store i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , i32 * * %27 , align 8 store i64 * * * * * null , i64 * * * * * * %28 , align 8 store i32 0 , i32 * %30 , align 4 br label %35 336 %36 = load i32 , i32 * %30 , align 4 %37 = icmp slt i32 %36 , 1 br i1 %37 , label %38 , label %38 333 store i32 0 , i32 * %31 , align 4 br label %39 3@@ 40 %40 = load i32 , i32 * %31 , align 4 %41 = icmp slt i32 %40 , 5 br i1 %41 , label %42 , label %42 443 %43 = load i32 , i32 * %30 , align 4 %44 = sext i32 %43 to i64 %45 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %19 , i64 0 , i64 %46 %46 = load i32 , i32 * %31 , align 4 %47 = sext i32 %46 to i64 %48 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %45 , i64 0 , i64 %33 store i32 -4 , i32 * %48 , align 4 br label %49 450 %50 = load i32 , i32 * %31 , align 4 %51 = add nsw i32 %50 , 1 store i32 %51 , i32 * %31 , align 4 br label %52 52 br label %53 554 %54 = load i32 , i32 * %30 , align 4 %55 = add nsw i32 %54 , 1 store i32 %55 , i32 * %30 , align 4 br label %56 533 store i32 0 , i32 * %30 , align 4 br label %57 558 %58 = load i32 , i32 * %30 , align 4 %59 = icmp slt i32 %58 , 5 br i1 %59 , label %60 , label %60 633 store i32 0 , i32 * %31 , align 4 br label %61 662 %62 = load i32 , i32 * %31 , align 4 %63 = icmp slt i32 %62 , 1 br i1 %63 , label %64 , label %64 665 %65 = load i32 , i32 * %30 , align 4 %66 = sext i32 %65 to i64 %67 = getelementptr inbounds [ 5 x [ 1 x i64 ] ] , [ 5 x [ 1 x i64 ] ] * %29 , i64 0 , i64 %68 %68 = load i32 , i32 * %31 , align 4 %69 = sext i32 %68 to i64 %70 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %67 , i64 0 , i64 %33 store i64 -1@@ 39@@ 17@@ 25@@ 1@@ 22@@ 66@@ 2@@ 135@@ 305 , i64 * %70 , align 8 br label %71 7@@ 72 %72 = load i32 , i32 * %31 , align 4 %73 = add nsw i32 %72 , 1 store i32 %73 , i32 * %31 , align 4 br label %74 72 br label %75 7@@ 76 %76 = load i32 , i32 * %30 , align 4 %77 = add nsw i32 %76 , 1 store i32 %77 , i32 * %30 , align 4 br label %78 7@@ 79 %79 = getelementptr inbounds [ 9 x [ 10 x [ 2 x i32 ] ] ] , [ 9 x [ 10 x [ 2 x i32 ] ] ] * %11 , i64 0 , i64 3 %80 = getelementptr inbounds [ 10 x [ 2 x i32 ] ] , [ 10 x [ 2 x i32 ] ] * %79 , i64 0 , i64 0 %81 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %80 , i64 0 , i64 0 %82 = load i32 , i32 * %81 , align 16 %83 = trunc i32 %82 to i8 %84 = load i8 * , i8 * * %12 , align 8 store i8 %83 , i8 * %84 , align 1 %85 = sext i8 %83 to i32 %86 = icmp ne i32 %85 , 0 %87 = zext i1 %86 to i32 %88 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %89 = load volatile i32 * * , i32 * * * %88 , align 8 %90 = load volatile i32 * , i32 * * %89 , align 8 %91 = load volatile i32 , i32 * %90 , align 4 %92 = and i32 %91 , %33 store volatile i32 %92 , i32 * %90 , align 4 %93 = load volatile i32 * * , i32 * * * @g_207 , align 8 %94 = load i32 * , i32 * * %93 , align 8 ret i32 * %94 }
define internal zeroext i16 @func_@@ 14 ( i32 * %0 , i8 signext %1 ) #0 { %3 = alloca i32 * , align 8 %4 = alloca i8 , align 1 %5 = alloca i32 , align 4 %6 = alloca [ 5 x i32 * * * * ] , align 16 %7 = alloca i32 * * * * , align 8 %8 = alloca i32 * * , align 8 %9 = alloca [ 3 x i32 ] , align 4 %10 = alloca i16 , align 2 %11 = alloca i32 * , align 8 %12 = alloca i8 * * , align 8 %13 = alloca i32 * , align 8 %14 = alloca [ 5 x [ 9 x [ 2 x i32 * * ] ] ] , align 16 %15 = alloca i64 , align 8 %16 = alloca i32 , align 4 %17 = alloca i32 , align 4 %18 = alloca i32 , align 4 %19 = alloca i32 , align 4 %20 = alloca i32 , align 4 %21 = alloca i32 * , align 8 %22 = alloca [ 4 x [ 5 x [ 5 x i32 * ] ] ] , align 16 %23 = alloca i32 , align 4 %24 = alloca [ 3 x [ 7 x [ 10 x i32 ] ] ] , align 16 %25 = alloca i32 , align 4 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i64 , align 8 %29 = alloca i8 * , align 8 %30 = alloca i32 , align 4 %31 = alloca [ 2 x i64 * ] , align 16 %32 = alloca i64 * , align 8 %33 = alloca i32 , align 4 %34 = alloca i64 * * * * , align 8 %35 = alloca i64 * * * * * , align 8 %36 = alloca i32 , align 4 %37 = alloca i8 * , align 8 %38 = alloca i32 * * * , align 8 store i32 * %0 , i32 * * %3 , align 8 store i8 %1 , i8 * %4 , align 1 store i32 -1 , i32 * %5 , align 4 store i32 * * * * @g_10@@ 10 , i32 * * * * * %7 , align 8 store i32 * * null , i32 * * * %8 , align 8 store i16 1 , i16 * %10 , align 2 store i32 * null , i32 * * %11 , align 8 store i8 * * @g_1@@ 7@@ 76 , i8 * * * %12 , align 8 store i32 * @g_6@@ 71 , i32 * * %13 , align 8 %39 = getelementptr inbounds [ 5 x [ 9 x [ 2 x i32 * * ] ] ] , [ 5 x [ 9 x [ 2 x i32 * * ] ] ] * %14 , i64 0 , i64 0 %40 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %39 , i64 0 , i64 0 %41 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %40 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %41 , align 8 %42 = getelementptr inbounds i32 * * , i32 * * * %41 , i64 1 store i32 * * %13 , i32 * * * %42 , align 8 %43 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %40 , i64 1 %44 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %43 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %44 , align 8 %45 = getelementptr inbounds i32 * * , i32 * * * %44 , i64 1 store i32 * * %13 , i32 * * * %45 , align 8 %46 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %43 , i64 1 %47 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %46 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %47 , align 8 %48 = getelementptr inbounds i32 * * , i32 * * * %47 , i64 1 store i32 * * %13 , i32 * * * %48 , align 8 %49 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %46 , i64 1 %50 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %49 , i64 0 , i64 0 store i32 * * null , i32 * * * %50 , align 8 %51 = getelementptr inbounds i32 * * , i32 * * * %50 , i64 1 store i32 * * %13 , i32 * * * %51 , align 8 %52 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %49 , i64 1 %53 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %52 , i64 0 , i64 0 store i32 * * null , i32 * * * %53 , align 8 %54 = getelementptr inbounds i32 * * , i32 * * * %53 , i64 1 store i32 * * %13 , i32 * * * %54 , align 8 %55 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %52 , i64 1 %56 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %55 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %56 , align 8 %57 = getelementptr inbounds i32 * * , i32 * * * %56 , i64 1 store i32 * * %13 , i32 * * * %57 , align 8 %58 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %55 , i64 1 %59 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %58 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %59 , align 8 %60 = getelementptr inbounds i32 * * , i32 * * * %59 , i64 1 store i32 * * %13 , i32 * * * %60 , align 8 %61 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %58 , i64 1 %62 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %61 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %62 , align 8 %63 = getelementptr inbounds i32 * * , i32 * * * %62 , i64 1 store i32 * * null , i32 * * * %63 , align 8 %64 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %61 , i64 1 %65 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %64 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %65 , align 8 %66 = getelementptr inbounds i32 * * , i32 * * * %65 , i64 1 store i32 * * null , i32 * * * %66 , align 8 %67 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %39 , i64 1 %68 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %67 , i64 0 , i64 0 %69 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %68 , i64 0 , i64 0 store i32 * * null , i32 * * * %69 , align 8 %70 = getelementptr inbounds i32 * * , i32 * * * %69 , i64 1 store i32 * * %13 , i32 * * * %70 , align 8 %71 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %68 , i64 1 %72 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %71 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %72 , align 8 %73 = getelementptr inbounds i32 * * , i32 * * * %72 , i64 1 store i32 * * null , i32 * * * %73 , align 8 %74 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %71 , i64 1 %75 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %74 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %75 , align 8 %76 = getelementptr inbounds i32 * * , i32 * * * %75 , i64 1 store i32 * * %13 , i32 * * * %76 , align 8 %77 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %74 , i64 1 %78 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %77 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %78 , align 8 %79 = getelementptr inbounds i32 * * , i32 * * * %78 , i64 1 store i32 * * %13 , i32 * * * %79 , align 8 %80 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %77 , i64 1 %81 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %80 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %81 , align 8 %82 = getelementptr inbounds i32 * * , i32 * * * %81 , i64 1 store i32 * * %13 , i32 * * * %82 , align 8 %83 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %80 , i64 1 %84 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %83 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %84 , align 8 %85 = getelementptr inbounds i32 * * , i32 * * * %84 , i64 1 store i32 * * %13 , i32 * * * %85 , align 8 %86 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %83 , i64 1 %87 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %86 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %87 , align 8 %88 = getelementptr inbounds i32 * * , i32 * * * %87 , i64 1 store i32 * * %13 , i32 * * * %88 , align 8 %89 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %86 , i64 1 %90 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %89 , i64 0 , i64 0 store i32 * * null , i32 * * * %90 , align 8 %91 = getelementptr inbounds i32 * * , i32 * * * %90 , i64 1 store i32 * * %13 , i32 * * * %91 , align 8 %92 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %89 , i64 1 %93 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %92 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %93 , align 8 %94 = getelementptr inbounds i32 * * , i32 * * * %93 , i64 1 store i32 * * %13 , i32 * * * %94 , align 8 %95 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %67 , i64 1 %96 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %95 , i64 0 , i64 0 %97 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %96 , i64 0 , i64 0 store i32 * * null , i32 * * * %97 , align 8 %98 = getelementptr inbounds i32 * * , i32 * * * %97 , i64 1 store i32 * * %13 , i32 * * * %98 , align 8 %99 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %96 , i64 1 %100 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %99 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %100 , align 8 %101 = getelementptr inbounds i32 * * , i32 * * * %100 , i64 1 store i32 * * %13 , i32 * * * %101 , align 8 %102 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %99 , i64 1 %103 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %102 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %103 , align 8 %104 = getelementptr inbounds i32 * * , i32 * * * %103 , i64 1 store i32 * * %13 , i32 * * * %104 , align 8 %105 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %102 , i64 1 %106 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %105 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %106 , align 8 %107 = getelementptr inbounds i32 * * , i32 * * * %106 , i64 1 store i32 * * %13 , i32 * * * %107 , align 8 %108 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %105 , i64 1 %109 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %108 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %109 , align 8 %110 = getelementptr inbounds i32 * * , i32 * * * %109 , i64 1 store i32 * * null , i32 * * * %110 , align 8 %111 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %108 , i64 1 %112 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %111 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %112 , align 8 %113 = getelementptr inbounds i32 * * , i32 * * * %112 , i64 1 store i32 * * %13 , i32 * * * %113 , align 8 %114 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %111 , i64 1 %115 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %114 , i64 0 , i64 0 store i32 * * null , i32 * * * %115 , align 8 %116 = getelementptr inbounds i32 * * , i32 * * * %115 , i64 1 store i32 * * %13 , i32 * * * %116 , align 8 %117 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %114 , i64 1 %118 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %117 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %118 , align 8 %119 = getelementptr inbounds i32 * * , i32 * * * %118 , i64 1 store i32 * * %13 , i32 * * * %119 , align 8 %120 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %117 , i64 1 %121 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %120 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %121 , align 8 %122 = getelementptr inbounds i32 * * , i32 * * * %121 , i64 1 store i32 * * %13 , i32 * * * %122 , align 8 %123 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %95 , i64 1 %124 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %123 , i64 0 , i64 0 %125 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %124 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %125 , align 8 %126 = getelementptr inbounds i32 * * , i32 * * * %125 , i64 1 store i32 * * %13 , i32 * * * %126 , align 8 %127 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %124 , i64 1 %128 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %127 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %128 , align 8 %129 = getelementptr inbounds i32 * * , i32 * * * %128 , i64 1 store i32 * * %13 , i32 * * * %129 , align 8 %130 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %127 , i64 1 %131 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %130 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %131 , align 8 %132 = getelementptr inbounds i32 * * , i32 * * * %131 , i64 1 store i32 * * %13 , i32 * * * %132 , align 8 %133 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %130 , i64 1 %134 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %133 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %134 , align 8 %135 = getelementptr inbounds i32 * * , i32 * * * %134 , i64 1 store i32 * * %13 , i32 * * * %135 , align 8 %136 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %133 , i64 1 %137 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %136 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %137 , align 8 %138 = getelementptr inbounds i32 * * , i32 * * * %137 , i64 1 store i32 * * %13 , i32 * * * %138 , align 8 %139 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %136 , i64 1 %140 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %139 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %140 , align 8 %141 = getelementptr inbounds i32 * * , i32 * * * %140 , i64 1 store i32 * * %13 , i32 * * * %141 , align 8 %142 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %139 , i64 1 %143 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %142 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %143 , align 8 %144 = getelementptr inbounds i32 * * , i32 * * * %143 , i64 1 store i32 * * %13 , i32 * * * %144 , align 8 %145 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %142 , i64 1 %146 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %145 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %146 , align 8 %147 = getelementptr inbounds i32 * * , i32 * * * %146 , i64 1 store i32 * * %13 , i32 * * * %147 , align 8 %148 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %145 , i64 1 %149 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %148 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %149 , align 8 %150 = getelementptr inbounds i32 * * , i32 * * * %149 , i64 1 store i32 * * %13 , i32 * * * %150 , align 8 %151 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %123 , i64 1 %152 = getelementptr inbounds [ 9 x [ 2 x i32 * * ] ] , [ 9 x [ 2 x i32 * * ] ] * %151 , i64 0 , i64 0 %153 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %152 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %153 , align 8 %154 = getelementptr inbounds i32 * * , i32 * * * %153 , i64 1 store i32 * * %13 , i32 * * * %154 , align 8 %155 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %152 , i64 1 %156 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %155 , i64 0 , i64 0 store i32 * * null , i32 * * * %156 , align 8 %157 = getelementptr inbounds i32 * * , i32 * * * %156 , i64 1 store i32 * * %13 , i32 * * * %157 , align 8 %158 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %155 , i64 1 %159 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %158 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %159 , align 8 %160 = getelementptr inbounds i32 * * , i32 * * * %159 , i64 1 store i32 * * null , i32 * * * %160 , align 8 %161 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %158 , i64 1 %162 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %161 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %162 , align 8 %163 = getelementptr inbounds i32 * * , i32 * * * %162 , i64 1 store i32 * * %13 , i32 * * * %163 , align 8 %164 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %161 , i64 1 %165 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %164 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %165 , align 8 %166 = getelementptr inbounds i32 * * , i32 * * * %165 , i64 1 store i32 * * %13 , i32 * * * %166 , align 8 %167 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %164 , i64 1 %168 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %167 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %168 , align 8 %169 = getelementptr inbounds i32 * * , i32 * * * %168 , i64 1 store i32 * * %13 , i32 * * * %169 , align 8 %170 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %167 , i64 1 %171 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %170 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %171 , align 8 %172 = getelementptr inbounds i32 * * , i32 * * * %171 , i64 1 store i32 * * %13 , i32 * * * %172 , align 8 %173 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %170 , i64 1 %174 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %173 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %174 , align 8 %175 = getelementptr inbounds i32 * * , i32 * * * %174 , i64 1 store i32 * * %13 , i32 * * * %175 , align 8 %176 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %173 , i64 1 %177 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %176 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %177 , align 8 %178 = getelementptr inbounds i32 * * , i32 * * * %177 , i64 1 store i32 * * %13 , i32 * * * %178 , align 8 store i64 1 , i64 * %15 , align 8 store i32 1 , i32 * %16 , align 4 store i32 0 , i32 * %17 , align 4 br label %179 11@@ 80 %180 = load i32 , i32 * %17 , align 4 %181 = icmp slt i32 %180 , 5 br i1 %181 , label %182 , label %182 1183 %183 = load i32 , i32 * %17 , align 4 %184 = sext i32 %183 to i64 %185 = getelementptr inbounds [ 5 x i32 * * * * ] , [ 5 x i32 * * * * ] * %6 , i64 0 , i64 %33 store i32 * * * * getelementptr inbounds ( [ 1 x [ 3 x i32 * * * ] ] , [ 1 x [ 3 x i32 * * * ] ] * @g_6@@ 82 , i64 0 , i64 0 , i64 1 ) , i32 * * * * * %185 , align 8 br label %186 11@@ 87 %187 = load i32 , i32 * %17 , align 4 %188 = add nsw i32 %187 , 1 store i32 %188 , i32 * %17 , align 4 br label %189 133 store i32 0 , i32 * %17 , align 4 br label %190 1191 %191 = load i32 , i32 * %17 , align 4 %192 = icmp slt i32 %191 , 3 br i1 %192 , label %193 , label %193 1194 %194 = load i32 , i32 * %17 , align 4 %195 = sext i32 %194 to i64 %196 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %9 , i64 0 , i64 %33 store i32 1 , i32 * %196 , align 4 br label %197 1198 %198 = load i32 , i32 * %17 , align 4 %199 = add nsw i32 %198 , 1 store i32 %199 , i32 * %17 , align 4 br label %200 233 store i8 -14 , i8 * %4 , align 1 br label %201 2202 %202 = load i8 , i8 * %4 , align 1 %203 = sext i8 %202 to i32 %204 = icmp eq i32 %203 , -1@@ 5 br i1 %204 , label %205 , label %205 233 store i32 532@@ 25@@ 96@@ 12 , i32 * %20 , align 4 store i32 * null , i32 * * %21 , align 8 %206 = bitcast [ 4 x [ 5 x [ 5 x i32 * ] ] ] * %22 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %206 , i8 * align 16 bitcast ( [ 4 x [ 5 x [ 5 x i32 * ] ] ] * @__const.func_@@ 14@@ .l_@@ 51 to i8 * ) , i64 800 , i1 false ) store i32 133@@ 35@@ 72@@ 39@@ 6 , i32 * %23 , align 4 %207 = bitcast [ 3 x [ 7 x [ 10 x i32 ] ] ] * %24 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %207 , i8 * align 16 bitcast ( [ 3 x [ 7 x [ 10 x i32 ] ] ] * @__const.func_@@ 14@@ .l_@@ 26@@ 00 to i8 * ) , i64 840 , i1 false ) br label %208 220@@ 9 %209 = load i8 , i8 * %4 , align 1 %210 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %209 , i8 zeroext 1 ) store i8 %210 , i8 * %4 , align 1 br label %211 2212 %212 = load i8 , i8 * %4 , align 1 %213 = sext i8 %212 to i32 %214 = load i32 * , i32 * * %11 , align 8 %215 = load i32 * * , i32 * * * @g_2@@ 6@@ 26 , align 8 store i32 * %214 , i32 * * %215 , align 8 %216 = load i32 * , i32 * * %3 , align 8 %217 = icmp eq i32 * %214 , %218 %218 = zext i1 %217 to i32 %219 = trunc i32 %218 to i8 %220 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %219 , i32 3 ) %221 = sext i8 %220 to i32 %222 = icmp eq i32 %213 , %223 %223 = zext i1 %222 to i32 %224 = load volatile i64 * * * , i64 * * * * @g_2@@ 6@@ 71 , align 8 %225 = icmp eq i64 * * * null , %226 %226 = zext i1 %225 to i32 %227 = icmp sle i32 %223 , %228 %228 = zext i1 %227 to i32 %229 = load i8 * * , i8 * * * %12 , align 8 %230 = load i8 * * * , i8 * * * * @g_24@@ 27 , align 8 %231 = load i8 * * , i8 * * * %230 , align 8 %232 = icmp eq i8 * * %229 , %233 %233 = zext i1 %232 to i32 %234 = load i32 * , i32 * * %3 , align 8 store i32 * %234 , i32 * * getelementptr inbounds ( [ 2 x [ 9 x [ 10 x i32 * ] ] ] , [ 2 x [ 9 x [ 10 x i32 * ] ] ] * @g_2@@ 6@@ 79 , i64 0 , i64 1 , i64 5 , i64 0 ) , align 16 %235 = load i32 * , i32 * * %3 , align 8 %236 = icmp eq i32 * %234 , %237 %237 = zext i1 %236 to i32 %238 = load i8 , i8 * %4 , align 1 %239 = sext i8 %238 to i32 %240 = icmp sle i32 %237 , %241 %241 = zext i1 %240 to i32 %242 = load i8 , i8 * %4 , align 1 %243 = sext i8 %242 to i32 %244 = icmp ne i32 %241 , %245 %245 = zext i1 %244 to i32 %246 = trunc i32 %245 to i16 %247 = load i16 * , i16 * * @g_@@ 695 , align 8 %248 = load i16 , i16 * %247 , align 2 %249 = zext i16 %248 to i32 %250 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %246 , i32 %249 ) %251 = sext i16 %250 to i32 %252 = icmp slt i32 %228 , %253 %253 = zext i1 %252 to i32 %254 = sext i32 %253 to i64 %255 = xor i64 335@@ 79@@ 16@@ 891 , %256 %256 = trunc i64 %255 to i32 %257 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %258 = load volatile i32 * * , i32 * * * %257 , align 8 %259 = load volatile i32 * , i32 * * %258 , align 8 store volatile i32 %256 , i32 * %259 , align 4 %260 = load i32 * , i32 * * @g_@@ 208 , align 8 %261 = load i32 , i32 * %260 , align 4 %262 = icmp ne i32 %261 , 0 br i1 %262 , label %263 , label %263 233 store i64 -126@@ 55@@ 278@@ 88@@ 279@@ 135@@ 380 , i64 * %28 , align 8 store i8 * @g_3@@ 44 , i8 * * %29 , align 8 store i32 -5 , i32 * %30 , align 4 store i64 * @g_9@@ 99 , i64 * * %32 , align 8 store i32 -2 , i32 * %33 , align 4 store i64 * * * * @g_22@@ 54 , i64 * * * * * %34 , align 8 store i64 * * * * * %34 , i64 * * * * * * %35 , align 8 store i32 0 , i32 * %36 , align 4 br label %264 22@@ 65 %265 = load i32 , i32 * %36 , align 4 %266 = icmp slt i32 %265 , 2 br i1 %266 , label %267 , label %267 22@@ 68 %268 = load i32 , i32 * %36 , align 4 %269 = sext i32 %268 to i64 %270 = getelementptr inbounds [ 2 x i64 * ] , [ 2 x i64 * ] * %31 , i64 0 , i64 %33 store i64 * @g_24@@ 12 , i64 * * %270 , align 8 br label %271 22@@ 72 %272 = load i32 , i32 * %36 , align 4 %273 = add nsw i32 %272 , 1 store i32 %273 , i32 * %36 , align 4 br label %274 22@@ 75 %275 = load i8 * * , i8 * * * @g_15@@ 91 , align 8 %276 = load i8 * , i8 * * %275 , align 8 %277 = load volatile i8 , i8 * %276 , align 1 %278 = zext i8 %277 to i32 %279 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext 1 , i32 %278 ) %280 = sext i8 %279 to i64 %281 = load i64 , i64 * %28 , align 8 %282 = xor i64 %281 , %33 store i64 %282 , i64 * %28 , align 8 %283 = load i32 * , i32 * * %3 , align 8 %284 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %285 = load i32 * * * , i32 * * * * %284 , align 8 %286 = load i32 * * , i32 * * * %285 , align 8 store i32 * %283 , i32 * * %286 , align 8 %287 = load i32 , i32 * @g_2@@ 110 , align 4 %288 = add i32 %287 , 1 store i32 %288 , i32 * @g_2@@ 110 , align 4 %289 = load i64 , i64 * %28 , align 8 %290 = icmp ne i64 %289 , 0 br i1 %290 , label %291 , label %291 2292 %292 = load volatile i64 * * * , i64 * * * * @g_2@@ 6@@ 71 , align 8 %293 = load i64 * * , i64 * * * %292 , align 8 %294 = load volatile i64 * , i64 * * %293 , align 8 %295 = load volatile i64 , i64 * %294 , align 8 %296 = load i8 , i8 * %4 , align 1 %297 = sext i8 %296 to i32 %298 = icmp ne i32 %297 , 0 %299 = zext i1 %298 to i32 %300 = trunc i32 %299 to i16 %301 = load i32 * * * * * , i32 * * * * * * getelementptr inbounds ( [ 7 x i32 * * * * * ] , [ 7 x i32 * * * * * ] * @g_2@@ 698 , i64 0 , i64 1 ) , align 8 store i32 * * * * * %301 , i32 * * * * * * getelementptr inbounds ( [ 7 x i32 * * * * * ] , [ 7 x i32 * * * * * ] * @g_2@@ 698 , i64 0 , i64 4 ) , align 16 %302 = icmp ne i32 * * * * * %301 , null %303 = zext i1 %302 to i32 %304 = trunc i32 %303 to i8 %305 = load i8 * , i8 * * %29 , align 8 store i8 %304 , i8 * %305 , align 1 %306 = zext i8 %304 to i32 %307 = load i8 , i8 * %4 , align 1 %308 = sext i8 %307 to i32 %309 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext -21 , i32 3 ) %310 = sext i8 %309 to i64 %311 = load i64 , i64 * %28 , align 8 %312 = icmp sge i64 %310 , %2 br i1 %312 , label %313 , label %313 33@@ 14 %314 = load i64 , i64 * %28 , align 8 %315 = icmp ne i64 %314 , 0 br label %316 33@@ 17 %317 = phi i1 [ false , %291 ] , [ %315 , %313 ] %318 = zext i1 %317 to i32 %319 = load i8 , i8 * %4 , align 1 %320 = sext i8 %319 to i32 %321 = icmp ne i32 %318 , %322 %322 = zext i1 %321 to i32 %323 = load i8 , i8 * %4 , align 1 %324 = sext i8 %323 to i32 %325 = xor i32 %322 , %326 %326 = trunc i32 %325 to i16 %327 = load i64 , i64 * %28 , align 8 %328 = trunc i64 %327 to i16 %329 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %326 , i16 zeroext %328 ) %330 = zext i16 %329 to i32 %331 = icmp sge i32 %308 , %332 %332 = zext i1 %331 to i32 %333 = sext i32 %332 to i64 %334 = load i64 , i64 * %28 , align 8 %335 = icmp eq i64 %333 , %336 %336 = zext i1 %335 to i32 store i32 %336 , i32 * %30 , align 4 %337 = icmp sle i32 %306 , %338 %338 = zext i1 %337 to i32 %339 = load i8 , i8 * %4 , align 1 %340 = sext i8 %339 to i32 %341 = load i8 , i8 * %4 , align 1 %342 = sext i8 %341 to i32 %343 = icmp sle i32 %340 , %344 %344 = zext i1 %343 to i32 %345 = trunc i32 %344 to i16 %346 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %300 , i16 zeroext %345 ) %347 = zext i16 %346 to i64 store i64 %347 , i64 * %15 , align 8 %348 = load i8 , i8 * %4 , align 1 %349 = sext i8 %348 to i64 %350 = xor i64 %347 , %351 %351 = icmp ne i64 %295 , %352 %352 = zext i1 %351 to i32 %353 = sext i32 %352 to i64 %354 = icmp eq i64 %353 , 69@@ 11@@ 7@@ 29@@ 70@@ 69@@ 40@@ 749@@ 123 br label %355 335@@ 6 %356 = phi i1 [ false , %274 ] , [ %354 , %316 ] %357 = zext i1 %356 to i32 %358 = load i32 , i32 * %16 , align 4 %359 = or i32 %358 , %33 store i32 %359 , i32 * %16 , align 4 %360 = sext i32 %359 to i64 %361 = call i64 @safe_add_func_int64_t_s_s ( i64 %360 , i64 0 ) %362 = call i64 @safe_div_func_int64_t_s_s ( i64 %361 , i64 -10@@ 99@@ 26@@ 18@@ 446@@ 56@@ 22@@ 95@@ 92 ) %363 = trunc i64 %362 to i32 %364 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext -30@@ 498 , i32 %363 ) %365 = sext i16 %364 to i64 %366 = load i64 * , i64 * * %32 , align 8 %367 = load i64 , i64 * %366 , align 8 %368 = and i64 %367 , %33 store i64 %368 , i64 * %366 , align 8 %369 = icmp ne i64 %368 , 0 br i1 %369 , label %373 , label %370 3371 %371 = load i32 , i32 * %30 , align 4 %372 = icmp ne i32 %371 , 0 br label %373 33@@ 74 %374 = phi i1 [ true , %355 ] , [ %372 , %370 ] %375 = zext i1 %374 to i32 %376 = load i8 , i8 * %4 , align 1 %377 = sext i8 %376 to i32 %378 = load i32 , i32 * getelementptr inbounds ( [ 2 x i32 ] , [ 2 x i32 ] * @g_1@@ 117 , i64 0 , i64 0 ) , align 4 %379 = icmp ult i32 %377 , %380 %380 = zext i1 %379 to i32 %381 = sext i32 %380 to i64 %382 = call i64 @safe_add_func_int64_t_s_s ( i64 %381 , i64 -1 ) %383 = load i32 * , i32 * * %3 , align 8 %384 = load i32 , i32 * %383 , align 4 %385 = sext i32 %384 to i64 %386 = or i64 %382 , %387 %387 = load i32 , i32 * %30 , align 4 %388 = trunc i32 %387 to i8 %389 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %388 , i8 signext 66 ) %390 = load i32 * , i32 * * %3 , align 8 %391 = load i32 , i32 * %390 , align 4 %392 = load i32 , i32 * %33 , align 4 %393 = xor i32 %392 , %33 store i32 %393 , i32 * %33 , align 4 %394 = load i64 * * * * * , i64 * * * * * * %35 , align 8 store i64 * * * * * %394 , i64 * * * * * * @g_27@@ 13 , align 8 br label %395 333 store i8 * @g_3@@ 43 , i8 * * %37 , align 8 store i32 * * * null , i32 * * * * %38 , align 8 %396 = load i8 * , i8 * * %37 , align 8 %397 = load i32 * * * , i32 * * * * %38 , align 8 %398 = icmp ne i32 * * * null , %399 %399 = zext i1 %398 to i32 %400 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %401 = load i32 * * * , i32 * * * * %400 , align 8 %402 = load i32 * * , i32 * * * %401 , align 8 %403 = load i32 * , i32 * * %402 , align 8 %404 = load i32 , i32 * %403 , align 4 %405 = load i8 * , i8 * * %37 , align 8 %406 = load i8 * * * , i8 * * * * @g_24@@ 24 , align 8 %407 = load i8 * * , i8 * * * %406 , align 8 %408 = load i8 * , i8 * * %407 , align 8 %409 = icmp eq i8 * %405 , %410 %410 = zext i1 %409 to i32 %411 = trunc i32 %410 to i16 %412 = load i8 , i8 * %4 , align 1 %413 = sext i8 %412 to i16 %414 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %411 , i16 signext %413 ) %415 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext -1 , i16 signext 0 ) %416 = trunc i16 %415 to i8 %417 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext -@@ 49 , i8 zeroext %416 ) %418 = zext i8 %417 to i16 %419 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %414 , i16 signext %418 ) %420 = sext i16 %419 to i64 %421 = icmp sle i64 %420 , -1 %422 = zext i1 %421 to i32 %423 = icmp eq i32 %399 , %424 %424 = zext i1 %423 to i32 %425 = load i8 * * , i8 * * * %12 , align 8 %426 = load i8 * , i8 * * %425 , align 8 %427 = icmp ne i8 * %396 , %428 %428 = zext i1 %427 to i32 %429 = sext i32 %428 to i64 %430 = xor i64 %429 , -2 %431 = trunc i64 %430 to i32 %432 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %433 = load volatile i32 * , i32 * * %432 , align 8 store volatile i32 %431 , i32 * %433 , align 4 br label %434 44@@ 35 %435 = load i8 , i8 * %4 , align 1 %436 = sext i8 %435 to i16 ret i16 %436 }
define internal i32 @func_@@ 22 ( i8 zeroext %0 , i32 * %1 , i32 %2 , i8 zeroext %3 , i64 %4 ) #0 { %6 = alloca i32 , align 4 %7 = alloca i8 , align 1 %8 = alloca i32 * , align 8 %9 = alloca i32 , align 4 %10 = alloca i8 , align 1 %11 = alloca i64 , align 8 %12 = alloca i16 , align 2 %13 = alloca i32 , align 4 %14 = alloca i32 , align 4 %15 = alloca i32 * , align 8 %16 = alloca i64 * , align 8 %17 = alloca [ 3 x i16 ] , align 2 %18 = alloca i32 , align 4 %19 = alloca i64 * , align 8 %20 = alloca i64 * * , align 8 %21 = alloca [ 6 x i64 * * * ] , align 16 %22 = alloca i64 * * * , align 8 %23 = alloca [ 10 x i32 ] , align 16 %24 = alloca i32 , align 4 %25 = alloca [ 6 x i32 ] , align 16 %26 = alloca i32 , align 4 %27 = alloca i16 , align 2 %28 = alloca i8 * , align 8 %29 = alloca i32 , align 4 %30 = alloca i16 * * , align 8 %31 = alloca i16 * * * , align 8 %32 = alloca i16 , align 2 %33 = alloca i32 , align 4 %34 = alloca [ 5 x i32 ] , align 16 %35 = alloca i32 , align 4 %36 = alloca i16 * , align 8 %37 = alloca i32 * * * * , align 8 %38 = alloca [ 6 x [ 2 x i32 * * * * * ] ] , align 16 %39 = alloca i32 , align 4 %40 = alloca i32 , align 4 %41 = alloca i8 , align 1 %42 = alloca i16 , align 2 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 %45 = alloca i32 * , align 8 %46 = alloca i32 * , align 8 %47 = alloca i8 , align 1 %48 = alloca i32 , align 4 %49 = alloca i64 * , align 8 %50 = alloca i32 , align 4 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca [ 5 x [ 9 x [ 5 x i64 ] ] ] , align 16 %54 = alloca i32 , align 4 %55 = alloca i32 , align 4 %56 = alloca i32 , align 4 %57 = alloca [ 2 x [ 6 x i32 * ] ] , align 16 %58 = alloca i32 , align 4 %59 = alloca i32 , align 4 %60 = alloca i32 , align 4 %61 = alloca [ 2 x [ 9 x i32 ] ] , align 16 %62 = alloca i32 * * * , align 8 %63 = alloca i32 * * * * * , align 8 %64 = alloca i32 * , align 8 %65 = alloca i32 * * , align 8 %66 = alloca i32 * * * , align 8 %67 = alloca [ 10 x [ 9 x [ 2 x i32 * * * * ] ] ] , align 16 %68 = alloca [ 1 x [ 1 x i32 * * * * * ] ] , align 8 %69 = alloca i64 * * * , align 8 %70 = alloca i16 * , align 8 %71 = alloca i16 , align 2 %72 = alloca [ 2 x i16 * * ] , align 16 %73 = alloca i16 * * * , align 8 %74 = alloca i64 * , align 8 %75 = alloca i64 * * , align 8 %76 = alloca i32 , align 4 %77 = alloca i32 , align 4 %78 = alloca i32 , align 4 %79 = alloca i64 , align 8 %80 = alloca i32 * , align 8 %81 = alloca i32 * * , align 8 %82 = alloca i32 * , align 8 %83 = alloca i16 * , align 8 %84 = alloca i32 * , align 8 %85 = alloca i32 , align 4 %86 = alloca i16 , align 2 %87 = alloca [ 7 x i32 ] , align 16 %88 = alloca i32 * * , align 8 %89 = alloca i64 * * , align 8 %90 = alloca i64 * * , align 8 %91 = alloca i32 * * * * , align 8 %92 = alloca i16 , align 2 %93 = alloca i32 * , align 8 %94 = alloca i32 * * , align 8 %95 = alloca i32 * * * , align 8 %96 = alloca i32 , align 4 %97 = alloca i32 , align 4 store i8 %0 , i8 * %7 , align 1 store i32 * %1 , i32 * * %8 , align 8 store i32 %2 , i32 * %9 , align 4 store i8 %3 , i8 * %10 , align 1 store i64 %4 , i64 * %11 , align 8 store i16 150@@ 40 , i16 * %12 , align 2 store i32 -@@ 83@@ 3800@@ 5@@ 67 , i32 * %13 , align 4 store i32 0 , i32 * %14 , align 4 store i32 * @g_2@@ 46 , i32 * * %15 , align 8 store i64 * @g_5@@ 06 , i64 * * %16 , align 8 store i32 -156@@ 20@@ 70@@ 633 , i32 * %18 , align 4 store i64 * null , i64 * * %19 , align 8 store i64 * * %19 , i64 * * * %20 , align 8 store i64 * * * null , i64 * * * * %22 , align 8 %98 = bitcast [ 10 x i32 ] * %23 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %98 , i8 * align 16 bitcast ( [ 10 x i32 ] * @__const.func_@@ 22@@ .l_@@ 20@@ 30 to i8 * ) , i64 40 , i1 false ) store i32 2 , i32 * %24 , align 4 %99 = bitcast [ 6 x i32 ] * %25 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 16 %99 , i8 0 , i64 24 , i1 false ) store i32 0 , i32 * %26 , align 4 store i16 42@@ 37 , i16 * %27 , align 2 store i8 * @g_3@@ 44 , i8 * * %28 , align 8 store i32 -12@@ 110@@ 775@@ 07 , i32 * %29 , align 4 store i16 * * @g_@@ 695 , i16 * * * %30 , align 8 store i16 * * * %30 , i16 * * * * %31 , align 8 store i16 -2@@ 4982 , i16 * %32 , align 2 store i32 0 , i32 * %33 , align 4 br label %100 11@@ 01 %101 = load i32 , i32 * %33 , align 4 %102 = icmp slt i32 %101 , 3 br i1 %102 , label %103 , label %103 1104 %104 = load i32 , i32 * %33 , align 4 %105 = sext i32 %104 to i64 %106 = getelementptr inbounds [ 3 x i16 ] , [ 3 x i16 ] * %17 , i64 0 , i64 %33 store i16 -2@@ 60@@ 64 , i16 * %106 , align 2 br label %107 11@@ 08 %108 = load i32 , i32 * %33 , align 4 %109 = add nsw i32 %108 , 1 store i32 %109 , i32 * %33 , align 4 br label %110 133 store i32 0 , i32 * %33 , align 4 br label %111 11@@ 12 %112 = load i32 , i32 * %33 , align 4 %113 = icmp slt i32 %112 , 6 br i1 %113 , label %114 , label %114 1115 %115 = load i32 , i32 * %33 , align 4 %116 = sext i32 %115 to i64 %117 = getelementptr inbounds [ 6 x i64 * * * ] , [ 6 x i64 * * * ] * %21 , i64 0 , i64 %33 store i64 * * * %20 , i64 * * * * %117 , align 8 br label %118 1119 %119 = load i32 , i32 * %33 , align 4 %120 = add nsw i32 %119 , 1 store i32 %120 , i32 * %33 , align 4 br label %121 133 store i32 -21 , i32 * @g_1@@ 50 , align 4 br label %122 1123 %123 = load i32 , i32 * @g_1@@ 50 , align 4 %124 = icmp ule i32 %123 , 14 br i1 %124 , label %125 , label %125 133 store i32 -7 , i32 * %35 , align 4 store i16 * @g_9@@ 06 , i16 * * %36 , align 8 store i32 * * * * null , i32 * * * * * %37 , align 8 %126 = getelementptr inbounds [ 6 x [ 2 x i32 * * * * * ] ] , [ 6 x [ 2 x i32 * * * * * ] ] * %38 , i64 0 , i64 0 %127 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %126 , i64 0 , i64 0 store i32 * * * * * %37 , i32 * * * * * * %127 , align 8 %128 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %127 , i64 1 store i32 * * * * * %37 , i32 * * * * * * %128 , align 8 %129 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %126 , i64 1 %130 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %129 , i64 0 , i64 0 store i32 * * * * * %37 , i32 * * * * * * %130 , align 8 %131 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %130 , i64 1 store i32 * * * * * %37 , i32 * * * * * * %131 , align 8 %132 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %129 , i64 1 %133 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %132 , i64 0 , i64 0 store i32 * * * * * %37 , i32 * * * * * * %133 , align 8 %134 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %133 , i64 1 store i32 * * * * * %37 , i32 * * * * * * %134 , align 8 %135 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %132 , i64 1 %136 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %135 , i64 0 , i64 0 store i32 * * * * * %37 , i32 * * * * * * %136 , align 8 %137 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %136 , i64 1 store i32 * * * * * %37 , i32 * * * * * * %137 , align 8 %138 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %135 , i64 1 %139 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %138 , i64 0 , i64 0 store i32 * * * * * %37 , i32 * * * * * * %139 , align 8 %140 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %139 , i64 1 store i32 * * * * * %37 , i32 * * * * * * %140 , align 8 %141 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %138 , i64 1 %142 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %141 , i64 0 , i64 0 store i32 * * * * * %37 , i32 * * * * * * %142 , align 8 %143 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %142 , i64 1 store i32 * * * * * %37 , i32 * * * * * * %143 , align 8 store i32 0 , i32 * %39 , align 4 br label %144 1145 %145 = load i32 , i32 * %39 , align 4 %146 = icmp slt i32 %145 , 5 br i1 %146 , label %147 , label %147 1148 %148 = load i32 , i32 * %39 , align 4 %149 = sext i32 %148 to i64 %150 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %34 , i64 0 , i64 %33 store i32 -2135@@ 7@@ 175@@ 06 , i32 * %150 , align 4 br label %151 1152 %152 = load i32 , i32 * %39 , align 4 %153 = add nsw i32 %152 , 1 store i32 %153 , i32 * %39 , align 4 br label %154 11@@ 55 %155 = load i64 , i64 * %11 , align 8 %156 = icmp ne i64 %155 , 0 br i1 %156 , label %157 , label %157 11@@ 58 %158 = load i32 , i32 * %9 , align 4 %159 = trunc i32 %158 to i16 %160 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %159 , i16 signext 25@@ 35@@ 9 ) %161 = sext i16 %160 to i32 %162 = load i32 * * * * , i32 * * * * * @g_15@@ 23 , align 8 %163 = load i32 * * * , i32 * * * * %162 , align 8 %164 = load i32 * * , i32 * * * %163 , align 8 %165 = load i32 * , i32 * * %164 , align 8 %166 = load i32 , i32 * %165 , align 4 %167 = add i32 %166 , -1 store i32 %167 , i32 * %165 , align 4 %168 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %34 , i64 0 , i64 4 store i32 %166 , i32 * %168 , align 16 %169 = icmp ne i32 %161 , %170 %170 = zext i1 %169 to i32 %171 = load i16 , i16 * %12 , align 2 %172 = load i8 , i8 * %7 , align 1 %173 = zext i8 %172 to i16 %174 = load i32 , i32 * %13 , align 4 %175 = load i32 , i32 * %9 , align 4 %176 = call i32 @safe_div_func_uint32_t_u_u ( i32 %174 , i32 %175 ) %177 = trunc i32 %176 to i16 %178 = load i32 , i32 * %13 , align 4 %179 = trunc i32 %178 to i16 %180 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %177 , i16 signext %179 ) %181 = sext i16 %180 to i32 %182 = load i8 , i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 6 ) , align 1 %183 = zext i8 %182 to i32 %184 = icmp eq i32 %181 , %185 %185 = zext i1 %184 to i32 %186 = load i16 * * , i16 * * * @g_5@@ 03 , align 8 %187 = load i16 * , i16 * * %186 , align 8 %188 = load i16 , i16 * %187 , align 2 %189 = sext i16 %188 to i32 %190 = or i32 %189 , %191 %191 = trunc i32 %190 to i16 store i16 %191 , i16 * %187 , align 2 %192 = load i8 , i8 * %10 , align 1 %193 = zext i8 %192 to i64 %194 = icmp sle i64 674@@ 3685@@ 9@@ 53@@ 70@@ 160@@ 75@@ 66 , %2 br i1 %194 , label %195 , label %195 1196 %196 = load i32 , i32 * %9 , align 4 %197 = icmp ne i32 %196 , 0 br label %198 1199 %199 = phi i1 [ false , %157 ] , [ %197 , %195 ] %200 = zext i1 %199 to i32 %201 = load i32 , i32 * %35 , align 4 %202 = xor i32 %201 , %33 store i32 %202 , i32 * %35 , align 4 %203 = call signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %173 , i32 %202 ) %204 = sext i16 %203 to i32 %205 = load i16 * , i16 * * %36 , align 8 %206 = load i16 , i16 * %205 , align 2 %207 = sext i16 %206 to i32 %208 = and i32 %207 , %209 %209 = trunc i32 %208 to i16 store i16 %209 , i16 * %205 , align 2 %210 = sext i16 %209 to i32 %211 = call zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %171 , i32 %210 ) %212 = zext i16 %211 to i32 %213 = xor i32 %170 , %214 %214 = trunc i32 %213 to i8 %215 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %214 , i32 6 ) %216 = sext i8 %215 to i32 %217 = icmp ne i32 %216 , 0 br label %218 22@@ 19 %219 = phi i1 [ false , %154 ] , [ %217 , %198 ] %220 = zext i1 %219 to i32 %221 = sext i32 %220 to i64 %222 = load i64 , i64 * %11 , align 8 %223 = icmp sle i64 %221 , %2 br i1 %223 , label %224 , label %224 2225 %225 = load i32 , i32 * %13 , align 4 %226 = icmp ne i32 %225 , 0 br label %227 2228 %228 = phi i1 [ false , %218 ] , [ %226 , %224 ] %229 = zext i1 %228 to i32 %230 = getelementptr inbounds [ 6 x [ 2 x i32 * * * * * ] ] , [ 6 x [ 2 x i32 * * * * * ] ] * %38 , i64 0 , i64 4 %231 = getelementptr inbounds [ 2 x i32 * * * * * ] , [ 2 x i32 * * * * * ] * %230 , i64 0 , i64 0 %232 = load i32 * * * * * , i32 * * * * * * %231 , align 16 %233 = bitcast i32 * * * * * %232 to i8 * %234 = icmp ne i8 * null , %235 %235 = zext i1 %234 to i32 %236 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %237 = load volatile i32 * * , i32 * * * %236 , align 8 %238 = load volatile i32 * , i32 * * %237 , align 8 store volatile i32 %235 , i32 * %238 , align 4 %239 = load i32 * , i32 * * %8 , align 8 %240 = load i32 , i32 * %239 , align 4 store i32 %240 , i32 * %6 , align 4 br label %241 2242 %242 = load i32 , i32 * @g_1@@ 50 , align 4 %243 = add i32 %242 , 1 store i32 %243 , i32 * @g_1@@ 50 , align 4 br label %244 22@@ 45 %245 = load i32 , i32 * %14 , align 4 %246 = load i32 , i32 * %14 , align 4 %247 = load i32 * , i32 * * %15 , align 8 store i32 %246 , i32 * %247 , align 4 %248 = load i32 * * * , i32 * * * * @g_10@@ 10 , align 8 %249 = load i32 * * , i32 * * * %248 , align 8 %250 = load i32 * , i32 * * %249 , align 8 %251 = load i32 , i32 * %250 , align 4 %252 = call i32 @safe_div_func_int32_t_s_s ( i32 %246 , i32 %251 ) %253 = load i8 , i8 * %10 , align 1 %254 = zext i8 %253 to i32 %255 = load i64 , i64 * %11 , align 8 %256 = trunc i64 %255 to i8 store i8 %256 , i8 * %7 , align 1 %257 = zext i8 %256 to i32 %258 = load i32 , i32 * %14 , align 4 %259 = load i8 , i8 * %10 , align 1 %260 = zext i8 %259 to i32 %261 = icmp slt i32 %260 , -@@ 456@@ 2@@ 332@@ 58 %262 = zext i1 %261 to i32 %263 = load i64 * , i64 * * %16 , align 8 %264 = icmp eq i64 * %263 , @g_394 %265 = zext i1 %264 to i32 %266 = xor i32 %258 , %267 %267 = icmp eq i32 %257 , %268 %268 = zext i1 %267 to i32 %269 = trunc i32 %268 to i8 %270 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %269 , i32 1 ) %271 = sext i8 %270 to i64 %272 = and i64 %271 , 90@@ 38@@ 76@@ 126 %273 = trunc i64 %272 to i8 %274 = getelementptr inbounds [ 3 x i16 ] , [ 3 x i16 ] * %17 , i64 0 , i64 0 %275 = load i16 , i16 * %274 , align 2 %276 = trunc i16 %275 to i8 %277 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %273 , i8 signext %276 ) %278 = sext i8 %277 to i32 %279 = icmp sle i32 %254 , %280 %280 = zext i1 %279 to i32 %281 = and i32 %252 , %282 %282 = sext i32 %281 to i64 %283 = and i64 %282 , 425@@ 33 %284 = icmp slt i64 %283 , 198 br i1 %284 , label %285 , label %285 22@@ 86 %286 = load i32 * , i32 * * %15 , align 8 %287 = load i32 , i32 * %286 , align 4 %288 = icmp ne i32 %287 , 0 br label %289 22@@ 90 %290 = phi i1 [ false , %244 ] , [ %288 , %285 ] %291 = zext i1 %290 to i32 %292 = icmp ne i32 %245 , %293 %293 = zext i1 %292 to i32 %294 = sext i32 %293 to i64 %295 = and i64 %294 , 38@@ 4@@ 64 %296 = trunc i64 %295 to i8 %297 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %296 , i32 1 ) %298 = icmp ne i8 %297 , 0 br i1 %298 , label %299 , label %299 233 store i8 0 , i8 * %41 , align 1 store i8 2 , i8 * @g_1@@ 7@@ 22 , align 1 br label %300 3301 %301 = load i8 , i8 * @g_1@@ 7@@ 22 , align 1 %302 = sext i8 %301 to i32 %303 = icmp sge i32 %302 , 0 br i1 %303 , label %304 , label %304 333 store i16 1 , i16 * %42 , align 2 store i32 -19@@ 40@@ 69@@ 9@@ 83 , i32 * %43 , align 4 store i32 -13@@ 46@@ 88@@ 270 , i32 * %44 , align 4 %305 = load i32 * , i32 * * @g_8@@ 55 , align 8 store volatile i32 -2 , i32 * %305 , align 4 %306 = load i8 , i8 * %10 , align 1 %307 = zext i8 %306 to i32 %308 = icmp ne i32 %307 , 0 br i1 %308 , label %309 , label %309 32 br label %310 3311 %311 = phi i1 [ false , %304 ] , [ true , %309 ] %312 = zext i1 %311 to i32 %313 = load i32 * , i32 * * %15 , align 8 %314 = load i32 , i32 * %313 , align 4 %315 = trunc i32 %314 to i16 %316 = load i32 * , i32 * * %15 , align 8 %317 = load i32 , i32 * %316 , align 4 %318 = trunc i32 %317 to i16 %319 = load i32 , i32 * %18 , align 4 %320 = trunc i32 %319 to i16 %321 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %318 , i16 zeroext %320 ) %322 = zext i16 %321 to i32 %323 = load i8 , i8 * %7 , align 1 %324 = zext i8 %323 to i32 %325 = load i8 * , i8 * * @g_15@@ 92 , align 8 %326 = load volatile i8 , i8 * %325 , align 1 %327 = zext i8 %326 to i32 %328 = icmp slt i32 %324 , %329 %329 = zext i1 %328 to i32 %330 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext -2 , i32 0 ) %331 = trunc i16 %330 to i8 %332 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %331 , i8 zeroext 52 ) %333 = zext i8 %332 to i32 %334 = or i32 %329 , %335 %335 = load i8 , i8 * @g_3@@ 43 , align 1 %336 = sext i8 %335 to i32 %337 = icmp ne i32 %334 , %338 %338 = zext i1 %337 to i32 %339 = icmp sge i32 %322 , %340 %340 = zext i1 %339 to i32 %341 = load i8 , i8 * %7 , align 1 %342 = zext i8 %341 to i32 %343 = icmp sle i32 %340 , %344 %344 = zext i1 %343 to i32 %345 = load i16 , i16 * %42 , align 2 %346 = zext i16 %345 to i32 %347 = or i32 %344 , %348 %348 = load i8 , i8 * %7 , align 1 %349 = zext i8 %348 to i32 %350 = icmp slt i32 %347 , %351 %351 = zext i1 %350 to i32 %352 = trunc i32 %351 to i16 %353 = load i32 , i32 * %9 , align 4 %354 = trunc i32 %353 to i16 %355 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %352 , i16 zeroext %354 ) %356 = zext i16 %355 to i32 %357 = load i32 * , i32 * * %15 , align 8 %358 = load i32 , i32 * %357 , align 4 %359 = icmp sgt i32 %356 , %360 %360 = zext i1 %359 to i32 %361 = load i32 * , i32 * * @g_1@@ 68 , align 8 store i32 %360 , i32 * %361 , align 4 %362 = load i8 , i8 * %41 , align 1 %363 = sext i8 %362 to i32 %364 = and i32 %360 , %365 %365 = zext i32 %364 to i64 %366 = load i8 , i8 * %7 , align 1 %367 = zext i8 %366 to i64 %368 = call i64 @safe_div_func_uint64_t_u_u ( i64 %365 , i64 %367 ) %369 = load i32 , i32 * %43 , align 4 %370 = sext i32 %369 to i64 %371 = or i64 %370 , %372 %372 = trunc i64 %371 to i32 store i32 %372 , i32 * %43 , align 4 %373 = trunc i32 %372 to i16 %374 = load i8 , i8 * %7 , align 1 %375 = zext i8 %374 to i16 %376 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %373 , i16 zeroext %375 ) %377 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %378 = load volatile i16 * , i16 * * %377 , align 8 store i16 %376 , i16 * %378 , align 2 %379 = zext i16 %376 to i32 %380 = icmp ne i32 %379 , 0 br i1 %380 , label %381 , label %381 33@@ 82 %382 = load i16 * , i16 * * @g_5@@ 04 , align 8 %383 = load i16 , i16 * %382 , align 2 %384 = sext i16 %383 to i32 %385 = icmp ne i32 %384 , 0 br label %386 338@@ 7 %387 = phi i1 [ false , %310 ] , [ %385 , %381 ] %388 = zext i1 %387 to i32 %389 = trunc i32 %388 to i16 %390 = load i8 , i8 * %41 , align 1 %391 = sext i8 %390 to i16 %392 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %389 , i16 signext %391 ) %393 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %315 , i16 zeroext %392 ) %394 = zext i16 %393 to i32 %395 = load i32 * , i32 * * %15 , align 8 store i32 %394 , i32 * %395 , align 4 %396 = load i32 * , i32 * * %8 , align 8 %397 = load i32 , i32 * %396 , align 4 %398 = icmp sgt i32 %394 , %399 %399 = zext i1 %398 to i32 %400 = call i32 @safe_unary_minus_func_int32_t_s ( i32 %399 ) %401 = trunc i32 %400 to i8 %402 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext 0 , i8 zeroext %401 ) %403 = load i8 , i8 * %41 , align 1 %404 = sext i8 %403 to i64 %405 = icmp sge i64 %404 , 70@@ 514@@ 415@@ 3 %406 = zext i1 %405 to i32 %407 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %408 = load volatile i32 * * , i32 * * * %407 , align 8 %409 = load volatile i32 * , i32 * * %408 , align 8 store volatile i32 %406 , i32 * %409 , align 4 store i8 0 , i8 * @g_1@@ 21 , align 1 br label %410 4411 %411 = load i8 , i8 * @g_1@@ 21 , align 1 %412 = sext i8 %411 to i32 %413 = icmp sge i32 %412 , 0 br i1 %413 , label %414 , label %414 433 store i32 * %43 , i32 * * %45 , align 8 store i32 * %44 , i32 * * %46 , align 8 store i8 1 , i8 * %47 , align 1 %415 = load i8 , i8 * %47 , align 1 %416 = add i8 %415 , -1 store i8 %416 , i8 * %47 , align 1 %417 = load i32 * , i32 * * %8 , align 8 %418 = load i32 , i32 * %417 , align 4 %419 = icmp ne i32 %418 , 0 br i1 %419 , label %420 , label %420 42 br label %421 433 store i32 0 , i32 * %18 , align 4 br label %422 44@@ 23 %423 = load i32 , i32 * %18 , align 4 %424 = icmp ule i32 %423 , 2 br i1 %424 , label %425 , label %425 433 store i64 * @g_5@@ 06 , i64 * * %49 , align 8 %426 = load i8 , i8 * @g_1@@ 21 , align 1 %427 = sext i8 %426 to i64 %428 = getelementptr inbounds [ 1 x [ 9 x [ 5 x i16 ] ] ] , [ 1 x [ 9 x [ 5 x i16 ] ] ] * @g_3@@ 84 , i64 0 , i64 %429 %429 = load i32 , i32 * %18 , align 4 %430 = add i32 %429 , 2 %431 = zext i32 %430 to i64 %432 = getelementptr inbounds [ 9 x [ 5 x i16 ] ] , [ 9 x [ 5 x i16 ] ] * %428 , i64 0 , i64 %433 %433 = load i32 , i32 * %18 , align 4 %434 = add i32 %433 , 2 %435 = zext i32 %434 to i64 %436 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %432 , i64 0 , i64 %437 %437 = load i16 , i16 * %436 , align 2 %438 = zext i16 %437 to i32 %439 = load i8 * * , i8 * * * @g_15@@ 91 , align 8 %440 = load i8 * , i8 * * %439 , align 8 %441 = icmp eq i8 * null , %442 %442 = zext i1 %441 to i32 %443 = trunc i32 %442 to i16 %444 = load i32 , i32 * @g_1@@ 64 , align 4 %445 = zext i32 %444 to i64 %446 = load i64 * , i64 * * %49 , align 8 store i64 %445 , i64 * %446 , align 8 %447 = load i8 , i8 * %7 , align 1 %448 = zext i8 %447 to i32 %449 = load i8 , i8 * @g_1@@ 21 , align 1 %450 = sext i8 %449 to i64 %451 = getelementptr inbounds [ 1 x [ 9 x [ 5 x i16 ] ] ] , [ 1 x [ 9 x [ 5 x i16 ] ] ] * @g_3@@ 84 , i64 0 , i64 %452 %452 = load i32 , i32 * %18 , align 4 %453 = add i32 %452 , 2 %454 = zext i32 %453 to i64 %455 = getelementptr inbounds [ 9 x [ 5 x i16 ] ] , [ 9 x [ 5 x i16 ] ] * %451 , i64 0 , i64 %456 %456 = load i32 , i32 * %18 , align 4 %457 = add i32 %456 , 2 %458 = zext i32 %457 to i64 %459 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %455 , i64 0 , i64 %460 %460 = load i16 , i16 * %459 , align 2 %461 = zext i16 %460 to i32 %462 = icmp sle i32 %448 , %463 %463 = zext i1 %462 to i32 %464 = getelementptr inbounds [ 6 x i64 * * * ] , [ 6 x i64 * * * ] * %21 , i64 0 , i64 5 %465 = load i64 * * * , i64 * * * * %464 , align 8 %466 = load i32 , i32 * @g_2@@ 46 , align 4 %467 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext 1 , i8 zeroext -1@@ 09 ) %468 = zext i8 %467 to i32 %469 = load i32 * , i32 * * %15 , align 8 %470 = load i32 , i32 * %469 , align 4 %471 = icmp sge i32 %468 , %472 %472 = zext i1 %471 to i32 %473 = icmp slt i32 %466 , %474 %474 = zext i1 %473 to i32 store i64 * * * %20 , i64 * * * * %22 , align 8 %475 = icmp ne i64 * * * %465 , %476 %476 = zext i1 %475 to i32 %477 = sext i32 %476 to i64 %478 = icmp eq i64 %445 , %479 %479 = zext i1 %478 to i32 %480 = trunc i32 %479 to i16 %481 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %443 , i16 zeroext %480 ) %482 = zext i16 %481 to i32 %483 = load i16 * , i16 * * @g_@@ 695 , align 8 %484 = load i16 , i16 * %483 , align 2 %485 = zext i16 %484 to i32 %486 = and i32 %485 , %487 %487 = trunc i32 %486 to i16 store i16 %487 , i16 * %483 , align 2 %488 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %23 , i64 0 , i64 0 %489 = load i32 , i32 * %488 , align 16 %490 = load i8 , i8 * %41 , align 1 %491 = sext i8 %490 to i32 %492 = icmp ne i32 %489 , %493 %493 = zext i1 %492 to i32 %494 = load i32 * , i32 * * %45 , align 8 %495 = load i32 , i32 * %494 , align 4 %496 = call i32 @safe_add_func_int32_t_s_s ( i32 %493 , i32 %495 ) %497 = load i32 , i32 * %44 , align 4 %498 = xor i32 %497 , %33 store i32 %498 , i32 * %44 , align 4 %499 = sext i32 %498 to i64 %500 = icmp eq i64 %499 , -5 %501 = zext i1 %500 to i32 %502 = icmp sgt i32 %438 , %503 %503 = zext i1 %502 to i32 %504 = sext i32 %503 to i64 %505 = xor i64 %504 , 1 %506 = load i32 * , i32 * * %8 , align 8 %507 = load i32 , i32 * %506 , align 4 %508 = sext i32 %507 to i64 %509 = or i64 %505 , %510 %510 = icmp ne i64 %509 , 0 br i1 %510 , label %511 , label %511 5512 %512 = load i8 , i8 * @g_1@@ 21 , align 1 %513 = sext i8 %512 to i64 %514 = getelementptr inbounds [ 1 x [ 9 x [ 5 x i16 ] ] ] , [ 1 x [ 9 x [ 5 x i16 ] ] ] * @g_3@@ 84 , i64 0 , i64 %515 %515 = load i32 , i32 * %18 , align 4 %516 = add i32 %515 , 2 %517 = zext i32 %516 to i64 %518 = getelementptr inbounds [ 9 x [ 5 x i16 ] ] , [ 9 x [ 5 x i16 ] ] * %514 , i64 0 , i64 %519 %519 = load i32 , i32 * %18 , align 4 %520 = add i32 %519 , 2 %521 = zext i32 %520 to i64 %522 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %518 , i64 0 , i64 %523 %523 = load i16 , i16 * %522 , align 2 %524 = zext i16 %523 to i32 store i32 %524 , i32 * %6 , align 4 br label %525 5526 %526 = load i32 * , i32 * * %8 , align 8 %527 = load i32 , i32 * %526 , align 4 store i32 %527 , i32 * %6 , align 4 br label %528 5529 %529 = load i32 , i32 * %18 , align 4 %530 = add i32 %529 , 1 store i32 %530 , i32 * %18 , align 4 br label %531 52 br label %532 5533 %533 = load i8 , i8 * @g_1@@ 21 , align 1 %534 = sext i8 %533 to i32 %535 = sub nsw i32 %534 , 1 %536 = trunc i32 %535 to i8 store i8 %536 , i8 * @g_1@@ 21 , align 1 br label %537 52 br label %538 5539 %539 = load i8 , i8 * @g_1@@ 7@@ 22 , align 1 %540 = sext i8 %539 to i32 %541 = sub nsw i32 %540 , 1 %542 = trunc i32 %541 to i8 store i8 %542 , i8 * @g_1@@ 7@@ 22 , align 1 br label %543 533 store i16 6 , i16 * @g_161 , align 2 br label %544 5545 %545 = load i16 , i16 * @g_161 , align 2 %546 = sext i16 %545 to i32 %547 = icmp ne i32 %546 , 20 br i1 %547 , label %548 , label %548 55@@ 49 %549 = bitcast [ 5 x [ 9 x [ 5 x i64 ] ] ] * %53 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %549 , i8 * align 16 bitcast ( [ 5 x [ 9 x [ 5 x i64 ] ] ] * @__const.func_@@ 22@@ .l_@@ 20@@ 35 to i8 * ) , i64 18@@ 00 , i1 false ) %550 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %551 = load volatile i16 * , i16 * * %550 , align 8 %552 = load i16 , i16 * %551 , align 2 %553 = getelementptr inbounds [ 5 x [ 9 x [ 5 x i64 ] ] ] , [ 5 x [ 9 x [ 5 x i64 ] ] ] * %53 , i64 0 , i64 0 %554 = getelementptr inbounds [ 9 x [ 5 x i64 ] ] , [ 9 x [ 5 x i64 ] ] * %553 , i64 0 , i64 5 %555 = getelementptr inbounds [ 5 x i64 ] , [ 5 x i64 ] * %554 , i64 0 , i64 0 %556 = load i64 , i64 * %555 , align 8 %557 = trunc i64 %556 to i16 %558 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %552 , i16 zeroext %557 ) %559 = zext i16 %558 to i32 %560 = load i32 * , i32 * * %15 , align 8 store i32 %559 , i32 * %560 , align 4 %561 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %562 = load volatile i32 * , i32 * * %561 , align 8 store volatile i32 %559 , i32 * %562 , align 4 br label %563 5564 %564 = load i16 , i16 * @g_161 , align 2 %565 = sext i16 %564 to i32 %566 = call i32 @safe_add_func_uint32_t_u_u ( i32 %565 , i32 7 ) %567 = trunc i32 %566 to i16 store i16 %567 , i16 * @g_161 , align 2 br label %568 52 br label %569 5570 %570 = bitcast [ 2 x [ 6 x i32 * ] ] * %57 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %570 , i8 * align 16 bitcast ( [ 2 x [ 6 x i32 * ] ] * @__const.func_@@ 22@@ .l_@@ 20@@ 43 to i8 * ) , i64 96 , i1 false ) store i32 -1 , i32 * %58 , align 4 store i32 1 , i32 * %59 , align 4 store i32 -58@@ 53@@ 30@@ 5@@ 63 , i32 * %60 , align 4 %571 = bitcast [ 2 x [ 9 x i32 ] ] * %61 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %571 , i8 * align 16 bitcast ( [ 2 x [ 9 x i32 ] ] * @__const.func_@@ 22@@ .l_@@ 210@@ 2 to i8 * ) , i64 72 , i1 false ) store i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 1 ) , i32 * * * * %62 , align 8 store i32 * * * * * null , i32 * * * * * * %63 , align 8 store i32 * %26 , i32 * * %64 , align 8 store i32 * * %64 , i32 * * * %65 , align 8 store i32 * * * %65 , i32 * * * * %66 , align 8 %572 = getelementptr inbounds [ 10 x [ 9 x [ 2 x i32 * * * * ] ] ] , [ 10 x [ 9 x [ 2 x i32 * * * * ] ] ] * %67 , i64 0 , i64 0 %573 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %572 , i64 0 , i64 0 %574 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %573 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %574 , align 8 %575 = getelementptr inbounds i32 * * * * , i32 * * * * * %574 , i64 1 store i32 * * * * null , i32 * * * * * %575 , align 8 %576 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %573 , i64 1 %577 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %576 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %577 , align 8 %578 = getelementptr inbounds i32 * * * * , i32 * * * * * %577 , i64 1 store i32 * * * * null , i32 * * * * * %578 , align 8 %579 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %576 , i64 1 %580 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %579 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %580 , align 8 %581 = getelementptr inbounds i32 * * * * , i32 * * * * * %580 , i64 1 store i32 * * * * %66 , i32 * * * * * %581 , align 8 %582 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %579 , i64 1 %583 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %582 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %583 , align 8 %584 = getelementptr inbounds i32 * * * * , i32 * * * * * %583 , i64 1 store i32 * * * * null , i32 * * * * * %584 , align 8 %585 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %582 , i64 1 %586 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %585 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %586 , align 8 %587 = getelementptr inbounds i32 * * * * , i32 * * * * * %586 , i64 1 store i32 * * * * null , i32 * * * * * %587 , align 8 %588 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %585 , i64 1 %589 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %588 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %589 , align 8 %590 = getelementptr inbounds i32 * * * * , i32 * * * * * %589 , i64 1 store i32 * * * * %66 , i32 * * * * * %590 , align 8 %591 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %588 , i64 1 %592 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %591 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %592 , align 8 %593 = getelementptr inbounds i32 * * * * , i32 * * * * * %592 , i64 1 store i32 * * * * null , i32 * * * * * %593 , align 8 %594 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %591 , i64 1 %595 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %594 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %595 , align 8 %596 = getelementptr inbounds i32 * * * * , i32 * * * * * %595 , i64 1 store i32 * * * * null , i32 * * * * * %596 , align 8 %597 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %594 , i64 1 %598 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %597 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %598 , align 8 %599 = getelementptr inbounds i32 * * * * , i32 * * * * * %598 , i64 1 store i32 * * * * %66 , i32 * * * * * %599 , align 8 %600 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %572 , i64 1 %601 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %600 , i64 0 , i64 0 %602 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %601 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %602 , align 8 %603 = getelementptr inbounds i32 * * * * , i32 * * * * * %602 , i64 1 store i32 * * * * null , i32 * * * * * %603 , align 8 %604 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %601 , i64 1 %605 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %604 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %605 , align 8 %606 = getelementptr inbounds i32 * * * * , i32 * * * * * %605 , i64 1 store i32 * * * * null , i32 * * * * * %606 , align 8 %607 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %604 , i64 1 %608 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %607 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %608 , align 8 %609 = getelementptr inbounds i32 * * * * , i32 * * * * * %608 , i64 1 store i32 * * * * %66 , i32 * * * * * %609 , align 8 %610 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %607 , i64 1 %611 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %610 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %611 , align 8 %612 = getelementptr inbounds i32 * * * * , i32 * * * * * %611 , i64 1 store i32 * * * * null , i32 * * * * * %612 , align 8 %613 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %610 , i64 1 %614 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %613 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %614 , align 8 %615 = getelementptr inbounds i32 * * * * , i32 * * * * * %614 , i64 1 store i32 * * * * null , i32 * * * * * %615 , align 8 %616 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %613 , i64 1 %617 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %616 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %617 , align 8 %618 = getelementptr inbounds i32 * * * * , i32 * * * * * %617 , i64 1 store i32 * * * * %66 , i32 * * * * * %618 , align 8 %619 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %616 , i64 1 %620 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %619 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %620 , align 8 %621 = getelementptr inbounds i32 * * * * , i32 * * * * * %620 , i64 1 store i32 * * * * null , i32 * * * * * %621 , align 8 %622 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %619 , i64 1 %623 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %622 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %623 , align 8 %624 = getelementptr inbounds i32 * * * * , i32 * * * * * %623 , i64 1 store i32 * * * * null , i32 * * * * * %624 , align 8 %625 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %622 , i64 1 %626 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %625 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %626 , align 8 %627 = getelementptr inbounds i32 * * * * , i32 * * * * * %626 , i64 1 store i32 * * * * %66 , i32 * * * * * %627 , align 8 %628 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %600 , i64 1 %629 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %628 , i64 0 , i64 0 %630 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %629 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %630 , align 8 %631 = getelementptr inbounds i32 * * * * , i32 * * * * * %630 , i64 1 store i32 * * * * null , i32 * * * * * %631 , align 8 %632 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %629 , i64 1 %633 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %632 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %633 , align 8 %634 = getelementptr inbounds i32 * * * * , i32 * * * * * %633 , i64 1 store i32 * * * * null , i32 * * * * * %634 , align 8 %635 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %632 , i64 1 %636 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %635 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %636 , align 8 %637 = getelementptr inbounds i32 * * * * , i32 * * * * * %636 , i64 1 store i32 * * * * %66 , i32 * * * * * %637 , align 8 %638 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %635 , i64 1 %639 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %638 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %639 , align 8 %640 = getelementptr inbounds i32 * * * * , i32 * * * * * %639 , i64 1 store i32 * * * * null , i32 * * * * * %640 , align 8 %641 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %638 , i64 1 %642 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %641 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %642 , align 8 %643 = getelementptr inbounds i32 * * * * , i32 * * * * * %642 , i64 1 store i32 * * * * null , i32 * * * * * %643 , align 8 %644 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %641 , i64 1 %645 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %644 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %645 , align 8 %646 = getelementptr inbounds i32 * * * * , i32 * * * * * %645 , i64 1 store i32 * * * * %66 , i32 * * * * * %646 , align 8 %647 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %644 , i64 1 %648 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %647 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %648 , align 8 %649 = getelementptr inbounds i32 * * * * , i32 * * * * * %648 , i64 1 store i32 * * * * null , i32 * * * * * %649 , align 8 %650 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %647 , i64 1 %651 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %650 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %651 , align 8 %652 = getelementptr inbounds i32 * * * * , i32 * * * * * %651 , i64 1 store i32 * * * * null , i32 * * * * * %652 , align 8 %653 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %650 , i64 1 %654 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %653 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %654 , align 8 %655 = getelementptr inbounds i32 * * * * , i32 * * * * * %654 , i64 1 store i32 * * * * %66 , i32 * * * * * %655 , align 8 %656 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %628 , i64 1 %657 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %656 , i64 0 , i64 0 %658 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %657 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %658 , align 8 %659 = getelementptr inbounds i32 * * * * , i32 * * * * * %658 , i64 1 store i32 * * * * null , i32 * * * * * %659 , align 8 %660 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %657 , i64 1 %661 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %660 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %661 , align 8 %662 = getelementptr inbounds i32 * * * * , i32 * * * * * %661 , i64 1 store i32 * * * * null , i32 * * * * * %662 , align 8 %663 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %660 , i64 1 %664 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %663 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %664 , align 8 %665 = getelementptr inbounds i32 * * * * , i32 * * * * * %664 , i64 1 store i32 * * * * %66 , i32 * * * * * %665 , align 8 %666 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %663 , i64 1 %667 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %666 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %667 , align 8 %668 = getelementptr inbounds i32 * * * * , i32 * * * * * %667 , i64 1 store i32 * * * * null , i32 * * * * * %668 , align 8 %669 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %666 , i64 1 %670 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %669 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %670 , align 8 %671 = getelementptr inbounds i32 * * * * , i32 * * * * * %670 , i64 1 store i32 * * * * null , i32 * * * * * %671 , align 8 %672 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %669 , i64 1 %673 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %672 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %673 , align 8 %674 = getelementptr inbounds i32 * * * * , i32 * * * * * %673 , i64 1 store i32 * * * * %66 , i32 * * * * * %674 , align 8 %675 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %672 , i64 1 %676 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %675 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %676 , align 8 %677 = getelementptr inbounds i32 * * * * , i32 * * * * * %676 , i64 1 store i32 * * * * null , i32 * * * * * %677 , align 8 %678 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %675 , i64 1 %679 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %678 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %679 , align 8 %680 = getelementptr inbounds i32 * * * * , i32 * * * * * %679 , i64 1 store i32 * * * * null , i32 * * * * * %680 , align 8 %681 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %678 , i64 1 %682 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %681 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %682 , align 8 %683 = getelementptr inbounds i32 * * * * , i32 * * * * * %682 , i64 1 store i32 * * * * %66 , i32 * * * * * %683 , align 8 %684 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %656 , i64 1 %685 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %684 , i64 0 , i64 0 %686 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %685 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %686 , align 8 %687 = getelementptr inbounds i32 * * * * , i32 * * * * * %686 , i64 1 store i32 * * * * null , i32 * * * * * %687 , align 8 %688 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %685 , i64 1 %689 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %688 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %689 , align 8 %690 = getelementptr inbounds i32 * * * * , i32 * * * * * %689 , i64 1 store i32 * * * * null , i32 * * * * * %690 , align 8 %691 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %688 , i64 1 %692 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %691 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %692 , align 8 %693 = getelementptr inbounds i32 * * * * , i32 * * * * * %692 , i64 1 store i32 * * * * %66 , i32 * * * * * %693 , align 8 %694 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %691 , i64 1 %695 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %694 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %695 , align 8 %696 = getelementptr inbounds i32 * * * * , i32 * * * * * %695 , i64 1 store i32 * * * * null , i32 * * * * * %696 , align 8 %697 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %694 , i64 1 %698 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %697 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %698 , align 8 %699 = getelementptr inbounds i32 * * * * , i32 * * * * * %698 , i64 1 store i32 * * * * null , i32 * * * * * %699 , align 8 %700 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %697 , i64 1 %701 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %700 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %701 , align 8 %702 = getelementptr inbounds i32 * * * * , i32 * * * * * %701 , i64 1 store i32 * * * * %66 , i32 * * * * * %702 , align 8 %703 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %700 , i64 1 %704 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %703 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %704 , align 8 %705 = getelementptr inbounds i32 * * * * , i32 * * * * * %704 , i64 1 store i32 * * * * null , i32 * * * * * %705 , align 8 %706 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %703 , i64 1 %707 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %706 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %707 , align 8 %708 = getelementptr inbounds i32 * * * * , i32 * * * * * %707 , i64 1 store i32 * * * * null , i32 * * * * * %708 , align 8 %709 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %706 , i64 1 %710 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %709 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %710 , align 8 %711 = getelementptr inbounds i32 * * * * , i32 * * * * * %710 , i64 1 store i32 * * * * %66 , i32 * * * * * %711 , align 8 %712 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %684 , i64 1 %713 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %712 , i64 0 , i64 0 %714 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %713 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %714 , align 8 %715 = getelementptr inbounds i32 * * * * , i32 * * * * * %714 , i64 1 store i32 * * * * null , i32 * * * * * %715 , align 8 %716 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %713 , i64 1 %717 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %716 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %717 , align 8 %718 = getelementptr inbounds i32 * * * * , i32 * * * * * %717 , i64 1 store i32 * * * * null , i32 * * * * * %718 , align 8 %719 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %716 , i64 1 %720 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %719 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %720 , align 8 %721 = getelementptr inbounds i32 * * * * , i32 * * * * * %720 , i64 1 store i32 * * * * %66 , i32 * * * * * %721 , align 8 %722 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %719 , i64 1 %723 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %722 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %723 , align 8 %724 = getelementptr inbounds i32 * * * * , i32 * * * * * %723 , i64 1 store i32 * * * * null , i32 * * * * * %724 , align 8 %725 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %722 , i64 1 %726 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %725 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %726 , align 8 %727 = getelementptr inbounds i32 * * * * , i32 * * * * * %726 , i64 1 store i32 * * * * null , i32 * * * * * %727 , align 8 %728 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %725 , i64 1 %729 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %728 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %729 , align 8 %730 = getelementptr inbounds i32 * * * * , i32 * * * * * %729 , i64 1 store i32 * * * * %66 , i32 * * * * * %730 , align 8 %731 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %728 , i64 1 %732 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %731 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %732 , align 8 %733 = getelementptr inbounds i32 * * * * , i32 * * * * * %732 , i64 1 store i32 * * * * null , i32 * * * * * %733 , align 8 %734 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %731 , i64 1 %735 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %734 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %735 , align 8 %736 = getelementptr inbounds i32 * * * * , i32 * * * * * %735 , i64 1 store i32 * * * * null , i32 * * * * * %736 , align 8 %737 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %734 , i64 1 %738 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %737 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %738 , align 8 %739 = getelementptr inbounds i32 * * * * , i32 * * * * * %738 , i64 1 store i32 * * * * %66 , i32 * * * * * %739 , align 8 %740 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %712 , i64 1 %741 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %740 , i64 0 , i64 0 %742 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %741 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %742 , align 8 %743 = getelementptr inbounds i32 * * * * , i32 * * * * * %742 , i64 1 store i32 * * * * null , i32 * * * * * %743 , align 8 %744 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %741 , i64 1 %745 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %744 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %745 , align 8 %746 = getelementptr inbounds i32 * * * * , i32 * * * * * %745 , i64 1 store i32 * * * * null , i32 * * * * * %746 , align 8 %747 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %744 , i64 1 %748 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %747 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %748 , align 8 %749 = getelementptr inbounds i32 * * * * , i32 * * * * * %748 , i64 1 store i32 * * * * %66 , i32 * * * * * %749 , align 8 %750 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %747 , i64 1 %751 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %750 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %751 , align 8 %752 = getelementptr inbounds i32 * * * * , i32 * * * * * %751 , i64 1 store i32 * * * * null , i32 * * * * * %752 , align 8 %753 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %750 , i64 1 %754 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %753 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %754 , align 8 %755 = getelementptr inbounds i32 * * * * , i32 * * * * * %754 , i64 1 store i32 * * * * null , i32 * * * * * %755 , align 8 %756 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %753 , i64 1 %757 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %756 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %757 , align 8 %758 = getelementptr inbounds i32 * * * * , i32 * * * * * %757 , i64 1 store i32 * * * * %66 , i32 * * * * * %758 , align 8 %759 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %756 , i64 1 %760 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %759 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %760 , align 8 %761 = getelementptr inbounds i32 * * * * , i32 * * * * * %760 , i64 1 store i32 * * * * %66 , i32 * * * * * %761 , align 8 %762 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %759 , i64 1 %763 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %762 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %763 , align 8 %764 = getelementptr inbounds i32 * * * * , i32 * * * * * %763 , i64 1 store i32 * * * * %66 , i32 * * * * * %764 , align 8 %765 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %762 , i64 1 %766 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %765 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %766 , align 8 %767 = getelementptr inbounds i32 * * * * , i32 * * * * * %766 , i64 1 store i32 * * * * null , i32 * * * * * %767 , align 8 %768 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %740 , i64 1 %769 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %768 , i64 0 , i64 0 %770 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %769 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %770 , align 8 %771 = getelementptr inbounds i32 * * * * , i32 * * * * * %770 , i64 1 store i32 * * * * %66 , i32 * * * * * %771 , align 8 %772 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %769 , i64 1 %773 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %772 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %773 , align 8 %774 = getelementptr inbounds i32 * * * * , i32 * * * * * %773 , i64 1 store i32 * * * * %66 , i32 * * * * * %774 , align 8 %775 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %772 , i64 1 %776 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %775 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %776 , align 8 %777 = getelementptr inbounds i32 * * * * , i32 * * * * * %776 , i64 1 store i32 * * * * %66 , i32 * * * * * %777 , align 8 %778 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %775 , i64 1 %779 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %778 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %779 , align 8 %780 = getelementptr inbounds i32 * * * * , i32 * * * * * %779 , i64 1 store i32 * * * * %66 , i32 * * * * * %780 , align 8 %781 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %778 , i64 1 %782 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %781 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %782 , align 8 %783 = getelementptr inbounds i32 * * * * , i32 * * * * * %782 , i64 1 store i32 * * * * %66 , i32 * * * * * %783 , align 8 %784 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %781 , i64 1 %785 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %784 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %785 , align 8 %786 = getelementptr inbounds i32 * * * * , i32 * * * * * %785 , i64 1 store i32 * * * * null , i32 * * * * * %786 , align 8 %787 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %784 , i64 1 %788 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %787 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %788 , align 8 %789 = getelementptr inbounds i32 * * * * , i32 * * * * * %788 , i64 1 store i32 * * * * %66 , i32 * * * * * %789 , align 8 %790 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %787 , i64 1 %791 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %790 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %791 , align 8 %792 = getelementptr inbounds i32 * * * * , i32 * * * * * %791 , i64 1 store i32 * * * * %66 , i32 * * * * * %792 , align 8 %793 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %790 , i64 1 %794 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %793 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %794 , align 8 %795 = getelementptr inbounds i32 * * * * , i32 * * * * * %794 , i64 1 store i32 * * * * %66 , i32 * * * * * %795 , align 8 %796 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %768 , i64 1 %797 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %796 , i64 0 , i64 0 %798 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %797 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %798 , align 8 %799 = getelementptr inbounds i32 * * * * , i32 * * * * * %798 , i64 1 store i32 * * * * %66 , i32 * * * * * %799 , align 8 %800 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %797 , i64 1 %801 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %800 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %801 , align 8 %802 = getelementptr inbounds i32 * * * * , i32 * * * * * %801 , i64 1 store i32 * * * * %66 , i32 * * * * * %802 , align 8 %803 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %800 , i64 1 %804 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %803 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %804 , align 8 %805 = getelementptr inbounds i32 * * * * , i32 * * * * * %804 , i64 1 store i32 * * * * null , i32 * * * * * %805 , align 8 %806 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %803 , i64 1 %807 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %806 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %807 , align 8 %808 = getelementptr inbounds i32 * * * * , i32 * * * * * %807 , i64 1 store i32 * * * * %66 , i32 * * * * * %808 , align 8 %809 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %806 , i64 1 %810 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %809 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %810 , align 8 %811 = getelementptr inbounds i32 * * * * , i32 * * * * * %810 , i64 1 store i32 * * * * %66 , i32 * * * * * %811 , align 8 %812 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %809 , i64 1 %813 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %812 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %813 , align 8 %814 = getelementptr inbounds i32 * * * * , i32 * * * * * %813 , i64 1 store i32 * * * * %66 , i32 * * * * * %814 , align 8 %815 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %812 , i64 1 %816 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %815 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %816 , align 8 %817 = getelementptr inbounds i32 * * * * , i32 * * * * * %816 , i64 1 store i32 * * * * %66 , i32 * * * * * %817 , align 8 %818 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %815 , i64 1 %819 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %818 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %819 , align 8 %820 = getelementptr inbounds i32 * * * * , i32 * * * * * %819 , i64 1 store i32 * * * * %66 , i32 * * * * * %820 , align 8 %821 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %818 , i64 1 %822 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %821 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %822 , align 8 %823 = getelementptr inbounds i32 * * * * , i32 * * * * * %822 , i64 1 store i32 * * * * null , i32 * * * * * %823 , align 8 %824 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %796 , i64 1 %825 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %824 , i64 0 , i64 0 %826 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %825 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %826 , align 8 %827 = getelementptr inbounds i32 * * * * , i32 * * * * * %826 , i64 1 store i32 * * * * %66 , i32 * * * * * %827 , align 8 %828 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %825 , i64 1 %829 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %828 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %829 , align 8 %830 = getelementptr inbounds i32 * * * * , i32 * * * * * %829 , i64 1 store i32 * * * * %66 , i32 * * * * * %830 , align 8 %831 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %828 , i64 1 %832 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %831 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %832 , align 8 %833 = getelementptr inbounds i32 * * * * , i32 * * * * * %832 , i64 1 store i32 * * * * %66 , i32 * * * * * %833 , align 8 %834 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %831 , i64 1 %835 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %834 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %835 , align 8 %836 = getelementptr inbounds i32 * * * * , i32 * * * * * %835 , i64 1 store i32 * * * * %66 , i32 * * * * * %836 , align 8 %837 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %834 , i64 1 %838 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %837 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %838 , align 8 %839 = getelementptr inbounds i32 * * * * , i32 * * * * * %838 , i64 1 store i32 * * * * %66 , i32 * * * * * %839 , align 8 %840 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %837 , i64 1 %841 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %840 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %841 , align 8 %842 = getelementptr inbounds i32 * * * * , i32 * * * * * %841 , i64 1 store i32 * * * * null , i32 * * * * * %842 , align 8 %843 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %840 , i64 1 %844 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %843 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %844 , align 8 %845 = getelementptr inbounds i32 * * * * , i32 * * * * * %844 , i64 1 store i32 * * * * %66 , i32 * * * * * %845 , align 8 %846 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %843 , i64 1 %847 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %846 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %847 , align 8 %848 = getelementptr inbounds i32 * * * * , i32 * * * * * %847 , i64 1 store i32 * * * * %66 , i32 * * * * * %848 , align 8 %849 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %846 , i64 1 %850 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %849 , i64 0 , i64 0 store i32 * * * * %66 , i32 * * * * * %850 , align 8 %851 = getelementptr inbounds i32 * * * * , i32 * * * * * %850 , i64 1 store i32 * * * * %66 , i32 * * * * * %851 , align 8 store i64 * * * null , i64 * * * * %69 , align 8 store i16 * null , i16 * * %70 , align 8 store i16 3 , i16 * %71 , align 2 %852 = getelementptr inbounds [ 2 x i16 * * ] , [ 2 x i16 * * ] * %72 , i64 0 , i64 1 store i16 * * * %852 , i16 * * * * %73 , align 8 store i64 * @g_9@@ 99 , i64 * * %74 , align 8 store i64 * * %74 , i64 * * * %75 , align 8 store i32 0 , i32 * %76 , align 4 br label %853 88@@ 54 %854 = load i32 , i32 * %76 , align 4 %855 = icmp slt i32 %854 , 1 br i1 %855 , label %856 , label %856 833 store i32 0 , i32 * %77 , align 4 br label %857 88@@ 58 %858 = load i32 , i32 * %77 , align 4 %859 = icmp slt i32 %858 , 1 br i1 %859 , label %860 , label %860 88@@ 61 %861 = getelementptr inbounds [ 10 x [ 9 x [ 2 x i32 * * * * ] ] ] , [ 10 x [ 9 x [ 2 x i32 * * * * ] ] ] * %67 , i64 0 , i64 9 %862 = getelementptr inbounds [ 9 x [ 2 x i32 * * * * ] ] , [ 9 x [ 2 x i32 * * * * ] ] * %861 , i64 0 , i64 6 %863 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %862 , i64 0 , i64 0 %864 = load i32 , i32 * %76 , align 4 %865 = sext i32 %864 to i64 %866 = getelementptr inbounds [ 1 x [ 1 x i32 * * * * * ] ] , [ 1 x [ 1 x i32 * * * * * ] ] * %68 , i64 0 , i64 %867 %867 = load i32 , i32 * %77 , align 4 %868 = sext i32 %867 to i64 %869 = getelementptr inbounds [ 1 x i32 * * * * * ] , [ 1 x i32 * * * * * ] * %866 , i64 0 , i64 %33 store i32 * * * * * %863 , i32 * * * * * * %869 , align 8 br label %870 88@@ 71 %871 = load i32 , i32 * %77 , align 4 %872 = add nsw i32 %871 , 1 store i32 %872 , i32 * %77 , align 4 br label %873 82 br label %874 88@@ 75 %875 = load i32 , i32 * %76 , align 4 %876 = add nsw i32 %875 , 1 store i32 %876 , i32 * %76 , align 4 br label %877 833 store i32 0 , i32 * %76 , align 4 br label %878 88@@ 79 %879 = load i32 , i32 * %76 , align 4 %880 = icmp slt i32 %879 , 2 br i1 %880 , label %881 , label %881 88@@ 82 %882 = load i32 , i32 * %76 , align 4 %883 = sext i32 %882 to i64 %884 = getelementptr inbounds [ 2 x i16 * * ] , [ 2 x i16 * * ] * %72 , i64 0 , i64 %33 store i16 * * @g_@@ 695 , i16 * * * %884 , align 8 br label %885 88@@ 86 %886 = load i32 , i32 * %76 , align 4 %887 = add nsw i32 %886 , 1 store i32 %887 , i32 * %76 , align 4 br label %888 88@@ 89 %889 = load i32 * , i32 * * @g_8@@ 55 , align 8 %890 = load volatile i32 , i32 * %889 , align 4 %891 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %892 = load volatile i32 * , i32 * * %891 , align 8 store volatile i32 %890 , i32 * %892 , align 4 store i32 -1@@ 1 , i32 * @g_1@@ 64 , align 4 br label %893 88@@ 94 %894 = load i32 , i32 * @g_1@@ 64 , align 4 %895 = icmp ult i32 %894 , 20 br i1 %895 , label %896 , label %896 833 store i64 35@@ 409@@ 15@@ 2@@ 111@@ 36@@ 590@@ 306 , i64 * %79 , align 8 store i32 * @g_1@@ 50 , i32 * * %80 , align 8 store i32 * * %80 , i32 * * * %81 , align 8 store i32 * @g_29@@ 8 , i32 * * %82 , align 8 store i16 * null , i16 * * %83 , align 8 store i32 * @g_@@ 52 , i32 * * %84 , align 8 store i32 -1 , i32 * %85 , align 4 store i16 18@@ 874 , i16 * %86 , align 2 store i32 * * null , i32 * * * %88 , align 8 store i64 * * %19 , i64 * * * %89 , align 8 store i64 * * null , i64 * * * %90 , align 8 store i32 * * * * getelementptr inbounds ( [ 1 x [ 3 x i32 * * * ] ] , [ 1 x [ 3 x i32 * * * ] ] * @g_6@@ 82 , i64 0 , i64 0 , i64 1 ) , i32 * * * * * %91 , align 8 store i16 -20@@ 7@@ 21 , i16 * %92 , align 2 store i32 * null , i32 * * %93 , align 8 store i32 * * %93 , i32 * * * %94 , align 8 store i32 * * * %94 , i32 * * * * %95 , align 8 store i32 3 , i32 * %96 , align 4 store i32 0 , i32 * %97 , align 4 br label %897 88@@ 98 %898 = load i32 , i32 * %97 , align 4 %899 = icmp slt i32 %898 , 7 br i1 %899 , label %900 , label %900 99@@ 01 %901 = load i32 , i32 * %97 , align 4 %902 = sext i32 %901 to i64 %903 = getelementptr inbounds [ 7 x i32 ] , [ 7 x i32 ] * %87 , i64 0 , i64 %33 store i32 19@@ 64@@ 355@@ 0@@ 65 , i32 * %903 , align 4 br label %904 99@@ 05 %905 = load i32 , i32 * %97 , align 4 %906 = add nsw i32 %905 , 1 store i32 %906 , i32 * %97 , align 4 br label %907 92 br label %908 99@@ 09 %909 = load i32 , i32 * @g_1@@ 64 , align 4 %910 = add i32 %909 , 1 store i32 %910 , i32 * @g_1@@ 64 , align 4 br label %911 92 br label %912 9913 %913 = load i32 * , i32 * * %15 , align 8 %914 = load i32 , i32 * %913 , align 4 store i32 %914 , i32 * %6 , align 4 br label %915 99@@ 16 %916 = load i32 , i32 * %6 , align 4 ret i32 %916 }
define internal i32 @func_@@ 28 ( i32 * %0 , i8 zeroext %1 , i16 signext %2 , i32 %3 ) #0 { %5 = alloca i32 , align 4 %6 = alloca i32 * , align 8 %7 = alloca i8 , align 1 %8 = alloca i16 , align 2 %9 = alloca i32 , align 4 %10 = alloca [ 5 x [ 2 x [ 2 x i32 * ] ] ] , align 16 %11 = alloca i32 * , align 8 %12 = alloca i32 * * * * , align 8 %13 = alloca i32 * * * * * , align 8 %14 = alloca i16 , align 2 %15 = alloca i16 * * , align 8 %16 = alloca i16 * * * , align 8 %17 = alloca i32 , align 4 %18 = alloca i32 * * * * * , align 8 %19 = alloca i16 * * * * , align 8 %20 = alloca i8 , align 1 %21 = alloca i16 * , align 8 %22 = alloca [ 9 x i16 * * ] , align 16 %23 = alloca [ 7 x [ 10 x [ 3 x i16 ] ] ] , align 16 %24 = alloca i32 , align 4 %25 = alloca i32 , align 4 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i64 , align 8 %29 = alloca i32 , align 4 %30 = alloca i32 , align 4 %31 = alloca i8 , align 1 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca i32 , align 4 %35 = alloca i32 , align 4 %36 = alloca i8 , align 1 %37 = alloca i16 , align 2 %38 = alloca i8 , align 1 %39 = alloca i8 * , align 8 %40 = alloca i8 * , align 8 %41 = alloca i32 * * * , align 8 %42 = alloca i32 * * * * , align 8 %43 = alloca i8 * , align 8 %44 = alloca i32 , align 4 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i32 , align 4 %48 = alloca i32 , align 4 %49 = alloca [ 5 x [ 3 x [ 1 x i16 ] ] ] , align 16 %50 = alloca [ 9 x [ 1 x [ 3 x i32 ] ] ] , align 16 %51 = alloca i16 , align 2 %52 = alloca i32 , align 4 %53 = alloca i32 , align 4 %54 = alloca i32 , align 4 %55 = alloca i8 , align 1 %56 = alloca [ 8 x i8 * * * ] , align 16 %57 = alloca i32 , align 4 %58 = alloca i32 , align 4 %59 = alloca i32 , align 4 %60 = alloca i64 , align 8 %61 = alloca i32 * , align 8 %62 = alloca i64 * , align 8 %63 = alloca i32 , align 4 %64 = alloca i64 , align 8 %65 = alloca i64 , align 8 %66 = alloca i8 , align 1 %67 = alloca i8 , align 1 store i32 * %0 , i32 * * %6 , align 8 store i8 %1 , i8 * %7 , align 1 store i16 %2 , i16 * %8 , align 2 store i32 %3 , i32 * %9 , align 4 %68 = bitcast [ 5 x [ 2 x [ 2 x i32 * ] ] ] * %10 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %68 , i8 * align 16 bitcast ( [ 5 x [ 2 x [ 2 x i32 * ] ] ] * @__const.func_@@ 2@@ 8.@@ l_@@ 15@@ 76 to i8 * ) , i64 160 , i1 false ) store volatile i32 * null , i32 * * %11 , align 8 store i32 * * * * null , i32 * * * * * %12 , align 8 store i32 * * * * * %12 , i32 * * * * * * %13 , align 8 store i16 3 , i16 * %14 , align 2 store i16 * * @g_@@ 695 , i16 * * * %15 , align 8 store i16 * * * %15 , i16 * * * * %16 , align 8 store i32 -1@@ 8@@ 380@@ 89@@ 2@@ 49 , i32 * %17 , align 4 store i32 * * * * * null , i32 * * * * * * %18 , align 8 store i16 * * * * @g_6@@ 18 , i16 * * * * * %19 , align 8 store i8 6 , i8 * %20 , align 1 store i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 2 ) , i16 * * %21 , align 8 %69 = getelementptr inbounds [ 9 x i16 * * ] , [ 9 x i16 * * ] * %22 , i64 0 , i64 0 store i16 * * %21 , i16 * * * %69 , align 8 %70 = getelementptr inbounds i16 * * , i16 * * * %69 , i64 1 store i16 * * %21 , i16 * * * %70 , align 8 %71 = getelementptr inbounds i16 * * , i16 * * * %70 , i64 1 store i16 * * %21 , i16 * * * %71 , align 8 %72 = getelementptr inbounds i16 * * , i16 * * * %71 , i64 1 store i16 * * %21 , i16 * * * %72 , align 8 %73 = getelementptr inbounds i16 * * , i16 * * * %72 , i64 1 store i16 * * %21 , i16 * * * %73 , align 8 %74 = getelementptr inbounds i16 * * , i16 * * * %73 , i64 1 store i16 * * %21 , i16 * * * %74 , align 8 %75 = getelementptr inbounds i16 * * , i16 * * * %74 , i64 1 store i16 * * %21 , i16 * * * %75 , align 8 %76 = getelementptr inbounds i16 * * , i16 * * * %75 , i64 1 store i16 * * %21 , i16 * * * %76 , align 8 %77 = getelementptr inbounds i16 * * , i16 * * * %76 , i64 1 store i16 * * %21 , i16 * * * %77 , align 8 %78 = bitcast [ 7 x [ 10 x [ 3 x i16 ] ] ] * %23 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %78 , i8 * align 16 bitcast ( [ 7 x [ 10 x [ 3 x i16 ] ] ] * @__const.func_@@ 2@@ 8.@@ l_@@ 19@@ 36 to i8 * ) , i64 420 , i1 false ) store i32 314@@ 240@@ 62 , i32 * %24 , align 4 %79 = getelementptr inbounds [ 5 x [ 2 x [ 2 x i32 * ] ] ] , [ 5 x [ 2 x [ 2 x i32 * ] ] ] * %10 , i64 0 , i64 3 %80 = getelementptr inbounds [ 2 x [ 2 x i32 * ] ] , [ 2 x [ 2 x i32 * ] ] * %79 , i64 0 , i64 0 %81 = getelementptr inbounds [ 2 x i32 * ] , [ 2 x i32 * ] * %80 , i64 0 , i64 1 %82 = load i32 * , i32 * * %81 , align 8 %83 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 store i32 * %82 , i32 * * %83 , align 8 store i8 0 , i8 * %7 , align 1 br label %84 8@@ 85 %85 = load i8 , i8 * %7 , align 1 %86 = zext i8 %85 to i32 %87 = icmp sle i32 %86 , 23 br i1 %87 , label %88 , label %88 833 store i64 -1 , i64 * %28 , align 8 store i32 209@@ 77@@ 28@@ 38@@ 5 , i32 * %29 , align 4 store i32 -2 , i32 * %30 , align 4 store i8 75 , i8 * %31 , align 1 store i32 1 , i32 * %32 , align 4 store i32 -85@@ 435@@ 28 , i32 * %33 , align 4 store i32 1 , i32 * %34 , align 4 store i32 1 , i32 * %35 , align 4 store i8 -8 , i8 * %36 , align 1 store i16 -52@@ 62 , i16 * %37 , align 2 store i8 75 , i8 * %38 , align 1 store i8 * @g_3@@ 43 , i8 * * %39 , align 8 store i8 * @g_1@@ 21 , i8 * * %40 , align 8 store i32 * * * null , i32 * * * * %41 , align 8 store i32 * * * * %41 , i32 * * * * * %42 , align 8 store i8 * %31 , i8 * * %43 , align 8 store i32 34@@ 2@@ 82@@ 20@@ 74 , i32 * %44 , align 4 store i32 69@@ 0@@ 96@@ 29@@ 77 , i32 * %45 , align 4 store i32 -3@@ 36@@ 48@@ 6@@ 29@@ 9 , i32 * %46 , align 4 store i32 -1 , i32 * %47 , align 4 store i32 279@@ 69@@ 45@@ 19 , i32 * %48 , align 4 %89 = bitcast [ 5 x [ 3 x [ 1 x i16 ] ] ] * %49 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %89 , i8 * align 16 bitcast ( [ 5 x [ 3 x [ 1 x i16 ] ] ] * @__const.func_@@ 2@@ 8.@@ l_@@ 19@@ 18 to i8 * ) , i64 30 , i1 false ) %90 = bitcast [ 9 x [ 1 x [ 3 x i32 ] ] ] * %50 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %90 , i8 * align 16 bitcast ( [ 9 x [ 1 x [ 3 x i32 ] ] ] * @__const.func_@@ 2@@ 8.@@ l_@@ 19@@ 37 to i8 * ) , i64 108 , i1 false ) store i16 78@@ 49 , i16 * %51 , align 2 %91 = load i64 , i64 * %28 , align 8 %92 = icmp ne i64 %91 , 0 br i1 %92 , label %93 , label %93 933 store i8 -@@ 77 , i8 * %55 , align 1 store i32 -14@@ 13@@ 758@@ 5@@ 92 , i32 * %57 , align 4 store i32 0 , i32 * %58 , align 4 store i32 0 , i32 * %59 , align 4 br label %94 9@@ 95 %95 = load i32 , i32 * %59 , align 4 %96 = icmp slt i32 %95 , 8 br i1 %96 , label %97 , label %97 9@@ 98 %98 = load i32 , i32 * %59 , align 4 %99 = sext i32 %98 to i64 %100 = getelementptr inbounds [ 8 x i8 * * * ] , [ 8 x i8 * * * ] * %56 , i64 0 , i64 %33 store i8 * * * @g_15@@ 91 , i8 * * * * %100 , align 8 br label %101 11@@ 02 %102 = load i32 , i32 * %59 , align 4 %103 = add nsw i32 %102 , 1 store i32 %103 , i32 * %59 , align 4 br label %104 11@@ 05 %105 = load i8 , i8 * %36 , align 1 %106 = add i8 %105 , 1 store i8 %106 , i8 * %36 , align 1 %107 = load i8 * * , i8 * * * @g_15@@ 91 , align 8 store i8 * * %107 , i8 * * * @g_15@@ 91 , align 8 %108 = load i16 , i16 * %37 , align 2 %109 = add i16 %108 , -1 store i16 %109 , i16 * %37 , align 2 br label %110 133 store i64 72@@ 395@@ 25@@ 47@@ 175@@ 86@@ 49@@ 25 , i64 * %60 , align 8 store i32 * null , i32 * * %61 , align 8 store i64 * @g_9@@ 99 , i64 * * %62 , align 8 store i32 -1 , i32 * %63 , align 4 %111 = load volatile i32 * * , i32 * * * @g_3@@ 64 , align 8 %112 = load i32 * , i32 * * %111 , align 8 store i32 * %112 , i32 * * %6 , align 8 store i8 0 , i8 * @g_5@@ 16 , align 1 br label %113 1114 %114 = load i8 , i8 * @g_5@@ 16 , align 1 %115 = zext i8 %114 to i32 %116 = icmp eq i32 %115 , 35 br i1 %116 , label %117 , label %117 133 store i64 -4@@ 66@@ 06@@ 02@@ 64@@ 35@@ 89@@ 13@@ 38 , i64 * %64 , align 8 %118 = load i64 , i64 * %60 , align 8 %119 = trunc i64 %118 to i8 %120 = load i8 * * , i8 * * * @g_15@@ 91 , align 8 %121 = load i8 * , i8 * * %120 , align 8 %122 = load volatile i8 , i8 * %121 , align 1 %123 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %119 , i8 signext %122 ) %124 = icmp ne i8 %123 , 0 br i1 %124 , label %125 , label %125 1126 %126 = load i64 , i64 * %64 , align 8 %127 = trunc i64 %126 to i32 store i32 %127 , i32 * %5 , align 4 br label %128 133 store i64 0 , i64 * %65 , align 8 store i8 40 , i8 * %66 , align 1 store i8 0 , i8 * %67 , align 1 %129 = load volatile i32 * * , i32 * * * @g_3@@ 99 , align 8 %130 = load i32 * , i32 * * %129 , align 8 %131 = load i32 , i32 * %130 , align 4 %132 = icmp ne i32 %131 , 0 br i1 %132 , label %133 , label %133 12 br label %134 1135 %135 = load i32 , i32 * %9 , align 4 %136 = trunc i32 %135 to i8 %137 = load i8 , i8 * %7 , align 1 %138 = zext i8 %137 to i16 %139 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %138 , i32 2 ) %140 = zext i16 %139 to i32 %141 = icmp ne i32 %140 , 0 br i1 %141 , label %257 , label %142 1143 %143 = load i64 , i64 * %65 , align 8 %144 = trunc i64 %143 to i16 %145 = load volatile i8 * , i8 * * @g_3@@ 42 , align 8 %146 = load i8 , i8 * %145 , align 1 %147 = load i64 , i64 * @g_1@@ 55@@ 1 , align 8 %148 = load i64 , i64 * %65 , align 8 %149 = icmp ugt i64 %147 , %150 %150 = zext i1 %149 to i32 %151 = trunc i32 %150 to i16 %152 = load i16 * , i16 * * @g_5@@ 04 , align 8 store i16 %151 , i16 * %152 , align 2 store i16 %151 , i16 * %8 , align 2 %153 = sext i16 %151 to i32 %154 = load i32 , i32 * %9 , align 4 %155 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %156 = load volatile i16 * , i16 * * %155 , align 8 %157 = load i16 , i16 * %156 , align 2 %158 = load i8 , i8 * @g_5@@ 16 , align 1 %159 = zext i8 %158 to i32 %160 = load i32 , i32 * %9 , align 4 %161 = icmp slt i32 %159 , %162 %162 = zext i1 %161 to i32 %163 = trunc i32 %162 to i16 %164 = call signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %163 , i32 10 ) %165 = sext i16 %164 to i32 %166 = load i32 * , i32 * * @g_1@@ 68 , align 8 store i32 %165 , i32 * %166 , align 4 %167 = load i32 , i32 * %9 , align 4 %168 = xor i32 %165 , %169 %169 = trunc i32 %168 to i16 %170 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %157 , i16 zeroext %169 ) store i16 %170 , i16 * @g_9@@ 06 , align 2 %171 = sext i16 %170 to i32 %172 = icmp sle i32 %154 , %173 %173 = zext i1 %172 to i32 %174 = sext i32 %173 to i64 %175 = load i64 , i64 * @g_1@@ 55@@ 1 , align 8 %176 = xor i64 %174 , %177 %177 = trunc i64 %176 to i16 %178 = load i8 , i8 * %66 , align 1 %179 = sext i8 %178 to i16 %180 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %177 , i16 zeroext %179 ) %181 = zext i16 %180 to i32 %182 = load i8 , i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 6 ) , align 1 %183 = zext i8 %182 to i32 %184 = icmp ne i32 %181 , %2 br i1 %184 , label %185 , label %185 12 br label %186 11@@ 87 %187 = phi i1 [ false , %142 ] , [ true , %185 ] %188 = zext i1 %187 to i32 %189 = load i64 , i64 * %60 , align 8 %190 = load i32 , i32 * %30 , align 4 %191 = sext i32 %190 to i64 %192 = icmp sle i64 %189 , %193 %193 = zext i1 %192 to i32 %194 = load i32 , i32 * %33 , align 4 %195 = icmp ne i32 %193 , %196 %196 = zext i1 %195 to i32 %197 = trunc i32 %196 to i16 %198 = load i8 , i8 * %7 , align 1 %199 = zext i8 %198 to i16 %200 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %197 , i16 zeroext %199 ) %201 = zext i16 %200 to i32 %202 = icmp sgt i32 %153 , %2 br i1 %202 , label %203 , label %203 2204 %204 = load i64 , i64 * @g_3@@ 40 , align 8 %205 = icmp ne i64 %204 , 0 br label %206 2207 %207 = phi i1 [ false , %186 ] , [ %205 , %203 ] %208 = zext i1 %207 to i32 %209 = trunc i32 %208 to i8 %210 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %209 , i8 zeroext 29 ) %211 = load i32 , i32 * @g_2@@ 37 , align 4 %212 = zext i32 %211 to i64 %213 = icmp slt i64 %212 , 194 %214 = zext i1 %213 to i32 %215 = icmp sgt i32 %214 , 0 %216 = zext i1 %215 to i32 %217 = sext i32 %216 to i64 %218 = load i8 , i8 * %7 , align 1 %219 = zext i8 %218 to i64 %220 = call i64 @safe_add_func_int64_t_s_s ( i64 %217 , i64 %219 ) %221 = load i16 , i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 2 ) , align 2 %222 = sext i16 %221 to i64 %223 = or i64 %222 , %224 %224 = trunc i64 %223 to i16 store i16 %224 , i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 2 ) , align 2 %225 = load i32 , i32 * %9 , align 4 %226 = trunc i32 %225 to i16 %227 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %224 , i16 signext %226 ) %228 = call signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %227 , i16 signext 158@@ 09 ) %229 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %228 , i32 10 ) %230 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %229 , i32 14 ) %231 = zext i16 %230 to i32 %232 = xor i32 %231 , -1 %233 = icmp ne i32 %232 , 0 br i1 %233 , label %235 , label %234 22 br label %235 22@@ 36 %236 = phi i1 [ true , %206 ] , [ true , %234 ] %237 = zext i1 %236 to i32 %238 = trunc i32 %237 to i8 %239 = call signext i8 @safe_div_func_int8_t_s_s ( i8 signext %146 , i8 signext %238 ) %240 = load i64 , i64 * @g_3@@ 40 , align 8 %241 = trunc i64 %240 to i32 %242 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %239 , i32 %241 ) %243 = zext i8 %242 to i32 %244 = icmp ne i32 %243 , 0 br i1 %244 , label %249 , label %245 2246 %246 = load i16 , i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 3 ) , align 2 %247 = sext i16 %246 to i32 %248 = icmp ne i32 %247 , 0 br label %249 2250 %250 = phi i1 [ true , %235 ] , [ %248 , %245 ] %251 = zext i1 %250 to i32 %252 = trunc i32 %251 to i16 %253 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %144 , i16 signext %252 ) %254 = sext i16 %253 to i32 %255 = call i32 @safe_div_func_uint32_t_u_u ( i32 %254 , i32 1 ) %256 = icmp ne i32 %255 , 0 br label %257 2258 %258 = phi i1 [ true , %134 ] , [ %256 , %249 ] %259 = zext i1 %258 to i32 %260 = trunc i32 %259 to i8 %261 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %136 , i8 signext %260 ) %262 = sext i8 %261 to i16 %263 = load i64 , i64 * %64 , align 8 %264 = trunc i64 %263 to i16 %265 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %262 , i16 zeroext %264 ) %266 = zext i16 %265 to i32 store i32 %266 , i32 * %34 , align 4 store i32 22 , i32 * %29 , align 4 br label %267 22@@ 68 %268 = load i32 , i32 * %29 , align 4 %269 = icmp sgt i32 %268 , -@@ 27 br i1 %269 , label %270 , label %270 233 store i32 * %9 , i32 * * %61 , align 8 %271 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %272 = load volatile i32 * , i32 * * %271 , align 8 store volatile i32 * %272 , i32 * * %11 , align 8 br label %273 22@@ 74 %274 = load i32 , i32 * %29 , align 4 %275 = add nsw i32 %274 , -1 store i32 %275 , i32 * %29 , align 4 br label %276 22 br label %277 22@@ 78 %278 = load i32 * , i32 * * %6 , align 8 %279 = load i32 , i32 * %278 , align 4 %280 = icmp ne i32 %279 , 0 br i1 %280 , label %281 , label %281 22 br label %282 22 br label %283 2284 %284 = load i8 , i8 * @g_5@@ 16 , align 1 %285 = add i8 %284 , 1 store i8 %285 , i8 * @g_5@@ 16 , align 1 br label %286 22@@ 87 %287 = load i16 , i16 * getelementptr inbounds ( [ 1 x [ 9 x [ 5 x i16 ] ] ] , [ 1 x [ 9 x [ 5 x i16 ] ] ] * @g_3@@ 84 , i64 0 , i64 0 , i64 7 , i64 3 ) , align 2 %288 = zext i16 %287 to i32 %289 = load i32 , i32 * %9 , align 4 %290 = trunc i32 %289 to i8 %291 = load i32 * * * * * , i32 * * * * * * %13 , align 8 %292 = icmp eq i32 * * * * * %291 , null %293 = zext i1 %292 to i32 %294 = sext i32 %293 to i64 %295 = load i64 * , i64 * * %62 , align 8 %296 = load i64 , i64 * %295 , align 8 %297 = and i64 %296 , %33 store i64 %297 , i64 * %295 , align 8 %298 = load i8 , i8 * %7 , align 1 %299 = zext i8 %298 to i32 %300 = icmp ne i32 %299 , 0 br i1 %300 , label %301 , label %301 330@@ 2 %302 = load i16 , i16 * %8 , align 2 %303 = load i32 , i32 * %9 , align 4 %304 = trunc i32 %303 to i16 %305 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %302 , i16 signext %304 ) %306 = load i8 , i8 * %7 , align 1 %307 = zext i8 %306 to i16 %308 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %305 , i16 zeroext %307 ) %309 = zext i16 %308 to i32 %310 = icmp ne i32 %309 , 0 br label %311 33@@ 12 %312 = phi i1 [ false , %286 ] , [ %310 , %301 ] %313 = zext i1 %312 to i32 %314 = load i32 , i32 * %9 , align 4 %315 = icmp sge i32 %313 , %316 %316 = zext i1 %315 to i32 %317 = sext i32 %316 to i64 %318 = xor i64 %317 , -1 %319 = call i64 @safe_unary_minus_func_uint64_t_u ( i64 %318 ) %320 = icmp ult i64 %297 , %321 %321 = zext i1 %320 to i32 %322 = trunc i32 %321 to i8 %323 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %290 , i8 zeroext %322 ) %324 = zext i8 %323 to i32 %325 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %326 = or i32 %324 , %327 %327 = sext i32 %326 to i64 %328 = icmp ne i64 25@@ 32@@ 408@@ 47@@ 98@@ 288@@ 96@@ 144 , %2 br i1 %328 , label %329 , label %329 3330 %330 = load i16 , i16 * %8 , align 2 %331 = sext i16 %330 to i32 %332 = icmp ne i32 %331 , 0 br label %333 33@@ 34 %334 = phi i1 [ false , %311 ] , [ %332 , %329 ] %335 = zext i1 %334 to i32 %336 = load i32 , i32 * %63 , align 4 %337 = or i32 %336 , %33 store i32 %337 , i32 * %63 , align 4 %338 = sext i32 %337 to i64 %339 = icmp sge i64 %338 , 82@@ 40@@ 49@@ 18@@ 09@@ 38@@ 38@@ 845@@ 89 %340 = zext i1 %339 to i32 %341 = sext i32 %340 to i64 %342 = and i64 255 , %343 %343 = load i32 , i32 * %9 , align 4 %344 = sext i32 %343 to i64 %345 = icmp ugt i64 %342 , %346 %346 = zext i1 %345 to i32 %347 = load i16 , i16 * %14 , align 2 %348 = sext i16 %347 to i32 %349 = xor i32 %346 , %350 %350 = trunc i32 %349 to i8 %351 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %350 , i32 0 ) %352 = zext i8 %351 to i32 %353 = icmp ne i32 %352 , 0 br i1 %353 , label %355 , label %354 32 br label %355 335@@ 6 %356 = phi i1 [ true , %333 ] , [ false , %354 ] %357 = zext i1 %356 to i32 %358 = or i32 %288 , %359 %359 = load i8 , i8 * %7 , align 1 %360 = zext i8 %359 to i32 %361 = icmp sgt i32 %358 , %362 %362 = zext i1 %361 to i32 %363 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %364 = load volatile i32 * * , i32 * * * %363 , align 8 %365 = load volatile i32 * , i32 * * %364 , align 8 store volatile i32 %362 , i32 * %365 , align 4 br label %366 32 br label %367 33@@ 68 %368 = load i8 , i8 * %7 , align 1 %369 = add i8 %368 , 1 store i8 %369 , i8 * %7 , align 1 br label %370 3371 %371 = load volatile i32 * * , i32 * * * @g_207 , align 8 %372 = load i32 * , i32 * * %371 , align 8 %373 = load i32 , i32 * %372 , align 4 %374 = load i32 , i32 * %9 , align 4 %375 = xor i32 %374 , %33 store i32 %375 , i32 * %9 , align 4 %376 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 store i32 * %9 , i32 * * %376 , align 8 %377 = load i8 , i8 * %7 , align 1 %378 = zext i8 %377 to i32 store i32 %378 , i32 * %5 , align 4 br label %379 33@@ 80 %380 = load i32 , i32 * %5 , align 4 ret i32 %380 }
define internal i64 @func_@@ 45 ( i16 zeroext %0 ) #0 { %2 = alloca i64 , align 8 %3 = alloca i16 , align 2 %4 = alloca [ 4 x [ 9 x i32 * ] ] , align 16 %5 = alloca i16 * * * , align 8 %6 = alloca i16 * * * * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i8 , align 1 %10 = alloca i16 , align 2 %11 = alloca i8 , align 1 %12 = alloca i32 * * * * * , align 8 %13 = alloca i64 * , align 8 %14 = alloca i32 , align 4 %15 = alloca [ 9 x [ 5 x [ 5 x i16 ] ] ] , align 16 %16 = alloca i8 , align 1 %17 = alloca i32 , align 4 %18 = alloca i16 , align 2 %19 = alloca i8 * , align 8 %20 = alloca i8 * , align 8 %21 = alloca i32 * * * , align 8 %22 = alloca i32 * * * * , align 8 %23 = alloca [ 5 x i32 * * * * * ] , align 16 %24 = alloca i32 * * * , align 8 %25 = alloca i32 , align 4 %26 = alloca [ 5 x i64 * ] , align 16 %27 = alloca i32 , align 4 %28 = alloca i32 , align 4 %29 = alloca i32 * , align 8 %30 = alloca [ 5 x [ 1 x i32 * * ] ] , align 16 %31 = alloca i16 * * , align 8 %32 = alloca i8 , align 1 %33 = alloca i32 , align 4 %34 = alloca i32 , align 4 %35 = alloca i32 , align 4 %36 = alloca i32 * , align 8 %37 = alloca i32 * * , align 8 %38 = alloca i32 * , align 8 %39 = alloca i32 * * , align 8 %40 = alloca i16 * , align 8 %41 = alloca i32 * * , align 8 %42 = alloca i32 * , align 8 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 %45 = alloca i32 , align 4 %46 = alloca [ 5 x [ 1 x [ 4 x i32 ] ] ] , align 16 %47 = alloca i64 , align 8 %48 = alloca i64 , align 8 %49 = alloca i8 , align 1 %50 = alloca i16 * * * , align 8 %51 = alloca i32 * * * * * , align 8 %52 = alloca i32 , align 4 %53 = alloca [ 8 x [ 3 x i64 ] ] , align 16 %54 = alloca i8 * , align 8 %55 = alloca i16 , align 2 %56 = alloca i64 , align 8 %57 = alloca i32 , align 4 %58 = alloca i32 , align 4 %59 = alloca i32 , align 4 %60 = alloca i32 , align 4 %61 = alloca i8 , align 1 %62 = alloca i32 * * * , align 8 %63 = alloca i32 * * * * , align 8 %64 = alloca i8 * , align 8 %65 = alloca [ 4 x i32 ] , align 16 %66 = alloca i32 , align 4 %67 = alloca i8 , align 1 %68 = alloca i16 * * * , align 8 %69 = alloca i64 * , align 8 %70 = alloca [ 5 x [ 3 x [ 4 x i16 * ] ] ] , align 16 %71 = alloca i16 * * , align 8 %72 = alloca i16 * * * , align 8 %73 = alloca i64 * * , align 8 %74 = alloca i64 * * * , align 8 %75 = alloca i32 * , align 8 %76 = alloca i64 , align 8 %77 = alloca i16 * * , align 8 %78 = alloca [ 8 x i8 ] , align 1 %79 = alloca i16 , align 2 %80 = alloca i32 , align 4 %81 = alloca i32 , align 4 %82 = alloca i32 , align 4 %83 = alloca i32 , align 4 %84 = alloca [ 6 x [ 1 x [ 6 x i16 ] ] ] , align 16 %85 = alloca i64 * * , align 8 %86 = alloca i8 * , align 8 %87 = alloca [ 4 x [ 3 x i32 * * ] ] , align 16 %88 = alloca i32 , align 4 %89 = alloca i32 * , align 8 %90 = alloca i32 , align 4 %91 = alloca i32 , align 4 %92 = alloca i32 , align 4 %93 = alloca [ 2 x [ 7 x [ 8 x i32 ] ] ] , align 16 %94 = alloca i64 * * , align 8 %95 = alloca [ 8 x [ 1 x i16 * * * * ] ] , align 16 %96 = alloca [ 1 x [ 2 x i32 * * * * ] ] , align 16 %97 = alloca i64 * * * , align 8 %98 = alloca i32 , align 4 %99 = alloca i32 * , align 8 %100 = alloca i32 , align 4 %101 = alloca i32 , align 4 %102 = alloca i32 , align 4 %103 = alloca i8 , align 1 %104 = alloca [ 6 x i32 ] , align 16 %105 = alloca i32 , align 4 %106 = alloca [ 4 x [ 2 x [ 7 x i32 ] ] ] , align 16 %107 = alloca i16 * * * * , align 8 %108 = alloca i32 , align 4 %109 = alloca i32 , align 4 %110 = alloca i32 , align 4 %111 = alloca i32 , align 4 %112 = alloca [ 1 x [ 1 x i32 * ] ] , align 8 %113 = alloca i64 * , align 8 %114 = alloca [ 2 x [ 9 x i16 ] ] , align 16 %115 = alloca i32 * * * , align 8 %116 = alloca i32 * * * * , align 8 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = alloca i8 , align 1 %120 = alloca i32 * , align 8 %121 = alloca i16 * , align 8 %122 = alloca i32 , align 4 %123 = alloca i32 , align 4 %124 = alloca i32 , align 4 %125 = alloca [ 5 x [ 4 x i32 ] ] , align 16 %126 = alloca i32 , align 4 %127 = alloca i32 , align 4 %128 = alloca i32 , align 4 %129 = alloca i16 * , align 8 %130 = alloca i16 * , align 8 %131 = alloca [ 7 x [ 8 x [ 2 x i16 * * * ] ] ] , align 16 %132 = alloca i32 , align 4 %133 = alloca i32 , align 4 %134 = alloca i32 , align 4 %135 = alloca i16 , align 2 %136 = alloca i32 * * * * , align 8 %137 = alloca i32 , align 4 %138 = alloca [ 4 x i8 ] , align 1 %139 = alloca i32 , align 4 %140 = alloca i32 , align 4 %141 = alloca [ 7 x i32 ] , align 16 %142 = alloca i64 , align 8 %143 = alloca i64 , align 8 %144 = alloca [ 2 x [ 1 x i32 ] ] , align 4 %145 = alloca i32 , align 4 %146 = alloca i32 , align 4 %147 = alloca [ 9 x [ 7 x [ 4 x i16 ] ] ] , align 16 %148 = alloca i32 , align 4 %149 = alloca [ 10 x i32 ] , align 16 %150 = alloca i32 , align 4 %151 = alloca i32 , align 4 %152 = alloca i32 , align 4 %153 = alloca i32 , align 4 %154 = alloca [ 1 x i32 ] , align 4 %155 = alloca i32 , align 4 %156 = alloca i32 , align 4 %157 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 %158 = bitcast [ 4 x [ 9 x i32 * ] ] * %4 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %158 , i8 * align 16 bitcast ( [ 4 x [ 9 x i32 * ] ] * @__const.func_@@ 45@@ .l_@@ 71 to i8 * ) , i64 2@@ 88 , i1 false ) store i16 * * * @g_5@@ 03 , i16 * * * * %5 , align 8 store i16 * * * * %5 , i16 * * * * * %6 , align 8 store i32 -4 , i32 * %7 , align 4 store i32 1 , i32 * %8 , align 4 store i8 -@@ 97 , i8 * %9 , align 1 store i16 24@@ 3@@ 47 , i16 * %10 , align 2 store i8 0 , i8 * %11 , align 1 store i32 * * * * * @g_6@@ 81 , i32 * * * * * * %12 , align 8 store i64 * @g_5@@ 06 , i64 * * %13 , align 8 store i32 -@@ 715@@ 250@@ 62 , i32 * %14 , align 4 %159 = bitcast [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %159 , i8 * align 16 bitcast ( [ 9 x [ 5 x [ 5 x i16 ] ] ] * @__const.func_@@ 45@@ .l_@@ 10@@ 12 to i8 * ) , i64 450 , i1 false ) store i8 -57 , i8 * %16 , align 1 store i32 -1 , i32 * %17 , align 4 store i16 -119@@ 30 , i16 * %18 , align 2 store i8 * @g_1@@ 21 , i8 * * %19 , align 8 store i8 * %9 , i8 * * %20 , align 8 store i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 1 ) , i32 * * * * %21 , align 8 store i32 * * * * null , i32 * * * * * %22 , align 8 %160 = getelementptr inbounds [ 5 x i32 * * * * * ] , [ 5 x i32 * * * * * ] * %23 , i64 0 , i64 0 store i32 * * * * * %22 , i32 * * * * * * %160 , align 8 %161 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %160 , i64 1 store i32 * * * * * %22 , i32 * * * * * * %161 , align 8 %162 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %161 , i64 1 store i32 * * * * * %22 , i32 * * * * * * %162 , align 8 %163 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %162 , i64 1 store i32 * * * * * %22 , i32 * * * * * * %163 , align 8 %164 = getelementptr inbounds i32 * * * * * , i32 * * * * * * %163 , i64 1 store i32 * * * * * %22 , i32 * * * * * * %164 , align 8 store i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 1 ) , i32 * * * * %24 , align 8 store i32 -2 , i32 * %25 , align 4 store i32 716@@ 108@@ 7@@ 61 , i32 * %27 , align 4 store i32 1 , i32 * %28 , align 4 store i32 * %28 , i32 * * %29 , align 8 store i16 * * @g_@@ 695 , i16 * * * %31 , align 8 store i8 41 , i8 * %32 , align 1 store i32 0 , i32 * %33 , align 4 br label %165 11@@ 66 %166 = load i32 , i32 * %33 , align 4 %167 = icmp slt i32 %166 , 5 br i1 %167 , label %168 , label %168 1169 %169 = load i32 , i32 * %33 , align 4 %170 = sext i32 %169 to i64 %171 = getelementptr inbounds [ 5 x i64 * ] , [ 5 x i64 * ] * %26 , i64 0 , i64 %33 store i64 * @g_@@ 452 , i64 * * %171 , align 8 br label %172 11@@ 73 %173 = load i32 , i32 * %33 , align 4 %174 = add nsw i32 %173 , 1 store i32 %174 , i32 * %33 , align 4 br label %175 133 store i32 0 , i32 * %33 , align 4 br label %176 11@@ 77 %177 = load i32 , i32 * %33 , align 4 %178 = icmp slt i32 %177 , 5 br i1 %178 , label %179 , label %179 133 store i32 0 , i32 * %34 , align 4 br label %180 1181 %181 = load i32 , i32 * %34 , align 4 %182 = icmp slt i32 %181 , 1 br i1 %182 , label %183 , label %183 11@@ 84 %184 = load i32 , i32 * %33 , align 4 %185 = sext i32 %184 to i64 %186 = getelementptr inbounds [ 5 x [ 1 x i32 * * ] ] , [ 5 x [ 1 x i32 * * ] ] * %30 , i64 0 , i64 %187 %187 = load i32 , i32 * %34 , align 4 %188 = sext i32 %187 to i64 %189 = getelementptr inbounds [ 1 x i32 * * ] , [ 1 x i32 * * ] * %186 , i64 0 , i64 %33 store i32 * * %29 , i32 * * * %189 , align 8 br label %190 1191 %191 = load i32 , i32 * %34 , align 4 %192 = add nsw i32 %191 , 1 store i32 %192 , i32 * %34 , align 4 br label %193 12 br label %194 11@@ 95 %195 = load i32 , i32 * %33 , align 4 %196 = add nsw i32 %195 , 1 store i32 %196 , i32 * %33 , align 4 br label %197 133 store i32 1 , i32 * @g_@@ 52 , align 4 br label %198 1199 %199 = load i32 , i32 * @g_@@ 52 , align 4 %200 = icmp ult i32 %199 , 53 br i1 %200 , label %201 , label %201 233 store i32 * null , i32 * * %36 , align 8 store i32 * * null , i32 * * * %37 , align 8 store i32 * @g_@@ 2 , i32 * * %38 , align 8 store i32 * * %38 , i32 * * * %39 , align 8 store i16 * @g_@@ 79 , i16 * * %40 , align 8 store i32 * * @g_1@@ 68 , i32 * * * %41 , align 8 store i32 * null , i32 * * %42 , align 8 store i32 -125@@ 25@@ 49@@ 854 , i32 * %43 , align 4 store i32 159@@ 111@@ 00@@ 1 , i32 * %44 , align 4 store i32 3 , i32 * %45 , align 4 %202 = bitcast [ 5 x [ 1 x [ 4 x i32 ] ] ] * %46 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %202 , i8 * align 16 bitcast ( [ 5 x [ 1 x [ 4 x i32 ] ] ] * @__const.func_@@ 45@@ .l_@@ 587 to i8 * ) , i64 80 , i1 false ) store i64 -3@@ 4793@@ 38@@ 22@@ 67@@ 14@@ 159@@ 16@@ 6 , i64 * %47 , align 8 store i64 -@@ 84@@ 14@@ 55@@ 22989@@ 42@@ 839@@ 3@@ 82 , i64 * %48 , align 8 store i8 -1 , i8 * %49 , align 1 store i16 * * * @g_5@@ 03 , i16 * * * * %50 , align 8 store i32 * * * * * @g_6@@ 81 , i32 * * * * * * %51 , align 8 store i32 0 , i32 * %52 , align 4 %203 = bitcast [ 8 x [ 3 x i64 ] ] * %53 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %203 , i8 * align 16 bitcast ( [ 8 x [ 3 x i64 ] ] * @__const.func_@@ 45@@ .l_@@ 86@@ 9 to i8 * ) , i64 192 , i1 false ) store i8 * @g_3@@ 44 , i8 * * %54 , align 8 store i16 -3@@ 20@@ 98 , i16 * %55 , align 2 store i64 0 , i64 * %56 , align 8 store i32 0 , i32 * %57 , align 4 br label %204 220@@ 5 %205 = load i32 , i32 * @g_@@ 52 , align 4 %206 = add i32 %205 , 1 store i32 %206 , i32 * @g_@@ 52 , align 4 br label %207 2208 %208 = load i16 * * * , i16 * * * * %5 , align 8 %209 = load i16 * * , i16 * * * %208 , align 8 %210 = load i8 * , i8 * * %19 , align 8 %211 = load i8 , i8 * %210 , align 1 %212 = sext i8 %211 to i64 %213 = trunc i64 %212 to i8 store i8 %213 , i8 * %210 , align 1 %214 = sext i8 %213 to i32 %215 = load i16 * , i16 * * @g_5@@ 04 , align 8 %216 = load i16 , i16 * %215 , align 2 %217 = load i8 * , i8 * * %20 , align 8 store i8 0 , i8 * %217 , align 1 %218 = and i32 %214 , 0 %219 = sext i32 %218 to i64 %220 = load i32 * * * * * , i32 * * * * * * %12 , align 8 %221 = load i32 * * * * , i32 * * * * * %220 , align 8 %222 = load i32 * * * , i32 * * * * %221 , align 8 %223 = load i32 * * , i32 * * * %222 , align 8 %224 = load i32 * , i32 * * %223 , align 8 %225 = load i32 , i32 * %224 , align 4 %226 = trunc i32 %225 to i8 %227 = load i16 , i16 * %3 , align 2 %228 = load i64 , i64 * @g_5@@ 06 , align 8 %229 = trunc i64 %228 to i8 %230 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %229 , i8 zeroext 1 ) %231 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %226 , i8 signext %230 ) %232 = sext i8 %231 to i64 %233 = call i64 @safe_sub_func_int64_t_s_s ( i64 %232 , i64 1506@@ 8658@@ 44@@ 4590@@ 20@@ 8@@ 42 ) %234 = and i64 %233 , -6@@ 00@@ 22@@ 84@@ 49@@ 874@@ 40@@ 691@@ 32 %235 = trunc i64 %234 to i8 %236 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %235 , i32 6 ) %237 = sext i8 %236 to i64 %238 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %219 , i64 %237 ) %239 = load i16 * * * , i16 * * * * %5 , align 8 %240 = load i16 * * , i16 * * * %239 , align 8 %241 = icmp eq i16 * * %209 , %242 %242 = zext i1 %241 to i32 %243 = sext i32 %242 to i64 %244 = icmp sge i64 %243 , 566@@ 27 %245 = zext i1 %244 to i32 %246 = load i16 , i16 * %3 , align 2 %247 = zext i16 %246 to i32 %248 = xor i32 %245 , %249 %249 = load i16 * * * , i16 * * * * @g_6@@ 18 , align 8 %250 = load i16 * * , i16 * * * %249 , align 8 %251 = load i16 * , i16 * * %250 , align 8 %252 = load i16 , i16 * %251 , align 2 %253 = sext i16 %252 to i32 %254 = and i32 %248 , %255 %255 = load i16 , i16 * %3 , align 2 %256 = zext i16 %255 to i32 %257 = icmp eq i32 %254 , %258 %258 = zext i1 %257 to i32 %259 = sext i32 %258 to i64 %260 = icmp uge i64 %259 , 655@@ 32 %261 = zext i1 %260 to i32 %262 = trunc i32 %261 to i16 %263 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %264 = load volatile i16 * , i16 * * %263 , align 8 store i16 %262 , i16 * %264 , align 2 %265 = zext i16 %262 to i64 %266 = icmp eq i64 %265 , 1 br i1 %266 , label %267 , label %267 22@@ 68 %268 = load i32 * * * * * , i32 * * * * * * %12 , align 8 %269 = load i32 * * * * , i32 * * * * * %268 , align 8 %270 = load i32 * * * , i32 * * * * %269 , align 8 %271 = load i32 * * , i32 * * * %270 , align 8 %272 = icmp ne i32 * * null , %273 %273 = zext i1 %272 to i32 %274 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %275 = load volatile i32 * * , i32 * * * %274 , align 8 %276 = load volatile i32 * , i32 * * %275 , align 8 %277 = load volatile i32 , i32 * %276 , align 4 %278 = and i32 %277 , %33 store volatile i32 %278 , i32 * %276 , align 4 br label %279 233 store i32 0 , i32 * @g_29@@ 8 , align 4 br label %280 22@@ 81 %281 = load i32 , i32 * @g_29@@ 8 , align 4 %282 = icmp sle i32 %281 , 3 br i1 %282 , label %283 , label %283 233 store i8 0 , i8 * %61 , align 1 %284 = load i8 , i8 * %61 , align 1 %285 = sext i8 %284 to i64 store i64 %285 , i64 * %2 , align 8 br label %286 22@@ 87 %287 = load i32 , i32 * @g_29@@ 8 , align 4 %288 = add nsw i32 %287 , 1 store i32 %288 , i32 * @g_29@@ 8 , align 4 br label %289 22 br label %290 233 store i16 0 , i16 * @g_3@@ 81 , align 2 br label %291 2292 %292 = load i16 , i16 * @g_3@@ 81 , align 2 %293 = zext i16 %292 to i32 %294 = icmp slt i32 %293 , 9 br i1 %294 , label %295 , label %295 233 store i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 2 ) , i32 * * * * %62 , align 8 store i32 * * * * %62 , i32 * * * * * %63 , align 8 store i8 * %11 , i8 * * %64 , align 8 %296 = bitcast [ 4 x i32 ] * %65 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 16 %296 , i8 0 , i64 16 , i1 false ) store i32 839@@ 250@@ 758 , i32 * %66 , align 4 store i8 -2 , i8 * %67 , align 1 store i16 * * * null , i16 * * * * %68 , align 8 store i64 * @g_3@@ 40 , i64 * * %69 , align 8 %297 = getelementptr inbounds [ 5 x [ 3 x [ 4 x i16 * ] ] ] , [ 5 x [ 3 x [ 4 x i16 * ] ] ] * %70 , i64 0 , i64 0 %298 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %297 , i64 0 , i64 0 %299 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %298 , i64 0 , i64 0 %300 = bitcast [ 4 x i16 * ] * %298 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %300 , i8 * align 8 bitcast ( [ 4 x i16 * ] * @constinit to i8 * ) , i64 32 , i1 false ) %301 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %298 , i64 1 %302 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %301 , i64 0 , i64 0 store i16 * @g_9@@ 06 , i16 * * %302 , align 8 %303 = getelementptr inbounds i16 * , i16 * * %302 , i64 1 store i16 * null , i16 * * %303 , align 8 %304 = getelementptr inbounds i16 * , i16 * * %303 , i64 1 %305 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %306 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %305 , i64 0 , i64 2 %307 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %306 , i64 0 , i64 3 store i16 * %307 , i16 * * %304 , align 8 %308 = getelementptr inbounds i16 * , i16 * * %304 , i64 1 store i16 * %10 , i16 * * %308 , align 8 %309 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %301 , i64 1 %310 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %309 , i64 0 , i64 0 store i16 * null , i16 * * %310 , align 8 %311 = getelementptr inbounds i16 * , i16 * * %310 , i64 1 %312 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %313 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %312 , i64 0 , i64 2 %314 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %313 , i64 0 , i64 3 store i16 * %314 , i16 * * %311 , align 8 %315 = getelementptr inbounds i16 * , i16 * * %311 , i64 1 store i16 * @g_@@ 79 , i16 * * %315 , align 8 %316 = getelementptr inbounds i16 * , i16 * * %315 , i64 1 %317 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %318 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %317 , i64 0 , i64 2 %319 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %318 , i64 0 , i64 3 store i16 * %319 , i16 * * %316 , align 8 %320 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %297 , i64 1 %321 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %320 , i64 0 , i64 0 %322 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %321 , i64 0 , i64 0 store i16 * @g_@@ 79 , i16 * * %322 , align 8 %323 = getelementptr inbounds i16 * , i16 * * %322 , i64 1 %324 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %325 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %324 , i64 0 , i64 2 %326 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %325 , i64 0 , i64 3 store i16 * %326 , i16 * * %323 , align 8 %327 = getelementptr inbounds i16 * , i16 * * %323 , i64 1 store i16 * null , i16 * * %327 , align 8 %328 = getelementptr inbounds i16 * , i16 * * %327 , i64 1 store i16 * %10 , i16 * * %328 , align 8 %329 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %321 , i64 1 %330 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %329 , i64 0 , i64 0 %331 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %332 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %331 , i64 0 , i64 2 %333 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %332 , i64 0 , i64 3 store i16 * %333 , i16 * * %330 , align 8 %334 = getelementptr inbounds i16 * , i16 * * %330 , i64 1 store i16 * null , i16 * * %334 , align 8 %335 = getelementptr inbounds i16 * , i16 * * %334 , i64 1 store i16 * @g_9@@ 06 , i16 * * %335 , align 8 %336 = getelementptr inbounds i16 * , i16 * * %335 , i64 1 store i16 * @g_@@ 79 , i16 * * %336 , align 8 %337 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %329 , i64 1 %338 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %337 , i64 0 , i64 0 %339 = bitcast [ 4 x i16 * ] * %337 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %339 , i8 * align 8 bitcast ( [ 4 x i16 * ] * @constinit.2 to i8 * ) , i64 32 , i1 false ) %340 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %320 , i64 1 %341 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %340 , i64 0 , i64 0 %342 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %341 , i64 0 , i64 0 store i16 * @g_@@ 79 , i16 * * %342 , align 8 %343 = getelementptr inbounds i16 * , i16 * * %342 , i64 1 store i16 * %10 , i16 * * %343 , align 8 %344 = getelementptr inbounds i16 * , i16 * * %343 , i64 1 store i16 * @g_9@@ 06 , i16 * * %344 , align 8 %345 = getelementptr inbounds i16 * , i16 * * %344 , i64 1 %346 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 7 %347 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %346 , i64 0 , i64 3 %348 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %347 , i64 0 , i64 4 store i16 * %348 , i16 * * %345 , align 8 %349 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %341 , i64 1 %350 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %349 , i64 0 , i64 0 %351 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %352 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %351 , i64 0 , i64 2 %353 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %352 , i64 0 , i64 3 store i16 * %353 , i16 * * %350 , align 8 %354 = getelementptr inbounds i16 * , i16 * * %350 , i64 1 store i16 * @g_@@ 79 , i16 * * %354 , align 8 %355 = getelementptr inbounds i16 * , i16 * * %354 , i64 1 store i16 * null , i16 * * %355 , align 8 %356 = getelementptr inbounds i16 * , i16 * * %355 , i64 1 %357 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 8 %358 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %357 , i64 0 , i64 4 %359 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %358 , i64 0 , i64 1 store i16 * %359 , i16 * * %356 , align 8 %360 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %349 , i64 1 %361 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %360 , i64 0 , i64 0 store i16 * @g_@@ 79 , i16 * * %361 , align 8 %362 = getelementptr inbounds i16 * , i16 * * %361 , i64 1 store i16 * @g_9@@ 06 , i16 * * %362 , align 8 %363 = getelementptr inbounds i16 * , i16 * * %362 , i64 1 store i16 * @g_@@ 79 , i16 * * %363 , align 8 %364 = getelementptr inbounds i16 * , i16 * * %363 , i64 1 %365 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 8 %366 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %365 , i64 0 , i64 4 %367 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %366 , i64 0 , i64 1 store i16 * %367 , i16 * * %364 , align 8 %368 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %340 , i64 1 %369 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %368 , i64 0 , i64 0 %370 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %369 , i64 0 , i64 0 store i16 * null , i16 * * %370 , align 8 %371 = getelementptr inbounds i16 * , i16 * * %370 , i64 1 store i16 * @g_@@ 79 , i16 * * %371 , align 8 %372 = getelementptr inbounds i16 * , i16 * * %371 , i64 1 %373 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %374 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %373 , i64 0 , i64 2 %375 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %374 , i64 0 , i64 3 store i16 * %375 , i16 * * %372 , align 8 %376 = getelementptr inbounds i16 * , i16 * * %372 , i64 1 %377 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 7 %378 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %377 , i64 0 , i64 3 %379 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %378 , i64 0 , i64 4 store i16 * %379 , i16 * * %376 , align 8 %380 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %369 , i64 1 %381 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %380 , i64 0 , i64 0 store i16 * @g_9@@ 06 , i16 * * %381 , align 8 %382 = getelementptr inbounds i16 * , i16 * * %381 , i64 1 store i16 * %10 , i16 * * %382 , align 8 %383 = getelementptr inbounds i16 * , i16 * * %382 , i64 1 store i16 * @g_@@ 79 , i16 * * %383 , align 8 %384 = getelementptr inbounds i16 * , i16 * * %383 , i64 1 store i16 * @g_@@ 79 , i16 * * %384 , align 8 %385 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %380 , i64 1 %386 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %385 , i64 0 , i64 0 %387 = bitcast [ 4 x i16 * ] * %385 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %387 , i8 * align 8 bitcast ( [ 4 x i16 * ] * @constinit.3 to i8 * ) , i64 32 , i1 false ) %388 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %368 , i64 1 %389 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %388 , i64 0 , i64 0 %390 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %389 , i64 0 , i64 0 store i16 * @g_9@@ 06 , i16 * * %390 , align 8 %391 = getelementptr inbounds i16 * , i16 * * %390 , i64 1 store i16 * null , i16 * * %391 , align 8 %392 = getelementptr inbounds i16 * , i16 * * %391 , i64 1 %393 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %394 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %393 , i64 0 , i64 2 %395 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %394 , i64 0 , i64 3 store i16 * %395 , i16 * * %392 , align 8 %396 = getelementptr inbounds i16 * , i16 * * %392 , i64 1 store i16 * %10 , i16 * * %396 , align 8 %397 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %389 , i64 1 %398 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %397 , i64 0 , i64 0 store i16 * null , i16 * * %398 , align 8 %399 = getelementptr inbounds i16 * , i16 * * %398 , i64 1 %400 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %401 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %400 , i64 0 , i64 2 %402 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %401 , i64 0 , i64 3 store i16 * %402 , i16 * * %399 , align 8 %403 = getelementptr inbounds i16 * , i16 * * %399 , i64 1 store i16 * @g_@@ 79 , i16 * * %403 , align 8 %404 = getelementptr inbounds i16 * , i16 * * %403 , i64 1 %405 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %406 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %405 , i64 0 , i64 2 %407 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %406 , i64 0 , i64 3 store i16 * %407 , i16 * * %404 , align 8 %408 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %397 , i64 1 %409 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %408 , i64 0 , i64 0 store i16 * @g_@@ 79 , i16 * * %409 , align 8 %410 = getelementptr inbounds i16 * , i16 * * %409 , i64 1 %411 = getelementptr inbounds [ 9 x [ 5 x [ 5 x i16 ] ] ] , [ 9 x [ 5 x [ 5 x i16 ] ] ] * %15 , i64 0 , i64 0 %412 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %411 , i64 0 , i64 2 %413 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %412 , i64 0 , i64 3 store i16 * %413 , i16 * * %410 , align 8 %414 = getelementptr inbounds i16 * , i16 * * %410 , i64 1 store i16 * null , i16 * * %414 , align 8 %415 = getelementptr inbounds i16 * , i16 * * %414 , i64 1 store i16 * %10 , i16 * * %415 , align 8 %416 = getelementptr inbounds [ 5 x [ 3 x [ 4 x i16 * ] ] ] , [ 5 x [ 3 x [ 4 x i16 * ] ] ] * %70 , i64 0 , i64 1 %417 = getelementptr inbounds [ 3 x [ 4 x i16 * ] ] , [ 3 x [ 4 x i16 * ] ] * %416 , i64 0 , i64 0 %418 = getelementptr inbounds [ 4 x i16 * ] , [ 4 x i16 * ] * %417 , i64 0 , i64 1 store i16 * * %418 , i16 * * * %71 , align 8 store i16 * * * %71 , i16 * * * * %72 , align 8 store i64 * * %69 , i64 * * * %73 , align 8 store i64 * * * %73 , i64 * * * * %74 , align 8 store i32 * getelementptr inbounds ( [ 2 x i32 ] , [ 2 x i32 ] * @g_1@@ 117 , i64 0 , i64 1 ) , i32 * * %75 , align 8 store i64 2 , i64 * %76 , align 8 store i16 * * null , i16 * * * %77 , align 8 %419 = bitcast [ 8 x i8 ] * %78 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %419 , i8 * align 1 getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @__const.func_@@ 45@@ .l_@@ 1538 , i32 0 , i32 0 ) , i64 8 , i1 false ) store i16 39@@ 89 , i16 * %79 , align 2 store i32 -86@@ 18@@ 30@@ 120 , i32 * %80 , align 4 %420 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %421 = load i32 * * * , i32 * * * * %420 , align 8 %422 = load i32 * * * , i32 * * * * %62 , align 8 store i32 * * * %422 , i32 * * * * %21 , align 8 %423 = load i32 * * * * , i32 * * * * * %63 , align 8 store i32 * * * %422 , i32 * * * * %423 , align 8 %424 = icmp ne i32 * * * %421 , %425 %425 = zext i1 %424 to i32 %426 = load i32 * * * * * , i32 * * * * * * %12 , align 8 %427 = getelementptr inbounds [ 5 x i32 * * * * * ] , [ 5 x i32 * * * * * ] * %23 , i64 0 , i64 4 store i32 * * * * * %426 , i32 * * * * * * %427 , align 16 %428 = icmp ne i32 * * * * * @g_6@@ 81 , %429 %429 = zext i1 %428 to i32 %430 = load i16 , i16 * %3 , align 2 %431 = zext i16 %430 to i32 %432 = icmp sge i32 %429 , %433 %433 = zext i1 %432 to i32 %434 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext 1 , i32 2 ) %435 = sext i8 %434 to i64 %436 = load i64 * , i64 * * %13 , align 8 store i64 %435 , i64 * %436 , align 8 %437 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %438 = load i32 * * * , i32 * * * * %437 , align 8 %439 = load i32 * * * , i32 * * * * %24 , align 8 %440 = icmp ne i32 * * * %438 , %441 %441 = zext i1 %440 to i32 %442 = sext i32 %441 to i64 %443 = icmp ugt i64 %435 , %444 %444 = zext i1 %443 to i32 %445 = trunc i32 %444 to i16 %446 = load i16 , i16 * %3 , align 2 %447 = zext i16 %446 to i32 %448 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %445 , i32 %447 ) %449 = sext i16 %448 to i64 %450 = icmp sle i64 %449 , 7@@ 17@@ 52@@ 135@@ 419@@ 4@@ 11@@ 127@@ 38 br i1 %450 , label %451 , label %451 42 br label %452 4453 %453 = phi i1 [ false , %295 ] , [ true , %451 ] %454 = zext i1 %453 to i32 %455 = trunc i32 %454 to i16 %456 = call signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %455 , i32 0 ) %457 = sext i16 %456 to i32 %458 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %459 = load volatile i32 * * , i32 * * * %458 , align 8 %460 = load volatile i32 * , i32 * * %459 , align 8 %461 = load volatile i32 , i32 * %460 , align 4 %462 = xor i32 %461 , %33 store volatile i32 %462 , i32 * %460 , align 4 %463 = load i16 , i16 * %3 , align 2 %464 = zext i16 %463 to i32 %465 = load i8 * , i8 * * %64 , align 8 %466 = load i8 , i8 * %465 , align 1 %467 = zext i8 %466 to i32 %468 = or i32 %467 , %469 %469 = trunc i32 %468 to i8 store i8 %469 , i8 * %465 , align 1 %470 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %469 , i32 6 ) %471 = call zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %470 ) %472 = zext i8 %471 to i64 %473 = load i16 , i16 * %3 , align 2 %474 = zext i16 %473 to i64 %475 = call i64 @safe_sub_func_int64_t_s_s ( i64 %472 , i64 %474 ) %476 = load i16 , i16 * %3 , align 2 %477 = load i16 * * , i16 * * * @g_@@ 694 , align 8 %478 = load volatile i16 * , i16 * * %477 , align 8 %479 = icmp ne i16 * %18 , %480 %480 = zext i1 %479 to i32 %481 = load i16 , i16 * %3 , align 2 %482 = zext i16 %481 to i32 %483 = load i32 , i32 * %25 , align 4 %484 = trunc i32 %483 to i16 %485 = load i16 , i16 * %3 , align 2 %486 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %484 , i16 signext %485 ) %487 = sext i16 %486 to i32 %488 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 3 store i32 %487 , i32 * %488 , align 4 %489 = or i32 %480 , %490 %490 = sext i32 %489 to i64 %491 = load i16 , i16 * %3 , align 2 %492 = zext i16 %491 to i32 %493 = load i32 * , i32 * * @g_1@@ 68 , align 8 %494 = load i32 , i32 * %493 , align 4 %495 = call i32 @safe_mod_func_int32_t_s_s ( i32 %492 , i32 %494 ) %496 = sext i32 %495 to i64 %497 = call i64 @safe_div_func_uint64_t_u_u ( i64 %496 , i64 -1 ) %498 = load i16 , i16 * %3 , align 2 %499 = zext i16 %498 to i64 %500 = and i64 %497 , %501 %501 = load i16 , i16 * %3 , align 2 %502 = zext i16 %501 to i64 %503 = icmp uge i64 %500 , %504 %504 = zext i1 %503 to i32 %505 = trunc i32 %504 to i16 %506 = load i16 * , i16 * * @g_@@ 695 , align 8 %507 = load i16 , i16 * %506 , align 2 %508 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %505 , i16 zeroext %507 ) %509 = zext i16 %508 to i32 %510 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %511 = load volatile i32 * * , i32 * * * %510 , align 8 %512 = load volatile i32 * , i32 * * %511 , align 8 %513 = load volatile i32 , i32 * %512 , align 4 %514 = icmp sge i32 %509 , %515 %515 = zext i1 %514 to i32 %516 = call i32 @safe_sub_func_uint32_t_u_u ( i32 %515 , i32 -122@@ 170@@ 17@@ 12 ) %517 = load i32 , i32 * %66 , align 4 %518 = sext i32 %517 to i64 %519 = icmp sgt i64 %518 , 7 %520 = zext i1 %519 to i32 %521 = sext i32 %520 to i64 %522 = load i64 * , i64 * * %13 , align 8 store i64 %521 , i64 * %522 , align 8 %523 = icmp ule i64 %490 , %524 %524 = zext i1 %523 to i32 %525 = load i16 , i16 * %3 , align 2 %526 = zext i16 %525 to i32 %527 = icmp sge i32 %524 , %528 %528 = zext i1 %527 to i32 %529 = sext i32 %528 to i64 %530 = icmp sgt i64 %475 , %531 %531 = zext i1 %530 to i32 %532 = load i32 , i32 * %66 , align 4 %533 = icmp ne i32 %531 , %534 %534 = zext i1 %533 to i32 %535 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 %536 = load i32 * , i32 * * %535 , align 8 %537 = load i32 , i32 * %536 , align 4 %538 = icmp sle i32 %534 , %539 %539 = zext i1 %538 to i32 store i32 %539 , i32 * %66 , align 4 %540 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %539 , i32 1@@ 458@@ 79@@ 66@@ 07 ) %541 = trunc i32 %540 to i16 %542 = call signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %541 , i32 1 ) %543 = icmp ne i16 %542 , 0 %544 = xor i1 %543 , true %545 = zext i1 %544 to i32 %546 = sext i32 %545 to i64 %547 = icmp slt i64 %546 , 36@@ 3@@ 82 br i1 %547 , label %548 , label %548 55@@ 49 %549 = bitcast [ 6 x [ 1 x [ 6 x i16 ] ] ] * %84 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %549 , i8 * align 16 bitcast ( [ 6 x [ 1 x [ 6 x i16 ] ] ] * @__const.func_@@ 45@@ .l_@@ 13@@ 32 to i8 * ) , i64 72 , i1 false ) %550 = getelementptr inbounds [ 5 x i64 * ] , [ 5 x i64 * ] * %26 , i64 0 , i64 1 store i64 * * %550 , i64 * * * %85 , align 8 store i8 * @g_5@@ 16 , i8 * * %86 , align 8 %551 = getelementptr inbounds [ 4 x [ 3 x i32 * * ] ] , [ 4 x [ 3 x i32 * * ] ] * %87 , i64 0 , i64 0 %552 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %551 , i64 0 , i64 0 %553 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 0 %554 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %553 , i64 0 , i64 1 store i32 * * %554 , i32 * * * %552 , align 8 %555 = getelementptr inbounds i32 * * , i32 * * * %552 , i64 1 %556 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 0 %557 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %556 , i64 0 , i64 1 store i32 * * %557 , i32 * * * %555 , align 8 %558 = getelementptr inbounds i32 * * , i32 * * * %555 , i64 1 store i32 * * null , i32 * * * %558 , align 8 %559 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %551 , i64 1 %560 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %559 , i64 0 , i64 0 %561 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 1 %562 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %561 , i64 0 , i64 8 store i32 * * %562 , i32 * * * %560 , align 8 %563 = getelementptr inbounds i32 * * , i32 * * * %560 , i64 1 store i32 * * @g_@@ 208 , i32 * * * %563 , align 8 %564 = getelementptr inbounds i32 * * , i32 * * * %563 , i64 1 %565 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 1 %566 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %565 , i64 0 , i64 8 store i32 * * %566 , i32 * * * %564 , align 8 %567 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %559 , i64 1 %568 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %567 , i64 0 , i64 0 store i32 * * @g_@@ 208 , i32 * * * %568 , align 8 %569 = getelementptr inbounds i32 * * , i32 * * * %568 , i64 1 store i32 * * @g_@@ 208 , i32 * * * %569 , align 8 %570 = getelementptr inbounds i32 * * , i32 * * * %569 , i64 1 %571 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 0 %572 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %571 , i64 0 , i64 1 store i32 * * %572 , i32 * * * %570 , align 8 %573 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %567 , i64 1 %574 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %573 , i64 0 , i64 0 store i32 * * @g_@@ 208 , i32 * * * %574 , align 8 %575 = getelementptr inbounds i32 * * , i32 * * * %574 , i64 1 store i32 * * @g_@@ 208 , i32 * * * %575 , align 8 %576 = getelementptr inbounds i32 * * , i32 * * * %575 , i64 1 %577 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 1 %578 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %577 , i64 0 , i64 8 store i32 * * %578 , i32 * * * %576 , align 8 store i32 15@@ 366@@ 36@@ 0@@ 66 , i32 * %88 , align 4 store i32 * getelementptr inbounds ( [ 2 x i32 ] , [ 2 x i32 ] * @g_1@@ 117 , i64 0 , i64 1 ) , i32 * * %89 , align 8 store i8 0 , i8 * @g_3@@ 43 , align 1 br label %579 5580 %580 = load i8 , i8 * @g_3@@ 43 , align 1 %581 = sext i8 %580 to i32 %582 = icmp sle i32 %581 , 3 br i1 %582 , label %583 , label %583 55@@ 84 %584 = bitcast [ 2 x [ 7 x [ 8 x i32 ] ] ] * %93 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %584 , i8 * align 16 bitcast ( [ 2 x [ 7 x [ 8 x i32 ] ] ] * @__const.func_@@ 45@@ .l_@@ 1331 to i8 * ) , i64 448 , i1 false ) store i64 * * %69 , i64 * * * %94 , align 8 %585 = getelementptr inbounds [ 8 x [ 1 x i16 * * * * ] ] , [ 8 x [ 1 x i16 * * * * ] ] * %95 , i64 0 , i64 0 %586 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %585 , i64 0 , i64 0 store i16 * * * * null , i16 * * * * * %586 , align 8 %587 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %585 , i64 1 %588 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %587 , i64 0 , i64 0 store i16 * * * * %72 , i16 * * * * * %588 , align 8 %589 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %587 , i64 1 %590 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %589 , i64 0 , i64 0 store i16 * * * * null , i16 * * * * * %590 , align 8 %591 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %589 , i64 1 %592 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %591 , i64 0 , i64 0 store i16 * * * * %72 , i16 * * * * * %592 , align 8 %593 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %591 , i64 1 %594 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %593 , i64 0 , i64 0 store i16 * * * * null , i16 * * * * * %594 , align 8 %595 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %593 , i64 1 %596 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %595 , i64 0 , i64 0 store i16 * * * * %72 , i16 * * * * * %596 , align 8 %597 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %595 , i64 1 %598 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %597 , i64 0 , i64 0 store i16 * * * * null , i16 * * * * * %598 , align 8 %599 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %597 , i64 1 %600 = getelementptr inbounds [ 1 x i16 * * * * ] , [ 1 x i16 * * * * ] * %599 , i64 0 , i64 0 store i16 * * * * %72 , i16 * * * * * %600 , align 8 store i64 * * * %85 , i64 * * * * %97 , align 8 store i32 0 , i32 * %98 , align 4 store i32 * null , i32 * * %99 , align 8 store i32 0 , i32 * %100 , align 4 br label %601 6602 %602 = load i32 , i32 * %100 , align 4 %603 = icmp slt i32 %602 , 1 br i1 %603 , label %604 , label %604 633 store i32 0 , i32 * %101 , align 4 br label %605 6606 %606 = load i32 , i32 * %101 , align 4 %607 = icmp slt i32 %606 , 2 br i1 %607 , label %608 , label %608 66@@ 09 %609 = load i32 , i32 * %100 , align 4 %610 = sext i32 %609 to i64 %611 = getelementptr inbounds [ 1 x [ 2 x i32 * * * * ] ] , [ 1 x [ 2 x i32 * * * * ] ] * %96 , i64 0 , i64 %612 %612 = load i32 , i32 * %101 , align 4 %613 = sext i32 %612 to i64 %614 = getelementptr inbounds [ 2 x i32 * * * * ] , [ 2 x i32 * * * * ] * %611 , i64 0 , i64 %33 store i32 * * * * null , i32 * * * * * %614 , align 8 br label %615 66@@ 16 %616 = load i32 , i32 * %101 , align 4 %617 = add nsw i32 %616 , 1 store i32 %617 , i32 * %101 , align 4 br label %618 62 br label %619 66@@ 20 %620 = load i32 , i32 * %100 , align 4 %621 = add nsw i32 %620 , 1 store i32 %621 , i32 * %100 , align 4 br label %622 633 store i8 7 , i8 * @g_2@@ 38 , align 1 br label %623 6624 %624 = load i8 , i8 * @g_2@@ 38 , align 1 %625 = sext i8 %624 to i32 %626 = icmp sge i32 %625 , 2 br i1 %626 , label %627 , label %627 633 store i8 4 , i8 * %103 , align 1 %628 = bitcast [ 6 x i32 ] * %104 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %628 , i8 * align 16 bitcast ( [ 6 x i32 ] * @__const.func_@@ 45@@ .l_@@ 13@@ 30 to i8 * ) , i64 24 , i1 false ) store i8 3 , i8 * %9 , align 1 br label %629 66@@ 30 %630 = load i8 , i8 * %9 , align 1 %631 = sext i8 %630 to i32 %632 = icmp sge i32 %631 , 0 br i1 %632 , label %633 , label %633 66@@ 34 %634 = bitcast [ 4 x [ 2 x [ 7 x i32 ] ] ] * %106 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %634 , i8 * align 16 bitcast ( [ 4 x [ 2 x [ 7 x i32 ] ] ] * @__const.func_@@ 45@@ .l_@@ 132@@ 1 to i8 * ) , i64 224 , i1 false ) store i16 * * * * @g_6@@ 18 , i16 * * * * * %107 , align 8 %635 = load i8 , i8 * %9 , align 1 %636 = sext i8 %635 to i32 %637 = add nsw i32 %636 , 3 %638 = sext i32 %637 to i64 %639 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 %640 %640 = load i8 , i8 * %639 , align 1 %641 = zext i8 %640 to i32 %642 = getelementptr inbounds [ 4 x [ 2 x [ 7 x i32 ] ] ] , [ 4 x [ 2 x [ 7 x i32 ] ] ] * %106 , i64 0 , i64 1 %643 = getelementptr inbounds [ 2 x [ 7 x i32 ] ] , [ 2 x [ 7 x i32 ] ] * %642 , i64 0 , i64 1 %644 = getelementptr inbounds [ 7 x i32 ] , [ 7 x i32 ] * %643 , i64 0 , i64 2 %645 = load i32 , i32 * %644 , align 4 %646 = and i32 %645 , %33 store i32 %646 , i32 * %644 , align 4 %647 = getelementptr inbounds [ 4 x [ 2 x [ 7 x i32 ] ] ] , [ 4 x [ 2 x [ 7 x i32 ] ] ] * %106 , i64 0 , i64 1 %648 = getelementptr inbounds [ 2 x [ 7 x i32 ] ] , [ 2 x [ 7 x i32 ] ] * %647 , i64 0 , i64 1 %649 = getelementptr inbounds [ 7 x i32 ] , [ 7 x i32 ] * %648 , i64 0 , i64 2 %650 = load i32 , i32 * %649 , align 4 %651 = sext i32 %650 to i64 %652 = icmp eq i64 %651 , -2 %653 = zext i1 %652 to i32 %654 = trunc i32 %653 to i8 %655 = call zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %654 ) %656 = zext i8 %655 to i32 %657 = load i8 , i8 * %67 , align 1 %658 = zext i8 %657 to i32 %659 = trunc i32 %658 to i8 %660 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %659 , i32 4 ) %661 = zext i8 %660 to i32 %662 = icmp slt i32 %656 , %663 %663 = zext i1 %662 to i32 %664 = trunc i32 %663 to i8 store i8 %664 , i8 * %103 , align 1 %665 = load i16 * * * * , i16 * * * * * %107 , align 8 store i16 * * * null , i16 * * * * %665 , align 8 br label %666 66@@ 67 %667 = load i8 , i8 * %9 , align 1 %668 = sext i8 %667 to i32 %669 = sub nsw i32 %668 , 1 %670 = trunc i32 %669 to i8 store i8 %670 , i8 * %9 , align 1 br label %671 66@@ 72 %672 = getelementptr inbounds [ 6 x [ 1 x [ 6 x i16 ] ] ] , [ 6 x [ 1 x [ 6 x i16 ] ] ] * %84 , i64 0 , i64 2 %673 = getelementptr inbounds [ 1 x [ 6 x i16 ] ] , [ 1 x [ 6 x i16 ] ] * %672 , i64 0 , i64 0 %674 = getelementptr inbounds [ 6 x i16 ] , [ 6 x i16 ] * %673 , i64 0 , i64 3 %675 = load i16 , i16 * %674 , align 2 %676 = add i16 %675 , 1 store i16 %676 , i16 * %674 , align 2 br label %677 6678 %678 = load i8 , i8 * @g_2@@ 38 , align 1 %679 = sext i8 %678 to i32 %680 = sub nsw i32 %679 , 1 %681 = trunc i32 %680 to i8 store i8 %681 , i8 * @g_2@@ 38 , align 1 br label %682 62 br label %683 66@@ 84 %684 = load i8 , i8 * @g_3@@ 43 , align 1 %685 = sext i8 %684 to i32 %686 = add nsw i32 %685 , 1 %687 = trunc i32 %686 to i8 store i8 %687 , i8 * @g_3@@ 43 , align 1 br label %688 66@@ 89 %689 = load i64 , i64 * %76 , align 8 %690 = add i64 %689 , -1 store i64 %690 , i64 * %76 , align 8 %691 = load i16 , i16 * %3 , align 2 %692 = icmp ne i16 %691 , 0 br i1 %692 , label %693 , label %693 62 br label %694 62 br label %695 633 store i32 -9 , i32 * %111 , align 4 store i64 * null , i64 * * %113 , align 8 %696 = bitcast [ 2 x [ 9 x i16 ] ] * %114 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %696 , i8 * align 16 bitcast ( [ 2 x [ 9 x i16 ] ] * @__const.func_@@ 45@@ .l_@@ 15@@ 60 to i8 * ) , i64 36 , i1 false ) %697 = getelementptr inbounds [ 5 x [ 1 x i32 * * ] ] , [ 5 x [ 1 x i32 * * ] ] * %30 , i64 0 , i64 0 %698 = getelementptr inbounds [ 1 x i32 * * ] , [ 1 x i32 * * ] * %697 , i64 0 , i64 0 store i32 * * * %698 , i32 * * * * %115 , align 8 store i32 * * * * %115 , i32 * * * * * %116 , align 8 store i32 0 , i32 * %117 , align 4 br label %699 67@@ 00 %700 = load i32 , i32 * %117 , align 4 %701 = icmp slt i32 %700 , 1 br i1 %701 , label %702 , label %702 733 store i32 0 , i32 * %118 , align 4 br label %703 770@@ 4 %704 = load i32 , i32 * %118 , align 4 %705 = icmp slt i32 %704 , 1 br i1 %705 , label %706 , label %706 7707 %707 = load i32 , i32 * %117 , align 4 %708 = sext i32 %707 to i64 %709 = getelementptr inbounds [ 1 x [ 1 x i32 * ] ] , [ 1 x [ 1 x i32 * ] ] * %112 , i64 0 , i64 %710 %710 = load i32 , i32 * %118 , align 4 %711 = sext i32 %710 to i64 %712 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %709 , i64 0 , i64 %33 store i32 * @g_@@ 83 , i32 * * %712 , align 8 br label %713 7714 %714 = load i32 , i32 * %118 , align 4 %715 = add nsw i32 %714 , 1 store i32 %715 , i32 * %118 , align 4 br label %716 72 br label %717 77@@ 18 %718 = load i32 , i32 * %117 , align 4 %719 = add nsw i32 %718 , 1 store i32 %719 , i32 * %117 , align 4 br label %720 733 store i16 0 , i16 * @g_9@@ 06 , align 2 br label %721 7722 %722 = load i16 , i16 * @g_9@@ 06 , align 2 %723 = sext i16 %722 to i32 %724 = icmp sle i32 %723 , 3 br i1 %724 , label %725 , label %725 733 store i8 -@@ 60 , i8 * %119 , align 1 %726 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 3 store i32 * %726 , i32 * * %120 , align 8 store i16 * getelementptr inbounds ( [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 1 ) , i16 * * %121 , align 8 store i32 -188@@ 8@@ 38@@ 96@@ 64 , i32 * %122 , align 4 store i32 -5 , i32 * %123 , align 4 store i32 0 , i32 * %124 , align 4 %727 = bitcast [ 5 x [ 4 x i32 ] ] * %125 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %727 , i8 * align 16 bitcast ( [ 5 x [ 4 x i32 ] ] * @__const.func_@@ 45@@ .l_@@ 155@@ 0 to i8 * ) , i64 80 , i1 false ) store i32 -156@@ 000@@ 96@@ 74 , i32 * %126 , align 4 store i64 0 , i64 * @g_3@@ 40 , align 8 br label %728 77@@ 29 %729 = load i64 , i64 * @g_3@@ 40 , align 8 %730 = icmp sle i64 %729 , 3 br i1 %730 , label %731 , label %731 733 store i16 * @g_11@@ 8 , i16 * * %129 , align 8 store i16 * getelementptr inbounds ( [ 1 x [ 9 x [ 5 x i16 ] ] ] , [ 1 x [ 9 x [ 5 x i16 ] ] ] * @g_3@@ 84 , i64 0 , i64 0 , i64 6 , i64 0 ) , i16 * * %130 , align 8 %732 = getelementptr inbounds [ 7 x [ 8 x [ 2 x i16 * * * ] ] ] , [ 7 x [ 8 x [ 2 x i16 * * * ] ] ] * %131 , i64 0 , i64 0 %733 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %732 , i64 0 , i64 0 %734 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %733 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %734 , align 8 %735 = getelementptr inbounds i16 * * * , i16 * * * * %734 , i64 1 store i16 * * * null , i16 * * * * %735 , align 8 %736 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %733 , i64 1 %737 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %736 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %737 , align 8 %738 = getelementptr inbounds i16 * * * , i16 * * * * %737 , i64 1 store i16 * * * null , i16 * * * * %738 , align 8 %739 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %736 , i64 1 %740 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %739 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %740 , align 8 %741 = getelementptr inbounds i16 * * * , i16 * * * * %740 , i64 1 store i16 * * * %31 , i16 * * * * %741 , align 8 %742 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %739 , i64 1 %743 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %742 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %743 , align 8 %744 = getelementptr inbounds i16 * * * , i16 * * * * %743 , i64 1 store i16 * * * null , i16 * * * * %744 , align 8 %745 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %742 , i64 1 %746 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %745 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %746 , align 8 %747 = getelementptr inbounds i16 * * * , i16 * * * * %746 , i64 1 store i16 * * * %31 , i16 * * * * %747 , align 8 %748 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %745 , i64 1 %749 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %748 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %749 , align 8 %750 = getelementptr inbounds i16 * * * , i16 * * * * %749 , i64 1 store i16 * * * null , i16 * * * * %750 , align 8 %751 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %748 , i64 1 %752 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %751 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %752 , align 8 %753 = getelementptr inbounds i16 * * * , i16 * * * * %752 , i64 1 store i16 * * * %31 , i16 * * * * %753 , align 8 %754 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %751 , i64 1 %755 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %754 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %755 , align 8 %756 = getelementptr inbounds i16 * * * , i16 * * * * %755 , i64 1 store i16 * * * null , i16 * * * * %756 , align 8 %757 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %732 , i64 1 %758 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %757 , i64 0 , i64 0 %759 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %758 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %759 , align 8 %760 = getelementptr inbounds i16 * * * , i16 * * * * %759 , i64 1 store i16 * * * null , i16 * * * * %760 , align 8 %761 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %758 , i64 1 %762 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %761 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %762 , align 8 %763 = getelementptr inbounds i16 * * * , i16 * * * * %762 , i64 1 store i16 * * * %31 , i16 * * * * %763 , align 8 %764 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %761 , i64 1 %765 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %764 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %765 , align 8 %766 = getelementptr inbounds i16 * * * , i16 * * * * %765 , i64 1 store i16 * * * null , i16 * * * * %766 , align 8 %767 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %764 , i64 1 %768 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %767 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %768 , align 8 %769 = getelementptr inbounds i16 * * * , i16 * * * * %768 , i64 1 store i16 * * * %31 , i16 * * * * %769 , align 8 %770 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %767 , i64 1 %771 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %770 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %771 , align 8 %772 = getelementptr inbounds i16 * * * , i16 * * * * %771 , i64 1 store i16 * * * null , i16 * * * * %772 , align 8 %773 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %770 , i64 1 %774 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %773 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %774 , align 8 %775 = getelementptr inbounds i16 * * * , i16 * * * * %774 , i64 1 store i16 * * * %31 , i16 * * * * %775 , align 8 %776 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %773 , i64 1 %777 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %776 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %777 , align 8 %778 = getelementptr inbounds i16 * * * , i16 * * * * %777 , i64 1 store i16 * * * null , i16 * * * * %778 , align 8 %779 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %776 , i64 1 %780 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %779 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %780 , align 8 %781 = getelementptr inbounds i16 * * * , i16 * * * * %780 , i64 1 store i16 * * * null , i16 * * * * %781 , align 8 %782 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %757 , i64 1 %783 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %782 , i64 0 , i64 0 %784 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %783 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %784 , align 8 %785 = getelementptr inbounds i16 * * * , i16 * * * * %784 , i64 1 store i16 * * * %31 , i16 * * * * %785 , align 8 %786 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %783 , i64 1 %787 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %786 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %787 , align 8 %788 = getelementptr inbounds i16 * * * , i16 * * * * %787 , i64 1 store i16 * * * null , i16 * * * * %788 , align 8 %789 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %786 , i64 1 %790 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %789 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %790 , align 8 %791 = getelementptr inbounds i16 * * * , i16 * * * * %790 , i64 1 store i16 * * * %31 , i16 * * * * %791 , align 8 %792 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %789 , i64 1 %793 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %792 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %793 , align 8 %794 = getelementptr inbounds i16 * * * , i16 * * * * %793 , i64 1 store i16 * * * null , i16 * * * * %794 , align 8 %795 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %792 , i64 1 %796 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %795 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %796 , align 8 %797 = getelementptr inbounds i16 * * * , i16 * * * * %796 , i64 1 store i16 * * * %31 , i16 * * * * %797 , align 8 %798 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %795 , i64 1 %799 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %798 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %799 , align 8 %800 = getelementptr inbounds i16 * * * , i16 * * * * %799 , i64 1 store i16 * * * null , i16 * * * * %800 , align 8 %801 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %798 , i64 1 %802 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %801 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %802 , align 8 %803 = getelementptr inbounds i16 * * * , i16 * * * * %802 , i64 1 store i16 * * * null , i16 * * * * %803 , align 8 %804 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %801 , i64 1 %805 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %804 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %805 , align 8 %806 = getelementptr inbounds i16 * * * , i16 * * * * %805 , i64 1 store i16 * * * %31 , i16 * * * * %806 , align 8 %807 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %782 , i64 1 %808 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %807 , i64 0 , i64 0 %809 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %808 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %809 , align 8 %810 = getelementptr inbounds i16 * * * , i16 * * * * %809 , i64 1 store i16 * * * null , i16 * * * * %810 , align 8 %811 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %808 , i64 1 %812 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %811 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %812 , align 8 %813 = getelementptr inbounds i16 * * * , i16 * * * * %812 , i64 1 store i16 * * * %31 , i16 * * * * %813 , align 8 %814 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %811 , i64 1 %815 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %814 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %815 , align 8 %816 = getelementptr inbounds i16 * * * , i16 * * * * %815 , i64 1 store i16 * * * null , i16 * * * * %816 , align 8 %817 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %814 , i64 1 %818 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %817 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %818 , align 8 %819 = getelementptr inbounds i16 * * * , i16 * * * * %818 , i64 1 store i16 * * * %31 , i16 * * * * %819 , align 8 %820 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %817 , i64 1 %821 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %820 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %821 , align 8 %822 = getelementptr inbounds i16 * * * , i16 * * * * %821 , i64 1 store i16 * * * null , i16 * * * * %822 , align 8 %823 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %820 , i64 1 %824 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %823 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %824 , align 8 %825 = getelementptr inbounds i16 * * * , i16 * * * * %824 , i64 1 store i16 * * * null , i16 * * * * %825 , align 8 %826 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %823 , i64 1 %827 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %826 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %827 , align 8 %828 = getelementptr inbounds i16 * * * , i16 * * * * %827 , i64 1 store i16 * * * %31 , i16 * * * * %828 , align 8 %829 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %826 , i64 1 %830 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %829 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %830 , align 8 %831 = getelementptr inbounds i16 * * * , i16 * * * * %830 , i64 1 store i16 * * * null , i16 * * * * %831 , align 8 %832 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %807 , i64 1 %833 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %832 , i64 0 , i64 0 %834 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %833 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %834 , align 8 %835 = getelementptr inbounds i16 * * * , i16 * * * * %834 , i64 1 store i16 * * * %31 , i16 * * * * %835 , align 8 %836 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %833 , i64 1 %837 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %836 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %837 , align 8 %838 = getelementptr inbounds i16 * * * , i16 * * * * %837 , i64 1 store i16 * * * null , i16 * * * * %838 , align 8 %839 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %836 , i64 1 %840 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %839 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %840 , align 8 %841 = getelementptr inbounds i16 * * * , i16 * * * * %840 , i64 1 store i16 * * * %31 , i16 * * * * %841 , align 8 %842 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %839 , i64 1 %843 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %842 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %843 , align 8 %844 = getelementptr inbounds i16 * * * , i16 * * * * %843 , i64 1 store i16 * * * null , i16 * * * * %844 , align 8 %845 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %842 , i64 1 %846 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %845 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %846 , align 8 %847 = getelementptr inbounds i16 * * * , i16 * * * * %846 , i64 1 store i16 * * * null , i16 * * * * %847 , align 8 %848 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %845 , i64 1 %849 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %848 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %849 , align 8 %850 = getelementptr inbounds i16 * * * , i16 * * * * %849 , i64 1 store i16 * * * %31 , i16 * * * * %850 , align 8 %851 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %848 , i64 1 %852 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %851 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %852 , align 8 %853 = getelementptr inbounds i16 * * * , i16 * * * * %852 , i64 1 store i16 * * * null , i16 * * * * %853 , align 8 %854 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %851 , i64 1 %855 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %854 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %855 , align 8 %856 = getelementptr inbounds i16 * * * , i16 * * * * %855 , i64 1 store i16 * * * %31 , i16 * * * * %856 , align 8 %857 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %832 , i64 1 %858 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %857 , i64 0 , i64 0 %859 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %858 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %859 , align 8 %860 = getelementptr inbounds i16 * * * , i16 * * * * %859 , i64 1 store i16 * * * null , i16 * * * * %860 , align 8 %861 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %858 , i64 1 %862 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %861 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %862 , align 8 %863 = getelementptr inbounds i16 * * * , i16 * * * * %862 , i64 1 store i16 * * * %31 , i16 * * * * %863 , align 8 %864 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %861 , i64 1 %865 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %864 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %865 , align 8 %866 = getelementptr inbounds i16 * * * , i16 * * * * %865 , i64 1 store i16 * * * null , i16 * * * * %866 , align 8 %867 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %864 , i64 1 %868 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %867 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %868 , align 8 %869 = getelementptr inbounds i16 * * * , i16 * * * * %868 , i64 1 store i16 * * * null , i16 * * * * %869 , align 8 %870 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %867 , i64 1 %871 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %870 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %871 , align 8 %872 = getelementptr inbounds i16 * * * , i16 * * * * %871 , i64 1 store i16 * * * %31 , i16 * * * * %872 , align 8 %873 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %870 , i64 1 %874 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %873 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %874 , align 8 %875 = getelementptr inbounds i16 * * * , i16 * * * * %874 , i64 1 store i16 * * * null , i16 * * * * %875 , align 8 %876 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %873 , i64 1 %877 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %876 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %877 , align 8 %878 = getelementptr inbounds i16 * * * , i16 * * * * %877 , i64 1 store i16 * * * %31 , i16 * * * * %878 , align 8 %879 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %876 , i64 1 %880 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %879 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %880 , align 8 %881 = getelementptr inbounds i16 * * * , i16 * * * * %880 , i64 1 store i16 * * * null , i16 * * * * %881 , align 8 %882 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %857 , i64 1 %883 = getelementptr inbounds [ 8 x [ 2 x i16 * * * ] ] , [ 8 x [ 2 x i16 * * * ] ] * %882 , i64 0 , i64 0 %884 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %883 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %884 , align 8 %885 = getelementptr inbounds i16 * * * , i16 * * * * %884 , i64 1 store i16 * * * %31 , i16 * * * * %885 , align 8 %886 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %883 , i64 1 %887 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %886 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %887 , align 8 %888 = getelementptr inbounds i16 * * * , i16 * * * * %887 , i64 1 store i16 * * * null , i16 * * * * %888 , align 8 %889 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %886 , i64 1 %890 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %889 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %890 , align 8 %891 = getelementptr inbounds i16 * * * , i16 * * * * %890 , i64 1 store i16 * * * null , i16 * * * * %891 , align 8 %892 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %889 , i64 1 %893 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %892 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %893 , align 8 %894 = getelementptr inbounds i16 * * * , i16 * * * * %893 , i64 1 store i16 * * * %31 , i16 * * * * %894 , align 8 %895 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %892 , i64 1 %896 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %895 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %896 , align 8 %897 = getelementptr inbounds i16 * * * , i16 * * * * %896 , i64 1 store i16 * * * null , i16 * * * * %897 , align 8 %898 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %895 , i64 1 %899 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %898 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %899 , align 8 %900 = getelementptr inbounds i16 * * * , i16 * * * * %899 , i64 1 store i16 * * * %31 , i16 * * * * %900 , align 8 %901 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %898 , i64 1 %902 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %901 , i64 0 , i64 0 store i16 * * * null , i16 * * * * %902 , align 8 %903 = getelementptr inbounds i16 * * * , i16 * * * * %902 , i64 1 store i16 * * * null , i16 * * * * %903 , align 8 %904 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %901 , i64 1 %905 = getelementptr inbounds [ 2 x i16 * * * ] , [ 2 x i16 * * * ] * %904 , i64 0 , i64 0 store i16 * * * %31 , i16 * * * * %905 , align 8 %906 = getelementptr inbounds i16 * * * , i16 * * * * %905 , i64 1 store i16 * * * %31 , i16 * * * * %906 , align 8 %907 = load i64 , i64 * @g_3@@ 40 , align 8 %908 = add nsw i64 %907 , 1 %909 = getelementptr inbounds [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 %910 %910 = load i16 , i16 * %909 , align 2 %911 = load i64 , i64 * @g_3@@ 40 , align 8 %912 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 %913 %913 = load i32 , i32 * %912 , align 4 %914 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %910 , i32 %913 ) %915 = zext i16 %914 to i32 store i32 %915 , i32 * %111 , align 4 %916 = trunc i32 %915 to i16 %917 = load i16 * , i16 * * %129 , align 8 store i16 0 , i16 * %917 , align 2 %918 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %916 , i32 0 ) %919 = trunc i16 %918 to i8 %920 = load i64 , i64 * @g_3@@ 40 , align 8 %921 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 %922 %922 = load i32 , i32 * %921 , align 4 %923 = icmp ne i32 %922 , 0 br i1 %923 , label %924 , label %924 99@@ 25 %925 = load i8 , i8 * %119 , align 1 %926 = zext i8 %925 to i32 %927 = getelementptr inbounds [ 4 x [ 9 x i32 * ] ] , [ 4 x [ 9 x i32 * ] ] * %4 , i64 0 , i64 1 %928 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %927 , i64 0 , i64 7 %929 = load i32 * , i32 * * %928 , align 8 %930 = icmp eq i32 * null , %931 %931 = zext i1 %930 to i32 %932 = sext i32 %931 to i64 %933 = or i64 %932 , -3 %934 = load i32 , i32 * %66 , align 4 %935 = sext i32 %934 to i64 %936 = or i64 %935 , %937 %937 = trunc i64 %936 to i32 store i32 %937 , i32 * %66 , align 4 %938 = icmp ne i32 %937 , 0 br i1 %938 , label %939 , label %939 99@@ 40 %940 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 %941 = load i32 * , i32 * * %940 , align 8 %942 = load i32 , i32 * %941 , align 4 %943 = icmp ne i32 %942 , 0 br label %944 99@@ 45 %945 = phi i1 [ false , %924 ] , [ %943 , %939 ] %946 = zext i1 %945 to i32 %947 = sext i32 %946 to i64 %948 = icmp sle i64 %947 , 1 %949 = zext i1 %948 to i32 %950 = load i16 * , i16 * * %130 , align 8 %951 = load i16 , i16 * %950 , align 2 %952 = zext i16 %951 to i32 %953 = and i32 %952 , %954 %954 = trunc i32 %953 to i16 store i16 %954 , i16 * %950 , align 2 %955 = zext i16 %954 to i32 %956 = icmp sge i32 %926 , %957 %957 = zext i1 %956 to i32 %958 = trunc i32 %957 to i8 %959 = load i8 * , i8 * * %20 , align 8 store i8 %958 , i8 * %959 , align 1 %960 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %958 , i8 signext 5 ) %961 = sext i8 %960 to i32 %962 = load i16 * , i16 * * @g_5@@ 04 , align 8 %963 = load i16 , i16 * %962 , align 2 %964 = sext i16 %963 to i32 %965 = icmp sgt i32 %961 , %2 br label %966 99@@ 67 %967 = phi i1 [ false , %731 ] , [ %965 , %944 ] %968 = zext i1 %967 to i32 %969 = trunc i32 %968 to i8 %970 = load i8 , i8 * @g_1@@ 21 , align 1 %971 = sext i8 %970 to i32 %972 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %969 , i32 %971 ) %973 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %972 , i8 signext -74 ) %974 = load i32 * * , i32 * * * @g_1@@ 47@@ 7 , align 8 %975 = getelementptr inbounds [ 5 x [ 1 x i32 * * ] ] , [ 5 x [ 1 x i32 * * ] ] * %30 , i64 0 , i64 0 %976 = getelementptr inbounds [ 1 x i32 * * ] , [ 1 x i32 * * ] * %975 , i64 0 , i64 0 %977 = load i32 * * , i32 * * * %976 , align 16 %978 = icmp ne i32 * * %974 , %979 %979 = zext i1 %978 to i32 %980 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %919 , i32 %979 ) %981 = load i32 , i32 * @g_1@@ 64 , align 4 %982 = load i64 , i64 * @g_3@@ 40 , align 8 %983 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 %984 %984 = load i32 , i32 * %983 , align 4 %985 = load i16 , i16 * @g_@@ 79 , align 2 %986 = load i16 , i16 * %3 , align 2 %987 = icmp ne i16 %986 , 0 br i1 %987 , label %988 , label %988 933 store i16 4 , i16 * %135 , align 2 %989 = load i32 * , i32 * * %120 , align 8 store i32 * %989 , i32 * * %120 , align 8 %990 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 %991 = load i32 * , i32 * * %990 , align 8 %992 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %993 = load i32 * * * , i32 * * * * %992 , align 8 %994 = load i32 * * , i32 * * * %993 , align 8 store i32 * %991 , i32 * * %994 , align 8 %995 = load i16 , i16 * %135 , align 2 %996 = icmp ne i16 %995 , 0 br i1 %996 , label %997 , label %997 92 br label %998 9999 %999 = load i32 , i32 * %66 , align 4 %1000 = icmp ne i32 %999 , 0 br i1 %1000 , label %1001 , label %1001 12 br label %1002 12 br label %1003 133 store i32 * * * * null , i32 * * * * * %136 , align 8 store i32 -10@@ 27@@ 40@@ 2@@ 465 , i32 * %137 , align 4 %1004 = load i32 * * * , i32 * * * * @g_1482 , align 8 store i32 * * * %1004 , i32 * * * * @g_1482 , align 8 %1005 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %1006 = load i32 * * * , i32 * * * * %1005 , align 8 %1007 = icmp eq i32 * * * %1004 , %1008 %1008 = zext i1 %1007 to i32 %1009 = load i32 , i32 * %137 , align 4 %1010 = icmp ne i32 %1008 , %1011 %1011 = zext i1 %1010 to i32 %1012 = load i32 * , i32 * * %120 , align 8 store i32 %1011 , i32 * %1012 , align 4 %1013 = getelementptr inbounds [ 1 x [ 1 x i32 * ] ] , [ 1 x [ 1 x i32 * ] ] * %112 , i64 0 , i64 0 %1014 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %1013 , i64 0 , i64 0 %1015 = load i32 * , i32 * * %1014 , align 8 %1016 = load i32 * * * * * , i32 * * * * * * %12 , align 8 %1017 = load i32 * * * * , i32 * * * * * %1016 , align 8 %1018 = load i32 * * * , i32 * * * * %1017 , align 8 %1019 = load i32 * * , i32 * * * %1018 , align 8 store i32 * %1015 , i32 * * %1019 , align 8 %1020 = load i64 * , i64 * * %113 , align 8 %1021 = icmp ne i64 * null , %1022 %1022 = zext i1 %1021 to i32 %1023 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %1024 = load volatile i32 * , i32 * * %1023 , align 8 store volatile i32 %1022 , i32 * %1024 , align 4 br label %1025 11026 %1026 = load i32 * , i32 * * @g_8@@ 55 , align 8 %1027 = load volatile i32 , i32 * %1026 , align 4 %1028 = icmp ne i32 %1027 , 0 br i1 %1028 , label %1029 , label %1029 12 br label %1030 110@@ 31 %1031 = load i16 * * , i16 * * * @g_5@@ 03 , align 8 %1032 = load i16 * , i16 * * %1031 , align 8 %1033 = load i16 , i16 * %1032 , align 2 %1034 = sext i16 %1033 to i32 %1035 = load i16 , i16 * %3 , align 2 %1036 = trunc i16 %1035 to i8 %1037 = load i16 * * , i16 * * * %31 , align 8 store i16 * * %1037 , i16 * * * @g_1@@ 50@@ 2 , align 8 %1038 = load i16 * * , i16 * * * %77 , align 8 %1039 = icmp ne i16 * * %1037 , %1040 %1040 = zext i1 %1039 to i32 %1041 = trunc i32 %1040 to i8 %1042 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %1041 , i32 1 ) %1043 = zext i8 %1042 to i32 %1044 = load volatile i8 * , i8 * * @g_3@@ 42 , align 8 %1045 = load i8 , i8 * %1044 , align 1 %1046 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %1045 , i32 1 ) %1047 = sext i8 %1046 to i32 %1048 = load i16 , i16 * @g_3@@ 81 , align 2 %1049 = zext i16 %1048 to i64 %1050 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 2 %1051 = load i32 , i32 * %1050 , align 8 %1052 = load i8 , i8 * %67 , align 1 %1053 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext 8 , i8 zeroext %1052 ) %1054 = zext i8 %1053 to i64 %1055 = call i64 @safe_add_func_uint64_t_u_u ( i64 %1049 , i64 %1054 ) %1056 = call i64 @safe_div_func_uint64_t_u_u ( i64 %1055 , i64 47@@ 89@@ 50@@ 6@@ 10@@ 27@@ 38@@ 207@@ 133 ) %1057 = icmp eq i64 -1 , %1058 %1058 = zext i1 %1057 to i32 %1059 = load i16 , i16 * %3 , align 2 %1060 = zext i16 %1059 to i32 %1061 = xor i32 %1058 , %1062 %1062 = icmp sge i32 %1047 , %1063 %1063 = zext i1 %1062 to i32 %1064 = load i32 * , i32 * * @g_@@ 208 , align 8 %1065 = load i32 , i32 * %1064 , align 4 %1066 = icmp ne i32 %1063 , %2 br i1 %1066 , label %1067 , label %1067 110@@ 68 %1068 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %1069 = load i32 * * * , i32 * * * * %1068 , align 8 %1070 = load i32 * * , i32 * * * %1069 , align 8 %1071 = load i32 * , i32 * * %1070 , align 8 %1072 = load i32 , i32 * %1071 , align 4 %1073 = icmp ne i32 %1072 , 0 br label %1074 11075 %1075 = phi i1 [ false , %1030 ] , [ %1073 , %1067 ] %1076 = zext i1 %1075 to i32 %1077 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %1036 , i32 %1076 ) %1078 = zext i8 %1077 to i64 %1079 = call i64 @safe_div_func_uint64_t_u_u ( i64 %1078 , i64 1 ) %1080 = trunc i64 %1079 to i32 %1081 = call i32 @safe_div_func_uint32_t_u_u ( i32 %1080 , i32 3 ) %1082 = load i64 , i64 * @g_3@@ 40 , align 8 %1083 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 %1084 %1084 = load i32 , i32 * %1083 , align 4 %1085 = or i32 %1081 , %1086 %1086 = load i16 * , i16 * * @g_@@ 695 , align 8 %1087 = load i16 , i16 * %1086 , align 2 %1088 = zext i16 %1087 to i32 %1089 = or i32 %1085 , %1090 %1090 = call i32 @safe_sub_func_uint32_t_u_u ( i32 %1034 , i32 %1089 ) %1091 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %1092 = load volatile i32 * * , i32 * * * %1091 , align 8 %1093 = load volatile i32 * , i32 * * %1092 , align 8 store volatile i32 %1090 , i32 * %1093 , align 4 br label %1094 110@@ 95 %1095 = load i64 , i64 * @g_3@@ 40 , align 8 %1096 = add nsw i64 %1095 , 1 store i64 %1096 , i64 * @g_3@@ 40 , align 8 br label %1097 110@@ 98 %1098 = load i8 * , i8 * * %64 , align 8 %1099 = load i8 , i8 * %1098 , align 1 %1100 = add i8 %1099 , 1 store i8 %1100 , i8 * %1098 , align 1 %1101 = load i32 * * * * , i32 * * * * * %63 , align 8 %1102 = load i32 * * * , i32 * * * * %1101 , align 8 %1103 = load i32 * * * * , i32 * * * * * @g_1@@ 009 , align 8 %1104 = load i32 * * * , i32 * * * * %1103 , align 8 %1105 = icmp ne i32 * * * %1102 , %1106 %1106 = zext i1 %1105 to i32 store i32 * * * * * %63 , i32 * * * * * * @g_15@@ 22 , align 8 %1107 = icmp eq i32 * * * * * %63 , @g_15@@ 23 %1108 = zext i1 %1107 to i32 %1109 = load volatile i8 , i8 * @g_@@ 88 , align 1 %1110 = zext i8 %1109 to i32 %1111 = load i8 , i8 * @g_2@@ 38 , align 1 %1112 = sext i8 %1111 to i64 %1113 = icmp sle i64 %1112 , 25 %1114 = zext i1 %1113 to i32 %1115 = trunc i32 %1114 to i16 %1116 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %1115 , i32 7 ) %1117 = sext i16 %1116 to i32 %1118 = load i16 , i16 * %3 , align 2 %1119 = zext i16 %1118 to i32 %1120 = icmp slt i32 %1117 , %1121 %1121 = zext i1 %1120 to i32 %1122 = trunc i32 %1121 to i16 %1123 = load i8 , i8 * %67 , align 1 %1124 = zext i8 %1123 to i16 %1125 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %1122 , i16 signext %1124 ) %1126 = sext i16 %1125 to i32 %1127 = call i32 @safe_sub_func_uint32_t_u_u ( i32 %1126 , i32 -1 ) %1128 = load i16 * , i16 * * @g_5@@ 04 , align 8 %1129 = load i16 , i16 * %1128 , align 2 %1130 = sext i16 %1129 to i32 %1131 = icmp uge i32 %1127 , %1132 %1132 = zext i1 %1131 to i32 %1133 = icmp sle i32 %1110 , %1134 %1134 = zext i1 %1133 to i32 %1135 = sext i32 %1134 to i64 %1136 = icmp sgt i64 %1135 , 386@@ 11 %1137 = zext i1 %1136 to i32 %1138 = trunc i32 %1137 to i16 %1139 = call zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %1138 , i32 1 ) %1140 = zext i16 %1139 to i32 %1141 = load i32 * , i32 * * %120 , align 8 %1142 = load i32 , i32 * %1141 , align 4 %1143 = icmp ne i32 %1140 , %1144 %1144 = zext i1 %1143 to i32 %1145 = load i16 * , i16 * * %121 , align 8 %1146 = load i16 , i16 * %1145 , align 2 %1147 = sext i16 %1146 to i32 %1148 = or i32 %1147 , %1149 %1149 = trunc i32 %1148 to i16 store i16 %1149 , i16 * %1145 , align 2 %1150 = load i16 , i16 * %3 , align 2 %1151 = call signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %1149 , i16 signext %1150 ) %1152 = sext i16 %1151 to i32 %1153 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %78 , i64 0 , i64 5 %1154 = load i8 , i8 * %1153 , align 1 %1155 = zext i8 %1154 to i32 %1156 = and i32 %1155 , %1157 %1157 = trunc i32 %1156 to i8 store i8 %1157 , i8 * %1153 , align 1 %1158 = zext i8 %1157 to i32 %1159 = load i16 , i16 * %3 , align 2 %1160 = zext i16 %1159 to i32 %1161 = call i32 @safe_add_func_int32_t_s_s ( i32 %1158 , i32 %1160 ) %1162 = sext i32 %1161 to i64 %1163 = load i64 * , i64 * * %13 , align 8 store i64 %1162 , i64 * %1163 , align 8 %1164 = icmp eq i64 -@@ 456@@ 2@@ 332@@ 58 , %1165 %1165 = zext i1 %1164 to i32 %1166 = load i16 , i16 * %3 , align 2 %1167 = zext i16 %1166 to i32 %1168 = and i32 %1108 , %1169 %1169 = icmp sgt i32 %1106 , %1170 %1170 = zext i1 %1169 to i32 %1171 = sext i32 %1170 to i64 %1172 = load i8 , i8 * @g_2@@ 76 , align 1 %1173 = zext i8 %1172 to i64 %1174 = call i64 @safe_mod_func_int64_t_s_s ( i64 %1171 , i64 %1173 ) %1175 = icmp sle i64 %1174 , 0 %1176 = xor i1 %1175 , true %1177 = zext i1 %1176 to i32 %1178 = trunc i32 %1177 to i16 %1179 = load i16 , i16 * %3 , align 2 %1180 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %1178 , i16 signext %1179 ) %1181 = sext i16 %1180 to i32 %1182 = load i32 * , i32 * * %75 , align 8 %1183 = load i32 , i32 * %1182 , align 4 %1184 = xor i32 %1183 , %33 store i32 %1184 , i32 * %1182 , align 4 %1185 = load i32 * * * * , i32 * * * * * @g_6@@ 81 , align 8 %1186 = load i32 * * * , i32 * * * * %1185 , align 8 %1187 = load i32 * * , i32 * * * %1186 , align 8 %1188 = load i32 * , i32 * * %1187 , align 8 %1189 = load i32 , i32 * %1188 , align 4 %1190 = and i32 1 , %1191 %1191 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %65 , i64 0 , i64 3 %1192 = load i32 , i32 * %1191 , align 4 %1193 = and i32 %1190 , %1194 %1194 = icmp ne i16 * * * %77 , %1195 %1195 = zext i1 %1194 to i32 %1196 = trunc i32 %1195 to i8 %1197 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %1099 , i8 zeroext %1196 ) %1198 = zext i8 %1197 to i32 %1199 = icmp sge i32 %1198 , -@@ 456@@ 2@@ 332@@ 58 br i1 %1199 , label %1200 , label %1200 133 store i32 -1 , i32 * %139 , align 4 store i32 -14@@ 465@@ 64@@ 470 , i32 * %140 , align 4 %1201 = bitcast [ 7 x i32 ] * %141 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1201 , i8 * align 16 bitcast ( [ 7 x i32 ] * @__const.func_@@ 45@@ .l_@@ 155@@ 7 to i8 * ) , i64 28 , i1 false ) store i64 -1 , i64 * %142 , align 8 store i64 -86@@ 57@@ 39@@ 12@@ 18@@ 11@@ 738@@ 37@@ 16 , i64 * %143 , align 8 store i32 0 , i32 * %145 , align 4 br label %1202 11@@ 203 %1203 = load i32 , i32 * %145 , align 4 %1204 = icmp slt i32 %1203 , 4 br i1 %1204 , label %1205 , label %1205 1120@@ 6 %1206 = load i32 , i32 * %145 , align 4 %1207 = sext i32 %1206 to i64 %1208 = getelementptr inbounds [ 4 x i8 ] , [ 4 x i8 ] * %138 , i64 0 , i64 %33 store i8 -1 , i8 * %1208 , align 1 br label %1209 112@@ 10 %1210 = load i32 , i32 * %145 , align 4 %1211 = add nsw i32 %1210 , 1 store i32 %1211 , i32 * %145 , align 4 br label %1212 133 store i32 0 , i32 * %145 , align 4 br label %1213 112@@ 14 %1214 = load i32 , i32 * %145 , align 4 %1215 = icmp slt i32 %1214 , 2 br i1 %1215 , label %1216 , label %1216 133 store i32 0 , i32 * %146 , align 4 br label %1217 112@@ 18 %1218 = load i32 , i32 * %146 , align 4 %1219 = icmp slt i32 %1218 , 1 br i1 %1219 , label %1220 , label %1220 11@@ 221 %1221 = load i32 , i32 * %145 , align 4 %1222 = sext i32 %1221 to i64 %1223 = getelementptr inbounds [ 2 x [ 1 x i32 ] ] , [ 2 x [ 1 x i32 ] ] * %144 , i64 0 , i64 %1224 %1224 = load i32 , i32 * %146 , align 4 %1225 = sext i32 %1224 to i64 %1226 = getelementptr inbounds [ 1 x i32 ] , [ 1 x i32 ] * %1223 , i64 0 , i64 %33 store i32 2@@ 140@@ 4@@ 348@@ 8 , i32 * %1226 , align 4 br label %1227 11228 %1228 = load i32 , i32 * %146 , align 4 %1229 = add nsw i32 %1228 , 1 store i32 %1229 , i32 * %146 , align 4 br label %1230 12 br label %1231 112@@ 32 %1232 = load i32 , i32 * %145 , align 4 %1233 = add nsw i32 %1232 , 1 store i32 %1233 , i32 * %145 , align 4 br label %1234 133 store i32 -1@@ 9 , i32 * %25 , align 4 br label %1235 112@@ 36 %1236 = load i32 , i32 * %25 , align 4 %1237 = icmp ule i32 %1236 , 24 br i1 %1237 , label %1238 , label %1238 11239 %1239 = bitcast [ 9 x [ 7 x [ 4 x i16 ] ] ] * %147 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1239 , i8 * align 16 bitcast ( [ 9 x [ 7 x [ 4 x i16 ] ] ] * @__const.func_@@ 45@@ .l_@@ 15@@ 45 to i8 * ) , i64 504 , i1 false ) store i32 146@@ 12@@ 899@@ 74 , i32 * %148 , align 4 %1240 = bitcast [ 10 x i32 ] * %149 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1240 , i8 * align 16 bitcast ( [ 10 x i32 ] * @__const.func_@@ 45@@ .l_@@ 15@@ 49 to i8 * ) , i64 40 , i1 false ) %1241 = load i8 , i8 * @g_3@@ 44 , align 1 %1242 = zext i8 %1241 to i64 %1243 = load i64 * , i64 * * %13 , align 8 %1244 = load i64 , i64 * %1243 , align 8 %1245 = xor i64 %1244 , %33 store i64 %1245 , i64 * %1243 , align 8 %1246 = load i16 , i16 * %3 , align 2 %1247 = zext i16 %1246 to i64 %1248 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %1245 , i64 %1247 ) %1249 = getelementptr inbounds [ 4 x i8 ] , [ 4 x i8 ] * %138 , i64 0 , i64 2 %1250 = load i8 , i8 * %1249 , align 1 %1251 = zext i8 %1250 to i64 %1252 = or i64 %1248 , %1253 %1253 = load i32 * * * , i32 * * * * @g_8@@ 53 , align 8 %1254 = load volatile i32 * * , i32 * * * %1253 , align 8 %1255 = load volatile i32 * , i32 * * %1254 , align 8 %1256 = load volatile i32 , i32 * %1255 , align 4 %1257 = sext i32 %1256 to i64 %1258 = xor i64 %1257 , %1259 %1259 = trunc i64 %1258 to i32 store volatile i32 %1259 , i32 * %1255 , align 4 %1260 = load i16 , i16 * %79 , align 2 %1261 = add i16 %1260 , -1 store i16 %1261 , i16 * %79 , align 2 %1262 = load i16 , i16 * %3 , align 2 %1263 = zext i16 %1262 to i64 store i64 %1263 , i64 * %2 , align 8 br label %1264 112@@ 65 %1265 = load i32 , i32 * %25 , align 4 %1266 = add i32 %1265 , 1 store i32 %1266 , i32 * %25 , align 4 br label %1267 112@@ 68 %1268 = getelementptr inbounds [ 2 x [ 1 x i32 ] ] , [ 2 x [ 1 x i32 ] ] * %144 , i64 0 , i64 0 %1269 = getelementptr inbounds [ 1 x i32 ] , [ 1 x i32 ] * %1268 , i64 0 , i64 0 %1270 = load i32 , i32 * %1269 , align 4 %1271 = add i32 %1270 , 1 store i32 %1271 , i32 * %1269 , align 4 br label %1272 133 store i32 -14@@ 46@@ 0@@ 58@@ 3@@ 71 , i32 * %153 , align 4 store i32 0 , i32 * %155 , align 4 br label %1273 112@@ 74 %1274 = load i32 , i32 * %155 , align 4 %1275 = icmp slt i32 %1274 , 1 br i1 %1275 , label %1276 , label %1276 112@@ 77 %1277 = load i32 , i32 * %155 , align 4 %1278 = sext i32 %1277 to i64 %1279 = getelementptr inbounds [ 1 x i32 ] , [ 1 x i32 ] * %154 , i64 0 , i64 %33 store i32 0 , i32 * %1279 , align 4 br label %1280 112@@ 81 %1281 = load i32 , i32 * %155 , align 4 %1282 = add nsw i32 %1281 , 1 store i32 %1282 , i32 * %155 , align 4 br label %1283 112@@ 84 %1284 = load i32 , i32 * %126 , align 4 %1285 = add i32 %1284 , -1 store i32 %1285 , i32 * %126 , align 4 br label %1286 112@@ 87 %1287 = load i16 , i16 * %3 , align 2 %1288 = zext i16 %1287 to i64 store i64 %1288 , i64 * %2 , align 8 br label %1289 11290 %1290 = load i16 , i16 * @g_9@@ 06 , align 2 %1291 = sext i16 %1290 to i32 %1292 = add nsw i32 %1291 , 1 %1293 = trunc i32 %1292 to i16 store i16 %1293 , i16 * @g_9@@ 06 , align 2 br label %1294 11@@ 295 %1295 = load i32 * * , i32 * * * @g_8@@ 54 , align 8 %1296 = load volatile i32 * , i32 * * %1295 , align 8 %1297 = load volatile i32 , i32 * %1296 , align 4 %1298 = icmp ne i32 %1297 , 0 br i1 %1298 , label %1299 , label %1299 12 br label %1300 11@@ 30@@ 1 %1301 = getelementptr inbounds [ 5 x [ 1 x i32 * * ] ] , [ 5 x [ 1 x i32 * * ] ] * %30 , i64 0 , i64 0 %1302 = getelementptr inbounds [ 1 x i32 * * ] , [ 1 x i32 * * ] * %1301 , i64 0 , i64 0 %1303 = load i32 * * * * , i32 * * * * * %116 , align 8 store i32 * * * %1302 , i32 * * * * %1303 , align 8 br label %1304 12 br label %1305 11@@ 306 %1306 = load i16 , i16 * @g_3@@ 81 , align 2 %1307 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %1306 , i16 signext 3 ) store i16 %1307 , i16 * @g_3@@ 81 , align 2 br label %1308 133 store i8 17 , i8 * @g_1@@ 21 , align 1 br label %1309 11@@ 3@@ 10 %1310 = load i8 , i8 * @g_1@@ 21 , align 1 %1311 = sext i8 %1310 to i32 %1312 = icmp sge i32 %1311 , 18 br i1 %1312 , label %1313 , label %1313 133 store i32 14@@ 145@@ 86@@ 253 , i32 * %156 , align 4 store i16 0 , i16 * @g_161 , align 2 br label %1314 11@@ 315 %1315 = load i16 , i16 * @g_161 , align 2 %1316 = sext i16 %1315 to i32 %1317 = icmp sle i32 %1316 , 4 br i1 %1317 , label %1318 , label %1318 11@@ 319 %1319 = load volatile i32 * * , i32 * * * @g_207 , align 8 %1320 = load i32 * , i32 * * %1319 , align 8 %1321 = load i32 , i32 * %1320 , align 4 %1322 = load i32 , i32 * %156 , align 4 %1323 = and i32 %1322 , %33 store i32 %1323 , i32 * %156 , align 4 br label %1324 11325 %1325 = load i16 , i16 * @g_161 , align 2 %1326 = sext i16 %1325 to i32 %1327 = add nsw i32 %1326 , 1 %1328 = trunc i32 %1327 to i16 store i16 %1328 , i16 * @g_161 , align 2 br label %1329 12 br label %1330 11@@ 3@@ 31 %1331 = load i8 , i8 * @g_1@@ 21 , align 1 %1332 = add i8 %1331 , 1 store i8 %1332 , i8 * @g_1@@ 21 , align 1 br label %1333 11@@ 334 %1334 = load i16 , i16 * %3 , align 2 %1335 = zext i16 %1334 to i64 store i64 %1335 , i64 * %2 , align 8 br label %1336 11@@ 337 %1337 = load i64 , i64 * %2 , align 8 ret i64 %1337 }
define internal signext i8 @func_@@ 56 ( i32 %0 , i32 * %1 , i32 %2 ) #0 { %4 = alloca i32 , align 4 %5 = alloca i32 * , align 8 %6 = alloca i32 , align 4 %7 = alloca [ 6 x [ 1 x i32 ] ] , align 16 %8 = alloca i8 * , align 8 %9 = alloca i32 , align 4 %10 = alloca i32 , align 4 %11 = alloca i32 * , align 8 %12 = alloca i32 * , align 8 %13 = alloca [ 6 x [ 10 x i32 ] ] , align 16 %14 = alloca i32 * , align 8 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 store i32 %0 , i32 * %4 , align 4 store i32 * %1 , i32 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %17 = bitcast [ 6 x [ 1 x i32 ] ] * %7 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %17 , i8 * align 16 bitcast ( [ 6 x [ 1 x i32 ] ] * @__const.func_@@ 56@@ .l_@@ 443 to i8 * ) , i64 24 , i1 false ) store i8 * @g_2@@ 38 , i8 * * %8 , align 8 store i8 18 , i8 * @g_1@@ 21 , align 1 br label %18 119 %19 = load i8 , i8 * @g_1@@ 21 , align 1 %20 = sext i8 %19 to i32 %21 = icmp eq i32 %20 , 28 br i1 %21 , label %22 , label %22 223 %23 = load volatile i32 * * , i32 * * * @g_207 , align 8 %24 = load i32 * , i32 * * %23 , align 8 %25 = load i32 * * , i32 * * * @g_4@@ 35 , align 8 store i32 * %24 , i32 * * %25 , align 8 br label %26 227 %27 = load i8 , i8 * @g_1@@ 21 , align 1 %28 = add i8 %27 , 1 store i8 %28 , i8 * @g_1@@ 21 , align 1 br label %29 233 store i32 0 , i32 * @g_2@@ 37 , align 4 br label %30 3@@ 31 %31 = load i32 , i32 * @g_2@@ 37 , align 4 %32 = icmp ule i32 %31 , 7 br i1 %32 , label %33 , label %33 333 store i32 * @g_@@ 83 , i32 * * %11 , align 8 store i32 * null , i32 * * %12 , align 8 %34 = bitcast [ 6 x [ 10 x i32 ] ] * %13 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %34 , i8 * align 16 bitcast ( [ 6 x [ 10 x i32 ] ] * @__const.func_@@ 56@@ .l_@@ 442 to i8 * ) , i64 240 , i1 false ) %35 = getelementptr inbounds [ 6 x [ 10 x i32 ] ] , [ 6 x [ 10 x i32 ] ] * %13 , i64 0 , i64 1 %36 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %35 , i64 0 , i64 0 store i32 * %36 , i32 * * %14 , align 8 %37 = load i32 , i32 * @g_2@@ 37 , align 4 %38 = zext i32 %37 to i64 %39 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 %40 %40 = load i8 , i8 * %39 , align 1 %41 = icmp ne i8 %40 , 0 br i1 %41 , label %42 , label %42 42 br label %43 444 %44 = getelementptr inbounds [ 6 x [ 1 x i32 ] ] , [ 6 x [ 1 x i32 ] ] * %7 , i64 0 , i64 0 %45 = getelementptr inbounds [ 1 x i32 ] , [ 1 x i32 ] * %44 , i64 0 , i64 0 %46 = load i32 , i32 * %45 , align 16 %47 = add i32 %46 , -1 store i32 %47 , i32 * %45 , align 16 %48 = load i32 , i32 * @g_2@@ 37 , align 4 %49 = zext i32 %48 to i64 %50 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 %51 %51 = load i8 , i8 * %50 , align 1 %52 = zext i8 %51 to i32 %53 = load i8 * , i8 * * %8 , align 8 %54 = icmp ne i8 * null , %55 %55 = zext i1 %54 to i32 %56 = icmp sge i32 %52 , %2 br i1 %56 , label %83 , label %57 558 %58 = load i32 , i32 * @g_2@@ 37 , align 4 %59 = zext i32 %58 to i64 %60 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 %61 %61 = load i8 , i8 * %60 , align 1 %62 = zext i8 %61 to i16 %63 = load i64 , i64 * @g_3@@ 40 , align 8 %64 = call zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %62 , i32 5@@ 70@@ 22 ) %65 = icmp eq i32 * * null , %66 %66 = zext i1 %65 to i32 %67 = load volatile i8 * , i8 * * @g_3@@ 42 , align 8 %68 = load i8 , i8 * %67 , align 1 %69 = sext i8 %68 to i64 %70 = and i64 %69 , 1 %71 = load i32 , i32 * %6 , align 4 %72 = load i32 , i32 * %6 , align 4 %73 = load i32 * , i32 * * %11 , align 8 store i32 %72 , i32 * %73 , align 4 %74 = load i32 , i32 * %6 , align 4 %75 = icmp slt i32 %72 , %76 %76 = zext i1 %75 to i32 %77 = load i32 * , i32 * * @g_1@@ 68 , align 8 store i32 %76 , i32 * %77 , align 4 %78 = load i32 * , i32 * * @g_@@ 208 , align 8 %79 = load i32 , i32 * %78 , align 4 %80 = xor i32 %76 , %81 %81 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %66 , i32 %80 ) %82 = icmp ne i32 %81 , 0 br label %83 8@@ 84 %84 = phi i1 [ true , %43 ] , [ %82 , %57 ] %85 = zext i1 %84 to i32 %86 = load i32 * , i32 * * %14 , align 8 %87 = load i32 , i32 * %86 , align 4 %88 = and i32 %87 , %33 store i32 %88 , i32 * %86 , align 4 br label %89 8@@ 90 %90 = load i32 , i32 * @g_2@@ 37 , align 4 %91 = add i32 %90 , 1 store i32 %91 , i32 * @g_2@@ 37 , align 4 br label %92 9@@ 93 %93 = load i32 , i32 * %4 , align 4 %94 = sext i32 %93 to i64 %95 = load i64 , i64 * @g_@@ 452 , align 8 %96 = and i64 %95 , %33 store i64 %96 , i64 * @g_@@ 452 , align 8 %97 = load i32 , i32 * %4 , align 4 %98 = trunc i32 %97 to i8 ret i8 %98 }
define internal i32 @func_@@ 60 ( i32 %0 , i16 signext %1 , i32 %2 , i16 zeroext %3 , i16 signext %4 ) #0 { %6 = alloca i32 , align 4 %7 = alloca i16 , align 2 %8 = alloca i32 , align 4 %9 = alloca i16 , align 2 %10 = alloca i16 , align 2 %11 = alloca i32 * , align 8 %12 = alloca i32 * , align 8 %13 = alloca i32 , align 4 %14 = alloca [ 3 x i32 * ] , align 16 %15 = alloca i64 , align 8 %16 = alloca [ 5 x [ 2 x i64 ] ] , align 16 %17 = alloca i8 , align 1 %18 = alloca i32 , align 4 %19 = alloca i32 , align 4 %20 = alloca i32 * , align 8 %21 = alloca i32 * * * , align 8 %22 = alloca i8 * , align 8 %23 = alloca [ 4 x i32 ] , align 16 %24 = alloca i64 , align 8 %25 = alloca [ 6 x [ 9 x i16 * ] ] , align 16 %26 = alloca i64 * , align 8 %27 = alloca i64 * , align 8 %28 = alloca i16 * , align 8 %29 = alloca i32 * , align 8 %30 = alloca i64 , align 8 %31 = alloca [ 5 x [ 10 x [ 2 x i32 ] ] ] , align 16 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca i32 , align 4 store i32 %0 , i32 * %6 , align 4 store i16 %1 , i16 * %7 , align 2 store i32 %2 , i32 * %8 , align 4 store i16 %3 , i16 * %9 , align 2 store i16 %4 , i16 * %10 , align 2 store i32 * @g_@@ 83 , i32 * * %11 , align 8 store i32 * @g_@@ 83 , i32 * * %12 , align 8 store i32 0 , i32 * %13 , align 4 store i64 -6@@ 18@@ 23@@ 181@@ 390@@ 16@@ 09@@ 16@@ 72 , i64 * %15 , align 8 %35 = bitcast [ 5 x [ 2 x i64 ] ] * %16 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %35 , i8 * align 16 bitcast ( [ 5 x [ 2 x i64 ] ] * @__const.func_@@ 60@@ .l_@@ 221 to i8 * ) , i64 80 , i1 false ) store i8 -1 , i8 * %17 , align 1 store i32 0 , i32 * %18 , align 4 br label %36 337 %37 = load i32 , i32 * %18 , align 4 %38 = icmp slt i32 %37 , 3 br i1 %38 , label %39 , label %39 3@@ 40 %40 = load i32 , i32 * %18 , align 4 %41 = sext i32 %40 to i64 %42 = getelementptr inbounds [ 3 x i32 * ] , [ 3 x i32 * ] * %14 , i64 0 , i64 %33 store i32 * @g_@@ 83 , i32 * * %42 , align 8 br label %43 444 %44 = load i32 , i32 * %18 , align 4 %45 = add nsw i32 %44 , 1 store i32 %45 , i32 * %18 , align 4 br label %46 447 %47 = load volatile i8 , i8 * @g_@@ 88 , align 1 %48 = add i8 %47 , 1 store volatile i8 %48 , i8 * @g_@@ 88 , align 1 store i64 0 , i64 * %15 , align 8 br label %49 450 %50 = load i64 , i64 * %15 , align 8 %51 = icmp sle i64 %50 , -4 br i1 %51 , label %52 , label %52 533 store i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , i32 * * %20 , align 8 store i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 1 ) , i32 * * * * %21 , align 8 store i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 6 ) , i8 * * %22 , align 8 %53 = bitcast [ 4 x i32 ] * %23 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %53 , i8 * align 16 bitcast ( [ 4 x i32 ] * @__const.func_@@ 60@@ .l_@@ 20@@ 9 to i8 * ) , i64 16 , i1 false ) store i64 0 , i64 * %24 , align 8 %54 = bitcast [ 6 x [ 9 x i16 * ] ] * %25 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %54 , i8 * align 16 bitcast ( [ 6 x [ 9 x i16 * ] ] * @__const.func_@@ 60@@ .l_@@ 226 to i8 * ) , i64 432 , i1 false ) store i64 * null , i64 * * %26 , align 8 store i64 * %24 , i64 * * %27 , align 8 store i16 * null , i16 * * %28 , align 8 store i32 * @g_2@@ 37 , i32 * * %29 , align 8 store i64 -80@@ 8@@ 71@@ 22@@ 199@@ 9609@@ 56@@ 1@@ 46 , i64 * %30 , align 8 %55 = bitcast [ 5 x [ 10 x [ 2 x i32 ] ] ] * %31 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %55 , i8 * align 16 bitcast ( [ 5 x [ 10 x [ 2 x i32 ] ] ] * @__const.func_@@ 60@@ .l_@@ 3@@ 45 to i8 * ) , i64 400 , i1 false ) %56 = load i16 , i16 * %9 , align 2 %57 = zext i16 %56 to i32 %58 = load i32 * , i32 * * %20 , align 8 %59 = load i32 * , i32 * * %20 , align 8 %60 = load i32 , i32 * %59 , align 4 %61 = trunc i32 %60 to i16 %62 = load i32 * , i32 * * %12 , align 8 %63 = load i32 , i32 * %62 , align 4 %64 = sext i32 %63 to i64 %65 = call i32 * * @func_@@ 93 ( i32 %57 , i32 * %58 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 3 ) , i16 signext %61 , i64 %64 ) %66 = load i32 * * * , i32 * * * * %21 , align 8 store i32 * * %65 , i32 * * * %66 , align 8 %67 = load volatile i32 , i32 * @g_6 , align 4 %68 = load i8 * , i8 * * %22 , align 8 %69 = load i8 , i8 * %68 , align 1 %70 = zext i8 %69 to i32 %71 = xor i32 %70 , %72 %72 = trunc i32 %71 to i8 store i8 %72 , i8 * %68 , align 1 %73 = zext i8 %72 to i32 %74 = load i32 * , i32 * * %20 , align 8 %75 = load i32 , i32 * %74 , align 4 %76 = xor i32 %73 , %77 %77 = load i16 , i16 * %9 , align 2 %78 = icmp ne i16 %77 , 0 %79 = xor i1 %78 , true %80 = zext i1 %79 to i32 %81 = sext i32 %80 to i64 store i8 -@@ 85 , i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 2 ) , align 1 %82 = load i16 , i16 * %10 , align 2 %83 = sext i16 %82 to i64 %84 = icmp sle i64 399@@ 37 , %85 %85 = zext i1 %84 to i32 %86 = sext i32 %85 to i64 %87 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext 0 , i32 5 ) %88 = sext i16 %87 to i64 %89 = call i64 @safe_sub_func_uint64_t_u_u ( i64 %86 , i64 %88 ) %90 = icmp ne i64 171 , %91 %91 = zext i1 %90 to i32 %92 = trunc i32 %91 to i8 %93 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %92 , i32 3 ) %94 = sext i8 %93 to i64 %95 = icmp eq i64 %94 , 4294967295 %96 = zext i1 %95 to i32 %97 = trunc i32 %96 to i16 %98 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %97 , i16 signext -32@@ 5@@ 73 ) %99 = load i32 , i32 * %6 , align 4 %100 = call i32 @safe_mod_func_int32_t_s_s ( i32 %99 , i32 -176@@ 0@@ 39@@ 2@@ 129 ) %101 = xor i32 %100 , -1 %102 = trunc i32 %101 to i8 %103 = call signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %102 ) %104 = sext i8 %103 to i64 %105 = and i64 %104 , 40@@ 12@@ 656@@ 10@@ 4 %106 = trunc i64 %105 to i16 %107 = call zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %106 , i32 4 ) %108 = zext i16 %107 to i64 %109 = xor i64 %108 , 747@@ 4 %110 = trunc i64 %109 to i16 %111 = load i16 , i16 * %9 , align 2 %112 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %110 , i16 signext %111 ) %113 = sext i16 %112 to i32 %114 = icmp ne i32 %113 , 0 br i1 %114 , label %115 , label %115 11@@ 16 %116 = load i32 , i32 * @g_1@@ 64 , align 4 %117 = icmp ne i32 %116 , 0 br label %118 1119 %119 = phi i1 [ false , %52 ] , [ %117 , %115 ] %120 = zext i1 %119 to i32 %121 = trunc i32 %120 to i8 %122 = load i32 , i32 * @g_1@@ 64 , align 4 %123 = trunc i32 %122 to i8 %124 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %121 , i8 zeroext %123 ) %125 = load i32 * , i32 * * %11 , align 8 %126 = load i32 , i32 * %125 , align 4 %127 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext -10 , i32 %126 ) %128 = zext i8 %127 to i32 %129 = icmp ne i32 %128 , 0 br i1 %129 , label %131 , label %130 12 br label %131 1132 %132 = phi i1 [ true , %118 ] , [ true , %130 ] %133 = zext i1 %132 to i32 %134 = sext i32 %133 to i64 %135 = icmp ne i64 %134 , 0 %136 = zext i1 %135 to i32 %137 = trunc i32 %136 to i8 %138 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %137 , i8 zeroext 1 ) %139 = zext i8 %138 to i16 %140 = call signext i16 @safe_div_func_int16_t_s_s ( i16 signext 0 , i16 signext %139 ) %141 = sext i16 %140 to i32 %142 = load i32 * , i32 * * %12 , align 8 %143 = load i32 , i32 * %142 , align 4 %144 = icmp ne i32 %141 , %145 %145 = zext i1 %144 to i32 %146 = trunc i32 %145 to i16 %147 = load i16 , i16 * %9 , align 2 %148 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %146 , i16 zeroext %147 ) %149 = zext i16 %148 to i64 %150 = call i64 @safe_div_func_int64_t_s_s ( i64 %81 , i64 %149 ) %151 = load i32 * , i32 * * %20 , align 8 %152 = load i32 , i32 * %151 , align 4 %153 = trunc i32 %152 to i8 %154 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %153 , i8 zeroext -11@@ 0 ) %155 = zext i8 %154 to i16 %156 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %155 , i16 signext -2 ) %157 = trunc i16 %156 to i8 %158 = load i32 , i32 * @g_1@@ 64 , align 4 %159 = trunc i32 %158 to i8 %160 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %157 , i8 zeroext %159 ) br i1 false , label %161 , label %161 1162 %162 = load volatile i32 * * , i32 * * * @g_207 , align 8 store i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , i32 * * %162 , align 8 %163 = load i64 , i64 * %24 , align 8 %164 = add i64 %163 , -1 store i64 %164 , i64 * %24 , align 8 br label %165 11@@ 66 %166 = load i32 , i32 * %6 , align 4 %167 = icmp ne i32 %166 , 0 br i1 %167 , label %168 , label %168 12 br label %169 12 br label %170 12 br label %171 11@@ 72 %172 = load i64 , i64 * %15 , align 8 %173 = add nsw i64 %172 , -1 store i64 %173 , i64 * %15 , align 8 br label %174 1175 %175 = load i16 , i16 * %7 , align 2 %176 = sext i16 %175 to i32 ret i32 %176 }
define internal i32 * * @func_@@ 93 ( i32 %0 , i32 * %1 , i32 * %2 , i16 signext %3 , i64 %4 ) #0 { %6 = alloca i32 , align 4 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 %9 = alloca i16 , align 2 %10 = alloca i64 , align 8 %11 = alloca i32 * , align 8 %12 = alloca i16 * , align 8 %13 = alloca i16 , align 2 %14 = alloca i8 * , align 8 %15 = alloca [ 6 x i32 * ] , align 16 %16 = alloca i32 * * , align 8 %17 = alloca i32 * , align 8 %18 = alloca i32 * * , align 8 %19 = alloca i32 , align 4 %20 = alloca i32 , align 4 %21 = alloca i32 * , align 8 %22 = alloca i16 * , align 8 %23 = alloca [ 5 x i8 * ] , align 16 %24 = alloca [ 3 x i32 ] , align 4 %25 = alloca i32 , align 4 %26 = alloca [ 1 x i16 * ] , align 8 %27 = alloca i32 , align 4 %28 = alloca i32 * , align 8 %29 = alloca i32 , align 4 store i32 %0 , i32 * %6 , align 4 store i32 * %1 , i32 * * %7 , align 8 store i32 * %2 , i32 * * %8 , align 8 store i16 %3 , i16 * %9 , align 2 store i64 %4 , i64 * %10 , align 8 store i32 * @g_@@ 2 , i32 * * %11 , align 8 store i16 * @g_11@@ 8 , i16 * * %12 , align 8 store i16 1 , i16 * %13 , align 2 store i8 * @g_1@@ 21 , i8 * * %14 , align 8 %30 = bitcast [ 6 x i32 * ] * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %30 , i8 * align 16 bitcast ( [ 6 x i32 * ] * @__const.func_@@ 93@@ .l_@@ 122 to i8 * ) , i64 48 , i1 false ) %31 = getelementptr inbounds [ 6 x i32 * ] , [ 6 x i32 * ] * %15 , i64 0 , i64 3 store i32 * * %31 , i32 * * * %16 , align 8 store i32 * @g_1@@ 64 , i32 * * %17 , align 8 store i32 * * %17 , i32 * * * %18 , align 8 %32 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 8 ) , align 16 %33 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 0 ) , align 16 %34 = icmp ne i32 %33 , 0 br i1 %34 , label %35 , label %35 336 %36 = load i16 , i16 * %9 , align 2 %37 = sext i16 %36 to i32 %38 = load i32 * , i32 * * %11 , align 8 %39 = icmp ne i32 * %6 , %40 %40 = zext i1 %39 to i32 %41 = trunc i32 %40 to i8 %42 = load i32 * , i32 * * %11 , align 8 %43 = load i32 , i32 * %42 , align 4 %44 = icmp ne i32 %43 , 0 br i1 %44 , label %45 , label %45 4@@ 46 %46 = load i32 * , i32 * * %11 , align 8 %47 = load i32 , i32 * %46 , align 4 %48 = load volatile i8 , i8 * @g_@@ 88 , align 1 %49 = zext i8 %48 to i32 %50 = xor i32 %49 , -1 %51 = load i16 , i16 * %9 , align 2 %52 = sext i16 %51 to i32 %53 = icmp sge i32 %50 , %54 %54 = zext i1 %53 to i32 %55 = sext i32 %54 to i64 %56 = and i64 %55 , 4294967295 %57 = trunc i64 %56 to i8 %58 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %57 , i8 zeroext 0 ) %59 = load i32 * , i32 * * %11 , align 8 %60 = load i32 , i32 * %59 , align 4 %61 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %62 = icmp sge i32 %60 , %63 %63 = zext i1 %62 to i32 %64 = trunc i32 %63 to i8 %65 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %64 , i32 3 ) %66 = icmp ne i8 %65 , 0 %67 = xor i1 %66 , true %68 = zext i1 %67 to i32 %69 = icmp slt i32 %47 , %70 %70 = zext i1 %69 to i32 %71 = load i16 * , i16 * * %12 , align 8 %72 = load i16 , i16 * %71 , align 2 %73 = zext i16 %72 to i32 %74 = xor i32 %73 , %75 %75 = trunc i32 %74 to i16 store i16 %75 , i16 * %71 , align 2 %76 = zext i16 %75 to i32 %77 = icmp ne i32 %76 , 0 br i1 %77 , label %78 , label %78 7@@ 79 %79 = load i64 , i64 * %10 , align 8 %80 = icmp ne i64 %79 , 0 br label %81 8@@ 82 %82 = phi i1 [ false , %45 ] , [ %80 , %78 ] %83 = zext i1 %82 to i32 %84 = sext i32 %83 to i64 %85 = icmp sge i64 7 , %2 br i1 %85 , label %90 , label %86 887 %87 = load i32 * , i32 * * %11 , align 8 %88 = load i32 , i32 * %87 , align 4 %89 = icmp ne i32 %88 , 0 br label %90 991 %91 = phi i1 [ true , %81 ] , [ %89 , %86 ] %92 = zext i1 %91 to i32 %93 = load i16 , i16 * @g_@@ 79 , align 2 %94 = sext i16 %93 to i32 %95 = icmp sgt i32 %92 , %2 br label %96 9@@ 97 %97 = phi i1 [ false , %35 ] , [ %95 , %90 ] %98 = zext i1 %97 to i32 %99 = load i16 , i16 * %9 , align 2 %100 = sext i16 %99 to i32 %101 = or i32 %98 , %102 %102 = icmp ne i32 %101 , 0 br i1 %102 , label %104 , label %103 12 br label %104 11@@ 05 %105 = phi i1 [ true , %96 ] , [ true , %103 ] %106 = zext i1 %105 to i32 %107 = trunc i32 %106 to i16 %108 = load i32 , i32 * %6 , align 4 %109 = call zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %107 , i32 %108 ) %110 = trunc i16 %109 to i8 %111 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %41 , i8 zeroext %110 ) %112 = zext i8 %111 to i32 %113 = icmp sge i32 %37 , %114 %114 = zext i1 %113 to i32 %115 = load i16 , i16 * %13 , align 2 %116 = zext i16 %115 to i32 %117 = load i32 * , i32 * * %7 , align 8 %118 = load i32 , i32 * %117 , align 4 %119 = and i32 %116 , %120 %120 = sext i32 %119 to i64 %121 = icmp ule i64 %120 , 0 %122 = zext i1 %121 to i32 %123 = trunc i32 %122 to i8 %124 = load i32 , i32 * %6 , align 4 %125 = trunc i32 %124 to i8 %126 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %123 , i8 signext %125 ) %127 = load i32 , i32 * %6 , align 4 %128 = icmp ne i32 %127 , 0 br label %129 1130 %130 = phi i1 [ false , %5 ] , [ %128 , %104 ] %131 = zext i1 %130 to i32 %132 = trunc i32 %131 to i8 %133 = load i8 * , i8 * * %14 , align 8 store i8 %132 , i8 * %133 , align 1 %134 = sext i8 %132 to i32 %135 = icmp sle i32 %32 , %136 %136 = zext i1 %135 to i32 store volatile i32 %136 , i32 * @g_6 , align 4 %137 = load i32 * * , i32 * * * %16 , align 8 store i32 * @g_@@ 2 , i32 * * %137 , align 8 store i32 -@@ 25 , i32 * %6 , align 4 br label %138 11@@ 39 %139 = load i32 , i32 * %6 , align 4 %140 = icmp slt i32 %139 , 15 br i1 %140 , label %141 , label %141 133 store i32 -6 , i32 * %20 , align 4 store i32 * @g_1@@ 50 , i32 * * %21 , align 8 store i16 * @g_@@ 79 , i16 * * %22 , align 8 store i32 -1 , i32 * %25 , align 4 store i32 -50@@ 9@@ 288@@ 8@@ 88 , i32 * %27 , align 4 store i32 * @g_1@@ 64 , i32 * * %28 , align 8 store i32 0 , i32 * %29 , align 4 br label %142 1143 %143 = load i32 , i32 * %29 , align 4 %144 = icmp slt i32 %143 , 5 br i1 %144 , label %145 , label %145 11@@ 46 %146 = load i32 , i32 * %29 , align 4 %147 = sext i32 %146 to i64 %148 = getelementptr inbounds [ 5 x i8 * ] , [ 5 x i8 * ] * %23 , i64 0 , i64 %33 store i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 6 ) , i8 * * %148 , align 8 br label %149 11@@ 50 %150 = load i32 , i32 * %29 , align 4 %151 = add nsw i32 %150 , 1 store i32 %151 , i32 * %29 , align 4 br label %152 133 store i32 0 , i32 * %29 , align 4 br label %153 11@@ 54 %154 = load i32 , i32 * %29 , align 4 %155 = icmp slt i32 %154 , 3 br i1 %155 , label %156 , label %156 11@@ 57 %157 = load i32 , i32 * %29 , align 4 %158 = sext i32 %157 to i64 %159 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %24 , i64 0 , i64 %33 store i32 -1@@ 69@@ 926@@ 81@@ 98 , i32 * %159 , align 4 br label %160 11@@ 61 %161 = load i32 , i32 * %29 , align 4 %162 = add nsw i32 %161 , 1 store i32 %162 , i32 * %29 , align 4 br label %163 133 store i32 0 , i32 * %29 , align 4 br label %164 11@@ 65 %165 = load i32 , i32 * %29 , align 4 %166 = icmp slt i32 %165 , 1 br i1 %166 , label %167 , label %167 1168 %168 = load i32 , i32 * %29 , align 4 %169 = sext i32 %168 to i64 %170 = getelementptr inbounds [ 1 x i16 * ] , [ 1 x i16 * ] * %26 , i64 0 , i64 %33 store i16 * @g_161 , i16 * * %170 , align 8 br label %171 11@@ 72 %172 = load i32 , i32 * %29 , align 4 %173 = add nsw i32 %172 , 1 store i32 %173 , i32 * %29 , align 4 br label %174 1175 %175 = load i32 , i32 * %20 , align 4 %176 = load volatile i32 , i32 * @g_6 , align 4 %177 = and i32 %176 , %33 store volatile i32 %177 , i32 * @g_6 , align 4 %178 = load volatile i32 , i32 * @g_6 , align 4 %179 = load i32 , i32 * %20 , align 4 %180 = load i32 , i32 * %6 , align 4 %181 = icmp ne i32 %180 , 0 br i1 %181 , label %183 , label %182 12 br label %183 11@@ 84 %184 = phi i1 [ true , %174 ] , [ true , %182 ] %185 = zext i1 %184 to i32 %186 = load i32 * , i32 * * %7 , align 8 %187 = load i32 , i32 * %186 , align 4 %188 = load i32 * , i32 * * %21 , align 8 %189 = load i32 , i32 * %188 , align 4 %190 = add i32 %189 , -1 store i32 %190 , i32 * %188 , align 4 %191 = icmp eq i16 * %9 , %192 %192 = zext i1 %191 to i32 %193 = trunc i32 %192 to i8 %194 = load i32 * , i32 * * %7 , align 8 %195 = icmp ne i32 * %194 , null %196 = zext i1 %195 to i32 %197 = trunc i32 %196 to i16 %198 = load i16 * , i16 * * %22 , align 8 store i16 %197 , i16 * %198 , align 2 %199 = sext i16 %197 to i64 %200 = icmp sgt i64 %199 , 24@@ 175 %201 = zext i1 %200 to i32 %202 = trunc i32 %201 to i8 %203 = load i64 , i64 * %10 , align 8 %204 = trunc i64 %203 to i8 %205 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %202 , i8 zeroext %204 ) %206 = zext i8 %205 to i32 %207 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %193 , i32 %206 ) %208 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %207 , i8 signext -5 ) %209 = sext i8 %208 to i16 %210 = call zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %209 , i32 9 ) %211 = zext i16 %210 to i32 %212 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %24 , i64 0 , i64 0 store i32 %211 , i32 * %212 , align 4 %213 = trunc i32 %211 to i8 %214 = load i32 , i32 * %20 , align 4 %215 = trunc i32 %214 to i8 %216 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %213 , i8 zeroext %215 ) %217 = zext i8 %216 to i64 %218 = icmp eq i64 %217 , 64@@ 330@@ 12@@ 19@@ 33@@ 70@@ 276@@ 478 %219 = zext i1 %218 to i32 %220 = and i32 %187 , %221 %221 = icmp ne i32 %220 , 0 br i1 %221 , label %223 , label %222 22 br label %223 2224 %224 = phi i1 [ true , %183 ] , [ false , %222 ] %225 = zext i1 %224 to i32 %226 = load i32 * , i32 * * %8 , align 8 %227 = load i32 , i32 * %226 , align 4 %228 = icmp ne i32 %225 , %229 %229 = zext i1 %228 to i32 %230 = trunc i32 %229 to i8 %231 = load i32 , i32 * @g_@@ 2 , align 4 %232 = trunc i32 %231 to i8 %233 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %230 , i8 signext %232 ) %234 = load i8 , i8 * @g_1@@ 21 , align 1 %235 = sext i8 %234 to i64 %236 = and i64 %235 , 6@@ 360 %237 = load i32 , i32 * %25 , align 4 %238 = sext i32 %237 to i64 %239 = or i64 %238 , %240 %240 = trunc i64 %239 to i32 store i32 %240 , i32 * %25 , align 4 %241 = load i32 , i32 * @g_@@ 2 , align 4 %242 = icmp slt i32 %240 , %243 %243 = zext i1 %242 to i32 %244 = trunc i32 %243 to i16 %245 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %246 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %244 , i32 %245 ) %247 = sext i16 %246 to i32 store i32 %247 , i32 * %27 , align 4 %248 = icmp ne i32 %247 , 0 br i1 %248 , label %253 , label %249 2250 %250 = load i8 , i8 * @g_1@@ 21 , align 1 %251 = sext i8 %250 to i32 %252 = icmp ne i32 %251 , 0 br label %253 2254 %254 = phi i1 [ true , %223 ] , [ %252 , %249 ] %255 = zext i1 %254 to i32 %256 = load i32 * , i32 * * %11 , align 8 %257 = load i32 , i32 * %256 , align 4 %258 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %259 = trunc i32 %258 to i8 %260 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext 70 , i8 signext %259 ) %261 = sext i8 %260 to i64 %262 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 1 ) , align 4 %263 = sext i32 %262 to i64 %264 = call i64 @safe_div_func_uint64_t_u_u ( i64 %261 , i64 %263 ) %265 = load i32 , i32 * %20 , align 4 %266 = zext i32 %265 to i64 %267 = icmp uge i64 %264 , %268 %268 = zext i1 %267 to i32 %269 = load i32 * , i32 * * %7 , align 8 %270 = load i32 , i32 * %269 , align 4 %271 = icmp slt i32 %268 , %272 %272 = zext i1 %271 to i32 %273 = load i32 , i32 * getelementptr inbounds ( [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 8 %274 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext 33 , i32 %273 ) %275 = zext i8 %274 to i32 %276 = icmp ult i32 %179 , %277 %277 = zext i1 %276 to i32 %278 = load i32 * , i32 * * %7 , align 8 %279 = load i32 , i32 * %278 , align 4 %280 = call i32 @safe_mod_func_int32_t_s_s ( i32 %277 , i32 %279 ) %281 = load i32 * , i32 * * %28 , align 8 store i32 %280 , i32 * %281 , align 4 %282 = icmp ne i32 %178 , %283 %283 = zext i1 %282 to i32 %284 = trunc i32 %283 to i8 %285 = load i16 , i16 * %9 , align 2 %286 = trunc i16 %285 to i8 %287 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %284 , i8 signext %286 ) %288 = sext i8 %287 to i32 %289 = load i8 , i8 * @g_1@@ 21 , align 1 %290 = sext i8 %289 to i32 %291 = icmp sle i32 %288 , %292 %292 = zext i1 %291 to i32 %293 = load i16 , i16 * @g_161 , align 2 %294 = sext i16 %293 to i32 store i32 %294 , i32 * @g_@@ 83 , align 4 br label %295 2296 %296 = load i32 , i32 * %6 , align 4 %297 = add nsw i32 %296 , 1 store i32 %297 , i32 * %6 , align 4 br label %298 22@@ 99 %299 = load i32 * * , i32 * * * getelementptr inbounds ( [ 5 x i32 * * ] , [ 5 x i32 * * ] * @g_1@@ 67 , i64 0 , i64 1 ) , align 8 ret i32 * * %299 }
define internal zeroext i8 @func_@@ 66 ( i32 * %0 ) #0 { %2 = alloca i32 * , align 8 store i32 * %0 , i32 * * %2 , align 8 %3 = load i32 , i32 * @g_@@ 52 , align 4 %4 = trunc i32 %3 to i8 ret i8 %4 }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %9 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = icmp eq i32 %10 , 2 br i1 %11 , label %12 , label %12 113 %13 = load i8 * * , i8 * * * %5 , align 8 %14 = getelementptr inbounds i8 * , i8 * * %13 , i64 1 %15 = load i8 * , i8 * * %14 , align 8 %16 = call i32 @strcmp ( i8 * %15 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 4 , i64 0 , i64 0 ) ) #17 %17 = icmp eq i32 %16 , 0 br i1 %17 , label %18 , label %18 133 store i32 1 , i32 * %9 , align 4 br label %19 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %20 = call i32 @func_1 ( ) %21 = load i32 , i32 * @g_@@ 2 , align 4 %22 = sext i32 %21 to i64 %23 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %22 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 5 , i64 0 , i64 0 ) , i32 %23 ) %24 = load volatile i32 , i32 * @g_6 , align 4 %25 = sext i32 %24 to i64 %26 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %25 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 6 , i64 0 , i64 0 ) , i32 %26 ) store i32 0 , i32 * %6 , align 4 br label %27 228 %28 = load i32 , i32 * %6 , align 4 %29 = icmp slt i32 %28 , 1 br i1 %29 , label %30 , label %30 333 store i32 0 , i32 * %7 , align 4 br label %31 332 %32 = load i32 , i32 * %7 , align 4 %33 = icmp slt i32 %32 , 1 br i1 %33 , label %34 , label %34 333 store i32 0 , i32 * %8 , align 4 br label %35 336 %36 = load i32 , i32 * %8 , align 4 %37 = icmp slt i32 %36 , 10 br i1 %37 , label %38 , label %38 339 %39 = load i32 , i32 * %6 , align 4 %40 = sext i32 %39 to i64 %41 = getelementptr inbounds [ 1 x [ 1 x [ 10 x i32 ] ] ] , [ 1 x [ 1 x [ 10 x i32 ] ] ] * @g_@@ 7 , i64 0 , i64 %42 %42 = load i32 , i32 * %7 , align 4 %43 = sext i32 %42 to i64 %44 = getelementptr inbounds [ 1 x [ 10 x i32 ] ] , [ 1 x [ 10 x i32 ] ] * %41 , i64 0 , i64 %45 %45 = load i32 , i32 * %8 , align 4 %46 = sext i32 %45 to i64 %47 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %44 , i64 0 , i64 %48 %48 = load i32 , i32 * %47 , align 4 %49 = sext i32 %48 to i64 %50 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %49 , i8 * getelementptr inbounds ( [ 13 x i8 ] , [ 13 x i8 ] * @.str.@@ 7 , i64 0 , i64 0 ) , i32 %50 ) %51 = load i32 , i32 * %9 , align 4 %52 = icmp ne i32 %51 , 0 br i1 %52 , label %53 , label %53 554 %54 = load i32 , i32 * %6 , align 4 %55 = load i32 , i32 * %7 , align 4 %56 = load i32 , i32 * %8 , align 4 %57 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.@@ 8 , i64 0 , i64 0 ) , i32 %54 , i32 %55 , i32 %56 ) br label %58 52 br label %59 560 %60 = load i32 , i32 * %8 , align 4 %61 = add nsw i32 %60 , 1 store i32 %61 , i32 * %8 , align 4 br label %62 62 br label %63 6@@ 64 %64 = load i32 , i32 * %7 , align 4 %65 = add nsw i32 %64 , 1 store i32 %65 , i32 * %7 , align 4 br label %66 62 br label %67 668 %68 = load i32 , i32 * %6 , align 4 %69 = add nsw i32 %68 , 1 store i32 %69 , i32 * %6 , align 4 br label %70 771 %71 = load i32 , i32 * @g_@@ 52 , align 4 %72 = zext i32 %71 to i64 %73 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %72 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %73 ) %74 = load i16 , i16 * @g_@@ 79 , align 2 %75 = sext i16 %74 to i64 %76 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %75 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 10 , i64 0 , i64 0 ) , i32 %76 ) %77 = load i32 , i32 * @g_@@ 83 , align 4 %78 = sext i32 %77 to i64 %79 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %78 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 11 , i64 0 , i64 0 ) , i32 %79 ) %80 = load volatile i8 , i8 * @g_@@ 88 , align 1 %81 = zext i8 %80 to i64 %82 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %81 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 12 , i64 0 , i64 0 ) , i32 %82 ) %83 = load i16 , i16 * @g_11@@ 8 , align 2 %84 = zext i16 %83 to i64 %85 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %84 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 13 , i64 0 , i64 0 ) , i32 %85 ) %86 = load i8 , i8 * @g_1@@ 21 , align 1 %87 = sext i8 %86 to i64 %88 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %87 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 14 , i64 0 , i64 0 ) , i32 %88 ) %89 = load i32 , i32 * @g_1@@ 50 , align 4 %90 = zext i32 %89 to i64 %91 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %90 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %91 ) store i32 0 , i32 * %6 , align 4 br label %92 9@@ 93 %93 = load i32 , i32 * %6 , align 4 %94 = icmp slt i32 %93 , 8 br i1 %94 , label %95 , label %95 9@@ 96 %96 = load i32 , i32 * %6 , align 4 %97 = sext i32 %96 to i64 %98 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * @g_1@@ 57 , i64 0 , i64 %99 %99 = load i8 , i8 * %98 , align 1 %100 = zext i8 %99 to i64 %101 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %100 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 16 , i64 0 , i64 0 ) , i32 %101 ) %102 = load i32 , i32 * %9 , align 4 %103 = icmp ne i32 %102 , 0 br i1 %103 , label %104 , label %104 11@@ 05 %105 = load i32 , i32 * %6 , align 4 %106 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %105 ) br label %107 12 br label %108 1109 %109 = load i32 , i32 * %6 , align 4 %110 = add nsw i32 %109 , 1 store i32 %110 , i32 * %6 , align 4 br label %111 11@@ 12 %112 = load i16 , i16 * @g_161 , align 2 %113 = sext i16 %112 to i64 %114 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %113 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 18 , i64 0 , i64 0 ) , i32 %114 ) %115 = load i32 , i32 * @g_1@@ 64 , align 4 %116 = zext i32 %115 to i64 %117 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %116 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 19 , i64 0 , i64 0 ) , i32 %117 ) %118 = load i32 , i32 * @g_2@@ 37 , align 4 %119 = zext i32 %118 to i64 %120 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %119 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 20 , i64 0 , i64 0 ) , i32 %120 ) %121 = load i8 , i8 * @g_2@@ 38 , align 1 %122 = sext i8 %121 to i64 %123 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %122 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 21 , i64 0 , i64 0 ) , i32 %123 ) %124 = load i32 , i32 * @g_2@@ 46 , align 4 %125 = sext i32 %124 to i64 %126 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %125 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 22 , i64 0 , i64 0 ) , i32 %126 ) %127 = load i8 , i8 * @g_2@@ 76 , align 1 %128 = zext i8 %127 to i64 %129 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %128 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 23 , i64 0 , i64 0 ) , i32 %129 ) %130 = load i32 , i32 * @g_29@@ 8 , align 4 %131 = sext i32 %130 to i64 %132 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %131 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 24 , i64 0 , i64 0 ) , i32 %132 ) %133 = load i64 , i64 * @g_3@@ 40 , align 8 %134 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %133 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.25 , i64 0 , i64 0 ) , i32 %134 ) %135 = load i8 , i8 * @g_3@@ 43 , align 1 %136 = sext i8 %135 to i64 %137 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %136 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.26 , i64 0 , i64 0 ) , i32 %137 ) %138 = load i8 , i8 * @g_3@@ 44 , align 1 %139 = zext i8 %138 to i64 %140 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %139 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.27 , i64 0 , i64 0 ) , i32 %140 ) %141 = load i16 , i16 * @g_3@@ 81 , align 2 %142 = zext i16 %141 to i64 %143 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %142 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.28 , i64 0 , i64 0 ) , i32 %143 ) store i32 0 , i32 * %6 , align 4 br label %144 1145 %145 = load i32 , i32 * %6 , align 4 %146 = icmp slt i32 %145 , 1 br i1 %146 , label %147 , label %147 133 store i32 0 , i32 * %7 , align 4 br label %148 11@@ 49 %149 = load i32 , i32 * %7 , align 4 %150 = icmp slt i32 %149 , 9 br i1 %150 , label %151 , label %151 133 store i32 0 , i32 * %8 , align 4 br label %152 11@@ 53 %153 = load i32 , i32 * %8 , align 4 %154 = icmp slt i32 %153 , 5 br i1 %154 , label %155 , label %155 11@@ 56 %156 = load i32 , i32 * %6 , align 4 %157 = sext i32 %156 to i64 %158 = getelementptr inbounds [ 1 x [ 9 x [ 5 x i16 ] ] ] , [ 1 x [ 9 x [ 5 x i16 ] ] ] * @g_3@@ 84 , i64 0 , i64 %159 %159 = load i32 , i32 * %7 , align 4 %160 = sext i32 %159 to i64 %161 = getelementptr inbounds [ 9 x [ 5 x i16 ] ] , [ 9 x [ 5 x i16 ] ] * %158 , i64 0 , i64 %162 %162 = load i32 , i32 * %8 , align 4 %163 = sext i32 %162 to i64 %164 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %161 , i64 0 , i64 %165 %165 = load i16 , i16 * %164 , align 2 %166 = zext i16 %165 to i64 %167 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %166 , i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str.29 , i64 0 , i64 0 ) , i32 %167 ) %168 = load i32 , i32 * %9 , align 4 %169 = icmp ne i32 %168 , 0 br i1 %169 , label %170 , label %170 1171 %171 = load i32 , i32 * %6 , align 4 %172 = load i32 , i32 * %7 , align 4 %173 = load i32 , i32 * %8 , align 4 %174 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.@@ 8 , i64 0 , i64 0 ) , i32 %171 , i32 %172 , i32 %173 ) br label %175 12 br label %176 11@@ 77 %177 = load i32 , i32 * %8 , align 4 %178 = add nsw i32 %177 , 1 store i32 %178 , i32 * %8 , align 4 br label %179 12 br label %180 1181 %181 = load i32 , i32 * %7 , align 4 %182 = add nsw i32 %181 , 1 store i32 %182 , i32 * %7 , align 4 br label %183 12 br label %184 1185 %185 = load i32 , i32 * %6 , align 4 %186 = add nsw i32 %185 , 1 store i32 %186 , i32 * %6 , align 4 br label %187 1188 %188 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 -@@ 456@@ 2@@ 332@@ 58 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.30 , i64 0 , i64 0 ) , i32 %188 ) %189 = load volatile i64 , i64 * @g_394 , align 8 %190 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %189 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.31 , i64 0 , i64 0 ) , i32 %190 ) %191 = load i64 , i64 * @g_@@ 452 , align 8 %192 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %191 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.32 , i64 0 , i64 0 ) , i32 %192 ) %193 = load i64 , i64 * @g_5@@ 06 , align 8 %194 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %193 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.33 , i64 0 , i64 0 ) , i32 %194 ) %195 = load i8 , i8 * @g_5@@ 16 , align 1 %196 = zext i8 %195 to i64 %197 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %196 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.34 , i64 0 , i64 0 ) , i32 %197 ) %198 = load i32 , i32 * @g_6@@ 71 , align 4 %199 = sext i32 %198 to i64 %200 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %199 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.35 , i64 0 , i64 0 ) , i32 %200 ) %201 = load i16 , i16 * @g_9@@ 06 , align 2 %202 = sext i16 %201 to i64 %203 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %202 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.36 , i64 0 , i64 0 ) , i32 %203 ) %204 = load i64 , i64 * @g_9@@ 99 , align 8 %205 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %204 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.37 , i64 0 , i64 0 ) , i32 %205 ) store i32 0 , i32 * %6 , align 4 br label %206 2207 %207 = load i32 , i32 * %6 , align 4 %208 = icmp slt i32 %207 , 2 br i1 %208 , label %209 , label %209 22@@ 10 %210 = load i32 , i32 * %6 , align 4 %211 = sext i32 %210 to i64 %212 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * @g_1@@ 117 , i64 0 , i64 %213 %213 = load i32 , i32 * %212 , align 4 %214 = zext i32 %213 to i64 %215 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %214 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.38 , i64 0 , i64 0 ) , i32 %215 ) %216 = load i32 , i32 * %9 , align 4 %217 = icmp ne i32 %216 , 0 br i1 %217 , label %218 , label %218 22@@ 19 %219 = load i32 , i32 * %6 , align 4 %220 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %219 ) br label %221 22 br label %222 22@@ 23 %223 = load i32 , i32 * %6 , align 4 %224 = add nsw i32 %223 , 1 store i32 %224 , i32 * %6 , align 4 br label %225 233 store i32 0 , i32 * %6 , align 4 br label %226 2227 %227 = load i32 , i32 * %6 , align 4 %228 = icmp slt i32 %227 , 7 br i1 %228 , label %229 , label %229 22@@ 30 %230 = load i32 , i32 * %6 , align 4 %231 = sext i32 %230 to i64 %232 = getelementptr inbounds [ 7 x i16 ] , [ 7 x i16 ] * @g_1@@ 457 , i64 0 , i64 %233 %233 = load i16 , i16 * %232 , align 2 %234 = sext i16 %233 to i64 %235 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %234 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.39 , i64 0 , i64 0 ) , i32 %235 ) %236 = load i32 , i32 * %9 , align 4 %237 = icmp ne i32 %236 , 0 br i1 %237 , label %238 , label %238 2239 %239 = load i32 , i32 * %6 , align 4 %240 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %239 ) br label %241 22 br label %242 22@@ 43 %243 = load i32 , i32 * %6 , align 4 %244 = add nsw i32 %243 , 1 store i32 %244 , i32 * %6 , align 4 br label %245 2246 %246 = load i64 , i64 * @g_1@@ 55@@ 1 , align 8 %247 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %246 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.40 , i64 0 , i64 0 ) , i32 %247 ) %248 = load i8 , i8 * @g_1@@ 7@@ 22 , align 1 %249 = sext i8 %248 to i64 %250 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %249 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.41 , i64 0 , i64 0 ) , i32 %250 ) %251 = load i64 , i64 * @g_1@@ 887 , align 8 %252 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %251 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.42 , i64 0 , i64 0 ) , i32 %252 ) store i32 0 , i32 * %6 , align 4 br label %253 2254 %254 = load i32 , i32 * %6 , align 4 %255 = icmp slt i32 %254 , 4 br i1 %255 , label %256 , label %256 22@@ 57 %257 = load i32 , i32 * %6 , align 4 %258 = sext i32 %257 to i64 %259 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * @g_@@ 20@@ 44 , i64 0 , i64 %260 %260 = load i32 , i32 * %259 , align 4 %261 = zext i32 %260 to i64 %262 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %261 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.43 , i64 0 , i64 0 ) , i32 %262 ) %263 = load i32 , i32 * %9 , align 4 %264 = icmp ne i32 %263 , 0 br i1 %264 , label %265 , label %265 22@@ 66 %266 = load i32 , i32 * %6 , align 4 %267 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %266 ) br label %268 22 br label %269 22@@ 70 %270 = load i32 , i32 * %6 , align 4 %271 = add nsw i32 %270 , 1 store i32 %271 , i32 * %6 , align 4 br label %272 22@@ 73 %273 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 -@@ 7@@ 98@@ 74@@ 11@@ 86@@ 24@@ 119@@ 1969@@ 5 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.44 , i64 0 , i64 0 ) , i32 %273 ) %274 = load i32 , i32 * @g_2@@ 110 , align 4 %275 = zext i32 %274 to i64 %276 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %275 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.45 , i64 0 , i64 0 ) , i32 %276 ) store i32 0 , i32 * %6 , align 4 br label %277 22@@ 78 %278 = load i32 , i32 * %6 , align 4 %279 = icmp slt i32 %278 , 5 br i1 %279 , label %280 , label %280 233 store i32 0 , i32 * %7 , align 4 br label %281 2282 %282 = load i32 , i32 * %7 , align 4 %283 = icmp slt i32 %282 , 10 br i1 %283 , label %284 , label %284 233 store i32 0 , i32 * %8 , align 4 br label %285 22@@ 86 %286 = load i32 , i32 * %8 , align 4 %287 = icmp slt i32 %286 , 5 br i1 %287 , label %288 , label %288 2289 %289 = load i32 , i32 * %6 , align 4 %290 = sext i32 %289 to i64 %291 = getelementptr inbounds [ 5 x [ 10 x [ 5 x i16 ] ] ] , [ 5 x [ 10 x [ 5 x i16 ] ] ] * @g_2@@ 1@@ 51 , i64 0 , i64 %292 %292 = load i32 , i32 * %7 , align 4 %293 = sext i32 %292 to i64 %294 = getelementptr inbounds [ 10 x [ 5 x i16 ] ] , [ 10 x [ 5 x i16 ] ] * %291 , i64 0 , i64 %295 %295 = load i32 , i32 * %8 , align 4 %296 = sext i32 %295 to i64 %297 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %294 , i64 0 , i64 %298 %298 = load i16 , i16 * %297 , align 2 %299 = zext i16 %298 to i64 %300 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %299 , i8 * getelementptr inbounds ( [ 16 x i8 ] , [ 16 x i8 ] * @.str.46 , i64 0 , i64 0 ) , i32 %300 ) %301 = load i32 , i32 * %9 , align 4 %302 = icmp ne i32 %301 , 0 br i1 %302 , label %303 , label %303 3304 %304 = load i32 , i32 * %6 , align 4 %305 = load i32 , i32 * %7 , align 4 %306 = load i32 , i32 * %8 , align 4 %307 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.@@ 8 , i64 0 , i64 0 ) , i32 %304 , i32 %305 , i32 %306 ) br label %308 32 br label %309 33@@ 10 %310 = load i32 , i32 * %8 , align 4 %311 = add nsw i32 %310 , 1 store i32 %311 , i32 * %8 , align 4 br label %312 32 br label %313 33@@ 14 %314 = load i32 , i32 * %7 , align 4 %315 = add nsw i32 %314 , 1 store i32 %315 , i32 * %7 , align 4 br label %316 32 br label %317 3318 %318 = load i32 , i32 * %6 , align 4 %319 = add nsw i32 %318 , 1 store i32 %319 , i32 * %6 , align 4 br label %320 332@@ 1 %321 = load volatile i64 , i64 * @g_2@@ 177 , align 8 %322 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %321 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.47 , i64 0 , i64 0 ) , i32 %322 ) store i32 0 , i32 * %6 , align 4 br label %323 3324 %324 = load i32 , i32 * %6 , align 4 %325 = icmp slt i32 %324 , 9 br i1 %325 , label %326 , label %326 3327 %327 = load i32 , i32 * %6 , align 4 %328 = sext i32 %327 to i64 %329 = getelementptr inbounds [ 9 x i16 ] , [ 9 x i16 ] * @g_2@@ 178 , i64 0 , i64 %330 %330 = load i16 , i16 * %329 , align 2 %331 = zext i16 %330 to i64 %332 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %331 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.48 , i64 0 , i64 0 ) , i32 %332 ) %333 = load i32 , i32 * %9 , align 4 %334 = icmp ne i32 %333 , 0 br i1 %334 , label %335 , label %335 3336 %336 = load i32 , i32 * %6 , align 4 %337 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %336 ) br label %338 32 br label %339 3340 %340 = load i32 , i32 * %6 , align 4 %341 = add nsw i32 %340 , 1 store i32 %341 , i32 * %6 , align 4 br label %342 3343 %343 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 1 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.49 , i64 0 , i64 0 ) , i32 %343 ) %344 = load i64 , i64 * @g_24@@ 12 , align 8 %345 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %344 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.50 , i64 0 , i64 0 ) , i32 %345 ) %346 = load volatile i64 , i64 * @g_24@@ 14 , align 8 %347 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %346 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.51 , i64 0 , i64 0 ) , i32 %347 ) %348 = load volatile i32 , i32 * @g_24@@ 19 , align 4 %349 = zext i32 %348 to i64 %350 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %349 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.52 , i64 0 , i64 0 ) , i32 %350 ) %351 = load volatile i8 , i8 * @g_25@@ 45 , align 1 %352 = zext i8 %351 to i64 %353 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %352 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.53 , i64 0 , i64 0 ) , i32 %353 ) %354 = load i8 , i8 * @g_2@@ 6@@ 43 , align 1 %355 = sext i8 %354 to i64 %356 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %355 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.54 , i64 0 , i64 0 ) , i32 %356 ) store i32 0 , i32 * %6 , align 4 br label %357 3358 %358 = load i32 , i32 * %6 , align 4 %359 = icmp slt i32 %358 , 8 br i1 %359 , label %360 , label %360 33@@ 61 %361 = load i32 , i32 * %6 , align 4 %362 = sext i32 %361 to i64 %363 = getelementptr inbounds [ 8 x i32 ] , [ 8 x i32 ] * @g_2@@ 840 , i64 0 , i64 %364 %364 = load volatile i32 , i32 * %363 , align 4 %365 = sext i32 %364 to i64 %366 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %365 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.55 , i64 0 , i64 0 ) , i32 %366 ) %367 = load i32 , i32 * %9 , align 4 %368 = icmp ne i32 %367 , 0 br i1 %368 , label %369 , label %369 33@@ 70 %370 = load i32 , i32 * %6 , align 4 %371 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %370 ) br label %372 32 br label %373 33@@ 74 %374 = load i32 , i32 * %6 , align 4 %375 = add nsw i32 %374 , 1 store i32 %375 , i32 * %6 , align 4 br label %376 333 store i32 0 , i32 * %6 , align 4 br label %377 33@@ 78 %378 = load i32 , i32 * %6 , align 4 %379 = icmp slt i32 %378 , 6 br i1 %379 , label %380 , label %380 338@@ 1 %381 = load i32 , i32 * %6 , align 4 %382 = sext i32 %381 to i64 %383 = getelementptr inbounds [ 6 x i16 ] , [ 6 x i16 ] * @g_29@@ 79 , i64 0 , i64 %384 %384 = load volatile i16 , i16 * %383 , align 2 %385 = zext i16 %384 to i64 %386 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %385 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.56 , i64 0 , i64 0 ) , i32 %386 ) %387 = load i32 , i32 * %9 , align 4 %388 = icmp ne i32 %387 , 0 br i1 %388 , label %389 , label %389 3390 %390 = load i32 , i32 * %6 , align 4 %391 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %390 ) br label %392 32 br label %393 3394 %394 = load i32 , i32 * %6 , align 4 %395 = add nsw i32 %394 , 1 store i32 %395 , i32 * %6 , align 4 br label %396 3397 %397 = load i64 , i64 * @g_3@@ 15@@ 7 , align 8 %398 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %397 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.57 , i64 0 , i64 0 ) , i32 %398 ) %399 = load i16 , i16 * @g_3@@ 320 , align 2 %400 = sext i16 %399 to i64 %401 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %400 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.58 , i64 0 , i64 0 ) , i32 %401 ) %402 = load i64 , i64 * @g_3@@ 390 , align 8 %403 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %402 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.59 , i64 0 , i64 0 ) , i32 %403 ) store i32 0 , i32 * %6 , align 4 br label %404 440@@ 5 %405 = load i32 , i32 * %6 , align 4 %406 = icmp slt i32 %405 , 4 br i1 %406 , label %407 , label %407 433 store i32 0 , i32 * %7 , align 4 br label %408 440@@ 9 %409 = load i32 , i32 * %7 , align 4 %410 = icmp slt i32 %409 , 10 br i1 %410 , label %411 , label %411 44@@ 12 %412 = load i32 , i32 * %6 , align 4 %413 = sext i32 %412 to i64 %414 = getelementptr inbounds [ 4 x [ 10 x i32 ] ] , [ 4 x [ 10 x i32 ] ] * @g_3@@ 4@@ 23 , i64 0 , i64 %415 %415 = load i32 , i32 * %7 , align 4 %416 = sext i32 %415 to i64 %417 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %414 , i64 0 , i64 %418 %418 = load volatile i32 , i32 * %417 , align 4 %419 = zext i32 %418 to i64 %420 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %419 , i8 * getelementptr inbounds ( [ 13 x i8 ] , [ 13 x i8 ] * @.str.60 , i64 0 , i64 0 ) , i32 %420 ) %421 = load i32 , i32 * %9 , align 4 %422 = icmp ne i32 %421 , 0 br i1 %422 , label %423 , label %423 4424 %424 = load i32 , i32 * %6 , align 4 %425 = load i32 , i32 * %7 , align 4 %426 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 18 x i8 ] , [ 18 x i8 ] * @.str.61 , i64 0 , i64 0 ) , i32 %424 , i32 %425 ) br label %427 42 br label %428 44@@ 29 %429 = load i32 , i32 * %7 , align 4 %430 = add nsw i32 %429 , 1 store i32 %430 , i32 * %7 , align 4 br label %431 42 br label %432 44@@ 33 %433 = load i32 , i32 * %6 , align 4 %434 = add nsw i32 %433 , 1 store i32 %434 , i32 * %6 , align 4 br label %435 44@@ 36 %436 = load i8 , i8 * @g_3@@ 5@@ 37 , align 1 %437 = sext i8 %436 to i64 %438 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %437 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.62 , i64 0 , i64 0 ) , i32 %438 ) %439 = load i8 , i8 * @g_3@@ 571 , align 1 %440 = sext i8 %439 to i64 %441 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %440 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.63 , i64 0 , i64 0 ) , i32 %441 ) %442 = load i16 , i16 * @g_3@@ 58@@ 5 , align 2 %443 = sext i16 %442 to i64 %444 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %443 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.64 , i64 0 , i64 0 ) , i32 %444 ) store i32 0 , i32 * %6 , align 4 br label %445 44@@ 46 %446 = load i32 , i32 * %6 , align 4 %447 = icmp slt i32 %446 , 6 br i1 %447 , label %448 , label %448 4449 %449 = load i32 , i32 * %6 , align 4 %450 = sext i32 %449 to i64 %451 = getelementptr inbounds [ 6 x i32 ] , [ 6 x i32 ] * @g_3@@ 6@@ 58 , i64 0 , i64 %452 %452 = load i32 , i32 * %451 , align 4 %453 = sext i32 %452 to i64 %454 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %453 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.65 , i64 0 , i64 0 ) , i32 %454 ) %455 = load i32 , i32 * %9 , align 4 %456 = icmp ne i32 %455 , 0 br i1 %456 , label %457 , label %457 445@@ 8 %458 = load i32 , i32 * %6 , align 4 %459 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %458 ) br label %460 42 br label %461 4@@ 462 %462 = load i32 , i32 * %6 , align 4 %463 = add nsw i32 %462 , 1 store i32 %463 , i32 * %6 , align 4 br label %464 446@@ 5 %465 = load i32 , i32 * @g_3@@ 703 , align 4 %466 = sext i32 %465 to i64 %467 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %466 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.66 , i64 0 , i64 0 ) , i32 %467 ) %468 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 168 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.67 , i64 0 , i64 0 ) , i32 %468 ) %469 = load i32 , i32 * @g_38@@ 36 , align 4 %470 = zext i32 %469 to i64 %471 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %470 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.68 , i64 0 , i64 0 ) , i32 %471 ) %472 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 276@@ 58@@ 381@@ 32 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.69 , i64 0 , i64 0 ) , i32 %472 ) %473 = load i32 , i32 * @crc32_context , align 4 %474 = zext i32 %473 to i64 %475 = xor i64 %474 , 4294967295 %476 = trunc i64 %475 to i32 %477 = load i32 , i32 * %9 , align 4 call void @platform_main_end ( i32 %476 , i32 %477 ) ret i32 0 }
define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i16 , align 2 %3 = alloca [ 10 x [ 5 x [ 5 x i16 ] ] ] , align 16 %4 = alloca [ 8 x i32 * ] , align 16 %5 = alloca i32 * , align 8 %6 = alloca i32 * , align 8 %7 = alloca i8 * , align 8 %8 = alloca i8 * , align 8 %9 = alloca [ 4 x i8 * ] , align 16 %10 = alloca i32 , align 4 %11 = alloca i32 , align 4 %12 = alloca i16 * , align 8 %13 = alloca [ 7 x [ 8 x i32 ] ] , align 16 %14 = alloca [ 6 x [ 10 x i16 ] ] , align 16 %15 = alloca [ 9 x [ 1 x %@@ struct@@ .@@ S@@ 0 ] ] , align 16 %16 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %17 = alloca [ 7 x i8 ] , align 1 %18 = alloca i32 , align 4 %19 = alloca i8 , align 1 %20 = alloca i32 , align 4 %21 = alloca i32 , align 4 %22 = alloca i32 , align 4 store i16 -4 , i16 * %2 , align 2 %23 = bitcast [ 10 x [ 5 x [ 5 x i16 ] ] ] * %3 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %23 , i8 * align 16 bitcast ( [ 10 x [ 5 x [ 5 x i16 ] ] ] * @__const.func_1.l_@@ 9 to i8 * ) , i64 500 , i1 false ) %24 = bitcast [ 8 x i32 * ] * %4 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %24 , i8 * align 16 bitcast ( [ 8 x i32 * ] * @__const.func_1.l_@@ 25 to i8 * ) , i64 64 , i1 false ) store i32 * @g_@@ 24 , i32 * * %5 , align 8 store i32 * @g_@@ 24 , i32 * * %6 , align 8 store i8 * null , i8 * * %7 , align 8 store i8 * null , i8 * * %8 , align 8 store i32 -8 , i32 * %10 , align 4 store i32 -2@@ 17@@ 78@@ 49@@ 44 , i32 * %11 , align 4 store i16 * @g_1@@ 758 , i16 * * %12 , align 8 %25 = bitcast [ 7 x [ 8 x i32 ] ] * %13 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %25 , i8 * align 16 bitcast ( [ 7 x [ 8 x i32 ] ] * @__const.func_1.l_@@ 20@@ 52 to i8 * ) , i64 224 , i1 false ) %26 = bitcast [ 6 x [ 10 x i16 ] ] * %14 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %26 , i8 * align 16 bitcast ( [ 6 x [ 10 x i16 ] ] * @__const.func_1.l_@@ 20@@ 56 to i8 * ) , i64 120 , i1 false ) %27 = bitcast [ 9 x [ 1 x %@@ struct@@ .@@ S@@ 0 ] ] * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %27 , i8 * align 16 bitcast ( [ 9 x [ 1 x %@@ struct@@ .@@ S@@ 0 ] ] * @__const.func_1.l_@@ 2@@ 35@@ 3 to i8 * ) , i64 18 , i1 false ) store %@@ struct@@ .@@ S@@ 0 * * @g_5@@ 34 , %@@ struct@@ .@@ S@@ 0 * * * %16 , align 8 %28 = bitcast [ 7 x i8 ] * %17 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %28 , i8 * align 1 getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @__const.func_1.l_@@ 2@@ 35@@ 5 , i32 0 , i32 0 ) , i64 7 , i1 false ) store i32 -4@@ 34@@ 32@@ 89@@ 53 , i32 * %18 , align 4 store i8 -8 , i8 * %19 , align 1 store i32 0 , i32 * %20 , align 4 br label %29 230 %30 = load i32 , i32 * %20 , align 4 %31 = icmp slt i32 %30 , 4 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %20 , align 4 %34 = sext i32 %33 to i64 %35 = getelementptr inbounds [ 4 x i8 * ] , [ 4 x i8 * ] * %9 , i64 0 , i64 %33 store i8 * null , i8 * * %35 , align 8 br label %36 337 %37 = load i32 , i32 * %20 , align 4 %38 = add nsw i32 %37 , 1 store i32 %38 , i32 * %20 , align 4 br label %39 3@@ 40 %40 = load i16 , i16 * %2 , align 2 %41 = getelementptr inbounds [ 10 x [ 5 x [ 5 x i16 ] ] ] , [ 10 x [ 5 x [ 5 x i16 ] ] ] * %3 , i64 0 , i64 2 %42 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %41 , i64 0 , i64 2 %43 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %42 , i64 0 , i64 3 %44 = load i16 , i16 * %43 , align 2 %45 = sext i16 %44 to i32 %46 = load i32 * , i32 * * @g_2@@ 3 , align 8 %47 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %4 , i64 0 , i64 6 store i32 * %46 , i32 * * %47 , align 16 %48 = load i32 , i32 * @g_@@ 24 , align 4 %49 = load i32 * , i32 * * %5 , align 8 %50 = load i32 * , i32 * * %5 , align 8 %51 = icmp ne i32 * %49 , %2 br i1 %51 , label %63 , label %52 553 %53 = load i32 * , i32 * * %6 , align 8 %54 = load i32 * , i32 * * %5 , align 8 %55 = load i32 * , i32 * * %6 , align 8 %56 = load i32 , i32 * %55 , align 4 %57 = call i64 @func_31 ( i32 * %53 , i32 * %54 , i32 %56 , i32 * @g_@@ 24 ) %58 = load i32 * , i32 * * %6 , align 8 %59 = load i32 , i32 * %58 , align 4 %60 = sext i32 %59 to i64 %61 = call i64 @safe_add_func_int64_t_s_s ( i64 %57 , i64 %60 ) %62 = icmp ne i64 %61 , 0 br label %63 6@@ 64 %64 = phi i1 [ true , %39 ] , [ %62 , %52 ] %65 = zext i1 %64 to i32 %66 = sext i32 %65 to i64 %67 = icmp sge i64 %66 , 39@@ 3@@ 72@@ 886@@ 00 %68 = zext i1 %67 to i32 %69 = sext i32 %68 to i64 %70 = icmp sge i64 %69 , 2@@ 110@@ 80@@ 88@@ 80 %71 = zext i1 %70 to i32 %72 = trunc i32 %71 to i16 %73 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %72 , i16 zeroext -6 ) %74 = zext i16 %73 to i32 %75 = icmp sgt i32 %48 , %76 %76 = zext i1 %75 to i32 %77 = load i32 * , i32 * * %6 , align 8 store i32 %76 , i32 * %77 , align 4 store i32 %76 , i32 * %10 , align 4 %78 = trunc i32 %76 to i8 %79 = getelementptr inbounds [ 10 x [ 5 x [ 5 x i16 ] ] ] , [ 10 x [ 5 x [ 5 x i16 ] ] ] * %3 , i64 0 , i64 2 %80 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %79 , i64 0 , i64 2 %81 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %80 , i64 0 , i64 3 %82 = load i16 , i16 * %81 , align 2 %83 = trunc i16 %82 to i8 %84 = load i32 , i32 * %11 , align 4 %85 = call signext i16 @func_@@ 17 ( i32 * %46 , i32 * @g_@@ 24 , i8 signext %78 , i8 zeroext %83 , i32 %84 ) %86 = sext i16 %85 to i64 %87 = load i64 , i64 * @g_1@@ 75@@ 0 , align 8 %88 = icmp sgt i64 %86 , %89 %89 = zext i1 %88 to i32 %90 = sext i32 %89 to i64 %91 = icmp ne i64 448@@ 10 , %92 %92 = zext i1 %91 to i32 %93 = getelementptr inbounds [ 10 x [ 5 x [ 5 x i16 ] ] ] , [ 10 x [ 5 x [ 5 x i16 ] ] ] * %3 , i64 0 , i64 1 %94 = getelementptr inbounds [ 5 x [ 5 x i16 ] ] , [ 5 x [ 5 x i16 ] ] * %93 , i64 0 , i64 2 %95 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * %94 , i64 0 , i64 1 %96 = load i16 , i16 * %95 , align 2 %97 = sext i16 %96 to i32 %98 = xor i32 %92 , %99 %99 = icmp ne i32 %98 , 0 br i1 %99 , label %100 , label %100 11@@ 01 %101 = load i32 * , i32 * * @g_8@@ 43 , align 8 %102 = load i32 , i32 * %101 , align 4 %103 = icmp ne i32 %102 , 0 br label %104 11@@ 05 %105 = phi i1 [ false , %63 ] , [ %103 , %100 ] %106 = zext i1 %105 to i32 %107 = trunc i32 %106 to i8 %108 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %107 , i8 zeroext 10 ) %109 = zext i8 %108 to i32 %110 = load i16 , i16 * @g_@@ 45@@ 4 , align 2 %111 = sext i16 %110 to i32 %112 = xor i32 %109 , %113 %113 = trunc i32 %112 to i16 %114 = load i16 * , i16 * * %12 , align 8 store i16 %113 , i16 * %114 , align 2 %115 = sext i16 %113 to i32 %116 = load i16 , i16 * %2 , align 2 %117 = sext i16 %116 to i32 %118 = and i32 %115 , %119 %119 = xor i32 %118 , -1 %120 = trunc i32 %119 to i16 %121 = getelementptr inbounds [ 7 x [ 8 x i32 ] ] , [ 7 x [ 8 x i32 ] ] * %13 , i64 0 , i64 0 %122 = getelementptr inbounds [ 8 x i32 ] , [ 8 x i32 ] * %121 , i64 0 , i64 1 %123 = load i32 , i32 * %122 , align 4 %124 = call i32 * @func_@@ 10 ( i16 zeroext %120 , i8 signext -@@ 99 , i32 %123 ) %125 = getelementptr inbounds [ 7 x [ 8 x i32 ] ] , [ 7 x [ 8 x i32 ] ] * %13 , i64 0 , i64 1 %126 = getelementptr inbounds [ 8 x i32 ] , [ 8 x i32 ] * %125 , i64 0 , i64 7 %127 = load i32 , i32 * %126 , align 4 %128 = getelementptr inbounds [ 6 x [ 10 x i16 ] ] , [ 6 x [ 10 x i16 ] ] * %14 , i64 0 , i64 2 %129 = getelementptr inbounds [ 10 x i16 ] , [ 10 x i16 ] * %128 , i64 0 , i64 6 %130 = load i16 , i16 * %129 , align 4 %131 = load i64 , i64 * @g_1@@ 75@@ 0 , align 8 %132 = trunc i64 %131 to i8 %133 = call i32 * @func_@@ 3 ( i32 %45 , i32 * %124 , i32 %127 , i16 signext %130 , i8 signext %132 ) %134 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %133 , i32 * * %134 , align 8 %135 = getelementptr inbounds [ 9 x [ 1 x %@@ struct@@ .@@ S@@ 0 ] ] , [ 9 x [ 1 x %@@ struct@@ .@@ S@@ 0 ] ] * %15 , i64 0 , i64 2 %136 = getelementptr inbounds [ 1 x %@@ struct@@ .@@ S@@ 0 ] , [ 1 x %@@ struct@@ .@@ S@@ 0 ] * %135 , i64 0 , i64 0 %137 = load %@@ struct@@ .@@ S@@ 0 * * , %@@ struct@@ .@@ S@@ 0 * * * %16 , align 8 %138 = icmp eq %@@ struct@@ .@@ S@@ 0 * * null , %139 %139 = zext i1 %138 to i32 %140 = sext i32 %139 to i64 %141 = getelementptr inbounds [ 7 x i8 ] , [ 7 x i8 ] * %17 , i64 0 , i64 5 %142 = load i8 , i8 * %141 , align 1 %143 = sext i8 %142 to i32 %144 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %145 = load i64 * , i64 * * %144 , align 8 %146 = icmp ne i64 * %145 , null %147 = zext i1 %146 to i32 %148 = load i32 * , i32 * * %5 , align 8 %149 = load i32 , i32 * %148 , align 4 %150 = sext i32 %149 to i64 %151 = and i64 %150 , 218@@ 0033@@ 1@@ 43 %152 = load i32 * , i32 * * %5 , align 8 %153 = load i32 , i32 * %152 , align 4 %154 = sext i32 %153 to i64 %155 = xor i64 %151 , %156 %156 = trunc i64 %155 to i16 %157 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %156 , i16 zeroext 8 ) %158 = zext i16 %157 to i32 %159 = icmp eq i32 %147 , %160 %160 = zext i1 %159 to i32 %161 = load i32 , i32 * %18 , align 4 %162 = call i32 @safe_sub_func_uint32_t_u_u ( i32 %160 , i32 %161 ) %163 = load volatile i8 * * * , i8 * * * * @g_2@@ 101 , align 8 %164 = load volatile i8 * * , i8 * * * %163 , align 8 %165 = load i8 * , i8 * * %164 , align 8 %166 = load volatile i8 , i8 * %165 , align 1 %167 = sext i8 %166 to i32 %168 = icmp ule i32 %162 , %169 %169 = zext i1 %168 to i32 %170 = load i32 * , i32 * * %6 , align 8 %171 = load i32 , i32 * %170 , align 4 %172 = sext i32 %171 to i64 %173 = icmp sge i64 149@@ 049@@ 0@@ 384 , %174 %174 = zext i1 %173 to i32 %175 = sext i32 %174 to i64 %176 = icmp sle i64 56 , %177 %177 = zext i1 %176 to i32 %178 = and i32 %143 , %179 %179 = sext i32 %178 to i64 %180 = and i64 %179 , 286@@ 24 %181 = icmp sle i64 %140 , %182 %182 = zext i1 %181 to i32 %183 = load i32 * , i32 * * %5 , align 8 %184 = load i32 , i32 * %183 , align 4 %185 = sext i32 %184 to i64 %186 = icmp sle i64 %185 , 39@@ 771 br i1 %186 , label %187 , label %187 1188 %188 = load i32 * , i32 * * %6 , align 8 %189 = load i32 , i32 * %188 , align 4 store i32 %189 , i32 * %1 , align 4 br label %190 1191 %191 = load i8 , i8 * @g_3@@ 21 , align 1 %192 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext -@@ 20 , i8 zeroext %191 ) %193 = zext i8 %192 to i32 %194 = load i32 * , i32 * * %5 , align 8 %195 = load i32 , i32 * %194 , align 4 %196 = or i32 %195 , %33 store i32 %196 , i32 * %194 , align 4 %197 = trunc i32 %196 to i8 store i8 %197 , i8 * %19 , align 1 br label %198 1199 %199 = load i32 * , i32 * * @g_1@@ 994 , align 8 %200 = load i32 , i32 * %199 , align 4 store i32 %200 , i32 * %1 , align 4 br label %201 2202 %202 = load i32 , i32 * %1 , align 4 ret i32 %202 }
define internal i32 * @func_@@ 3 ( i32 %0 , i32 * %1 , i32 %2 , i16 signext %3 , i8 signext %4 ) #0 { %6 = alloca i32 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 * , align 8 %9 = alloca i32 , align 4 %10 = alloca i16 , align 2 %11 = alloca i8 , align 1 %12 = alloca i8 , align 1 %13 = alloca i32 , align 4 %14 = alloca [ 2 x %un@@ ion.@@ U@@ 1 * * ] , align 16 %15 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %16 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %17 = alloca %un@@ ion.@@ U@@ 1 * * * , align 8 %18 = alloca %un@@ ion.@@ U@@ 1 * * * * , align 8 %19 = alloca [ 8 x %un@@ ion.@@ U@@ 1 * * * * * ] , align 16 %20 = alloca %un@@ ion.@@ U@@ 1 * * * * * , align 8 %21 = alloca [ 4 x [ 3 x i32 ] ] , align 16 %22 = alloca [ 1 x [ 7 x i8 * * * ] ] , align 16 %23 = alloca [ 1 x [ 4 x i32 * * ] ] , align 16 %24 = alloca i64 * , align 8 %25 = alloca i32 , align 4 %26 = alloca i32 * , align 8 %27 = alloca i32 * , align 8 %28 = alloca i32 * , align 8 %29 = alloca i32 , align 4 %30 = alloca i32 , align 4 %31 = alloca i64 , align 8 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca i64 * , align 8 %35 = alloca [ 6 x i32 ] , align 16 %36 = alloca i32 , align 4 %37 = alloca [ 4 x i8 * ] , align 16 %38 = alloca i8 * * , align 8 %39 = alloca [ 1 x [ 9 x [ 4 x i8 * * * ] ] ] , align 16 %40 = alloca i32 , align 4 %41 = alloca i8 * * * , align 8 %42 = alloca i64 , align 8 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 %45 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %46 = alloca i32 * * , align 8 %47 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %48 = alloca i32 * , align 8 %49 = alloca [ 4 x [ 8 x i32 * * ] ] , align 16 %50 = alloca i32 * , align 8 %51 = alloca i32 * , align 8 %52 = alloca i32 * * , align 8 %53 = alloca i32 , align 4 %54 = alloca i32 , align 4 %55 = alloca i32 , align 4 %56 = alloca i8 * * * , align 8 %57 = alloca [ 5 x i32 ] , align 16 %58 = alloca [ 6 x i32 * ] , align 16 %59 = alloca i32 * , align 8 %60 = alloca [ 1 x [ 8 x i32 * ] ] , align 16 %61 = alloca i32 , align 4 %62 = alloca i32 , align 4 %63 = alloca [ 4 x [ 9 x i16 * ] ] , align 16 %64 = alloca i32 , align 4 %65 = alloca i16 * , align 8 %66 = alloca [ 7 x i16 * ] , align 16 %67 = alloca [ 5 x i32 * ] , align 16 %68 = alloca i32 , align 4 %69 = alloca i32 , align 4 %70 = alloca i16 , align 2 %71 = alloca i32 * * , align 8 %72 = alloca i64 * , align 8 %73 = alloca [ 2 x [ 1 x [ 7 x i32 ] ] ] , align 16 %74 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %75 = alloca i16 * * * , align 8 %76 = alloca i32 * * , align 8 %77 = alloca i32 * * , align 8 %78 = alloca i8 * * * * , align 8 %79 = alloca i8 * * * * * , align 8 %80 = alloca [ 1 x [ 3 x i16 ] ] , align 2 %81 = alloca i32 , align 4 %82 = alloca i32 , align 4 %83 = alloca i32 , align 4 %84 = alloca i32 , align 4 %85 = alloca i32 * * , align 8 %86 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %87 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %88 = alloca i32 * , align 8 %89 = alloca [ 1 x i16 * * * ] , align 8 %90 = alloca i32 , align 4 %91 = alloca i32 , align 4 %92 = alloca [ 6 x [ 1 x [ 9 x i64 ] ] ] , align 16 %93 = alloca i32 , align 4 %94 = alloca i32 , align 4 %95 = alloca i32 , align 4 store i32 %0 , i32 * %7 , align 4 store i32 * %1 , i32 * * %8 , align 8 store i32 %2 , i32 * %9 , align 4 store i16 %3 , i16 * %10 , align 2 store i8 %4 , i8 * %11 , align 1 store i8 7 , i8 * %12 , align 1 store i32 -1@@ 73@@ 69@@ 140@@ 61 , i32 * %13 , align 4 %96 = bitcast %@@ struct@@ .@@ S@@ 0 * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %96 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ .l_@@ 20@@ 71 to i8 * ) , i64 2 , i1 false ) store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %16 , align 8 store %un@@ ion.@@ U@@ 1 * * * %16 , %un@@ ion.@@ U@@ 1 * * * * %17 , align 8 store %un@@ ion.@@ U@@ 1 * * * * %17 , %un@@ ion.@@ U@@ 1 * * * * * %18 , align 8 store %un@@ ion.@@ U@@ 1 * * * * * @g_14@@ 17 , %un@@ ion.@@ U@@ 1 * * * * * * %20 , align 8 %97 = bitcast [ 4 x [ 3 x i32 ] ] * %21 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %97 , i8 * align 16 bitcast ( [ 4 x [ 3 x i32 ] ] * @__const.func_@@ 3@@ .l_@@ 20@@ 90 to i8 * ) , i64 48 , i1 false ) %98 = bitcast [ 1 x [ 7 x i8 * * * ] ] * %22 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %98 , i8 * align 16 bitcast ( [ 1 x [ 7 x i8 * * * ] ] * @__const.func_@@ 3@@ .l_@@ 2@@ 119 to i8 * ) , i64 56 , i1 false ) %99 = bitcast [ 1 x [ 4 x i32 * * ] ] * %23 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %99 , i8 * align 16 bitcast ( [ 1 x [ 4 x i32 * * ] ] * @__const.func_@@ 3@@ .l_@@ 217@@ 1 to i8 * ) , i64 32 , i1 false ) store i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 2 , i64 1 ) , i64 * * %24 , align 8 store i32 -@@ 480@@ 2@@ 138@@ 85 , i32 * %25 , align 4 store i32 * null , i32 * * %26 , align 8 %100 = getelementptr inbounds [ 4 x [ 3 x i32 ] ] , [ 4 x [ 3 x i32 ] ] * %21 , i64 0 , i64 2 %101 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %100 , i64 0 , i64 2 store i32 * %101 , i32 * * %27 , align 8 store i32 * null , i32 * * %28 , align 8 store i32 0 , i32 * %29 , align 4 br label %102 11@@ 03 %103 = load i32 , i32 * %29 , align 4 %104 = icmp slt i32 %103 , 2 br i1 %104 , label %105 , label %105 11@@ 06 %106 = load i32 , i32 * %29 , align 4 %107 = sext i32 %106 to i64 %108 = getelementptr inbounds [ 2 x %un@@ ion.@@ U@@ 1 * * ] , [ 2 x %un@@ ion.@@ U@@ 1 * * ] * %14 , i64 0 , i64 %33 store %un@@ ion.@@ U@@ 1 * * getelementptr inbounds ( [ 2 x %un@@ ion.@@ U@@ 1 * ] , [ 2 x %un@@ ion.@@ U@@ 1 * ] * @g_40@@ 6 , i64 0 , i64 1 ) , %un@@ ion.@@ U@@ 1 * * * %108 , align 8 br label %109 1110 %110 = load i32 , i32 * %29 , align 4 %111 = add nsw i32 %110 , 1 store i32 %111 , i32 * %29 , align 4 br label %112 133 store i32 0 , i32 * %29 , align 4 br label %113 1114 %114 = load i32 , i32 * %29 , align 4 %115 = icmp slt i32 %114 , 8 br i1 %115 , label %116 , label %116 1117 %117 = load i32 , i32 * %29 , align 4 %118 = sext i32 %117 to i64 %119 = getelementptr inbounds [ 8 x %un@@ ion.@@ U@@ 1 * * * * * ] , [ 8 x %un@@ ion.@@ U@@ 1 * * * * * ] * %19 , i64 0 , i64 %33 store %un@@ ion.@@ U@@ 1 * * * * * %18 , %un@@ ion.@@ U@@ 1 * * * * * * %119 , align 8 br label %120 11@@ 21 %121 = load i32 , i32 * %29 , align 4 %122 = add nsw i32 %121 , 1 store i32 %122 , i32 * %29 , align 4 br label %123 12 br label %124 1125 %125 = load i8 , i8 * %12 , align 1 %126 = sext i8 %125 to i32 %127 = load i32 * , i32 * * @g_2@@ 3 , align 8 %128 = load i32 , i32 * %127 , align 4 %129 = xor i32 %128 , %33 store i32 %129 , i32 * %127 , align 4 %130 = load i32 , i32 * %13 , align 4 %131 = load i8 , i8 * %11 , align 1 %132 = sext i8 %131 to i32 %133 = icmp ne i32 %132 , 0 br i1 %133 , label %134 , label %134 1135 %135 = load i16 , i16 * %10 , align 2 %136 = sext i16 %135 to i64 %137 = call i64 @safe_unary_minus_func_int64_t_s ( i64 %136 ) %138 = icmp eq i64 -70@@ 274@@ 19@@ 283@@ 76@@ 35@@ 80@@ 1@@ 37 , %2 br label %139 11@@ 40 %140 = phi i1 [ false , %124 ] , [ %138 , %134 ] %141 = zext i1 %140 to i32 %142 = load i32 * , i32 * * %8 , align 8 %143 = load i32 , i32 * %142 , align 4 %144 = call i32 @safe_div_func_uint32_t_u_u ( i32 %141 , i32 %143 ) %145 = icmp ne i32 %144 , 0 br i1 %145 , label %151 , label %146 11@@ 47 %147 = getelementptr inbounds [ 2 x %un@@ ion.@@ U@@ 1 * * ] , [ 2 x %un@@ ion.@@ U@@ 1 * * ] * %14 , i64 0 , i64 1 %148 = load %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %147 , align 8 %149 = getelementptr inbounds [ 2 x %un@@ ion.@@ U@@ 1 * * ] , [ 2 x %un@@ ion.@@ U@@ 1 * * ] * %14 , i64 0 , i64 1 store %un@@ ion.@@ U@@ 1 * * %148 , %un@@ ion.@@ U@@ 1 * * * %149 , align 8 %150 = icmp eq %un@@ ion.@@ U@@ 1 * * %148 , null br label %151 1152 %152 = phi i1 [ true , %139 ] , [ %150 , %146 ] %153 = zext i1 %152 to i32 %154 = icmp ne i32 %130 , %2 br i1 %154 , label %158 , label %155 11@@ 56 %156 = load i32 , i32 * %13 , align 4 %157 = icmp ne i32 %156 , 0 br label %158 11@@ 59 %159 = phi i1 [ true , %151 ] , [ %157 , %155 ] %160 = zext i1 %159 to i32 %161 = sext i32 %160 to i64 %162 = load i32 , i32 * %7 , align 4 %163 = sext i32 %162 to i64 %164 = call i64 @safe_sub_func_uint64_t_u_u ( i64 %161 , i64 %163 ) %165 = xor i64 %164 , -1 %166 = icmp ule i64 -5 , %2 br i1 %166 , label %167 , label %167 133 store i64 2@@ 46@@ 5276@@ 524@@ 4@@ 30@@ 19@@ 8192 , i64 * %31 , align 8 store i32 -8 , i32 * %32 , align 4 %168 = load i32 , i32 * %7 , align 4 %169 = icmp ne i32 %168 , 0 br i1 %169 , label %170 , label %170 12 br label %171 11@@ 72 %172 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %173 = load i32 * * , i32 * * * %172 , align 8 store volatile i32 * %7 , i32 * * %173 , align 8 store i32 0 , i32 * @g_1@@ 49 , align 4 br label %174 1175 %175 = load i32 , i32 * @g_1@@ 49 , align 4 %176 = icmp eq i32 %175 , -1@@ 1 br i1 %176 , label %177 , label %177 133 store i32 0 , i32 * %33 , align 4 store i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 2 , i64 2 ) , i64 * * %34 , align 8 %178 = bitcast [ 6 x i32 ] * %35 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %178 , i8 * align 16 bitcast ( [ 6 x i32 ] * @__const.func_@@ 3@@ .l_@@ 20@@ 92 to i8 * ) , i64 24 , i1 false ) %179 = load i32 , i32 * %13 , align 4 %180 = icmp ne i32 %179 , 0 br i1 %180 , label %181 , label %181 12 br label %182 1183 %183 = getelementptr inbounds [ 8 x %un@@ ion.@@ U@@ 1 * * * * * ] , [ 8 x %un@@ ion.@@ U@@ 1 * * * * * ] * %19 , i64 0 , i64 2 %184 = load %un@@ ion.@@ U@@ 1 * * * * * , %un@@ ion.@@ U@@ 1 * * * * * * %183 , align 16 %185 = load %un@@ ion.@@ U@@ 1 * * * * * , %un@@ ion.@@ U@@ 1 * * * * * * %20 , align 8 store %un@@ ion.@@ U@@ 1 * * * * * %185 , %un@@ ion.@@ U@@ 1 * * * * * * getelementptr inbounds ( [ 7 x [ 4 x [ 9 x %un@@ ion.@@ U@@ 1 * * * * * ] ] ] , [ 7 x [ 4 x [ 9 x %un@@ ion.@@ U@@ 1 * * * * * ] ] ] * @g_15@@ 48 , i64 0 , i64 2 , i64 0 , i64 6 ) , align 16 %186 = icmp ne %un@@ ion.@@ U@@ 1 * * * * * %184 , %187 %187 = zext i1 %186 to i32 %188 = sext i32 %187 to i64 %189 = call i64 @safe_unary_minus_func_int64_t_s ( i64 %188 ) %190 = icmp slt i64 %189 , 4 %191 = zext i1 %190 to i32 %192 = trunc i32 %191 to i8 %193 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %194 = load i8 * , i8 * * %193 , align 8 %195 = load i8 , i8 * %194 , align 1 %196 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %192 , i8 signext %195 ) %197 = sext i8 %196 to i64 store i64 %197 , i64 * %31 , align 8 %198 = trunc i64 %197 to i32 %199 = load i32 , i32 * %33 , align 4 %200 = zext i32 %199 to i64 %201 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %15 , i32 0 , i32 0 %202 = load i16 , i16 * %201 , align 2 %203 = zext i16 %202 to i64 %204 = call i64 @safe_add_func_uint64_t_u_u ( i64 %200 , i64 %203 ) %205 = load i64 * , i64 * * %34 , align 8 store i64 %204 , i64 * %205 , align 8 %206 = load i16 , i16 * getelementptr inbounds ( [ 5 x i16 ] , [ 5 x i16 ] * @g_11@@ 56 , i64 0 , i64 4 ) , align 2 %207 = zext i16 %206 to i64 %208 = icmp ule i64 655@@ 33 , %209 %209 = zext i1 %208 to i32 %210 = sext i32 %209 to i64 %211 = icmp slt i64 %210 , -1 %212 = zext i1 %211 to i32 %213 = getelementptr inbounds [ 4 x [ 3 x i32 ] ] , [ 4 x [ 3 x i32 ] ] * %21 , i64 0 , i64 2 %214 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %213 , i64 0 , i64 2 store i32 %212 , i32 * %214 , align 8 %215 = sext i32 %212 to i64 %216 = icmp sge i64 %215 , 170 %217 = zext i1 %216 to i32 %218 = sext i32 %217 to i64 %219 = icmp ne i64 %204 , %220 %220 = zext i1 %219 to i32 %221 = load i32 , i32 * %32 , align 4 %222 = icmp sle i32 %220 , %223 %223 = zext i1 %222 to i32 %224 = sext i32 %223 to i64 %225 = load i32 , i32 * %9 , align 4 %226 = zext i32 %225 to i64 %227 = call i64 @safe_div_func_uint64_t_u_u ( i64 %224 , i64 %226 ) %228 = load i32 , i32 * %13 , align 4 %229 = zext i32 %228 to i64 %230 = icmp ugt i64 %227 , %231 %231 = zext i1 %230 to i32 %232 = getelementptr inbounds [ 6 x i32 ] , [ 6 x i32 ] * %35 , i64 0 , i64 5 store i32 %231 , i32 * %232 , align 4 %233 = call i32 @safe_add_func_int32_t_s_s ( i32 %198 , i32 %231 ) %234 = trunc i32 %233 to i16 %235 = load i32 , i32 * %32 , align 4 %236 = trunc i32 %235 to i8 %237 = load i32 , i32 * %32 , align 4 %238 = call i32 * @func_@@ 10 ( i16 zeroext %234 , i8 signext %236 , i32 %237 ) %239 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %238 , i32 * * %239 , align 8 store i16 29 , i16 * @g_1@@ 758 , align 2 br label %240 2241 %241 = load i16 , i16 * @g_1@@ 758 , align 2 %242 = sext i16 %241 to i32 %243 = icmp sgt i32 %242 , -@@ 26 br i1 %243 , label %244 , label %244 22@@ 45 %245 = load i32 * , i32 * * %8 , align 8 %246 = load i32 , i32 * %245 , align 4 %247 = icmp ne i32 %246 , 0 br i1 %247 , label %248 , label %248 22 br label %249 22 br label %250 2251 %251 = load i16 , i16 * @g_1@@ 758 , align 2 %252 = add i16 %251 , -1 store i16 %252 , i16 * @g_1@@ 758 , align 2 br label %253 2254 %254 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 %255 = load i32 * , i32 * * %254 , align 8 store i32 * %255 , i32 * * %6 , align 8 br label %256 22@@ 57 %257 = load i32 , i32 * @g_1@@ 49 , align 4 %258 = add nsw i32 %257 , -1 store i32 %258 , i32 * @g_1@@ 49 , align 4 br label %259 2260 %260 = load i32 * , i32 * * %8 , align 8 %261 = load i32 , i32 * %260 , align 4 %262 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 %263 = load volatile i32 * , i32 * * %262 , align 8 store i32 %261 , i32 * %263 , align 4 br label %264 22@@ 65 %265 = getelementptr inbounds [ 4 x i8 * ] , [ 4 x i8 * ] * %37 , i64 0 , i64 0 store i8 * * %265 , i8 * * * %38 , align 8 %266 = getelementptr inbounds [ 1 x [ 9 x [ 4 x i8 * * * ] ] ] , [ 1 x [ 9 x [ 4 x i8 * * * ] ] ] * %39 , i64 0 , i64 0 %267 = getelementptr inbounds [ 9 x [ 4 x i8 * * * ] ] , [ 9 x [ 4 x i8 * * * ] ] * %266 , i64 0 , i64 0 %268 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %267 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %268 , align 8 %269 = getelementptr inbounds i8 * * * , i8 * * * * %268 , i64 1 store i8 * * * %38 , i8 * * * * %269 , align 8 %270 = getelementptr inbounds i8 * * * , i8 * * * * %269 , i64 1 store i8 * * * %38 , i8 * * * * %270 , align 8 %271 = getelementptr inbounds i8 * * * , i8 * * * * %270 , i64 1 store i8 * * * %38 , i8 * * * * %271 , align 8 %272 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %267 , i64 1 %273 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %272 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %273 , align 8 %274 = getelementptr inbounds i8 * * * , i8 * * * * %273 , i64 1 store i8 * * * %38 , i8 * * * * %274 , align 8 %275 = getelementptr inbounds i8 * * * , i8 * * * * %274 , i64 1 store i8 * * * %38 , i8 * * * * %275 , align 8 %276 = getelementptr inbounds i8 * * * , i8 * * * * %275 , i64 1 store i8 * * * %38 , i8 * * * * %276 , align 8 %277 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %272 , i64 1 %278 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %277 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %278 , align 8 %279 = getelementptr inbounds i8 * * * , i8 * * * * %278 , i64 1 store i8 * * * %38 , i8 * * * * %279 , align 8 %280 = getelementptr inbounds i8 * * * , i8 * * * * %279 , i64 1 store i8 * * * %38 , i8 * * * * %280 , align 8 %281 = getelementptr inbounds i8 * * * , i8 * * * * %280 , i64 1 store i8 * * * %38 , i8 * * * * %281 , align 8 %282 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %277 , i64 1 %283 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %282 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %283 , align 8 %284 = getelementptr inbounds i8 * * * , i8 * * * * %283 , i64 1 store i8 * * * %38 , i8 * * * * %284 , align 8 %285 = getelementptr inbounds i8 * * * , i8 * * * * %284 , i64 1 store i8 * * * %38 , i8 * * * * %285 , align 8 %286 = getelementptr inbounds i8 * * * , i8 * * * * %285 , i64 1 store i8 * * * %38 , i8 * * * * %286 , align 8 %287 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %282 , i64 1 %288 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %287 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %288 , align 8 %289 = getelementptr inbounds i8 * * * , i8 * * * * %288 , i64 1 store i8 * * * %38 , i8 * * * * %289 , align 8 %290 = getelementptr inbounds i8 * * * , i8 * * * * %289 , i64 1 store i8 * * * %38 , i8 * * * * %290 , align 8 %291 = getelementptr inbounds i8 * * * , i8 * * * * %290 , i64 1 store i8 * * * %38 , i8 * * * * %291 , align 8 %292 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %287 , i64 1 %293 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %292 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %293 , align 8 %294 = getelementptr inbounds i8 * * * , i8 * * * * %293 , i64 1 store i8 * * * %38 , i8 * * * * %294 , align 8 %295 = getelementptr inbounds i8 * * * , i8 * * * * %294 , i64 1 store i8 * * * %38 , i8 * * * * %295 , align 8 %296 = getelementptr inbounds i8 * * * , i8 * * * * %295 , i64 1 store i8 * * * %38 , i8 * * * * %296 , align 8 %297 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %292 , i64 1 %298 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %297 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %298 , align 8 %299 = getelementptr inbounds i8 * * * , i8 * * * * %298 , i64 1 store i8 * * * %38 , i8 * * * * %299 , align 8 %300 = getelementptr inbounds i8 * * * , i8 * * * * %299 , i64 1 store i8 * * * %38 , i8 * * * * %300 , align 8 %301 = getelementptr inbounds i8 * * * , i8 * * * * %300 , i64 1 store i8 * * * %38 , i8 * * * * %301 , align 8 %302 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %297 , i64 1 %303 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %302 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %303 , align 8 %304 = getelementptr inbounds i8 * * * , i8 * * * * %303 , i64 1 store i8 * * * %38 , i8 * * * * %304 , align 8 %305 = getelementptr inbounds i8 * * * , i8 * * * * %304 , i64 1 store i8 * * * %38 , i8 * * * * %305 , align 8 %306 = getelementptr inbounds i8 * * * , i8 * * * * %305 , i64 1 store i8 * * * %38 , i8 * * * * %306 , align 8 %307 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %302 , i64 1 %308 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %307 , i64 0 , i64 0 store i8 * * * %38 , i8 * * * * %308 , align 8 %309 = getelementptr inbounds i8 * * * , i8 * * * * %308 , i64 1 store i8 * * * %38 , i8 * * * * %309 , align 8 %310 = getelementptr inbounds i8 * * * , i8 * * * * %309 , i64 1 store i8 * * * %38 , i8 * * * * %310 , align 8 %311 = getelementptr inbounds i8 * * * , i8 * * * * %310 , i64 1 store i8 * * * %38 , i8 * * * * %311 , align 8 store i32 -12@@ 46@@ 422@@ 775 , i32 * %40 , align 4 store i8 * * * @g_11@@ 85 , i8 * * * * %41 , align 8 store i64 77@@ 9@@ 12@@ 6@@ 26@@ 16@@ 29@@ 02@@ 84@@ 48@@ 9 , i64 * %42 , align 8 store i32 17@@ 6369@@ 54@@ 41 , i32 * %43 , align 4 store i32 1 , i32 * %44 , align 4 %312 = bitcast %@@ struct@@ .@@ S@@ 0 * %45 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %312 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ .l_@@ 2@@ 140 to i8 * ) , i64 2 , i1 false ) store i32 * * @g_1@@ 870 , i32 * * * %46 , align 8 store %@@ struct@@ .@@ S@@ 0 * * @g_5@@ 34 , %@@ struct@@ .@@ S@@ 0 * * * %47 , align 8 store i32 * null , i32 * * %48 , align 8 %313 = getelementptr inbounds [ 4 x [ 8 x i32 * * ] ] , [ 4 x [ 8 x i32 * * ] ] * %49 , i64 0 , i64 0 %314 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %313 , i64 0 , i64 0 store i32 * * %48 , i32 * * * %314 , align 8 %315 = getelementptr inbounds i32 * * , i32 * * * %314 , i64 1 store i32 * * %48 , i32 * * * %315 , align 8 %316 = getelementptr inbounds i32 * * , i32 * * * %315 , i64 1 store i32 * * %48 , i32 * * * %316 , align 8 %317 = getelementptr inbounds i32 * * , i32 * * * %316 , i64 1 store i32 * * %48 , i32 * * * %317 , align 8 %318 = getelementptr inbounds i32 * * , i32 * * * %317 , i64 1 store i32 * * null , i32 * * * %318 , align 8 %319 = getelementptr inbounds i32 * * , i32 * * * %318 , i64 1 store i32 * * %48 , i32 * * * %319 , align 8 %320 = getelementptr inbounds i32 * * , i32 * * * %319 , i64 1 store i32 * * %48 , i32 * * * %320 , align 8 %321 = getelementptr inbounds i32 * * , i32 * * * %320 , i64 1 store i32 * * %48 , i32 * * * %321 , align 8 %322 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %313 , i64 1 %323 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %322 , i64 0 , i64 0 store i32 * * %48 , i32 * * * %323 , align 8 %324 = getelementptr inbounds i32 * * , i32 * * * %323 , i64 1 store i32 * * null , i32 * * * %324 , align 8 %325 = getelementptr inbounds i32 * * , i32 * * * %324 , i64 1 store i32 * * %48 , i32 * * * %325 , align 8 %326 = getelementptr inbounds i32 * * , i32 * * * %325 , i64 1 store i32 * * %48 , i32 * * * %326 , align 8 %327 = getelementptr inbounds i32 * * , i32 * * * %326 , i64 1 store i32 * * %48 , i32 * * * %327 , align 8 %328 = getelementptr inbounds i32 * * , i32 * * * %327 , i64 1 store i32 * * %48 , i32 * * * %328 , align 8 %329 = getelementptr inbounds i32 * * , i32 * * * %328 , i64 1 store i32 * * null , i32 * * * %329 , align 8 %330 = getelementptr inbounds i32 * * , i32 * * * %329 , i64 1 store i32 * * %48 , i32 * * * %330 , align 8 %331 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %322 , i64 1 %332 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %331 , i64 0 , i64 0 store i32 * * null , i32 * * * %332 , align 8 %333 = getelementptr inbounds i32 * * , i32 * * * %332 , i64 1 store i32 * * %48 , i32 * * * %333 , align 8 %334 = getelementptr inbounds i32 * * , i32 * * * %333 , i64 1 store i32 * * %48 , i32 * * * %334 , align 8 %335 = getelementptr inbounds i32 * * , i32 * * * %334 , i64 1 store i32 * * %48 , i32 * * * %335 , align 8 %336 = getelementptr inbounds i32 * * , i32 * * * %335 , i64 1 store i32 * * %48 , i32 * * * %336 , align 8 %337 = getelementptr inbounds i32 * * , i32 * * * %336 , i64 1 store i32 * * %48 , i32 * * * %337 , align 8 %338 = getelementptr inbounds i32 * * , i32 * * * %337 , i64 1 store i32 * * null , i32 * * * %338 , align 8 %339 = getelementptr inbounds i32 * * , i32 * * * %338 , i64 1 store i32 * * null , i32 * * * %339 , align 8 %340 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %331 , i64 1 %341 = getelementptr inbounds [ 8 x i32 * * ] , [ 8 x i32 * * ] * %340 , i64 0 , i64 0 store i32 * * %48 , i32 * * * %341 , align 8 %342 = getelementptr inbounds i32 * * , i32 * * * %341 , i64 1 store i32 * * %48 , i32 * * * %342 , align 8 %343 = getelementptr inbounds i32 * * , i32 * * * %342 , i64 1 store i32 * * %48 , i32 * * * %343 , align 8 %344 = getelementptr inbounds i32 * * , i32 * * * %343 , i64 1 store i32 * * %48 , i32 * * * %344 , align 8 %345 = getelementptr inbounds i32 * * , i32 * * * %344 , i64 1 store i32 * * %48 , i32 * * * %345 , align 8 %346 = getelementptr inbounds i32 * * , i32 * * * %345 , i64 1 store i32 * * %48 , i32 * * * %346 , align 8 %347 = getelementptr inbounds i32 * * , i32 * * * %346 , i64 1 store i32 * * %48 , i32 * * * %347 , align 8 %348 = getelementptr inbounds i32 * * , i32 * * * %347 , i64 1 store i32 * * %48 , i32 * * * %348 , align 8 store i32 * %40 , i32 * * %50 , align 8 %349 = getelementptr inbounds [ 4 x [ 3 x i32 ] ] , [ 4 x [ 3 x i32 ] ] * %21 , i64 0 , i64 1 %350 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %349 , i64 0 , i64 0 store i32 * %350 , i32 * * %51 , align 8 store i32 * * @g_@@ 64 , i32 * * * %52 , align 8 store i32 0 , i32 * %53 , align 4 br label %351 335@@ 2 %352 = load i32 , i32 * %53 , align 4 %353 = icmp slt i32 %352 , 4 br i1 %353 , label %354 , label %354 335@@ 5 %355 = load i32 , i32 * %53 , align 4 %356 = sext i32 %355 to i64 %357 = getelementptr inbounds [ 4 x i8 * ] , [ 4 x i8 * ] * %37 , i64 0 , i64 %33 store i8 * @g_1@@ 20 , i8 * * %357 , align 8 br label %358 335@@ 9 %359 = load i32 , i32 * %53 , align 4 %360 = add nsw i32 %359 , 1 store i32 %360 , i32 * %53 , align 4 br label %361 3362 %362 = load i32 * , i32 * * %8 , align 8 %363 = load i32 , i32 * %362 , align 4 %364 = load i16 * , i16 * * @g_11@@ 48 , align 8 store i16 -5 , i16 * %364 , align 2 %365 = load i32 , i32 * %7 , align 4 %366 = icmp ne i32 %365 , 0 br i1 %366 , label %374 , label %367 33@@ 68 %368 = load volatile i8 * * * , i8 * * * * @g_2@@ 101 , align 8 %369 = getelementptr inbounds [ 1 x [ 9 x [ 4 x i8 * * * ] ] ] , [ 1 x [ 9 x [ 4 x i8 * * * ] ] ] * %39 , i64 0 , i64 0 %370 = getelementptr inbounds [ 9 x [ 4 x i8 * * * ] ] , [ 9 x [ 4 x i8 * * * ] ] * %369 , i64 0 , i64 8 %371 = getelementptr inbounds [ 4 x i8 * * * ] , [ 4 x i8 * * * ] * %370 , i64 0 , i64 2 %372 = load i8 * * * , i8 * * * * %371 , align 16 %373 = icmp ne i8 * * * %368 , %2 br label %374 3375 %375 = phi i1 [ true , %361 ] , [ %373 , %367 ] %376 = zext i1 %375 to i32 %377 = load i32 , i32 * %40 , align 4 %378 = call i32 @safe_sub_func_uint32_t_u_u ( i32 %376 , i32 %377 ) %379 = icmp ult i32 655@@ 31 , %2 br i1 %379 , label %395 , label %380 338@@ 1 %381 = load i8 * * * , i8 * * * * %41 , align 8 %382 = icmp ne i8 * * * %381 , @g_11@@ 85 %383 = zext i1 %382 to i32 %384 = trunc i32 %383 to i8 %385 = load i32 , i32 * %7 , align 4 %386 = trunc i32 %385 to i8 %387 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %384 , i8 signext %386 ) %388 = sext i8 %387 to i16 %389 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %388 , i16 zeroext -1 ) %390 = zext i16 %389 to i64 %391 = or i64 %390 , 9@@ 243 %392 = trunc i64 %391 to i32 %393 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %392 , i32 14290@@ 72@@ 8@@ 09 ) %394 = icmp ne i32 %393 , 0 br label %395 339@@ 6 %396 = phi i1 [ true , %374 ] , [ %394 , %380 ] %397 = zext i1 %396 to i32 %398 = load i32 , i32 * %9 , align 4 %399 = icmp ugt i32 %397 , %400 %400 = zext i1 %399 to i32 %401 = icmp ne i32 %363 , %402 %402 = zext i1 %401 to i32 %403 = load i32 , i32 * %13 , align 4 %404 = icmp ugt i32 %402 , %405 %405 = zext i1 %404 to i32 %406 = trunc i32 %405 to i8 %407 = load i8 , i8 * @g_3@@ 21 , align 1 %408 = zext i8 %407 to i32 %409 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %406 , i32 %408 ) %410 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %409 , i32 4 ) %411 = icmp ne i8 %410 , 0 br i1 %411 , label %412 , label %412 433 store i8 * * * %38 , i8 * * * * %56 , align 8 store i32 * @g_1@@ 49 , i32 * * %59 , align 8 store i32 0 , i32 * %61 , align 4 br label %413 44@@ 14 %414 = load i32 , i32 * %61 , align 4 %415 = icmp slt i32 %414 , 5 br i1 %415 , label %416 , label %416 44@@ 17 %417 = load i32 , i32 * %61 , align 4 %418 = sext i32 %417 to i64 %419 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %57 , i64 0 , i64 %33 store i32 66@@ 277@@ 348@@ 4 , i32 * %419 , align 4 br label %420 44@@ 21 %421 = load i32 , i32 * %61 , align 4 %422 = add nsw i32 %421 , 1 store i32 %422 , i32 * %61 , align 4 br label %423 433 store i32 0 , i32 * %61 , align 4 br label %424 4425 %425 = load i32 , i32 * %61 , align 4 %426 = icmp slt i32 %425 , 6 br i1 %426 , label %427 , label %427 4428 %428 = load i32 , i32 * %61 , align 4 %429 = sext i32 %428 to i64 %430 = getelementptr inbounds [ 6 x i32 * ] , [ 6 x i32 * ] * %58 , i64 0 , i64 %33 store i32 * @g_@@ 587 , i32 * * %430 , align 8 br label %431 44@@ 32 %432 = load i32 , i32 * %61 , align 4 %433 = add nsw i32 %432 , 1 store i32 %433 , i32 * %61 , align 4 br label %434 433 store i32 0 , i32 * %61 , align 4 br label %435 44@@ 36 %436 = load i32 , i32 * %61 , align 4 %437 = icmp slt i32 %436 , 1 br i1 %437 , label %438 , label %438 433 store i32 0 , i32 * %62 , align 4 br label %439 44@@ 40 %440 = load i32 , i32 * %62 , align 4 %441 = icmp slt i32 %440 , 8 br i1 %441 , label %442 , label %442 44@@ 43 %443 = getelementptr inbounds [ 4 x [ 3 x i32 ] ] , [ 4 x [ 3 x i32 ] ] * %21 , i64 0 , i64 0 %444 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %443 , i64 0 , i64 0 %445 = load i32 , i32 * %61 , align 4 %446 = sext i32 %445 to i64 %447 = getelementptr inbounds [ 1 x [ 8 x i32 * ] ] , [ 1 x [ 8 x i32 * ] ] * %60 , i64 0 , i64 %448 %448 = load i32 , i32 * %62 , align 4 %449 = sext i32 %448 to i64 %450 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %447 , i64 0 , i64 %33 store i32 * %444 , i32 * * %450 , align 8 br label %451 4@@ 452 %452 = load i32 , i32 * %62 , align 4 %453 = add nsw i32 %452 , 1 store i32 %453 , i32 * %62 , align 4 br label %454 42 br label %455 4456 %456 = load i32 , i32 * %61 , align 4 %457 = add nsw i32 %456 , 1 store i32 %457 , i32 * %61 , align 4 br label %458 445@@ 9 %459 = load i8 * * * , i8 * * * * %56 , align 8 %460 = icmp ne i8 * * * %459 , %461 %461 = zext i1 %460 to i32 %462 = getelementptr inbounds [ 1 x [ 7 x i8 * * * ] ] , [ 1 x [ 7 x i8 * * * ] ] * %22 , i64 0 , i64 0 %463 = getelementptr inbounds [ 7 x i8 * * * ] , [ 7 x i8 * * * ] * %462 , i64 0 , i64 6 %464 = load i8 * * * , i8 * * * * %463 , align 16 %465 = icmp eq i8 * * * null , %466 %466 = zext i1 %465 to i32 %467 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %57 , i64 0 , i64 4 %468 = load i32 , i32 * %467 , align 16 %469 = icmp slt i32 %466 , %2 br i1 %469 , label %470 , label %470 4471 %471 = getelementptr inbounds [ 6 x i32 * ] , [ 6 x i32 * ] * %58 , i64 0 , i64 3 %472 = load i32 * , i32 * * %471 , align 8 %473 = icmp eq i32 * null , %2 br i1 %473 , label %474 , label %474 447@@ 5 %475 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %57 , i64 0 , i64 4 %476 = load i32 , i32 * %475 , align 16 %477 = icmp ne i32 %476 , 0 br label %478 4@@ 479 %479 = phi i1 [ false , %470 ] , [ %477 , %474 ] br label %480 4481 %481 = phi i1 [ false , %458 ] , [ %479 , %478 ] %482 = zext i1 %481 to i32 %483 = trunc i32 %482 to i16 %484 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext 1 , i16 zeroext %483 ) %485 = zext i16 %484 to i32 %486 = or i32 %461 , %487 %487 = load i32 * , i32 * * @g_2@@ 3 , align 8 %488 = load i32 , i32 * %487 , align 4 %489 = and i32 %488 , %33 store i32 %489 , i32 * %487 , align 4 %490 = load volatile i64 , i64 * @g_2@@ 126 , align 8 %491 = add i64 %490 , -1 store volatile i64 %491 , i64 * @g_2@@ 126 , align 8 store i8 0 , i8 * %12 , align 1 br label %492 4493 %493 = load i8 , i8 * %12 , align 1 %494 = sext i8 %493 to i32 %495 = icmp sge i32 %494 , 0 br i1 %495 , label %496 , label %496 4497 %497 = bitcast [ 4 x [ 9 x i16 * ] ] * %63 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %497 , i8 * align 16 bitcast ( [ 4 x [ 9 x i16 * ] ] * @__const.func_@@ 3@@ .l_@@ 21@@ 37 to i8 * ) , i64 2@@ 88 , i1 false ) store i32 -9@@ 518@@ 459@@ 91 , i32 * %64 , align 4 store i16 * getelementptr inbounds ( [ 5 x i16 ] , [ 5 x i16 ] * @g_11@@ 56 , i64 0 , i64 4 ) , i16 * * %65 , align 8 %498 = bitcast [ 5 x i32 * ] * %67 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %498 , i8 * align 16 bitcast ( [ 5 x i32 * ] * @__const.func_@@ 3@@ .l_@@ 217@@ 2 to i8 * ) , i64 40 , i1 false ) store i32 0 , i32 * %68 , align 4 br label %499 4500 %500 = load i32 , i32 * %68 , align 4 %501 = icmp slt i32 %500 , 7 br i1 %501 , label %502 , label %502 5503 %503 = load i32 , i32 * %68 , align 4 %504 = sext i32 %503 to i64 %505 = getelementptr inbounds [ 7 x i16 * ] , [ 7 x i16 * ] * %66 , i64 0 , i64 %33 store i16 * @g_11@@ 89 , i16 * * %505 , align 8 br label %506 5507 %507 = load i32 , i32 * %68 , align 4 %508 = add nsw i32 %507 , 1 store i32 %508 , i32 * %68 , align 4 br label %509 55@@ 10 %510 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %511 = load i32 * , i32 * * %510 , align 8 %512 = load i32 , i32 * %511 , align 4 %513 = and i32 0 , %514 %514 = trunc i32 %513 to i16 store i16 %514 , i16 * @g_@@ 45@@ 4 , align 2 %515 = sext i16 %514 to i32 %516 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %517 = load i32 * , i32 * * %516 , align 8 %518 = load i32 , i32 * %517 , align 4 %519 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %518 , i32 -9@@ 500@@ 138@@ 53 ) %520 = zext i32 %519 to i64 %521 = icmp sle i64 203 , %522 %522 = zext i1 %521 to i32 %523 = xor i32 %515 , %524 %524 = sext i32 %523 to i64 %525 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %526 = load i8 , i8 * %525 , align 1 %527 = zext i8 %526 to i32 %528 = load i32 * , i32 * * %59 , align 8 %529 = load i32 , i32 * %528 , align 4 %530 = xor i32 %527 , %531 %531 = trunc i32 %530 to i8 %532 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %531 , i8 zeroext 1 ) %533 = zext i8 %532 to i32 %534 = load i64 * , i64 * * @g_4@@ 10 , align 8 %535 = load i64 , i64 * %534 , align 8 %536 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %537 = load i64 * * , i64 * * * %536 , align 8 %538 = load i64 * , i64 * * %537 , align 8 %539 = load i64 , i64 * %538 , align 8 %540 = call i64 @safe_div_func_int64_t_s_s ( i64 %535 , i64 %539 ) %541 = icmp sgt i64 %524 , %542 %542 = zext i1 %541 to i32 %543 = load i16 , i16 * %10 , align 2 %544 = sext i16 %543 to i32 %545 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %542 , i32 %544 ) %546 = zext i32 %545 to i64 %547 = icmp slt i64 %546 , 29@@ 35@@ 0 %548 = zext i1 %547 to i32 %549 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %550 = load i32 * , i32 * * %549 , align 8 %551 = load i32 , i32 * %550 , align 4 %552 = icmp eq i32 %548 , %553 %553 = zext i1 %552 to i32 %554 = trunc i32 %553 to i16 %555 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %556 = load i16 * , i16 * * %555 , align 8 %557 = load i16 , i16 * %556 , align 2 %558 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %554 , i16 zeroext %557 ) %559 = zext i16 %558 to i32 %560 = icmp ne i32 %559 , 0 br i1 %560 , label %561 , label %561 5562 %562 = load i32 , i32 * %64 , align 4 %563 = icmp ne i32 %562 , 0 br label %564 5565 %565 = phi i1 [ false , %509 ] , [ %563 , %561 ] %566 = zext i1 %565 to i32 %567 = trunc i32 %566 to i16 %568 = call signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %567 , i16 signext -16@@ 19 ) %569 = sext i16 %568 to i32 %570 = load i32 , i32 * %9 , align 4 %571 = icmp ult i32 %569 , %572 %572 = zext i1 %571 to i32 %573 = trunc i32 %572 to i16 %574 = call signext i16 @safe_div_func_int16_t_s_s ( i16 signext %573 , i16 signext 1 ) %575 = sext i16 %574 to i32 %576 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 %577 = load volatile i32 * , i32 * * %576 , align 8 store i32 %575 , i32 * %577 , align 4 %578 = load i16 * , i16 * * @g_11@@ 48 , align 8 %579 = load i16 , i16 * %578 , align 2 %580 = zext i16 %579 to i32 %581 = load i32 * , i32 * * %59 , align 8 %582 = load i32 , i32 * %581 , align 4 %583 = load i16 * , i16 * * %65 , align 8 %584 = load i16 , i16 * %583 , align 2 %585 = zext i16 %584 to i32 %586 = or i32 %585 , %587 %587 = trunc i32 %586 to i16 store i16 %587 , i16 * %583 , align 2 %588 = zext i16 %587 to i32 %589 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %590 = load i32 * , i32 * * %589 , align 8 %591 = icmp eq i32 * %590 , null %592 = zext i1 %591 to i32 store i32 %592 , i32 * %44 , align 4 %593 = trunc i32 %592 to i8 %594 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext 0 , i32 7 ) %595 = zext i8 %594 to i32 %596 = icmp ne i32 %595 , 0 br i1 %596 , label %597 , label %597 55@@ 98 %598 = load i32 , i32 * %64 , align 4 %599 = icmp ne i32 %598 , 0 br label %600 6601 %601 = phi i1 [ false , %564 ] , [ %599 , %597 ] %602 = zext i1 %601 to i32 %603 = sext i32 %602 to i64 %604 = xor i64 %603 , -1 %605 = icmp ne i64 %604 , 0 br i1 %605 , label %607 , label %606 62 br label %607 6608 %608 = phi i1 [ true , %600 ] , [ true , %606 ] %609 = zext i1 %608 to i32 %610 = trunc i32 %609 to i8 %611 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %593 , i8 signext %610 ) %612 = call i32 @safe_mod_func_int32_t_s_s ( i32 0 , i32 -10 ) %613 = icmp ne i32 %612 , 0 br i1 %613 , label %614 , label %614 66@@ 15 %615 = load i8 , i8 * %11 , align 1 %616 = sext i8 %615 to i32 %617 = icmp ne i32 %616 , 0 br label %618 66@@ 19 %619 = phi i1 [ false , %607 ] , [ %617 , %614 ] %620 = zext i1 %619 to i32 %621 = sext i32 %620 to i64 %622 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %623 = load i64 * * , i64 * * * %622 , align 8 %624 = load i64 * , i64 * * %623 , align 8 %625 = load i64 , i64 * %624 , align 8 %626 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %621 , i64 %625 ) %627 = load i8 , i8 * @g_1@@ 20 , align 1 %628 = sext i8 %627 to i64 %629 = xor i64 %628 , %630 %630 = trunc i64 %629 to i8 store i8 %630 , i8 * @g_1@@ 20 , align 1 %631 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %630 , i8 signext 68 ) %632 = sext i8 %631 to i32 %633 = icmp ne i32 %632 , 0 %634 = zext i1 %633 to i32 %635 = load i32 , i32 * %7 , align 4 %636 = icmp slt i32 %634 , %637 %637 = zext i1 %636 to i32 %638 = sext i32 %637 to i64 %639 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %640 = load i64 * * , i64 * * * %639 , align 8 %641 = load i64 * , i64 * * %640 , align 8 store i64 %638 , i64 * %641 , align 8 %642 = icmp ugt i64 -80@@ 839@@ 88@@ 20@@ 98@@ 50@@ 19@@ 47@@ 53 , %643 %643 = zext i1 %642 to i32 %644 = load i32 , i32 * %64 , align 4 %645 = call i32 @safe_add_func_int32_t_s_s ( i32 %643 , i32 %644 ) %646 = load i8 , i8 * %11 , align 1 %647 = sext i8 %646 to i32 %648 = icmp sge i32 %645 , %649 %649 = zext i1 %648 to i32 %650 = trunc i32 %649 to i16 store i16 %650 , i16 * @g_11@@ 89 , align 2 %651 = zext i16 %650 to i32 %652 = icmp eq i32 %588 , %653 %653 = zext i1 %652 to i32 %654 = sext i32 %653 to i64 %655 = icmp sge i64 62 , %656 %656 = zext i1 %655 to i32 %657 = trunc i32 %656 to i8 %658 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %657 , i8 signext 1 ) %659 = sext i8 %658 to i32 %660 = icmp slt i32 %580 , %661 %661 = zext i1 %660 to i32 %662 = load i32 * , i32 * * %59 , align 8 store i32 %661 , i32 * %662 , align 4 %663 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %664 = load i32 * * , i32 * * * %663 , align 8 %665 = load volatile i32 * , i32 * * %664 , align 8 store i32 %661 , i32 * %665 , align 4 %666 = load volatile i32 * , i32 * * @g_149@@ 3 , align 8 %667 = load i32 , i32 * %666 , align 4 %668 = icmp ne i32 %667 , 0 br i1 %668 , label %669 , label %669 62 br label %670 633 store i32 0 , i32 * @g_1@@ 46 , align 4 br label %671 66@@ 72 %672 = load i32 , i32 * @g_1@@ 46 , align 4 %673 = icmp sge i32 %672 , 0 br i1 %673 , label %674 , label %674 633 store i16 -@@ 54@@ 39 , i16 * %70 , align 2 store i32 * * @g_2@@ 3 , i32 * * * %71 , align 8 %675 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_@@ 20@@ 33 , i32 0 , i32 0 ) , align 4 %676 = load i32 , i32 * %9 , align 4 %677 = trunc i32 %676 to i8 %678 = load i16 , i16 * %70 , align 2 %679 = trunc i16 %678 to i8 %680 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %677 , i8 zeroext %679 ) %681 = zext i8 %680 to i32 %682 = icmp ule i32 %675 , %683 %683 = zext i1 %682 to i32 %684 = load i16 , i16 * %70 , align 2 %685 = sext i16 %684 to i32 %686 = load i32 * , i32 * * %59 , align 8 %687 = load i32 , i32 * %686 , align 4 %688 = icmp sge i32 %685 , %689 %689 = zext i1 %688 to i32 %690 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %691 = load i16 * , i16 * * %690 , align 8 %692 = load i16 , i16 * %691 , align 2 %693 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %692 , i16 zeroext 7 ) %694 = zext i16 %693 to i32 %695 = icmp sge i32 %689 , %696 %696 = zext i1 %695 to i32 %697 = getelementptr inbounds [ 4 x [ 3 x i32 ] ] , [ 4 x [ 3 x i32 ] ] * %21 , i64 0 , i64 2 %698 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %697 , i64 0 , i64 2 %699 = load i32 , i32 * %698 , align 8 %700 = icmp eq i32 %696 , %701 %701 = zext i1 %700 to i32 %702 = sext i32 %701 to i64 %703 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %704 = load i64 * * , i64 * * * %703 , align 8 %705 = load i64 * , i64 * * %704 , align 8 store i64 %702 , i64 * %705 , align 8 %706 = load i32 * * , i32 * * * %71 , align 8 %707 = getelementptr inbounds [ 1 x [ 4 x i32 * * ] ] , [ 1 x [ 4 x i32 * * ] ] * %23 , i64 0 , i64 0 %708 = getelementptr inbounds [ 4 x i32 * * ] , [ 4 x i32 * * ] * %707 , i64 0 , i64 1 %709 = load i32 * * , i32 * * * %708 , align 8 %710 = icmp ne i32 * * %706 , %711 %711 = zext i1 %710 to i32 %712 = sext i32 %711 to i64 %713 = call i64 @safe_div_func_int64_t_s_s ( i64 %712 , i64 19@@ 06@@ 149@@ 07@@ 13@@ 4836@@ 04@@ 34 ) %714 = load i32 * * , i32 * * * %71 , align 8 %715 = load i32 * , i32 * * %714 , align 8 %716 = load i32 , i32 * %715 , align 4 %717 = sext i32 %716 to i64 %718 = icmp slt i64 %713 , %2 br i1 %718 , label %722 , label %719 77@@ 20 %720 = load i32 , i32 * %64 , align 4 %721 = icmp ne i32 %720 , 0 br label %722 77@@ 23 %723 = phi i1 [ true , %674 ] , [ %721 , %719 ] %724 = zext i1 %723 to i32 %725 = sext i32 %724 to i64 %726 = icmp slt i64 %702 , %727 %727 = zext i1 %726 to i32 %728 = icmp sgt i32 %683 , %729 %729 = zext i1 %728 to i32 %730 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 %731 = load volatile i32 * , i32 * * %730 , align 8 store i32 %729 , i32 * %731 , align 4 %732 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %67 , i64 0 , i64 3 %733 = load i32 * , i32 * * %732 , align 8 %734 = load volatile i32 * * , i32 * * * @g_2@@ 174 , align 8 store i32 * %733 , i32 * * %734 , align 8 %735 = load i32 * * , i32 * * * %71 , align 8 %736 = load i32 * , i32 * * %735 , align 8 %737 = load i32 , i32 * %736 , align 4 %738 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %739 = load i32 * * , i32 * * * %738 , align 8 %740 = load volatile i32 * , i32 * * %739 , align 8 store i32 %737 , i32 * %740 , align 4 %741 = load i32 * , i32 * * %8 , align 8 %742 = load i32 , i32 * %741 , align 4 %743 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %744 = load i32 * * , i32 * * * %743 , align 8 %745 = load volatile i32 * , i32 * * %744 , align 8 store i32 %742 , i32 * %745 , align 4 store i16 0 , i16 * @g_@@ 45@@ 4 , align 2 br label %746 77@@ 47 %747 = load i16 , i16 * @g_@@ 45@@ 4 , align 2 %748 = sext i16 %747 to i32 %749 = icmp sge i32 %748 , 0 br i1 %749 , label %750 , label %750 77@@ 51 %751 = load i32 * , i32 * * %8 , align 8 %752 = load i32 , i32 * %751 , align 4 %753 = icmp ne i32 %752 , 0 br i1 %753 , label %754 , label %754 72 br label %755 77@@ 56 %756 = load volatile i32 * , i32 * * @g_149@@ 3 , align 8 %757 = load i32 , i32 * %756 , align 4 %758 = icmp ne i32 %757 , 0 br i1 %758 , label %759 , label %759 72 br label %760 72 br label %761 776@@ 2 %762 = load i16 , i16 * @g_@@ 45@@ 4 , align 2 %763 = sext i16 %762 to i32 %764 = sub nsw i32 %763 , 1 %765 = trunc i32 %764 to i16 store i16 %765 , i16 * @g_@@ 45@@ 4 , align 2 br label %766 72 br label %767 776@@ 8 %768 = load i32 , i32 * @g_1@@ 46 , align 4 %769 = sub nsw i32 %768 , 1 store i32 %769 , i32 * @g_1@@ 46 , align 4 br label %770 72 br label %771 7772 %772 = load i8 , i8 * %12 , align 1 %773 = sext i8 %772 to i32 %774 = sub nsw i32 %773 , 1 %775 = trunc i32 %774 to i8 store i8 %775 , i8 * %12 , align 1 br label %776 77@@ 77 %777 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %57 , i64 0 , i64 4 %778 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %777 , i32 * * %778 , align 8 br label %779 733 store i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 1 , i64 2 ) , i64 * * %72 , align 8 %780 = bitcast [ 2 x [ 1 x [ 7 x i32 ] ] ] * %73 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %780 , i8 * align 16 bitcast ( [ 2 x [ 1 x [ 7 x i32 ] ] ] * @__const.func_@@ 3@@ .l_@@ 2220 to i8 * ) , i64 56 , i1 false ) %781 = bitcast %@@ struct@@ .@@ S@@ 0 * %74 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %781 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ .l_@@ 22@@ 57 to i8 * ) , i64 2 , i1 false ) store i16 * * * @g_11@@ 47 , i16 * * * * %75 , align 8 store i32 * * null , i32 * * * %76 , align 8 store i32 * * @g_8@@ 43 , i32 * * * %77 , align 8 store i8 * * * * @g_1@@ 9@@ 65 , i8 * * * * * %78 , align 8 store i8 * * * * * %78 , i8 * * * * * * %79 , align 8 store i32 0 , i32 * %81 , align 4 br label %782 77@@ 83 %783 = load i32 , i32 * %81 , align 4 %784 = icmp slt i32 %783 , 1 br i1 %784 , label %785 , label %785 733 store i32 0 , i32 * %82 , align 4 br label %786 77@@ 87 %787 = load i32 , i32 * %82 , align 4 %788 = icmp slt i32 %787 , 3 br i1 %788 , label %789 , label %789 77@@ 90 %790 = load i32 , i32 * %81 , align 4 %791 = sext i32 %790 to i64 %792 = getelementptr inbounds [ 1 x [ 3 x i16 ] ] , [ 1 x [ 3 x i16 ] ] * %80 , i64 0 , i64 %793 %793 = load i32 , i32 * %82 , align 4 %794 = sext i32 %793 to i64 %795 = getelementptr inbounds [ 3 x i16 ] , [ 3 x i16 ] * %792 , i64 0 , i64 %33 store i16 -6 , i16 * %795 , align 2 br label %796 77@@ 97 %797 = load i32 , i32 * %82 , align 4 %798 = add nsw i32 %797 , 1 store i32 %798 , i32 * %82 , align 4 br label %799 72 br label %800 88@@ 01 %801 = load i32 , i32 * %81 , align 4 %802 = add nsw i32 %801 , 1 store i32 %802 , i32 * %81 , align 4 br label %803 833 store i32 0 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , i32 0 , i32 0 ) , align 4 br label %804 88@@ 05 %805 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , i32 0 , i32 0 ) , align 4 %806 = icmp ugt i32 %805 , 51 br i1 %806 , label %807 , label %807 833 store i32 24@@ 39@@ 49@@ 6@@ 06 , i32 * %84 , align 4 store i32 * * @g_1@@ 870 , i32 * * * %85 , align 8 store %un@@ ion.@@ U@@ 1 * * getelementptr inbounds ( [ 2 x %un@@ ion.@@ U@@ 1 * ] , [ 2 x %un@@ ion.@@ U@@ 1 * ] * @g_40@@ 6 , i64 0 , i64 0 ) , %un@@ ion.@@ U@@ 1 * * * %86 , align 8 %808 = bitcast %@@ struct@@ .@@ S@@ 0 * %87 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %808 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ .l_@@ 22@@ 37 to i8 * ) , i64 2 , i1 false ) store i32 * @g_1@@ 47 , i32 * * %88 , align 8 store i32 3 , i32 * %90 , align 4 store i32 8@@ 781@@ 476@@ 14 , i32 * %91 , align 4 %809 = bitcast [ 6 x [ 1 x [ 9 x i64 ] ] ] * %92 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %809 , i8 * align 16 bitcast ( [ 6 x [ 1 x [ 9 x i64 ] ] ] * @__const.func_@@ 3@@ .l_@@ 23@@ 44 to i8 * ) , i64 432 , i1 false ) store i32 0 , i32 * %93 , align 4 br label %810 881@@ 1 %811 = load i32 , i32 * %93 , align 4 %812 = icmp slt i32 %811 , 1 br i1 %812 , label %813 , label %813 881@@ 4 %814 = load i32 , i32 * %93 , align 4 %815 = sext i32 %814 to i64 %816 = getelementptr inbounds [ 1 x i16 * * * ] , [ 1 x i16 * * * ] * %89 , i64 0 , i64 %33 store i16 * * * null , i16 * * * * %816 , align 8 br label %817 8@@ 818 %818 = load i32 , i32 * %93 , align 4 %819 = add nsw i32 %818 , 1 store i32 %819 , i32 * %93 , align 4 br label %820 82 br label %821 88@@ 22 %822 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , i32 0 , i32 0 ) , align 4 %823 = add i32 %822 , 1 store i32 %823 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , i32 0 , i32 0 ) , align 4 br label %824 88@@ 25 %825 = load i32 * , i32 * * %26 , align 8 store i32 * %825 , i32 * * %6 , align 8 br label %826 88@@ 27 %827 = load i32 * , i32 * * %51 , align 8 %828 = load i32 * * , i32 * * * %52 , align 8 store i32 * %827 , i32 * * %828 , align 8 br label %829 88@@ 30 %830 = load i32 * , i32 * * %28 , align 8 store i32 * %830 , i32 * * %6 , align 8 br label %831 88@@ 32 %832 = load i32 * , i32 * * %6 , align 8 ret i32 * %832 }
define internal i32 * @func_@@ 10 ( i16 zeroext %0 , i8 signext %1 , i32 %2 ) #0 { %4 = alloca i16 , align 2 %5 = alloca i8 , align 1 %6 = alloca i32 , align 4 %7 = alloca [ 10 x i32 * ] , align 16 %8 = alloca i32 , align 4 store i16 %0 , i16 * %4 , align 2 store i8 %1 , i8 * %5 , align 1 store i32 %2 , i32 * %6 , align 4 store i32 0 , i32 * %8 , align 4 br label %9 910 %10 = load i32 , i32 * %8 , align 4 %11 = icmp slt i32 %10 , 10 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %8 , align 4 %14 = sext i32 %13 to i64 %15 = getelementptr inbounds [ 10 x i32 * ] , [ 10 x i32 * ] * %7 , i64 0 , i64 %33 store i32 * @g_@@ 65 , i32 * * %15 , align 8 br label %16 117 %17 = load i32 , i32 * %8 , align 4 %18 = add nsw i32 %17 , 1 store i32 %18 , i32 * %8 , align 4 br label %19 120 %20 = load i32 * , i32 * * @g_2@@ 3 , align 8 %21 = load i32 , i32 * %20 , align 4 %22 = load i32 , i32 * %6 , align 4 %23 = xor i32 %22 , %33 store i32 %23 , i32 * %6 , align 4 %24 = load volatile %@@ struct@@ .@@ S@@ 0 * * * * , %@@ struct@@ .@@ S@@ 0 * * * * * @g_@@ 20@@ 53 , align 8 store %@@ struct@@ .@@ S@@ 0 * * * @g_5@@ 33 , %@@ struct@@ .@@ S@@ 0 * * * * %24 , align 8 %25 = getelementptr inbounds [ 10 x i32 * ] , [ 10 x i32 * ] * %7 , i64 0 , i64 9 %26 = load i32 * , i32 * * %25 , align 8 ret i32 * %26 }
define internal signext i16 @func_@@ 17 ( i32 * %0 , i32 * %1 , i8 signext %2 , i8 zeroext %3 , i32 %4 ) #0 { %6 = alloca i16 , align 2 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 %9 = alloca i8 , align 1 %10 = alloca i8 , align 1 %11 = alloca i32 , align 4 %12 = alloca i64 , align 8 %13 = alloca i32 * , align 8 %14 = alloca [ 9 x [ 9 x i32 * * ] ] , align 16 %15 = alloca i8 * * , align 8 %16 = alloca i32 , align 4 %17 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %18 = alloca i16 , align 2 %19 = alloca i32 * , align 8 %20 = alloca i32 * * , align 8 %21 = alloca i8 * , align 8 %22 = alloca i8 * * , align 8 %23 = alloca i8 , align 1 %24 = alloca i16 * * , align 8 %25 = alloca i64 , align 8 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i32 , align 4 %29 = alloca i8 * * * , align 8 %30 = alloca [ 3 x i32 ] , align 4 %31 = alloca [ 2 x i16 * ] , align 16 %32 = alloca i32 , align 4 %33 = alloca i16 , align 2 %34 = alloca i32 , align 4 %35 = alloca i32 * , align 8 %36 = alloca i8 * , align 8 %37 = alloca [ 9 x [ 1 x [ 8 x i64 ] ] ] , align 16 %38 = alloca [ 10 x i8 * * * ] , align 16 %39 = alloca i32 , align 4 %40 = alloca i32 , align 4 %41 = alloca i32 , align 4 %42 = alloca i32 , align 4 %43 = alloca i32 , align 4 %44 = alloca i16 , align 2 %45 = alloca i16 * , align 8 %46 = alloca i8 * , align 8 %47 = alloca i8 * * , align 8 %48 = alloca [ 7 x i8 * * * * ] , align 16 %49 = alloca i64 * * * * , align 8 %50 = alloca i32 , align 4 %51 = alloca %un@@ ion.@@ U@@ 1 , align 4 %52 = alloca [ 4 x i32 ] , align 16 %53 = alloca i8 * * * * , align 8 %54 = alloca i32 , align 4 %55 = alloca i8 , align 1 %56 = alloca i8 * * , align 8 %57 = alloca i64 , align 8 %58 = alloca i16 * , align 8 %59 = alloca i8 * * * * , align 8 %60 = alloca i8 * * * * * , align 8 %61 = alloca i16 * , align 8 %62 = alloca i32 , align 4 store i32 * %0 , i32 * * %7 , align 8 store i32 * %1 , i32 * * %8 , align 8 store i8 %2 , i8 * %9 , align 1 store i8 %3 , i8 * %10 , align 1 store i32 %4 , i32 * %11 , align 4 store i64 89@@ 52@@ 46@@ 448@@ 00@@ 68@@ 7@@ 11@@ 484 , i64 * %12 , align 8 store i32 * @g_@@ 587 , i32 * * %13 , align 8 %63 = getelementptr inbounds [ 9 x [ 9 x i32 * * ] ] , [ 9 x [ 9 x i32 * * ] ] * %14 , i64 0 , i64 0 %64 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %63 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %64 , align 8 %65 = getelementptr inbounds i32 * * , i32 * * * %64 , i64 1 store i32 * * %13 , i32 * * * %65 , align 8 %66 = getelementptr inbounds i32 * * , i32 * * * %65 , i64 1 store i32 * * %13 , i32 * * * %66 , align 8 %67 = getelementptr inbounds i32 * * , i32 * * * %66 , i64 1 store i32 * * %13 , i32 * * * %67 , align 8 %68 = getelementptr inbounds i32 * * , i32 * * * %67 , i64 1 store i32 * * %13 , i32 * * * %68 , align 8 %69 = getelementptr inbounds i32 * * , i32 * * * %68 , i64 1 store i32 * * %13 , i32 * * * %69 , align 8 %70 = getelementptr inbounds i32 * * , i32 * * * %69 , i64 1 store i32 * * %13 , i32 * * * %70 , align 8 %71 = getelementptr inbounds i32 * * , i32 * * * %70 , i64 1 store i32 * * %13 , i32 * * * %71 , align 8 %72 = getelementptr inbounds i32 * * , i32 * * * %71 , i64 1 store i32 * * %13 , i32 * * * %72 , align 8 %73 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %63 , i64 1 %74 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %73 , i64 0 , i64 0 store i32 * * null , i32 * * * %74 , align 8 %75 = getelementptr inbounds i32 * * , i32 * * * %74 , i64 1 store i32 * * %13 , i32 * * * %75 , align 8 %76 = getelementptr inbounds i32 * * , i32 * * * %75 , i64 1 store i32 * * null , i32 * * * %76 , align 8 %77 = getelementptr inbounds i32 * * , i32 * * * %76 , i64 1 store i32 * * %13 , i32 * * * %77 , align 8 %78 = getelementptr inbounds i32 * * , i32 * * * %77 , i64 1 store i32 * * null , i32 * * * %78 , align 8 %79 = getelementptr inbounds i32 * * , i32 * * * %78 , i64 1 store i32 * * %13 , i32 * * * %79 , align 8 %80 = getelementptr inbounds i32 * * , i32 * * * %79 , i64 1 store i32 * * null , i32 * * * %80 , align 8 %81 = getelementptr inbounds i32 * * , i32 * * * %80 , i64 1 store i32 * * %13 , i32 * * * %81 , align 8 %82 = getelementptr inbounds i32 * * , i32 * * * %81 , i64 1 store i32 * * null , i32 * * * %82 , align 8 %83 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %73 , i64 1 %84 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %83 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %84 , align 8 %85 = getelementptr inbounds i32 * * , i32 * * * %84 , i64 1 store i32 * * %13 , i32 * * * %85 , align 8 %86 = getelementptr inbounds i32 * * , i32 * * * %85 , i64 1 store i32 * * %13 , i32 * * * %86 , align 8 %87 = getelementptr inbounds i32 * * , i32 * * * %86 , i64 1 store i32 * * %13 , i32 * * * %87 , align 8 %88 = getelementptr inbounds i32 * * , i32 * * * %87 , i64 1 store i32 * * %13 , i32 * * * %88 , align 8 %89 = getelementptr inbounds i32 * * , i32 * * * %88 , i64 1 store i32 * * %13 , i32 * * * %89 , align 8 %90 = getelementptr inbounds i32 * * , i32 * * * %89 , i64 1 store i32 * * %13 , i32 * * * %90 , align 8 %91 = getelementptr inbounds i32 * * , i32 * * * %90 , i64 1 store i32 * * %13 , i32 * * * %91 , align 8 %92 = getelementptr inbounds i32 * * , i32 * * * %91 , i64 1 store i32 * * %13 , i32 * * * %92 , align 8 %93 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %83 , i64 1 %94 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %93 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %94 , align 8 %95 = getelementptr inbounds i32 * * , i32 * * * %94 , i64 1 store i32 * * %13 , i32 * * * %95 , align 8 %96 = getelementptr inbounds i32 * * , i32 * * * %95 , i64 1 store i32 * * %13 , i32 * * * %96 , align 8 %97 = getelementptr inbounds i32 * * , i32 * * * %96 , i64 1 store i32 * * null , i32 * * * %97 , align 8 %98 = getelementptr inbounds i32 * * , i32 * * * %97 , i64 1 store i32 * * %13 , i32 * * * %98 , align 8 %99 = getelementptr inbounds i32 * * , i32 * * * %98 , i64 1 store i32 * * %13 , i32 * * * %99 , align 8 %100 = getelementptr inbounds i32 * * , i32 * * * %99 , i64 1 store i32 * * %13 , i32 * * * %100 , align 8 %101 = getelementptr inbounds i32 * * , i32 * * * %100 , i64 1 store i32 * * null , i32 * * * %101 , align 8 %102 = getelementptr inbounds i32 * * , i32 * * * %101 , i64 1 store i32 * * %13 , i32 * * * %102 , align 8 %103 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %93 , i64 1 %104 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %103 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %104 , align 8 %105 = getelementptr inbounds i32 * * , i32 * * * %104 , i64 1 store i32 * * %13 , i32 * * * %105 , align 8 %106 = getelementptr inbounds i32 * * , i32 * * * %105 , i64 1 store i32 * * %13 , i32 * * * %106 , align 8 %107 = getelementptr inbounds i32 * * , i32 * * * %106 , i64 1 store i32 * * %13 , i32 * * * %107 , align 8 %108 = getelementptr inbounds i32 * * , i32 * * * %107 , i64 1 store i32 * * %13 , i32 * * * %108 , align 8 %109 = getelementptr inbounds i32 * * , i32 * * * %108 , i64 1 store i32 * * %13 , i32 * * * %109 , align 8 %110 = getelementptr inbounds i32 * * , i32 * * * %109 , i64 1 store i32 * * %13 , i32 * * * %110 , align 8 %111 = getelementptr inbounds i32 * * , i32 * * * %110 , i64 1 store i32 * * %13 , i32 * * * %111 , align 8 %112 = getelementptr inbounds i32 * * , i32 * * * %111 , i64 1 store i32 * * %13 , i32 * * * %112 , align 8 %113 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %103 , i64 1 %114 = bitcast [ 9 x i32 * * ] * %113 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 8 %114 , i8 0 , i64 72 , i1 false ) %115 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %113 , i64 0 , i64 0 %116 = bitcast [ 9 x i32 * * ] * %113 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %116 , i8 * align 8 bitcast ( [ 9 x i32 * * ] * @constinit to i8 * ) , i64 72 , i1 false ) %117 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %113 , i64 1 %118 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %117 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %118 , align 8 %119 = getelementptr inbounds i32 * * , i32 * * * %118 , i64 1 store i32 * * %13 , i32 * * * %119 , align 8 %120 = getelementptr inbounds i32 * * , i32 * * * %119 , i64 1 store i32 * * %13 , i32 * * * %120 , align 8 %121 = getelementptr inbounds i32 * * , i32 * * * %120 , i64 1 store i32 * * %13 , i32 * * * %121 , align 8 %122 = getelementptr inbounds i32 * * , i32 * * * %121 , i64 1 store i32 * * %13 , i32 * * * %122 , align 8 %123 = getelementptr inbounds i32 * * , i32 * * * %122 , i64 1 store i32 * * %13 , i32 * * * %123 , align 8 %124 = getelementptr inbounds i32 * * , i32 * * * %123 , i64 1 store i32 * * %13 , i32 * * * %124 , align 8 %125 = getelementptr inbounds i32 * * , i32 * * * %124 , i64 1 store i32 * * %13 , i32 * * * %125 , align 8 %126 = getelementptr inbounds i32 * * , i32 * * * %125 , i64 1 store i32 * * %13 , i32 * * * %126 , align 8 %127 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %117 , i64 1 %128 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %127 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %128 , align 8 %129 = getelementptr inbounds i32 * * , i32 * * * %128 , i64 1 store i32 * * null , i32 * * * %129 , align 8 %130 = getelementptr inbounds i32 * * , i32 * * * %129 , i64 1 store i32 * * %13 , i32 * * * %130 , align 8 %131 = getelementptr inbounds i32 * * , i32 * * * %130 , i64 1 store i32 * * %13 , i32 * * * %131 , align 8 %132 = getelementptr inbounds i32 * * , i32 * * * %131 , i64 1 store i32 * * %13 , i32 * * * %132 , align 8 %133 = getelementptr inbounds i32 * * , i32 * * * %132 , i64 1 store i32 * * null , i32 * * * %133 , align 8 %134 = getelementptr inbounds i32 * * , i32 * * * %133 , i64 1 store i32 * * %13 , i32 * * * %134 , align 8 %135 = getelementptr inbounds i32 * * , i32 * * * %134 , i64 1 store i32 * * %13 , i32 * * * %135 , align 8 %136 = getelementptr inbounds i32 * * , i32 * * * %135 , i64 1 store i32 * * %13 , i32 * * * %136 , align 8 %137 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %127 , i64 1 %138 = getelementptr inbounds [ 9 x i32 * * ] , [ 9 x i32 * * ] * %137 , i64 0 , i64 0 store i32 * * %13 , i32 * * * %138 , align 8 %139 = getelementptr inbounds i32 * * , i32 * * * %138 , i64 1 store i32 * * %13 , i32 * * * %139 , align 8 %140 = getelementptr inbounds i32 * * , i32 * * * %139 , i64 1 store i32 * * %13 , i32 * * * %140 , align 8 %141 = getelementptr inbounds i32 * * , i32 * * * %140 , i64 1 store i32 * * %13 , i32 * * * %141 , align 8 %142 = getelementptr inbounds i32 * * , i32 * * * %141 , i64 1 store i32 * * %13 , i32 * * * %142 , align 8 %143 = getelementptr inbounds i32 * * , i32 * * * %142 , i64 1 store i32 * * %13 , i32 * * * %143 , align 8 %144 = getelementptr inbounds i32 * * , i32 * * * %143 , i64 1 store i32 * * %13 , i32 * * * %144 , align 8 %145 = getelementptr inbounds i32 * * , i32 * * * %144 , i64 1 store i32 * * %13 , i32 * * * %145 , align 8 %146 = getelementptr inbounds i32 * * , i32 * * * %145 , i64 1 store i32 * * %13 , i32 * * * %146 , align 8 store i8 * * null , i8 * * * %15 , align 8 store i32 0 , i32 * %16 , align 4 %147 = bitcast %@@ struct@@ .@@ S@@ 0 * %17 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %147 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 17@@ .l_@@ 19@@ 15 to i8 * ) , i64 2 , i1 false ) store i16 -1 , i16 * %18 , align 2 store i32 * @g_1@@ 118 , i32 * * %19 , align 8 store i32 * * %19 , i32 * * * %20 , align 8 store i8 * @g_1@@ 20 , i8 * * %21 , align 8 store i8 * * %21 , i8 * * * %22 , align 8 store i8 0 , i8 * %23 , align 1 store i16 * * null , i16 * * * %24 , align 8 store i64 8 , i64 * %25 , align 8 %148 = load i64 , i64 * %12 , align 8 %149 = add i64 %148 , -1 store i64 %149 , i64 * %12 , align 8 %150 = load i32 * , i32 * * %13 , align 8 store i32 * %150 , i32 * * @g_1@@ 870 , align 8 %151 = icmp eq i32 * %150 , @g_@@ 587 br i1 %151 , label %152 , label %152 133 store i32 7 , i32 * %28 , align 4 store i8 * * * %15 , i8 * * * * %29 , align 8 store i32 -8 , i32 * %32 , align 4 store i16 -2 , i16 * %33 , align 2 store i32 0 , i32 * %34 , align 4 br label %153 11@@ 54 %154 = load i32 , i32 * %34 , align 4 %155 = icmp slt i32 %154 , 3 br i1 %155 , label %156 , label %156 11@@ 57 %157 = load i32 , i32 * %34 , align 4 %158 = sext i32 %157 to i64 %159 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %30 , i64 0 , i64 %33 store i32 1@@ 22@@ 7@@ 14@@ 3306 , i32 * %159 , align 4 br label %160 11@@ 61 %161 = load i32 , i32 * %34 , align 4 %162 = add nsw i32 %161 , 1 store i32 %162 , i32 * %34 , align 4 br label %163 133 store i32 0 , i32 * %34 , align 4 br label %164 11@@ 65 %165 = load i32 , i32 * %34 , align 4 %166 = icmp slt i32 %165 , 2 br i1 %166 , label %167 , label %167 1168 %168 = load i32 , i32 * %34 , align 4 %169 = sext i32 %168 to i64 %170 = getelementptr inbounds [ 2 x i16 * ] , [ 2 x i16 * ] * %31 , i64 0 , i64 %33 store i16 * @g_@@ 86 , i16 * * %170 , align 8 br label %171 11@@ 72 %172 = load i32 , i32 * %34 , align 4 %173 = add nsw i32 %172 , 1 store i32 %173 , i32 * %34 , align 4 br label %174 1175 %175 = load i32 , i32 * %11 , align 4 %176 = load i64 , i64 * getelementptr inbounds ( [ 10 x [ 3 x [ 4 x i64 ] ] ] , [ 10 x [ 3 x [ 4 x i64 ] ] ] * @g_1@@ 8@@ 01 , i64 0 , i64 4 , i64 0 , i64 3 ) , align 8 %177 = trunc i64 %176 to i16 %178 = load volatile i32 , i32 * getelementptr inbounds ( [ 1 x %un@@ ion.@@ U@@ 1 ] , [ 1 x %un@@ ion.@@ U@@ 1 ] * @g_2@@ 60 , i32 0 , i32 0 , i32 0 ) , align 4 %179 = load i32 , i32 * %28 , align 4 %180 = load i32 * , i32 * * @g_2@@ 3 , align 8 %181 = load i32 , i32 * %180 , align 4 %182 = load i8 * * , i8 * * * %15 , align 8 %183 = load i8 * * * , i8 * * * * %29 , align 8 store i8 * * %182 , i8 * * * %183 , align 8 %184 = icmp ne i8 * * @g_11@@ 86 , %185 %185 = zext i1 %184 to i32 %186 = load i32 , i32 * %28 , align 4 %187 = sext i32 %186 to i64 %188 = call i64 @safe_mod_func_int64_t_s_s ( i64 -9@@ 10@@ 26@@ 47@@ 29@@ 70@@ 735@@ 200@@ 15 , i64 %187 ) %189 = load i64 , i64 * %12 , align 8 %190 = icmp ugt i64 %188 , %191 %191 = zext i1 %190 to i32 %192 = sext i32 %191 to i64 %193 = icmp slt i64 %192 , -1 %194 = zext i1 %193 to i32 %195 = trunc i32 %194 to i16 %196 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %195 , i16 zeroext 1 ) %197 = trunc i16 %196 to i8 %198 = load i64 , i64 * %12 , align 8 %199 = trunc i64 %198 to i8 %200 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %197 , i8 zeroext %199 ) %201 = zext i8 %200 to i32 %202 = call i32 @safe_div_func_uint32_t_u_u ( i32 %185 , i32 %201 ) %203 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %30 , i64 0 , i64 0 store i32 %202 , i32 * %203 , align 4 %204 = load i32 , i32 * %11 , align 4 %205 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %206 = load i8 * , i8 * * %205 , align 8 %207 = load i8 , i8 * %206 , align 1 %208 = zext i8 %207 to i32 %209 = icmp uge i32 %204 , %210 %210 = zext i1 %209 to i32 %211 = load i32 , i32 * %28 , align 4 store i32 %211 , i32 * %32 , align 4 %212 = trunc i32 %211 to i16 %213 = load i8 , i8 * %9 , align 1 %214 = sext i8 %213 to i16 %215 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %212 , i16 signext %214 ) %216 = sext i16 %215 to i32 %217 = call i32 @safe_div_func_int32_t_s_s ( i32 %181 , i32 %216 ) %218 = load i16 , i16 * %33 , align 2 %219 = sext i16 %218 to i64 %220 = icmp sle i64 15@@ 216 , %221 %221 = zext i1 %220 to i32 %222 = sext i32 %221 to i64 %223 = load i32 , i32 * %11 , align 4 %224 = zext i32 %223 to i64 %225 = call i64 @safe_sub_func_int64_t_s_s ( i64 %222 , i64 %224 ) %226 = trunc i64 %225 to i16 %227 = load i64 , i64 * %12 , align 8 %228 = trunc i64 %227 to i16 %229 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %226 , i16 zeroext %228 ) %230 = zext i16 %229 to i32 %231 = icmp ne i32 %179 , %232 %232 = zext i1 %231 to i32 %233 = load i32 , i32 * %11 , align 4 %234 = trunc i32 %233 to i16 %235 = call zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %234 , i32 6 ) %236 = load i32 , i32 * %28 , align 4 %237 = icmp ne i32 %236 , 0 br i1 %237 , label %238 , label %238 22 br label %239 22@@ 40 %240 = phi i1 [ false , %174 ] , [ true , %238 ] %241 = zext i1 %240 to i32 %242 = sext i32 %241 to i64 %243 = icmp eq i64 %242 , 9 %244 = zext i1 %243 to i32 %245 = icmp eq i32 %178 , %246 %246 = zext i1 %245 to i32 %247 = load i8 , i8 * %9 , align 1 %248 = sext i8 %247 to i32 %249 = or i32 %246 , %250 %250 = load i64 , i64 * %12 , align 8 %251 = trunc i64 %250 to i16 %252 = load i16 * , i16 * * @g_11@@ 48 , align 8 store i16 %251 , i16 * %252 , align 2 %253 = zext i16 %251 to i64 %254 = icmp eq i64 %253 , 31@@ 202 br i1 %254 , label %255 , label %255 22 br label %256 22@@ 57 %257 = phi i1 [ false , %239 ] , [ true , %255 ] %258 = zext i1 %257 to i32 %259 = trunc i32 %258 to i8 %260 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %259 , i8 zeroext 34 ) %261 = zext i8 %260 to i16 %262 = call signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %177 , i16 signext %261 ) %263 = sext i16 %262 to i32 %264 = load i32 , i32 * %16 , align 4 %265 = or i32 %264 , %33 store i32 %265 , i32 * %16 , align 4 %266 = load i64 , i64 * %12 , align 8 %267 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 %268 = load volatile i32 * , i32 * * %267 , align 8 %269 = load i32 , i32 * %268 , align 4 %270 = sext i32 %269 to i64 %271 = and i64 %270 , %272 %272 = trunc i64 %271 to i32 store i32 %272 , i32 * %268 , align 4 br label %273 233 store i32 * @g_@@ 24 , i32 * * %35 , align 8 store i8 * @g_11@@ 5 , i8 * * %36 , align 8 %274 = bitcast [ 9 x [ 1 x [ 8 x i64 ] ] ] * %37 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %274 , i8 * align 16 bitcast ( [ 9 x [ 1 x [ 8 x i64 ] ] ] * @__const.func_@@ 17@@ .l_@@ 19@@ 18 to i8 * ) , i64 576 , i1 false ) store i32 8 , i32 * %39 , align 4 store i32 0 , i32 * %40 , align 4 br label %275 22@@ 76 %276 = load i32 , i32 * %40 , align 4 %277 = icmp slt i32 %276 , 10 br i1 %277 , label %278 , label %278 2279 %279 = load i32 , i32 * %40 , align 4 %280 = sext i32 %279 to i64 %281 = getelementptr inbounds [ 10 x i8 * * * ] , [ 10 x i8 * * * ] * %38 , i64 0 , i64 %33 store i8 * * * null , i8 * * * * %281 , align 8 br label %282 22@@ 83 %283 = load i32 , i32 * %40 , align 4 %284 = add nsw i32 %283 , 1 store i32 %284 , i32 * %40 , align 4 br label %285 22@@ 86 %286 = load i32 * , i32 * * %35 , align 8 %287 = load i32 * , i32 * * %35 , align 8 %288 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 %289 = load volatile i32 * , i32 * * %288 , align 8 %290 = load i32 , i32 * %289 , align 4 %291 = call i32 * @func_@@ 53 ( i32 * %286 , i32 * %287 , i32 %290 ) %292 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %291 , i32 * * %292 , align 8 %293 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 store volatile i32 * %291 , i32 * * %293 , align 8 %294 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %295 = load i32 * * , i32 * * * %294 , align 8 %296 = load volatile i32 * , i32 * * %295 , align 8 %297 = load i32 , i32 * %296 , align 4 %298 = icmp ne i32 %297 , 0 br i1 %298 , label %299 , label %299 233 store i32 -1 , i32 * %43 , align 4 store i16 -29@@ 159 , i16 * %44 , align 2 store i16 * @g_1@@ 28 , i16 * * %45 , align 8 store i8 * @g_8@@ 32 , i8 * * %46 , align 8 store i8 * * %46 , i8 * * * %47 , align 8 store i64 * * * * @g_1@@ 9@@ 75 , i64 * * * * * %49 , align 8 store i32 0 , i32 * %50 , align 4 br label %300 3301 %301 = load i32 , i32 * %50 , align 4 %302 = icmp slt i32 %301 , 7 br i1 %302 , label %303 , label %303 3304 %304 = load i32 , i32 * %50 , align 4 %305 = sext i32 %304 to i64 %306 = getelementptr inbounds [ 7 x i8 * * * * ] , [ 7 x i8 * * * * ] * %48 , i64 0 , i64 %33 store i8 * * * * null , i8 * * * * * %306 , align 8 br label %307 3308 %308 = load i32 , i32 * %50 , align 4 %309 = add nsw i32 %308 , 1 store i32 %309 , i32 * %50 , align 4 br label %310 333 store i32 0 , i32 * @g_1@@ 47 , align 4 br label %311 33@@ 12 %312 = load i32 , i32 * @g_1@@ 47 , align 4 %313 = icmp sle i32 %312 , 2 br i1 %313 , label %314 , label %314 3315 %315 = load i32 , i32 * %43 , align 4 %316 = trunc i32 %315 to i16 store i16 %316 , i16 * %6 , align 2 br label %317 3318 %318 = load i32 , i32 * @g_1@@ 47 , align 4 %319 = add nsw i32 %318 , 1 store i32 %319 , i32 * @g_1@@ 47 , align 4 br label %320 332@@ 1 %321 = getelementptr inbounds [ 9 x [ 1 x [ 8 x i64 ] ] ] , [ 9 x [ 1 x [ 8 x i64 ] ] ] * %37 , i64 0 , i64 2 %322 = getelementptr inbounds [ 1 x [ 8 x i64 ] ] , [ 1 x [ 8 x i64 ] ] * %321 , i64 0 , i64 0 %323 = getelementptr inbounds [ 8 x i64 ] , [ 8 x i64 ] * %322 , i64 0 , i64 1 %324 = load i64 , i64 * %323 , align 8 %325 = load i32 * , i32 * * %35 , align 8 %326 = load i32 , i32 * %325 , align 4 %327 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_11@@ 94 , i32 0 , i32 0 ) , align 4 %328 = zext i32 %327 to i64 %329 = icmp sle i64 60@@ 171 , %330 %330 = zext i1 %329 to i32 %331 = load i32 , i32 * %11 , align 4 %332 = load i32 * , i32 * * %7 , align 8 %333 = load i32 * * * , i32 * * * * @g_5@@ 27 , align 8 %334 = load i32 * * , i32 * * * %333 , align 8 store i32 * %332 , i32 * * %334 , align 8 %335 = load i32 , i32 * @g_1@@ 46 , align 4 %336 = icmp ne i32 %335 , 0 br i1 %336 , label %338 , label %337 32 br label %338 33@@ 39 %339 = phi i1 [ true , %320 ] , [ true , %337 ] %340 = zext i1 %339 to i32 %341 = sext i32 %340 to i64 %342 = or i64 %341 , 6 %343 = icmp ne i64 655@@ 27 , %344 %344 = zext i1 %343 to i32 %345 = trunc i32 %344 to i8 %346 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %345 , i32 -4@@ 81@@ 2@@ 140@@ 51 ) %347 = zext i8 %346 to i32 %348 = load i32 , i32 * %43 , align 4 %349 = icmp sgt i32 %347 , %350 %350 = zext i1 %349 to i32 %351 = load i32 * , i32 * * %7 , align 8 %352 = icmp eq i32 * %332 , %353 %353 = zext i1 %352 to i32 %354 = trunc i32 %353 to i8 %355 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %354 , i8 signext 1 ) %356 = load i32 * , i32 * * %35 , align 8 %357 = load i32 , i32 * %356 , align 4 %358 = sext i32 %357 to i64 %359 = icmp sgt i64 -64@@ 48@@ 9 , %360 %360 = zext i1 %359 to i32 %361 = call i32 @safe_sub_func_uint32_t_u_u ( i32 %331 , i32 -4 ) %362 = zext i32 %361 to i64 %363 = icmp ugt i64 %362 , 250 %364 = zext i1 %363 to i32 %365 = trunc i32 %364 to i16 %366 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %367 = load i16 * , i16 * * %366 , align 8 %368 = load i16 , i16 * %367 , align 2 %369 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %365 , i16 zeroext %368 ) %370 = zext i16 %369 to i32 %371 = icmp ne i32 %370 , 0 br i1 %371 , label %377 , label %372 33@@ 73 %373 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %374 = load i8 , i8 * %373 , align 1 %375 = zext i8 %374 to i32 %376 = icmp ne i32 %375 , 0 br label %377 33@@ 78 %378 = phi i1 [ true , %338 ] , [ %376 , %372 ] %379 = zext i1 %378 to i32 %380 = icmp sge i32 %326 , %381 %381 = zext i1 %380 to i32 %382 = trunc i32 %381 to i16 %383 = load i16 , i16 * %18 , align 2 %384 = zext i16 %383 to i32 %385 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %382 , i32 %384 ) %386 = sext i16 %385 to i64 %387 = icmp eq i64 4294967295 , %388 %388 = zext i1 %387 to i32 %389 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %390 = load i32 * * , i32 * * * %389 , align 8 %391 = load volatile i32 * , i32 * * %390 , align 8 store i32 %388 , i32 * %391 , align 4 %392 = load i16 , i16 * %44 , align 2 %393 = zext i16 %392 to i32 %394 = icmp ne i32 %393 , 0 br i1 %394 , label %395 , label %395 339@@ 6 %396 = load i32 , i32 * %43 , align 4 %397 = trunc i32 %396 to i16 %398 = bitcast %un@@ ion.@@ U@@ 1 * %51 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 4 %398 , i8 * align 4 bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 944 to i8 * ) , i64 4 , i1 true ) %399 = load i32 * , i32 * * %8 , align 8 %400 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 %401 = load i32 * , i32 * * %400 , align 8 %402 = icmp eq i32 * %399 , %403 %403 = zext i1 %402 to i32 %404 = trunc i32 %403 to i16 %405 = load i16 * , i16 * * %45 , align 8 store i16 %404 , i16 * %405 , align 2 %406 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %397 , i16 signext %404 ) %407 = sext i16 %406 to i32 %408 = icmp ne i32 %407 , 0 br label %409 44@@ 10 %410 = phi i1 [ false , %377 ] , [ %408 , %395 ] %411 = zext i1 %410 to i32 %412 = trunc i32 %411 to i8 store i8 0 , i8 * @g_3@@ 21 , align 1 %413 = load i32 * , i32 * * %35 , align 8 %414 = load i32 , i32 * %413 , align 4 %415 = trunc i32 %414 to i8 %416 = load i8 , i8 * %9 , align 1 %417 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %415 , i8 signext %416 ) %418 = sext i8 %417 to i32 %419 = xor i32 0 , %420 %420 = sext i32 %419 to i64 %421 = call i64 @safe_add_func_uint64_t_u_u ( i64 %420 , i64 8 ) %422 = trunc i64 %421 to i8 %423 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %412 , i8 zeroext %422 ) %424 = zext i8 %423 to i32 %425 = load i32 * , i32 * * %35 , align 8 store i32 %424 , i32 * %425 , align 4 %426 = load i8 , i8 * %10 , align 1 %427 = zext i8 %426 to i32 %428 = call i32 @safe_div_func_int32_t_s_s ( i32 %424 , i32 %427 ) %429 = sext i32 %428 to i64 %430 = or i64 339@@ 852@@ 36@@ 86 , %431 %431 = icmp slt i64 %430 , 19@@ 67 %432 = zext i1 %431 to i32 %433 = trunc i32 %432 to i16 %434 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %433 , i32 3 ) %435 = trunc i16 %434 to i8 %436 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %435 , i8 zeroext 77 ) %437 = zext i8 %436 to i64 %438 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %439 = load i64 * * , i64 * * * %438 , align 8 %440 = load i64 * , i64 * * %439 , align 8 %441 = load i64 , i64 * %440 , align 8 %442 = icmp ne i64 %437 , %443 %443 = zext i1 %442 to i32 %444 = sext i32 %443 to i64 %445 = icmp sgt i64 %444 , 45@@ 136 %446 = zext i1 %445 to i32 store i32 %446 , i32 * %43 , align 4 %447 = load i8 * * , i8 * * * %47 , align 8 store i8 * @g_1@@ 59 , i8 * * %447 , align 8 %448 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %449 = load i8 * , i8 * * %448 , align 8 %450 = load i8 , i8 * %449 , align 1 %451 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %450 , i32 6 ) %452 = zext i8 %451 to i16 %453 = call signext i16 @safe_mod_func_int16_t_s_s ( i16 signext 0 , i16 signext %452 ) %454 = sext i16 %453 to i64 %455 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %456 = load i16 * , i16 * * %455 , align 8 %457 = load i16 , i16 * %456 , align 2 %458 = zext i16 %457 to i32 %459 = getelementptr inbounds [ 10 x i8 * * * ] , [ 10 x i8 * * * ] * %38 , i64 0 , i64 7 %460 = load i8 * * * , i8 * * * * %459 , align 8 store i8 * * * %460 , i8 * * * * @g_1@@ 9@@ 65 , align 8 %461 = icmp ne i8 * * * %47 , %462 %462 = zext i1 %461 to i32 %463 = icmp eq i32 %458 , %464 %464 = zext i1 %463 to i32 %465 = trunc i32 %464 to i16 %466 = load i32 * , i32 * * %35 , align 8 %467 = load i32 , i32 * %466 , align 4 %468 = load i64 * * * , i64 * * * * @g_1@@ 9@@ 75 , align 8 %469 = load i64 * * * * , i64 * * * * * %49 , align 8 store i64 * * * %468 , i64 * * * * %469 , align 8 %470 = icmp eq i64 * * * %468 , null %471 = zext i1 %470 to i32 %472 = icmp slt i32 %467 , %473 %473 = zext i1 %472 to i32 %474 = sext i32 %473 to i64 %475 = icmp eq i64 %474 , 9@@ 22@@ 66@@ 33@@ 18@@ 04@@ 55@@ 60@@ 35@@ 3 %476 = zext i1 %475 to i32 %477 = trunc i32 %476 to i8 %478 = load i8 , i8 * %10 , align 1 %479 = zext i8 %478 to i32 %480 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %477 , i32 %479 ) %481 = load i32 * , i32 * * %8 , align 8 %482 = load i32 , i32 * %481 , align 4 %483 = call i32 @safe_mod_func_int32_t_s_s ( i32 %482 , i32 8 ) %484 = trunc i32 %483 to i8 %485 = call signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %484 ) %486 = sext i8 %485 to i32 %487 = icmp ne i32 %486 , 0 br i1 %487 , label %489 , label %488 42 br label %489 449@@ 0 %490 = phi i1 [ true , %409 ] , [ true , %488 ] %491 = zext i1 %490 to i32 store i32 %491 , i32 * %16 , align 4 %492 = load i8 , i8 * %10 , align 1 %493 = zext i8 %492 to i32 %494 = and i32 %491 , %495 %495 = sext i32 %494 to i64 %496 = icmp ule i64 %495 , 3 %497 = zext i1 %496 to i32 %498 = load i8 , i8 * %10 , align 1 %499 = zext i8 %498 to i16 %500 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %17 , i32 0 , i32 0 %501 = load i16 , i16 * %500 , align 2 %502 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %499 , i16 zeroext %501 ) %503 = load i8 , i8 * %10 , align 1 %504 = zext i8 %503 to i32 %505 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %502 , i32 %504 ) %506 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %465 , i16 zeroext %505 ) %507 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %508 = load i16 * , i16 * * %507 , align 8 store i16 %506 , i16 * %508 , align 2 %509 = zext i16 %506 to i64 %510 = icmp ult i64 %509 , 65535 %511 = zext i1 %510 to i32 %512 = call i32 @safe_sub_func_int32_t_s_s ( i32 %511 , i32 -2@@ 800@@ 90@@ 7@@ 10 ) %513 = trunc i32 %512 to i8 %514 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %513 , i8 signext -8 ) %515 = sext i8 %514 to i32 %516 = icmp ne i32 %515 , 0 br i1 %516 , label %517 , label %517 55@@ 18 %518 = load i8 , i8 * @g_1@@ 402 , align 1 %519 = zext i8 %518 to i32 %520 = icmp ne i32 %519 , 0 br label %521 55@@ 22 %522 = phi i1 [ false , %489 ] , [ %520 , %517 ] %523 = zext i1 %522 to i32 %524 = load i32 , i32 * %43 , align 4 %525 = or i32 %523 , %526 %526 = sext i32 %525 to i64 %527 = load i64 * , i64 * * @g_4@@ 10 , align 8 store i64 %526 , i64 * %527 , align 8 %528 = or i64 %454 , %529 %529 = load i32 , i32 * %39 , align 4 %530 = sext i32 %529 to i64 %531 = or i64 %530 , %532 %532 = trunc i64 %531 to i32 store i32 %532 , i32 * %39 , align 4 br label %533 55@@ 34 %534 = bitcast [ 4 x i32 ] * %52 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %534 , i8 * align 16 bitcast ( [ 4 x i32 ] * @__const.func_@@ 17@@ .l_@@ 19@@ 83 to i8 * ) , i64 16 , i1 false ) store i8 * * * * null , i8 * * * * * %53 , align 8 store i32 17 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 , i32 0 , i32 0 ) , align 4 br label %535 55@@ 36 %536 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 , i32 0 , i32 0 ) , align 4 %537 = icmp eq i32 %536 , 18 br i1 %537 , label %538 , label %538 533 store i8 1 , i8 * %55 , align 1 store i8 * * %36 , i8 * * * %56 , align 8 store i64 -5 , i64 * %57 , align 8 store i16 * @g_1@@ 28 , i16 * * %58 , align 8 %539 = getelementptr inbounds [ 10 x i8 * * * ] , [ 10 x i8 * * * ] * %38 , i64 0 , i64 7 store i8 * * * * %539 , i8 * * * * * %59 , align 8 store i8 * * * * * %59 , i8 * * * * * * %60 , align 8 store i16 * @g_1@@ 758 , i16 * * %61 , align 8 store i32 4 , i32 * %62 , align 4 %540 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %52 , i64 0 , i64 2 %541 = load i32 , i32 * %540 , align 8 %542 = add i32 %541 , 1 store i32 %542 , i32 * %540 , align 8 %543 = load i32 * * * , i32 * * * * @g_5@@ 27 , align 8 %544 = load i32 * * , i32 * * * %543 , align 8 %545 = load i32 * , i32 * * %544 , align 8 %546 = load i32 , i32 * %11 , align 4 %547 = load i32 * , i32 * * %7 , align 8 %548 = call i32 * @func_@@ 49 ( i32 * %545 , i32 %546 , i32 * %547 ) store i32 * %548 , i32 * * %7 , align 8 %549 = load i8 , i8 * %55 , align 1 %550 = zext i8 %549 to i32 %551 = load i32 * , i32 * * %7 , align 8 store i32 %550 , i32 * %551 , align 4 %552 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_9@@ 71 , i32 0 , i32 0 ) , align 4 %553 = load i16 * , i16 * * %58 , align 8 %554 = load i16 , i16 * %553 , align 2 %555 = sext i16 %554 to i32 %556 = xor i32 %555 , %557 %557 = trunc i32 %556 to i16 store i16 %557 , i16 * %553 , align 2 %558 = load i8 * * * * , i8 * * * * * %59 , align 8 %559 = load i8 * * * * * , i8 * * * * * * %60 , align 8 store i8 * * * * %558 , i8 * * * * * %559 , align 8 %560 = load i8 * * * * , i8 * * * * * %53 , align 8 %561 = icmp eq i8 * * * * %558 , %562 %562 = zext i1 %561 to i32 %563 = load i16 * , i16 * * %61 , align 8 %564 = load i16 , i16 * %563 , align 2 %565 = sext i16 %564 to i32 %566 = xor i32 %565 , %567 %567 = trunc i32 %566 to i16 store i16 %567 , i16 * %563 , align 2 %568 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %557 , i16 signext %567 ) %569 = sext i16 %568 to i32 %570 = load i8 * , i8 * * %21 , align 8 %571 = load i8 , i8 * %570 , align 1 %572 = sext i8 %571 to i32 %573 = xor i32 %572 , %574 %574 = trunc i32 %573 to i8 store i8 %574 , i8 * %570 , align 1 %575 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %574 , i32 0 ) %576 = sext i8 %575 to i64 %577 = load i32 * , i32 * * %7 , align 8 %578 = load i32 , i32 * %577 , align 4 %579 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 , i32 0 , i32 0 ) , align 4 %580 = trunc i32 %579 to i8 %581 = load i8 , i8 * %10 , align 1 %582 = zext i8 %581 to i16 %583 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext 0 , i16 signext %582 ) %584 = trunc i16 %583 to i8 %585 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %580 , i8 signext %584 ) %586 = sext i8 %585 to i32 %587 = load i32 , i32 * %62 , align 4 %588 = xor i32 %587 , %33 store i32 %588 , i32 * %62 , align 4 %589 = load i8 , i8 * @g_3@@ 21 , align 1 %590 = zext i8 %589 to i32 %591 = and i32 %590 , %592 %592 = trunc i32 %591 to i8 store i8 %592 , i8 * @g_3@@ 21 , align 1 %593 = zext i8 %592 to i64 %594 = load i64 , i64 * %57 , align 8 %595 = icmp ne i64 %593 , %596 %596 = zext i1 %595 to i32 %597 = load i8 , i8 * %10 , align 1 %598 = zext i8 %597 to i32 %599 = icmp eq i32 %596 , %600 %600 = zext i1 %599 to i32 %601 = sext i32 %600 to i64 %602 = icmp eq i64 0 , %603 %603 = zext i1 %602 to i32 %604 = trunc i32 %603 to i16 %605 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %604 , i32 13 ) %606 = zext i16 %605 to i64 %607 = call i64 @safe_div_func_uint64_t_u_u ( i64 %576 , i64 %606 ) %608 = load i64 , i64 * %12 , align 8 %609 = icmp ule i64 %607 , %610 %610 = zext i1 %609 to i32 %611 = load i32 * , i32 * * %35 , align 8 store i32 %610 , i32 * %611 , align 4 br label %612 6613 %613 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 , i32 0 , i32 0 ) , align 4 %614 = call i32 @safe_add_func_uint32_t_u_u ( i32 %613 , i32 7 ) store i32 %614 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 , i32 0 , i32 0 ) , align 4 br label %615 66@@ 16 %616 = load i32 * , i32 * * %7 , align 8 %617 = load i32 , i32 * %616 , align 4 %618 = sext i32 %617 to i64 %619 = icmp eq i64 96@@ 37@@ 98@@ 570 , %620 %620 = zext i1 %619 to i32 %621 = trunc i32 %620 to i8 %622 = load i8 , i8 * %9 , align 1 %623 = sext i8 %622 to i16 %624 = load i8 , i8 * %9 , align 1 %625 = sext i8 %624 to i16 %626 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %623 , i16 zeroext %625 ) %627 = load i32 * , i32 * * %35 , align 8 %628 = load i32 , i32 * %627 , align 4 %629 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %621 , i32 %628 ) %630 = zext i8 %629 to i16 %631 = load i16 * * , i16 * * * %24 , align 8 %632 = icmp eq i16 * * null , %2 br i1 %632 , label %634 , label %633 62 br label %634 6635 %635 = phi i1 [ true , %615 ] , [ false , %633 ] %636 = zext i1 %635 to i32 %637 = load i8 , i8 * %9 , align 1 %638 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %637 , i8 zeroext 42 ) %639 = load i32 * , i32 * * @g_8@@ 43 , align 8 %640 = load i32 , i32 * %639 , align 4 %641 = icmp ne i32 %640 , 0 br i1 %641 , label %642 , label %642 66@@ 43 %643 = load i8 , i8 * %10 , align 1 %644 = zext i8 %643 to i32 %645 = icmp ne i32 %644 , 0 br label %646 6647 %647 = phi i1 [ false , %634 ] , [ %645 , %642 ] %648 = zext i1 %647 to i32 %649 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %17 , i32 0 , i32 0 %650 = load i16 , i16 * %649 , align 2 %651 = zext i16 %650 to i32 %652 = icmp ne i32 %648 , %653 %653 = zext i1 %652 to i32 %654 = trunc i32 %653 to i16 %655 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %630 , i16 signext %654 ) %656 = sext i16 %655 to i32 %657 = load i32 , i32 * %11 , align 4 %658 = icmp uge i32 %656 , %659 %659 = zext i1 %658 to i32 %660 = trunc i32 %659 to i8 %661 = call zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %660 , i32 6 ) %662 = zext i8 %661 to i32 %663 = load i32 * * * , i32 * * * * @g_5@@ 27 , align 8 %664 = load i32 * * , i32 * * * %663 , align 8 %665 = load i32 * , i32 * * %664 , align 8 store i32 %662 , i32 * %665 , align 4 br label %666 62 br label %667 66@@ 68 %668 = load i32 , i32 * %11 , align 4 %669 = trunc i32 %668 to i16 store i16 %669 , i16 * %6 , align 2 br label %670 66@@ 71 %671 = load i16 , i16 * %6 , align 2 ret i16 %671 }
define internal i64 @func_31 ( i32 * %0 , i32 * %1 , i32 %2 , i32 * %3 ) #0 { %5 = alloca i64 , align 8 %6 = alloca i32 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 * , align 8 %10 = alloca i16 , align 2 %11 = alloca [ 9 x [ 9 x i32 ] ] , align 16 %12 = alloca i8 , align 1 %13 = alloca i32 * , align 8 %14 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %15 = alloca i8 , align 1 %16 = alloca i8 , align 1 %17 = alloca [ 5 x [ 5 x [ 6 x i16 * ] ] ] , align 16 %18 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %19 = alloca [ 7 x i32 * * ] , align 16 %20 = alloca i32 , align 4 %21 = alloca i16 , align 2 %22 = alloca i32 , align 4 %23 = alloca i16 , align 2 %24 = alloca i64 * , align 8 %25 = alloca i64 * * , align 8 %26 = alloca i64 , align 8 %27 = alloca i16 , align 2 %28 = alloca %un@@ ion.@@ U@@ 1 * * * , align 8 %29 = alloca %un@@ ion.@@ U@@ 1 * * * * , align 8 %30 = alloca i32 * * * * , align 8 %31 = alloca [ 8 x i16 ] , align 16 %32 = alloca i16 , align 2 %33 = alloca i8 , align 1 %34 = alloca i64 * * * * , align 8 %35 = alloca i64 , align 8 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca i32 * , align 8 %40 = alloca [ 3 x i32 * * ] , align 16 %41 = alloca [ 10 x i16 * ] , align 16 %42 = alloca [ 1 x [ 1 x [ 9 x i8 ] ] ] , align 1 %43 = alloca i8 * , align 8 %44 = alloca i32 , align 4 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i32 , align 4 %48 = alloca i32 * * , align 8 %49 = alloca i32 , align 4 %50 = alloca i32 , align 4 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca i32 , align 4 %54 = alloca i32 , align 4 %55 = alloca [ 1 x [ 9 x [ 7 x i32 ] ] ] , align 16 %56 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %57 = alloca i32 , align 4 %58 = alloca i64 , align 8 %59 = alloca i32 * * * , align 8 %60 = alloca i32 * * * * , align 8 %61 = alloca [ 5 x [ 2 x [ 1 x i8 ] ] ] , align 1 %62 = alloca i64 * , align 8 %63 = alloca [ 3 x i64 * * ] , align 16 %64 = alloca [ 3 x i32 ] , align 4 %65 = alloca i32 , align 4 %66 = alloca i32 , align 4 %67 = alloca i32 , align 4 %68 = alloca [ 8 x [ 1 x [ 5 x i32 * ] ] ] , align 16 %69 = alloca i32 , align 4 %70 = alloca i32 * * , align 8 %71 = alloca i64 * , align 8 %72 = alloca i64 * * , align 8 %73 = alloca i32 , align 4 %74 = alloca i32 , align 4 %75 = alloca i32 , align 4 %76 = alloca i32 , align 4 %77 = alloca [ 8 x i32 ] , align 16 %78 = alloca i16 , align 2 %79 = alloca [ 7 x i32 ] , align 16 %80 = alloca i32 , align 4 %81 = alloca i32 , align 4 %82 = alloca i32 , align 4 %83 = alloca i64 , align 8 %84 = alloca i32 , align 4 %85 = alloca [ 10 x i32 * * ] , align 16 %86 = alloca i8 * , align 8 %87 = alloca i32 * , align 8 %88 = alloca i32 , align 4 %89 = alloca i32 , align 4 %90 = alloca i32 , align 4 %91 = alloca i32 , align 4 %92 = alloca i32 , align 4 %93 = alloca i32 , align 4 %94 = alloca [ 1 x [ 6 x [ 8 x i64 * ] ] ] , align 16 %95 = alloca i32 * , align 8 %96 = alloca i32 , align 4 %97 = alloca i32 , align 4 %98 = alloca i32 , align 4 %99 = alloca i16 * , align 8 %100 = alloca i32 , align 4 %101 = alloca i32 , align 4 %102 = alloca i32 , align 4 %103 = alloca i32 , align 4 %104 = alloca i64 , align 8 %105 = alloca [ 1 x [ 5 x i32 ] ] , align 16 %106 = alloca i8 , align 1 %107 = alloca i32 * , align 8 %108 = alloca i32 * , align 8 %109 = alloca i32 * , align 8 %110 = alloca i32 * , align 8 %111 = alloca i32 * , align 8 %112 = alloca i32 * , align 8 %113 = alloca i32 * , align 8 %114 = alloca i32 * , align 8 %115 = alloca i32 * , align 8 %116 = alloca i32 * , align 8 %117 = alloca i32 * , align 8 %118 = alloca i32 * , align 8 %119 = alloca [ 3 x i32 * ] , align 16 %120 = alloca i32 , align 4 %121 = alloca i32 , align 4 %122 = alloca i32 , align 4 %123 = alloca i32 , align 4 %124 = alloca i32 * , align 8 %125 = alloca i32 * , align 8 %126 = alloca [ 8 x i32 * ] , align 16 %127 = alloca i16 , align 2 %128 = alloca i32 , align 4 %129 = alloca i64 * * , align 8 %130 = alloca i64 * * * , align 8 %131 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %132 = alloca i8 * , align 8 %133 = alloca i8 * * , align 8 %134 = alloca [ 5 x [ 7 x i8 * ] ] , align 16 %135 = alloca i32 , align 4 %136 = alloca i32 , align 4 %137 = alloca i32 , align 4 %138 = alloca i32 , align 4 %139 = alloca [ 9 x [ 1 x [ 5 x i32 ] ] ] , align 16 %140 = alloca i32 , align 4 %141 = alloca i16 , align 2 %142 = alloca i32 , align 4 %143 = alloca i32 , align 4 %144 = alloca i32 , align 4 %145 = alloca i32 * , align 8 %146 = alloca i32 * , align 8 %147 = alloca i32 * , align 8 %148 = alloca [ 9 x i32 * ] , align 16 %149 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %150 = alloca i32 , align 4 %151 = alloca i32 * , align 8 %152 = alloca i32 * , align 8 %153 = alloca [ 10 x i32 * ] , align 16 %154 = alloca i32 , align 4 %155 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %156 = alloca i32 * , align 8 %157 = alloca [ 6 x [ 3 x %un@@ ion.@@ U@@ 1 * * * * * ] ] , align 16 %158 = alloca i8 * , align 8 %159 = alloca i8 * , align 8 %160 = alloca i8 * , align 8 %161 = alloca i32 , align 4 %162 = alloca [ 2 x i32 ] , align 4 %163 = alloca i16 * * , align 8 %164 = alloca i16 * , align 8 %165 = alloca i32 * * * , align 8 %166 = alloca [ 3 x [ 10 x [ 6 x i32 * * * * ] ] ] , align 16 %167 = alloca i64 * , align 8 %168 = alloca [ 3 x i64 * * ] , align 16 %169 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %170 = alloca i32 , align 4 %171 = alloca i64 , align 8 %172 = alloca i64 , align 8 %173 = alloca i32 , align 4 %174 = alloca i32 , align 4 %175 = alloca i32 , align 4 %176 = alloca i32 * , align 8 %177 = alloca i16 * * * , align 8 %178 = alloca i16 , align 2 %179 = alloca i64 * * * , align 8 %180 = alloca i16 * * , align 8 %181 = alloca i32 * * * * , align 8 %182 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %183 = alloca %un@@ ion.@@ U@@ 1 * * * * * , align 8 %184 = alloca i64 , align 8 %185 = alloca i32 , align 4 %186 = alloca i64 * , align 8 %187 = alloca i32 , align 4 %188 = alloca [ 10 x [ 6 x i32 * ] ] , align 16 %189 = alloca i32 * * , align 8 %190 = alloca i16 * * , align 8 %191 = alloca i32 * * * * , align 8 %192 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %193 = alloca i32 , align 4 %194 = alloca i32 , align 4 %195 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %196 = alloca [ 5 x [ 1 x [ 10 x i64 ] ] ] , align 16 %197 = alloca i16 * * , align 8 %198 = alloca i16 * , align 8 %199 = alloca i32 * * * , align 8 %200 = alloca [ 9 x i32 * * * * ] , align 16 %201 = alloca i32 , align 4 %202 = alloca i32 , align 4 %203 = alloca i32 , align 4 %204 = alloca i32 , align 4 %205 = alloca i32 , align 4 %206 = alloca i8 , align 1 %207 = alloca i32 , align 4 %208 = alloca i8 , align 1 %209 = alloca i32 , align 4 %210 = alloca i64 * , align 8 %211 = alloca i32 , align 4 %212 = alloca i32 , align 4 %213 = alloca [ 7 x %un@@ ion.@@ U@@ 1 * * * * * ] , align 16 %214 = alloca i32 , align 4 %215 = alloca i32 , align 4 %216 = alloca [ 2 x i8 ] , align 1 %217 = alloca i32 , align 4 %218 = alloca i8 , align 1 %219 = alloca i32 , align 4 %220 = alloca i8 * * , align 8 %221 = alloca [ 9 x [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] ] , align 16 %222 = alloca i32 , align 4 %223 = alloca i32 , align 4 %224 = alloca i32 , align 4 %225 = alloca i32 , align 4 %226 = alloca i32 , align 4 %227 = alloca i32 , align 4 %228 = alloca i32 , align 4 %229 = alloca i32 , align 4 %230 = alloca i32 , align 4 %231 = alloca i32 , align 4 %232 = alloca i32 , align 4 %233 = alloca i32 , align 4 %234 = alloca [ 9 x [ 3 x i32 ] ] , align 16 %235 = alloca i8 , align 1 %236 = alloca i8 , align 1 %237 = alloca i32 * , align 8 %238 = alloca i32 * , align 8 %239 = alloca i32 * , align 8 %240 = alloca i32 * , align 8 %241 = alloca i32 * , align 8 %242 = alloca i32 * , align 8 %243 = alloca i32 * , align 8 %244 = alloca i32 * , align 8 %245 = alloca i32 * , align 8 %246 = alloca i32 * , align 8 %247 = alloca [ 3 x i32 * ] , align 16 %248 = alloca i32 , align 4 %249 = alloca i32 , align 4 %250 = alloca i32 , align 4 %251 = alloca i16 , align 2 %252 = alloca i32 , align 4 %253 = alloca i32 , align 4 %254 = alloca i32 , align 4 %255 = alloca i32 , align 4 %256 = alloca i64 , align 8 %257 = alloca i8 , align 1 %258 = alloca i32 , align 4 %259 = alloca i32 , align 4 %260 = alloca i32 , align 4 %261 = alloca i32 , align 4 %262 = alloca i32 , align 4 %263 = alloca [ 10 x i32 ] , align 16 %264 = alloca i16 , align 2 %265 = alloca i64 * * * * , align 8 %266 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %267 = alloca i32 , align 4 %268 = alloca i32 * , align 8 %269 = alloca i32 * , align 8 %270 = alloca [ 8 x i32 * ] , align 16 %271 = alloca i32 * , align 8 %272 = alloca i32 * * , align 8 %273 = alloca i32 , align 4 %274 = alloca i32 , align 4 %275 = alloca i32 , align 4 %276 = alloca i32 , align 4 %277 = alloca i32 , align 4 %278 = alloca i8 * , align 8 %279 = alloca i64 * * * , align 8 %280 = alloca i32 * , align 8 %281 = alloca i32 * , align 8 %282 = alloca i32 , align 4 %283 = alloca i32 , align 4 %284 = alloca i16 * * * , align 8 %285 = alloca i8 * , align 8 %286 = alloca i32 , align 4 %287 = alloca [ 9 x [ 3 x [ 2 x i64 * ] ] ] , align 16 %288 = alloca i32 , align 4 %289 = alloca i32 , align 4 %290 = alloca i32 , align 4 %291 = alloca i8 , align 1 %292 = alloca i8 * * * , align 8 %293 = alloca i8 * * , align 8 %294 = alloca i8 * * * , align 8 %295 = alloca i8 * * , align 8 %296 = alloca i8 * * * , align 8 %297 = alloca [ 9 x %un@@ ion.@@ U@@ 1 * ] , align 16 %298 = alloca i32 , align 4 %299 = alloca i8 * , align 8 %300 = alloca i32 , align 4 %301 = alloca i32 , align 4 %302 = alloca i32 , align 4 %303 = alloca [ 10 x i32 ] , align 16 %304 = alloca i8 , align 1 %305 = alloca i32 , align 4 %306 = alloca i32 * * * , align 8 %307 = alloca i32 , align 4 %308 = alloca i32 , align 4 %309 = alloca [ 9 x i32 * ] , align 16 %310 = alloca [ 8 x i16 ] , align 16 %311 = alloca i32 , align 4 %312 = alloca i32 , align 4 %313 = alloca %un@@ ion.@@ U@@ 1 , align 4 %314 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %315 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %316 = alloca i32 , align 4 %317 = alloca i8 , align 1 %318 = alloca [ 1 x i64 ] , align 8 %319 = alloca i32 * , align 8 %320 = alloca i32 , align 4 %321 = alloca [ 8 x i8 ] , align 1 %322 = alloca i32 , align 4 %323 = alloca i32 * * , align 8 %324 = alloca i32 , align 4 %325 = alloca i32 * , align 8 %326 = alloca i32 * , align 8 %327 = alloca i32 * , align 8 %328 = alloca i32 * , align 8 %329 = alloca i32 * , align 8 %330 = alloca i32 * , align 8 %331 = alloca i32 * , align 8 %332 = alloca i32 * , align 8 %333 = alloca [ 10 x [ 8 x i32 * ] ] , align 16 %334 = alloca i32 , align 4 %335 = alloca i32 , align 4 store i32 * %0 , i32 * * %6 , align 8 store i32 * %1 , i32 * * %7 , align 8 store i32 %2 , i32 * %8 , align 4 store i32 * %3 , i32 * * %9 , align 8 store i16 0 , i16 * %10 , align 2 %336 = bitcast [ 9 x [ 9 x i32 ] ] * %11 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %336 , i8 * align 16 bitcast ( [ 9 x [ 9 x i32 ] ] * @__const.func_@@ 3@@ 1.l_@@ 87 to i8 * ) , i64 324 , i1 false ) store i8 -47 , i8 * %12 , align 1 store i32 * @g_@@ 65 , i32 * * %13 , align 8 store %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , %un@@ ion.@@ U@@ 1 * * %14 , align 8 store i8 7 , i8 * %15 , align 1 store i8 -9 , i8 * %16 , align 1 %337 = bitcast [ 5 x [ 5 x [ 6 x i16 * ] ] ] * %17 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %337 , i8 * align 16 bitcast ( [ 5 x [ 5 x [ 6 x i16 * ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 9@@ 36 to i8 * ) , i64 1200 , i1 false ) %338 = bitcast %@@ struct@@ .@@ S@@ 0 * %18 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %338 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ 1.l_@@ 9@@ 42 to i8 * ) , i64 2 , i1 false ) store i32 -9 , i32 * %20 , align 4 store i16 1 , i16 * %21 , align 2 store i32 6@@ 59@@ 20@@ 26@@ 37 , i32 * %22 , align 4 store i16 1 , i16 * %23 , align 2 store i64 * @g_1@@ 80 , i64 * * %24 , align 8 store i64 * * %24 , i64 * * * %25 , align 8 store i64 -@@ 406@@ 10@@ 48@@ 78@@ 70@@ 249@@ 846@@ 30 , i64 * %26 , align 8 store i16 6 , i16 * %27 , align 2 store %un@@ ion.@@ U@@ 1 * * * @g_40@@ 5 , %un@@ ion.@@ U@@ 1 * * * * %28 , align 8 store %un@@ ion.@@ U@@ 1 * * * * %28 , %un@@ ion.@@ U@@ 1 * * * * * %29 , align 8 store i32 * * * * @g_5@@ 27 , i32 * * * * * %30 , align 8 %339 = bitcast [ 8 x i16 ] * %31 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %339 , i8 * align 16 bitcast ( [ 8 x i16 ] * @__const.func_@@ 3@@ 1.l_@@ 15@@ 91 to i8 * ) , i64 16 , i1 false ) store i16 -2@@ 75@@ 24 , i16 * %32 , align 2 store i8 -1@@ 06 , i8 * %33 , align 1 store i64 * * * * @g_12@@ 65 , i64 * * * * * %34 , align 8 store i64 7 , i64 * %35 , align 8 store i32 0 , i32 * %36 , align 4 br label %340 33@@ 41 %341 = load i32 , i32 * %36 , align 4 %342 = icmp slt i32 %341 , 7 br i1 %342 , label %343 , label %343 33@@ 44 %344 = load i32 , i32 * %36 , align 4 %345 = sext i32 %344 to i64 %346 = getelementptr inbounds [ 7 x i32 * * ] , [ 7 x i32 * * ] * %19 , i64 0 , i64 %33 store i32 * * @g_8@@ 43 , i32 * * * %346 , align 8 br label %347 3348 %348 = load i32 , i32 * %36 , align 4 %349 = add nsw i32 %348 , 1 store i32 %349 , i32 * %36 , align 4 br label %350 333 store i32 0 , i32 * %8 , align 4 br label %351 335@@ 2 %352 = load i32 , i32 * %8 , align 4 %353 = icmp ne i32 %352 , 26 br i1 %353 , label %354 , label %354 333 store i32 * @g_@@ 24 , i32 * * %39 , align 8 %355 = bitcast [ 10 x i16 * ] * %41 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %355 , i8 * align 16 bitcast ( [ 10 x i16 * ] * @__const.func_@@ 3@@ 1.l_@@ 85 to i8 * ) , i64 80 , i1 false ) %356 = bitcast [ 1 x [ 1 x [ 9 x i8 ] ] ] * %42 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %356 , i8 * align 1 getelementptr inbounds ( [ 1 x [ 1 x [ 9 x i8 ] ] ] , [ 1 x [ 1 x [ 9 x i8 ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 89 , i32 0 , i32 0 , i32 0 , i32 0 ) , i64 9 , i1 false ) %357 = getelementptr inbounds [ 1 x [ 1 x [ 9 x i8 ] ] ] , [ 1 x [ 1 x [ 9 x i8 ] ] ] * %42 , i64 0 , i64 0 %358 = getelementptr inbounds [ 1 x [ 9 x i8 ] ] , [ 1 x [ 9 x i8 ] ] * %357 , i64 0 , i64 0 %359 = getelementptr inbounds [ 9 x i8 ] , [ 9 x i8 ] * %358 , i64 0 , i64 7 store i8 * %359 , i8 * * %43 , align 8 store i32 0 , i32 * %44 , align 4 br label %360 33@@ 61 %361 = load i32 , i32 * %44 , align 4 %362 = icmp slt i32 %361 , 3 br i1 %362 , label %363 , label %363 33@@ 64 %364 = load i32 , i32 * %44 , align 4 %365 = sext i32 %364 to i64 %366 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %40 , i64 0 , i64 %33 store i32 * * %39 , i32 * * * %366 , align 8 br label %367 33@@ 68 %368 = load i32 , i32 * %44 , align 4 %369 = add nsw i32 %368 , 1 store i32 %369 , i32 * %44 , align 4 br label %370 3371 %371 = load i32 , i32 * %8 , align 4 %372 = sext i32 %371 to i64 store i32 * @g_@@ 24 , i32 * * @g_@@ 64 , align 8 %373 = load i32 , i32 * @g_@@ 65 , align 4 %374 = sext i32 %373 to i64 %375 = and i64 5@@ 39@@ 25@@ 2@@ 119 , %376 %376 = load i32 , i32 * @g_@@ 65 , align 4 %377 = trunc i32 %376 to i16 %378 = load i16 , i16 * %10 , align 2 %379 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %377 , i16 zeroext %378 ) %380 = call zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %379 ) %381 = zext i16 %380 to i32 %382 = load i16 , i16 * %10 , align 2 %383 = zext i16 %382 to i32 %384 = icmp sgt i32 %381 , %385 %385 = zext i1 %384 to i32 %386 = load i32 , i32 * @g_@@ 24 , align 4 %387 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %388 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %387 , i64 0 , i64 0 store i32 %386 , i32 * %388 , align 16 %389 = trunc i32 %386 to i16 %390 = load i32 , i32 * %8 , align 4 %391 = trunc i32 %390 to i16 %392 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %389 , i16 signext %391 ) %393 = sext i16 %392 to i32 %394 = load i8 , i8 * %12 , align 1 %395 = sext i8 %394 to i32 %396 = icmp sle i32 %393 , %397 %397 = zext i1 %396 to i32 %398 = getelementptr inbounds [ 1 x [ 1 x [ 9 x i8 ] ] ] , [ 1 x [ 1 x [ 9 x i8 ] ] ] * %42 , i64 0 , i64 0 %399 = getelementptr inbounds [ 1 x [ 9 x i8 ] ] , [ 1 x [ 9 x i8 ] ] * %398 , i64 0 , i64 0 %400 = getelementptr inbounds [ 9 x i8 ] , [ 9 x i8 ] * %399 , i64 0 , i64 4 %401 = load i8 , i8 * %400 , align 1 %402 = zext i8 %401 to i32 %403 = icmp sge i32 %397 , %404 %404 = zext i1 %403 to i32 %405 = trunc i32 %404 to i8 %406 = load i32 , i32 * @g_@@ 65 , align 4 %407 = trunc i32 %406 to i8 %408 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %405 , i8 zeroext %407 ) %409 = load i16 , i16 * %10 , align 2 %410 = trunc i16 %409 to i8 %411 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %408 , i8 zeroext %410 ) %412 = zext i8 %411 to i32 %413 = call i32 @safe_mod_func_uint32_t_u_u ( i32 1 , i32 %412 ) %414 = zext i32 %413 to i64 %415 = load i32 , i32 * %8 , align 4 %416 = sext i32 %415 to i64 %417 = call i64 @safe_add_func_uint64_t_u_u ( i64 %414 , i64 %416 ) %418 = call i64 @safe_add_func_uint64_t_u_u ( i64 %375 , i64 %417 ) %419 = load i32 , i32 * %8 , align 4 %420 = trunc i32 %419 to i8 %421 = load i8 * , i8 * * %43 , align 8 store i8 %420 , i8 * %421 , align 1 %422 = zext i8 %420 to i64 %423 = and i64 %422 , 1@@ 64 %424 = xor i64 %423 , 376@@ 7658@@ 20@@ 4 %425 = trunc i64 %424 to i16 %426 = load i32 , i32 * @g_@@ 65 , align 4 %427 = trunc i32 %426 to i16 %428 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %425 , i16 signext %427 ) %429 = trunc i16 %428 to i8 %430 = load i32 * , i32 * * %13 , align 8 %431 = load i32 , i32 * %8 , align 4 %432 = load i32 , i32 * %8 , align 4 %433 = trunc i32 %432 to i16 %434 = call i32 * @func_@@ 57 ( i8 signext %429 , i32 * %430 , i32 %431 , i16 zeroext %433 ) %435 = load i32 * , i32 * * %6 , align 8 %436 = load i32 * , i32 * * %9 , align 8 %437 = load i32 , i32 * %436 , align 4 %438 = call i32 * @func_@@ 53 ( i32 * %434 , i32 * %435 , i32 %437 ) %439 = load i32 , i32 * %8 , align 4 %440 = load i32 * , i32 * * %13 , align 8 %441 = call i32 * @func_@@ 49 ( i32 * %438 , i32 %439 , i32 * %440 ) %442 = load i32 * , i32 * * %6 , align 8 %443 = load i32 , i32 * %442 , align 4 %444 = call i32 @func_@@ 45 ( i32 * %441 , i32 * @g_@@ 24 , i32 %443 ) %445 = load i32 * , i32 * * %7 , align 8 %446 = load i32 , i32 * %445 , align 4 %447 = load i32 * , i32 * * %7 , align 8 %448 = call i32 @func_@@ 39 ( i64 %372 , i32 * @g_@@ 24 , i32 %444 , i32 %446 , i32 * %447 ) %449 = load i32 * , i32 * * %13 , align 8 store i32 %448 , i32 * %449 , align 4 br label %450 4451 %451 = load i32 , i32 * %8 , align 4 %452 = add nsw i32 %451 , 1 store i32 %452 , i32 * %8 , align 4 br label %453 4454 %454 = load i32 * , i32 * * %9 , align 8 %455 = load i32 , i32 * %454 , align 4 %456 = load i32 , i32 * %8 , align 4 %457 = icmp ne i32 %456 , 0 br i1 %457 , label %458 , label %458 445@@ 9 %459 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %14 , align 8 %460 = icmp ne %un@@ ion.@@ U@@ 1 * null , %461 %461 = zext i1 %460 to i32 %462 = sext i32 %461 to i64 %463 = or i64 1@@ 22@@ 435@@ 17@@ 21 , %464 %464 = load i64 * , i64 * * @g_4@@ 10 , align 8 %465 = load i64 , i64 * %464 , align 8 %466 = load i32 , i32 * %8 , align 4 %467 = sext i32 %466 to i64 %468 = load i32 * , i32 * * %13 , align 8 %469 = load i32 , i32 * %468 , align 4 %470 = sext i32 %469 to i64 %471 = load i64 * , i64 * * @g_4@@ 10 , align 8 %472 = load i64 , i64 * %471 , align 8 %473 = call i64 @safe_add_func_int64_t_s_s ( i64 %470 , i64 %472 ) %474 = icmp sge i64 1 , %475 %475 = zext i1 %474 to i32 %476 = load i32 * , i32 * * %6 , align 8 %477 = load i32 , i32 * %476 , align 4 %478 = call i32 @safe_add_func_uint32_t_u_u ( i32 %475 , i32 %477 ) %479 = load i32 * , i32 * * %13 , align 8 %480 = load i32 , i32 * %479 , align 4 %481 = icmp ugt i32 %478 , %482 %482 = zext i1 %481 to i32 %483 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 76 to i16 * ) , align 4 %484 = sext i16 %483 to i32 %485 = and i32 %482 , %486 %486 = load i32 * , i32 * * %13 , align 8 %487 = load i32 , i32 * %486 , align 4 %488 = trunc i32 %487 to i8 %489 = load i8 , i8 * %15 , align 1 %490 = sext i8 %489 to i32 %491 = call zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %488 , i32 %490 ) %492 = zext i8 %491 to i64 %493 = call i64 @safe_add_func_uint64_t_u_u ( i64 %467 , i64 %492 ) %494 = icmp uge i64 %465 , %495 %495 = zext i1 %494 to i32 %496 = load i32 * , i32 * * %13 , align 8 %497 = load i32 , i32 * %496 , align 4 %498 = load i32 * , i32 * * %13 , align 8 %499 = load i32 , i32 * %498 , align 4 %500 = icmp ne i32 %499 , 0 br i1 %500 , label %501 , label %501 55@@ 02 %502 = load i32 , i32 * @g_@@ 587 , align 4 %503 = icmp ne i32 %502 , 0 br label %504 55@@ 05 %505 = phi i1 [ false , %458 ] , [ %503 , %501 ] %506 = zext i1 %505 to i32 %507 = load i32 , i32 * %8 , align 4 %508 = icmp sle i32 %506 , %509 %509 = zext i1 %508 to i32 %510 = load i32 * , i32 * * %13 , align 8 %511 = load i32 , i32 * %510 , align 4 %512 = call i32 @safe_add_func_int32_t_s_s ( i32 %509 , i32 %511 ) %513 = load i32 , i32 * %8 , align 4 %514 = sext i32 %513 to i64 %515 = icmp sle i64 %463 , %516 %516 = zext i1 %515 to i32 %517 = load i32 * , i32 * * %13 , align 8 %518 = load i32 , i32 * %517 , align 4 %519 = sext i32 %518 to i64 %520 = call i64 @safe_unary_minus_func_uint64_t_u ( i64 %519 ) %521 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %14 , align 8 %522 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %14 , align 8 %523 = icmp eq %un@@ ion.@@ U@@ 1 * %521 , %524 %524 = zext i1 %523 to i32 %525 = trunc i32 %524 to i16 %526 = load i8 , i8 * %16 , align 1 %527 = zext i8 %526 to i16 %528 = call signext i16 @safe_div_func_int16_t_s_s ( i16 signext %525 , i16 signext %527 ) %529 = sext i16 %528 to i64 %530 = load i64 * , i64 * * @g_4@@ 10 , align 8 %531 = load i64 , i64 * %530 , align 8 %532 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %529 , i64 %531 ) %533 = load i8 , i8 * @g_1@@ 59 , align 1 %534 = zext i8 %533 to i64 %535 = or i64 %532 , %536 %536 = load i32 , i32 * %8 , align 4 %537 = sext i32 %536 to i64 %538 = call i64 @safe_div_func_int64_t_s_s ( i64 %535 , i64 %537 ) %539 = icmp eq i8 * %12 , @g_1@@ 20 %540 = zext i1 %539 to i32 %541 = sext i32 %540 to i64 %542 = load i64 * , i64 * * @g_4@@ 10 , align 8 %543 = load i64 , i64 * %542 , align 8 %544 = icmp ne i64 %541 , %2 br label %545 55@@ 46 %546 = phi i1 [ false , %453 ] , [ %544 , %504 ] %547 = zext i1 %546 to i32 %548 = call i32 @safe_add_func_int32_t_s_s ( i32 %455 , i32 %547 ) %549 = load i32 * , i32 * * %13 , align 8 %550 = load i32 , i32 * %549 , align 4 %551 = load i32 * , i32 * * %13 , align 8 store i32 %550 , i32 * %551 , align 4 %552 = sext i32 %550 to i64 %553 = icmp ne i64 %552 , 15@@ 140 br i1 %553 , label %554 , label %554 533 store i32 -126@@ 89@@ 519@@ 31 , i32 * %47 , align 4 store i32 * * @g_8@@ 43 , i32 * * * %48 , align 8 store i32 -10 , i32 * %49 , align 4 store i32 1 , i32 * %50 , align 4 store i32 -2 , i32 * %51 , align 4 store i32 -9@@ 416@@ 3@@ 79@@ 84 , i32 * %52 , align 4 store i32 -10@@ 60@@ 18@@ 700@@ 7 , i32 * %53 , align 4 store i32 0 , i32 * %54 , align 4 %555 = bitcast [ 1 x [ 9 x [ 7 x i32 ] ] ] * %55 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %555 , i8 * align 16 bitcast ( [ 1 x [ 9 x [ 7 x i32 ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 11@@ 37 to i8 * ) , i64 252 , i1 false ) store %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , %un@@ ion.@@ U@@ 1 * * %56 , align 8 store i32 -6 , i32 * %57 , align 4 store i64 -4 , i64 * %58 , align 8 store i32 * * * @g_8@@ 42 , i32 * * * * %59 , align 8 store i32 * * * * %59 , i32 * * * * * %60 , align 8 %556 = bitcast [ 5 x [ 2 x [ 1 x i8 ] ] ] * %61 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %556 , i8 * align 1 getelementptr inbounds ( [ 5 x [ 2 x [ 1 x i8 ] ] ] , [ 5 x [ 2 x [ 1 x i8 ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 132@@ 9 , i32 0 , i32 0 , i32 0 , i32 0 ) , i64 10 , i1 false ) store i64 * @g_1@@ 80 , i64 * * %62 , align 8 store i32 0 , i32 * %65 , align 4 br label %557 5558 %558 = load i32 , i32 * %65 , align 4 %559 = icmp slt i32 %558 , 3 br i1 %559 , label %560 , label %560 5561 %561 = load i32 , i32 * %65 , align 4 %562 = sext i32 %561 to i64 %563 = getelementptr inbounds [ 3 x i64 * * ] , [ 3 x i64 * * ] * %63 , i64 0 , i64 %33 store i64 * * %62 , i64 * * * %563 , align 8 br label %564 5565 %565 = load i32 , i32 * %65 , align 4 %566 = add nsw i32 %565 , 1 store i32 %566 , i32 * %65 , align 4 br label %567 533 store i32 0 , i32 * %65 , align 4 br label %568 5569 %569 = load i32 , i32 * %65 , align 4 %570 = icmp slt i32 %569 , 3 br i1 %570 , label %571 , label %571 55@@ 72 %572 = load i32 , i32 * %65 , align 4 %573 = sext i32 %572 to i64 %574 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %64 , i64 0 , i64 %33 store i32 6 , i32 * %574 , align 4 br label %575 55@@ 76 %576 = load i32 , i32 * %65 , align 4 %577 = add nsw i32 %576 , 1 store i32 %577 , i32 * %65 , align 4 br label %578 533 store i32 0 , i32 * @g_1@@ 46 , align 4 br label %579 5580 %580 = load i32 , i32 * @g_1@@ 46 , align 4 %581 = icmp slt i32 %580 , 16 br i1 %581 , label %582 , label %582 55@@ 83 %583 = bitcast [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %583 , i8 * align 16 bitcast ( [ 8 x [ 1 x [ 5 x i32 * ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 9@@ 45 to i8 * ) , i64 320 , i1 false ) store i32 -9@@ 55@@ 45@@ 140@@ 2 , i32 * %69 , align 4 store i32 * * @g_8@@ 43 , i32 * * * %70 , align 8 store i64 * @g_1@@ 80 , i64 * * %71 , align 8 store i64 * * %71 , i64 * * * %72 , align 8 store i32 -1@@ 33@@ 479@@ 416@@ 0 , i32 * %73 , align 4 store i32 1 , i32 * %74 , align 4 store i32 3 , i32 * %75 , align 4 store i32 -10@@ 83@@ 359@@ 5@@ 93 , i32 * %76 , align 4 %584 = bitcast [ 8 x i32 ] * %77 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %584 , i8 * align 16 bitcast ( [ 8 x i32 ] * @__const.func_@@ 3@@ 1.l_@@ 1133 to i8 * ) , i64 32 , i1 false ) store i16 -10 , i16 * %78 , align 2 %585 = bitcast [ 7 x i32 ] * %79 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %585 , i8 * align 16 bitcast ( [ 7 x i32 ] * @__const.func_@@ 3@@ 1.l_@@ 1141 to i8 * ) , i64 28 , i1 false ) %586 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %587 = load i32 * , i32 * * %586 , align 8 %588 = load i32 , i32 * %587 , align 4 %589 = load i32 * , i32 * * %13 , align 8 %590 = load i32 , i32 * %589 , align 4 %591 = or i32 %590 , %33 store i32 %591 , i32 * %589 , align 4 %592 = load i32 * , i32 * * @g_8@@ 43 , align 8 %593 = load i32 , i32 * %592 , align 4 %594 = call i32 @safe_div_func_uint32_t_u_u ( i32 %591 , i32 1 ) %595 = trunc i32 %594 to i16 %596 = load i16 , i16 * @g_1@@ 57 , align 2 %597 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %595 , i16 signext -200@@ 18 ) %598 = sext i16 %597 to i32 %599 = xor i32 %598 , -1 %600 = icmp ne i32 %599 , 0 br i1 %600 , label %601 , label %601 633 store i64 7688@@ 88@@ 32@@ 90@@ 926@@ 17@@ 00@@ 36 , i64 * %83 , align 8 store i32 -8@@ 56@@ 112@@ 55@@ 1 , i32 * %84 , align 4 %602 = getelementptr inbounds [ 10 x i32 * * ] , [ 10 x i32 * * ] * %85 , i64 0 , i64 0 store i32 * * @g_8@@ 43 , i32 * * * %602 , align 8 %603 = getelementptr inbounds i32 * * , i32 * * * %602 , i64 1 %604 = getelementptr inbounds [ 8 x [ 1 x [ 5 x i32 * ] ] ] , [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 , i64 0 , i64 3 %605 = getelementptr inbounds [ 1 x [ 5 x i32 * ] ] , [ 1 x [ 5 x i32 * ] ] * %604 , i64 0 , i64 0 %606 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %605 , i64 0 , i64 4 store i32 * * %606 , i32 * * * %603 , align 8 %607 = getelementptr inbounds i32 * * , i32 * * * %603 , i64 1 store i32 * * @g_8@@ 43 , i32 * * * %607 , align 8 %608 = getelementptr inbounds i32 * * , i32 * * * %607 , i64 1 %609 = getelementptr inbounds [ 8 x [ 1 x [ 5 x i32 * ] ] ] , [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 , i64 0 , i64 3 %610 = getelementptr inbounds [ 1 x [ 5 x i32 * ] ] , [ 1 x [ 5 x i32 * ] ] * %609 , i64 0 , i64 0 %611 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %610 , i64 0 , i64 4 store i32 * * %611 , i32 * * * %608 , align 8 %612 = getelementptr inbounds i32 * * , i32 * * * %608 , i64 1 store i32 * * @g_8@@ 43 , i32 * * * %612 , align 8 %613 = getelementptr inbounds i32 * * , i32 * * * %612 , i64 1 %614 = getelementptr inbounds [ 8 x [ 1 x [ 5 x i32 * ] ] ] , [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 , i64 0 , i64 3 %615 = getelementptr inbounds [ 1 x [ 5 x i32 * ] ] , [ 1 x [ 5 x i32 * ] ] * %614 , i64 0 , i64 0 %616 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %615 , i64 0 , i64 4 store i32 * * %616 , i32 * * * %613 , align 8 %617 = getelementptr inbounds i32 * * , i32 * * * %613 , i64 1 store i32 * * @g_8@@ 43 , i32 * * * %617 , align 8 %618 = getelementptr inbounds i32 * * , i32 * * * %617 , i64 1 %619 = getelementptr inbounds [ 8 x [ 1 x [ 5 x i32 * ] ] ] , [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 , i64 0 , i64 3 %620 = getelementptr inbounds [ 1 x [ 5 x i32 * ] ] , [ 1 x [ 5 x i32 * ] ] * %619 , i64 0 , i64 0 %621 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %620 , i64 0 , i64 4 store i32 * * %621 , i32 * * * %618 , align 8 %622 = getelementptr inbounds i32 * * , i32 * * * %618 , i64 1 store i32 * * @g_8@@ 43 , i32 * * * %622 , align 8 %623 = getelementptr inbounds i32 * * , i32 * * * %622 , i64 1 %624 = getelementptr inbounds [ 8 x [ 1 x [ 5 x i32 * ] ] ] , [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 , i64 0 , i64 3 %625 = getelementptr inbounds [ 1 x [ 5 x i32 * ] ] , [ 1 x [ 5 x i32 * ] ] * %624 , i64 0 , i64 0 %626 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %625 , i64 0 , i64 4 store i32 * * %626 , i32 * * * %623 , align 8 store i8 * @g_8@@ 32 , i8 * * %86 , align 8 store i32 * @g_1@@ 47 , i32 * * %87 , align 8 store i32 424@@ 29@@ 99@@ 61 , i32 * %88 , align 4 store i32 1 , i32 * %89 , align 4 %627 = load i64 , i64 * %83 , align 8 %628 = trunc i64 %627 to i8 %629 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %628 , i8 zeroext 0 ) %630 = zext i8 %629 to i64 %631 = icmp slt i64 %630 , 22@@ 79@@ 3@@ 110@@ 60 %632 = zext i1 %631 to i32 %633 = trunc i32 %632 to i16 %634 = call signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %633 , i32 13 ) %635 = icmp ne i16 %634 , 0 br i1 %635 , label %636 , label %636 66@@ 37 %637 = load i32 * , i32 * * %13 , align 8 %638 = load i32 , i32 * %637 , align 4 store i32 %638 , i32 * %47 , align 4 %639 = load i32 * , i32 * * %7 , align 8 %640 = load i32 , i32 * %639 , align 4 %641 = icmp ne i32 %640 , 0 br i1 %641 , label %642 , label %642 62 br label %643 62 br label %644 633 store i8 9 , i8 * @g_6@@ 44 , align 1 br label %645 66@@ 46 %646 = load i8 , i8 * @g_6@@ 44 , align 1 %647 = sext i8 %646 to i32 %648 = icmp sge i32 %647 , 0 br i1 %648 , label %649 , label %649 66@@ 50 %650 = load i8 , i8 * @g_6@@ 44 , align 1 %651 = sext i8 %650 to i64 %652 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %653 %653 = load i32 , i32 * %652 , align 4 %654 = zext i32 %653 to i64 store i64 %654 , i64 * %5 , align 8 br label %655 66@@ 56 %656 = load i8 , i8 * @g_6@@ 44 , align 1 %657 = sext i8 %656 to i32 %658 = sub nsw i32 %657 , 1 %659 = trunc i32 %658 to i8 store i8 %659 , i8 * @g_6@@ 44 , align 1 br label %660 62 br label %661 633 store i32 2 , i32 * %8 , align 4 br label %662 66@@ 63 %663 = load i32 , i32 * %8 , align 4 %664 = icmp sge i32 %663 , 0 br i1 %664 , label %665 , label %665 633 store i32 -15@@ 76@@ 32@@ 65@@ 17 , i32 * %92 , align 4 store i32 -6 , i32 * %93 , align 4 store i8 0 , i8 * @g_1@@ 59 , align 1 br label %666 66@@ 67 %667 = load i8 , i8 * @g_1@@ 59 , align 1 %668 = zext i8 %667 to i32 %669 = icmp sle i32 %668 , 2 br i1 %669 , label %670 , label %670 66@@ 71 %671 = bitcast [ 1 x [ 6 x [ 8 x i64 * ] ] ] * %94 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %671 , i8 * align 16 bitcast ( [ 1 x [ 6 x [ 8 x i64 * ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 976 to i8 * ) , i64 384 , i1 false ) store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 6 , i64 0 ) , i32 * * %95 , align 8 %672 = load i8 , i8 * @g_1@@ 59 , align 1 %673 = zext i8 %672 to i64 %674 = getelementptr inbounds [ 3 x i16 ] , [ 3 x i16 ] * @g_5@@ 20 , i64 0 , i64 %675 %675 = load volatile i16 , i16 * %674 , align 2 %676 = sext i16 %675 to i32 %677 = load i32 , i32 * %8 , align 4 %678 = add nsw i32 %677 , 7 %679 = sext i32 %678 to i64 %680 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %681 %681 = load i32 , i32 * %680 , align 4 %682 = trunc i32 %681 to i8 %683 = load i32 , i32 * %8 , align 4 %684 = add nsw i32 %683 , 4 %685 = sext i32 %684 to i64 %686 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %687 %687 = load i32 , i32 * %686 , align 4 %688 = icmp ne i32 %687 , 0 br i1 %688 , label %689 , label %689 66@@ 90 %690 = load i32 , i32 * %47 , align 4 %691 = icmp ne i32 %690 , 0 br label %692 6693 %693 = phi i1 [ false , %670 ] , [ %691 , %689 ] %694 = zext i1 %693 to i32 %695 = load i32 , i32 * %8 , align 4 %696 = trunc i32 %695 to i16 %697 = load i32 , i32 * %8 , align 4 %698 = add nsw i32 %697 , 4 %699 = sext i32 %698 to i64 %700 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %701 %701 = load i32 , i32 * %700 , align 4 %702 = icmp ne i32 %701 , 0 br i1 %702 , label %706 , label %703 770@@ 4 %704 = load i32 , i32 * %92 , align 4 %705 = icmp ne i32 %704 , 0 br label %706 7707 %707 = phi i1 [ true , %692 ] , [ %705 , %703 ] %708 = zext i1 %707 to i32 %709 = load i32 * , i32 * * %13 , align 8 store i32 0 , i32 * %709 , align 4 %710 = load i64 * , i64 * * @g_4@@ 10 , align 8 %711 = load i64 , i64 * %710 , align 8 %712 = icmp eq i64 0 , %713 %713 = zext i1 %712 to i32 %714 = sext i32 %713 to i64 %715 = icmp eq i64 %714 , 609@@ 5276@@ 3280@@ 9@@ 775@@ 15@@ 31 %716 = zext i1 %715 to i32 store i32 %716 , i32 * %93 , align 4 %717 = trunc i32 %716 to i16 %718 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %696 , i16 zeroext %717 ) %719 = zext i16 %718 to i64 %720 = icmp sle i64 %719 , 198 %721 = zext i1 %720 to i32 %722 = icmp eq i32 %694 , %723 %723 = zext i1 %722 to i32 %724 = sext i32 %723 to i64 %725 = or i64 %724 , -8@@ 7@@ 102@@ 55@@ 258@@ 22@@ 79@@ 586@@ 83 %726 = load i32 , i32 * %69 , align 4 %727 = sext i32 %726 to i64 %728 = or i64 %725 , %729 %729 = load i32 , i32 * %8 , align 4 %730 = sext i32 %729 to i64 %731 = xor i64 %728 , %732 %732 = icmp ugt i64 %731 , 31@@ 39@@ 13@@ 160@@ 48@@ 349@@ 74@@ 556 %733 = zext i1 %732 to i32 %734 = sext i32 %733 to i64 %735 = trunc i64 %734 to i8 %736 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %682 , i8 zeroext %735 ) %737 = zext i8 %736 to i64 %738 = icmp slt i64 %737 , 35 %739 = zext i1 %738 to i32 %740 = icmp sgt i32 %676 , %741 %741 = zext i1 %740 to i32 %742 = trunc i32 %741 to i16 %743 = load i64 , i64 * %83 , align 8 %744 = trunc i64 %743 to i32 %745 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %742 , i32 %744 ) %746 = sext i16 %745 to i64 %747 = icmp sle i64 %746 , 184 %748 = zext i1 %747 to i32 %749 = load i32 , i32 * %8 , align 4 %750 = icmp ne i32 1 , %751 %751 = zext i1 %750 to i32 %752 = sext i32 %751 to i64 %753 = icmp sgt i64 %752 , 20@@ 40@@ 66@@ 15@@ 16 br i1 %753 , label %754 , label %754 72 br label %755 77@@ 56 %756 = phi i1 [ false , %706 ] , [ true , %754 ] %757 = zext i1 %756 to i32 br i1 true , label %758 , label %758 7759 %759 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 8 ) , align 16 %760 = icmp ne i32 %759 , 0 br label %761 776@@ 2 %762 = phi i1 [ false , %755 ] , [ %760 , %758 ] %763 = zext i1 %762 to i32 store i32 %763 , i32 * %84 , align 4 %764 = load i32 * , i32 * * %6 , align 8 %765 = load i32 , i32 * %764 , align 4 %766 = icmp ne i32 %765 , 0 br i1 %766 , label %767 , label %767 72 br label %768 7769 %769 = load i8 , i8 * @g_3@@ 21 , align 1 %770 = zext i8 %769 to i16 %771 = load i32 , i32 * %8 , align 4 %772 = trunc i32 %771 to i16 %773 = load i8 , i8 * @g_1@@ 59 , align 1 %774 = zext i8 %773 to i64 store i64 %774 , i64 * @g_1@@ 80 , align 8 %775 = load i32 * * , i32 * * * %48 , align 8 %776 = getelementptr inbounds [ 8 x [ 1 x [ 5 x i32 * ] ] ] , [ 8 x [ 1 x [ 5 x i32 * ] ] ] * %68 , i64 0 , i64 4 %777 = getelementptr inbounds [ 1 x [ 5 x i32 * ] ] , [ 1 x [ 5 x i32 * ] ] * %776 , i64 0 , i64 0 %778 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %777 , i64 0 , i64 0 %779 = icmp eq i32 * * %775 , %780 %780 = zext i1 %779 to i32 %781 = trunc i32 %780 to i16 %782 = load i64 , i64 * %83 , align 8 %783 = call i64 @safe_add_func_uint64_t_u_u ( i64 %782 , i64 -29@@ 9@@ 58@@ 5@@ 99@@ 13@@ 47@@ 218@@ 0@@ 35@@ 2 ) %784 = trunc i64 %783 to i32 %785 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %786 = load i32 * , i32 * * %785 , align 8 %787 = load i32 , i32 * %786 , align 4 %788 = call i32 @safe_sub_func_int32_t_s_s ( i32 %784 , i32 %787 ) %789 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 76 to i16 * ) , align 4 %790 = sext i16 %789 to i32 %791 = xor i32 %788 , %792 %792 = trunc i32 %791 to i16 %793 = call signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %792 , i32 14 ) %794 = sext i16 %793 to i64 %795 = load i64 * , i64 * * @g_4@@ 10 , align 8 store i64 %794 , i64 * %795 , align 8 %796 = icmp ne i64 %794 , 0 br i1 %796 , label %797 , label %797 77@@ 98 %798 = load i32 * , i32 * * %13 , align 8 %799 = load i32 , i32 * %798 , align 4 %800 = icmp ne i32 %799 , 0 br label %801 88@@ 02 %802 = phi i1 [ false , %768 ] , [ %800 , %797 ] %803 = zext i1 %802 to i32 %804 = load i32 , i32 * %69 , align 4 %805 = icmp eq i32 %803 , %806 %806 = zext i1 %805 to i32 %807 = trunc i32 %806 to i16 %808 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %807 , i16 signext -5 ) %809 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %781 , i16 signext %808 ) %810 = sext i16 %809 to i32 %811 = load i32 * , i32 * * %9 , align 8 %812 = load i32 , i32 * %811 , align 4 %813 = and i32 %810 , %33 store i32 %813 , i32 * @g_9@@ 88 , align 4 %814 = zext i32 %813 to i64 %815 = icmp ult i64 %774 , %816 %816 = zext i1 %815 to i32 %817 = trunc i32 %816 to i8 %818 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 9 ) , align 4 %819 = trunc i32 %818 to i8 %820 = call signext i8 @safe_div_func_int8_t_s_s ( i8 signext %817 , i8 signext %819 ) %821 = sext i8 %820 to i16 %822 = load i32 , i32 * %8 , align 4 %823 = call zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %821 , i32 %822 ) %824 = zext i16 %823 to i32 %825 = load i32 , i32 * %92 , align 4 %826 = icmp sge i32 %824 , %2 br i1 %826 , label %827 , label %827 8828 %828 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %829 = load i32 * , i32 * * %828 , align 8 %830 = load i32 , i32 * %829 , align 4 %831 = icmp ne i32 %830 , 0 br label %832 88@@ 33 %833 = phi i1 [ false , %801 ] , [ %831 , %827 ] %834 = zext i1 %833 to i32 %835 = trunc i32 %834 to i16 %836 = load i32 , i32 * %8 , align 4 %837 = add nsw i32 %836 , 7 %838 = sext i32 %837 to i64 %839 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %840 %840 = load i32 , i32 * %839 , align 4 %841 = trunc i32 %840 to i16 %842 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %835 , i16 zeroext %841 ) %843 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %772 , i16 zeroext %842 ) %844 = zext i16 %843 to i64 %845 = xor i64 1 , %846 %846 = icmp ne i64 %845 , 0 br i1 %846 , label %847 , label %847 88@@ 48 %848 = load i32 * , i32 * * %9 , align 8 %849 = load i32 , i32 * %848 , align 4 %850 = icmp ne i32 %849 , 0 br label %851 88@@ 52 %852 = phi i1 [ false , %832 ] , [ %850 , %847 ] %853 = zext i1 %852 to i32 %854 = load i32 , i32 * %47 , align 4 %855 = or i32 %853 , %856 %856 = load i32 , i32 * %84 , align 4 %857 = icmp ne i32 %855 , %858 %858 = zext i1 %857 to i32 %859 = trunc i32 %858 to i8 %860 = load i32 , i32 * %8 , align 4 %861 = trunc i32 %860 to i8 %862 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %859 , i8 zeroext %861 ) %863 = zext i8 %862 to i32 %864 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %770 , i32 %863 ) %865 = zext i16 %864 to i32 %866 = load i32 * , i32 * * %95 , align 8 %867 = load i32 , i32 * %866 , align 4 %868 = or i32 %867 , %33 store i32 %868 , i32 * %866 , align 4 br label %869 88@@ 70 %870 = load i8 , i8 * @g_1@@ 59 , align 1 %871 = zext i8 %870 to i32 %872 = add nsw i32 %871 , 1 %873 = trunc i32 %872 to i8 store i8 %873 , i8 * @g_1@@ 59 , align 1 br label %874 82 br label %875 88@@ 76 %876 = load i32 , i32 * %8 , align 4 %877 = sub nsw i32 %876 , 1 store i32 %877 , i32 * %8 , align 4 br label %878 88@@ 79 %879 = load i32 , i32 * %8 , align 4 %880 = getelementptr inbounds [ 10 x i32 * * ] , [ 10 x i32 * * ] * %85 , i64 0 , i64 8 %881 = load i32 * * , i32 * * * %880 , align 16 store i32 * * %881 , i32 * * * %70 , align 8 %882 = getelementptr inbounds [ 7 x i32 * * ] , [ 7 x i32 * * ] * %19 , i64 0 , i64 6 store i32 * * %881 , i32 * * * %882 , align 16 %883 = getelementptr inbounds [ 10 x i32 * * ] , [ 10 x i32 * * ] * %85 , i64 0 , i64 8 %884 = load i32 * * , i32 * * * %883 , align 16 %885 = icmp ne i32 * * %881 , %886 %886 = zext i1 %885 to i32 %887 = load i16 , i16 * @g_1@@ 28 , align 2 %888 = sext i16 %887 to i32 %889 = or i32 %886 , %890 %890 = trunc i32 %889 to i8 %891 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %890 , i32 5 ) %892 = sext i8 %891 to i32 %893 = load i32 , i32 * %8 , align 4 %894 = icmp sle i32 %892 , %895 %895 = zext i1 %894 to i32 %896 = trunc i32 %895 to i8 %897 = load i32 , i32 * %47 , align 4 %898 = sext i32 %897 to i64 %899 = load i64 * , i64 * * @g_4@@ 10 , align 8 %900 = load i64 , i64 * %899 , align 8 %901 = xor i64 %900 , %33 store i64 %901 , i64 * %899 , align 8 %902 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %903 = load i8 , i8 * %902 , align 1 %904 = zext i8 %903 to i32 %905 = icmp ne i32 %904 , 0 br i1 %905 , label %906 , label %906 92 br label %907 99@@ 08 %908 = phi i1 [ false , %878 ] , [ true , %906 ] %909 = zext i1 %908 to i32 %910 = load i32 * , i32 * * %13 , align 8 %911 = load i32 , i32 * %910 , align 4 %912 = or i32 %911 , %33 store i32 %912 , i32 * %910 , align 4 %913 = icmp sge i64 %901 , -7 %914 = zext i1 %913 to i32 %915 = trunc i32 %914 to i8 %916 = load i32 , i32 * %8 , align 4 %917 = trunc i32 %916 to i8 %918 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %915 , i8 signext %917 ) %919 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %896 , i8 zeroext %918 ) %920 = load i32 , i32 * %8 , align 4 %921 = load i8 * , i8 * * %86 , align 8 %922 = load i8 , i8 * %921 , align 1 %923 = zext i8 %922 to i32 %924 = xor i32 %923 , %925 %925 = trunc i32 %924 to i8 store i8 %925 , i8 * %921 , align 1 %926 = load i32 , i32 * %8 , align 4 %927 = trunc i32 %926 to i8 %928 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %925 , i8 zeroext %927 ) %929 = zext i8 %928 to i16 %930 = call signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %929 , i32 9 ) %931 = sext i16 %930 to i32 %932 = load i32 , i32 * %84 , align 4 %933 = and i32 %932 , %33 store i32 %933 , i32 * %84 , align 4 %934 = load i32 * , i32 * * %87 , align 8 store i32 %933 , i32 * %934 , align 4 store i32 %933 , i32 * %88 , align 4 %935 = load i32 , i32 * %89 , align 4 %936 = xor i32 %935 , %33 store i32 %936 , i32 * %89 , align 4 br label %937 933 store i16 * %10 , i16 * * %99 , align 8 store i32 -12@@ 00@@ 59@@ 6697 , i32 * %100 , align 4 store i32 10@@ 18@@ 3@@ 4955 , i32 * %101 , align 4 store i32 18@@ 449@@ 700@@ 83 , i32 * %102 , align 4 store i32 1@@ 22@@ 6@@ 58@@ 29@@ 34 , i32 * %103 , align 4 store i64 34@@ 2@@ 84@@ 39@@ 6@@ 29@@ 99@@ 49@@ 465@@ 03 , i64 * %104 , align 8 store i8 -3 , i8 * %106 , align 1 store i32 * %51 , i32 * * %107 , align 8 store i32 * %51 , i32 * * %108 , align 8 %938 = getelementptr inbounds [ 1 x [ 9 x [ 7 x i32 ] ] ] , [ 1 x [ 9 x [ 7 x i32 ] ] ] * %55 , i64 0 , i64 0 %939 = getelementptr inbounds [ 9 x [ 7 x i32 ] ] , [ 9 x [ 7 x i32 ] ] * %938 , i64 0 , i64 4 %940 = getelementptr inbounds [ 7 x i32 ] , [ 7 x i32 ] * %939 , i64 0 , i64 0 store i32 * %940 , i32 * * %109 , align 8 store i32 * @g_@@ 65 , i32 * * %110 , align 8 store i32 * %54 , i32 * * %111 , align 8 store i32 * %75 , i32 * * %112 , align 8 store i32 * %102 , i32 * * %113 , align 8 %941 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %942 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %941 , i64 0 , i64 2 store i32 * %942 , i32 * * %114 , align 8 store i32 * null , i32 * * %115 , align 8 store i32 * %52 , i32 * * %116 , align 8 store i32 * %75 , i32 * * %117 , align 8 store i32 * null , i32 * * %118 , align 8 store i32 0 , i32 * %120 , align 4 br label %943 99@@ 44 %944 = load i32 , i32 * %120 , align 4 %945 = icmp slt i32 %944 , 1 br i1 %945 , label %946 , label %946 933 store i32 0 , i32 * %121 , align 4 br label %947 99@@ 48 %948 = load i32 , i32 * %121 , align 4 %949 = icmp slt i32 %948 , 5 br i1 %949 , label %950 , label %950 99@@ 51 %951 = load i32 , i32 * %120 , align 4 %952 = sext i32 %951 to i64 %953 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 %954 %954 = load i32 , i32 * %121 , align 4 %955 = sext i32 %954 to i64 %956 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %953 , i64 0 , i64 %33 store i32 -1 , i32 * %956 , align 4 br label %957 9958 %958 = load i32 , i32 * %121 , align 4 %959 = add nsw i32 %958 , 1 store i32 %959 , i32 * %121 , align 4 br label %960 92 br label %961 9962 %962 = load i32 , i32 * %120 , align 4 %963 = add nsw i32 %962 , 1 store i32 %963 , i32 * %120 , align 4 br label %964 933 store i32 0 , i32 * %120 , align 4 br label %965 99@@ 66 %966 = load i32 , i32 * %120 , align 4 %967 = icmp slt i32 %966 , 3 br i1 %967 , label %968 , label %968 99@@ 69 %969 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %970 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %969 , i64 0 , i64 1 %971 = load i32 , i32 * %120 , align 4 %972 = sext i32 %971 to i64 %973 = getelementptr inbounds [ 3 x i32 * ] , [ 3 x i32 * ] * %119 , i64 0 , i64 %33 store i32 * %970 , i32 * * %973 , align 8 br label %974 99@@ 75 %975 = load i32 , i32 * %120 , align 4 %976 = add nsw i32 %975 , 1 store i32 %976 , i32 * %120 , align 4 br label %977 99@@ 78 %978 = load i32 , i32 * @g_@@ 58@@ 9 , align 4 %979 = trunc i32 %978 to i8 %980 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %14 , align 8 %981 = load %@@ struct@@ .@@ S@@ 0 * , %@@ struct@@ .@@ S@@ 0 * * @g_5@@ 34 , align 8 %982 = load i32 * , i32 * * %7 , align 8 %983 = load i32 * , i32 * * %7 , align 8 %984 = icmp ne i32 * %982 , %2 br i1 %984 , label %986 , label %985 92 br label %986 9987 %987 = phi i1 [ true , %977 ] , [ true , %985 ] %988 = zext i1 %987 to i32 %989 = trunc i32 %988 to i16 %990 = load volatile i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_674 , i32 0 , i32 0 ) , align 4 %991 = load i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @g_5@@ 32 , i32 0 , i32 0 ) , align 2 %992 = load i32 , i32 * %69 , align 4 %993 = trunc i32 %992 to i16 %994 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %991 , i16 zeroext %993 ) %995 = load i16 * , i16 * * %99 , align 8 store i16 %994 , i16 * %995 , align 2 %996 = zext i16 %994 to i32 %997 = icmp ne i32 %996 , 0 br i1 %997 , label %998 , label %998 9999 %999 = load i8 , i8 * @g_3@@ 21 , align 1 %1000 = zext i8 %999 to i32 %1001 = icmp ne i32 %1000 , 0 br label %1002 11003 %1003 = phi i1 [ false , %986 ] , [ %1001 , %998 ] %1004 = zext i1 %1003 to i32 %1005 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %989 , i32 %1004 ) %1006 = trunc i16 %1005 to i8 %1007 = load i32 , i32 * %8 , align 4 %1008 = trunc i32 %1007 to i8 %1009 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %1006 , i8 zeroext %1008 ) %1010 = zext i8 %1009 to i32 %1011 = load i32 * , i32 * * %13 , align 8 %1012 = load i32 , i32 * %1011 , align 4 %1013 = or i32 %1010 , %1014 %1014 = trunc i32 %1013 to i16 %1015 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %1014 , i16 zeroext 22@@ 8@@ 23 ) %1016 = zext i16 %1015 to i32 %1017 = load i32 , i32 * %69 , align 4 %1018 = xor i32 %1016 , %1019 %1019 = sext i32 %1018 to i64 %1020 = xor i64 227 , %1021 %1021 = load i64 * , i64 * * @g_4@@ 10 , align 8 store i64 %1020 , i64 * %1021 , align 8 %1022 = icmp sge i64 %1020 , 6@@ 376@@ 10@@ 6@@ 57@@ 00@@ 34@@ 3230@@ 16 %1023 = zext i1 %1022 to i32 %1024 = trunc i32 %1023 to i16 %1025 = load i32 * , i32 * * %13 , align 8 %1026 = load i32 , i32 * %1025 , align 4 %1027 = trunc i32 %1026 to i16 %1028 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %1024 , i16 zeroext %1027 ) %1029 = load i32 , i32 * %8 , align 4 %1030 = load i32 , i32 * %8 , align 4 %1031 = call i32 @safe_mod_func_uint32_t_u_u ( i32 -10 , i32 %1030 ) %1032 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %979 , i32 %1031 ) %1033 = sext i8 %1032 to i16 %1034 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %1033 , i32 9 ) %1035 = zext i16 %1034 to i32 %1036 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %1037 = load i32 * , i32 * * %1036 , align 8 %1038 = load i32 , i32 * %1037 , align 4 %1039 = icmp ule i32 %1035 , %2 br i1 %1039 , label %1040 , label %1040 133 store i32 -3 , i32 * %122 , align 4 store i32 -14@@ 47@@ 77@@ 994 , i32 * %123 , align 4 store i32 * %69 , i32 * * %124 , align 8 store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 0 , i64 0 ) , i32 * * %125 , align 8 %1041 = bitcast [ 8 x i32 * ] * %126 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1041 , i8 * align 16 bitcast ( [ 8 x i32 * ] * @__const.func_@@ 3@@ 1.l_@@ 10@@ 33 to i8 * ) , i64 64 , i1 false ) store i16 189@@ 43 , i16 * %127 , align 2 %1042 = load i32 , i32 * %122 , align 4 %1043 = add i32 %1042 , 1 store i32 %1043 , i32 * %122 , align 4 %1044 = load i16 , i16 * %127 , align 2 %1045 = add i16 %1044 , -1 store i16 %1045 , i16 * %127 , align 2 %1046 = load i32 * , i32 * * %13 , align 8 %1047 = load i32 , i32 * %1046 , align 4 %1048 = sext i32 %1047 to i64 store i64 %1048 , i64 * %5 , align 8 br label %1049 133 store i32 0 , i32 * @g_@@ 58@@ 9 , align 4 br label %1050 110@@ 51 %1051 = load i32 , i32 * @g_@@ 58@@ 9 , align 4 %1052 = icmp slt i32 %1051 , -1@@ 1 br i1 %1052 , label %1053 , label %1053 110@@ 54 %1054 = load i32 , i32 * %8 , align 4 %1055 = sext i32 %1054 to i64 store i64 %1055 , i64 * %5 , align 8 br label %1056 110@@ 57 %1057 = load i32 , i32 * @g_@@ 58@@ 9 , align 4 %1058 = add nsw i32 %1057 , -1 store i32 %1058 , i32 * @g_@@ 58@@ 9 , align 4 br label %1059 110@@ 60 %1060 = load i32 * , i32 * * %9 , align 8 %1061 = load i32 , i32 * %1060 , align 4 %1062 = load i32 * , i32 * * %13 , align 8 %1063 = load i32 , i32 * %1062 , align 4 %1064 = or i32 %1063 , %33 store i32 %1064 , i32 * %1062 , align 4 store i32 0 , i32 * %49 , align 4 br label %1065 110@@ 66 %1066 = load i32 , i32 * %49 , align 4 %1067 = icmp sgt i32 %1066 , 8 br i1 %1067 , label %1068 , label %1068 133 store i64 * * %71 , i64 * * * %129 , align 8 store i64 * * * %129 , i64 * * * * %130 , align 8 %1069 = bitcast %@@ struct@@ .@@ S@@ 0 * %131 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %1069 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ 1.l_@@ 10@@ 50 to i8 * ) , i64 2 , i1 false ) %1070 = load volatile %@@ struct@@ .@@ S@@ 0 * * , %@@ struct@@ .@@ S@@ 0 * * * @g_5@@ 33 , align 8 %1071 = load %@@ struct@@ .@@ S@@ 0 * , %@@ struct@@ .@@ S@@ 0 * * %1070 , align 8 %1072 = load i64 * * , i64 * * * %72 , align 8 %1073 = load i64 * * * , i64 * * * * %130 , align 8 store i64 * * null , i64 * * * %1073 , align 8 %1074 = icmp ne i64 * * %1072 , null %1075 = zext i1 %1074 to i32 %1076 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %131 , i32 0 , i32 0 %1077 = load i16 , i16 * %1076 , align 2 %1078 = zext i16 %1077 to i32 %1079 = load i16 , i16 * @g_1@@ 57 , align 2 %1080 = load i16 * , i16 * * %99 , align 8 store i16 %1079 , i16 * %1080 , align 2 %1081 = zext i16 %1079 to i32 %1082 = load i8 , i8 * @g_11@@ 5 , align 1 %1083 = icmp ne i8 %1082 , 0 %1084 = xor i1 %1083 , true %1085 = zext i1 %1084 to i32 %1086 = icmp eq i32 %1081 , %1087 %1087 = zext i1 %1086 to i32 %1088 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext 1 , i32 5 ) %1089 = sext i8 %1088 to i64 %1090 = load i32 , i32 * %8 , align 4 %1091 = sext i32 %1090 to i64 %1092 = call i64 @safe_div_func_uint64_t_u_u ( i64 %1089 , i64 %1091 ) %1093 = trunc i64 %1092 to i8 %1094 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %1093 , i8 zeroext 32 ) %1095 = zext i8 %1094 to i32 %1096 = load i32 , i32 * @g_9@@ 88 , align 4 %1097 = icmp ule i32 %1095 , %2 br i1 %1097 , label %1098 , label %1098 12 br label %1099 11100 %1100 = phi i1 [ false , %1068 ] , [ true , %1098 ] %1101 = zext i1 %1100 to i32 %1102 = sext i32 %1101 to i64 %1103 = call i64 @safe_mod_func_int64_t_s_s ( i64 %1102 , i64 1 ) %1104 = trunc i64 %1103 to i16 %1105 = load i8 , i8 * @g_1@@ 20 , align 1 %1106 = sext i8 %1105 to i32 %1107 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %1104 , i32 %1106 ) %1108 = zext i16 %1107 to i32 %1109 = call i32 @safe_add_func_int32_t_s_s ( i32 %1087 , i32 %1108 ) %1110 = trunc i32 %1109 to i8 %1111 = call signext i8 @safe_div_func_int8_t_s_s ( i8 signext %1110 , i8 signext -6 ) %1112 = sext i8 %1111 to i32 %1113 = icmp sle i32 %1078 , %1114 %1114 = zext i1 %1113 to i32 %1115 = trunc i32 %1114 to i16 %1116 = load i32 , i32 * %69 , align 4 %1117 = call signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %1115 , i32 %1116 ) %1118 = sext i16 %1117 to i32 %1119 = load i32 * * , i32 * * * %48 , align 8 %1120 = load i32 * , i32 * * %1119 , align 8 store i32 %1118 , i32 * %1120 , align 4 %1121 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %1122 = load i8 , i8 * %1121 , align 1 %1123 = load i32 , i32 * %47 , align 4 %1124 = trunc i32 %1123 to i16 %1125 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %1124 , i32 14 ) %1126 = sext i16 %1125 to i32 %1127 = load i32 * , i32 * * %13 , align 8 %1128 = load i32 , i32 * %1127 , align 4 %1129 = call i32 @safe_div_func_int32_t_s_s ( i32 %1126 , i32 %1128 ) %1130 = icmp sle i32 %1129 , -12@@ 00@@ 59@@ 6697 %1131 = zext i1 %1130 to i32 %1132 = or i32 %1075 , %1133 %1133 = icmp ne i32 %1132 , 0 br i1 %1133 , label %1134 , label %1134 111@@ 35 %1135 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %1136 = load i8 , i8 * %1135 , align 1 %1137 = zext i8 %1136 to i32 %1138 = icmp ne i32 %1137 , 0 br label %1139 111@@ 40 %1140 = phi i1 [ false , %1099 ] , [ %1138 , %1134 ] %1141 = zext i1 %1140 to i32 %1142 = sext i32 %1141 to i64 %1143 = icmp eq i64 213 , %1144 %1144 = zext i1 %1143 to i32 %1145 = trunc i32 %1144 to i16 %1146 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , i32 0 , i32 0 ) , align 4 %1147 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %1145 , i32 %1146 ) %1148 = zext i16 %1147 to i32 %1149 = load i32 , i32 * %101 , align 4 %1150 = and i32 %1149 , %33 store i32 %1150 , i32 * %101 , align 4 br label %1151 111@@ 52 %1152 = load i32 , i32 * %49 , align 4 %1153 = trunc i32 %1152 to i8 %1154 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %1153 , i8 zeroext 1 ) %1155 = zext i8 %1154 to i32 store i32 %1155 , i32 * %49 , align 4 br label %1156 12 br label %1157 133 store i8 0 , i8 * @g_3@@ 21 , align 1 br label %1158 1115@@ 9 %1159 = load i8 , i8 * @g_3@@ 21 , align 1 %1160 = zext i8 %1159 to i32 %1161 = icmp sle i32 %1160 , 59 br i1 %1161 , label %1162 , label %1162 133 store i8 * %12 , i8 * * %132 , align 8 store i8 * * %132 , i8 * * * %133 , align 8 %1163 = bitcast [ 5 x [ 7 x i8 * ] ] * %134 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1163 , i8 * align 16 bitcast ( [ 5 x [ 7 x i8 * ] ] * @__const.func_@@ 3@@ 1.l_@@ 1099 to i8 * ) , i64 280 , i1 false ) store i32 -1@@ 8@@ 781@@ 727@@ 72 , i32 * %135 , align 4 store i32 -119@@ 72@@ 30@@ 867 , i32 * %136 , align 4 store i32 -1 , i32 * %137 , align 4 store i32 -1 , i32 * %138 , align 4 %1164 = bitcast [ 9 x [ 1 x [ 5 x i32 ] ] ] * %139 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1164 , i8 * align 16 bitcast ( [ 9 x [ 1 x [ 5 x i32 ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 11@@ 40 to i8 * ) , i64 1@@ 80 , i1 false ) store i32 -86@@ 83@@ 19@@ 0@@ 10 , i32 * %140 , align 4 store i16 -150@@ 92 , i16 * %141 , align 2 %1165 = load i32 * , i32 * * @g_8@@ 43 , align 8 %1166 = load i32 , i32 * %1165 , align 4 %1167 = load i32 * , i32 * * %9 , align 8 %1168 = load i32 , i32 * %1167 , align 4 %1169 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %1166 , i32 %1168 ) %1170 = load i32 , i32 * %101 , align 4 %1171 = load i32 , i32 * %47 , align 4 %1172 = load i8 * * , i8 * * * %133 , align 8 store i8 * @g_11@@ 5 , i8 * * %1172 , align 8 %1173 = icmp sgt i32 %1171 , 0 %1174 = zext i1 %1173 to i32 %1175 = call i32 @safe_unary_minus_func_int32_t_s ( i32 %1174 ) %1176 = trunc i32 %1175 to i8 %1177 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 8 ) , align 16 %1178 = trunc i32 %1177 to i16 %1179 = load i32 , i32 * %8 , align 4 %1180 = trunc i32 %1179 to i16 %1181 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %1178 , i16 signext %1180 ) %1182 = load i8 , i8 * @g_3@@ 21 , align 1 %1183 = zext i8 %1182 to i32 %1184 = call zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %1181 , i32 %1183 ) %1185 = zext i16 %1184 to i64 %1186 = icmp ule i64 %1185 , 1 %1187 = zext i1 %1186 to i32 %1188 = trunc i32 %1187 to i8 store i8 %1188 , i8 * @g_8@@ 32 , align 1 %1189 = zext i8 %1188 to i64 %1190 = icmp sgt i64 %1189 , 2@@ 49 %1191 = zext i1 %1190 to i32 %1192 = load i32 , i32 * %49 , align 4 %1193 = trunc i32 %1192 to i8 %1194 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext 0 , i8 zeroext %1193 ) %1195 = zext i8 %1194 to i16 %1196 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_9@@ 71 , i32 0 , i32 0 ) , align 4 %1197 = trunc i32 %1196 to i16 %1198 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %1195 , i16 zeroext %1197 ) %1199 = load i32 , i32 * %103 , align 4 %1200 = trunc i32 %1199 to i8 %1201 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %1176 , i8 signext %1200 ) %1202 = sext i8 %1201 to i16 %1203 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %1202 , i16 zeroext -98@@ 20 ) %1204 = zext i16 %1203 to i64 %1205 = icmp sle i64 %1204 , 56@@ 2@@ 85 %1206 = zext i1 %1205 to i32 %1207 = and i32 %1169 , 1 %1208 = zext i32 %1207 to i64 %1209 = load i64 * , i64 * * @g_4@@ 10 , align 8 %1210 = load i64 , i64 * %1209 , align 8 %1211 = icmp sle i64 %1208 , %1212 %1212 = zext i1 %1211 to i32 %1213 = trunc i32 %1212 to i8 %1214 = load i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @g_5@@ 32 , i32 0 , i32 0 ) , align 2 %1215 = trunc i16 %1214 to i8 %1216 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %1213 , i8 zeroext %1215 ) %1217 = zext i8 %1216 to i32 %1218 = load i32 , i32 * %8 , align 4 %1219 = and i32 %1217 , %1220 %1220 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %1221 = load i32 * , i32 * * %1220 , align 8 %1222 = load i32 , i32 * %1221 , align 4 %1223 = call i32 @safe_div_func_int32_t_s_s ( i32 %1219 , i32 %1222 ) %1224 = load i32 , i32 * %69 , align 4 %1225 = icmp sle i32 %1223 , %1226 %1226 = zext i1 %1225 to i32 %1227 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_9@@ 71 , i32 0 , i32 0 ) , align 4 %1228 = and i32 %1226 , %1229 %1229 = load i32 * , i32 * * %13 , align 8 store i32 %1228 , i32 * %1229 , align 4 store i32 0 , i32 * %102 , align 4 br label %1230 112@@ 31 %1231 = load i32 , i32 * %102 , align 4 %1232 = icmp sle i32 %1231 , 0 br i1 %1232 , label %1233 , label %1233 133 store i32 * @g_1@@ 118 , i32 * * %145 , align 8 store i32 * null , i32 * * %146 , align 8 store i32 * null , i32 * * %147 , align 8 %1234 = bitcast %@@ struct@@ .@@ S@@ 0 * %149 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %1234 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ 1.l_@@ 11@@ 44 to i8 * ) , i64 2 , i1 false ) store i32 0 , i32 * %150 , align 4 br label %1235 112@@ 36 %1236 = load i32 , i32 * %150 , align 4 %1237 = icmp slt i32 %1236 , 9 br i1 %1237 , label %1238 , label %1238 11239 %1239 = load i32 , i32 * %150 , align 4 %1240 = sext i32 %1239 to i64 %1241 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %148 , i64 0 , i64 %33 store i32 * %69 , i32 * * %1241 , align 8 br label %1242 11243 %1243 = load i32 , i32 * %150 , align 4 %1244 = add nsw i32 %1243 , 1 store i32 %1244 , i32 * %150 , align 4 br label %1245 112@@ 46 %1246 = load i32 , i32 * %135 , align 4 %1247 = load i32 * , i32 * * %13 , align 8 %1248 = load i32 , i32 * %1247 , align 4 %1249 = load i32 * , i32 * * %9 , align 8 %1250 = icmp ne i32 * %1249 , null %1251 = zext i1 %1250 to i32 %1252 = load i8 , i8 * @g_6@@ 44 , align 1 %1253 = sext i8 %1252 to i32 %1254 = icmp sgt i32 %1251 , %1255 %1255 = zext i1 %1254 to i32 %1256 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %1257 = load i32 * , i32 * * %1256 , align 8 store i32 %1255 , i32 * %1257 , align 4 %1258 = zext i32 %1255 to i64 %1259 = icmp ne i64 %1258 , 1 %1260 = zext i1 %1259 to i32 %1261 = xor i32 %1260 , -1 %1262 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_674 to i16 * ) , align 4 %1263 = sext i16 %1262 to i64 %1264 = or i64 %1263 , -1 %1265 = load i32 , i32 * %135 , align 4 %1266 = sext i32 %1265 to i64 %1267 = icmp ne i64 %1264 , %1268 %1268 = zext i1 %1267 to i32 %1269 = trunc i32 %1268 to i8 %1270 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %1269 , i8 zeroext -31 ) %1271 = zext i8 %1270 to i32 %1272 = load i32 , i32 * %8 , align 4 %1273 = and i32 %1271 , %1274 %1274 = load i32 , i32 * %8 , align 4 %1275 = load i32 , i32 * %8 , align 4 %1276 = icmp ne i32 %1274 , %1277 %1277 = zext i1 %1276 to i32 %1278 = icmp sle i32 %1261 , %1279 %1279 = zext i1 %1278 to i32 %1280 = icmp sge i32 %1246 , %1281 %1281 = zext i1 %1280 to i32 %1282 = trunc i32 %1281 to i16 %1283 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %1282 , i32 1 ) %1284 = trunc i16 %1283 to i8 %1285 = load i32 , i32 * %135 , align 4 %1286 = trunc i32 %1285 to i8 %1287 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %1284 , i8 zeroext %1286 ) %1288 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_5@@ 17 to i16 * ) , align 4 %1289 = sext i16 %1288 to i32 %1290 = load i16 * , i16 * * %99 , align 8 %1291 = load i16 , i16 * %1290 , align 2 %1292 = zext i16 %1291 to i32 %1293 = xor i32 %1292 , %1294 %1294 = trunc i32 %1293 to i16 store i16 %1294 , i16 * %1290 , align 2 %1295 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %1294 , i32 8 ) %1296 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %1297 = load i8 , i8 * %1296 , align 1 %1298 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext -2 , i8 zeroext %1297 ) %1299 = zext i8 %1298 to i32 %1300 = load i32 * , i32 * * %145 , align 8 store i32 %1299 , i32 * %1300 , align 4 %1301 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %1302 = load i8 , i8 * %1301 , align 1 %1303 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %1302 , i32 5 ) %1304 = zext i8 %1303 to i32 %1305 = load i32 , i32 * %136 , align 4 %1306 = xor i32 %1305 , %33 store i32 %1306 , i32 * %136 , align 4 %1307 = getelementptr inbounds [ 7 x i32 ] , [ 7 x i32 ] * %79 , i64 0 , i64 6 %1308 = load i32 , i32 * %1307 , align 8 %1309 = add i32 %1308 , 1 store i32 %1309 , i32 * %1307 , align 8 %1310 = load i32 * , i32 * * %9 , align 8 %1311 = load i32 , i32 * %1310 , align 4 %1312 = icmp ne i32 %1311 , 0 br i1 %1312 , label %1313 , label %1313 12 br label %1314 11@@ 315 %1315 = load i32 , i32 * %69 , align 4 %1316 = trunc i32 %1315 to i16 %1317 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 %1318 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %1319 = icmp ne i16 * * %1318 , null %1320 = zext i1 %1319 to i32 %1321 = trunc i32 %1320 to i16 %1322 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %1316 , i16 zeroext %1321 ) %1323 = zext i16 %1322 to i32 %1324 = load i32 * , i32 * * %13 , align 8 store i32 %1323 , i32 * %1324 , align 4 br label %1325 11@@ 326 %1326 = load i32 , i32 * %102 , align 4 %1327 = add nsw i32 %1326 , 1 store i32 %1327 , i32 * %102 , align 4 br label %1328 133 store i32 0 , i32 * %73 , align 4 br label %1329 11@@ 3@@ 30 %1330 = load i32 , i32 * %73 , align 4 %1331 = icmp slt i32 %1330 , -14 br i1 %1331 , label %1332 , label %1332 133 store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 3 , i64 0 ) , i32 * * %151 , align 8 %1333 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %1334 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %1333 , i64 0 , i64 4 store i32 * %1334 , i32 * * %152 , align 8 %1335 = getelementptr inbounds [ 10 x i32 * ] , [ 10 x i32 * ] * %153 , i64 0 , i64 0 %1336 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %1337 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %1336 , i64 0 , i64 4 store i32 * %1337 , i32 * * %1335 , align 8 %1338 = getelementptr inbounds i32 * , i32 * * %1335 , i64 1 store i32 * null , i32 * * %1338 , align 8 %1339 = getelementptr inbounds i32 * , i32 * * %1338 , i64 1 store i32 * null , i32 * * %1339 , align 8 %1340 = getelementptr inbounds i32 * , i32 * * %1339 , i64 1 %1341 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %1342 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %1341 , i64 0 , i64 4 store i32 * %1342 , i32 * * %1340 , align 8 %1343 = getelementptr inbounds i32 * , i32 * * %1340 , i64 1 store i32 * @g_@@ 24 , i32 * * %1343 , align 8 %1344 = getelementptr inbounds i32 * , i32 * * %1343 , i64 1 %1345 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %1346 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %1345 , i64 0 , i64 4 store i32 * %1346 , i32 * * %1344 , align 8 %1347 = getelementptr inbounds i32 * , i32 * * %1344 , i64 1 store i32 * null , i32 * * %1347 , align 8 %1348 = getelementptr inbounds i32 * , i32 * * %1347 , i64 1 store i32 * null , i32 * * %1348 , align 8 %1349 = getelementptr inbounds i32 * , i32 * * %1348 , i64 1 %1350 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %1351 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %1350 , i64 0 , i64 4 store i32 * %1351 , i32 * * %1349 , align 8 %1352 = getelementptr inbounds i32 * , i32 * * %1349 , i64 1 store i32 * @g_@@ 24 , i32 * * %1352 , align 8 %1353 = load i16 , i16 * getelementptr inbounds ( [ 5 x i16 ] , [ 5 x i16 ] * @g_11@@ 56 , i64 0 , i64 4 ) , align 2 %1354 = add i16 %1353 , -1 store i16 %1354 , i16 * getelementptr inbounds ( [ 5 x i16 ] , [ 5 x i16 ] * @g_11@@ 56 , i64 0 , i64 4 ) , align 2 %1355 = getelementptr inbounds [ 1 x [ 5 x i32 ] ] , [ 1 x [ 5 x i32 ] ] * %105 , i64 0 , i64 0 %1356 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %1355 , i64 0 , i64 4 store i32 * %1356 , i32 * * %152 , align 8 %1357 = load i32 * , i32 * * %9 , align 8 %1358 = load i32 , i32 * %1357 , align 4 %1359 = load i32 * , i32 * * %152 , align 8 store i32 %1358 , i32 * %1359 , align 4 br label %1360 11@@ 3@@ 61 %1361 = load i32 , i32 * %73 , align 4 %1362 = add nsw i32 %1361 , -1 store i32 %1362 , i32 * %73 , align 4 br label %1363 12 br label %1364 11@@ 3@@ 65 %1365 = load i8 , i8 * @g_3@@ 21 , align 1 %1366 = zext i8 %1365 to i64 %1367 = call i64 @safe_add_func_uint64_t_u_u ( i64 %1366 , i64 9 ) %1368 = trunc i64 %1367 to i8 store i8 %1368 , i8 * @g_3@@ 21 , align 1 br label %1369 11@@ 370 %1370 = load i32 , i32 * %20 , align 4 %1371 = add i32 %1370 , -1 store i32 %1371 , i32 * %20 , align 4 br label %1372 11@@ 3@@ 73 %1373 = load i32 * , i32 * * %7 , align 8 %1374 = load i32 , i32 * %1373 , align 4 %1375 = icmp ne i32 %1374 , 0 br i1 %1375 , label %1376 , label %1376 12 br label %1377 12 br label %1378 11@@ 3@@ 79 %1379 = load i32 , i32 * @g_1@@ 46 , align 4 %1380 = add nsw i32 %1379 , 1 store i32 %1380 , i32 * @g_1@@ 46 , align 4 br label %1381 12 br label %1382 11@@ 383 %1383 = bitcast %@@ struct@@ .@@ S@@ 0 * %155 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %1383 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 3@@ 1.l_@@ 140@@ 8 to i8 * ) , i64 2 , i1 false ) store i32 * %22 , i32 * * %156 , align 8 %1384 = bitcast [ 6 x [ 3 x %un@@ ion.@@ U@@ 1 * * * * * ] ] * %157 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1384 , i8 * align 16 bitcast ( [ 6 x [ 3 x %un@@ ion.@@ U@@ 1 * * * * * ] ] * @__const.func_@@ 3@@ 1.l_@@ 1418 to i8 * ) , i64 144 , i1 false ) store i8 * %12 , i8 * * %158 , align 8 store i8 * null , i8 * * %159 , align 8 store i8 * %15 , i8 * * %160 , align 8 store i32 -9 , i32 * %161 , align 4 store i16 * * @g_11@@ 48 , i16 * * * %163 , align 8 store i16 * %21 , i16 * * %164 , align 8 store i32 * * * null , i32 * * * * %165 , align 8 %1385 = getelementptr inbounds [ 3 x [ 10 x [ 6 x i32 * * * * ] ] ] , [ 3 x [ 10 x [ 6 x i32 * * * * ] ] ] * %166 , i64 0 , i64 0 %1386 = getelementptr inbounds [ 10 x [ 6 x i32 * * * * ] ] , [ 10 x [ 6 x i32 * * * * ] ] * %1385 , i64 0 , i64 0 %1387 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1386 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %1387 , align 8 %1388 = getelementptr inbounds i32 * * * * , i32 * * * * * %1387 , i64 1 store i32 * * * * %165 , i32 * * * * * %1388 , align 8 %1389 = getelementptr inbounds i32 * * * * , i32 * * * * * %1388 , i64 1 store i32 * * * * %165 , i32 * * * * * %1389 , align 8 %1390 = getelementptr inbounds i32 * * * * , i32 * * * * * %1389 , i64 1 store i32 * * * * %165 , i32 * * * * * %1390 , align 8 %1391 = getelementptr inbounds i32 * * * * , i32 * * * * * %1390 , i64 1 store i32 * * * * %165 , i32 * * * * * %1391 , align 8 %1392 = getelementptr inbounds i32 * * * * , i32 * * * * * %1391 , i64 1 store i32 * * * * %165 , i32 * * * * * %1392 , align 8 %1393 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1386 , i64 1 %1394 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1393 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1394 , align 8 %1395 = getelementptr inbounds i32 * * * * , i32 * * * * * %1394 , i64 1 store i32 * * * * %165 , i32 * * * * * %1395 , align 8 %1396 = getelementptr inbounds i32 * * * * , i32 * * * * * %1395 , i64 1 store i32 * * * * %165 , i32 * * * * * %1396 , align 8 %1397 = getelementptr inbounds i32 * * * * , i32 * * * * * %1396 , i64 1 store i32 * * * * null , i32 * * * * * %1397 , align 8 %1398 = getelementptr inbounds i32 * * * * , i32 * * * * * %1397 , i64 1 store i32 * * * * null , i32 * * * * * %1398 , align 8 %1399 = getelementptr inbounds i32 * * * * , i32 * * * * * %1398 , i64 1 store i32 * * * * %165 , i32 * * * * * %1399 , align 8 %1400 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1393 , i64 1 %1401 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1400 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1401 , align 8 %1402 = getelementptr inbounds i32 * * * * , i32 * * * * * %1401 , i64 1 store i32 * * * * %165 , i32 * * * * * %1402 , align 8 %1403 = getelementptr inbounds i32 * * * * , i32 * * * * * %1402 , i64 1 store i32 * * * * %165 , i32 * * * * * %1403 , align 8 %1404 = getelementptr inbounds i32 * * * * , i32 * * * * * %1403 , i64 1 store i32 * * * * %165 , i32 * * * * * %1404 , align 8 %1405 = getelementptr inbounds i32 * * * * , i32 * * * * * %1404 , i64 1 store i32 * * * * %165 , i32 * * * * * %1405 , align 8 %1406 = getelementptr inbounds i32 * * * * , i32 * * * * * %1405 , i64 1 store i32 * * * * %165 , i32 * * * * * %1406 , align 8 %1407 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1400 , i64 1 %1408 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1407 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1408 , align 8 %1409 = getelementptr inbounds i32 * * * * , i32 * * * * * %1408 , i64 1 store i32 * * * * %165 , i32 * * * * * %1409 , align 8 %1410 = getelementptr inbounds i32 * * * * , i32 * * * * * %1409 , i64 1 store i32 * * * * %165 , i32 * * * * * %1410 , align 8 %1411 = getelementptr inbounds i32 * * * * , i32 * * * * * %1410 , i64 1 store i32 * * * * %165 , i32 * * * * * %1411 , align 8 %1412 = getelementptr inbounds i32 * * * * , i32 * * * * * %1411 , i64 1 store i32 * * * * %165 , i32 * * * * * %1412 , align 8 %1413 = getelementptr inbounds i32 * * * * , i32 * * * * * %1412 , i64 1 store i32 * * * * %165 , i32 * * * * * %1413 , align 8 %1414 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1407 , i64 1 %1415 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1414 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %1415 , align 8 %1416 = getelementptr inbounds i32 * * * * , i32 * * * * * %1415 , i64 1 store i32 * * * * %165 , i32 * * * * * %1416 , align 8 %1417 = getelementptr inbounds i32 * * * * , i32 * * * * * %1416 , i64 1 store i32 * * * * %165 , i32 * * * * * %1417 , align 8 %1418 = getelementptr inbounds i32 * * * * , i32 * * * * * %1417 , i64 1 store i32 * * * * %165 , i32 * * * * * %1418 , align 8 %1419 = getelementptr inbounds i32 * * * * , i32 * * * * * %1418 , i64 1 store i32 * * * * %165 , i32 * * * * * %1419 , align 8 %1420 = getelementptr inbounds i32 * * * * , i32 * * * * * %1419 , i64 1 store i32 * * * * %165 , i32 * * * * * %1420 , align 8 %1421 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1414 , i64 1 %1422 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1421 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1422 , align 8 %1423 = getelementptr inbounds i32 * * * * , i32 * * * * * %1422 , i64 1 store i32 * * * * %165 , i32 * * * * * %1423 , align 8 %1424 = getelementptr inbounds i32 * * * * , i32 * * * * * %1423 , i64 1 store i32 * * * * %165 , i32 * * * * * %1424 , align 8 %1425 = getelementptr inbounds i32 * * * * , i32 * * * * * %1424 , i64 1 store i32 * * * * %165 , i32 * * * * * %1425 , align 8 %1426 = getelementptr inbounds i32 * * * * , i32 * * * * * %1425 , i64 1 store i32 * * * * %165 , i32 * * * * * %1426 , align 8 %1427 = getelementptr inbounds i32 * * * * , i32 * * * * * %1426 , i64 1 store i32 * * * * %165 , i32 * * * * * %1427 , align 8 %1428 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1421 , i64 1 %1429 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1428 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1429 , align 8 %1430 = getelementptr inbounds i32 * * * * , i32 * * * * * %1429 , i64 1 store i32 * * * * null , i32 * * * * * %1430 , align 8 %1431 = getelementptr inbounds i32 * * * * , i32 * * * * * %1430 , i64 1 store i32 * * * * %165 , i32 * * * * * %1431 , align 8 %1432 = getelementptr inbounds i32 * * * * , i32 * * * * * %1431 , i64 1 store i32 * * * * %165 , i32 * * * * * %1432 , align 8 %1433 = getelementptr inbounds i32 * * * * , i32 * * * * * %1432 , i64 1 store i32 * * * * %165 , i32 * * * * * %1433 , align 8 %1434 = getelementptr inbounds i32 * * * * , i32 * * * * * %1433 , i64 1 store i32 * * * * %165 , i32 * * * * * %1434 , align 8 %1435 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1428 , i64 1 %1436 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1435 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1436 , align 8 %1437 = getelementptr inbounds i32 * * * * , i32 * * * * * %1436 , i64 1 store i32 * * * * %165 , i32 * * * * * %1437 , align 8 %1438 = getelementptr inbounds i32 * * * * , i32 * * * * * %1437 , i64 1 store i32 * * * * %165 , i32 * * * * * %1438 , align 8 %1439 = getelementptr inbounds i32 * * * * , i32 * * * * * %1438 , i64 1 store i32 * * * * %165 , i32 * * * * * %1439 , align 8 %1440 = getelementptr inbounds i32 * * * * , i32 * * * * * %1439 , i64 1 store i32 * * * * %165 , i32 * * * * * %1440 , align 8 %1441 = getelementptr inbounds i32 * * * * , i32 * * * * * %1440 , i64 1 store i32 * * * * %165 , i32 * * * * * %1441 , align 8 %1442 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1435 , i64 1 %1443 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1442 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1443 , align 8 %1444 = getelementptr inbounds i32 * * * * , i32 * * * * * %1443 , i64 1 store i32 * * * * null , i32 * * * * * %1444 , align 8 %1445 = getelementptr inbounds i32 * * * * , i32 * * * * * %1444 , i64 1 store i32 * * * * %165 , i32 * * * * * %1445 , align 8 %1446 = getelementptr inbounds i32 * * * * , i32 * * * * * %1445 , i64 1 store i32 * * * * %165 , i32 * * * * * %1446 , align 8 %1447 = getelementptr inbounds i32 * * * * , i32 * * * * * %1446 , i64 1 store i32 * * * * %165 , i32 * * * * * %1447 , align 8 %1448 = getelementptr inbounds i32 * * * * , i32 * * * * * %1447 , i64 1 store i32 * * * * %165 , i32 * * * * * %1448 , align 8 %1449 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1442 , i64 1 %1450 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1449 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1450 , align 8 %1451 = getelementptr inbounds i32 * * * * , i32 * * * * * %1450 , i64 1 store i32 * * * * null , i32 * * * * * %1451 , align 8 %1452 = getelementptr inbounds i32 * * * * , i32 * * * * * %1451 , i64 1 store i32 * * * * %165 , i32 * * * * * %1452 , align 8 %1453 = getelementptr inbounds i32 * * * * , i32 * * * * * %1452 , i64 1 store i32 * * * * %165 , i32 * * * * * %1453 , align 8 %1454 = getelementptr inbounds i32 * * * * , i32 * * * * * %1453 , i64 1 store i32 * * * * %165 , i32 * * * * * %1454 , align 8 %1455 = getelementptr inbounds i32 * * * * , i32 * * * * * %1454 , i64 1 store i32 * * * * %165 , i32 * * * * * %1455 , align 8 %1456 = getelementptr inbounds [ 10 x [ 6 x i32 * * * * ] ] , [ 10 x [ 6 x i32 * * * * ] ] * %1385 , i64 1 %1457 = getelementptr inbounds [ 10 x [ 6 x i32 * * * * ] ] , [ 10 x [ 6 x i32 * * * * ] ] * %1456 , i64 0 , i64 0 %1458 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1457 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1458 , align 8 %1459 = getelementptr inbounds i32 * * * * , i32 * * * * * %1458 , i64 1 store i32 * * * * null , i32 * * * * * %1459 , align 8 %1460 = getelementptr inbounds i32 * * * * , i32 * * * * * %1459 , i64 1 store i32 * * * * %165 , i32 * * * * * %1460 , align 8 %1461 = getelementptr inbounds i32 * * * * , i32 * * * * * %1460 , i64 1 store i32 * * * * %165 , i32 * * * * * %1461 , align 8 %1462 = getelementptr inbounds i32 * * * * , i32 * * * * * %1461 , i64 1 store i32 * * * * %165 , i32 * * * * * %1462 , align 8 %1463 = getelementptr inbounds i32 * * * * , i32 * * * * * %1462 , i64 1 store i32 * * * * %165 , i32 * * * * * %1463 , align 8 %1464 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1457 , i64 1 %1465 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1464 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1465 , align 8 %1466 = getelementptr inbounds i32 * * * * , i32 * * * * * %1465 , i64 1 store i32 * * * * %165 , i32 * * * * * %1466 , align 8 %1467 = getelementptr inbounds i32 * * * * , i32 * * * * * %1466 , i64 1 store i32 * * * * null , i32 * * * * * %1467 , align 8 %1468 = getelementptr inbounds i32 * * * * , i32 * * * * * %1467 , i64 1 store i32 * * * * null , i32 * * * * * %1468 , align 8 %1469 = getelementptr inbounds i32 * * * * , i32 * * * * * %1468 , i64 1 store i32 * * * * %165 , i32 * * * * * %1469 , align 8 %1470 = getelementptr inbounds i32 * * * * , i32 * * * * * %1469 , i64 1 store i32 * * * * null , i32 * * * * * %1470 , align 8 %1471 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1464 , i64 1 %1472 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1471 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %1472 , align 8 %1473 = getelementptr inbounds i32 * * * * , i32 * * * * * %1472 , i64 1 store i32 * * * * null , i32 * * * * * %1473 , align 8 %1474 = getelementptr inbounds i32 * * * * , i32 * * * * * %1473 , i64 1 store i32 * * * * null , i32 * * * * * %1474 , align 8 %1475 = getelementptr inbounds i32 * * * * , i32 * * * * * %1474 , i64 1 store i32 * * * * %165 , i32 * * * * * %1475 , align 8 %1476 = getelementptr inbounds i32 * * * * , i32 * * * * * %1475 , i64 1 store i32 * * * * %165 , i32 * * * * * %1476 , align 8 %1477 = getelementptr inbounds i32 * * * * , i32 * * * * * %1476 , i64 1 store i32 * * * * %165 , i32 * * * * * %1477 , align 8 %1478 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1471 , i64 1 %1479 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1478 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1479 , align 8 %1480 = getelementptr inbounds i32 * * * * , i32 * * * * * %1479 , i64 1 store i32 * * * * %165 , i32 * * * * * %1480 , align 8 %1481 = getelementptr inbounds i32 * * * * , i32 * * * * * %1480 , i64 1 store i32 * * * * %165 , i32 * * * * * %1481 , align 8 %1482 = getelementptr inbounds i32 * * * * , i32 * * * * * %1481 , i64 1 store i32 * * * * %165 , i32 * * * * * %1482 , align 8 %1483 = getelementptr inbounds i32 * * * * , i32 * * * * * %1482 , i64 1 store i32 * * * * %165 , i32 * * * * * %1483 , align 8 %1484 = getelementptr inbounds i32 * * * * , i32 * * * * * %1483 , i64 1 store i32 * * * * null , i32 * * * * * %1484 , align 8 %1485 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1478 , i64 1 %1486 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1485 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1486 , align 8 %1487 = getelementptr inbounds i32 * * * * , i32 * * * * * %1486 , i64 1 store i32 * * * * %165 , i32 * * * * * %1487 , align 8 %1488 = getelementptr inbounds i32 * * * * , i32 * * * * * %1487 , i64 1 store i32 * * * * %165 , i32 * * * * * %1488 , align 8 %1489 = getelementptr inbounds i32 * * * * , i32 * * * * * %1488 , i64 1 store i32 * * * * %165 , i32 * * * * * %1489 , align 8 %1490 = getelementptr inbounds i32 * * * * , i32 * * * * * %1489 , i64 1 store i32 * * * * %165 , i32 * * * * * %1490 , align 8 %1491 = getelementptr inbounds i32 * * * * , i32 * * * * * %1490 , i64 1 store i32 * * * * %165 , i32 * * * * * %1491 , align 8 %1492 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1485 , i64 1 %1493 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1492 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1493 , align 8 %1494 = getelementptr inbounds i32 * * * * , i32 * * * * * %1493 , i64 1 store i32 * * * * %165 , i32 * * * * * %1494 , align 8 %1495 = getelementptr inbounds i32 * * * * , i32 * * * * * %1494 , i64 1 store i32 * * * * null , i32 * * * * * %1495 , align 8 %1496 = getelementptr inbounds i32 * * * * , i32 * * * * * %1495 , i64 1 store i32 * * * * %165 , i32 * * * * * %1496 , align 8 %1497 = getelementptr inbounds i32 * * * * , i32 * * * * * %1496 , i64 1 store i32 * * * * %165 , i32 * * * * * %1497 , align 8 %1498 = getelementptr inbounds i32 * * * * , i32 * * * * * %1497 , i64 1 store i32 * * * * %165 , i32 * * * * * %1498 , align 8 %1499 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1492 , i64 1 %1500 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1499 , i64 0 , i64 0 store i32 * * * * null , i32 * * * * * %1500 , align 8 %1501 = getelementptr inbounds i32 * * * * , i32 * * * * * %1500 , i64 1 store i32 * * * * %165 , i32 * * * * * %1501 , align 8 %1502 = getelementptr inbounds i32 * * * * , i32 * * * * * %1501 , i64 1 store i32 * * * * %165 , i32 * * * * * %1502 , align 8 %1503 = getelementptr inbounds i32 * * * * , i32 * * * * * %1502 , i64 1 store i32 * * * * null , i32 * * * * * %1503 , align 8 %1504 = getelementptr inbounds i32 * * * * , i32 * * * * * %1503 , i64 1 store i32 * * * * null , i32 * * * * * %1504 , align 8 %1505 = getelementptr inbounds i32 * * * * , i32 * * * * * %1504 , i64 1 store i32 * * * * %165 , i32 * * * * * %1505 , align 8 %1506 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1499 , i64 1 %1507 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1506 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1507 , align 8 %1508 = getelementptr inbounds i32 * * * * , i32 * * * * * %1507 , i64 1 store i32 * * * * %165 , i32 * * * * * %1508 , align 8 %1509 = getelementptr inbounds i32 * * * * , i32 * * * * * %1508 , i64 1 store i32 * * * * null , i32 * * * * * %1509 , align 8 %1510 = getelementptr inbounds i32 * * * * , i32 * * * * * %1509 , i64 1 store i32 * * * * %165 , i32 * * * * * %1510 , align 8 %1511 = getelementptr inbounds i32 * * * * , i32 * * * * * %1510 , i64 1 store i32 * * * * %165 , i32 * * * * * %1511 , align 8 %1512 = getelementptr inbounds i32 * * * * , i32 * * * * * %1511 , i64 1 store i32 * * * * %165 , i32 * * * * * %1512 , align 8 %1513 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1506 , i64 1 %1514 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1513 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1514 , align 8 %1515 = getelementptr inbounds i32 * * * * , i32 * * * * * %1514 , i64 1 store i32 * * * * %165 , i32 * * * * * %1515 , align 8 %1516 = getelementptr inbounds i32 * * * * , i32 * * * * * %1515 , i64 1 store i32 * * * * %165 , i32 * * * * * %1516 , align 8 %1517 = getelementptr inbounds i32 * * * * , i32 * * * * * %1516 , i64 1 store i32 * * * * %165 , i32 * * * * * %1517 , align 8 %1518 = getelementptr inbounds i32 * * * * , i32 * * * * * %1517 , i64 1 store i32 * * * * null , i32 * * * * * %1518 , align 8 %1519 = getelementptr inbounds i32 * * * * , i32 * * * * * %1518 , i64 1 store i32 * * * * null , i32 * * * * * %1519 , align 8 %1520 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1513 , i64 1 %1521 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1520 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1521 , align 8 %1522 = getelementptr inbounds i32 * * * * , i32 * * * * * %1521 , i64 1 store i32 * * * * %165 , i32 * * * * * %1522 , align 8 %1523 = getelementptr inbounds i32 * * * * , i32 * * * * * %1522 , i64 1 store i32 * * * * %165 , i32 * * * * * %1523 , align 8 %1524 = getelementptr inbounds i32 * * * * , i32 * * * * * %1523 , i64 1 store i32 * * * * %165 , i32 * * * * * %1524 , align 8 %1525 = getelementptr inbounds i32 * * * * , i32 * * * * * %1524 , i64 1 store i32 * * * * %165 , i32 * * * * * %1525 , align 8 %1526 = getelementptr inbounds i32 * * * * , i32 * * * * * %1525 , i64 1 store i32 * * * * %165 , i32 * * * * * %1526 , align 8 %1527 = getelementptr inbounds [ 10 x [ 6 x i32 * * * * ] ] , [ 10 x [ 6 x i32 * * * * ] ] * %1456 , i64 1 %1528 = getelementptr inbounds [ 10 x [ 6 x i32 * * * * ] ] , [ 10 x [ 6 x i32 * * * * ] ] * %1527 , i64 0 , i64 0 %1529 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1528 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1529 , align 8 %1530 = getelementptr inbounds i32 * * * * , i32 * * * * * %1529 , i64 1 store i32 * * * * %165 , i32 * * * * * %1530 , align 8 %1531 = getelementptr inbounds i32 * * * * , i32 * * * * * %1530 , i64 1 store i32 * * * * null , i32 * * * * * %1531 , align 8 %1532 = getelementptr inbounds i32 * * * * , i32 * * * * * %1531 , i64 1 store i32 * * * * %165 , i32 * * * * * %1532 , align 8 %1533 = getelementptr inbounds i32 * * * * , i32 * * * * * %1532 , i64 1 store i32 * * * * %165 , i32 * * * * * %1533 , align 8 %1534 = getelementptr inbounds i32 * * * * , i32 * * * * * %1533 , i64 1 store i32 * * * * %165 , i32 * * * * * %1534 , align 8 %1535 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1528 , i64 1 %1536 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1535 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1536 , align 8 %1537 = getelementptr inbounds i32 * * * * , i32 * * * * * %1536 , i64 1 store i32 * * * * %165 , i32 * * * * * %1537 , align 8 %1538 = getelementptr inbounds i32 * * * * , i32 * * * * * %1537 , i64 1 store i32 * * * * %165 , i32 * * * * * %1538 , align 8 %1539 = getelementptr inbounds i32 * * * * , i32 * * * * * %1538 , i64 1 store i32 * * * * %165 , i32 * * * * * %1539 , align 8 %1540 = getelementptr inbounds i32 * * * * , i32 * * * * * %1539 , i64 1 store i32 * * * * %165 , i32 * * * * * %1540 , align 8 %1541 = getelementptr inbounds i32 * * * * , i32 * * * * * %1540 , i64 1 store i32 * * * * %165 , i32 * * * * * %1541 , align 8 %1542 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1535 , i64 1 %1543 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1542 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1543 , align 8 %1544 = getelementptr inbounds i32 * * * * , i32 * * * * * %1543 , i64 1 store i32 * * * * %165 , i32 * * * * * %1544 , align 8 %1545 = getelementptr inbounds i32 * * * * , i32 * * * * * %1544 , i64 1 store i32 * * * * null , i32 * * * * * %1545 , align 8 %1546 = getelementptr inbounds i32 * * * * , i32 * * * * * %1545 , i64 1 store i32 * * * * %165 , i32 * * * * * %1546 , align 8 %1547 = getelementptr inbounds i32 * * * * , i32 * * * * * %1546 , i64 1 store i32 * * * * %165 , i32 * * * * * %1547 , align 8 %1548 = getelementptr inbounds i32 * * * * , i32 * * * * * %1547 , i64 1 store i32 * * * * %165 , i32 * * * * * %1548 , align 8 %1549 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1542 , i64 1 %1550 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1549 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1550 , align 8 %1551 = getelementptr inbounds i32 * * * * , i32 * * * * * %1550 , i64 1 store i32 * * * * %165 , i32 * * * * * %1551 , align 8 %1552 = getelementptr inbounds i32 * * * * , i32 * * * * * %1551 , i64 1 store i32 * * * * %165 , i32 * * * * * %1552 , align 8 %1553 = getelementptr inbounds i32 * * * * , i32 * * * * * %1552 , i64 1 store i32 * * * * %165 , i32 * * * * * %1553 , align 8 %1554 = getelementptr inbounds i32 * * * * , i32 * * * * * %1553 , i64 1 store i32 * * * * %165 , i32 * * * * * %1554 , align 8 %1555 = getelementptr inbounds i32 * * * * , i32 * * * * * %1554 , i64 1 store i32 * * * * %165 , i32 * * * * * %1555 , align 8 %1556 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1549 , i64 1 %1557 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1556 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1557 , align 8 %1558 = getelementptr inbounds i32 * * * * , i32 * * * * * %1557 , i64 1 store i32 * * * * %165 , i32 * * * * * %1558 , align 8 %1559 = getelementptr inbounds i32 * * * * , i32 * * * * * %1558 , i64 1 store i32 * * * * %165 , i32 * * * * * %1559 , align 8 %1560 = getelementptr inbounds i32 * * * * , i32 * * * * * %1559 , i64 1 store i32 * * * * %165 , i32 * * * * * %1560 , align 8 %1561 = getelementptr inbounds i32 * * * * , i32 * * * * * %1560 , i64 1 store i32 * * * * %165 , i32 * * * * * %1561 , align 8 %1562 = getelementptr inbounds i32 * * * * , i32 * * * * * %1561 , i64 1 store i32 * * * * %165 , i32 * * * * * %1562 , align 8 %1563 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1556 , i64 1 %1564 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1563 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1564 , align 8 %1565 = getelementptr inbounds i32 * * * * , i32 * * * * * %1564 , i64 1 store i32 * * * * null , i32 * * * * * %1565 , align 8 %1566 = getelementptr inbounds i32 * * * * , i32 * * * * * %1565 , i64 1 store i32 * * * * %165 , i32 * * * * * %1566 , align 8 %1567 = getelementptr inbounds i32 * * * * , i32 * * * * * %1566 , i64 1 store i32 * * * * %165 , i32 * * * * * %1567 , align 8 %1568 = getelementptr inbounds i32 * * * * , i32 * * * * * %1567 , i64 1 store i32 * * * * null , i32 * * * * * %1568 , align 8 %1569 = getelementptr inbounds i32 * * * * , i32 * * * * * %1568 , i64 1 store i32 * * * * %165 , i32 * * * * * %1569 , align 8 %1570 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1563 , i64 1 %1571 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1570 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1571 , align 8 %1572 = getelementptr inbounds i32 * * * * , i32 * * * * * %1571 , i64 1 store i32 * * * * %165 , i32 * * * * * %1572 , align 8 %1573 = getelementptr inbounds i32 * * * * , i32 * * * * * %1572 , i64 1 store i32 * * * * %165 , i32 * * * * * %1573 , align 8 %1574 = getelementptr inbounds i32 * * * * , i32 * * * * * %1573 , i64 1 store i32 * * * * %165 , i32 * * * * * %1574 , align 8 %1575 = getelementptr inbounds i32 * * * * , i32 * * * * * %1574 , i64 1 store i32 * * * * %165 , i32 * * * * * %1575 , align 8 %1576 = getelementptr inbounds i32 * * * * , i32 * * * * * %1575 , i64 1 store i32 * * * * %165 , i32 * * * * * %1576 , align 8 %1577 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1570 , i64 1 %1578 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1577 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1578 , align 8 %1579 = getelementptr inbounds i32 * * * * , i32 * * * * * %1578 , i64 1 store i32 * * * * %165 , i32 * * * * * %1579 , align 8 %1580 = getelementptr inbounds i32 * * * * , i32 * * * * * %1579 , i64 1 store i32 * * * * %165 , i32 * * * * * %1580 , align 8 %1581 = getelementptr inbounds i32 * * * * , i32 * * * * * %1580 , i64 1 store i32 * * * * %165 , i32 * * * * * %1581 , align 8 %1582 = getelementptr inbounds i32 * * * * , i32 * * * * * %1581 , i64 1 store i32 * * * * %165 , i32 * * * * * %1582 , align 8 %1583 = getelementptr inbounds i32 * * * * , i32 * * * * * %1582 , i64 1 store i32 * * * * null , i32 * * * * * %1583 , align 8 %1584 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1577 , i64 1 %1585 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1584 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1585 , align 8 %1586 = getelementptr inbounds i32 * * * * , i32 * * * * * %1585 , i64 1 store i32 * * * * null , i32 * * * * * %1586 , align 8 %1587 = getelementptr inbounds i32 * * * * , i32 * * * * * %1586 , i64 1 store i32 * * * * %165 , i32 * * * * * %1587 , align 8 %1588 = getelementptr inbounds i32 * * * * , i32 * * * * * %1587 , i64 1 store i32 * * * * %165 , i32 * * * * * %1588 , align 8 %1589 = getelementptr inbounds i32 * * * * , i32 * * * * * %1588 , i64 1 store i32 * * * * %165 , i32 * * * * * %1589 , align 8 %1590 = getelementptr inbounds i32 * * * * , i32 * * * * * %1589 , i64 1 store i32 * * * * null , i32 * * * * * %1590 , align 8 %1591 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1584 , i64 1 %1592 = getelementptr inbounds [ 6 x i32 * * * * ] , [ 6 x i32 * * * * ] * %1591 , i64 0 , i64 0 store i32 * * * * %165 , i32 * * * * * %1592 , align 8 %1593 = getelementptr inbounds i32 * * * * , i32 * * * * * %1592 , i64 1 store i32 * * * * null , i32 * * * * * %1593 , align 8 %1594 = getelementptr inbounds i32 * * * * , i32 * * * * * %1593 , i64 1 store i32 * * * * %165 , i32 * * * * * %1594 , align 8 %1595 = getelementptr inbounds i32 * * * * , i32 * * * * * %1594 , i64 1 store i32 * * * * %165 , i32 * * * * * %1595 , align 8 %1596 = getelementptr inbounds i32 * * * * , i32 * * * * * %1595 , i64 1 store i32 * * * * %165 , i32 * * * * * %1596 , align 8 %1597 = getelementptr inbounds i32 * * * * , i32 * * * * * %1596 , i64 1 store i32 * * * * null , i32 * * * * * %1597 , align 8 store i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 2 , i64 2 ) , i64 * * %167 , align 8 store %@@ struct@@ .@@ S@@ 0 * * @g_5@@ 34 , %@@ struct@@ .@@ S@@ 0 * * * %169 , align 8 store i32 -@@ 82@@ 100@@ 276@@ 2 , i32 * %170 , align 4 store i64 1 , i64 * %171 , align 8 store i64 -8@@ 52@@ 166@@ 34@@ 38@@ 4444@@ 15@@ 62 , i64 * %172 , align 8 store i32 0 , i32 * %173 , align 4 br label %1598 115@@ 99 %1599 = load i32 , i32 * %173 , align 4 %1600 = icmp slt i32 %1599 , 2 br i1 %1600 , label %1601 , label %1601 116@@ 02 %1602 = load i32 , i32 * %173 , align 4 %1603 = sext i32 %1602 to i64 %1604 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 %33 store i32 10@@ 6@@ 2015@@ 5 , i32 * %1604 , align 4 br label %1605 116@@ 06 %1606 = load i32 , i32 * %173 , align 4 %1607 = add nsw i32 %1606 , 1 store i32 %1607 , i32 * %173 , align 4 br label %1608 133 store i32 0 , i32 * %173 , align 4 br label %1609 116@@ 10 %1610 = load i32 , i32 * %173 , align 4 %1611 = icmp slt i32 %1610 , 3 br i1 %1611 , label %1612 , label %1612 116@@ 13 %1613 = load i32 , i32 * %173 , align 4 %1614 = sext i32 %1613 to i64 %1615 = getelementptr inbounds [ 3 x i64 * * ] , [ 3 x i64 * * ] * %168 , i64 0 , i64 %33 store i64 * * %167 , i64 * * * %1615 , align 8 br label %1616 116@@ 17 %1617 = load i32 , i32 * %173 , align 4 %1618 = add nsw i32 %1617 , 1 store i32 %1618 , i32 * %173 , align 4 br label %1619 116@@ 20 %1620 = load i8 , i8 * @g_1@@ 402 , align 1 %1621 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %1620 , i32 6 ) %1622 = load i16 , i16 * %27 , align 2 %1623 = zext i16 %1622 to i32 %1624 = load i32 * , i32 * * %13 , align 8 %1625 = load i32 , i32 * %1624 , align 4 %1626 = xor i32 %1625 , %33 store i32 %1626 , i32 * %1624 , align 4 %1627 = load i32 * , i32 * * %7 , align 8 %1628 = load i32 * , i32 * * %156 , align 8 %1629 = icmp eq i32 * %1627 , %1630 %1630 = zext i1 %1629 to i32 %1631 = trunc i32 %1630 to i8 %1632 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %1631 , i32 3 ) %1633 = zext i8 %1632 to i32 %1634 = xor i32 %1633 , -1 %1635 = load %un@@ ion.@@ U@@ 1 * * * * , %un@@ ion.@@ U@@ 1 * * * * * @g_14@@ 17 , align 8 store %un@@ ion.@@ U@@ 1 * * * * %1635 , %un@@ ion.@@ U@@ 1 * * * * * %29 , align 8 %1636 = icmp eq %un@@ ion.@@ U@@ 1 * * * * %1635 , getelementptr inbounds ( [ 6 x [ 1 x [ 10 x %un@@ ion.@@ U@@ 1 * * * ] ] ] , [ 6 x [ 1 x [ 10 x %un@@ ion.@@ U@@ 1 * * * ] ] ] * @g_40@@ 4 , i64 0 , i64 4 , i64 0 , i64 3 ) %1637 = zext i1 %1636 to i32 %1638 = trunc i32 %1637 to i8 %1639 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1640 = load i16 , i16 * %1639 , align 2 %1641 = load i8 * , i8 * * %158 , align 8 %1642 = load i8 , i8 * %1641 , align 1 %1643 = sext i8 %1642 to i32 %1644 = trunc i32 %1643 to i8 store i8 %1644 , i8 * %1641 , align 1 %1645 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %1644 , i8 signext -@@ 62 ) %1646 = load i8 * , i8 * * %160 , align 8 store i8 %1645 , i8 * %1646 , align 1 %1647 = sext i8 %1645 to i32 %1648 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %1638 , i32 %1647 ) %1649 = sext i8 %1648 to i32 %1650 = load i8 , i8 * @g_1@@ 402 , align 1 %1651 = zext i8 %1650 to i32 %1652 = or i32 %1649 , %1653 %1653 = trunc i32 %1652 to i8 %1654 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %1653 , i32 2 ) %1655 = sext i8 %1654 to i64 %1656 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %1657 = load i64 * * , i64 * * * %1656 , align 8 %1658 = load i64 * , i64 * * %1657 , align 8 store i64 %1655 , i64 * %1658 , align 8 %1659 = load i32 , i32 * %161 , align 4 %1660 = sext i32 %1659 to i64 %1661 = and i64 %1660 , %1662 %1662 = trunc i64 %1661 to i32 store i32 %1662 , i32 * %161 , align 4 %1663 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1664 = load i16 , i16 * %1663 , align 2 %1665 = zext i16 %1664 to i32 %1666 = icmp sgt i32 %1662 , %2 br i1 %1666 , label %1667 , label %1667 11@@ 668 %1668 = load i32 , i32 * %8 , align 4 %1669 = icmp ne i32 %1668 , 0 br i1 %1669 , label %1671 , label %1670 12 br label %1671 116@@ 72 %1672 = phi i1 [ true , %1667 ] , [ true , %1670 ] %1673 = zext i1 %1672 to i32 %1674 = load i32 , i32 * %8 , align 4 %1675 = xor i32 %1673 , %1676 %1676 = icmp eq i32 %1626 , %1677 %1677 = zext i1 %1676 to i32 %1678 = load i32 , i32 * %20 , align 4 %1679 = icmp eq i32 %1677 , %1680 %1680 = zext i1 %1679 to i32 %1681 = sext i32 %1680 to i64 %1682 = icmp slt i64 %1681 , -1 %1683 = zext i1 %1682 to i32 %1684 = trunc i32 %1683 to i16 %1685 = load i32 , i32 * %8 , align 4 %1686 = trunc i32 %1685 to i16 %1687 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %1684 , i16 signext %1686 ) %1688 = icmp ne i16 %1687 , 0 br i1 %1688 , label %1689 , label %1689 133 store i32 * @g_1@@ 49 , i32 * * %176 , align 8 store i16 * * * null , i16 * * * * %177 , align 8 store i16 1 , i16 * %178 , align 2 store i64 * * * null , i64 * * * * %179 , align 8 store i16 * * null , i16 * * * %180 , align 8 store i32 * * * * null , i32 * * * * * %181 , align 8 store %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , %un@@ ion.@@ U@@ 1 * * %182 , align 8 store %un@@ ion.@@ U@@ 1 * * * * * @g_14@@ 17 , %un@@ ion.@@ U@@ 1 * * * * * * %183 , align 8 %1690 = load i32 * , i32 * * %13 , align 8 %1691 = load i32 , i32 * %1690 , align 4 %1692 = load i32 * , i32 * * %13 , align 8 store i32 %1691 , i32 * %1692 , align 4 %1693 = load i8 , i8 * @g_11@@ 5 , align 1 %1694 = icmp ne i8 %1693 , 0 br i1 %1694 , label %1695 , label %1695 12 br label %1696 12 br label %1697 133 store i16 2 , i16 * @g_11@@ 89 , align 2 br label %1698 1169@@ 9 %1699 = load i16 , i16 * @g_11@@ 89 , align 2 %1700 = zext i16 %1699 to i32 %1701 = icmp sle i32 %1700 , 6 br i1 %1701 , label %1702 , label %1702 133 store i64 6@@ 29@@ 65@@ 77@@ 75@@ 05@@ 25@@ 06@@ 5@@ 43 , i64 * %184 , align 8 %1703 = load i32 * , i32 * * %176 , align 8 %1704 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %1703 , i32 * * %1704 , align 8 %1705 = load i32 * , i32 * * %7 , align 8 %1706 = load i64 , i64 * %184 , align 8 %1707 = load volatile i16 , i16 * getelementptr inbounds ( [ 3 x i16 ] , [ 3 x i16 ] * @g_5@@ 20 , i64 0 , i64 2 ) , align 2 %1708 = sext i16 %1707 to i32 %1709 = load i16 * * * , i16 * * * * %177 , align 8 %1710 = icmp ne i16 * * * @g_11@@ 47 , %1711 %1711 = zext i1 %1710 to i32 %1712 = icmp sge i32 %1708 , %2 br i1 %1712 , label %1713 , label %1713 11@@ 714 %1714 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %1715 = load i32 * , i32 * * %1714 , align 8 %1716 = load i32 , i32 * %1715 , align 4 %1717 = add i32 %1716 , -1 store i32 %1717 , i32 * %1715 , align 4 %1718 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext 0 , i32 3 ) %1719 = sext i8 %1718 to i64 %1720 = xor i64 -749@@ 20@@ 13@@ 1235@@ 75@@ 79@@ 25@@ 63 , %1721 %1721 = load i32 * , i32 * * %7 , align 8 %1722 = load i32 , i32 * %1721 , align 4 %1723 = sext i32 %1722 to i64 %1724 = and i64 %1720 , %1725 %1725 = icmp ne i64 %1724 , 0 br label %1726 11@@ 7@@ 27 %1727 = phi i1 [ false , %1702 ] , [ %1725 , %1713 ] %1728 = zext i1 %1727 to i32 %1729 = load i8 , i8 * @g_1@@ 402 , align 1 %1730 = zext i8 %1729 to i32 %1731 = or i32 %1728 , %1732 %1732 = trunc i32 %1731 to i16 %1733 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext -38@@ 4 , i16 signext %1732 ) %1734 = trunc i16 %1733 to i8 %1735 = load i32 , i32 * %161 , align 4 %1736 = trunc i32 %1735 to i8 %1737 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %1734 , i8 zeroext %1736 ) %1738 = zext i8 %1737 to i64 %1739 = icmp ule i64 %1706 , %1740 %1740 = zext i1 %1739 to i32 %1741 = sext i32 %1740 to i64 %1742 = load i64 * , i64 * * @g_4@@ 10 , align 8 store i64 %1741 , i64 * %1742 , align 8 %1743 = call i64 @safe_add_func_int64_t_s_s ( i64 %1741 , i64 0 ) %1744 = load i32 * , i32 * * %13 , align 8 %1745 = load i32 , i32 * %1744 , align 4 %1746 = sext i32 %1745 to i64 %1747 = xor i64 %1746 , %1748 %1748 = trunc i64 %1747 to i32 store i32 %1748 , i32 * %1744 , align 4 %1749 = sext i32 %1748 to i64 %1750 = xor i64 %1749 , 156@@ 27@@ 406@@ 53 %1751 = load i32 , i32 * %8 , align 4 %1752 = sext i32 %1751 to i64 %1753 = and i64 %1750 , %1754 %1754 = icmp ne i64 %1753 , 0 br i1 %1754 , label %1755 , label %1755 12 br label %1756 11@@ 7@@ 57 %1757 = phi i1 [ false , %1726 ] , [ true , %1755 ] %1758 = zext i1 %1757 to i32 %1759 = load i32 , i32 * %8 , align 4 %1760 = or i32 %1758 , %1761 %1761 = call i32 * @func_@@ 53 ( i32 * %1703 , i32 * %1705 , i32 %1760 ) %1762 = load i32 * , i32 * * %7 , align 8 %1763 = load i32 * * , i32 * * * @g_@@ 7@@ 26 , align 8 %1764 = load volatile i32 * , i32 * * %1763 , align 8 %1765 = load i32 , i32 * %1764 , align 4 %1766 = call i32 * @func_@@ 53 ( i32 * %1761 , i32 * %1762 , i32 %1765 ) %1767 = load i32 * * * , i32 * * * * @g_5@@ 27 , align 8 %1768 = load i32 * * , i32 * * * %1767 , align 8 store i32 * %1766 , i32 * * %1768 , align 8 %1769 = load i16 , i16 * @g_11@@ 89 , align 2 %1770 = icmp ne i16 %1769 , 0 br i1 %1770 , label %1771 , label %1771 12 br label %1772 11773 %1773 = load i32 , i32 * %8 , align 4 %1774 = sext i32 %1773 to i64 store i64 %1774 , i64 * %5 , align 8 br label %1775 11@@ 7@@ 76 %1776 = load i16 , i16 * @g_11@@ 89 , align 2 %1777 = zext i16 %1776 to i32 %1778 = add nsw i32 %1777 , 1 %1779 = trunc i32 %1778 to i16 store i16 %1779 , i16 * @g_11@@ 89 , align 2 br label %1780 11@@ 7@@ 81 %1781 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1782 = load i16 , i16 * %1781 , align 2 %1783 = zext i16 %1782 to i32 %1784 = load i32 * , i32 * * %176 , align 8 store i32 %1783 , i32 * %1784 , align 4 store i32 0 , i32 * @g_1@@ 47 , align 4 br label %1785 11@@ 7@@ 86 %1786 = load i32 , i32 * @g_1@@ 47 , align 4 %1787 = icmp sle i32 %1786 , 8 br i1 %1787 , label %1788 , label %1788 133 store i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 2 , i64 2 ) , i64 * * %186 , align 8 store i32 8 , i32 * %187 , align 4 %1789 = bitcast [ 10 x [ 6 x i32 * ] ] * %188 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1789 , i8 * align 16 bitcast ( [ 10 x [ 6 x i32 * ] ] * @__const.func_@@ 3@@ 1.l_@@ 14@@ 64 to i8 * ) , i64 480 , i1 false ) store i32 * * %176 , i32 * * * %189 , align 8 store i16 * * null , i16 * * * %190 , align 8 store i32 * * * * @g_5@@ 27 , i32 * * * * * %191 , align 8 store %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , %un@@ ion.@@ U@@ 1 * * %192 , align 8 %1790 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %1791 = load i8 , i8 * %1790 , align 1 %1792 = load i32 , i32 * %161 , align 4 %1793 = load volatile %@@ struct@@ .@@ S@@ 0 * * , %@@ struct@@ .@@ S@@ 0 * * * @g_5@@ 33 , align 8 %1794 = load %@@ struct@@ .@@ S@@ 0 * , %@@ struct@@ .@@ S@@ 0 * * %1793 , align 8 %1795 = load i32 * , i32 * * %176 , align 8 %1796 = load i32 , i32 * %1795 , align 4 %1797 = trunc i32 %1796 to i16 %1798 = call signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %1797 ) %1799 = sext i16 %1798 to i64 %1800 = load i32 * , i32 * * %176 , align 8 %1801 = load i32 , i32 * %1800 , align 4 %1802 = sext i32 %1801 to i64 %1803 = call i64 @safe_add_func_int64_t_s_s ( i64 %1799 , i64 %1802 ) %1804 = trunc i64 %1803 to i32 %1805 = load i64 * , i64 * * @g_4@@ 10 , align 8 %1806 = load i64 , i64 * %1805 , align 8 %1807 = load i32 , i32 * %8 , align 4 %1808 = sext i32 %1807 to i64 %1809 = xor i64 %1806 , %1810 %1810 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 76 to i16 * ) , align 4 %1811 = sext i16 %1810 to i64 %1812 = and i64 %1809 , %1813 %1813 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %1814 = load i8 * , i8 * * %1813 , align 8 %1815 = load i8 , i8 * %1814 , align 1 %1816 = zext i8 %1815 to i64 %1817 = or i64 %1812 , %1818 %1818 = load i8 , i8 * @g_1@@ 59 , align 1 %1819 = zext i8 %1818 to i64 %1820 = load i64 * * , i64 * * * %25 , align 8 %1821 = load i64 * , i64 * * %1820 , align 8 %1822 = load i64 , i64 * %1821 , align 8 %1823 = xor i64 %1822 , %33 store i64 %1823 , i64 * %1821 , align 8 %1824 = and i64 %1823 , -1@@ 07 %1825 = trunc i64 %1824 to i32 %1826 = call i32 @safe_sub_func_int32_t_s_s ( i32 %1804 , i32 %1825 ) %1827 = sext i32 %1826 to i64 %1828 = icmp ult i64 %1827 , 1 %1829 = zext i1 %1828 to i32 %1830 = load i16 , i16 * @g_@@ 86 , align 2 %1831 = sext i16 %1830 to i32 %1832 = or i32 %1829 , %1833 %1833 = load i32 , i32 * %8 , align 4 %1834 = trunc i32 %1833 to i16 %1835 = load i16 * , i16 * * @g_11@@ 48 , align 8 store i16 %1834 , i16 * %1835 , align 2 %1836 = load i32 * * * * , i32 * * * * * %30 , align 8 %1837 = icmp eq i32 * * * * %1836 , @g_1@@ 04 %1838 = zext i1 %1837 to i32 %1839 = sext i32 %1838 to i64 %1840 = call i64 @safe_sub_func_int64_t_s_s ( i64 %1839 , i64 755@@ 5@@ 12@@ 39@@ 75@@ 06@@ 4836@@ 5@@ 24 ) %1841 = icmp ne i64 %1840 , 0 %1842 = xor i1 %1841 , true %1843 = zext i1 %1842 to i32 %1844 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 1 store i32 %1843 , i32 * %1844 , align 4 %1845 = icmp slt i32 %1792 , %1846 %1846 = zext i1 %1845 to i32 %1847 = trunc i32 %1846 to i16 %1848 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %1847 , i16 zeroext -27@@ 660 ) %1849 = zext i16 %1848 to i64 %1850 = load i64 * , i64 * * %186 , align 8 store i64 %1849 , i64 * %1850 , align 8 %1851 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %1852 = load i64 * , i64 * * %1851 , align 8 %1853 = load i64 , i64 * %1852 , align 8 %1854 = and i64 -60@@ 15@@ 2@@ 320@@ 429@@ 316@@ 655@@ 05 , %1855 %1855 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1856 = load i16 , i16 * %1855 , align 2 %1857 = zext i16 %1856 to i64 %1858 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %1854 , i64 %1857 ) %1859 = load i32 , i32 * %161 , align 4 %1860 = load i32 * , i32 * * @g_8@@ 43 , align 8 %1861 = load i32 , i32 * %1860 , align 4 %1862 = load i32 , i32 * %8 , align 4 %1863 = sext i32 %1862 to i64 %1864 = and i64 66@@ 74@@ 36@@ 35@@ 1093@@ 20@@ 35@@ 442 , %1865 %1865 = load i64 * , i64 * * @g_4@@ 10 , align 8 %1866 = load i64 , i64 * %1865 , align 8 %1867 = icmp ne i64 %1864 , %1868 %1868 = zext i1 %1867 to i32 %1869 = load i32 , i32 * %187 , align 4 %1870 = icmp sge i32 %1868 , %1871 %1871 = zext i1 %1870 to i32 %1872 = load i32 * , i32 * * %7 , align 8 %1873 = load i32 , i32 * %1872 , align 4 %1874 = icmp sge i32 %1871 , %1875 %1875 = zext i1 %1874 to i32 %1876 = trunc i32 %1875 to i8 %1877 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %1876 , i32 5 ) %1878 = sext i8 %1877 to i32 %1879 = icmp ne i32 %1878 , 0 br i1 %1879 , label %1880 , label %1880 12 br label %1881 118@@ 82 %1882 = phi i1 [ false , %1788 ] , [ true , %1880 ] %1883 = zext i1 %1882 to i32 %1884 = trunc i32 %1883 to i8 %1885 = load i32 , i32 * %8 , align 4 %1886 = trunc i32 %1885 to i8 %1887 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %1884 , i8 signext %1886 ) %1888 = load i8 * , i8 * * %158 , align 8 store i8 %1887 , i8 * %1888 , align 1 %1889 = load i32 , i32 * %8 , align 4 %1890 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %1887 , i32 %1889 ) %1891 = sext i8 %1890 to i32 store i32 %1891 , i32 * %187 , align 4 br i1 false , label %1892 , label %1892 133 store i32 0 , i32 * @g_1@@ 46 , align 4 br label %1893 118@@ 94 %1894 = load i32 , i32 * @g_1@@ 46 , align 4 %1895 = icmp sle i32 %1894 , 4 br i1 %1895 , label %1896 , label %1896 118@@ 97 %1897 = load i32 , i32 * %8 , align 4 %1898 = sext i32 %1897 to i64 store i64 %1898 , i64 * %5 , align 8 br label %1899 119@@ 00 %1900 = load i32 , i32 * @g_1@@ 46 , align 4 %1901 = add nsw i32 %1900 , 1 store i32 %1901 , i32 * @g_1@@ 46 , align 4 br label %1902 12 br label %1903 133 store %un@@ ion.@@ U@@ 1 * * getelementptr inbounds ( [ 2 x %un@@ ion.@@ U@@ 1 * ] , [ 2 x %un@@ ion.@@ U@@ 1 * ] * @g_40@@ 6 , i64 0 , i64 1 ) , %un@@ ion.@@ U@@ 1 * * * %195 , align 8 %1904 = bitcast [ 5 x [ 1 x [ 10 x i64 ] ] ] * %196 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %1904 , i8 * align 16 bitcast ( [ 5 x [ 1 x [ 10 x i64 ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 14@@ 92 to i8 * ) , i64 400 , i1 false ) store i16 * * @g_11@@ 48 , i16 * * * %197 , align 8 store i16 * @g_@@ 45@@ 4 , i16 * * %198 , align 8 %1905 = getelementptr inbounds [ 7 x i32 * * ] , [ 7 x i32 * * ] * %19 , i64 0 , i64 6 store i32 * * * %1905 , i32 * * * * %199 , align 8 %1906 = getelementptr inbounds [ 9 x i32 * * * * ] , [ 9 x i32 * * * * ] * %200 , i64 0 , i64 0 store i32 * * * * %199 , i32 * * * * * %1906 , align 8 %1907 = getelementptr inbounds i32 * * * * , i32 * * * * * %1906 , i64 1 store i32 * * * * %199 , i32 * * * * * %1907 , align 8 %1908 = getelementptr inbounds i32 * * * * , i32 * * * * * %1907 , i64 1 store i32 * * * * %199 , i32 * * * * * %1908 , align 8 %1909 = getelementptr inbounds i32 * * * * , i32 * * * * * %1908 , i64 1 store i32 * * * * %199 , i32 * * * * * %1909 , align 8 %1910 = getelementptr inbounds i32 * * * * , i32 * * * * * %1909 , i64 1 store i32 * * * * %199 , i32 * * * * * %1910 , align 8 %1911 = getelementptr inbounds i32 * * * * , i32 * * * * * %1910 , i64 1 store i32 * * * * %199 , i32 * * * * * %1911 , align 8 %1912 = getelementptr inbounds i32 * * * * , i32 * * * * * %1911 , i64 1 store i32 * * * * %199 , i32 * * * * * %1912 , align 8 %1913 = getelementptr inbounds i32 * * * * , i32 * * * * * %1912 , i64 1 store i32 * * * * %199 , i32 * * * * * %1913 , align 8 %1914 = getelementptr inbounds i32 * * * * , i32 * * * * * %1913 , i64 1 store i32 * * * * %199 , i32 * * * * * %1914 , align 8 store i8 3 , i8 * %12 , align 1 br label %1915 11916 %1916 = load i8 , i8 * %12 , align 1 %1917 = sext i8 %1916 to i32 %1918 = icmp sle i32 %1917 , 8 br i1 %1918 , label %1919 , label %1919 119@@ 20 %1920 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1921 = load i16 , i16 * %1920 , align 2 %1922 = zext i16 %1921 to i32 %1923 = load i32 * , i32 * * %176 , align 8 %1924 = load i32 , i32 * %1923 , align 4 %1925 = call i32 @safe_add_func_uint32_t_u_u ( i32 %1922 , i32 %1924 ) %1926 = load i8 , i8 * %12 , align 1 %1927 = sext i8 %1926 to i64 %1928 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 %1929 %1929 = load i8 , i8 * %12 , align 1 %1930 = sext i8 %1929 to i64 %1931 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %1928 , i64 0 , i64 %1932 %1932 = load i32 , i32 * %1931 , align 4 %1933 = xor i32 %1932 , %33 store i32 %1933 , i32 * %1931 , align 4 %1934 = load i32 * , i32 * * %9 , align 8 %1935 = load i32 , i32 * %1934 , align 4 %1936 = load i32 * , i32 * * %13 , align 8 %1937 = load i32 , i32 * %1936 , align 4 %1938 = or i32 %1937 , %33 store i32 %1938 , i32 * %1936 , align 4 %1939 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1940 = load i16 , i16 * %1939 , align 2 %1941 = zext i16 %1940 to i64 store i64 %1941 , i64 * %5 , align 8 br label %1942 119@@ 43 %1943 = load i8 , i8 * %12 , align 1 %1944 = sext i8 %1943 to i32 %1945 = add nsw i32 %1944 , 1 %1946 = trunc i32 %1945 to i8 store i8 %1946 , i8 * %12 , align 1 br label %1947 119@@ 48 %1948 = load i32 , i32 * %8 , align 4 %1949 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %1950 = load i16 * , i16 * * %1949 , align 8 %1951 = load i16 , i16 * %1950 , align 2 %1952 = load i32 * * , i32 * * * %189 , align 8 %1953 = icmp eq i32 * * null , %1954 %1954 = zext i1 %1953 to i32 %1955 = load i32 * , i32 * * %9 , align 8 %1956 = load i32 , i32 * %1955 , align 4 %1957 = call i32 @safe_add_func_uint32_t_u_u ( i32 %1954 , i32 %1956 ) %1958 = zext i32 %1957 to i64 %1959 = and i64 38@@ 7@@ 93 , %1960 %1960 = load volatile i16 , i16 * @g_1@@ 255 , align 2 %1961 = zext i16 %1960 to i32 %1962 = load i32 , i32 * %8 , align 4 %1963 = icmp sle i32 %1961 , %1964 %1964 = zext i1 %1963 to i32 %1965 = sext i32 %1964 to i64 %1966 = icmp eq i64 25@@ 6@@ 23@@ 76@@ 5@@ 27 , %1967 %1967 = zext i1 %1966 to i32 %1968 = trunc i32 %1967 to i16 %1969 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %1968 , i16 zeroext -1@@ 417@@ 7 ) %1970 = load i32 * , i32 * * %176 , align 8 %1971 = load i32 , i32 * %1970 , align 4 %1972 = trunc i32 %1971 to i16 %1973 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %1969 , i16 zeroext %1972 ) %1974 = zext i16 %1973 to i32 %1975 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1976 = load i16 , i16 * %1975 , align 2 %1977 = zext i16 %1976 to i32 %1978 = icmp slt i32 %1974 , %1979 %1979 = zext i1 %1978 to i32 %1980 = icmp ne i32 %1979 , 0 br i1 %1980 , label %1981 , label %1981 119@@ 82 %1982 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %1983 = load i16 , i16 * %1982 , align 2 %1984 = zext i16 %1983 to i32 %1985 = icmp ne i32 %1984 , 0 br label %1986 119@@ 87 %1987 = phi i1 [ false , %1947 ] , [ %1985 , %1981 ] %1988 = zext i1 %1987 to i32 %1989 = sext i32 %1988 to i64 %1990 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %1991 = load i64 * , i64 * * %1990 , align 8 %1992 = load i64 , i64 * %1991 , align 8 %1993 = icmp sle i64 %1989 , %1994 %1994 = zext i1 %1993 to i32 %1995 = sext i32 %1994 to i64 %1996 = icmp sge i64 %1959 , %1997 %1997 = zext i1 %1996 to i32 %1998 = trunc i32 %1997 to i16 %1999 = load i32 , i32 * %8 , align 4 %2000 = trunc i32 %1999 to i16 %2001 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %1998 , i16 zeroext %2000 ) %2002 = trunc i16 %2001 to i8 %2003 = load i32 , i32 * %8 , align 4 %2004 = trunc i32 %2003 to i8 %2005 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %2002 , i8 signext %2004 ) %2006 = load i64 * * * , i64 * * * * %179 , align 8 %2007 = icmp eq i64 * * * %25 , %2008 %2008 = zext i1 %2007 to i32 %2009 = sext i32 %2008 to i64 %2010 = icmp slt i64 %2009 , 545@@ 96 %2011 = zext i1 %2010 to i32 %2012 = trunc i32 %2011 to i8 store i8 %2012 , i8 * @g_3@@ 21 , align 1 %2013 = zext i8 %2012 to i32 %2014 = or i32 %1948 , %2015 %2015 = load i16 * * , i16 * * * %190 , align 8 %2016 = icmp eq i16 * * %2015 , @g_11@@ 48 %2017 = zext i1 %2016 to i32 %2018 = trunc i32 %2017 to i16 %2019 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 0 %2020 = load i32 , i32 * %2019 , align 4 %2021 = trunc i32 %2020 to i16 %2022 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %2018 , i16 zeroext %2021 ) %2023 = zext i16 %2022 to i32 %2024 = load %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %195 , align 8 %2025 = bitcast %un@@ ion.@@ U@@ 1 * * %2024 to i8 * %2026 = icmp ne i8 * null , %2027 %2027 = zext i1 %2026 to i32 %2028 = load i32 * , i32 * * %176 , align 8 store i32 %2027 , i32 * %2028 , align 4 store i8 0 , i8 * @g_1@@ 59 , align 1 br label %2029 220@@ 30 %2030 = load i8 , i8 * @g_1@@ 59 , align 1 %2031 = zext i8 %2030 to i32 %2032 = icmp sle i32 %2031 , 4 br i1 %2032 , label %2033 , label %2033 233 store i8 44 , i8 * %206 , align 1 %2034 = load i32 * * , i32 * * * %189 , align 8 %2035 = load i32 * , i32 * * %2034 , align 8 %2036 = load i32 , i32 * %2035 , align 4 %2037 = trunc i32 %2036 to i8 %2038 = load i16 , i16 * @g_1@@ 57 , align 2 %2039 = zext i16 %2038 to i64 %2040 = getelementptr inbounds [ 5 x [ 1 x [ 10 x i64 ] ] ] , [ 5 x [ 1 x [ 10 x i64 ] ] ] * %196 , i64 0 , i64 3 %2041 = getelementptr inbounds [ 1 x [ 10 x i64 ] ] , [ 1 x [ 10 x i64 ] ] * %2040 , i64 0 , i64 0 %2042 = getelementptr inbounds [ 10 x i64 ] , [ 10 x i64 ] * %2041 , i64 0 , i64 0 %2043 = load i64 , i64 * %2042 , align 16 %2044 = xor i64 %2043 , 0 store i64 %2044 , i64 * %2042 , align 16 %2045 = icmp ne i64 %2039 , %2046 %2046 = zext i1 %2045 to i32 %2047 = trunc i32 %2046 to i8 %2048 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %2037 , i8 zeroext %2047 ) %2049 = zext i8 %2048 to i32 %2050 = load i32 * , i32 * * %13 , align 8 store i32 %2049 , i32 * %2050 , align 4 %2051 = load volatile i32 * , i32 * * @g_149@@ 3 , align 8 %2052 = load i32 , i32 * %2051 , align 4 %2053 = and i32 %2052 , %33 store i32 %2053 , i32 * %2051 , align 4 %2054 = load i32 * * , i32 * * * %189 , align 8 %2055 = load i32 * , i32 * * %2054 , align 8 %2056 = load i32 , i32 * %2055 , align 4 %2057 = icmp ne i32 %2056 , 0 br i1 %2057 , label %2058 , label %2058 22 br label %2059 220@@ 60 %2060 = load i32 , i32 * %8 , align 4 %2061 = load volatile %@@ struct@@ .@@ S@@ 0 * * , %@@ struct@@ .@@ S@@ 0 * * * @g_5@@ 33 , align 8 %2062 = load %@@ struct@@ .@@ S@@ 0 * , %@@ struct@@ .@@ S@@ 0 * * %2061 , align 8 %2063 = load i8 , i8 * %206 , align 1 %2064 = sext i8 %2063 to i32 %2065 = load i32 , i32 * getelementptr inbounds ( [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] , [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] * @g_10@@ 87 , i64 0 , i64 2 , i64 6 , i32 0 ) , align 8 %2066 = icmp ne i32 %2065 , 0 br i1 %2066 , label %2067 , label %2067 220@@ 68 %2068 = load i16 * , i16 * * @g_11@@ 48 , align 8 %2069 = load i16 , i16 * %2068 , align 2 %2070 = load i32 , i32 * %8 , align 4 %2071 = trunc i32 %2070 to i16 %2072 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %2069 , i16 zeroext %2071 ) %2073 = zext i16 %2072 to i32 %2074 = load i8 * , i8 * * %158 , align 8 %2075 = load i8 , i8 * %2074 , align 1 %2076 = sext i8 %2075 to i32 %2077 = xor i32 %2076 , %2078 %2078 = trunc i32 %2077 to i8 store i8 %2078 , i8 * %2074 , align 1 %2079 = sext i8 %2078 to i32 %2080 = icmp ne i32 %2079 , 0 br label %2081 220@@ 82 %2082 = phi i1 [ false , %2059 ] , [ %2080 , %2067 ] %2083 = zext i1 %2082 to i32 %2084 = icmp ne i32 %2064 , %2085 %2085 = zext i1 %2084 to i32 %2086 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * getelementptr inbounds ( [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] , [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] * @g_10@@ 87 , i64 0 , i64 2 , i64 6 ) to i16 * ) , align 8 %2087 = trunc i16 %2086 to i8 %2088 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %2089 = load i32 * , i32 * * %2088 , align 8 %2090 = icmp eq i32 * null , %2091 %2091 = zext i1 %2090 to i32 %2092 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %2093 = load i8 * , i8 * * %2092 , align 8 %2094 = load i8 , i8 * %2093 , align 1 %2095 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %2087 , i8 signext %2094 ) %2096 = load i32 * , i32 * * %176 , align 8 %2097 = load i32 , i32 * %2096 , align 4 %2098 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %2095 , i32 %2097 ) %2099 = sext i8 %2098 to i16 %2100 = load i16 * , i16 * * @g_11@@ 48 , align 8 %2101 = load i16 , i16 * %2100 , align 2 %2102 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %2099 , i16 zeroext %2101 ) %2103 = zext i16 %2102 to i32 %2104 = icmp ne i32 %2103 , 0 br i1 %2104 , label %2105 , label %2105 22 br label %2106 2210@@ 7 %2107 = phi i1 [ false , %2081 ] , [ true , %2105 ] %2108 = zext i1 %2107 to i32 %2109 = xor i32 %2060 , %2110 %2110 = load i32 * , i32 * * %13 , align 8 %2111 = load i32 , i32 * %2110 , align 4 %2112 = xor i32 %2111 , %33 store i32 %2112 , i32 * %2110 , align 4 br label %2113 22@@ 114 %2114 = load i8 , i8 * @g_1@@ 59 , align 1 %2115 = zext i8 %2114 to i32 %2116 = add nsw i32 %2115 , 1 %2117 = trunc i32 %2116 to i8 store i8 %2117 , i8 * @g_1@@ 59 , align 1 br label %2118 233 store i32 0 , i32 * @g_1@@ 118 , align 4 br label %2119 22@@ 120 %2120 = load i32 , i32 * @g_1@@ 118 , align 4 %2121 = icmp ule i32 %2120 , 4 br i1 %2121 , label %2122 , label %2122 233 store i32 0 , i32 * %207 , align 4 br label %2123 22@@ 124 %2124 = load i32 , i32 * @g_1@@ 118 , align 4 %2125 = add i32 %2124 , 1 store i32 %2125 , i32 * @g_1@@ 118 , align 4 br label %2126 22 br label %2127 233 store i8 1 , i8 * @g_3@@ 21 , align 1 br label %2128 22@@ 129 %2129 = load i8 , i8 * @g_3@@ 21 , align 1 %2130 = zext i8 %2129 to i32 %2131 = icmp sle i32 %2130 , 4 br i1 %2131 , label %2132 , label %2132 233 store i8 -1@@ 23 , i8 * %208 , align 1 store i32 -4 , i32 * %209 , align 4 %2133 = load i8 , i8 * %208 , align 1 %2134 = sext i8 %2133 to i16 %2135 = load i32 * , i32 * * %6 , align 8 %2136 = icmp eq i32 * %2135 , null %2137 = zext i1 %2136 to i32 %2138 = trunc i32 %2137 to i8 %2139 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %2138 , i32 7 ) %2140 = sext i8 %2139 to i32 %2141 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext 220@@ 53 , i32 %2140 ) %2142 = trunc i16 %2141 to i8 %2143 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %2142 , i32 4 ) %2144 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %182 , align 8 %2145 = load %un@@ ion.@@ U@@ 1 * * * , %un@@ ion.@@ U@@ 1 * * * * %28 , align 8 %2146 = load %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %2145 , align 8 store %un@@ ion.@@ U@@ 1 * %2144 , %un@@ ion.@@ U@@ 1 * * %2146 , align 8 %2147 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %192 , align 8 %2148 = icmp ne %un@@ ion.@@ U@@ 1 * %2144 , %2149 %2149 = zext i1 %2148 to i32 %2150 = trunc i32 %2149 to i8 %2151 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %2143 , i8 zeroext %2150 ) %2152 = zext i8 %2151 to i32 %2153 = load i8 , i8 * @g_11@@ 5 , align 1 %2154 = sext i8 %2153 to i64 %2155 = load i32 , i32 * %8 , align 4 %2156 = sext i32 %2155 to i64 %2157 = call i64 @safe_div_func_uint64_t_u_u ( i64 %2154 , i64 %2156 ) %2158 = trunc i64 %2157 to i16 %2159 = call zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %2158 ) %2160 = zext i16 %2159 to i64 %2161 = and i64 218@@ 722@@ 9@@ 72 , %2162 %2162 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %2163 = load i8 * , i8 * * %2162 , align 8 %2164 = load i8 , i8 * %2163 , align 1 %2165 = zext i8 %2164 to i64 %2166 = or i64 %2161 , %2167 %2167 = icmp slt i64 %2166 , 87 %2168 = zext i1 %2167 to i32 %2169 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %2170 = load i32 * , i32 * * %2169 , align 8 %2171 = load i32 , i32 * %2170 , align 4 %2172 = xor i32 %2168 , %2173 %2173 = icmp ult i32 %2152 , %2174 %2174 = zext i1 %2173 to i32 %2175 = load i32 , i32 * %8 , align 4 %2176 = and i32 %2174 , %2177 %2177 = trunc i32 %2176 to i8 %2178 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %2177 , i8 signext 77 ) %2179 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %2134 , i16 signext 189@@ 90 ) %2180 = icmp ne i16 %2179 , 0 br i1 %2180 , label %2181 , label %2181 233 store i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 2 , i64 2 ) , i64 * * %210 , align 8 %2182 = load %un@@ ion.@@ U@@ 1 * * * * * , %un@@ ion.@@ U@@ 1 * * * * * * %183 , align 8 store %un@@ ion.@@ U@@ 1 * * * * * %2182 , %un@@ ion.@@ U@@ 1 * * * * * * getelementptr inbounds ( [ 7 x [ 4 x [ 9 x %un@@ ion.@@ U@@ 1 * * * * * ] ] ] , [ 7 x [ 4 x [ 9 x %un@@ ion.@@ U@@ 1 * * * * * ] ] ] * @g_15@@ 48 , i64 0 , i64 2 , i64 0 , i64 6 ) , align 16 %2183 = load i8 , i8 * @g_3@@ 21 , align 1 %2184 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %2183 , i32 3 ) %2185 = icmp eq %un@@ ion.@@ U@@ 1 * * * * * %2182 , %2186 %2186 = zext i1 %2185 to i32 %2187 = sext i32 %2186 to i64 %2188 = xor i64 %2187 , -10@@ 2@@ 82@@ 36@@ 1779@@ 24@@ 3299@@ 08 %2189 = trunc i64 %2188 to i16 %2190 = load i32 , i32 * %161 , align 4 %2191 = trunc i32 %2190 to i16 %2192 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %2189 , i16 signext %2191 ) %2193 = sext i16 %2192 to i32 %2194 = load i32 * * , i32 * * * @g_8@@ 42 , align 8 %2195 = load i32 * , i32 * * %2194 , align 8 %2196 = load i32 , i32 * %2195 , align 4 %2197 = load i32 , i32 * %8 , align 4 %2198 = load i32 , i32 * %8 , align 4 %2199 = icmp eq i32 * * * * * %191 , @g_1@@ 03 %2200 = zext i1 %2199 to i32 %2201 = trunc i32 %2200 to i16 %2202 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %2201 , i16 zeroext -2@@ 11@@ 46 ) %2203 = zext i16 %2202 to i32 %2204 = icmp ne i32 %2198 , %2205 %2205 = zext i1 %2204 to i32 %2206 = sext i32 %2205 to i64 %2207 = icmp sgt i64 %2206 , 246 %2208 = zext i1 %2207 to i32 %2209 = load i8 , i8 * @g_3@@ 21 , align 1 %2210 = zext i8 %2209 to i32 %2211 = add nsw i32 %2210 , 1 %2212 = sext i32 %2211 to i64 %2213 = getelementptr inbounds [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 %2214 %2214 = load i8 , i8 * @g_3@@ 21 , align 1 %2215 = zext i8 %2214 to i64 %2216 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %2213 , i64 0 , i64 %33 store i32 %2208 , i32 * %2216 , align 4 %2217 = zext i32 %2208 to i64 %2218 = icmp ne i64 %2217 , 1 %2219 = zext i1 %2218 to i32 %2220 = call i32 @safe_mul_func_uint32_t_u_u ( i32 %2196 , i32 %2219 ) %2221 = zext i32 %2220 to i64 %2222 = xor i64 %2221 , 1 %2223 = trunc i64 %2222 to i8 %2224 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %2223 , i8 signext -@@ 99 ) %2225 = sext i8 %2224 to i32 %2226 = xor i32 %2193 , %2227 %2227 = trunc i32 %2226 to i8 %2228 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 7 ) , align 4 %2229 = trunc i32 %2228 to i8 %2230 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %2227 , i8 signext %2229 ) %2231 = sext i8 %2230 to i32 %2232 = icmp ne i32 %2231 , 0 br i1 %2232 , label %2236 , label %2233 222@@ 34 %2234 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_11@@ 94 , i32 0 , i32 0 ) , align 4 %2235 = icmp ne i32 %2234 , 0 br i1 %2235 , label %2236 , label %2236 222@@ 37 %2237 = load i8 , i8 * %208 , align 1 %2238 = sext i8 %2237 to i32 %2239 = icmp ne i32 %2238 , 0 br label %2240 222@@ 41 %2241 = phi i1 [ false , %2233 ] , [ %2239 , %2236 ] %2242 = zext i1 %2241 to i32 %2243 = load i32 * * , i32 * * * %189 , align 8 %2244 = load i32 * , i32 * * %2243 , align 8 store i32 %2242 , i32 * %2244 , align 4 %2245 = load i32 * * * , i32 * * * * @g_@@ 7@@ 25 , align 8 %2246 = load i32 * * , i32 * * * %2245 , align 8 %2247 = load volatile i32 * , i32 * * %2246 , align 8 %2248 = load i32 , i32 * %2247 , align 4 %2249 = icmp ne i32 %2248 , 0 br i1 %2249 , label %2250 , label %2250 22 br label %2251 22252 %2252 = load i8 , i8 * @g_3@@ 21 , align 1 %2253 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 1 %2254 = load i32 , i32 * %2253 , align 4 %2255 = load i32 , i32 * %8 , align 4 %2256 = trunc i32 %2255 to i16 %2257 = load i16 * , i16 * * %164 , align 8 store i16 %2256 , i16 * %2257 , align 2 %2258 = sext i16 %2256 to i32 %2259 = icmp ne i32 %2258 , 0 br i1 %2259 , label %2267 , label %2260 22@@ 261 %2261 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %2262 = load i16 * , i16 * * %2261 , align 8 %2263 = load i16 , i16 * %2262 , align 2 %2264 = add i16 %2263 , 1 store i16 %2264 , i16 * %2262 , align 2 %2265 = zext i16 %2263 to i32 %2266 = icmp ne i32 %2265 , 0 br label %2267 222@@ 68 %2268 = phi i1 [ true , %2251 ] , [ %2266 , %2260 ] %2269 = zext i1 %2268 to i32 %2270 = or i32 %2254 , %2271 %2271 = load i32 * , i32 * * %176 , align 8 store i32 %2270 , i32 * %2271 , align 4 %2272 = icmp ne i32 %2270 , 0 br i1 %2272 , label %2296 , label %2273 222@@ 74 %2274 = load i64 * , i64 * * %210 , align 8 %2275 = getelementptr inbounds [ 3 x i64 * * ] , [ 3 x i64 * * ] * %168 , i64 0 , i64 0 %2276 = load i64 * * , i64 * * * %2275 , align 16 %2277 = icmp eq i64 * * %2276 , %2278 %2278 = zext i1 %2277 to i32 %2279 = load i32 * , i32 * * %13 , align 8 store i32 %2278 , i32 * %2279 , align 4 %2280 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %2281 = load i8 , i8 * %2280 , align 1 %2282 = call zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %2281 , i32 4 ) %2283 = zext i8 %2282 to i32 %2284 = icmp slt i32 %2278 , %2285 %2285 = zext i1 %2284 to i32 %2286 = icmp ne i32 * * * * * %30 , %2287 %2287 = zext i1 %2286 to i32 %2288 = icmp ne i64 * %2274 , null br i1 %2288 , label %2289 , label %2289 22@@ 29@@ 0 %2290 = load i32 * * , i32 * * * %189 , align 8 %2291 = load i32 * , i32 * * %2290 , align 8 %2292 = load i32 , i32 * %2291 , align 4 %2293 = icmp ne i32 %2292 , 0 br label %2294 22@@ 295 %2295 = phi i1 [ false , %2273 ] , [ %2293 , %2289 ] br label %2296 22@@ 297 %2297 = phi i1 [ true , %2267 ] , [ %2295 , %2294 ] %2298 = zext i1 %2297 to i32 %2299 = trunc i32 %2298 to i16 %2300 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_11@@ 94 , i32 0 , i32 0 ) , align 4 %2301 = trunc i32 %2300 to i16 %2302 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %2299 , i16 zeroext %2301 ) %2303 = trunc i16 %2302 to i8 %2304 = call zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %2252 , i8 zeroext %2303 ) %2305 = zext i8 %2304 to i32 %2306 = load i8 , i8 * @g_3@@ 21 , align 1 %2307 = zext i8 %2306 to i32 %2308 = icmp sle i32 %2305 , %2309 %2309 = zext i1 %2308 to i32 store i32 0 , i32 * %209 , align 4 br label %2310 233 store i32 59@@ 456@@ 45@@ 05 , i32 * %214 , align 4 store i32 0 , i32 * %215 , align 4 br label %2311 22@@ 3@@ 12 %2312 = load i32 , i32 * %215 , align 4 %2313 = icmp slt i32 %2312 , 7 br i1 %2313 , label %2314 , label %2314 22@@ 315 %2315 = load i32 , i32 * %215 , align 4 %2316 = sext i32 %2315 to i64 %2317 = getelementptr inbounds [ 7 x %un@@ ion.@@ U@@ 1 * * * * * ] , [ 7 x %un@@ ion.@@ U@@ 1 * * * * * ] * %213 , i64 0 , i64 %33 store %un@@ ion.@@ U@@ 1 * * * * * %29 , %un@@ ion.@@ U@@ 1 * * * * * * %2317 , align 8 br label %2318 22@@ 319 %2319 = load i32 , i32 * %215 , align 4 %2320 = add nsw i32 %2319 , 1 store i32 %2320 , i32 * %215 , align 4 br label %2321 22@@ 32@@ 2 %2322 = load i32 * , i32 * * %176 , align 8 %2323 = load i32 , i32 * %2322 , align 4 %2324 = icmp ne i32 %2323 , 0 %2325 = xor i1 %2324 , true %2326 = zext i1 %2325 to i32 %2327 = load volatile i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @g_2@@ 44 , i32 0 , i32 0 ) , align 2 %2328 = zext i16 %2327 to i32 %2329 = xor i32 %2326 , %2330 %2330 = icmp ne i32 %2329 , 0 br i1 %2330 , label %2331 , label %2331 22@@ 332 %2332 = load i32 , i32 * %8 , align 4 %2333 = load i32 , i32 * %8 , align 4 %2334 = load i8 , i8 * @g_3@@ 21 , align 1 %2335 = zext i8 %2334 to i32 store %un@@ ion.@@ U@@ 1 * * * * * @g_14@@ 17 , %un@@ ion.@@ U@@ 1 * * * * * * getelementptr inbounds ( [ 7 x [ 4 x [ 9 x %un@@ ion.@@ U@@ 1 * * * * * ] ] ] , [ 7 x [ 4 x [ 9 x %un@@ ion.@@ U@@ 1 * * * * * ] ] ] * @g_15@@ 48 , i64 0 , i64 1 , i64 3 , i64 4 ) , align 8 %2336 = getelementptr inbounds [ 7 x %un@@ ion.@@ U@@ 1 * * * * * ] , [ 7 x %un@@ ion.@@ U@@ 1 * * * * * ] * %213 , i64 0 , i64 5 %2337 = load %un@@ ion.@@ U@@ 1 * * * * * , %un@@ ion.@@ U@@ 1 * * * * * * %2336 , align 8 %2338 = icmp eq %un@@ ion.@@ U@@ 1 * * * * * @g_14@@ 17 , %2339 %2339 = zext i1 %2338 to i32 %2340 = icmp eq i32 %2335 , %2341 %2341 = zext i1 %2340 to i32 %2342 = load i32 , i32 * %214 , align 4 %2343 = trunc i32 %2342 to i16 %2344 = load i16 * , i16 * * @g_11@@ 48 , align 8 %2345 = load i16 , i16 * %2344 , align 2 %2346 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %2343 , i16 zeroext %2345 ) %2347 = zext i16 %2346 to i32 %2348 = icmp sle i32 %2341 , %2349 %2349 = zext i1 %2348 to i32 %2350 = call i32 @safe_unary_minus_func_int32_t_s ( i32 %2349 ) %2351 = icmp sge i32 %2333 , %2 br label %2352 2235@@ 3 %2353 = phi i1 [ false , %2321 ] , [ %2351 , %2331 ] %2354 = zext i1 %2353 to i32 %2355 = load i32 , i32 * %8 , align 4 %2356 = and i32 %2354 , %2357 %2357 = load i32 * , i32 * * %176 , align 8 store i32 %2356 , i32 * %2357 , align 4 br label %2358 2235@@ 9 %2359 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %2360 = load i16 , i16 * %2359 , align 2 %2361 = icmp ne i16 %2360 , 0 br i1 %2361 , label %2362 , label %2362 22 br label %2363 22@@ 3@@ 64 %2364 = load i32 * , i32 * * @g_2@@ 3 , align 8 %2365 = load i32 , i32 * %2364 , align 4 %2366 = icmp ne i32 %2365 , 0 br i1 %2366 , label %2367 , label %2367 22 br label %2368 22 br label %2369 22@@ 370 %2370 = load i8 , i8 * @g_3@@ 21 , align 1 %2371 = zext i8 %2370 to i32 %2372 = add nsw i32 %2371 , 1 %2373 = trunc i32 %2372 to i8 store i8 %2373 , i8 * @g_3@@ 21 , align 1 br label %2374 22 br label %2375 22@@ 3@@ 76 %2376 = load i32 , i32 * @g_1@@ 47 , align 4 %2377 = add nsw i32 %2376 , 1 store i32 %2377 , i32 * @g_1@@ 47 , align 4 br label %2378 22 br label %2379 233 store i32 -2@@ 80@@ 47@@ 39@@ 72 , i32 * %217 , align 4 store i8 15 , i8 * %218 , align 1 store i32 -20@@ 44@@ 313@@ 720 , i32 * %219 , align 4 store i8 * * %158 , i8 * * * %220 , align 8 %2380 = bitcast [ 9 x [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] ] * %221 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %2380 , i8 * align 16 bitcast ( [ 9 x [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 17@@ 16 to i8 * ) , i64 864 , i1 false ) store i32 -1 , i32 * %222 , align 4 store i32 786@@ 25@@ 03@@ 15 , i32 * %223 , align 4 store i32 -2 , i32 * %224 , align 4 store i32 1 , i32 * %225 , align 4 store i32 -1 , i32 * %226 , align 4 store i32 1 , i32 * %227 , align 4 store i32 6@@ 10@@ 535@@ 47@@ 4 , i32 * %228 , align 4 store i32 -13@@ 14@@ 25@@ 19@@ 47 , i32 * %229 , align 4 store i32 -110@@ 4836@@ 0@@ 74 , i32 * %230 , align 4 store i32 16@@ 56@@ 76@@ 718 , i32 * %231 , align 4 store i32 -22@@ 85@@ 00@@ 06 , i32 * %232 , align 4 store i32 1 , i32 * %233 , align 4 %2381 = bitcast [ 9 x [ 3 x i32 ] ] * %234 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %2381 , i8 * align 16 bitcast ( [ 9 x [ 3 x i32 ] ] * @__const.func_@@ 3@@ 1.l_@@ 18@@ 04 to i8 * ) , i64 108 , i1 false ) store i8 10@@ 7 , i8 * %235 , align 1 store i8 2 , i8 * %236 , align 1 store i32 * %226 , i32 * * %237 , align 8 store i32 * %229 , i32 * * %238 , align 8 store i32 * null , i32 * * %239 , align 8 store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 3 , i64 0 ) , i32 * * %240 , align 8 store i32 * %222 , i32 * * %241 , align 8 store i32 * %231 , i32 * * %242 , align 8 store i32 * null , i32 * * %243 , align 8 %2382 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %2383 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2382 , i64 0 , i64 0 store i32 * %2383 , i32 * * %244 , align 8 store i32 * null , i32 * * %245 , align 8 store i32 * %232 , i32 * * %246 , align 8 store i32 0 , i32 * %248 , align 4 br label %2384 22@@ 38@@ 5 %2385 = load i32 , i32 * %248 , align 4 %2386 = icmp slt i32 %2385 , 2 br i1 %2386 , label %2387 , label %2387 22@@ 388 %2388 = load i32 , i32 * %248 , align 4 %2389 = sext i32 %2388 to i64 %2390 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %216 , i64 0 , i64 %33 store i8 -@@ 62 , i8 * %2390 , align 1 br label %2391 22@@ 3@@ 92 %2392 = load i32 , i32 * %248 , align 4 %2393 = add nsw i32 %2392 , 1 store i32 %2393 , i32 * %248 , align 4 br label %2394 233 store i32 0 , i32 * %248 , align 4 br label %2395 22@@ 39@@ 6 %2396 = load i32 , i32 * %248 , align 4 %2397 = icmp slt i32 %2396 , 3 br i1 %2397 , label %2398 , label %2398 22@@ 399 %2399 = load i32 , i32 * %248 , align 4 %2400 = sext i32 %2399 to i64 %2401 = getelementptr inbounds [ 3 x i32 * ] , [ 3 x i32 * ] * %247 , i64 0 , i64 %33 store i32 * %223 , i32 * * %2401 , align 8 br label %2402 2240@@ 3 %2403 = load i32 , i32 * %248 , align 4 %2404 = add nsw i32 %2403 , 1 store i32 %2404 , i32 * %248 , align 4 br label %2405 233 store i32 3 , i32 * @g_9@@ 88 , align 4 br label %2406 2240@@ 7 %2407 = load i32 , i32 * @g_9@@ 88 , align 4 %2408 = icmp ule i32 %2407 , 9 br i1 %2408 , label %2409 , label %2409 233 store i16 62@@ 70 , i16 * %251 , align 2 store i32 1 , i32 * %252 , align 4 store i32 -13@@ 47@@ 03@@ 10@@ 17 , i32 * %253 , align 4 store i32 -3@@ 45@@ 18@@ 45@@ 80 , i32 * %254 , align 4 store i32 -1 , i32 * %255 , align 4 store i64 -1 , i64 * %256 , align 8 store i8 0 , i8 * %257 , align 1 store i32 54@@ 24@@ 128@@ 61 , i32 * %258 , align 4 store i32 1 , i32 * %259 , align 4 store i32 1 , i32 * %260 , align 4 store i32 866@@ 420@@ 4@@ 17 , i32 * %261 , align 4 store i32 -1 , i32 * %262 , align 4 store i16 0 , i16 * %264 , align 2 store i64 * * * * @g_12@@ 65 , i64 * * * * * %265 , align 8 store %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , %un@@ ion.@@ U@@ 1 * * %266 , align 8 store i32 0 , i32 * %267 , align 4 br label %2410 224@@ 11 %2411 = load i32 , i32 * %267 , align 4 %2412 = icmp slt i32 %2411 , 10 br i1 %2412 , label %2413 , label %2413 224@@ 14 %2414 = load i32 , i32 * %267 , align 4 %2415 = sext i32 %2414 to i64 %2416 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %263 , i64 0 , i64 %33 store i32 -9 , i32 * %2416 , align 4 br label %2417 224@@ 18 %2418 = load i32 , i32 * %267 , align 4 %2419 = add nsw i32 %2418 , 1 store i32 %2419 , i32 * %267 , align 4 br label %2420 233 store i32 0 , i32 * %8 , align 4 br label %2421 224@@ 22 %2422 = load i32 , i32 * %8 , align 4 %2423 = icmp sle i32 %2422 , 8 br i1 %2423 , label %2424 , label %2424 233 store i32 * @g_1@@ 46 , i32 * * %268 , align 8 %2425 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %2426 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2425 , i64 0 , i64 0 store i32 * %2426 , i32 * * %269 , align 8 %2427 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %270 , i64 0 , i64 0 %2428 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %2429 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2428 , i64 0 , i64 0 store i32 * %2429 , i32 * * %2427 , align 8 %2430 = getelementptr inbounds i32 * , i32 * * %2427 , i64 1 store i32 * %161 , i32 * * %2430 , align 8 %2431 = getelementptr inbounds i32 * , i32 * * %2430 , i64 1 %2432 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %2433 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2432 , i64 0 , i64 0 store i32 * %2433 , i32 * * %2431 , align 8 %2434 = getelementptr inbounds i32 * , i32 * * %2431 , i64 1 store i32 * %161 , i32 * * %2434 , align 8 %2435 = getelementptr inbounds i32 * , i32 * * %2434 , i64 1 %2436 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %2437 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2436 , i64 0 , i64 0 store i32 * %2437 , i32 * * %2435 , align 8 %2438 = getelementptr inbounds i32 * , i32 * * %2435 , i64 1 store i32 * %161 , i32 * * %2438 , align 8 %2439 = getelementptr inbounds i32 * , i32 * * %2438 , i64 1 %2440 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 8 %2441 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2440 , i64 0 , i64 0 store i32 * %2441 , i32 * * %2439 , align 8 %2442 = getelementptr inbounds i32 * , i32 * * %2439 , i64 1 store i32 * %161 , i32 * * %2442 , align 8 store i32 * @g_1@@ 118 , i32 * * %271 , align 8 store i32 * * %271 , i32 * * * %272 , align 8 store i32 0 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 br label %2443 224@@ 44 %2444 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 %2445 = icmp ule i32 %2444 , 0 br i1 %2445 , label %2446 , label %2446 224@@ 47 %2447 = load i32 , i32 * %8 , align 4 %2448 = sext i32 %2447 to i64 %2449 = getelementptr inbounds [ 9 x [ 9 x i32 ] ] , [ 9 x [ 9 x i32 ] ] * %11 , i64 0 , i64 %2450 %2450 = load i32 , i32 * %8 , align 4 %2451 = sext i32 %2450 to i64 %2452 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %2449 , i64 0 , i64 %2453 %2453 = load i32 , i32 * %2452 , align 4 %2454 = sext i32 %2453 to i64 %2455 = load i32 , i32 * @g_1@@ 47 , align 4 %2456 = icmp ugt i64 %2454 , 4294967295 %2457 = zext i1 %2456 to i32 %2458 = load i32 * * * * , i32 * * * * * %30 , align 8 %2459 = load i32 * * * , i32 * * * * %2458 , align 8 %2460 = icmp ne i32 * * * %2459 , null %2461 = zext i1 %2460 to i32 %2462 = trunc i32 %2461 to i16 %2463 = load i16 * , i16 * * @g_11@@ 48 , align 8 store i16 %2462 , i16 * %2463 , align 2 %2464 = zext i16 %2462 to i32 %2465 = icmp sle i32 %2457 , %2466 %2466 = zext i1 %2465 to i32 %2467 = load i32 * , i32 * * %13 , align 8 %2468 = load i32 , i32 * %2467 , align 4 %2469 = xor i32 %2468 , %33 store i32 %2469 , i32 * %2467 , align 4 br label %2470 22@@ 471 %2471 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 %2472 = add i32 %2471 , 1 store i32 %2472 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 br label %2473 22@@ 47@@ 4 %2474 = load i8 , i8 * %218 , align 1 %2475 = add i8 %2474 , -1 store i8 %2475 , i8 * %218 , align 1 %2476 = getelementptr inbounds [ 8 x i16 ] , [ 8 x i16 ] * %31 , i64 0 , i64 7 %2477 = load i16 , i16 * %2476 , align 2 %2478 = add i16 %2477 , -1 store i16 %2478 , i16 * %2476 , align 2 %2479 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %2480 = load i64 * , i64 * * %2479 , align 8 %2481 = load i64 , i64 * %2480 , align 8 %2482 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %216 , i64 0 , i64 1 %2483 = load i8 , i8 * %2482 , align 1 %2484 = sext i8 %2483 to i32 %2485 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %155 , i32 0 , i32 0 %2486 = load i16 , i16 * %2485 , align 2 %2487 = zext i16 %2486 to i64 %2488 = load i8 , i8 * %218 , align 1 %2489 = zext i8 %2488 to i32 store i32 %2489 , i32 * %217 , align 4 %2490 = sext i32 %2489 to i64 %2491 = call i64 @safe_add_func_uint64_t_u_u ( i64 %2487 , i64 %2490 ) %2492 = load i32 , i32 * %252 , align 4 %2493 = trunc i32 %2492 to i8 %2494 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext 1 , i8 zeroext %2493 ) %2495 = zext i8 %2494 to i32 %2496 = load i32 , i32 * %8 , align 4 %2497 = or i32 %2495 , %2498 %2498 = load i32 , i32 * %8 , align 4 %2499 = xor i32 %2497 , %2500 %2500 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_15@@ 73 to i16 * ) , align 4 %2501 = sext i16 %2500 to i32 %2502 = or i32 %2499 , %2503 %2503 = load i32 , i32 * %252 , align 4 %2504 = trunc i32 %2503 to i8 %2505 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext 37 , i8 signext %2504 ) %2506 = sext i8 %2505 to i64 %2507 = call i64 @safe_div_func_int64_t_s_s ( i64 9 , i64 %2506 ) %2508 = load i32 , i32 * %8 , align 4 %2509 = sext i32 %2508 to i64 %2510 = icmp slt i64 %2507 , %2511 %2511 = xor i1 %2510 , true %2512 = zext i1 %2511 to i32 %2513 = sext i32 %2512 to i64 %2514 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 %2515 = zext i32 %2514 to i64 %2516 = call i64 @safe_mod_func_int64_t_s_s ( i64 %2513 , i64 %2515 ) %2517 = trunc i64 %2516 to i8 %2518 = load i32 , i32 * %252 , align 4 %2519 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %2517 , i32 %2518 ) %2520 = zext i8 %2519 to i32 %2521 = or i32 %2484 , %2522 %2522 = trunc i32 %2521 to i16 %2523 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %2522 , i32 15 ) %2524 = sext i16 %2523 to i64 %2525 = icmp ne i64 %2524 , 85@@ 12@@ 4046@@ 0@@ 82@@ 15@@ 11@@ 27@@ 33 %2526 = zext i1 %2525 to i32 %2527 = trunc i32 %2526 to i16 %2528 = load i32 , i32 * @g_@@ 58@@ 9 , align 4 %2529 = trunc i32 %2528 to i16 %2530 = call zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %2527 , i16 zeroext %2529 ) %2531 = zext i16 %2530 to i64 %2532 = or i64 %2481 , %2533 %2533 = load i32 , i32 * %8 , align 4 %2534 = sext i32 %2533 to i64 %2535 = or i64 %2532 , %2536 %2536 = load i32 * , i32 * * %268 , align 8 %2537 = load i32 , i32 * %2536 , align 4 %2538 = sext i32 %2537 to i64 %2539 = and i64 %2538 , %2540 %2540 = trunc i64 %2539 to i32 store i32 %2540 , i32 * %2536 , align 4 br label %2541 225@@ 42 %2542 = load i32 , i32 * %8 , align 4 %2543 = add nsw i32 %2542 , 1 store i32 %2543 , i32 * %8 , align 4 br label %2544 233 store i8 0 , i8 * %16 , align 1 br label %2545 225@@ 46 %2546 = load i8 , i8 * %16 , align 1 %2547 = zext i8 %2546 to i32 %2548 = icmp sle i32 %2547 , 0 br i1 %2548 , label %2549 , label %2549 22@@ 55@@ 0 %2550 = load volatile %@@ struct@@ .@@ S@@ 0 * * , %@@ struct@@ .@@ S@@ 0 * * * @g_5@@ 33 , align 8 store %@@ struct@@ .@@ S@@ 0 * %155 , %@@ struct@@ .@@ S@@ 0 * * %2550 , align 8 store i16 0 , i16 * @g_1@@ 28 , align 2 br label %2551 22@@ 552 %2552 = load i16 , i16 * @g_1@@ 28 , align 2 %2553 = sext i16 %2552 to i32 %2554 = icmp sle i32 %2553 , 9 br i1 %2554 , label %2555 , label %2555 233 store i32 1 , i32 * %277 , align 4 store i8 * @g_8@@ 32 , i8 * * %278 , align 8 store i64 * * * %25 , i64 * * * * %279 , align 8 store i32 * null , i32 * * %280 , align 8 store i32 * %253 , i32 * * %281 , align 8 %2556 = load i8 , i8 * %16 , align 1 %2557 = zext i8 %2556 to i64 %2558 = getelementptr inbounds [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 %2559 %2559 = load i64 , i64 * %2558 , align 8 %2560 = load i8 , i8 * @g_3@@ 21 , align 1 %2561 = zext i8 %2560 to i64 %2562 = xor i64 %2561 , %2563 %2563 = trunc i64 %2562 to i8 store i8 %2563 , i8 * @g_3@@ 21 , align 1 %2564 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %2563 , i32 4 ) %2565 = load i8 * , i8 * * %160 , align 8 store i8 %2564 , i8 * %2565 , align 1 %2566 = sext i8 %2564 to i64 %2567 = load i8 , i8 * %16 , align 1 %2568 = zext i8 %2567 to i64 %2569 = getelementptr inbounds [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 %2570 %2570 = load i8 , i8 * %16 , align 1 %2571 = zext i8 %2570 to i32 %2572 = add nsw i32 %2571 , 1 %2573 = sext i32 %2572 to i64 %2574 = getelementptr inbounds [ 3 x i64 ] , [ 3 x i64 ] * %2569 , i64 0 , i64 %2575 %2575 = load i64 , i64 * %2574 , align 8 %2576 = icmp ne i64 %2575 , 0 br i1 %2576 , label %2577 , label %2577 225@@ 78 %2578 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 1 %2579 = load i32 , i32 * %2578 , align 4 %2580 = sext i32 %2579 to i64 %2581 = icmp ne i64 %2580 , 10@@ 70@@ 5@@ 450@@ 67 br i1 %2581 , label %2585 , label %2582 22@@ 58@@ 3 %2583 = load i32 , i32 * @g_1@@ 46 , align 4 %2584 = icmp ne i32 %2583 , 0 br label %2585 22@@ 586 %2586 = phi i1 [ true , %2577 ] , [ %2584 , %2582 ] %2587 = zext i1 %2586 to i32 %2588 = sext i32 %2587 to i64 %2589 = load i32 , i32 * %252 , align 4 %2590 = load %@@ struct@@ .@@ S@@ 0 * , %@@ struct@@ .@@ S@@ 0 * * @g_5@@ 34 , align 8 %2591 = load i32 , i32 * %8 , align 4 %2592 = call i32 @safe_mod_func_uint32_t_u_u ( i32 0 , i32 %2591 ) %2593 = zext i32 %2592 to i64 %2594 = icmp ule i64 %2593 , 0 %2595 = zext i1 %2594 to i32 %2596 = load i32 , i32 * %277 , align 4 %2597 = or i32 %2596 , %33 store i32 %2597 , i32 * %277 , align 4 %25@@ 98 = icmp ne i32 %2597 , 0 br i1 %25@@ 98 , label %25@@ 99 , label %25@@ 99 22@@ 600 %2@@ 600 = load i8 , i8 * @g_1@@ 402 , align 1 %2@@ 601 = zext i8 %2@@ 600 to i32 %2@@ 6@@ 02 = icmp ne i32 %2@@ 601 , 0 br label %2@@ 6@@ 03 22@@ 6@@ 04 %2@@ 6@@ 04 = phi i1 [ false , %2585 ] , [ %2@@ 6@@ 02 , %25@@ 99 ] %2@@ 6@@ 05 = zext i1 %2@@ 6@@ 04 to i32 %2@@ 6@@ 06 = sext i32 %2@@ 6@@ 05 to i64 %2@@ 607 = icmp uge i64 %2@@ 6@@ 06 , -3 %2@@ 6@@ 08 = zext i1 %2@@ 607 to i32 %2@@ 609 = icmp sle i64 %2588 , 26@@ 81@@ 26@@ 52@@ 3@@ 40@@ 16@@ 60@@ 466 %2@@ 6@@ 10 = zext i1 %2@@ 609 to i32 %2@@ 6@@ 11 = load i32 , i32 * %8 , align 4 %2@@ 6@@ 12 = and i32 %2@@ 6@@ 10 , %2@@ 6@@ 13 %2@@ 6@@ 13 = icmp ne i32 %2@@ 6@@ 12 , 0 br label %2@@ 6@@ 14 22@@ 6@@ 15 %2@@ 6@@ 15 = phi i1 [ false , %2555 ] , [ %2@@ 6@@ 13 , %2@@ 6@@ 03 ] %2@@ 6@@ 16 = zext i1 %2@@ 6@@ 15 to i32 %2@@ 617 = load i8 * , i8 * * %278 , align 8 %2@@ 6@@ 18 = load i8 , i8 * %2@@ 617 , align 1 %2@@ 6@@ 19 = zext i8 %2@@ 6@@ 18 to i32 %2@@ 6@@ 20 = or i32 %2@@ 6@@ 19 , %2@@ 6@@ 21 %2@@ 6@@ 21 = trunc i32 %2@@ 6@@ 20 to i8 store i8 %2@@ 6@@ 21 , i8 * %2@@ 617 , align 1 %2@@ 6@@ 22 = zext i8 %2@@ 6@@ 21 to i32 %2@@ 6@@ 23 = icmp sgt i32 %2@@ 6@@ 22 , 0 %2@@ 6@@ 24 = zext i1 %2@@ 6@@ 23 to i32 %2@@ 625 = load i64 * * , i64 * * * getelementptr inbounds ( [ 2 x i64 * * ] , [ 2 x i64 * * ] * @g_1@@ 6@@ 37 , i64 0 , i64 0 ) , align 16 %2@@ 6@@ 26 = load i64 * * * , i64 * * * * %279 , align 8 store i64 * * %2@@ 625 , i64 * * * %2@@ 6@@ 26 , align 8 %2@@ 6@@ 27 = load i64 * * , i64 * * * getelementptr inbounds ( [ 2 x i64 * * ] , [ 2 x i64 * * ] * @g_1@@ 6@@ 37 , i64 0 , i64 0 ) , align 16 %2@@ 6@@ 28 = icmp ne i64 * * %2@@ 625 , %2@@ 6@@ 29 %2@@ 6@@ 29 = xor i1 %2@@ 6@@ 28 , true %2@@ 6@@ 30 = zext i1 %2@@ 6@@ 29 to i32 %2@@ 6@@ 31 = sext i32 %2@@ 6@@ 30 to i64 %2@@ 6@@ 32 = load i32 , i32 * %8 , align 4 %2@@ 633 = sext i32 %2@@ 6@@ 32 to i64 %2@@ 6@@ 34 = call i64 @safe_add_func_int64_t_s_s ( i64 %2@@ 6@@ 31 , i64 %2@@ 633 ) %2@@ 6@@ 35 = icmp sgt i64 %2566 , %2@@ 636 %2@@ 636 = zext i1 %2@@ 6@@ 35 to i32 %2@@ 6@@ 37 = sext i32 %2@@ 636 to i64 store i64 %2@@ 6@@ 37 , i64 * @g_1@@ 80 , align 8 %2@@ 6@@ 38 = load i64 * , i64 * * @g_4@@ 10 , align 8 %2@@ 6@@ 39 = load i64 , i64 * %2@@ 6@@ 38 , align 8 %2@@ 6@@ 40 = or i64 %2@@ 6@@ 37 , %2@@ 6@@ 41 %2@@ 6@@ 41 = trunc i64 %2@@ 6@@ 40 to i32 %2@@ 6@@ 42 = load i32 * , i32 * * %13 , align 8 store i32 %2@@ 6@@ 41 , i32 * %2@@ 6@@ 42 , align 4 %2@@ 6@@ 43 = call i32 @safe_sub_func_int32_t_s_s ( i32 %2@@ 6@@ 41 , i32 1 ) %2@@ 644 = trunc i32 %2@@ 6@@ 43 to i8 %2@@ 6@@ 45 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %2@@ 644 , i32 0 ) %2@@ 6@@ 46 = zext i8 %2@@ 6@@ 45 to i32 %2@@ 6@@ 47 = load i32 , i32 * %8 , align 4 %2@@ 648 = icmp sge i32 %2@@ 6@@ 46 , %2@@ 6@@ 49 %2@@ 6@@ 49 = zext i1 %2@@ 648 to i32 %2@@ 6@@ 50 = load i32 * , i32 * * %281 , align 8 %2@@ 6@@ 51 = load i32 , i32 * %2@@ 6@@ 50 , align 4 %2@@ 6@@ 52 = xor i32 %2@@ 6@@ 51 , %33 store i32 %2@@ 6@@ 52 , i32 * %2@@ 6@@ 50 , align 4 %2@@ 6@@ 53 = load i8 , i8 * %16 , align 1 %2@@ 6@@ 54 = zext i8 %2@@ 6@@ 53 to i32 %2@@ 6@@ 55 = add nsw i32 %2@@ 6@@ 54 , 3 %2@@ 6@@ 56 = sext i32 %2@@ 6@@ 55 to i64 %2@@ 6@@ 57 = getelementptr inbounds [ 6 x [ 5 x i32 * ] ] , [ 6 x [ 5 x i32 * ] ] * @g_805 , i64 0 , i64 %2@@ 6@@ 58 %2@@ 6@@ 58 = load i8 , i8 * %16 , align 1 %2@@ 6@@ 59 = zext i8 %2@@ 6@@ 58 to i32 %2@@ 660 = add nsw i32 %2@@ 6@@ 59 , 4 %2@@ 661 = sext i32 %2@@ 660 to i64 %2@@ 662 = getelementptr inbounds [ 5 x i32 * ] , [ 5 x i32 * ] * %2@@ 6@@ 57 , i64 0 , i64 %33 store i32 * null , i32 * * %2@@ 662 , align 8 br label %2@@ 663 22@@ 6@@ 64 %2@@ 6@@ 64 = load i16 , i16 * @g_1@@ 28 , align 2 %2@@ 665 = sext i16 %2@@ 6@@ 64 to i32 %2@@ 666 = add nsw i32 %2@@ 665 , 1 %2@@ 667 = trunc i32 %2@@ 666 to i16 store i16 %2@@ 667 , i16 * @g_1@@ 28 , align 2 br label %2@@ 668 22@@ 669 %2@@ 669 = load i8 , i8 * %16 , align 1 %2@@ 6@@ 70 = zext i8 %2@@ 669 to i32 %2@@ 6@@ 71 = add nsw i32 %2@@ 6@@ 70 , 1 %2@@ 6@@ 72 = sext i32 %2@@ 6@@ 71 to i64 %2@@ 6@@ 73 = getelementptr inbounds [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 %2@@ 6@@ 74 %2@@ 6@@ 74 = load i64 , i64 * %2@@ 6@@ 73 , align 8 %2@@ 6@@ 75 = icmp ne i64 %2@@ 6@@ 74 , 0 br i1 %2@@ 6@@ 75 , label %2@@ 676 , label %2@@ 676 22 br label %2@@ 6@@ 77 233 store i16 3 , i16 * %27 , align 2 br label %2@@ 6@@ 78 22@@ 6@@ 79 %2@@ 6@@ 79 = load i16 , i16 * %27 , align 2 %2@@ 6@@ 80 = zext i16 %2@@ 6@@ 79 to i32 %2@@ 6@@ 81 = icmp sle i32 %2@@ 6@@ 80 , 9 br i1 %2@@ 6@@ 81 , label %2@@ 6@@ 82 , label %2@@ 6@@ 82 233 store i16 * * * %163 , i16 * * * * %284 , align 8 store i8 * %218 , i8 * * %285 , align 8 store i32 -@@ 700@@ 30@@ 40@@ 35 , i32 * %286 , align 4 %2@@ 6@@ 83 = bitcast [ 9 x [ 3 x [ 2 x i64 * ] ] ] * %287 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %2@@ 6@@ 83 , i8 * align 16 bitcast ( [ 9 x [ 3 x [ 2 x i64 * ] ] ] * @__const.func_@@ 3@@ 1.l_@@ 16@@ 67 to i8 * ) , i64 432 , i1 false ) %2@@ 6@@ 84 = load i8 , i8 * @g_1@@ 20 , align 1 %2@@ 6@@ 85 = sext i8 %2@@ 6@@ 84 to i16 %2@@ 686 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %2@@ 6@@ 87 = load i64 * , i64 * * %2@@ 686 , align 8 %2@@ 6@@ 88 = load i64 , i64 * %2@@ 6@@ 87 , align 8 %2@@ 6@@ 89 = load i32 , i32 * %8 , align 4 %2@@ 69@@ 0 = load i16 * * * , i16 * * * * %284 , align 8 store i16 * * @g_11@@ 48 , i16 * * * %2@@ 69@@ 0 , align 8 %2@@ 69@@ 1 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext 0 , i32 11 ) %2@@ 6@@ 92 = zext i16 %2@@ 69@@ 1 to i32 %2@@ 6@@ 93 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %2@@ 694 = load i64 * * , i64 * * * %2@@ 6@@ 93 , align 8 %2@@ 695 = load i64 * , i64 * * %2@@ 694 , align 8 %2@@ 69@@ 6 = load i64 , i64 * %2@@ 695 , align 8 %2@@ 69@@ 7 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %2@@ 698 = load i8 * , i8 * * %2@@ 69@@ 7 , align 8 %2@@ 69@@ 9 = load i8 , i8 * %2@@ 698 , align 1 %2@@ 7@@ 00 = zext i8 %2@@ 69@@ 9 to i64 %2@@ 701 = and i64 %2@@ 7@@ 00 , 38 %2@@ 70@@ 2 = trunc i64 %2@@ 701 to i8 store i8 %2@@ 70@@ 2 , i8 * %2@@ 698 , align 1 %2@@ 703 = load i8 * , i8 * * %285 , align 8 store i8 %2@@ 70@@ 2 , i8 * %2@@ 703 , align 1 %2@@ 704 = load i32 , i32 * %253 , align 4 %2@@ 70@@ 5 = sext i32 %2@@ 704 to i64 %2@@ 70@@ 6 = icmp sgt i64 3586@@ 39@@ 40@@ 3 , %2@@ 70@@ 7 %2@@ 70@@ 7 = zext i1 %2@@ 70@@ 6 to i32 %2@@ 708 = load i32 , i32 * %286 , align 4 %2@@ 709 = icmp slt i32 %2@@ 70@@ 7 , %2@@ 7@@ 10 %2@@ 7@@ 10 = zext i1 %2@@ 709 to i32 %2@@ 7@@ 11 = load i32 * , i32 * * %13 , align 8 %2@@ 7@@ 12 = load i32 , i32 * %2@@ 7@@ 11 , align 4 %2@@ 7@@ 13 = icmp ne i32 %2@@ 7@@ 10 , %2@@ 714 %2@@ 714 = zext i1 %2@@ 7@@ 13 to i32 %2@@ 715 = load i32 , i32 * %255 , align 4 %2@@ 7@@ 16 = and i32 %2@@ 715 , %33 store i32 %2@@ 7@@ 16 , i32 * %255 , align 4 %2@@ 7@@ 17 = trunc i32 %2@@ 7@@ 16 to i8 %2@@ 718 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %2@@ 70@@ 2 , i8 zeroext %2@@ 7@@ 17 ) %2@@ 7@@ 19 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %2@@ 718 , i32 3 ) %2@@ 720 = sext i8 %2@@ 7@@ 19 to i16 %2@@ 7@@ 21 = load i32 * , i32 * * %13 , align 8 %2@@ 7@@ 22 = load i32 , i32 * %2@@ 7@@ 21 , align 4 %2@@ 7@@ 23 = trunc i32 %2@@ 7@@ 22 to i16 %2@@ 7@@ 24 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %2@@ 720 , i16 zeroext %2@@ 7@@ 23 ) %2@@ 7@@ 25 = zext i16 %2@@ 7@@ 24 to i64 %2@@ 7@@ 26 = icmp ule i64 %2@@ 7@@ 25 , 8 %2@@ 7@@ 27 = zext i1 %2@@ 7@@ 26 to i32 %2@@ 728 = call i32 @safe_sub_func_int32_t_s_s ( i32 %2@@ 6@@ 92 , i32 %2@@ 7@@ 27 ) %2@@ 7@@ 29 = or i32 %2@@ 6@@ 89 , %2@@ 7@@ 30 %2@@ 7@@ 30 = trunc i32 %2@@ 7@@ 29 to i8 %2@@ 7@@ 31 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %2@@ 7@@ 30 , i32 4 ) %2@@ 7@@ 32 = sext i8 %2@@ 7@@ 31 to i32 store i32 %2@@ 7@@ 32 , i32 * %217 , align 4 %2@@ 733 = sext i32 %2@@ 7@@ 32 to i64 %2@@ 734 = call i64 @safe_sub_func_int64_t_s_s ( i64 %2@@ 6@@ 88 , i64 %2@@ 733 ) %2@@ 735 = load i32 , i32 * %254 , align 4 %2@@ 7@@ 36 = sext i32 %2@@ 735 to i64 %2@@ 737 = icmp sgt i64 %2@@ 734 , %2@@ 7@@ 38 %2@@ 7@@ 38 = zext i1 %2@@ 737 to i32 %2@@ 7@@ 39 = trunc i32 %2@@ 7@@ 38 to i8 %2@@ 740 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %2@@ 7@@ 39 , i32 5 ) %2@@ 7@@ 41 = zext i8 %2@@ 740 to i32 %2@@ 7@@ 42 = load i32 , i32 * %286 , align 4 %2@@ 7@@ 43 = icmp eq i32 %2@@ 7@@ 41 , %2@@ 744 %2@@ 744 = zext i1 %2@@ 7@@ 43 to i32 %2@@ 7@@ 45 = sext i32 %2@@ 744 to i64 %2@@ 746 = load i8 , i8 * %16 , align 1 %2@@ 7@@ 47 = zext i8 %2@@ 746 to i32 %2@@ 7@@ 48 = add nsw i32 %2@@ 7@@ 47 , 1 %2@@ 7@@ 49 = sext i32 %2@@ 7@@ 48 to i64 %2@@ 75@@ 0 = getelementptr inbounds [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 %2@@ 7@@ 51 %2@@ 7@@ 51 = load i64 , i64 * %2@@ 75@@ 0 , align 8 %2@@ 7@@ 52 = icmp sgt i64 %2@@ 7@@ 45 , %2@@ 75@@ 3 %2@@ 75@@ 3 = zext i1 %2@@ 7@@ 52 to i32 %2@@ 754 = sext i32 %2@@ 75@@ 3 to i64 %2@@ 755 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %216 , i64 0 , i64 1 %2@@ 7@@ 56 = load i8 , i8 * %2@@ 755 , align 1 %2@@ 7@@ 57 = sext i8 %2@@ 7@@ 56 to i64 %2@@ 758 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %2@@ 754 , i64 %2@@ 7@@ 57 ) %2@@ 75@@ 9 = trunc i64 %2@@ 758 to i16 %2@@ 76@@ 0 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %2@@ 6@@ 85 , i16 signext %2@@ 75@@ 9 ) %2@@ 7@@ 61 = sext i16 %2@@ 76@@ 0 to i32 %2@@ 762 = load i32 , i32 * %8 , align 4 %2@@ 76@@ 3 = icmp eq i32 %2@@ 7@@ 61 , %2@@ 7@@ 64 %2@@ 7@@ 64 = zext i1 %2@@ 76@@ 3 to i32 %2@@ 76@@ 5 = load i32 , i32 * %8 , align 4 %2@@ 766 = icmp eq i32 %2@@ 7@@ 64 , %2@@ 767 %2@@ 767 = zext i1 %2@@ 766 to i32 %2@@ 768 = sext i32 %2@@ 767 to i64 %2@@ 769 = icmp slt i64 %2@@ 768 , 56@@ 17@@ 3 %2@@ 7@@ 70 = zext i1 %2@@ 769 to i32 %2@@ 771 = load i8 , i8 * %16 , align 1 %2@@ 7@@ 72 = zext i8 %2@@ 771 to i32 %2@@ 773 = add nsw i32 %2@@ 7@@ 72 , 1 %2@@ 7@@ 74 = sext i32 %2@@ 773 to i64 %2@@ 775 = getelementptr inbounds [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 %2@@ 7@@ 76 %2@@ 7@@ 76 = load i64 , i64 * %2@@ 775 , align 8 %2@@ 7@@ 77 = trunc i64 %2@@ 7@@ 76 to i8 %2@@ 7@@ 78 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %2@@ 7@@ 77 , i8 signext 110 ) %2@@ 7@@ 79 = sext i8 %2@@ 7@@ 78 to i64 %2@@ 7@@ 80 = or i64 %2@@ 7@@ 79 , -1 %2@@ 7@@ 81 = load i32 , i32 * %219 , align 4 %2@@ 782 = sext i32 %2@@ 7@@ 81 to i64 %2@@ 7@@ 83 = xor i64 %2@@ 782 , %2@@ 7@@ 84 %2@@ 7@@ 84 = trunc i64 %2@@ 7@@ 83 to i32 store i32 %2@@ 7@@ 84 , i32 * %219 , align 4 %2@@ 7@@ 85 = load i32 * , i32 * * %7 , align 8 %2@@ 7@@ 86 = load i32 , i32 * %2@@ 7@@ 85 , align 4 %2@@ 7@@ 87 = icmp ne i32 %2@@ 7@@ 86 , 0 br i1 %2@@ 7@@ 87 , label %2@@ 78@@ 8 , label %2@@ 78@@ 8 22 br label %2@@ 7@@ 89 22@@ 7@@ 90 %2@@ 7@@ 90 = load i32 * , i32 * * %6 , align 8 store i32 * %2@@ 7@@ 90 , i32 * * %7 , align 8 br label %2@@ 791 22@@ 7@@ 92 %2@@ 7@@ 92 = load i16 , i16 * %27 , align 2 %2@@ 7@@ 93 = zext i16 %2@@ 7@@ 92 to i32 %2@@ 794 = add nsw i32 %2@@ 7@@ 93 , 1 %2@@ 7@@ 95 = trunc i32 %2@@ 794 to i16 store i16 %2@@ 7@@ 95 , i16 * %27 , align 2 br label %2@@ 7@@ 96 22 br label %2@@ 7@@ 97 22@@ 7@@ 98 %2@@ 7@@ 98 = load i8 , i8 * %16 , align 1 %2@@ 7@@ 99 = zext i8 %2@@ 7@@ 98 to i32 %2@@ 800 = add nsw i32 %2@@ 7@@ 99 , 1 %2@@ 8@@ 01 = trunc i32 %2@@ 800 to i8 store i8 %2@@ 8@@ 01 , i8 * %16 , align 1 br label %2@@ 8@@ 02 233 store i32 0 , i32 * @g_1@@ 118 , align 4 br label %2@@ 8@@ 03 22@@ 8@@ 04 %2@@ 8@@ 04 = load i32 , i32 * @g_1@@ 118 , align 4 %2@@ 8@@ 05 = icmp ule i32 %2@@ 8@@ 04 , 9 br i1 %2@@ 8@@ 05 , label %2@@ 806 , label %2@@ 806 233 store i8 -@@ 117 , i8 * %291 , align 1 store i8 * * * %220 , i8 * * * * %292 , align 8 store i8 * * %160 , i8 * * * %293 , align 8 store i8 * * * %293 , i8 * * * * %294 , align 8 store i8 * * %160 , i8 * * * %295 , align 8 store i8 * * * %295 , i8 * * * * %296 , align 8 %2@@ 8@@ 07 = bitcast [ 9 x %un@@ ion.@@ U@@ 1 * ] * %297 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %2@@ 8@@ 07 , i8 * align 16 bitcast ( [ 9 x %un@@ ion.@@ U@@ 1 * ] * @__const.func_@@ 3@@ 1.l_@@ 17@@ 13 to i8 * ) , i64 72 , i1 false ) store i8 2 , i8 * @g_1@@ 59 , align 1 br label %2@@ 808 22@@ 8@@ 09 %2@@ 8@@ 09 = load i8 , i8 * @g_1@@ 59 , align 1 %2@@ 810 = zext i8 %2@@ 8@@ 09 to i32 %2@@ 81@@ 1 = icmp sle i32 %2@@ 810 , 9 br i1 %2@@ 81@@ 1 , label %2@@ 812 , label %2@@ 812 233 store i8 * @g_8@@ 32 , i8 * * %299 , align 8 store i32 -30@@ 53@@ 78@@ 35 , i32 * %300 , align 4 %2@@ 81@@ 3 = load i32 , i32 * %254 , align 4 %2@@ 81@@ 4 = load i8 , i8 * @g_3@@ 21 , align 1 %2@@ 81@@ 5 = zext i8 %2@@ 81@@ 4 to i64 %2@@ 8@@ 16 = and i64 %2@@ 81@@ 5 , 0 %2@@ 81@@ 7 = trunc i64 %2@@ 8@@ 16 to i8 store i8 %2@@ 81@@ 7 , i8 * @g_3@@ 21 , align 1 %2@@ 818 = load i8 * , i8 * * %299 , align 8 store i8 %2@@ 81@@ 7 , i8 * %2@@ 818 , align 1 %2@@ 81@@ 9 = zext i8 %2@@ 81@@ 7 to i64 %2@@ 8@@ 20 = icmp sgt i64 %2@@ 81@@ 9 , 2@@ 45 %2@@ 8@@ 21 = zext i1 %2@@ 8@@ 20 to i32 %2@@ 8@@ 22 = sext i32 %2@@ 8@@ 21 to i64 %2@@ 8@@ 23 = icmp uge i64 655@@ 33 , %2@@ 8@@ 24 %2@@ 8@@ 24 = zext i1 %2@@ 8@@ 23 to i32 %2@@ 8@@ 25 = load i32 , i32 * %8 , align 4 %2@@ 8@@ 26 = load i32 , i32 * %8 , align 4 %2@@ 8@@ 27 = icmp ne i16 * * * %163 , %2@@ 8@@ 28 %2@@ 8@@ 28 = zext i1 %2@@ 8@@ 27 to i32 %2@@ 8@@ 29 = load i8 , i8 * @g_1@@ 59 , align 1 %2@@ 8@@ 30 = zext i8 %2@@ 8@@ 29 to i64 %2@@ 8@@ 31 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %33 store i32 %2@@ 8@@ 28 , i32 * %2@@ 8@@ 31 , align 4 %2@@ 8@@ 32 = zext i32 %2@@ 8@@ 28 to i64 %2@@ 833 = icmp ne i64 %2@@ 8@@ 32 , 926@@ 03@@ 55@@ 18 %2@@ 8@@ 34 = zext i1 %2@@ 833 to i32 %2@@ 8@@ 35 = icmp sgt i32 %2@@ 8@@ 24 , %2@@ 8@@ 36 %2@@ 8@@ 36 = zext i1 %2@@ 8@@ 35 to i32 %2@@ 8@@ 37 = sext i32 %2@@ 8@@ 36 to i64 %2@@ 8@@ 38 = icmp uge i64 %2@@ 8@@ 37 , 253 br i1 %2@@ 8@@ 38 , label %2@@ 8@@ 39 , label %2@@ 8@@ 39 22 br label %2@@ 840 22@@ 8@@ 41 %2@@ 8@@ 41 = phi i1 [ false , %2@@ 812 ] , [ false , %2@@ 8@@ 39 ] %2@@ 8@@ 42 = zext i1 %2@@ 8@@ 41 to i32 %2@@ 8@@ 43 = load i32 , i32 * %8 , align 4 %2@@ 8@@ 44 = icmp slt i32 %2@@ 8@@ 42 , %2@@ 845 %2@@ 845 = zext i1 %2@@ 8@@ 44 to i32 %2@@ 8@@ 46 = sext i32 %2@@ 845 to i64 %2@@ 8@@ 47 = icmp ult i64 %2@@ 8@@ 46 , 0 %2@@ 848 = zext i1 %2@@ 8@@ 47 to i32 %2@@ 8@@ 49 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %2@@ 850 = load i64 * * , i64 * * * %2@@ 8@@ 49 , align 8 %2@@ 8@@ 51 = load i64 * , i64 * * %2@@ 850 , align 8 %2@@ 852 = load i64 , i64 * %2@@ 8@@ 51 , align 8 %2@@ 8@@ 53 = icmp sgt i64 %2@@ 852 , 1 %2@@ 854 = zext i1 %2@@ 8@@ 53 to i32 %2@@ 8@@ 55 = load i8 , i8 * @g_6@@ 44 , align 1 %2@@ 8@@ 56 = sext i8 %2@@ 8@@ 55 to i32 %2@@ 8@@ 57 = or i32 %2@@ 8@@ 56 , %2@@ 8@@ 58 %2@@ 8@@ 58 = trunc i32 %2@@ 8@@ 57 to i8 store i8 %2@@ 8@@ 58 , i8 * @g_6@@ 44 , align 1 %2@@ 8@@ 59 = load i8 * , i8 * * %160 , align 8 store i8 %2@@ 8@@ 58 , i8 * %2@@ 8@@ 59 , align 1 %2@@ 86@@ 0 = sext i8 %2@@ 8@@ 58 to i32 %2@@ 8@@ 61 = load i32 , i32 * %8 , align 4 %2@@ 86@@ 2 = or i32 %2@@ 86@@ 0 , %2@@ 863 %2@@ 863 = trunc i32 %2@@ 86@@ 2 to i8 %2@@ 864 = load i32 , i32 * %8 , align 4 %2@@ 865 = trunc i32 %2@@ 864 to i8 %2@@ 866 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %2@@ 863 , i8 zeroext %2@@ 865 ) %2@@ 867 = load i32 , i32 * %8 , align 4 %2@@ 868 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %2@@ 866 , i32 %2@@ 867 ) %2@@ 86@@ 9 = zext i8 %2@@ 868 to i16 %2@@ 870 = load i16 , i16 * %251 , align 2 %2@@ 8@@ 71 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %2@@ 86@@ 9 , i16 signext %2@@ 870 ) %2@@ 8@@ 72 = sext i16 %2@@ 8@@ 71 to i64 %2@@ 8@@ 73 = icmp sle i64 %2@@ 8@@ 72 , 546@@ 51 %2@@ 874 = zext i1 %2@@ 8@@ 73 to i32 %2@@ 875 = load i32 , i32 * %300 , align 4 %2@@ 8@@ 76 = icmp eq i32 %2@@ 874 , %2@@ 877 %2@@ 877 = zext i1 %2@@ 8@@ 76 to i32 %2@@ 8@@ 78 = sext i32 %2@@ 877 to i64 %2@@ 8@@ 79 = icmp ule i64 0 , %2@@ 8@@ 80 %2@@ 8@@ 80 = zext i1 %2@@ 8@@ 79 to i32 %2@@ 8@@ 81 = load i32 , i32 * %300 , align 4 %2@@ 8@@ 82 = icmp sge i32 %2@@ 8@@ 80 , %2@@ 883 %2@@ 883 = zext i1 %2@@ 8@@ 82 to i32 %2@@ 8@@ 84 = sext i32 %2@@ 883 to i64 %2@@ 8@@ 85 = load i64 , i64 * %256 , align 8 %2@@ 8@@ 86 = xor i64 %2@@ 8@@ 85 , %33 store i64 %2@@ 8@@ 86 , i64 * %256 , align 8 br label %2@@ 887 22@@ 8@@ 88 %2@@ 8@@ 88 = load i8 , i8 * @g_1@@ 59 , align 1 %2@@ 889 = zext i8 %2@@ 8@@ 88 to i32 %2@@ 8@@ 90 = add nsw i32 %2@@ 889 , 1 %2@@ 891 = trunc i32 %2@@ 8@@ 90 to i8 store i8 %2@@ 891 , i8 * @g_1@@ 59 , align 1 br label %2@@ 8@@ 92 22@@ 8@@ 93 %2@@ 8@@ 93 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %2@@ 894 = load i16 * , i16 * * %2@@ 8@@ 93 , align 8 %2@@ 8@@ 95 = load i16 , i16 * %2@@ 894 , align 2 %2@@ 8@@ 96 = zext i16 %2@@ 8@@ 95 to i32 %2@@ 8@@ 97 = load i8 , i8 * %291 , align 1 %2@@ 8@@ 98 = zext i8 %2@@ 8@@ 97 to i32 %2@@ 899 = and i32 %2@@ 8@@ 96 , %2@@ 900 %2@@ 900 = load i8 , i8 * %291 , align 1 %2@@ 9@@ 01 = zext i8 %2@@ 900 to i32 %2@@ 9@@ 02 = call i32 @safe_unary_minus_func_uint32_t_u ( i32 -10 ) %2@@ 9@@ 03 = load %@@ struct@@ .@@ S@@ 0 * * , %@@ struct@@ .@@ S@@ 0 * * * %169 , align 8 %2@@ 9@@ 04 = icmp eq %@@ struct@@ .@@ S@@ 0 * * null , %2@@ 9@@ 05 %2@@ 9@@ 05 = zext i1 %2@@ 9@@ 04 to i32 %2@@ 9@@ 06 = or i32 %2@@ 9@@ 02 , %2@@ 9@@ 07 %2@@ 9@@ 07 = icmp ne i32 %2@@ 9@@ 06 , 0 br i1 %2@@ 9@@ 07 , label %2@@ 9@@ 08 , label %2@@ 9@@ 08 22@@ 9@@ 09 %2@@ 9@@ 09 = load i32 , i32 * getelementptr inbounds ( [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 0 , i64 4 ) , align 16 %2@@ 910 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %2@@ 9@@ 11 = load i64 * , i64 * * %2@@ 910 , align 8 %2@@ 912 = load i64 , i64 * %2@@ 9@@ 11 , align 8 %2@@ 9@@ 13 = icmp ne i64 %2@@ 912 , 0 br i1 %2@@ 9@@ 13 , label %2@@ 9@@ 19 , label %2@@ 9@@ 14 22@@ 9@@ 15 %2@@ 9@@ 15 = load i32 , i32 * %170 , align 4 %2@@ 9@@ 16 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext -7 , i32 %2@@ 9@@ 15 ) %2@@ 9@@ 17 = zext i8 %2@@ 9@@ 16 to i32 %2@@ 9@@ 18 = icmp ne i32 %2@@ 9@@ 17 , 0 br label %2@@ 9@@ 19 22@@ 9@@ 20 %2@@ 9@@ 20 = phi i1 [ true , %2@@ 9@@ 08 ] , [ %2@@ 9@@ 18 , %2@@ 9@@ 14 ] %2@@ 9@@ 21 = zext i1 %2@@ 9@@ 20 to i32 %2@@ 9@@ 22 = icmp ugt i32 %2@@ 9@@ 09 , %2@@ 9@@ 23 %2@@ 9@@ 23 = zext i1 %2@@ 9@@ 22 to i32 %2@@ 9@@ 24 = trunc i32 %2@@ 9@@ 23 to i8 %2@@ 9@@ 25 = load volatile i16 , i16 * @g_@@ 556 , align 2 %2@@ 9@@ 26 = trunc i16 %2@@ 9@@ 25 to i8 %2@@ 9@@ 27 = call zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %2@@ 9@@ 24 , i8 zeroext %2@@ 9@@ 26 ) %2@@ 9@@ 28 = zext i8 %2@@ 9@@ 27 to i32 %2@@ 9@@ 29 = load i8 , i8 * %257 , align 1 %2@@ 9@@ 30 = sext i8 %2@@ 9@@ 29 to i32 %2@@ 9@@ 31 = or i32 %2@@ 9@@ 28 , %2@@ 9@@ 32 %2@@ 9@@ 32 = icmp ne i32 %2@@ 9@@ 31 , 0 br label %2@@ 933 22@@ 9@@ 34 %2@@ 9@@ 34 = phi i1 [ false , %2@@ 8@@ 92 ] , [ %2@@ 9@@ 32 , %2@@ 9@@ 19 ] %2@@ 9@@ 35 = zext i1 %2@@ 9@@ 34 to i32 %2@@ 9@@ 36 = icmp sgt i32 %2@@ 9@@ 01 , %2@@ 9@@ 37 %2@@ 9@@ 37 = zext i1 %2@@ 9@@ 36 to i32 %2@@ 938 = sext i32 %2@@ 9@@ 37 to i64 %2@@ 9@@ 39 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %2@@ 9@@ 40 = load i64 * , i64 * * %2@@ 9@@ 39 , align 8 %2@@ 9@@ 41 = load i64 , i64 * %2@@ 9@@ 40 , align 8 %2@@ 9@@ 42 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %2@@ 938 , i64 %2@@ 9@@ 41 ) %2@@ 9@@ 43 = trunc i64 %2@@ 9@@ 42 to i8 %2@@ 944 = call zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %2@@ 9@@ 43 , i32 2 ) %2@@ 9@@ 45 = zext i8 %2@@ 944 to i32 %2@@ 9@@ 46 = icmp ne i32 %2@@ 899 , %2@@ 9@@ 47 %2@@ 9@@ 47 = zext i1 %2@@ 9@@ 46 to i32 %2@@ 9@@ 48 = trunc i32 %2@@ 9@@ 47 to i16 %2@@ 9@@ 49 = load i16 * , i16 * * @g_11@@ 48 , align 8 store i16 %2@@ 9@@ 48 , i16 * %2@@ 9@@ 49 , align 2 %2@@ 9@@ 50 = zext i16 %2@@ 9@@ 48 to i32 %2@@ 951 = load i32 , i32 * %8 , align 4 %2@@ 9@@ 52 = icmp sle i32 %2@@ 9@@ 50 , %2@@ 9@@ 53 %2@@ 9@@ 53 = zext i1 %2@@ 9@@ 52 to i32 %2@@ 9@@ 54 = load i32 * , i32 * * %13 , align 8 %2@@ 9@@ 55 = load i32 , i32 * %2@@ 9@@ 54 , align 4 %2@@ 9@@ 56 = and i32 %2@@ 9@@ 55 , %33 store i32 %2@@ 9@@ 56 , i32 * %2@@ 9@@ 54 , align 4 %2@@ 9@@ 57 = load i32 , i32 * %8 , align 4 %2@@ 9@@ 58 = load i32 , i32 * %8 , align 4 %2@@ 9@@ 59 = icmp ne i32 %2@@ 9@@ 58 , 0 br i1 %2@@ 9@@ 59 , label %2@@ 960 , label %2@@ 960 22@@ 9@@ 61 %2@@ 9@@ 61 = load i32 * , i32 * * @g_8@@ 43 , align 8 %2@@ 9@@ 62 = load i32 , i32 * %2@@ 9@@ 61 , align 4 %2@@ 9@@ 63 = load i32 , i32 * @g_9@@ 88 , align 4 %2@@ 9@@ 64 = zext i32 %2@@ 9@@ 63 to i64 %2@@ 9@@ 65 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %33 store i32 %2@@ 9@@ 62 , i32 * %2@@ 9@@ 65 , align 4 %2@@ 9@@ 66 = zext i32 %2@@ 9@@ 62 to i64 %2@@ 9@@ 67 = icmp eq i64 9@@ 4993@@ 20@@ 99 , %2@@ 9@@ 68 %2@@ 9@@ 68 = zext i1 %2@@ 9@@ 67 to i32 %2@@ 9@@ 69 = load i8 * * , i8 * * * %220 , align 8 %2@@ 9@@ 70 = load i8 * * * , i8 * * * * %292 , align 8 store i8 * * %2@@ 9@@ 69 , i8 * * * %2@@ 9@@ 70 , align 8 %2@@ 9@@ 71 = load i8 * * * , i8 * * * * %294 , align 8 store i8 * * %2@@ 9@@ 69 , i8 * * * %2@@ 9@@ 71 , align 8 %2@@ 9@@ 72 = load i8 * * * , i8 * * * * %296 , align 8 store i8 * * %2@@ 9@@ 69 , i8 * * * %2@@ 9@@ 72 , align 8 %2@@ 9@@ 73 = icmp ne i8 * * %2@@ 9@@ 69 , %2@@ 9@@ 74 %2@@ 9@@ 74 = zext i1 %2@@ 9@@ 73 to i32 %2@@ 9@@ 75 = trunc i32 %2@@ 9@@ 74 to i8 %2@@ 976 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_3@@ 73 to i16 * ) , align 4 %2@@ 9@@ 77 = getelementptr inbounds [ 9 x %un@@ ion.@@ U@@ 1 * ] , [ 9 x %un@@ ion.@@ U@@ 1 * ] * %297 , i64 0 , i64 4 %2@@ 978 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %2@@ 9@@ 77 , align 16 %2@@ 9@@ 79 = icmp ne %un@@ ion.@@ U@@ 1 * %2@@ 978 , null %2@@ 9@@ 80 = zext i1 %2@@ 9@@ 79 to i32 %2@@ 981 = trunc i32 %2@@ 9@@ 80 to i8 %2@@ 9@@ 82 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %2@@ 9@@ 75 , i8 signext %2@@ 981 ) %2@@ 9@@ 83 = load i32 , i32 * @g_@@ 65 , align 4 %2@@ 9@@ 84 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext 0 , i32 %2@@ 9@@ 83 ) %2@@ 9@@ 85 = sext i8 %2@@ 9@@ 84 to i64 %2@@ 9@@ 86 = icmp ne i64 %2@@ 9@@ 85 , -3 br i1 %2@@ 9@@ 86 , label %2@@ 987 , label %2@@ 987 22@@ 9@@ 88 %2@@ 9@@ 88 = load i16 , i16 * %251 , align 2 %2@@ 9@@ 89 = sext i16 %2@@ 9@@ 88 to i32 %2@@ 9@@ 90 = icmp ne i32 %2@@ 9@@ 89 , 0 br label %2@@ 991 22@@ 9@@ 92 %2@@ 9@@ 92 = phi i1 [ false , %2@@ 960 ] , [ %2@@ 9@@ 90 , %2@@ 987 ] %2@@ 9@@ 93 = zext i1 %2@@ 9@@ 92 to i32 %2@@ 994 = trunc i32 %2@@ 9@@ 93 to i16 %2@@ 9@@ 95 = load i16 * , i16 * * @g_11@@ 48 , align 8 %2@@ 9@@ 96 = load i16 , i16 * %2@@ 9@@ 95 , align 2 %2@@ 9@@ 97 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %2@@ 994 , i16 signext %2@@ 9@@ 96 ) %2@@ 9@@ 98 = sext i16 %2@@ 9@@ 97 to i32 %2@@ 9@@ 99 = icmp ne i32 %2@@ 9@@ 98 , 0 br i1 %2@@ 9@@ 99 , label %3@@ 003 , label %3@@ 000 33@@ 00@@ 1 %3@@ 00@@ 1 = load i64 , i64 * getelementptr inbounds ( [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 2 , i64 1 ) , align 8 %3@@ 00@@ 2 = icmp ne i64 %3@@ 00@@ 1 , 0 br label %3@@ 003 33@@ 00@@ 4 %3@@ 00@@ 4 = phi i1 [ true , %2@@ 991 ] , [ %3@@ 00@@ 2 , %3@@ 000 ] %3@@ 00@@ 5 = zext i1 %3@@ 00@@ 4 to i32 %3@@ 00@@ 6 = trunc i32 %3@@ 00@@ 5 to i8 %3@@ 007 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %3@@ 00@@ 6 , i32 2 ) %3@@ 008 = sext i8 %3@@ 007 to i64 %3@@ 009 = icmp ne i64 -7 , %3@@ 0@@ 10 %3@@ 0@@ 10 = zext i1 %3@@ 009 to i32 %3@@ 0@@ 11 = load i32 * , i32 * * %7 , align 8 %3@@ 0@@ 12 = load i32 , i32 * %3@@ 0@@ 11 , align 4 %3@@ 0@@ 13 = call i32 @safe_mod_func_int32_t_s_s ( i32 %3@@ 0@@ 10 , i32 %3@@ 0@@ 12 ) %3@@ 0@@ 14 = sext i32 %3@@ 0@@ 13 to i64 %3@@ 0@@ 15 = icmp sgt i64 %3@@ 0@@ 14 , -1 %3@@ 0@@ 16 = zext i1 %3@@ 0@@ 15 to i32 %3@@ 0@@ 17 = sext i32 %3@@ 0@@ 16 to i64 %3@@ 0@@ 18 = icmp ne i64 %3@@ 0@@ 17 , 547@@ 35@@ 25@@ 14@@ 76@@ 49@@ 00@@ 44@@ 13 br label %3@@ 0@@ 19 330@@ 20 %3@@ 0@@ 20 = phi i1 [ false , %2@@ 933 ] , [ %3@@ 0@@ 18 , %3@@ 003 ] %3@@ 0@@ 21 = zext i1 %3@@ 0@@ 20 to i32 %3@@ 0@@ 22 = load i32 , i32 * %219 , align 4 %3@@ 0@@ 23 = xor i32 %3@@ 0@@ 22 , %33 store i32 %3@@ 0@@ 23 , i32 * %219 , align 4 br label %3@@ 0@@ 24 330@@ 25 %3@@ 0@@ 25 = load i32 , i32 * @g_1@@ 118 , align 4 %3@@ 0@@ 26 = add i32 %3@@ 0@@ 25 , 1 store i32 %3@@ 0@@ 26 , i32 * @g_1@@ 118 , align 4 br label %3@@ 0@@ 27 333 store i8 0 , i8 * @g_1@@ 402 , align 1 br label %3@@ 0@@ 28 330@@ 29 %3@@ 029 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 0@@ 30 = zext i8 %3@@ 029 to i32 %3@@ 031 = icmp sle i32 %3@@ 0@@ 30 , 0 br i1 %3@@ 031 , label %3@@ 0@@ 32 , label %3@@ 0@@ 32 333 store i32 -6 , i32 * %302 , align 4 %3@@ 0@@ 33 = bitcast [ 10 x i32 ] * %303 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %3@@ 0@@ 33 , i8 * align 16 bitcast ( [ 10 x i32 ] * @__const.func_@@ 3@@ 1.l_@@ 17@@ 44 to i8 * ) , i64 40 , i1 false ) store i8 2 , i8 * %304 , align 1 store i32 -1 , i32 * %305 , align 4 store i32 * * * @g_8@@ 42 , i32 * * * * %306 , align 8 store i32 -6 , i32 * %307 , align 4 %3@@ 0@@ 34 = getelementptr inbounds [ 9 x [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] ] , [ 9 x [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] ] * %221 , i64 0 , i64 4 %3@@ 0@@ 35 = getelementptr inbounds [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] , [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] * %3@@ 0@@ 34 , i64 0 , i64 1 %3@@ 0@@ 36 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * * ] * %3@@ 0@@ 35 , i64 0 , i64 3 %3@@ 0@@ 37 = load %un@@ ion.@@ U@@ 1 * * * , %un@@ ion.@@ U@@ 1 * * * * %3@@ 0@@ 36 , align 8 store %un@@ ion.@@ U@@ 1 * * * %3@@ 0@@ 37 , %un@@ ion.@@ U@@ 1 * * * * %28 , align 8 %3@@ 0@@ 38 = icmp eq %un@@ ion.@@ U@@ 1 * * * %3@@ 0@@ 37 , null %3@@ 0@@ 39 = zext i1 %3@@ 0@@ 38 to i32 %3@@ 0@@ 40 = sext i32 %3@@ 0@@ 39 to i64 %3@@ 0@@ 41 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 0@@ 42 = zext i8 %3@@ 0@@ 41 to i64 %3@@ 0@@ 43 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %216 , i64 0 , i64 %3@@ 0@@ 44 %3@@ 0@@ 44 = load i8 , i8 * %3@@ 0@@ 43 , align 1 %3@@ 0@@ 45 = sext i8 %3@@ 0@@ 44 to i64 %3@@ 0@@ 46 = call i64 @safe_mod_func_int64_t_s_s ( i64 %3@@ 0@@ 40 , i64 %3@@ 0@@ 45 ) %3@@ 0@@ 47 = load i32 , i32 * %219 , align 4 %3@@ 0@@ 48 = load i32 , i32 * getelementptr inbounds ( [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] , [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] * @g_10@@ 87 , i64 0 , i64 2 , i64 6 , i32 0 ) , align 8 %3@@ 049 = icmp ne i32 %3@@ 0@@ 47 , %3@@ 0@@ 50 %3@@ 0@@ 50 = zext i1 %3@@ 049 to i32 %3@@ 0@@ 51 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 0@@ 52 = zext i8 %3@@ 0@@ 51 to i64 %3@@ 0@@ 53 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %216 , i64 0 , i64 %3@@ 0@@ 54 %3@@ 0@@ 54 = load i8 , i8 * %3@@ 0@@ 53 , align 1 %3@@ 0@@ 55 = sext i8 %3@@ 0@@ 54 to i32 %3@@ 0@@ 56 = icmp ne i32 %3@@ 0@@ 55 , 0 br i1 %3@@ 0@@ 56 , label %3@@ 0@@ 57 , label %3@@ 0@@ 57 330@@ 58 %3@@ 0@@ 58 = load i32 , i32 * %161 , align 4 %3@@ 0@@ 59 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 0@@ 60 = zext i8 %3@@ 0@@ 59 to i32 %3@@ 0@@ 61 = add nsw i32 %3@@ 0@@ 60 , 2 %3@@ 0@@ 62 = sext i32 %3@@ 0@@ 61 to i64 %3@@ 0@@ 63 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %33 store i32 %3@@ 0@@ 58 , i32 * %3@@ 0@@ 63 , align 4 %3@@ 0@@ 64 = icmp ne i32 %3@@ 0@@ 58 , 0 br i1 %3@@ 0@@ 64 , label %3@@ 0@@ 69 , label %3@@ 0@@ 65 330@@ 66 %3@@ 0@@ 66 = load i16 , i16 * %251 , align 2 %3@@ 0@@ 67 = sext i16 %3@@ 0@@ 66 to i32 %3@@ 0@@ 68 = icmp ne i32 %3@@ 0@@ 67 , 0 br label %3@@ 0@@ 69 330@@ 70 %3@@ 0@@ 70 = phi i1 [ true , %3@@ 0@@ 57 ] , [ %3@@ 0@@ 68 , %3@@ 0@@ 65 ] %3@@ 0@@ 71 = zext i1 %3@@ 0@@ 70 to i32 %3@@ 0@@ 72 = sext i32 %3@@ 0@@ 71 to i64 %3@@ 0@@ 73 = call i64 @safe_div_func_int64_t_s_s ( i64 %3@@ 0@@ 72 , i64 -39@@ 24@@ 15@@ 119@@ 5@@ 70@@ 58@@ 02 ) %3@@ 0@@ 74 = load i32 , i32 * %8 , align 4 %3@@ 0@@ 75 = sext i32 %3@@ 0@@ 74 to i64 %3@@ 0@@ 76 = call i64 @safe_div_func_uint64_t_u_u ( i64 0 , i64 %3@@ 0@@ 75 ) %3@@ 0@@ 77 = load i8 , i8 * @g_3@@ 21 , align 1 %3@@ 0@@ 78 = zext i8 %3@@ 0@@ 77 to i16 %3@@ 0@@ 79 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext 0 , i16 signext %3@@ 0@@ 78 ) %3@@ 0@@ 80 = sext i16 %3@@ 0@@ 79 to i64 %3@@ 0@@ 81 = icmp slt i64 %3@@ 0@@ 80 , 234 %3@@ 0@@ 82 = zext i1 %3@@ 0@@ 81 to i32 %3@@ 0@@ 83 = load i16 * , i16 * * @g_11@@ 48 , align 8 %3@@ 0@@ 84 = load i16 , i16 * %3@@ 0@@ 83 , align 2 %3@@ 085 = zext i16 %3@@ 0@@ 84 to i32 %3@@ 0@@ 86 = icmp ne i32 %3@@ 085 , 0 br i1 %3@@ 0@@ 86 , label %3@@ 093 , label %3@@ 0@@ 87 330@@ 88 %3@@ 0@@ 88 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %3@@ 0@@ 89 = load i16 * , i16 * * %3@@ 0@@ 88 , align 8 %3@@ 0@@ 90 = load i16 , i16 * %3@@ 0@@ 89 , align 2 %3@@ 0@@ 91 = zext i16 %3@@ 0@@ 90 to i32 %3@@ 0@@ 92 = icmp ne i32 %3@@ 0@@ 91 , 0 br label %3@@ 093 330@@ 94 %3@@ 0@@ 94 = phi i1 [ true , %3@@ 0@@ 69 ] , [ %3@@ 0@@ 92 , %3@@ 0@@ 87 ] %3@@ 0@@ 95 = zext i1 %3@@ 0@@ 94 to i32 %3@@ 0@@ 96 = sext i32 %3@@ 0@@ 95 to i64 %3@@ 0@@ 97 = icmp sgt i64 %3@@ 0@@ 46 , %2 br i1 %3@@ 0@@ 97 , label %3@@ 098 , label %3@@ 098 330@@ 99 %3@@ 0@@ 99 = getelementptr inbounds [ 9 x i32 * ] , [ 9 x i32 * ] * %309 , i64 0 , i64 0 store i32 * %217 , i32 * * %3@@ 0@@ 99 , align 8 %3@@ 100 = getelementptr inbounds i32 * , i32 * * %3@@ 0@@ 99 , i64 1 store i32 * %217 , i32 * * %3@@ 100 , align 8 %3@@ 101 = getelementptr inbounds i32 * , i32 * * %3@@ 100 , i64 1 store i32 * %217 , i32 * * %3@@ 101 , align 8 %3@@ 102 = getelementptr inbounds i32 * , i32 * * %3@@ 101 , i64 1 store i32 * %217 , i32 * * %3@@ 102 , align 8 %3@@ 10@@ 3 = getelementptr inbounds i32 * , i32 * * %3@@ 102 , i64 1 store i32 * %217 , i32 * * %3@@ 10@@ 3 , align 8 %3@@ 10@@ 4 = getelementptr inbounds i32 * , i32 * * %3@@ 10@@ 3 , i64 1 store i32 * %217 , i32 * * %3@@ 10@@ 4 , align 8 %3@@ 105 = getelementptr inbounds i32 * , i32 * * %3@@ 10@@ 4 , i64 1 store i32 * %217 , i32 * * %3@@ 105 , align 8 %3@@ 10@@ 6 = getelementptr inbounds i32 * , i32 * * %3@@ 105 , i64 1 store i32 * %217 , i32 * * %3@@ 10@@ 6 , align 8 %3@@ 10@@ 7 = getelementptr inbounds i32 * , i32 * * %3@@ 10@@ 6 , i64 1 store i32 * %217 , i32 * * %3@@ 10@@ 7 , align 8 %3@@ 108 = bitcast [ 8 x i16 ] * %310 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %3@@ 108 , i8 * align 16 bitcast ( [ 8 x i16 ] * @__const.func_@@ 3@@ 1.l_@@ 17@@ 70 to i8 * ) , i64 16 , i1 false ) %3@@ 10@@ 9 = load i32 , i32 * %258 , align 4 %3@@ 110 = add i32 %3@@ 10@@ 9 , 1 store i32 %3@@ 110 , i32 * %258 , align 4 %3@@ 111 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 112 = zext i8 %3@@ 111 to i64 %3@@ 113 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %216 , i64 0 , i64 %3@@ 114 %3@@ 114 = load i8 , i8 * %3@@ 113 , align 1 %3@@ 115 = sext i8 %3@@ 114 to i32 %3@@ 116 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 117 = zext i8 %3@@ 116 to i32 %3@@ 118 = add nsw i32 %3@@ 117 , 4 %3@@ 119 = sext i32 %3@@ 118 to i64 %3@@ 120 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %33 store i32 %3@@ 115 , i32 * %3@@ 120 , align 4 %3@@ 121 = load i32 , i32 * %8 , align 4 %3@@ 122 = call i32 @safe_div_func_uint32_t_u_u ( i32 %3@@ 115 , i32 %3@@ 121 ) %3@@ 123 = load i32 , i32 * %217 , align 4 %3@@ 124 = load i32 * , i32 * * %13 , align 8 store i32 %3@@ 123 , i32 * %3@@ 124 , align 4 %3@@ 125 = xor i32 %3@@ 123 , -1 %3@@ 126 = bitcast %un@@ ion.@@ U@@ 1 * %313 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 4 %3@@ 126 , i8 * align 4 bitcast ( %un@@ ion.@@ U@@ 1 * getelementptr inbounds ( [ 8 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] ] , [ 8 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] ] * @g_1@@ 7@@ 36 , i64 0 , i64 3 , i64 5 , i64 0 ) to i8 * ) , i64 4 , i1 true ) %3@@ 127 = load i64 * * , i64 * * * getelementptr inbounds ( [ 2 x i64 * * ] , [ 2 x i64 * * ] * @g_1@@ 6@@ 37 , i64 0 , i64 1 ) , align 8 %3@@ 128 = icmp eq i64 * * %3@@ 127 , null %3@@ 129 = zext i1 %3@@ 128 to i32 %3@@ 130 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , i32 0 , i32 0 ) , align 4 %3@@ 131 = icmp ne i32 %3@@ 129 , %3@@ 132 %3@@ 132 = zext i1 %3@@ 131 to i32 %3@@ 133 = load i8 * , i8 * * %158 , align 8 store i8 8 , i8 * %3@@ 133 , align 1 %3@@ 1@@ 34 = load i8 * , i8 * * %160 , align 8 store i8 8 , i8 * %3@@ 1@@ 34 , align 1 %3@@ 1@@ 35 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext -1@@ 24 , i8 signext 8 ) %3@@ 136 = sext i8 %3@@ 1@@ 35 to i16 %3@@ 1@@ 37 = load i32 , i32 * %8 , align 4 %3@@ 138 = call signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %3@@ 136 , i32 %3@@ 1@@ 37 ) %3@@ 139 = load i32 , i32 * %8 , align 4 %3@@ 140 = load i32 , i32 * %8 , align 4 %3@@ 1@@ 41 = icmp sle i32 %3@@ 139 , %2 br i1 %3@@ 1@@ 41 , label %3@@ 1@@ 43 , label %3@@ 1@@ 42 32 br label %3@@ 1@@ 43 33@@ 144 %3@@ 144 = phi i1 [ true , %3@@ 098 ] , [ true , %3@@ 1@@ 42 ] %3@@ 145 = zext i1 %3@@ 144 to i32 %3@@ 1@@ 46 = icmp eq i32 %3@@ 132 , %3@@ 147 %3@@ 147 = zext i1 %3@@ 1@@ 46 to i32 %3@@ 148 = trunc i32 %3@@ 147 to i16 %3@@ 1@@ 49 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %3@@ 150 = load i16 * , i16 * * %3@@ 1@@ 49 , align 8 %3@@ 1@@ 51 = load i16 , i16 * %3@@ 150 , align 2 %3@@ 152 = zext i16 %3@@ 1@@ 51 to i32 %3@@ 15@@ 3 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %3@@ 148 , i32 %3@@ 152 ) %3@@ 154 = sext i16 %3@@ 15@@ 3 to i32 %3@@ 15@@ 5 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 1 %3@@ 156 = load i32 , i32 * %3@@ 15@@ 5 , align 4 %3@@ 15@@ 7 = or i32 %3@@ 154 , %3@@ 158 %3@@ 158 = sext i32 %3@@ 15@@ 7 to i64 %3@@ 159 = load i64 * * , i64 * * * @g_12@@ 66 , align 8 %3@@ 160 = load i64 * , i64 * * %3@@ 159 , align 8 %3@@ 1@@ 61 = load i64 , i64 * %3@@ 160 , align 8 %3@@ 16@@ 2 = and i64 %3@@ 1@@ 61 , %33 store i64 %3@@ 16@@ 2 , i64 * %3@@ 160 , align 8 %3@@ 16@@ 3 = bitcast i64 * * * %25 to i8 * %3@@ 1@@ 64 = icmp eq i8 * null , %3@@ 16@@ 5 %3@@ 16@@ 5 = zext i1 %3@@ 1@@ 64 to i32 %3@@ 16@@ 6 = sext i32 %3@@ 16@@ 5 to i64 %3@@ 16@@ 7 = call i64 @safe_div_func_uint64_t_u_u ( i64 %3@@ 16@@ 6 , i64 -10@@ 124@@ 318@@ 375@@ 32@@ 758 ) %3@@ 168 = load i16 * * , i16 * * * @g_11@@ 47 , align 8 %3@@ 169 = load i16 * , i16 * * %3@@ 168 , align 8 store i16 -2@@ 17@@ 32 , i16 * %3@@ 169 , align 2 %3@@ 170 = icmp ugt i32 %3@@ 122 , 438@@ 04 %3@@ 171 = zext i1 %3@@ 170 to i32 %3@@ 17@@ 2 = sext i32 %3@@ 171 to i64 %3@@ 17@@ 3 = icmp ne i64 %3@@ 17@@ 2 , 0 %3@@ 174 = zext i1 %3@@ 17@@ 3 to i32 %3@@ 175 = load i16 , i16 * %32 , align 2 %3@@ 176 = load i32 , i32 * %8 , align 4 %3@@ 177 = trunc i32 %3@@ 176 to i16 %3@@ 178 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %3@@ 175 , i16 signext %3@@ 177 ) %3@@ 179 = sext i16 %3@@ 178 to i32 %3@@ 1@@ 80 = load i32 , i32 * %253 , align 4 %3@@ 1@@ 81 = and i32 %3@@ 1@@ 80 , %33 store i32 %3@@ 1@@ 81 , i32 * %253 , align 4 %3@@ 1@@ 82 = load i32 , i32 * %233 , align 4 %3@@ 18@@ 3 = add i32 %3@@ 1@@ 82 , -1 store i32 %3@@ 18@@ 3 , i32 * %233 , align 4 %3@@ 184 = load i32 , i32 * %305 , align 4 %3@@ 1@@ 85 = add i32 %3@@ 184 , 1 store i32 %3@@ 1@@ 85 , i32 * %305 , align 4 br label %3@@ 186 33@@ 187 %3@@ 187 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %303 , i64 0 , i64 0 %3@@ 18@@ 8 = load i32 , i32 * %3@@ 187 , align 16 %3@@ 189 = sext i32 %3@@ 18@@ 8 to i64 store i64 %3@@ 189 , i64 * %5 , align 8 br label %3@@ 190 33@@ 191 %3@@ 191 = load i32 , i32 * %217 , align 4 %3@@ 192 = trunc i32 %3@@ 191 to i8 %3@@ 193 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext 0 , i32 14 ) %3@@ 194 = call zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %3@@ 193 , i16 zeroext 313@@ 64 ) %3@@ 195 = load i64 * * * * , i64 * * * * * %265 , align 8 %3@@ 196 = load i32 , i32 * %170 , align 4 %3@@ 19@@ 7 = load i32 , i32 * %305 , align 4 %3@@ 198 = icmp ne i32 %3@@ 19@@ 7 , 0 %3@@ 19@@ 9 = zext i1 %3@@ 198 to i32 %3@@ 200 = trunc i32 %3@@ 19@@ 9 to i16 %3@@ 201 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %3@@ 200 , i32 10 ) %3@@ 202 = load i32 , i32 * %219 , align 4 %3@@ 203 = icmp eq i32 0 , %3@@ 20@@ 4 %3@@ 20@@ 4 = zext i1 %3@@ 203 to i32 %3@@ 20@@ 5 = load i32 , i32 * %8 , align 4 %3@@ 20@@ 6 = and i32 %3@@ 20@@ 4 , %3@@ 207 %3@@ 207 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %3@@ 201 , i32 %3@@ 20@@ 6 ) %3@@ 208 = sext i16 %3@@ 207 to i64 %3@@ 20@@ 9 = or i64 %3@@ 208 , 1 %3@@ 2@@ 10 = load i8 , i8 * @g_3@@ 21 , align 1 %3@@ 2@@ 11 = zext i8 %3@@ 2@@ 10 to i64 %3@@ 2@@ 12 = icmp eq i64 %3@@ 20@@ 9 , %3@@ 213 %3@@ 213 = zext i1 %3@@ 2@@ 12 to i32 %3@@ 2@@ 14 = sext i32 %3@@ 213 to i64 %3@@ 2@@ 15 = load i64 * * * , i64 * * * * @g_12@@ 65 , align 8 %3@@ 216 = load i64 * * , i64 * * * %3@@ 2@@ 15 , align 8 %3@@ 217 = load i64 * , i64 * * %3@@ 216 , align 8 store i64 %3@@ 2@@ 14 , i64 * %3@@ 217 , align 8 %3@@ 218 = load i32 , i32 * %8 , align 4 %3@@ 219 = sext i32 %3@@ 218 to i64 %3@@ 220 = call i64 @safe_div_func_int64_t_s_s ( i64 %3@@ 2@@ 14 , i64 %3@@ 219 ) %3@@ 221 = load i8 * * , i8 * * * %220 , align 8 %3@@ 222 = load i8 * , i8 * * %3@@ 221 , align 8 %3@@ 223 = load i8 , i8 * %3@@ 222 , align 1 %3@@ 224 = sext i8 %3@@ 223 to i64 %3@@ 225 = xor i64 %3@@ 224 , %3@@ 226 %3@@ 226 = trunc i64 %3@@ 225 to i8 store i8 %3@@ 226 , i8 * %3@@ 222 , align 1 %3@@ 227 = sext i8 %3@@ 226 to i64 %3@@ 228 = icmp uge i64 %3@@ 227 , 3 br i1 %3@@ 228 , label %3@@ 2@@ 32 , label %3@@ 229 332@@ 30 %3@@ 230 = load i32 , i32 * %8 , align 4 %3@@ 2@@ 31 = icmp ne i32 %3@@ 230 , 0 br label %3@@ 2@@ 32 332@@ 33 %3@@ 233 = phi i1 [ true , %3@@ 190 ] , [ %3@@ 2@@ 31 , %3@@ 229 ] %3@@ 234 = zext i1 %3@@ 233 to i32 %3@@ 2@@ 35 = icmp ugt i32 %3@@ 196 , %3@@ 2@@ 36 %3@@ 2@@ 36 = xor i1 %3@@ 2@@ 35 , true %3@@ 2@@ 37 = zext i1 %3@@ 2@@ 36 to i32 %3@@ 2@@ 38 = load i64 * * * * , i64 * * * * * %34 , align 8 %3@@ 2@@ 39 = icmp eq i64 * * * * %3@@ 195 , %3@@ 240 %3@@ 240 = zext i1 %3@@ 2@@ 39 to i32 %3@@ 2@@ 41 = sext i32 %3@@ 240 to i64 %3@@ 2@@ 42 = icmp ne i64 %3@@ 2@@ 41 , 9 br i1 %3@@ 2@@ 42 , label %3@@ 246 , label %3@@ 243 332@@ 44 %3@@ 244 = load i32 , i32 * %8 , align 4 %3@@ 2@@ 45 = icmp ne i32 %3@@ 244 , 0 br label %3@@ 246 332@@ 47 %3@@ 247 = phi i1 [ true , %3@@ 2@@ 32 ] , [ %3@@ 2@@ 45 , %3@@ 243 ] %3@@ 2@@ 48 = zext i1 %3@@ 247 to i32 %3@@ 2@@ 49 = load i32 * , i32 * * %7 , align 8 %3@@ 250 = load i32 , i32 * %3@@ 2@@ 49 , align 4 %3@@ 251 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %3@@ 2@@ 48 , i32 %3@@ 250 ) %3@@ 252 = load i32 , i32 * %8 , align 4 %3@@ 253 = xor i32 %3@@ 251 , %3@@ 254 %3@@ 254 = load i32 , i32 * @g_1@@ 49 , align 4 %3@@ 255 = icmp eq i32 %3@@ 253 , %3@@ 256 %3@@ 256 = zext i1 %3@@ 255 to i32 %3@@ 257 = sext i32 %3@@ 256 to i64 %3@@ 25@@ 8 = icmp ne i64 %3@@ 257 , 0 %3@@ 25@@ 9 = zext i1 %3@@ 25@@ 8 to i32 %3@@ 2@@ 60 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %3@@ 192 , i32 %3@@ 25@@ 9 ) %3@@ 261 = zext i8 %3@@ 2@@ 60 to i64 %3@@ 2@@ 62 = icmp sle i64 459@@ 81 , %3@@ 2@@ 63 %3@@ 2@@ 63 = zext i1 %3@@ 2@@ 62 to i32 %3@@ 2@@ 64 = load i16 * , i16 * * %164 , align 8 %3@@ 2@@ 65 = load i16 , i16 * %3@@ 2@@ 64 , align 2 %3@@ 266 = sext i16 %3@@ 2@@ 65 to i32 %3@@ 2@@ 67 = or i32 %3@@ 266 , %3@@ 2@@ 68 %3@@ 2@@ 68 = trunc i32 %3@@ 2@@ 67 to i16 store i16 %3@@ 2@@ 68 , i16 * %3@@ 2@@ 64 , align 2 %3@@ 269 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_5@@ 17 to i16 * ) , align 4 %3@@ 270 = trunc i16 %3@@ 269 to i8 %3@@ 2@@ 71 = call signext i8 @safe_div_func_int8_t_s_s ( i8 signext %3@@ 270 , i8 signext -6 ) %3@@ 2@@ 72 = sext i8 %3@@ 2@@ 71 to i16 %3@@ 2@@ 73 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %303 , i64 0 , i64 9 %3@@ 2@@ 74 = load i32 , i32 * %3@@ 2@@ 73 , align 4 %3@@ 2@@ 75 = trunc i32 %3@@ 2@@ 74 to i16 %3@@ 2@@ 76 = call signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %3@@ 2@@ 72 , i16 signext %3@@ 2@@ 75 ) %3@@ 277 = trunc i16 %3@@ 2@@ 76 to i8 store i8 %3@@ 277 , i8 * @g_11@@ 5 , align 1 %3@@ 2@@ 78 = load i8 * , i8 * * %160 , align 8 store i8 %3@@ 277 , i8 * %3@@ 2@@ 78 , align 1 %3@@ 2@@ 79 = sext i8 %3@@ 277 to i32 %3@@ 280 = load i8 , i8 * %304 , align 1 %3@@ 281 = sext i8 %3@@ 280 to i32 %3@@ 2@@ 82 = icmp sgt i32 %3@@ 2@@ 79 , %3@@ 2@@ 83 %3@@ 2@@ 83 = zext i1 %3@@ 2@@ 82 to i32 %3@@ 2@@ 84 = sext i32 %3@@ 2@@ 83 to i64 %3@@ 2@@ 85 = trunc i64 %3@@ 2@@ 84 to i16 %3@@ 2@@ 86 = load i32 , i32 * %8 , align 4 %3@@ 287 = trunc i32 %3@@ 2@@ 86 to i16 %3@@ 2@@ 88 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %3@@ 2@@ 85 , i16 zeroext %3@@ 287 ) %3@@ 289 = load i32 , i32 * %224 , align 4 %3@@ 29@@ 0 = call zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %3@@ 2@@ 88 , i32 %3@@ 289 ) %3@@ 291 = load i32 * , i32 * * %9 , align 8 %3@@ 292 = load i32 , i32 * %3@@ 291 , align 4 %3@@ 293 = icmp ne i32 %3@@ 292 , 0 br i1 %3@@ 293 , label %3@@ 294 , label %3@@ 294 332@@ 95 %3@@ 295 = load i32 , i32 * %8 , align 4 %3@@ 29@@ 6 = sext i32 %3@@ 295 to i64 store i64 %3@@ 29@@ 6 , i64 * %5 , align 8 br label %3@@ 297 333 store %un@@ ion.@@ U@@ 1 * getelementptr inbounds ( [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] , [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] * @g_10@@ 87 , i64 0 , i64 2 , i64 6 ) , %un@@ ion.@@ U@@ 1 * * %314 , align 8 store %un@@ ion.@@ U@@ 1 * * %314 , %un@@ ion.@@ U@@ 1 * * * %315 , align 8 store i32 20@@ 35@@ 17@@ 28@@ 33 , i32 * %316 , align 4 %3@@ 298 = load i64 , i64 * %171 , align 8 %3@@ 29@@ 9 = load volatile i16 , i16 * getelementptr inbounds ( [ 3 x i16 ] , [ 3 x i16 ] * @g_5@@ 20 , i64 0 , i64 2 ) , align 2 %3@@ 300 = sext i16 %3@@ 29@@ 9 to i64 %3@@ 30@@ 1 = icmp slt i64 %3@@ 298 , %3@@ 302 %3@@ 302 = zext i1 %3@@ 30@@ 1 to i32 %3@@ 30@@ 3 = load i32 * , i32 * * %13 , align 8 %3@@ 304 = load i32 , i32 * %3@@ 30@@ 3 , align 4 %3@@ 305 = or i32 %3@@ 304 , %33 store i32 %3@@ 305 , i32 * %3@@ 30@@ 3 , align 4 %3@@ 306 = load i32 * , i32 * * %6 , align 8 %3@@ 30@@ 7 = load i32 , i32 * %3@@ 306 , align 4 %3@@ 30@@ 8 = load i32 * , i32 * * %13 , align 8 store i32 %3@@ 30@@ 7 , i32 * %3@@ 30@@ 8 , align 4 %3@@ 309 = load i32 * , i32 * * %9 , align 8 %3@@ 3@@ 10 = load i32 , i32 * %3@@ 309 , align 4 %3@@ 3@@ 11 = sext i32 %3@@ 3@@ 10 to i64 %3@@ 3@@ 12 = load i64 , i64 * getelementptr inbounds ( [ 10 x [ 3 x [ 4 x i64 ] ] ] , [ 10 x [ 3 x [ 4 x i64 ] ] ] * @g_1@@ 8@@ 01 , i64 0 , i64 4 , i64 0 , i64 3 ) , align 8 %3@@ 313 = xor i64 %3@@ 3@@ 12 , %33 store i64 %3@@ 313 , i64 * getelementptr inbounds ( [ 10 x [ 3 x [ 4 x i64 ] ] ] , [ 10 x [ 3 x [ 4 x i64 ] ] ] * @g_1@@ 8@@ 01 , i64 0 , i64 4 , i64 0 , i64 3 ) , align 8 %3@@ 3@@ 14 = getelementptr inbounds [ 9 x [ 3 x i32 ] ] , [ 9 x [ 3 x i32 ] ] * %234 , i64 0 , i64 4 %3@@ 315 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %3@@ 3@@ 14 , i64 0 , i64 1 %3@@ 316 = load i32 , i32 * %3@@ 315 , align 4 %3@@ 317 = zext i32 %3@@ 316 to i64 %3@@ 3@@ 18 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %266 , align 8 %3@@ 319 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %314 , align 8 %3@@ 320 = load %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %315 , align 8 store %un@@ ion.@@ U@@ 1 * %3@@ 319 , %un@@ ion.@@ U@@ 1 * * %3@@ 320 , align 8 %3@@ 321 = icmp ne %un@@ ion.@@ U@@ 1 * %3@@ 3@@ 18 , %3@@ 32@@ 2 %3@@ 32@@ 2 = zext i1 %3@@ 321 to i32 %3@@ 323 = sext i32 %3@@ 32@@ 2 to i64 %3@@ 324 = or i64 %3@@ 323 , 9 %3@@ 325 = trunc i64 %3@@ 324 to i32 store i32 %3@@ 325 , i32 * %316 , align 4 %3@@ 326 = load i32 , i32 * %316 , align 4 %3@@ 32@@ 7 = trunc i32 %3@@ 326 to i8 %3@@ 32@@ 8 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 6 ) , align 8 %3@@ 32@@ 9 = trunc i32 %3@@ 32@@ 8 to i8 %3@@ 3@@ 30 = call signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %3@@ 32@@ 7 , i8 signext %3@@ 32@@ 9 ) %3@@ 3@@ 31 = sext i8 %3@@ 3@@ 30 to i32 %3@@ 332 = sext i32 %3@@ 3@@ 31 to i64 %3@@ 333 = icmp ugt i64 -16@@ 70@@ 85@@ 16@@ 55@@ 14@@ 2542@@ 1@@ 61 , %3@@ 334 %3@@ 334 = zext i1 %3@@ 333 to i32 %3@@ 335 = load i32 * , i32 * * %7 , align 8 %3@@ 336 = load i32 , i32 * %3@@ 335 , align 4 %3@@ 337 = sext i32 %3@@ 336 to i64 %3@@ 338 = xor i64 %3@@ 337 , 4294967294 %3@@ 339 = load i16 , i16 * %251 , align 2 %3@@ 3@@ 40 = sext i16 %3@@ 339 to i64 %3@@ 3@@ 41 = icmp ule i64 %3@@ 338 , %2 br i1 %3@@ 3@@ 41 , label %3@@ 3@@ 43 , label %3@@ 342 32 br i1 true , label %3@@ 3@@ 43 , label %3@@ 3@@ 43 32 br label %3@@ 3@@ 44 33@@ 3@@ 45 %3@@ 3@@ 45 = phi i1 [ false , %3@@ 342 ] , [ true , %3@@ 3@@ 43 ] %3@@ 3@@ 46 = zext i1 %3@@ 3@@ 45 to i32 %3@@ 3@@ 47 = trunc i32 %3@@ 3@@ 46 to i16 %3@@ 3@@ 48 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext 268@@ 09 , i16 zeroext %3@@ 3@@ 47 ) %3@@ 3@@ 49 = zext i16 %3@@ 3@@ 48 to i64 %3@@ 35@@ 0 = call i64 @safe_sub_func_int64_t_s_s ( i64 %3@@ 317 , i64 %3@@ 3@@ 49 ) %3@@ 35@@ 1 = trunc i64 %3@@ 35@@ 0 to i32 %3@@ 35@@ 2 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %263 , i64 0 , i64 7 store i32 %3@@ 35@@ 1 , i32 * %3@@ 35@@ 2 , align 4 br label %3@@ 35@@ 3 333 store i32 3 , i32 * %253 , align 4 br label %3@@ 35@@ 4 33@@ 35@@ 5 %3@@ 35@@ 5 = load i32 , i32 * %253 , align 4 %3@@ 35@@ 6 = icmp sge i32 %3@@ 35@@ 5 , 0 br i1 %3@@ 35@@ 6 , label %3@@ 357 , label %3@@ 357 333 store i8 30 , i8 * %317 , align 1 %3@@ 35@@ 8 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %260 , i32 * * %3@@ 35@@ 8 , align 8 br label %3@@ 35@@ 9 33@@ 360 %3@@ 360 = load i32 , i32 * %253 , align 4 %3@@ 3@@ 61 = sub nsw i32 %3@@ 360 , 1 store i32 %3@@ 3@@ 61 , i32 * %253 , align 4 br label %3@@ 3@@ 62 33@@ 3@@ 63 %3@@ 3@@ 63 = load i32 , i32 * %232 , align 4 %3@@ 3@@ 64 = icmp ne i32 %3@@ 3@@ 63 , 0 br i1 %3@@ 3@@ 64 , label %3@@ 3@@ 65 , label %3@@ 3@@ 65 333 store i32 * null , i32 * * %319 , align 8 store i32 0 , i32 * %320 , align 4 br label %3@@ 3@@ 66 33@@ 3@@ 67 %3@@ 3@@ 67 = load i32 , i32 * %320 , align 4 %3@@ 3@@ 68 = icmp slt i32 %3@@ 3@@ 67 , 1 br i1 %3@@ 3@@ 68 , label %3@@ 369 , label %3@@ 369 33@@ 370 %3@@ 370 = load i32 , i32 * %320 , align 4 %3@@ 3@@ 71 = sext i32 %3@@ 370 to i64 %3@@ 372 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %318 , i64 0 , i64 %33 store i64 -10 , i64 * %3@@ 372 , align 8 br label %3@@ 3@@ 73 33@@ 374 %3@@ 374 = load i32 , i32 * %320 , align 4 %3@@ 375 = add nsw i32 %3@@ 374 , 1 store i32 %3@@ 375 , i32 * %320 , align 4 br label %3@@ 3@@ 76 33@@ 377 %3@@ 377 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %318 , i64 0 , i64 0 %3@@ 3@@ 78 = load i64 , i64 * %3@@ 377 , align 8 %3@@ 3@@ 79 = add i64 %3@@ 3@@ 78 , 1 store i64 %3@@ 3@@ 79 , i64 * %3@@ 377 , align 8 %3@@ 380 = load i32 * , i32 * * %319 , align 8 %3@@ 38@@ 1 = load i32 * * , i32 * * * @g_5@@ 28 , align 8 store i32 * %3@@ 380 , i32 * * %3@@ 38@@ 1 , align 8 br label %3@@ 3@@ 82 33@@ 383 %3@@ 383 = bitcast [ 8 x i8 ] * %321 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %3@@ 383 , i8 * align 1 getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @__const.func_@@ 3@@ 1.l_@@ 18@@ 22 , i32 0 , i32 0 ) , i64 8 , i1 false ) store i32 0 , i32 * %322 , align 4 store i32 * * getelementptr inbounds ( [ 6 x [ 5 x i32 * ] ] , [ 6 x [ 5 x i32 * ] ] * @g_805 , i64 0 , i64 2 , i64 0 ) , i32 * * * %323 , align 8 %3@@ 384 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 6@@ 32 , i32 0 , i32 0 ) , align 4 %3@@ 38@@ 5 = trunc i32 %3@@ 384 to i16 %3@@ 38@@ 6 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %321 , i64 0 , i64 5 %3@@ 38@@ 7 = load i8 , i8 * %3@@ 38@@ 6 , align 1 %3@@ 388 = load i16 , i16 * @g_@@ 45@@ 4 , align 2 %3@@ 38@@ 9 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %3@@ 38@@ 5 , i16 signext %3@@ 388 ) %3@@ 390 = sext i16 %3@@ 38@@ 9 to i32 %3@@ 39@@ 1 = icmp ne i32 %3@@ 390 , 0 br i1 %3@@ 39@@ 1 , label %3@@ 39@@ 3 , label %3@@ 3@@ 92 32 br label %3@@ 39@@ 3 33@@ 39@@ 4 %3@@ 39@@ 4 = phi i1 [ true , %3@@ 3@@ 82 ] , [ true , %3@@ 3@@ 92 ] %3@@ 395 = zext i1 %3@@ 39@@ 4 to i32 %3@@ 39@@ 6 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 1 %3@@ 39@@ 7 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %303 , i64 0 , i64 9 %3@@ 39@@ 8 = load i32 , i32 * %3@@ 39@@ 7 , align 4 %3@@ 399 = load i32 * , i32 * * %9 , align 8 %3@@ 400 = call i32 * @func_@@ 49 ( i32 * %3@@ 39@@ 6 , i32 %3@@ 39@@ 8 , i32 * %3@@ 399 ) %3@@ 401 = load i32 * * , i32 * * * %323 , align 8 store i32 * %3@@ 400 , i32 * * %3@@ 401 , align 8 %3@@ 402 = load i8 * * , i8 * * * @g_11@@ 85 , align 8 %3@@ 40@@ 3 = load i8 * , i8 * * %3@@ 402 , align 8 %3@@ 40@@ 4 = load i8 , i8 * %3@@ 40@@ 3 , align 1 %3@@ 405 = load i8 , i8 * %235 , align 1 %3@@ 406 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %3@@ 40@@ 4 , i8 zeroext %3@@ 405 ) %3@@ 407 = zext i8 %3@@ 406 to i32 %3@@ 408 = load i32 * , i32 * * %13 , align 8 %3@@ 409 = load i32 , i32 * %3@@ 408 , align 4 %3@@ 4@@ 10 = xor i32 %3@@ 409 , %33 store i32 %3@@ 4@@ 10 , i32 * %3@@ 408 , align 4 %3@@ 4@@ 11 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * %303 , i64 0 , i64 7 %3@@ 4@@ 12 = load i32 * * , i32 * * * %323 , align 8 store i32 * %3@@ 4@@ 11 , i32 * * %3@@ 4@@ 12 , align 8 br label %3@@ 4@@ 13 333 store i32 9 , i32 * %230 , align 4 br label %3@@ 4@@ 14 33@@ 415 %3@@ 415 = load i32 , i32 * %230 , align 4 %3@@ 416 = icmp sge i32 %3@@ 415 , 3 br i1 %3@@ 416 , label %3@@ 4@@ 17 , label %3@@ 4@@ 17 33@@ 4@@ 18 %3@@ 4@@ 18 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %162 , i64 0 , i64 0 store i32 * %3@@ 4@@ 18 , i32 * * %325 , align 8 store i32 * null , i32 * * %326 , align 8 store i32 * %225 , i32 * * %327 , align 8 store i32 * %222 , i32 * * %328 , align 8 store i32 * %161 , i32 * * %329 , align 8 store i32 * %217 , i32 * * %330 , align 8 store i32 * %254 , i32 * * %331 , align 8 store i32 * null , i32 * * %332 , align 8 %3@@ 4@@ 19 = getelementptr inbounds [ 10 x [ 8 x i32 * ] ] , [ 10 x [ 8 x i32 * ] ] * %333 , i64 0 , i64 0 %3@@ 420 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 19 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 420 , align 8 %3@@ 421 = getelementptr inbounds i32 * , i32 * * %3@@ 420 , i64 1 store i32 * %259 , i32 * * %3@@ 421 , align 8 %3@@ 422 = getelementptr inbounds i32 * , i32 * * %3@@ 421 , i64 1 store i32 * %227 , i32 * * %3@@ 422 , align 8 %3@@ 4@@ 23 = getelementptr inbounds i32 * , i32 * * %3@@ 422 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 23 , align 8 %3@@ 4@@ 24 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 23 , i64 1 store i32 * %227 , i32 * * %3@@ 4@@ 24 , align 8 %3@@ 4@@ 25 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 24 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 25 , align 8 %3@@ 4@@ 26 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 25 , i64 1 store i32 * %227 , i32 * * %3@@ 4@@ 26 , align 8 %3@@ 4@@ 27 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 26 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 27 , align 8 %3@@ 4@@ 28 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 19 , i64 1 %3@@ 4@@ 29 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 28 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 4@@ 29 , align 8 %3@@ 4@@ 30 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 29 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 30 , align 8 %3@@ 4@@ 31 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 30 , i64 1 store i32 * %227 , i32 * * %3@@ 4@@ 31 , align 8 %3@@ 432 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 31 , i64 1 store i32 * %259 , i32 * * %3@@ 432 , align 8 %3@@ 433 = getelementptr inbounds i32 * , i32 * * %3@@ 432 , i64 1 store i32 * %227 , i32 * * %3@@ 433 , align 8 %3@@ 434 = getelementptr inbounds i32 * , i32 * * %3@@ 433 , i64 1 store i32 * %259 , i32 * * %3@@ 434 , align 8 %3@@ 4@@ 35 = getelementptr inbounds i32 * , i32 * * %3@@ 434 , i64 1 store i32 * %227 , i32 * * %3@@ 4@@ 35 , align 8 %3@@ 4@@ 36 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 35 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 36 , align 8 %3@@ 4@@ 37 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 28 , i64 1 %3@@ 4@@ 38 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 37 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 4@@ 38 , align 8 %3@@ 4@@ 39 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 38 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 39 , align 8 %3@@ 4@@ 40 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 39 , i64 1 store i32 * %227 , i32 * * %3@@ 4@@ 40 , align 8 %3@@ 441 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 40 , i64 1 store i32 * %259 , i32 * * %3@@ 441 , align 8 %3@@ 442 = getelementptr inbounds i32 * , i32 * * %3@@ 441 , i64 1 store i32 * %227 , i32 * * %3@@ 442 , align 8 %3@@ 443 = getelementptr inbounds i32 * , i32 * * %3@@ 442 , i64 1 store i32 * %259 , i32 * * %3@@ 443 , align 8 %3@@ 444 = getelementptr inbounds i32 * , i32 * * %3@@ 443 , i64 1 store i32 * %227 , i32 * * %3@@ 444 , align 8 %3@@ 4@@ 45 = getelementptr inbounds i32 * , i32 * * %3@@ 444 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 45 , align 8 %3@@ 4@@ 46 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 37 , i64 1 %3@@ 447 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 46 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 447 , align 8 %3@@ 448 = getelementptr inbounds i32 * , i32 * * %3@@ 447 , i64 1 store i32 * %259 , i32 * * %3@@ 448 , align 8 %3@@ 449 = getelementptr inbounds i32 * , i32 * * %3@@ 448 , i64 1 store i32 * %227 , i32 * * %3@@ 449 , align 8 %3@@ 450 = getelementptr inbounds i32 * , i32 * * %3@@ 449 , i64 1 store i32 * %259 , i32 * * %3@@ 450 , align 8 %3@@ 45@@ 1 = getelementptr inbounds i32 * , i32 * * %3@@ 450 , i64 1 store i32 * %227 , i32 * * %3@@ 45@@ 1 , align 8 %3@@ 452 = getelementptr inbounds i32 * , i32 * * %3@@ 45@@ 1 , i64 1 store i32 * %259 , i32 * * %3@@ 452 , align 8 %3@@ 453 = getelementptr inbounds i32 * , i32 * * %3@@ 452 , i64 1 store i32 * %227 , i32 * * %3@@ 453 , align 8 %3@@ 45@@ 4 = getelementptr inbounds i32 * , i32 * * %3@@ 453 , i64 1 store i32 * %259 , i32 * * %3@@ 45@@ 4 , align 8 %3@@ 455 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 46 , i64 1 %3@@ 456 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 455 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 456 , align 8 %3@@ 457 = getelementptr inbounds i32 * , i32 * * %3@@ 456 , i64 1 store i32 * %259 , i32 * * %3@@ 457 , align 8 %3@@ 45@@ 8 = getelementptr inbounds i32 * , i32 * * %3@@ 457 , i64 1 store i32 * %227 , i32 * * %3@@ 45@@ 8 , align 8 %3@@ 45@@ 9 = getelementptr inbounds i32 * , i32 * * %3@@ 45@@ 8 , i64 1 store i32 * %259 , i32 * * %3@@ 45@@ 9 , align 8 %3@@ 460 = getelementptr inbounds i32 * , i32 * * %3@@ 45@@ 9 , i64 1 store i32 * %227 , i32 * * %3@@ 460 , align 8 %3@@ 4@@ 61 = getelementptr inbounds i32 * , i32 * * %3@@ 460 , i64 1 store i32 * %259 , i32 * * %3@@ 4@@ 61 , align 8 %3@@ 462 = getelementptr inbounds i32 * , i32 * * %3@@ 4@@ 61 , i64 1 store i32 * %227 , i32 * * %3@@ 462 , align 8 %3@@ 463 = getelementptr inbounds i32 * , i32 * * %3@@ 462 , i64 1 store i32 * %259 , i32 * * %3@@ 463 , align 8 %3@@ 4@@ 64 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 455 , i64 1 %3@@ 465 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 64 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 465 , align 8 %3@@ 466 = getelementptr inbounds i32 * , i32 * * %3@@ 465 , i64 1 store i32 * %259 , i32 * * %3@@ 466 , align 8 %3@@ 46@@ 7 = getelementptr inbounds i32 * , i32 * * %3@@ 466 , i64 1 store i32 * %227 , i32 * * %3@@ 46@@ 7 , align 8 %3@@ 46@@ 8 = getelementptr inbounds i32 * , i32 * * %3@@ 46@@ 7 , i64 1 store i32 * %259 , i32 * * %3@@ 46@@ 8 , align 8 %3@@ 46@@ 9 = getelementptr inbounds i32 * , i32 * * %3@@ 46@@ 8 , i64 1 store i32 * %227 , i32 * * %3@@ 46@@ 9 , align 8 %3@@ 470 = getelementptr inbounds i32 * , i32 * * %3@@ 46@@ 9 , i64 1 store i32 * %259 , i32 * * %3@@ 470 , align 8 %3@@ 471 = getelementptr inbounds i32 * , i32 * * %3@@ 470 , i64 1 store i32 * %227 , i32 * * %3@@ 471 , align 8 %3@@ 472 = getelementptr inbounds i32 * , i32 * * %3@@ 471 , i64 1 store i32 * %259 , i32 * * %3@@ 472 , align 8 %3@@ 473 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 4@@ 64 , i64 1 %3@@ 47@@ 4 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 473 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 47@@ 4 , align 8 %3@@ 47@@ 5 = getelementptr inbounds i32 * , i32 * * %3@@ 47@@ 4 , i64 1 store i32 * %259 , i32 * * %3@@ 47@@ 5 , align 8 %3@@ 476 = getelementptr inbounds i32 * , i32 * * %3@@ 47@@ 5 , i64 1 store i32 * %227 , i32 * * %3@@ 476 , align 8 %3@@ 47@@ 7 = getelementptr inbounds i32 * , i32 * * %3@@ 476 , i64 1 store i32 * %259 , i32 * * %3@@ 47@@ 7 , align 8 %3@@ 478 = getelementptr inbounds i32 * , i32 * * %3@@ 47@@ 7 , i64 1 store i32 * %227 , i32 * * %3@@ 478 , align 8 %3@@ 479 = getelementptr inbounds i32 * , i32 * * %3@@ 478 , i64 1 store i32 * %259 , i32 * * %3@@ 479 , align 8 %3@@ 480 = getelementptr inbounds i32 * , i32 * * %3@@ 479 , i64 1 store i32 * %227 , i32 * * %3@@ 480 , align 8 %3@@ 48@@ 1 = getelementptr inbounds i32 * , i32 * * %3@@ 480 , i64 1 store i32 * %259 , i32 * * %3@@ 48@@ 1 , align 8 %3@@ 482 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 473 , i64 1 %3@@ 48@@ 3 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 482 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 48@@ 3 , align 8 %3@@ 484 = getelementptr inbounds i32 * , i32 * * %3@@ 48@@ 3 , i64 1 store i32 * %259 , i32 * * %3@@ 484 , align 8 %3@@ 48@@ 5 = getelementptr inbounds i32 * , i32 * * %3@@ 484 , i64 1 store i32 * %227 , i32 * * %3@@ 48@@ 5 , align 8 %3@@ 48@@ 6 = getelementptr inbounds i32 * , i32 * * %3@@ 48@@ 5 , i64 1 store i32 * %259 , i32 * * %3@@ 48@@ 6 , align 8 %3@@ 487 = getelementptr inbounds i32 * , i32 * * %3@@ 48@@ 6 , i64 1 store i32 * %227 , i32 * * %3@@ 487 , align 8 %3@@ 488 = getelementptr inbounds i32 * , i32 * * %3@@ 487 , i64 1 store i32 * %259 , i32 * * %3@@ 488 , align 8 %3@@ 48@@ 9 = getelementptr inbounds i32 * , i32 * * %3@@ 488 , i64 1 store i32 * %227 , i32 * * %3@@ 48@@ 9 , align 8 %3@@ 490 = getelementptr inbounds i32 * , i32 * * %3@@ 48@@ 9 , i64 1 store i32 * %259 , i32 * * %3@@ 490 , align 8 %3@@ 491 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 482 , i64 1 %3@@ 492 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 491 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 492 , align 8 %3@@ 49@@ 3 = getelementptr inbounds i32 * , i32 * * %3@@ 492 , i64 1 store i32 * %259 , i32 * * %3@@ 49@@ 3 , align 8 %3@@ 494 = getelementptr inbounds i32 * , i32 * * %3@@ 49@@ 3 , i64 1 store i32 * %227 , i32 * * %3@@ 494 , align 8 %3@@ 49@@ 5 = getelementptr inbounds i32 * , i32 * * %3@@ 494 , i64 1 store i32 * %259 , i32 * * %3@@ 49@@ 5 , align 8 %3@@ 496 = getelementptr inbounds i32 * , i32 * * %3@@ 49@@ 5 , i64 1 store i32 * %227 , i32 * * %3@@ 496 , align 8 %3@@ 49@@ 7 = getelementptr inbounds i32 * , i32 * * %3@@ 496 , i64 1 store i32 * %259 , i32 * * %3@@ 49@@ 7 , align 8 %3@@ 498 = getelementptr inbounds i32 * , i32 * * %3@@ 49@@ 7 , i64 1 store i32 * %227 , i32 * * %3@@ 498 , align 8 %3@@ 499 = getelementptr inbounds i32 * , i32 * * %3@@ 498 , i64 1 store i32 * %259 , i32 * * %3@@ 499 , align 8 %3@@ 500 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 491 , i64 1 %3@@ 501 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %3@@ 500 , i64 0 , i64 0 store i32 * %227 , i32 * * %3@@ 501 , align 8 %3@@ 50@@ 2 = getelementptr inbounds i32 * , i32 * * %3@@ 501 , i64 1 store i32 * %259 , i32 * * %3@@ 50@@ 2 , align 8 %3@@ 5@@ 03 = getelementptr inbounds i32 * , i32 * * %3@@ 50@@ 2 , i64 1 store i32 * %227 , i32 * * %3@@ 5@@ 03 , align 8 %3@@ 504 = getelementptr inbounds i32 * , i32 * * %3@@ 5@@ 03 , i64 1 store i32 * %259 , i32 * * %3@@ 504 , align 8 %3@@ 5@@ 05 = getelementptr inbounds i32 * , i32 * * %3@@ 504 , i64 1 store i32 * %227 , i32 * * %3@@ 5@@ 05 , align 8 %3@@ 5@@ 06 = getelementptr inbounds i32 * , i32 * * %3@@ 5@@ 05 , i64 1 store i32 * %259 , i32 * * %3@@ 5@@ 06 , align 8 %3@@ 5@@ 07 = getelementptr inbounds i32 * , i32 * * %3@@ 5@@ 06 , i64 1 store i32 * %227 , i32 * * %3@@ 5@@ 07 , align 8 %3@@ 5@@ 08 = getelementptr inbounds i32 * , i32 * * %3@@ 5@@ 07 , i64 1 store i32 * %259 , i32 * * %3@@ 5@@ 08 , align 8 %3@@ 509 = load i8 , i8 * %236 , align 1 %3@@ 510 = add i8 %3@@ 509 , -1 store i8 %3@@ 510 , i8 * %236 , align 1 br label %3@@ 5@@ 11 335@@ 12 %3@@ 512 = load i32 , i32 * %230 , align 4 %3@@ 5@@ 13 = sub nsw i32 %3@@ 512 , 1 store i32 %3@@ 5@@ 13 , i32 * %230 , align 4 br label %3@@ 5@@ 14 32 br label %3@@ 5@@ 15 335@@ 16 %3@@ 5@@ 16 = load i8 , i8 * @g_1@@ 402 , align 1 %3@@ 517 = zext i8 %3@@ 5@@ 16 to i32 %3@@ 5@@ 18 = add nsw i32 %3@@ 517 , 1 %3@@ 5@@ 19 = trunc i32 %3@@ 5@@ 18 to i8 store i8 %3@@ 5@@ 19 , i8 * @g_1@@ 402 , align 1 br label %3@@ 5@@ 20 32 br label %3@@ 521 335@@ 22 %3@@ 5@@ 22 = load i32 , i32 * @g_9@@ 88 , align 4 %3@@ 5@@ 23 = add i32 %3@@ 5@@ 22 , 1 store i32 %3@@ 5@@ 23 , i32 * @g_9@@ 88 , align 4 br label %3@@ 5@@ 24 333 store i16 -7 , i16 * @g_11@@ 89 , align 2 br label %3@@ 525 335@@ 26 %3@@ 5@@ 26 = load i16 , i16 * @g_11@@ 89 , align 2 %3@@ 5@@ 27 = zext i16 %3@@ 5@@ 26 to i32 %3@@ 5@@ 28 = icmp sge i32 %3@@ 5@@ 27 , 6 br i1 %3@@ 5@@ 28 , label %3@@ 5@@ 29 , label %3@@ 5@@ 29 33530 %3@@ 5@@ 30 = load i32 , i32 * %8 , align 4 %3@@ 5@@ 31 = sext i32 %3@@ 5@@ 30 to i64 store i64 %3@@ 5@@ 31 , i64 * %5 , align 8 br label %3@@ 5@@ 32 335@@ 33 %3@@ 533 = load i16 , i16 * @g_11@@ 89 , align 2 %3@@ 5@@ 34 = zext i16 %3@@ 533 to i32 %3@@ 5@@ 35 = call i32 @safe_add_func_int32_t_s_s ( i32 %3@@ 5@@ 34 , i32 4 ) %3@@ 5@@ 36 = trunc i32 %3@@ 5@@ 35 to i16 store i16 %3@@ 5@@ 36 , i16 * @g_11@@ 89 , align 2 br label %3@@ 5@@ 37 335@@ 38 %3@@ 5@@ 38 = load i64 , i64 * %172 , align 8 %3@@ 539 = add i64 %3@@ 5@@ 38 , -1 store i64 %3@@ 539 , i64 * %172 , align 8 br label %3@@ 540 335@@ 41 %3@@ 5@@ 41 = load i32 , i32 * %8 , align 4 %3@@ 5@@ 42 = sext i32 %3@@ 5@@ 41 to i64 store i64 %3@@ 5@@ 42 , i64 * %5 , align 8 br label %3@@ 5@@ 43 335@@ 44 %3@@ 5@@ 44 = load i64 * , i64 * * @g_4@@ 10 , align 8 %3@@ 5@@ 45 = load i64 , i64 * %3@@ 5@@ 44 , align 8 store i64 %3@@ 5@@ 45 , i64 * %5 , align 8 br label %3@@ 5@@ 46 335@@ 47 %3@@ 5@@ 47 = load i64 , i64 * %5 , align 8 ret i64 %3@@ 5@@ 47 }
define internal i32 * @func_@@ 53 ( i32 * %0 , i32 * %1 , i32 %2 ) #0 { %4 = alloca i32 * , align 8 %5 = alloca i32 * , align 8 %6 = alloca i32 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 * * , align 8 %9 = alloca i32 * * * , align 8 %10 = alloca i32 * , align 8 %11 = alloca i32 * , align 8 %12 = alloca i16 , align 2 %13 = alloca i16 , align 2 %14 = alloca i8 * , align 8 %15 = alloca [ 2 x i32 * * ] , align 16 %16 = alloca [ 10 x i64 ] , align 16 %17 = alloca i32 , align 4 %18 = alloca [ 8 x i8 ] , align 1 %19 = alloca [ 4 x [ 5 x [ 2 x i8 ] ] ] , align 16 %20 = alloca [ 4 x [ 9 x [ 5 x i32 ] ] ] , align 16 %21 = alloca [ 8 x [ 8 x i32 * ] ] , align 16 %22 = alloca i16 * , align 8 %23 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %24 = alloca [ 10 x [ 4 x %un@@ ion.@@ U@@ 1 * * ] ] , align 16 %25 = alloca i32 , align 4 %26 = alloca i64 , align 8 %27 = alloca i32 , align 4 %28 = alloca i64 * , align 8 %29 = alloca i64 * * , align 8 %30 = alloca i32 , align 4 %31 = alloca i32 , align 4 %32 = alloca i32 , align 4 %33 = alloca i32 * , align 8 %34 = alloca i8 * , align 8 %35 = alloca i32 * , align 8 %36 = alloca i16 * , align 8 %37 = alloca [ 4 x [ 2 x i32 ] ] , align 16 %38 = alloca i32 , align 4 %39 = alloca i32 , align 4 %40 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %41 = alloca i32 , align 4 %42 = alloca [ 4 x i64 ] , align 16 %43 = alloca i32 * * , align 8 %44 = alloca [ 9 x i32 * * * ] , align 16 %45 = alloca i32 , align 4 %46 = alloca [ 9 x [ 1 x i32 * ] ] , align 16 %47 = alloca [ 9 x i64 * ] , align 16 %48 = alloca [ 4 x i8 * ] , align 16 %49 = alloca i16 * , align 8 %50 = alloca i32 , align 4 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca i8 , align 1 %54 = alloca i64 * , align 8 %55 = alloca i64 * , align 8 %56 = alloca i32 , align 4 %57 = alloca i8 , align 1 %58 = alloca [ 2 x [ 4 x i32 ] ] , align 16 %59 = alloca i8 * , align 8 %60 = alloca i8 * * , align 8 %61 = alloca i8 * , align 8 %62 = alloca [ 7 x [ 10 x %@@ struct@@ .@@ S@@ 0 ] ] , align 16 %63 = alloca i16 , align 2 %64 = alloca i16 * , align 8 %65 = alloca i32 , align 4 %66 = alloca i32 , align 4 %67 = alloca i32 , align 4 %68 = alloca i8 , align 1 %69 = alloca i32 * * * * , align 8 %70 = alloca i32 , align 4 %71 = alloca %@@ struct@@ .@@ S@@ 0 , align 2 %72 = alloca %un@@ ion.@@ U@@ 1 , align 4 %73 = alloca i64 * * * , align 8 store i32 * %0 , i32 * * %5 , align 8 store i32 * %1 , i32 * * %6 , align 8 store i32 %2 , i32 * %7 , align 4 store i32 * * null , i32 * * * %8 , align 8 store i32 * * * %8 , i32 * * * * %9 , align 8 store i32 * @g_@@ 24 , i32 * * %10 , align 8 store i32 * @g_@@ 65 , i32 * * %11 , align 8 store i16 16@@ 2@@ 67 , i16 * %12 , align 2 store i16 280@@ 67 , i16 * %13 , align 2 store i8 * @g_1@@ 59 , i8 * * %14 , align 8 %74 = bitcast [ 10 x i64 ] * %16 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %74 , i8 * align 16 bitcast ( [ 10 x i64 ] * @__const.func_@@ 53@@ .l_@@ 295 to i8 * ) , i64 80 , i1 false ) store i32 0 , i32 * %17 , align 4 br label %75 7@@ 76 %76 = load i32 , i32 * %17 , align 4 %77 = icmp slt i32 %76 , 2 br i1 %77 , label %78 , label %78 7@@ 79 %79 = load i32 , i32 * %17 , align 4 %80 = sext i32 %79 to i64 %81 = getelementptr inbounds [ 2 x i32 * * ] , [ 2 x i32 * * ] * %15 , i64 0 , i64 %33 store i32 * * %11 , i32 * * * %81 , align 8 br label %82 883 %83 = load i32 , i32 * %17 , align 4 %84 = add nsw i32 %83 , 1 store i32 %84 , i32 * %17 , align 4 br label %85 82 br label %86 887 %87 = load i32 * * * , i32 * * * * %9 , align 8 %88 = load volatile i32 * * * * , i32 * * * * * @g_1@@ 03 , align 8 store i32 * * * %87 , i32 * * * * %88 , align 8 store i64 0 , i64 * @g_@@ 95 , align 8 br label %89 8@@ 90 %90 = load i64 , i64 * @g_@@ 95 , align 8 %91 = icmp sgt i64 %90 , 17 br i1 %91 , label %92 , label %92 9@@ 93 %93 = bitcast [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %93 , i8 * align 16 getelementptr inbounds ( [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * @__const.func_@@ 53@@ .l_@@ 126 , i32 0 , i32 0 , i32 0 , i32 0 ) , i64 40 , i1 false ) %94 = bitcast [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %94 , i8 * align 16 bitcast ( [ 4 x [ 9 x [ 5 x i32 ] ] ] * @__const.func_@@ 53@@ .l_@@ 138 to i8 * ) , i64 720 , i1 false ) %95 = bitcast [ 8 x [ 8 x i32 * ] ] * %21 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %95 , i8 * align 16 bitcast ( [ 8 x [ 8 x i32 * ] ] * @__const.func_@@ 53@@ .l_@@ 1@@ 41 to i8 * ) , i64 512 , i1 false ) store i16 * @g_1@@ 57 , i16 * * %22 , align 8 store %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , %un@@ ion.@@ U@@ 1 * * %23 , align 8 %96 = getelementptr inbounds [ 10 x [ 4 x %un@@ ion.@@ U@@ 1 * * ] ] , [ 10 x [ 4 x %un@@ ion.@@ U@@ 1 * * ] ] * %24 , i64 0 , i64 0 %97 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %96 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %97 , align 8 %98 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %97 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %98 , align 8 %99 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %98 , i64 1 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %99 , align 8 %100 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %99 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %100 , align 8 %101 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %96 , i64 1 %102 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %101 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %102 , align 8 %103 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %102 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %103 , align 8 %104 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %103 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %104 , align 8 %105 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %104 , i64 1 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %105 , align 8 %106 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %101 , i64 1 %107 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %106 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %107 , align 8 %108 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %107 , i64 1 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %108 , align 8 %109 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %108 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %109 , align 8 %110 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %109 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %110 , align 8 %111 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %106 , i64 1 %112 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %111 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %112 , align 8 %113 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %112 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %113 , align 8 %114 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %113 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %114 , align 8 %115 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %114 , i64 1 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %115 , align 8 %116 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %111 , i64 1 %117 = bitcast [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %116 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 16 %117 , i8 0 , i64 32 , i1 false ) %118 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %116 , i64 0 , i64 0 %119 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %118 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %119 , align 8 %120 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %119 , i64 1 %121 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %120 , i64 1 %122 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %116 , i64 1 %123 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %122 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %123 , align 8 %124 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %123 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %124 , align 8 %125 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %124 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %125 , align 8 %126 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %125 , i64 1 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %126 , align 8 %127 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %122 , i64 1 %128 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %127 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %128 , align 8 %129 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %128 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %129 , align 8 %130 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %129 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %130 , align 8 %131 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %130 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %131 , align 8 %132 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %127 , i64 1 %133 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %132 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %133 , align 8 %134 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %133 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %134 , align 8 %135 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %134 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %135 , align 8 %136 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %135 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %136 , align 8 %137 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %132 , i64 1 %138 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %137 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %138 , align 8 %139 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %138 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %139 , align 8 %140 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %139 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %140 , align 8 %141 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %140 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %141 , align 8 %142 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %137 , i64 1 %143 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %142 , i64 0 , i64 0 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %143 , align 8 %144 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %143 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %144 , align 8 %145 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %144 , i64 1 store %un@@ ion.@@ U@@ 1 * * %23 , %un@@ ion.@@ U@@ 1 * * * %145 , align 8 %146 = getelementptr inbounds %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %145 , i64 1 store %un@@ ion.@@ U@@ 1 * * null , %un@@ ion.@@ U@@ 1 * * * %146 , align 8 store i32 -1 , i32 * %25 , align 4 store i64 1 , i64 * %26 , align 8 store i32 9 , i32 * %27 , align 4 store i64 * %26 , i64 * * %28 , align 8 store i64 * * %28 , i64 * * * %29 , align 8 store i32 0 , i32 * %30 , align 4 br label %147 1148 %148 = load i32 , i32 * %30 , align 4 %149 = icmp slt i32 %148 , 8 br i1 %149 , label %150 , label %150 11@@ 51 %151 = load i32 , i32 * %30 , align 4 %152 = sext i32 %151 to i64 %153 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %18 , i64 0 , i64 %33 store i8 49 , i8 * %153 , align 1 br label %154 11@@ 55 %155 = load i32 , i32 * %30 , align 4 %156 = add nsw i32 %155 , 1 store i32 %156 , i32 * %30 , align 4 br label %157 133 store i16 11 , i16 * @g_@@ 86 , align 2 br label %158 11@@ 59 %159 = load i16 , i16 * @g_@@ 86 , align 2 %160 = sext i16 %159 to i32 %161 = icmp sge i32 %160 , -10 br i1 %161 , label %162 , label %162 133 store i32 * @g_@@ 65 , i32 * * %33 , align 8 store i8 * @g_11@@ 5 , i8 * * %34 , align 8 store i32 * getelementptr inbounds ( [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 1 , i64 0 ) , i32 * * %35 , align 8 store i16 * @g_1@@ 28 , i16 * * %36 , align 8 %163 = bitcast [ 4 x [ 2 x i32 ] ] * %37 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %163 , i8 * align 16 bitcast ( [ 4 x [ 2 x i32 ] ] * @__const.func_@@ 53@@ .l_@@ 129 to i8 * ) , i64 32 , i1 false ) %164 = load i32 , i32 * %7 , align 4 %165 = load i64 , i64 * @g_@@ 95 , align 8 %166 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %18 , i64 0 , i64 2 %167 = load i8 , i8 * %166 , align 1 %168 = load i32 * , i32 * * %5 , align 8 %169 = load i32 , i32 * %168 , align 4 %170 = load i32 * , i32 * * %33 , align 8 store i32 %169 , i32 * %170 , align 4 %171 = sext i32 %169 to i64 %172 = load i32 , i32 * %7 , align 4 %173 = load i8 * , i8 * * %34 , align 8 %174 = load i8 , i8 * %173 , align 1 %175 = sext i8 %174 to i32 %176 = xor i32 %175 , %177 %177 = trunc i32 %176 to i8 store i8 %177 , i8 * %173 , align 1 %178 = load i32 * , i32 * * %35 , align 8 %179 = load i32 , i32 * %178 , align 4 %180 = add i32 %179 , 1 store i32 %180 , i32 * %178 , align 4 %181 = trunc i32 %180 to i8 store i8 %181 , i8 * @g_1@@ 20 , align 1 %182 = sext i8 %181 to i32 %183 = load i64 , i64 * @g_@@ 95 , align 8 %184 = icmp sle i64 %183 , 38@@ 97@@ 86@@ 8139@@ 48@@ 309@@ 15@@ 80 %185 = zext i1 %184 to i32 %186 = sext i32 %185 to i64 %187 = load i32 , i32 * @g_@@ 24 , align 4 %188 = sext i32 %187 to i64 %189 = call i64 @safe_mod_func_int64_t_s_s ( i64 %186 , i64 %188 ) %190 = load i32 , i32 * %7 , align 4 %191 = trunc i32 %190 to i8 %192 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %193 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %192 , i64 0 , i64 2 %194 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %193 , i64 0 , i64 0 %195 = load i8 , i8 * %194 , align 2 %196 = zext i8 %195 to i32 %197 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %191 , i32 %196 ) %198 = icmp ne i8 %197 , 0 br i1 %198 , label %202 , label %199 1200 %200 = load i64 , i64 * @g_@@ 95 , align 8 %201 = icmp ne i64 %200 , 0 br label %202 2203 %203 = phi i1 [ false , %162 ] , [ %201 , %199 ] %204 = zext i1 %203 to i32 %205 = load i16 * , i16 * * %36 , align 8 %206 = load i16 , i16 * %205 , align 2 %207 = sext i16 %206 to i64 %208 = and i64 %207 , -2 %209 = trunc i64 %208 to i16 store i16 %209 , i16 * %205 , align 2 %210 = sext i16 %209 to i32 %211 = load i16 , i16 * @g_@@ 86 , align 2 %212 = sext i16 %211 to i32 %213 = icmp ne i32 %210 , %214 %214 = zext i1 %213 to i32 %215 = sext i32 %214 to i64 %216 = icmp slt i64 %189 , %217 %217 = zext i1 %216 to i32 %218 = icmp ne i32 %182 , %219 %219 = zext i1 %218 to i32 %220 = sext i32 %219 to i64 %221 = icmp sgt i64 %220 , 82 %222 = zext i1 %221 to i32 %223 = load i32 , i32 * %7 , align 4 %224 = icmp sgt i32 %222 , %225 %225 = zext i1 %224 to i32 %226 = trunc i32 %225 to i8 %227 = call signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %177 , i8 signext %226 ) %228 = sext i8 %227 to i32 %229 = load i16 , i16 * @g_@@ 86 , align 2 %230 = sext i16 %229 to i32 %231 = icmp sle i32 %228 , %232 %232 = zext i1 %231 to i32 %233 = icmp slt i64 %171 , -1 %234 = zext i1 %233 to i32 %235 = getelementptr inbounds [ 4 x [ 2 x i32 ] ] , [ 4 x [ 2 x i32 ] ] * %37 , i64 0 , i64 3 %236 = getelementptr inbounds [ 2 x i32 ] , [ 2 x i32 ] * %235 , i64 0 , i64 0 store i32 %234 , i32 * %236 , align 8 br label %237 22@@ 38 %238 = load i16 , i16 * @g_@@ 86 , align 2 %239 = sext i16 %238 to i32 %240 = call i32 @safe_sub_func_int32_t_s_s ( i32 %239 , i32 9 ) %241 = trunc i32 %240 to i16 store i16 %241 , i16 * @g_@@ 86 , align 2 br label %242 22@@ 43 %243 = load i16 , i16 * @g_1@@ 28 , align 2 %244 = icmp ne i16 %243 , 0 br i1 %244 , label %245 , label %245 22 br label %246 22@@ 47 %247 = load volatile %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * @g_1@@ 30 , align 8 %248 = load volatile %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * @g_1@@ 33 , align 8 store volatile %un@@ ion.@@ U@@ 1 * %247 , %un@@ ion.@@ U@@ 1 * * %248 , align 8 %249 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %250 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %249 , i64 0 , i64 1 %251 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %250 , i64 0 , i64 0 %252 = load i8 , i8 * %251 , align 2 %253 = zext i8 %252 to i32 %254 = icmp ne i32 %253 , 0 br i1 %254 , label %256 , label %255 22 br label %256 22@@ 57 %257 = phi i1 [ true , %246 ] , [ true , %255 ] %258 = zext i1 %257 to i32 %259 = load i32 , i32 * %7 , align 4 %260 = icmp eq i32 %258 , %2 br i1 %260 , label %261 , label %261 22@@ 62 %262 = bitcast %@@ struct@@ .@@ S@@ 0 * %40 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %262 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 53@@ .l_@@ 136 to i8 * ) , i64 2 , i1 false ) store i32 -1 , i32 * %41 , align 4 store i32 * * @g_2@@ 3 , i32 * * * %43 , align 8 %263 = bitcast [ 9 x i32 * * * ] * %44 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 16 %263 , i8 0 , i64 72 , i1 false ) store i32 0 , i32 * %45 , align 4 br label %264 22@@ 65 %265 = load i32 , i32 * %45 , align 4 %266 = icmp slt i32 %265 , 4 br i1 %266 , label %267 , label %267 22@@ 68 %268 = load i32 , i32 * %45 , align 4 %269 = sext i32 %268 to i64 %270 = getelementptr inbounds [ 4 x i64 ] , [ 4 x i64 ] * %42 , i64 0 , i64 %33 store i64 82@@ 760@@ 11@@ 4679@@ 50@@ 35@@ 80@@ 40 , i64 * %270 , align 8 br label %271 22@@ 72 %272 = load i32 , i32 * %45 , align 4 %273 = add nsw i32 %272 , 1 store i32 %273 , i32 * %45 , align 4 br label %274 233 store i32 0 , i32 * %7 , align 4 br label %275 22@@ 76 %276 = load i32 , i32 * %7 , align 4 %277 = icmp sle i32 %276 , 7 br i1 %277 , label %278 , label %278 2279 %279 = bitcast [ 9 x [ 1 x i32 * ] ] * %46 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %279 , i8 * align 16 bitcast ( [ 9 x [ 1 x i32 * ] ] * @__const.func_@@ 53@@ .l_@@ 1@@ 37 to i8 * ) , i64 72 , i1 false ) %280 = bitcast [ 9 x i64 * ] * %47 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %280 , i8 * align 16 bitcast ( [ 9 x i64 * ] * @__const.func_@@ 53@@ .l_@@ 1@@ 42 to i8 * ) , i64 72 , i1 false ) %281 = getelementptr inbounds [ 4 x i8 * ] , [ 4 x i8 * ] * %48 , i64 0 , i64 0 %282 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %283 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %282 , i64 0 , i64 2 %284 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %283 , i64 0 , i64 0 store i8 * %284 , i8 * * %281 , align 8 %285 = getelementptr inbounds i8 * , i8 * * %281 , i64 1 %286 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %287 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %286 , i64 0 , i64 2 %288 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %287 , i64 0 , i64 0 store i8 * %288 , i8 * * %285 , align 8 %289 = getelementptr inbounds i8 * , i8 * * %285 , i64 1 %290 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %291 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %290 , i64 0 , i64 2 %292 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %291 , i64 0 , i64 0 store i8 * %292 , i8 * * %289 , align 8 %293 = getelementptr inbounds i8 * , i8 * * %289 , i64 1 %294 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %295 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %294 , i64 0 , i64 2 %296 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %295 , i64 0 , i64 0 store i8 * %296 , i8 * * %293 , align 8 store i16 * @g_1@@ 57 , i16 * * %49 , align 8 store i32 -149@@ 38@@ 216@@ 37 , i32 * %50 , align 4 %297 = load i32 * , i32 * * %10 , align 8 %298 = icmp eq i32 * %297 , %299 %299 = zext i1 %298 to i32 %300 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 1 %301 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %300 , i64 0 , i64 3 %302 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %301 , i64 0 , i64 3 store i32 %299 , i32 * %302 , align 4 %303 = load i8 , i8 * @g_11@@ 5 , align 1 %304 = sext i8 %303 to i32 %305 = getelementptr inbounds [ 8 x [ 8 x i32 * ] ] , [ 8 x [ 8 x i32 * ] ] * %21 , i64 0 , i64 7 %306 = getelementptr inbounds [ 8 x i32 * ] , [ 8 x i32 * ] * %305 , i64 0 , i64 2 %307 = load i32 * , i32 * * %306 , align 16 %308 = icmp eq i32 * %307 , null %309 = zext i1 %308 to i32 %310 = icmp eq i32 %304 , %311 %311 = zext i1 %310 to i32 %312 = sext i32 %311 to i64 %313 = load i8 , i8 * @g_11@@ 5 , align 1 %314 = sext i8 %313 to i64 store i64 %314 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 1 ) , align 8 %315 = icmp sgt i64 %312 , %316 %316 = zext i1 %315 to i32 %317 = trunc i32 %316 to i8 %318 = getelementptr inbounds [ 9 x [ 1 x i32 * ] ] , [ 9 x [ 1 x i32 * ] ] * %46 , i64 0 , i64 1 %319 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %318 , i64 0 , i64 0 %320 = load i32 * , i32 * * %319 , align 8 %321 = load i32 * , i32 * * %11 , align 8 %322 = icmp ne i32 * %320 , %323 %323 = zext i1 %322 to i32 %324 = icmp eq i32 * %7 , %325 %325 = zext i1 %324 to i32 %326 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %317 , i32 %325 ) %327 = zext i8 %326 to i32 %328 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 6 ) , align 8 %329 = add i32 %328 , 1 store i32 %329 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 6 ) , align 8 %330 = icmp ule i32 %327 , %331 %331 = zext i1 %330 to i32 %332 = sext i32 %331 to i64 %333 = or i64 %332 , 8 %334 = load i32 * , i32 * * %11 , align 8 %335 = load i32 , i32 * %334 , align 4 %336 = sext i32 %335 to i64 %337 = and i64 %336 , %338 %338 = trunc i64 %337 to i32 store i32 %338 , i32 * %334 , align 4 %339 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 1 %340 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %339 , i64 0 , i64 3 %341 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %340 , i64 0 , i64 0 %342 = load i32 , i32 * %341 , align 4 %343 = or i32 %342 , %33 store i32 %343 , i32 * %341 , align 4 %344 = load i16 * , i16 * * %49 , align 8 store i16 30@@ 76@@ 5 , i16 * %344 , align 2 %345 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %346 = icmp ne i8 * %345 , null %347 = zext i1 %346 to i32 %348 = trunc i32 %347 to i16 %349 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext 30@@ 76@@ 5 , i16 zeroext %348 ) %350 = icmp ne i16 %349 , 0 br i1 %350 , label %351 , label %351 333 store i8 1 , i8 * %53 , align 1 store i64 * null , i64 * * %54 , align 8 store i64 * @g_1@@ 80 , i64 * * %55 , align 8 %352 = load i8 , i8 * %53 , align 1 %353 = sext i8 %352 to i32 %354 = load i16 * , i16 * * %22 , align 8 %355 = icmp ne i16 * null , %356 %356 = zext i1 %355 to i32 %357 = or i32 %353 , %358 %358 = load i32 , i32 * %7 , align 4 %359 = and i32 %357 , %360 %360 = trunc i32 %359 to i8 %361 = load i32 , i32 * %7 , align 4 %362 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 1 %363 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %362 , i64 0 , i64 3 %364 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %363 , i64 0 , i64 3 %365 = icmp eq i32 * %7 , %366 %366 = zext i1 %365 to i32 %367 = trunc i32 %366 to i8 %368 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %360 , i8 signext %367 ) %369 = sext i8 %368 to i32 %370 = load i32 , i32 * %50 , align 4 %371 = zext i32 %370 to i64 %372 = and i64 11 , %373 %373 = trunc i64 %372 to i16 %374 = load i8 , i8 * @g_1@@ 20 , align 1 %375 = sext i8 %374 to i16 %376 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %373 , i16 signext %375 ) %377 = sext i16 %376 to i32 %378 = icmp sle i32 %369 , %379 %379 = zext i1 %378 to i32 %380 = sext i32 %379 to i64 %381 = icmp slt i64 1@@ 205@@ 45@@ 7@@ 118 , %382 %382 = zext i1 %381 to i32 %383 = load i32 , i32 * %7 , align 4 %384 = sext i32 %383 to i64 %385 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %18 , i64 0 , i64 %386 %386 = load i8 , i8 * %385 , align 1 %387 = sext i8 %386 to i32 %388 = xor i32 %387 , %389 %389 = trunc i32 %388 to i8 store i8 %389 , i8 * %385 , align 1 %390 = sext i8 %389 to i32 %391 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 7 ) , align 4 %392 = icmp ugt i32 %390 , %393 %393 = zext i1 %392 to i32 %394 = getelementptr inbounds [ 10 x [ 4 x %un@@ ion.@@ U@@ 1 * * ] ] , [ 10 x [ 4 x %un@@ ion.@@ U@@ 1 * * ] ] * %24 , i64 0 , i64 6 %395 = getelementptr inbounds [ 4 x %un@@ ion.@@ U@@ 1 * * ] , [ 4 x %un@@ ion.@@ U@@ 1 * * ] * %394 , i64 0 , i64 0 %396 = load %un@@ ion.@@ U@@ 1 * * , %un@@ ion.@@ U@@ 1 * * * %395 , align 16 %397 = icmp ne %un@@ ion.@@ U@@ 1 * * %396 , null %398 = zext i1 %397 to i32 %399 = sext i32 %398 to i64 %400 = call i64 @safe_add_func_uint64_t_u_u ( i64 %399 , i64 1 ) %401 = load volatile i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 31 , i32 0 , i32 0 ) , align 4 %402 = zext i32 %401 to i64 %403 = call i64 @safe_mod_func_int64_t_s_s ( i64 %400 , i64 %402 ) %404 = icmp ne i64 %403 , 0 br i1 %404 , label %412 , label %405 4406 %406 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %407 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %406 , i64 0 , i64 2 %408 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %407 , i64 0 , i64 0 %409 = load i8 , i8 * %408 , align 2 %410 = zext i8 %409 to i32 %411 = icmp ne i32 %410 , 0 br label %412 44@@ 13 %413 = phi i1 [ true , %351 ] , [ %411 , %405 ] %414 = zext i1 %413 to i32 %415 = trunc i32 %414 to i8 %416 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %415 , i8 zeroext 7 ) %417 = zext i8 %416 to i64 store i64 %417 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 0 ) , align 16 %418 = icmp ne i64 %417 , 0 br i1 %418 , label %419 , label %419 44@@ 20 %420 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , i32 0 , i32 0 ) , align 4 %421 = icmp ne i32 %420 , 0 br label %422 44@@ 23 %423 = phi i1 [ false , %412 ] , [ %421 , %419 ] %424 = zext i1 %423 to i32 %425 = load i16 , i16 * %13 , align 2 %426 = zext i16 %425 to i32 %427 = icmp eq i32 %424 , %428 %428 = zext i1 %427 to i32 %429 = sext i32 %428 to i64 %430 = load i64 * , i64 * * %55 , align 8 %431 = load i64 , i64 * %430 , align 8 %432 = xor i64 %431 , %33 store i64 %432 , i64 * %430 , align 8 %433 = icmp ugt i64 %432 , -40@@ 70@@ 9@@ 449@@ 99@@ 76@@ 2@@ 196@@ 200 %434 = zext i1 %433 to i32 %435 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 1 %436 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %435 , i64 0 , i64 2 %437 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %436 , i64 0 , i64 1 %438 = load i32 , i32 * %437 , align 4 %439 = sext i32 %438 to i64 %440 = xor i64 %439 , 1969@@ 00@@ 96@@ 28 %441 = trunc i64 %440 to i32 store i32 %441 , i32 * %437 , align 4 %442 = load i32 , i32 * %7 , align 4 %443 = trunc i32 %442 to i16 %444 = load i8 , i8 * %53 , align 1 %445 = sext i8 %444 to i32 %446 = load volatile i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 31 , i32 0 , i32 0 ) , align 4 %447 = icmp ne i32 %446 , 0 br i1 %447 , label %529 , label %448 4449 %449 = load i32 , i32 * getelementptr inbounds ( [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 1 , i64 0 ) , align 4 %450 = xor i32 %449 , -1 %451 = icmp ne i32 %450 , 0 br i1 %451 , label %452 , label %452 4453 %453 = load i16 , i16 * @g_1@@ 28 , align 2 %454 = sext i16 %453 to i64 %455 = load i32 , i32 * %7 , align 4 %456 = icmp ne i32 %455 , 0 br i1 %456 , label %457 , label %457 445@@ 8 %458 = load i32 , i32 * %7 , align 4 %459 = load i32 , i32 * %7 , align 4 %460 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 2 %461 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %460 , i64 0 , i64 3 %462 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %461 , i64 0 , i64 0 %463 = load i8 , i8 * %462 , align 2 %464 = zext i8 %463 to i32 %465 = load i32 , i32 * %7 , align 4 %466 = icmp slt i32 %464 , %467 %467 = zext i1 %466 to i32 %468 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %469 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %468 , i64 0 , i64 2 %470 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %469 , i64 0 , i64 0 %471 = load i8 , i8 * %470 , align 2 %472 = zext i8 %471 to i32 %473 = icmp sgt i32 %467 , %474 %474 = zext i1 %473 to i32 %475 = trunc i32 %474 to i8 %476 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %475 , i8 zeroext 82 ) %477 = zext i8 %476 to i64 %478 = icmp sge i64 %477 , -1 %479 = zext i1 %478 to i32 %480 = icmp sgt i32 %459 , %481 %481 = zext i1 %480 to i32 %482 = icmp sgt i32 %458 , %2 br label %483 448@@ 4 %484 = phi i1 [ false , %452 ] , [ %482 , %457 ] %485 = zext i1 %484 to i32 %486 = sext i32 %485 to i64 %487 = call i64 @safe_sub_func_int64_t_s_s ( i64 %454 , i64 %486 ) %488 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 1 ) , align 8 %489 = icmp ne i64 %488 , 0 br label %490 4@@ 491 %491 = phi i1 [ false , %448 ] , [ %489 , %483 ] %492 = zext i1 %491 to i32 %493 = trunc i32 %492 to i16 %494 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %493 , i16 zeroext 1 ) %495 = zext i16 %494 to i32 %496 = icmp ne i32 %495 , 0 br i1 %496 , label %497 , label %497 4498 %498 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 1 ) , align 8 %499 = icmp ne i64 %498 , 0 br label %500 55@@ 01 %501 = phi i1 [ false , %490 ] , [ %499 , %497 ] %502 = zext i1 %501 to i32 store i32 %502 , i32 * %41 , align 4 %503 = sext i32 %502 to i64 %504 = call i64 @safe_add_func_int64_t_s_s ( i64 %503 , i64 -1 ) %505 = trunc i64 %504 to i16 %506 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %505 , i16 signext -1@@ 58@@ 89 ) %507 = trunc i16 %506 to i8 %508 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %507 , i8 zeroext 105 ) %509 = zext i8 %508 to i64 %510 = icmp ne i64 %509 , 9@@ 130@@ 242@@ 335@@ 9@@ 770@@ 40@@ 4@@ 26 br i1 %510 , label %511 , label %511 52 br label %512 55@@ 13 %513 = phi i1 [ false , %500 ] , [ false , %511 ] %514 = zext i1 %513 to i32 %515 = sext i32 %514 to i64 %516 = load i32 , i32 * %7 , align 4 %517 = sext i32 %516 to i64 %518 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %515 , i64 %517 ) %519 = icmp ule i64 %518 , 77@@ 19@@ 415@@ 78 %520 = zext i1 %519 to i32 %521 = sext i32 %520 to i64 %522 = icmp sge i64 %521 , 69@@ 78@@ 730@@ 219@@ 108@@ 06@@ 875@@ 3 %523 = zext i1 %522 to i32 %524 = trunc i32 %523 to i16 %525 = load i32 , i32 * %7 , align 4 %526 = call signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %524 , i32 %525 ) %527 = sext i16 %526 to i32 %528 = icmp ne i32 %527 , 0 br label %529 55@@ 30 %530 = phi i1 [ true , %422 ] , [ %528 , %512 ] %531 = xor i1 %530 , true %532 = zext i1 %531 to i32 %533 = icmp sgt i32 %445 , %534 %534 = zext i1 %533 to i32 %535 = load i16 * , i16 * * %22 , align 8 %536 = load i16 , i16 * %535 , align 2 %537 = zext i16 %536 to i32 %538 = xor i32 %537 , %539 %539 = trunc i32 %538 to i16 store i16 %539 , i16 * %535 , align 2 %540 = zext i16 %539 to i32 %541 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %443 , i32 %540 ) %542 = sext i16 %541 to i64 %543 = load i64 , i64 * @g_1@@ 80 , align 8 %544 = or i64 %543 , %33 store i64 %544 , i64 * @g_1@@ 80 , align 8 %545 = load i32 , i32 * %7 , align 4 %546 = sext i32 %545 to i64 %547 = icmp ule i64 %544 , %2 br i1 %547 , label %548 , label %548 52 br label %549 55@@ 50 %550 = phi i1 [ false , %529 ] , [ true , %548 ] %551 = zext i1 %550 to i32 %552 = load i32 * , i32 * * %11 , align 8 store i32 %551 , i32 * %552 , align 4 %553 = load i32 , i32 * %7 , align 4 %554 = load i32 , i32 * %7 , align 4 %555 = xor i32 %554 , 0 %556 = trunc i32 %555 to i8 %557 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %556 , i8 signext -11@@ 9 ) %558 = sext i8 %557 to i16 %559 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext 0 , i16 signext %558 ) %560 = sext i16 %559 to i32 %561 = load i32 * , i32 * * %11 , align 8 %562 = load i32 , i32 * %561 , align 4 %563 = or i32 %562 , %33 store i32 %563 , i32 * %561 , align 4 br label %564 533 store i32 1 , i32 * @g_1@@ 47 , align 4 br label %565 5566 %566 = load i32 , i32 * @g_1@@ 47 , align 4 %567 = icmp sle i32 %566 , 8 br i1 %567 , label %568 , label %568 533 store i32 * @g_@@ 24 , i32 * * %4 , align 8 br label %569 5570 %570 = load i32 , i32 * @g_1@@ 47 , align 4 %571 = add nsw i32 %570 , 1 store i32 %571 , i32 * @g_1@@ 47 , align 4 br label %572 533 store i64 0 , i64 * @g_1@@ 80 , align 8 br label %573 5574 %574 = load i64 , i64 * @g_1@@ 80 , align 8 %575 = icmp ule i64 %574 , 9 br i1 %575 , label %576 , label %576 5577 %577 = load i32 , i32 * @g_@@ 65 , align 4 %578 = icmp ne i32 %577 , 0 br i1 %578 , label %579 , label %579 52 br label %580 52 br label %581 55@@ 82 %582 = load i64 , i64 * @g_1@@ 80 , align 8 %583 = add i64 %582 , 1 store i64 %583 , i64 * @g_1@@ 80 , align 8 br label %584 52 br label %585 533 store i64 0 , i64 * @g_1@@ 80 , align 8 br label %586 55@@ 87 %587 = load i64 , i64 * @g_1@@ 80 , align 8 %588 = icmp ule i64 %587 , 0 br i1 %588 , label %589 , label %589 533 store i8 60 , i8 * %57 , align 1 store i8 * null , i8 * * %59 , align 8 store i8 * * %59 , i8 * * * %60 , align 8 store i8 * @g_1@@ 20 , i8 * * %61 , align 8 %590 = bitcast [ 7 x [ 10 x %@@ struct@@ .@@ S@@ 0 ] ] * %62 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %590 , i8 * align 16 bitcast ( [ 7 x [ 10 x %@@ struct@@ .@@ S@@ 0 ] ] * @__const.func_@@ 53@@ .l_@@ 277 to i8 * ) , i64 140 , i1 false ) store i16 -1 , i16 * %63 , align 2 store i16 * @g_1@@ 28 , i16 * * %64 , align 8 store i32 0 , i32 * %65 , align 4 br label %591 5592 %592 = load i32 , i32 * %65 , align 4 %593 = icmp slt i32 %592 , 2 br i1 %593 , label %594 , label %594 533 store i32 0 , i32 * %66 , align 4 br label %595 5596 %596 = load i32 , i32 * %66 , align 4 %597 = icmp slt i32 %596 , 4 br i1 %597 , label %598 , label %598 55@@ 99 %599 = load i32 , i32 * %65 , align 4 %600 = sext i32 %599 to i64 %601 = getelementptr inbounds [ 2 x [ 4 x i32 ] ] , [ 2 x [ 4 x i32 ] ] * %58 , i64 0 , i64 %602 %602 = load i32 , i32 * %66 , align 4 %603 = sext i32 %602 to i64 %604 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %601 , i64 0 , i64 %33 store i32 -10 , i32 * %604 , align 4 br label %605 6606 %606 = load i32 , i32 * %66 , align 4 %607 = add nsw i32 %606 , 1 store i32 %607 , i32 * %66 , align 4 br label %608 62 br label %609 6610 %610 = load i32 , i32 * %65 , align 4 %611 = add nsw i32 %610 , 1 store i32 %611 , i32 * %65 , align 4 br label %612 6613 %613 = load i64 , i64 * @g_1@@ 80 , align 8 %614 = add i64 %613 , 2 %615 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %616 %616 = load i32 , i32 * %615 , align 4 %617 = zext i32 %616 to i64 %618 = icmp eq i64 0 , %2 br i1 %618 , label %619 , label %619 66@@ 20 %620 = getelementptr inbounds [ 4 x i64 ] , [ 4 x i64 ] * %42 , i64 0 , i64 3 %621 = load i64 , i64 * %620 , align 8 %622 = add i64 %621 , 1 store i64 %622 , i64 * %620 , align 8 br label %623 633 store i8 0 , i8 * %68 , align 1 %624 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %44 , i64 0 , i64 4 store i32 * * * * %624 , i32 * * * * * %69 , align 8 %625 = load i8 , i8 * %68 , align 1 %626 = add i8 %625 , 1 store i8 %626 , i8 * %68 , align 1 %627 = load i64 , i64 * @g_1@@ 80 , align 8 %628 = add i64 %627 , 5 %629 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %630 %630 = load i32 , i32 * %629 , align 4 %631 = load i32 , i32 * %7 , align 4 %632 = load i32 , i32 * %7 , align 4 %633 = getelementptr inbounds [ 9 x i32 * * * ] , [ 9 x i32 * * * ] * %44 , i64 0 , i64 8 %634 = load i32 * * * , i32 * * * * %633 , align 16 %635 = load i32 * * * * , i32 * * * * * %69 , align 8 store i32 * * * %634 , i32 * * * * %635 , align 8 %636 = load i16 , i16 * @g_@@ 86 , align 2 %637 = load i64 , i64 * @g_1@@ 80 , align 8 %638 = getelementptr inbounds [ 1 x i32 * * ] , [ 1 x i32 * * ] * @g_1@@ 05 , i64 0 , i64 %639 %639 = icmp eq i32 * * * %634 , %640 %640 = zext i1 %639 to i32 %641 = load i32 , i32 * %25 , align 4 %642 = trunc i32 %641 to i8 %643 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %642 , i32 6 ) %644 = sext i8 %643 to i32 %645 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %632 , i32 %644 ) %646 = zext i32 %645 to i64 %647 = load i8 , i8 * %57 , align 1 %648 = zext i8 %647 to i64 %649 = call i64 @safe_add_func_int64_t_s_s ( i64 %646 , i64 %648 ) %650 = load i64 , i64 * @g_1@@ 80 , align 8 %651 = getelementptr inbounds [ 1 x i32 * * ] , [ 1 x i32 * * ] * @g_1@@ 05 , i64 0 , i64 %652 %652 = load i32 * * , i32 * * * %651 , align 8 %653 = icmp eq i32 * * %652 , null %654 = zext i1 %653 to i32 %655 = trunc i32 %654 to i16 %656 = load i64 , i64 * @g_1@@ 80 , align 8 %657 = trunc i64 %656 to i16 %658 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %655 , i16 signext %657 ) %659 = trunc i16 %658 to i8 %660 = load i32 , i32 * %7 , align 4 %661 = trunc i32 %660 to i8 %662 = call signext i8 @safe_div_func_int8_t_s_s ( i8 signext %659 , i8 signext %661 ) %663 = sext i8 %662 to i16 %664 = call signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %663 , i32 2 ) %665 = sext i16 %664 to i32 %666 = load i32 * , i32 * * %11 , align 8 store i32 %665 , i32 * %666 , align 4 %667 = xor i32 %630 , %668 %668 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 1 %669 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %668 , i64 0 , i64 3 %670 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %669 , i64 0 , i64 3 %671 = load i32 , i32 * %670 , align 4 %672 = or i32 %671 , %33 store i32 %672 , i32 * %670 , align 4 %673 = getelementptr inbounds [ 2 x [ 4 x i32 ] ] , [ 2 x [ 4 x i32 ] ] * %58 , i64 0 , i64 0 %674 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %673 , i64 0 , i64 0 store i32 %672 , i32 * %674 , align 16 br label %675 66@@ 76 %676 = load i32 , i32 * %7 , align 4 %677 = trunc i32 %676 to i16 %678 = bitcast %@@ struct@@ .@@ S@@ 0 * %71 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 2 %678 , i8 * align 2 bitcast ( %@@ struct@@ .@@ S@@ 0 * @g_2@@ 44 to i8 * ) , i64 2 , i1 true ) %679 = load i32 * , i32 * * %11 , align 8 %680 = load i32 , i32 * %679 , align 4 %681 = sext i32 %680 to i64 %682 = and i64 %681 , 308@@ 730@@ 64@@ 18@@ 76@@ 7658@@ 0@@ 88 %683 = trunc i64 %682 to i32 store i32 %683 , i32 * %679 , align 4 %684 = load i32 * , i32 * * %10 , align 8 %685 = load i32 , i32 * %684 , align 4 %686 = sext i32 %685 to i64 %687 = icmp uge i64 36@@ 559@@ 12@@ 198 , %688 %688 = zext i1 %687 to i32 %689 = load i8 * * , i8 * * * %60 , align 8 store i8 * @g_1@@ 59 , i8 * * %689 , align 8 %690 = load i32 , i32 * %7 , align 4 %691 = load volatile i8 * , i8 * * @g_1@@ 58 , align 8 %692 = load i8 , i8 * %691 , align 1 %693 = zext i8 %692 to i32 %694 = icmp ne i32 %690 , %695 %695 = zext i1 %694 to i32 %696 = trunc i32 %695 to i16 %697 = load i32 , i32 * %7 , align 4 %698 = trunc i32 %697 to i16 %699 = call zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %696 , i16 zeroext %698 ) %700 = zext i16 %699 to i64 %701 = call i64 @safe_add_func_int64_t_s_s ( i64 %700 , i64 -1 ) %702 = load i32 , i32 * @g_@@ 24 , align 4 %703 = sext i32 %702 to i64 %704 = call i64 @safe_add_func_int64_t_s_s ( i64 %701 , i64 %703 ) %705 = trunc i64 %704 to i32 %706 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 0 %707 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %706 , i64 0 , i64 1 %708 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %707 , i64 0 , i64 1 store i32 %705 , i32 * %708 , align 4 %709 = load i8 * , i8 * * %14 , align 8 %710 = icmp ne i8 * @g_1@@ 59 , %711 %711 = zext i1 %710 to i32 %712 = sext i32 %711 to i64 %713 = or i64 %712 , 101 %714 = trunc i64 %713 to i32 %715 = call i32 @safe_unary_minus_func_int32_t_s ( i32 %714 ) %716 = call i32 @safe_unary_minus_func_uint32_t_u ( i32 %715 ) %717 = and i32 %688 , %718 %718 = trunc i32 %717 to i8 %719 = load i8 * , i8 * * %61 , align 8 store i8 %718 , i8 * %719 , align 1 %720 = load i64 , i64 * %26 , align 8 %721 = trunc i64 %720 to i32 %722 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %718 , i32 %721 ) %723 = sext i8 %722 to i32 %724 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 1 %725 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %724 , i64 0 , i64 2 %726 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %725 , i64 0 , i64 0 %727 = load i8 , i8 * %726 , align 2 %728 = zext i8 %727 to i32 %729 = icmp eq i32 %723 , %730 %730 = zext i1 %729 to i32 %731 = sext i32 %730 to i64 %732 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 1 ) , align 8 %733 = icmp sgt i64 %731 , %734 %734 = zext i1 %733 to i32 %735 = load i8 , i8 * @g_1@@ 59 , align 1 %736 = zext i8 %735 to i32 %737 = icmp slt i32 %734 , %738 %738 = zext i1 %737 to i32 %739 = bitcast %un@@ ion.@@ U@@ 1 * %72 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 4 %739 , i8 * align 4 bitcast ( [ 1 x %un@@ ion.@@ U@@ 1 ] * @g_2@@ 60 to i8 * ) , i64 4 , i1 true ) %740 = getelementptr inbounds [ 9 x [ 1 x i32 * ] ] , [ 9 x [ 1 x i32 * ] ] * %46 , i64 0 , i64 1 %741 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %740 , i64 0 , i64 0 %742 = load i32 * , i32 * * %741 , align 8 %743 = icmp ne i32 * %742 , null %744 = zext i1 %743 to i32 %745 = sext i32 %744 to i64 %746 = icmp sle i64 %745 , 35 %747 = zext i1 %746 to i32 %748 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 6 ) , align 8 %749 = icmp ult i32 %747 , %2 br i1 %749 , label %753 , label %750 77@@ 51 %751 = load i32 , i32 * %7 , align 4 %752 = icmp ne i32 %751 , 0 br label %753 775@@ 4 %754 = phi i1 [ true , %675 ] , [ %752 , %750 ] %755 = zext i1 %754 to i32 %756 = icmp sgt i32 %683 , %757 %757 = zext i1 %756 to i32 %758 = sext i32 %757 to i64 %759 = call i64 @safe_add_func_int64_t_s_s ( i64 0 , i64 %758 ) %760 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , i32 0 , i32 0 ) , align 4 %761 = load i32 , i32 * %7 , align 4 %762 = trunc i32 %761 to i16 %763 = load i32 , i32 * %7 , align 4 %764 = trunc i32 %763 to i16 %765 = call zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %762 , i16 zeroext %764 ) %766 = load i32 , i32 * %7 , align 4 %767 = call signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext 5 , i32 %766 ) %768 = sext i8 %767 to i32 %769 = load i32 * , i32 * * @g_2@@ 3 , align 8 %770 = load i32 , i32 * %769 , align 4 %771 = call i32 @safe_sub_func_int32_t_s_s ( i32 %768 , i32 %770 ) %772 = sext i32 %771 to i64 %773 = call i64 @safe_unary_minus_func_int64_t_s ( i64 %772 ) %774 = trunc i64 %773 to i32 %775 = call zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %677 , i32 %774 ) %776 = zext i16 %775 to i32 store i32 %776 , i32 * %27 , align 4 %777 = load i16 , i16 * @g_@@ 86 , align 2 %778 = sext i16 %777 to i32 %779 = call i32 @safe_unary_minus_func_uint32_t_u ( i32 %778 ) %780 = trunc i32 %779 to i8 %781 = load i32 , i32 * %7 , align 4 %782 = call zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %780 , i32 %781 ) %783 = zext i8 %782 to i32 %784 = load i64 , i64 * @g_1@@ 80 , align 8 %785 = add i64 %784 , 2 %786 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %787 %787 = load i32 , i32 * %786 , align 4 %788 = trunc i32 %787 to i8 %789 = load i8 * , i8 * * %61 , align 8 store i8 %788 , i8 * %789 , align 1 %790 = load i32 , i32 * %7 , align 4 %791 = trunc i32 %790 to i8 %792 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %791 , i32 0 ) %793 = zext i8 %792 to i16 %794 = load i32 , i32 * getelementptr inbounds ( [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 7 ) , align 4 %795 = xor i32 %794 , -1 %796 = icmp ne i32 %795 , 0 br i1 %796 , label %803 , label %797 77@@ 98 %798 = load i32 , i32 * getelementptr inbounds ( [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 1 , i64 3 ) , align 4 %799 = icmp ne i32 %798 , 0 br i1 %799 , label %800 , label %800 82 br label %801 88@@ 02 %802 = phi i1 [ false , %797 ] , [ true , %800 ] br label %803 88@@ 04 %804 = phi i1 [ true , %753 ] , [ %802 , %801 ] %805 = zext i1 %804 to i32 %806 = load i16 , i16 * %63 , align 2 %807 = sext i16 %806 to i32 %808 = and i32 %805 , %809 %809 = trunc i32 %808 to i16 %810 = call signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %809 ) %811 = sext i16 %810 to i64 %812 = xor i64 %811 , 1 %813 = load i16 * , i16 * * %64 , align 8 %814 = load i16 , i16 * %813 , align 2 %815 = sext i16 %814 to i64 %816 = and i64 %815 , %817 %817 = trunc i64 %816 to i16 store i16 %817 , i16 * %813 , align 2 %818 = sext i16 %817 to i32 %819 = load i32 , i32 * %7 , align 4 %820 = icmp sle i32 %818 , %821 %821 = zext i1 %820 to i32 %822 = sext i32 %821 to i64 %823 = icmp sle i64 %822 , 6@@ 312@@ 879@@ 422@@ 66689@@ 55@@ 99 %824 = zext i1 %823 to i32 %825 = load i32 , i32 * %7 , align 4 %826 = icmp sge i32 %824 , %827 %827 = zext i1 %826 to i32 %828 = load i16 * , i16 * * %22 , align 8 %829 = load i16 , i16 * %828 , align 2 %830 = zext i16 %829 to i32 %831 = and i32 %830 , %832 %832 = trunc i32 %831 to i16 store i16 %832 , i16 * %828 , align 2 %833 = zext i16 %832 to i64 %834 = or i64 %833 , 2 %835 = trunc i64 %834 to i16 %836 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %793 , i16 signext %835 ) %837 = sext i16 %836 to i32 %838 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 1 %839 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %838 , i64 0 , i64 3 %840 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %839 , i64 0 , i64 3 %841 = load i32 , i32 * %840 , align 4 %842 = and i32 %837 , %843 %843 = sext i32 %842 to i64 %844 = xor i64 1 , %845 %845 = load i64 , i64 * @g_1@@ 80 , align 8 %846 = add i64 %845 , 2 %847 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %848 %848 = load i32 , i32 * %847 , align 4 %849 = zext i32 %848 to i64 %850 = icmp eq i64 %844 , %851 %851 = zext i1 %850 to i32 %852 = sext i32 %851 to i64 %853 = icmp ne i64 %852 , 1 %854 = zext i1 %853 to i32 %855 = sext i32 %854 to i64 %856 = or i64 1 , %857 %857 = trunc i64 %856 to i32 %858 = call signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %788 , i32 %857 ) %859 = sext i8 %858 to i32 %860 = icmp eq i32 %783 , %2 br i1 %860 , label %861 , label %861 833 store i32 * @g_@@ 24 , i32 * * %4 , align 8 br label %862 8@@ 863 %863 = load i8 , i8 * @g_1@@ 59 , align 1 %864 = load i8 * , i8 * * %61 , align 8 store i8 %863 , i8 * %864 , align 1 %865 = sext i8 %863 to i64 %866 = icmp ule i64 9 , %867 %867 = zext i1 %866 to i32 %868 = trunc i32 %867 to i16 %869 = load i32 , i32 * %7 , align 4 %870 = getelementptr inbounds [ 4 x [ 5 x [ 2 x i8 ] ] ] , [ 4 x [ 5 x [ 2 x i8 ] ] ] * %19 , i64 0 , i64 2 %871 = getelementptr inbounds [ 5 x [ 2 x i8 ] ] , [ 5 x [ 2 x i8 ] ] * %870 , i64 0 , i64 3 %872 = getelementptr inbounds [ 2 x i8 ] , [ 2 x i8 ] * %871 , i64 0 , i64 1 %873 = load i8 , i8 * %872 , align 1 %874 = zext i8 %873 to i32 %875 = icmp slt i32 %869 , %876 %876 = zext i1 %875 to i32 %877 = trunc i32 %876 to i16 %878 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %868 , i16 signext %877 ) %879 = sext i16 %878 to i64 %880 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 0 ) , align 16 %881 = icmp slt i64 %879 , %2 br i1 %881 , label %900 , label %882 88@@ 83 %883 = load i32 * , i32 * * %11 , align 8 %884 = load i32 , i32 * %883 , align 4 %885 = load i32 , i32 * %7 , align 4 store i32 %885 , i32 * getelementptr inbounds ( [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 1 , i64 0 ) , align 4 %886 = xor i32 %884 , %887 %887 = trunc i32 %886 to i16 %888 = load i16 , i16 * %63 , align 2 %889 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 31 to i16 * ) , align 4 %890 = sext i16 %889 to i64 %891 = load i32 , i32 * @g_@@ 65 , align 4 %892 = sext i32 %891 to i64 %893 = call i64 @safe_div_func_int64_t_s_s ( i64 %890 , i64 %892 ) %894 = trunc i64 %893 to i16 %895 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %888 , i16 zeroext %894 ) %896 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %895 , i16 signext -200@@ 34 ) %897 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %887 , i16 signext %896 ) %898 = sext i16 %897 to i32 %899 = icmp ne i32 %898 , 0 br label %900 99@@ 01 %901 = phi i1 [ true , %862 ] , [ %899 , %882 ] %902 = zext i1 %901 to i32 %903 = getelementptr inbounds [ 4 x [ 9 x [ 5 x i32 ] ] ] , [ 4 x [ 9 x [ 5 x i32 ] ] ] * %20 , i64 0 , i64 2 %904 = getelementptr inbounds [ 9 x [ 5 x i32 ] ] , [ 9 x [ 5 x i32 ] ] * %903 , i64 0 , i64 8 %905 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %904 , i64 0 , i64 0 %906 = load i32 , i32 * %905 , align 8 %907 = and i32 %906 , %33 store i32 %907 , i32 * %905 , align 8 %908 = load i32 , i32 * %7 , align 4 %909 = icmp sgt i32 %907 , %910 %910 = zext i1 %909 to i32 %911 = getelementptr inbounds [ 2 x [ 4 x i32 ] ] , [ 2 x [ 4 x i32 ] ] * %58 , i64 0 , i64 0 %912 = getelementptr inbounds [ 4 x i32 ] , [ 4 x i32 ] * %911 , i64 0 , i64 0 store i32 %910 , i32 * %912 , align 16 %913 = load i32 * , i32 * * %11 , align 8 store i32 %910 , i32 * %913 , align 4 store i32 * %7 , i32 * * @g_@@ 64 , align 8 store i32 * %7 , i32 * * @g_@@ 64 , align 8 %914 = load i32 , i32 * %25 , align 4 %915 = icmp ne i32 %914 , 0 br i1 %915 , label %916 , label %916 92 br label %917 92 br label %918 92 br label %919 99@@ 20 %920 = load i64 , i64 * @g_1@@ 80 , align 8 %921 = add i64 %920 , 1 store i64 %921 , i64 * @g_1@@ 80 , align 8 br label %922 92 br label %923 9924 %924 = load i32 , i32 * %7 , align 4 %925 = add nsw i32 %924 , 1 store i32 %925 , i32 * %7 , align 4 br label %926 92 br label %927 933 store i64 * * * %29 , i64 * * * * %73 , align 8 %928 = load i64 * * , i64 * * * %29 , align 8 %929 = load i64 * * * , i64 * * * * %73 , align 8 store i64 * * %928 , i64 * * * %929 , align 8 br label %930 92 br label %931 99@@ 32 %932 = load i64 , i64 * @g_@@ 95 , align 8 %933 = add nsw i64 %932 , 1 store i64 %933 , i64 * @g_@@ 95 , align 8 br label %934 92 br label %935 933 store i32 * %7 , i32 * * %6 , align 8 %936 = getelementptr inbounds [ 10 x i64 ] , [ 10 x i64 ] * %16 , i64 0 , i64 0 %937 = load i64 , i64 * %936 , align 16 %938 = add i64 %937 , -1 store i64 %938 , i64 * %936 , align 16 store i32 * @g_1@@ 47 , i32 * * %4 , align 8 br label %939 99@@ 40 %940 = load i32 * , i32 * * %4 , align 8 ret i32 * %940 }
define internal i32 * @func_@@ 49 ( i32 * %0 , i32 %1 , i32 * %2 ) #0 { %4 = alloca i32 * , align 8 %5 = alloca i32 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 %9 = alloca i32 * * , align 8 %10 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %11 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %12 = alloca %un@@ ion.@@ U@@ 1 * * * , align 8 %13 = alloca %un@@ ion.@@ U@@ 1 * * * * , align 8 %14 = alloca i32 , align 4 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = alloca i32 , align 4 %18 = alloca i32 , align 4 %19 = alloca i32 , align 4 %20 = alloca i8 , align 1 %21 = alloca i8 , align 1 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca i64 , align 8 %25 = alloca i32 * , align 8 %26 = alloca %un@@ ion.@@ U@@ 1 * * * , align 8 %27 = alloca [ 8 x [ 4 x %@@ struct@@ .@@ S@@ 0 ] ] , align 16 %28 = alloca i32 , align 4 %29 = alloca i32 , align 4 %30 = alloca [ 3 x i32 * ] , align 16 %31 = alloca i8 * , align 8 %32 = alloca i8 * , align 8 %33 = alloca i32 * , align 8 %34 = alloca [ 3 x i32 * * ] , align 16 %35 = alloca %un@@ ion.@@ U@@ 1 * * * , align 8 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca i8 , align 1 %39 = alloca [ 1 x [ 1 x i64 ] ] , align 8 %40 = alloca %un@@ ion.@@ U@@ 1 * * * , align 8 %41 = alloca i32 , align 4 %42 = alloca i32 , align 4 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 store i32 * %0 , i32 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i32 * %2 , i32 * * %7 , align 8 store i32 * @g_1@@ 49 , i32 * * %8 , align 8 store i32 * * %8 , i32 * * * %9 , align 8 store %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , %un@@ ion.@@ U@@ 1 * * %10 , align 8 store %un@@ ion.@@ U@@ 1 * * %10 , %un@@ ion.@@ U@@ 1 * * * %11 , align 8 store %un@@ ion.@@ U@@ 1 * * * %11 , %un@@ ion.@@ U@@ 1 * * * * %12 , align 8 store %un@@ ion.@@ U@@ 1 * * * * %12 , %un@@ ion.@@ U@@ 1 * * * * * %13 , align 8 store i32 -@@ 53@@ 00@@ 8@@ 38@@ 42 , i32 * %14 , align 4 store i32 0 , i32 * %15 , align 4 store i32 5 , i32 * %16 , align 4 store i32 5 , i32 * %17 , align 4 store i32 1 , i32 * %18 , align 4 store i32 1 , i32 * %19 , align 4 store i8 62 , i8 * %20 , align 1 store i8 76 , i8 * %21 , align 1 store i32 10449@@ 279@@ 74 , i32 * %22 , align 4 store i32 1 , i32 * %23 , align 4 store i64 66@@ 29@@ 824@@ 13@@ 119@@ 417@@ 52@@ 39 , i64 * %24 , align 8 store i32 * null , i32 * * %25 , align 8 store %un@@ ion.@@ U@@ 1 * * * %11 , %un@@ ion.@@ U@@ 1 * * * * %26 , align 8 %45 = bitcast [ 8 x [ 4 x %@@ struct@@ .@@ S@@ 0 ] ] * %27 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %45 , i8 * align 16 bitcast ( [ 8 x [ 4 x %@@ struct@@ .@@ S@@ 0 ] ] * @__const.func_@@ 49@@ .l_@@ 3@@ 40 to i8 * ) , i64 64 , i1 false ) %46 = load i32 * , i32 * * %8 , align 8 %47 = load i32 * * , i32 * * * %9 , align 8 store i32 * %46 , i32 * * %47 , align 8 %48 = load %un@@ ion.@@ U@@ 1 * * * * , %un@@ ion.@@ U@@ 1 * * * * * %13 , align 8 store %un@@ ion.@@ U@@ 1 * * * null , %un@@ ion.@@ U@@ 1 * * * * %48 , align 8 store i32 -@@ 24 , i32 * @g_1@@ 46 , align 4 br label %49 450 %50 = load i32 , i32 * @g_1@@ 46 , align 4 %51 = icmp sge i32 %50 , -1@@ 9 br i1 %51 , label %52 , label %52 533 store i8 * @g_1@@ 59 , i8 * * %31 , align 8 store i8 * @g_3@@ 21 , i8 * * %32 , align 8 store i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , i32 0 , i32 0 ) , i32 * * %33 , align 8 store %un@@ ion.@@ U@@ 1 * * * null , %un@@ ion.@@ U@@ 1 * * * * %35 , align 8 store i32 0 , i32 * %36 , align 4 br label %53 554 %54 = load i32 , i32 * %36 , align 4 %55 = icmp slt i32 %54 , 3 br i1 %55 , label %56 , label %56 55@@ 7 %57 = load i32 , i32 * %36 , align 4 %58 = sext i32 %57 to i64 %59 = getelementptr inbounds [ 3 x i32 * ] , [ 3 x i32 * ] * %30 , i64 0 , i64 %33 store i32 * @g_1@@ 47 , i32 * * %59 , align 8 br label %60 661 %61 = load i32 , i32 * %36 , align 4 %62 = add nsw i32 %61 , 1 store i32 %62 , i32 * %36 , align 4 br label %63 633 store i32 0 , i32 * %36 , align 4 br label %64 665 %65 = load i32 , i32 * %36 , align 4 %66 = icmp slt i32 %65 , 3 br i1 %66 , label %67 , label %67 668 %68 = load i32 , i32 * %36 , align 4 %69 = sext i32 %68 to i64 %70 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %34 , i64 0 , i64 %33 store i32 * * %33 , i32 * * * %70 , align 8 br label %71 7@@ 72 %72 = load i32 , i32 * %36 , align 4 %73 = add nsw i32 %72 , 1 store i32 %73 , i32 * %36 , align 4 br label %74 775 %75 = load i32 , i32 * %23 , align 4 %76 = add i32 %75 , 1 store i32 %76 , i32 * %23 , align 4 %77 = load i8 * , i8 * * %31 , align 8 store i8 -@@ 20 , i8 * %77 , align 1 %78 = load i8 * , i8 * * %32 , align 8 store i8 -@@ 20 , i8 * %78 , align 1 %79 = load i16 , i16 * @g_1@@ 57 , align 2 %80 = zext i16 %79 to i32 %81 = load i64 , i64 * %24 , align 8 store i32 * getelementptr inbounds ( [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 3 , i64 0 ) , i32 * * %25 , align 8 %82 = and i32 %80 , 0 %83 = load i32 * , i32 * * %8 , align 8 store i32 %82 , i32 * %83 , align 4 %84 = load %un@@ ion.@@ U@@ 1 * * * , %un@@ ion.@@ U@@ 1 * * * * %35 , align 8 %85 = icmp ne %un@@ ion.@@ U@@ 1 * * * null , %86 %86 = zext i1 %85 to i32 %87 = icmp slt i32 %82 , %2 br i1 %87 , label %88 , label %88 833 store i32 9 , i32 * %37 , align 4 %89 = load i32 , i32 * %37 , align 4 %90 = add i32 %89 , -1 store i32 %90 , i32 * %37 , align 4 %91 = load i32 * , i32 * * %5 , align 8 %92 = load i32 , i32 * %91 , align 4 %93 = load i32 * , i32 * * %8 , align 8 %94 = load i32 , i32 * %93 , align 4 %95 = and i32 %94 , %33 store i32 %95 , i32 * %93 , align 4 br label %96 933 store i8 -@@ 22 , i8 * %38 , align 1 store %un@@ ion.@@ U@@ 1 * * * %11 , %un@@ ion.@@ U@@ 1 * * * * %40 , align 8 store i32 3 , i32 * %41 , align 4 store i32 175@@ 45@@ 44@@ 4@@ 18 , i32 * %42 , align 4 store i32 0 , i32 * %43 , align 4 br label %97 9@@ 98 %98 = load i32 , i32 * %43 , align 4 %99 = icmp slt i32 %98 , 1 br i1 %99 , label %100 , label %100 133 store i32 0 , i32 * %44 , align 4 br label %101 11@@ 02 %102 = load i32 , i32 * %44 , align 4 %103 = icmp slt i32 %102 , 1 br i1 %103 , label %104 , label %104 11@@ 05 %105 = load i32 , i32 * %43 , align 4 %106 = sext i32 %105 to i64 %107 = getelementptr inbounds [ 1 x [ 1 x i64 ] ] , [ 1 x [ 1 x i64 ] ] * %39 , i64 0 , i64 %108 %108 = load i32 , i32 * %44 , align 4 %109 = sext i32 %108 to i64 %110 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %107 , i64 0 , i64 %33 store i64 -1@@ 29@@ 60@@ 37@@ 103@@ 44@@ 15@@ 24@@ 1@@ 49 , i64 * %110 , align 8 br label %111 11@@ 12 %112 = load i32 , i32 * %44 , align 4 %113 = add nsw i32 %112 , 1 store i32 %113 , i32 * %44 , align 4 br label %114 12 br label %115 11@@ 16 %116 = load i32 , i32 * %43 , align 4 %117 = add nsw i32 %116 , 1 store i32 %117 , i32 * %43 , align 4 br label %118 1119 %119 = load i8 , i8 * %38 , align 1 %120 = getelementptr inbounds [ 1 x [ 1 x i64 ] ] , [ 1 x [ 1 x i64 ] ] * %39 , i64 0 , i64 0 %121 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %120 , i64 0 , i64 0 %122 = load i64 , i64 * %121 , align 8 %123 = trunc i64 %122 to i8 %124 = call signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %123 , i32 1 ) %125 = load %un@@ ion.@@ U@@ 1 * , %un@@ ion.@@ U@@ 1 * * %10 , align 8 %126 = load %un@@ ion.@@ U@@ 1 * * * , %un@@ ion.@@ U@@ 1 * * * * %26 , align 8 %127 = load %un@@ ion.@@ U@@ 1 * * * * , %un@@ ion.@@ U@@ 1 * * * * * %13 , align 8 store %un@@ ion.@@ U@@ 1 * * * %126 , %un@@ ion.@@ U@@ 1 * * * * %127 , align 8 %128 = load %un@@ ion.@@ U@@ 1 * * * , %un@@ ion.@@ U@@ 1 * * * * %40 , align 8 store %un@@ ion.@@ U@@ 1 * * * %128 , %un@@ ion.@@ U@@ 1 * * * * %35 , align 8 %129 = icmp ne %un@@ ion.@@ U@@ 1 * * * %126 , %2 br i1 %129 , label %130 , label %130 1131 %131 = getelementptr inbounds [ 8 x [ 4 x %@@ struct@@ .@@ S@@ 0 ] ] , [ 8 x [ 4 x %@@ struct@@ .@@ S@@ 0 ] ] * %27 , i64 0 , i64 3 %132 = getelementptr inbounds [ 4 x %@@ struct@@ .@@ S@@ 0 ] , [ 4 x %@@ struct@@ .@@ S@@ 0 ] * %131 , i64 0 , i64 2 %133 = call signext i8 @safe_sub_func_int8_t_s_s ( i8 signext -8 , i8 signext 0 ) %134 = sext i8 %133 to i32 %135 = icmp sle i32 1 , %136 %136 = zext i1 %135 to i32 %137 = load i32 , i32 * %41 , align 4 %138 = icmp eq i32 %136 , %139 %139 = zext i1 %138 to i32 %140 = load i32 * , i32 * * %7 , align 8 %141 = load i32 , i32 * %140 , align 4 %142 = xor i32 %139 , %143 %143 = load i16 , i16 * @g_@@ 86 , align 2 %144 = sext i16 %143 to i32 %145 = icmp ne i32 %144 , 0 br i1 %145 , label %147 , label %146 12 br label %147 1148 %148 = phi i1 [ true , %130 ] , [ true , %146 ] %149 = zext i1 %148 to i32 %150 = trunc i32 %149 to i16 %151 = load i32 , i32 * %6 , align 4 %152 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %150 , i32 %151 ) %153 = sext i16 %152 to i32 %154 = icmp ne i32 %153 , 0 br i1 %154 , label %155 , label %155 12 br label %156 11@@ 57 %157 = phi i1 [ false , %147 ] , [ true , %155 ] br label %158 11@@ 59 %159 = phi i1 [ false , %118 ] , [ %157 , %156 ] %160 = zext i1 %159 to i32 %161 = trunc i32 %160 to i16 %162 = getelementptr inbounds [ 1 x [ 1 x i64 ] ] , [ 1 x [ 1 x i64 ] ] * %39 , i64 0 , i64 0 %163 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %162 , i64 0 , i64 0 %164 = load i64 , i64 * %163 , align 8 %165 = trunc i64 %164 to i16 %166 = call zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %161 , i16 zeroext %165 ) %167 = zext i16 %166 to i32 %168 = load i32 * , i32 * * %8 , align 8 store i32 %167 , i32 * %168 , align 4 %169 = icmp ne i32 %167 , 0 br i1 %169 , label %170 , label %170 1171 %171 = load i32 * , i32 * * %8 , align 8 %172 = load i32 , i32 * %171 , align 4 %173 = icmp ne i32 %172 , 0 br label %174 1175 %175 = phi i1 [ false , %158 ] , [ %173 , %170 ] %176 = zext i1 %175 to i32 %177 = sext i32 %176 to i64 %178 = xor i64 %177 , 65535 %179 = load i32 , i32 * %6 , align 4 %180 = zext i32 %179 to i64 %181 = icmp ule i64 %178 , %182 %182 = zext i1 %181 to i32 %183 = load i32 , i32 * %42 , align 4 %184 = or i32 %183 , %33 store i32 %184 , i32 * %42 , align 4 br label %185 1186 %186 = load i32 * , i32 * * %7 , align 8 store i32 * %186 , i32 * * %4 , align 8 br label %187 1188 %188 = load i32 , i32 * @g_1@@ 46 , align 4 %189 = add nsw i32 %188 , 1 store i32 %189 , i32 * @g_1@@ 46 , align 4 br label %190 1191 %191 = load i32 * , i32 * * %5 , align 8 store i32 * %191 , i32 * * %4 , align 8 br label %192 1193 %193 = load i32 * , i32 * * %4 , align 8 ret i32 * %193 }
define internal i32 @func_@@ 39 ( i64 %0 , i32 * %1 , i32 %2 , i32 %3 , i32 * %4 ) #0 { %6 = alloca i64 , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 %10 = alloca i32 * , align 8 %11 = alloca [ 5 x [ 3 x [ 8 x i64 ] ] ] , align 16 %12 = alloca i32 , align 4 %13 = alloca i32 , align 4 %14 = alloca i32 , align 4 store i64 %0 , i64 * %6 , align 8 store i32 * %1 , i32 * * %7 , align 8 store i32 %2 , i32 * %8 , align 4 store i32 %3 , i32 * %9 , align 4 store i32 * %4 , i32 * * %10 , align 8 %15 = bitcast [ 5 x [ 3 x [ 8 x i64 ] ] ] * %11 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %15 , i8 * align 16 bitcast ( [ 5 x [ 3 x [ 8 x i64 ] ] ] * @__const.func_@@ 39@@ .l_@@ 912 to i8 * ) , i64 960 , i1 false ) %16 = load i32 * * * , i32 * * * * @g_5@@ 27 , align 8 %17 = load i32 * * , i32 * * * %16 , align 8 store i32 * %9 , i32 * * %17 , align 8 %18 = getelementptr inbounds [ 5 x [ 3 x [ 8 x i64 ] ] ] , [ 5 x [ 3 x [ 8 x i64 ] ] ] * %11 , i64 0 , i64 0 %19 = getelementptr inbounds [ 3 x [ 8 x i64 ] ] , [ 3 x [ 8 x i64 ] ] * %18 , i64 0 , i64 2 %20 = getelementptr inbounds [ 8 x i64 ] , [ 8 x i64 ] * %19 , i64 0 , i64 1 %21 = load i64 , i64 * %20 , align 8 %22 = trunc i64 %21 to i32 ret i32 %22 }
define internal i32 @func_@@ 45 ( i32 * %0 , i32 * %1 , i32 %2 ) #0 { %4 = alloca i32 , align 4 %5 = alloca i32 * , align 8 %6 = alloca i32 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 * , align 8 %9 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %10 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %11 = alloca i32 , align 4 %12 = alloca i32 , align 4 %13 = alloca i32 , align 4 %14 = alloca i32 , align 4 %15 = alloca i64 , align 8 %16 = alloca i32 * * , align 8 %17 = alloca [ 8 x [ 4 x i32 * * * ] ] , align 16 %18 = alloca [ 5 x [ 1 x [ 7 x i8 * ] ] ] , align 16 %19 = alloca i32 * , align 8 %20 = alloca i8 , align 1 %21 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %22 = alloca i32 , align 4 %23 = alloca [ 10 x i32 * ] , align 16 %24 = alloca i32 * * , align 8 %25 = alloca i64 * , align 8 %26 = alloca [ 6 x [ 7 x i64 * * ] ] , align 16 %27 = alloca i64 * * * , align 8 %28 = alloca i8 , align 1 %29 = alloca [ 7 x i8 * ] , align 16 %30 = alloca [ 8 x [ 9 x i32 ] ] , align 16 %31 = alloca i32 , align 4 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca i32 , align 4 store i32 * %0 , i32 * * %5 , align 8 store i32 * %1 , i32 * * %6 , align 8 store i32 %2 , i32 * %7 , align 4 store i32 * @g_1@@ 47 , i32 * * %8 , align 8 store %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , %un@@ ion.@@ U@@ 1 * * %9 , align 8 store %un@@ ion.@@ U@@ 1 * * %9 , %un@@ ion.@@ U@@ 1 * * * %10 , align 8 store i32 -6 , i32 * %11 , align 4 store i32 2 , i32 * %12 , align 4 store i32 420@@ 722@@ 171 , i32 * %13 , align 4 store i32 210@@ 67@@ 660@@ 53 , i32 * %14 , align 4 store i64 -85@@ 17@@ 46@@ 429@@ 27@@ 170@@ 716@@ 15 , i64 * %15 , align 8 store i32 * * null , i32 * * * %16 , align 8 %35 = getelementptr inbounds [ 8 x [ 4 x i32 * * * ] ] , [ 8 x [ 4 x i32 * * * ] ] * %17 , i64 0 , i64 0 %36 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %35 , i64 0 , i64 0 store i32 * * * %16 , i32 * * * * %36 , align 8 %37 = getelementptr inbounds i32 * * * , i32 * * * * %36 , i64 1 store i32 * * * %16 , i32 * * * * %37 , align 8 %38 = getelementptr inbounds i32 * * * , i32 * * * * %37 , i64 1 store i32 * * * null , i32 * * * * %38 , align 8 %39 = getelementptr inbounds i32 * * * , i32 * * * * %38 , i64 1 store i32 * * * null , i32 * * * * %39 , align 8 %40 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %35 , i64 1 %41 = bitcast [ 4 x i32 * * * ] * %40 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 16 %41 , i8 0 , i64 32 , i1 false ) %42 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %40 , i64 0 , i64 0 %43 = getelementptr inbounds i32 * * * , i32 * * * * %42 , i64 1 %44 = getelementptr inbounds i32 * * * , i32 * * * * %43 , i64 1 store i32 * * * %16 , i32 * * * * %44 , align 8 %45 = getelementptr inbounds i32 * * * , i32 * * * * %44 , i64 1 %46 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %40 , i64 1 %47 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %46 , i64 0 , i64 0 store i32 * * * %16 , i32 * * * * %47 , align 8 %48 = getelementptr inbounds i32 * * * , i32 * * * * %47 , i64 1 store i32 * * * %16 , i32 * * * * %48 , align 8 %49 = getelementptr inbounds i32 * * * , i32 * * * * %48 , i64 1 store i32 * * * %16 , i32 * * * * %49 , align 8 %50 = getelementptr inbounds i32 * * * , i32 * * * * %49 , i64 1 store i32 * * * %16 , i32 * * * * %50 , align 8 %51 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %46 , i64 1 %52 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %51 , i64 0 , i64 0 store i32 * * * %16 , i32 * * * * %52 , align 8 %53 = getelementptr inbounds i32 * * * , i32 * * * * %52 , i64 1 store i32 * * * %16 , i32 * * * * %53 , align 8 %54 = getelementptr inbounds i32 * * * , i32 * * * * %53 , i64 1 store i32 * * * %16 , i32 * * * * %54 , align 8 %55 = getelementptr inbounds i32 * * * , i32 * * * * %54 , i64 1 store i32 * * * %16 , i32 * * * * %55 , align 8 %56 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %51 , i64 1 %57 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %56 , i64 0 , i64 0 store i32 * * * null , i32 * * * * %57 , align 8 %58 = getelementptr inbounds i32 * * * , i32 * * * * %57 , i64 1 store i32 * * * %16 , i32 * * * * %58 , align 8 %59 = getelementptr inbounds i32 * * * , i32 * * * * %58 , i64 1 store i32 * * * null , i32 * * * * %59 , align 8 %60 = getelementptr inbounds i32 * * * , i32 * * * * %59 , i64 1 store i32 * * * %16 , i32 * * * * %60 , align 8 %61 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %56 , i64 1 %62 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %61 , i64 0 , i64 0 store i32 * * * %16 , i32 * * * * %62 , align 8 %63 = getelementptr inbounds i32 * * * , i32 * * * * %62 , i64 1 store i32 * * * %16 , i32 * * * * %63 , align 8 %64 = getelementptr inbounds i32 * * * , i32 * * * * %63 , i64 1 store i32 * * * null , i32 * * * * %64 , align 8 %65 = getelementptr inbounds i32 * * * , i32 * * * * %64 , i64 1 store i32 * * * null , i32 * * * * %65 , align 8 %66 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %61 , i64 1 %67 = bitcast [ 4 x i32 * * * ] * %66 to i8 * call void @llvm.memset.p0i8.i64 ( i8 * align 16 %67 , i8 0 , i64 32 , i1 false ) %68 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %66 , i64 0 , i64 0 %69 = getelementptr inbounds i32 * * * , i32 * * * * %68 , i64 1 %70 = getelementptr inbounds i32 * * * , i32 * * * * %69 , i64 1 store i32 * * * %16 , i32 * * * * %70 , align 8 %71 = getelementptr inbounds i32 * * * , i32 * * * * %70 , i64 1 %72 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %66 , i64 1 %73 = getelementptr inbounds [ 4 x i32 * * * ] , [ 4 x i32 * * * ] * %72 , i64 0 , i64 0 store i32 * * * %16 , i32 * * * * %73 , align 8 %74 = getelementptr inbounds i32 * * * , i32 * * * * %73 , i64 1 store i32 * * * %16 , i32 * * * * %74 , align 8 %75 = getelementptr inbounds i32 * * * , i32 * * * * %74 , i64 1 store i32 * * * %16 , i32 * * * * %75 , align 8 %76 = getelementptr inbounds i32 * * * , i32 * * * * %75 , i64 1 store i32 * * * %16 , i32 * * * * %76 , align 8 %77 = bitcast [ 5 x [ 1 x [ 7 x i8 * ] ] ] * %18 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %77 , i8 * align 16 bitcast ( [ 5 x [ 1 x [ 7 x i8 * ] ] ] * @__const.func_@@ 45@@ .l_@@ 484 to i8 * ) , i64 280 , i1 false ) store i32 * @g_@@ 65 , i32 * * %19 , align 8 store i8 -1 , i8 * %20 , align 1 store %@@ struct@@ .@@ S@@ 0 * null , %@@ struct@@ .@@ S@@ 0 * * %21 , align 8 store i32 0 , i32 * %22 , align 4 %78 = getelementptr inbounds [ 10 x i32 * ] , [ 10 x i32 * ] * %23 , i64 0 , i64 0 store i32 * %12 , i32 * * %78 , align 8 %79 = getelementptr inbounds i32 * , i32 * * %78 , i64 1 store i32 * %12 , i32 * * %79 , align 8 %80 = getelementptr inbounds i32 * , i32 * * %79 , i64 1 store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 3 , i64 0 ) , i32 * * %80 , align 8 %81 = getelementptr inbounds i32 * , i32 * * %80 , i64 1 store i32 * %12 , i32 * * %81 , align 8 %82 = getelementptr inbounds i32 * , i32 * * %81 , i64 1 store i32 * %12 , i32 * * %82 , align 8 %83 = getelementptr inbounds i32 * , i32 * * %82 , i64 1 store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 3 , i64 0 ) , i32 * * %83 , align 8 %84 = getelementptr inbounds i32 * , i32 * * %83 , i64 1 store i32 * %12 , i32 * * %84 , align 8 %85 = getelementptr inbounds i32 * , i32 * * %84 , i64 1 store i32 * %12 , i32 * * %85 , align 8 %86 = getelementptr inbounds i32 * , i32 * * %85 , i64 1 store i32 * getelementptr inbounds ( [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 3 , i64 0 ) , i32 * * %86 , align 8 %87 = getelementptr inbounds i32 * , i32 * * %86 , i64 1 store i32 * %12 , i32 * * %87 , align 8 %88 = getelementptr inbounds [ 10 x i32 * ] , [ 10 x i32 * ] * %23 , i64 0 , i64 0 store i32 * * %88 , i32 * * * %24 , align 8 store i64 * %15 , i64 * * %25 , align 8 %89 = getelementptr inbounds [ 6 x [ 7 x i64 * * ] ] , [ 6 x [ 7 x i64 * * ] ] * %26 , i64 0 , i64 0 %90 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %89 , i64 0 , i64 0 store i64 * * null , i64 * * * %90 , align 8 %91 = getelementptr inbounds i64 * * , i64 * * * %90 , i64 1 store i64 * * %25 , i64 * * * %91 , align 8 %92 = getelementptr inbounds i64 * * , i64 * * * %91 , i64 1 store i64 * * %25 , i64 * * * %92 , align 8 %93 = getelementptr inbounds i64 * * , i64 * * * %92 , i64 1 store i64 * * null , i64 * * * %93 , align 8 %94 = getelementptr inbounds i64 * * , i64 * * * %93 , i64 1 store i64 * * null , i64 * * * %94 , align 8 %95 = getelementptr inbounds i64 * * , i64 * * * %94 , i64 1 store i64 * * %25 , i64 * * * %95 , align 8 %96 = getelementptr inbounds i64 * * , i64 * * * %95 , i64 1 store i64 * * %25 , i64 * * * %96 , align 8 %97 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %89 , i64 1 %98 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %97 , i64 0 , i64 0 store i64 * * %25 , i64 * * * %98 , align 8 %99 = getelementptr inbounds i64 * * , i64 * * * %98 , i64 1 store i64 * * %25 , i64 * * * %99 , align 8 %100 = getelementptr inbounds i64 * * , i64 * * * %99 , i64 1 store i64 * * %25 , i64 * * * %100 , align 8 %101 = getelementptr inbounds i64 * * , i64 * * * %100 , i64 1 store i64 * * %25 , i64 * * * %101 , align 8 %102 = getelementptr inbounds i64 * * , i64 * * * %101 , i64 1 store i64 * * %25 , i64 * * * %102 , align 8 %103 = getelementptr inbounds i64 * * , i64 * * * %102 , i64 1 store i64 * * %25 , i64 * * * %103 , align 8 %104 = getelementptr inbounds i64 * * , i64 * * * %103 , i64 1 store i64 * * %25 , i64 * * * %104 , align 8 %105 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %97 , i64 1 %106 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %105 , i64 0 , i64 0 store i64 * * %25 , i64 * * * %106 , align 8 %107 = getelementptr inbounds i64 * * , i64 * * * %106 , i64 1 store i64 * * %25 , i64 * * * %107 , align 8 %108 = getelementptr inbounds i64 * * , i64 * * * %107 , i64 1 store i64 * * %25 , i64 * * * %108 , align 8 %109 = getelementptr inbounds i64 * * , i64 * * * %108 , i64 1 store i64 * * %25 , i64 * * * %109 , align 8 %110 = getelementptr inbounds i64 * * , i64 * * * %109 , i64 1 store i64 * * %25 , i64 * * * %110 , align 8 %111 = getelementptr inbounds i64 * * , i64 * * * %110 , i64 1 store i64 * * null , i64 * * * %111 , align 8 %112 = getelementptr inbounds i64 * * , i64 * * * %111 , i64 1 store i64 * * %25 , i64 * * * %112 , align 8 %113 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %105 , i64 1 %114 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %113 , i64 0 , i64 0 store i64 * * null , i64 * * * %114 , align 8 %115 = getelementptr inbounds i64 * * , i64 * * * %114 , i64 1 store i64 * * null , i64 * * * %115 , align 8 %116 = getelementptr inbounds i64 * * , i64 * * * %115 , i64 1 store i64 * * %25 , i64 * * * %116 , align 8 %117 = getelementptr inbounds i64 * * , i64 * * * %116 , i64 1 store i64 * * %25 , i64 * * * %117 , align 8 %118 = getelementptr inbounds i64 * * , i64 * * * %117 , i64 1 store i64 * * %25 , i64 * * * %118 , align 8 %119 = getelementptr inbounds i64 * * , i64 * * * %118 , i64 1 store i64 * * %25 , i64 * * * %119 , align 8 %120 = getelementptr inbounds i64 * * , i64 * * * %119 , i64 1 store i64 * * %25 , i64 * * * %120 , align 8 %121 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %113 , i64 1 %122 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %121 , i64 0 , i64 0 store i64 * * %25 , i64 * * * %122 , align 8 %123 = getelementptr inbounds i64 * * , i64 * * * %122 , i64 1 store i64 * * %25 , i64 * * * %123 , align 8 %124 = getelementptr inbounds i64 * * , i64 * * * %123 , i64 1 store i64 * * %25 , i64 * * * %124 , align 8 %125 = getelementptr inbounds i64 * * , i64 * * * %124 , i64 1 store i64 * * %25 , i64 * * * %125 , align 8 %126 = getelementptr inbounds i64 * * , i64 * * * %125 , i64 1 store i64 * * %25 , i64 * * * %126 , align 8 %127 = getelementptr inbounds i64 * * , i64 * * * %126 , i64 1 store i64 * * %25 , i64 * * * %127 , align 8 %128 = getelementptr inbounds i64 * * , i64 * * * %127 , i64 1 store i64 * * null , i64 * * * %128 , align 8 %129 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %121 , i64 1 %130 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %129 , i64 0 , i64 0 store i64 * * null , i64 * * * %130 , align 8 %131 = getelementptr inbounds i64 * * , i64 * * * %130 , i64 1 store i64 * * %25 , i64 * * * %131 , align 8 %132 = getelementptr inbounds i64 * * , i64 * * * %131 , i64 1 store i64 * * null , i64 * * * %132 , align 8 %133 = getelementptr inbounds i64 * * , i64 * * * %132 , i64 1 store i64 * * null , i64 * * * %133 , align 8 %134 = getelementptr inbounds i64 * * , i64 * * * %133 , i64 1 store i64 * * %25 , i64 * * * %134 , align 8 %135 = getelementptr inbounds i64 * * , i64 * * * %134 , i64 1 store i64 * * %25 , i64 * * * %135 , align 8 %136 = getelementptr inbounds i64 * * , i64 * * * %135 , i64 1 store i64 * * %25 , i64 * * * %136 , align 8 %137 = getelementptr inbounds [ 6 x [ 7 x i64 * * ] ] , [ 6 x [ 7 x i64 * * ] ] * %26 , i64 0 , i64 3 %138 = getelementptr inbounds [ 7 x i64 * * ] , [ 7 x i64 * * ] * %137 , i64 0 , i64 3 store i64 * * * %138 , i64 * * * * %27 , align 8 store i8 -@@ 93 , i8 * %28 , align 1 %139 = bitcast [ 7 x i8 * ] * %29 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %139 , i8 * align 16 bitcast ( [ 7 x i8 * ] * @__const.func_@@ 45@@ .l_@@ 9@@ 09 to i8 * ) , i64 56 , i1 false ) %140 = bitcast [ 8 x [ 9 x i32 ] ] * %30 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %140 , i8 * align 16 bitcast ( [ 8 x [ 9 x i32 ] ] * @__const.func_@@ 45@@ .l_@@ 910 to i8 * ) , i64 2@@ 88 , i1 false ) store i32 147@@ 59@@ 29@@ 3@@ 48 , i32 * %31 , align 4 store i16 0 , i16 * @g_1@@ 57 , align 2 br label %141 11@@ 42 %142 = load i16 , i16 * @g_1@@ 57 , align 2 %143 = zext i16 %142 to i32 %144 = icmp sge i32 %143 , 7 br i1 %144 , label %145 , label %145 11@@ 46 %146 = load i32 , i32 * %7 , align 4 store i32 %146 , i32 * %4 , align 4 br label %147 1148 %148 = load i16 , i16 * @g_1@@ 57 , align 2 %149 = zext i16 %148 to i64 %150 = call i64 @safe_add_func_int64_t_s_s ( i64 %149 , i64 3 ) %151 = trunc i64 %150 to i16 store i16 %151 , i16 * @g_1@@ 57 , align 2 br label %152 11@@ 53 %153 = load i32 , i32 * %7 , align 4 store i32 %153 , i32 * %4 , align 4 br label %154 11@@ 55 %155 = load i32 , i32 * %4 , align 4 ret i32 %155 }
define internal i32 * @func_@@ 57 ( i8 signext %0 , i32 * %1 , i32 %2 , i16 zeroext %3 ) #0 { %5 = alloca i8 , align 1 %6 = alloca i32 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i16 , align 2 %9 = alloca i16 * , align 8 %10 = alloca i32 , align 4 %11 = alloca [ 5 x i64 * ] , align 16 %12 = alloca i32 , align 4 %13 = alloca i32 , align 4 %14 = alloca i32 , align 4 store i8 %0 , i8 * %5 , align 1 store i32 * %1 , i32 * * %6 , align 8 store i32 %2 , i32 * %7 , align 4 store i16 %3 , i16 * %8 , align 2 store i16 * null , i16 * * %9 , align 8 store i32 -4 , i32 * %10 , align 4 store i32 1 , i32 * %12 , align 4 store i32 274@@ 175@@ 69@@ 6 , i32 * %13 , align 4 store i32 0 , i32 * %14 , align 4 br label %15 116 %16 = load i32 , i32 * %14 , align 4 %17 = icmp slt i32 %16 , 5 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %14 , align 4 %20 = sext i32 %19 to i64 %21 = getelementptr inbounds [ 5 x i64 * ] , [ 5 x i64 * ] * %11 , i64 0 , i64 %33 store i64 * @g_@@ 95 , i64 * * %21 , align 8 br label %22 223 %23 = load i32 , i32 * %14 , align 4 %24 = add nsw i32 %23 , 1 store i32 %24 , i32 * %14 , align 4 br label %25 226 %26 = load i16 , i16 * @g_@@ 86 , align 2 %27 = sext i16 %26 to i32 %28 = load i16 , i16 * @g_@@ 86 , align 2 %29 = sext i16 %28 to i32 %30 = load i32 , i32 * %10 , align 4 %31 = xor i32 %30 , %33 store i32 %31 , i32 * %10 , align 4 %32 = icmp eq i32 %27 , %33 %33 = zext i1 %32 to i32 %34 = load i16 * , i16 * * %9 , align 8 %35 = icmp eq i16 * @g_@@ 86 , %36 %36 = zext i1 %35 to i32 %37 = sext i32 %36 to i64 %38 = load i32 , i32 * %12 , align 4 %39 = sext i32 %38 to i64 %40 = xor i64 %39 , 715@@ 99@@ 786@@ 269@@ 089@@ 733@@ 60 %41 = trunc i64 %40 to i32 store i32 %41 , i32 * %12 , align 4 %42 = sext i32 %41 to i64 store i64 %42 , i64 * @g_@@ 95 , align 8 %43 = load i32 , i32 * @g_@@ 65 , align 4 %44 = trunc i32 %43 to i8 %45 = load i32 , i32 * @g_@@ 65 , align 4 %46 = trunc i32 %45 to i8 %47 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %44 , i8 zeroext %46 ) %48 = zext i8 %47 to i32 %49 = load i32 , i32 * @g_@@ 24 , align 4 %50 = icmp ne i32 0 , %51 %51 = zext i1 %50 to i32 %52 = and i32 %48 , %53 %53 = load i32 , i32 * %13 , align 4 %54 = or i32 %52 , %55 %55 = sext i32 %54 to i64 %56 = or i64 %55 , 175 %57 = icmp ne i64 %56 , 0 %58 = xor i1 %57 , true %59 = zext i1 %58 to i32 %60 = load i32 , i32 * @g_@@ 24 , align 4 %61 = and i32 %59 , %62 %62 = sext i32 %61 to i64 %63 = icmp eq i64 1 , %64 %64 = zext i1 %63 to i32 %65 = sext i32 %64 to i64 %66 = and i64 %42 , %67 %67 = or i64 %37 , 37@@ 55@@ 35@@ 65@@ 73 %68 = trunc i64 %67 to i32 %69 = load i32 * , i32 * * %6 , align 8 store i32 %68 , i32 * %69 , align 4 ret i32 * @g_@@ 24 }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %9 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = icmp eq i32 %10 , 2 br i1 %11 , label %12 , label %12 113 %13 = load i8 * * , i8 * * * %5 , align 8 %14 = getelementptr inbounds i8 * , i8 * * %13 , i64 1 %15 = load i8 * , i8 * * %14 , align 8 %16 = call i32 @strcmp ( i8 * %15 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 2 , i64 0 , i64 0 ) ) #17 %17 = icmp eq i32 %16 , 0 br i1 %17 , label %18 , label %18 133 store i32 1 , i32 * %9 , align 4 br label %19 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %20 = call i32 @func_1 ( ) %21 = load i32 , i32 * @g_@@ 24 , align 4 %22 = sext i32 %21 to i64 %23 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %22 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 3 , i64 0 , i64 0 ) , i32 %23 ) %24 = load i32 , i32 * @g_@@ 65 , align 4 %25 = sext i32 %24 to i64 %26 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %25 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 4 , i64 0 , i64 0 ) , i32 %26 ) %27 = load i16 , i16 * @g_@@ 86 , align 2 %28 = sext i16 %27 to i64 %29 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %28 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 5 , i64 0 , i64 0 ) , i32 %29 ) %30 = load i64 , i64 * @g_@@ 95 , align 8 %31 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %30 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 6 , i64 0 , i64 0 ) , i32 %31 ) %32 = load i8 , i8 * @g_11@@ 5 , align 1 %33 = sext i8 %32 to i64 %34 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %33 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 7 , i64 0 , i64 0 ) , i32 %34 ) store i32 0 , i32 * %6 , align 4 br label %35 336 %36 = load i32 , i32 * %6 , align 4 %37 = icmp slt i32 %36 , 7 br i1 %37 , label %38 , label %38 333 store i32 0 , i32 * %7 , align 4 br label %39 3@@ 40 %40 = load i32 , i32 * %7 , align 4 %41 = icmp slt i32 %40 , 5 br i1 %41 , label %42 , label %42 443 %43 = load i32 , i32 * %6 , align 4 %44 = sext i32 %43 to i64 %45 = getelementptr inbounds [ 7 x [ 5 x i32 ] ] , [ 7 x [ 5 x i32 ] ] * @g_117 , i64 0 , i64 %46 %46 = load i32 , i32 * %7 , align 4 %47 = sext i32 %46 to i64 %48 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %45 , i64 0 , i64 %49 %49 = load i32 , i32 * %48 , align 4 %50 = zext i32 %49 to i64 %51 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %50 , i8 * getelementptr inbounds ( [ 12 x i8 ] , [ 12 x i8 ] * @.str.@@ 8 , i64 0 , i64 0 ) , i32 %51 ) %52 = load i32 , i32 * %9 , align 4 %53 = icmp ne i32 %52 , 0 br i1 %53 , label %54 , label %54 555 %55 = load i32 , i32 * %6 , align 4 %56 = load i32 , i32 * %7 , align 4 %57 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 18 x i8 ] , [ 18 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %55 , i32 %56 ) br label %58 52 br label %59 560 %60 = load i32 , i32 * %7 , align 4 %61 = add nsw i32 %60 , 1 store i32 %61 , i32 * %7 , align 4 br label %62 62 br label %63 6@@ 64 %64 = load i32 , i32 * %6 , align 4 %65 = add nsw i32 %64 , 1 store i32 %65 , i32 * %6 , align 4 br label %66 667 %67 = load i8 , i8 * @g_1@@ 20 , align 1 %68 = sext i8 %67 to i64 %69 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %68 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 10 , i64 0 , i64 0 ) , i32 %69 ) %70 = load i16 , i16 * @g_1@@ 28 , align 2 %71 = sext i16 %70 to i64 %72 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %71 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 11 , i64 0 , i64 0 ) , i32 %72 ) %73 = load volatile i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 31 , i32 0 , i32 0 ) , align 4 %74 = zext i32 %73 to i64 %75 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %74 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 12 , i64 0 , i64 0 ) , i32 %75 ) %76 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 31 to i16 * ) , align 4 %77 = sext i16 %76 to i64 %78 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %77 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 13 , i64 0 , i64 0 ) , i32 %78 ) store i32 0 , i32 * %6 , align 4 br label %79 7@@ 80 %80 = load i32 , i32 * %6 , align 4 %81 = icmp slt i32 %80 , 2 br i1 %81 , label %82 , label %82 883 %83 = load i32 , i32 * %6 , align 4 %84 = sext i32 %83 to i64 %85 = getelementptr inbounds [ 2 x i64 ] , [ 2 x i64 ] * @g_1@@ 43 , i64 0 , i64 %86 %86 = load i64 , i64 * %85 , align 8 %87 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %86 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 14 , i64 0 , i64 0 ) , i32 %87 ) %88 = load i32 , i32 * %9 , align 4 %89 = icmp ne i32 %88 , 0 br i1 %89 , label %90 , label %90 991 %91 = load i32 , i32 * %6 , align 4 %92 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %91 ) br label %93 92 br label %94 9@@ 95 %95 = load i32 , i32 * %6 , align 4 %96 = add nsw i32 %95 , 1 store i32 %96 , i32 * %6 , align 4 br label %97 9@@ 98 %98 = load i32 , i32 * @g_1@@ 46 , align 4 %99 = sext i32 %98 to i64 %100 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %99 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 16 , i64 0 , i64 0 ) , i32 %100 ) %101 = load i32 , i32 * @g_1@@ 47 , align 4 %102 = sext i32 %101 to i64 %103 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %102 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %103 ) %104 = load i32 , i32 * @g_1@@ 49 , align 4 %105 = sext i32 %104 to i64 %106 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %105 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 18 , i64 0 , i64 0 ) , i32 %106 ) store i32 0 , i32 * %6 , align 4 br label %107 11@@ 08 %108 = load i32 , i32 * %6 , align 4 %109 = icmp slt i32 %108 , 10 br i1 %109 , label %110 , label %110 1111 %111 = load i32 , i32 * %6 , align 4 %112 = sext i32 %111 to i64 %113 = getelementptr inbounds [ 10 x i32 ] , [ 10 x i32 ] * @g_151 , i64 0 , i64 %114 %114 = load i32 , i32 * %113 , align 4 %115 = zext i32 %114 to i64 %116 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %115 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 19 , i64 0 , i64 0 ) , i32 %116 ) %117 = load i32 , i32 * %9 , align 4 %118 = icmp ne i32 %117 , 0 br i1 %118 , label %119 , label %119 1120 %120 = load i32 , i32 * %6 , align 4 %121 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %120 ) br label %122 12 br label %123 1124 %124 = load i32 , i32 * %6 , align 4 %125 = add nsw i32 %124 , 1 store i32 %125 , i32 * %6 , align 4 br label %126 11@@ 27 %127 = load i16 , i16 * @g_1@@ 57 , align 2 %128 = zext i16 %127 to i64 %129 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %128 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 20 , i64 0 , i64 0 ) , i32 %129 ) %130 = load i8 , i8 * @g_1@@ 59 , align 1 %131 = zext i8 %130 to i64 %132 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %131 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 21 , i64 0 , i64 0 ) , i32 %132 ) %133 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 76 , i32 0 , i32 0 ) , align 4 %134 = zext i32 %133 to i64 %135 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %134 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 22 , i64 0 , i64 0 ) , i32 %135 ) %136 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 76 to i16 * ) , align 4 %137 = sext i16 %136 to i64 %138 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %137 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.@@ 23 , i64 0 , i64 0 ) , i32 %138 ) %139 = load i64 , i64 * @g_1@@ 80 , align 8 %140 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %139 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 24 , i64 0 , i64 0 ) , i32 %140 ) %141 = load volatile i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @g_2@@ 44 , i32 0 , i32 0 ) , align 2 %142 = zext i16 %141 to i64 %143 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %142 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.25 , i64 0 , i64 0 ) , i32 %143 ) store i32 0 , i32 * %6 , align 4 br label %144 1145 %145 = load i32 , i32 * %6 , align 4 %146 = icmp slt i32 %145 , 1 br i1 %146 , label %147 , label %147 1148 %148 = load i32 , i32 * %6 , align 4 %149 = sext i32 %148 to i64 %150 = getelementptr inbounds [ 1 x %un@@ ion.@@ U@@ 1 ] , [ 1 x %un@@ ion.@@ U@@ 1 ] * @g_2@@ 60 , i64 0 , i64 %151 %151 = bitcast %un@@ ion.@@ U@@ 1 * %150 to i32 * %152 = load volatile i32 , i32 * %151 , align 4 %153 = zext i32 %152 to i64 %154 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %153 , i8 * getelementptr inbounds ( [ 12 x i8 ] , [ 12 x i8 ] * @.str.26 , i64 0 , i64 0 ) , i32 %154 ) %155 = load i32 , i32 * %6 , align 4 %156 = sext i32 %155 to i64 %157 = getelementptr inbounds [ 1 x %un@@ ion.@@ U@@ 1 ] , [ 1 x %un@@ ion.@@ U@@ 1 ] * @g_2@@ 60 , i64 0 , i64 %158 %158 = bitcast %un@@ ion.@@ U@@ 1 * %157 to i16 * %159 = load volatile i16 , i16 * %158 , align 4 %160 = sext i16 %159 to i64 %161 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %160 , i8 * getelementptr inbounds ( [ 12 x i8 ] , [ 12 x i8 ] * @.str.27 , i64 0 , i64 0 ) , i32 %161 ) %162 = load i32 , i32 * %9 , align 4 %163 = icmp ne i32 %162 , 0 br i1 %163 , label %164 , label %164 11@@ 65 %165 = load i32 , i32 * %6 , align 4 %166 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %165 ) br label %167 12 br label %168 1169 %169 = load i32 , i32 * %6 , align 4 %170 = add nsw i32 %169 , 1 store i32 %170 , i32 * %6 , align 4 br label %171 11@@ 72 %172 = load i8 , i8 * @g_3@@ 21 , align 1 %173 = zext i8 %172 to i64 %174 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %173 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.28 , i64 0 , i64 0 ) , i32 %174 ) %175 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_3@@ 73 , i32 0 , i32 0 ) , align 4 %176 = zext i32 %175 to i64 %177 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %176 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.29 , i64 0 , i64 0 ) , i32 %177 ) %178 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_3@@ 73 to i16 * ) , align 4 %179 = sext i16 %178 to i64 %180 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %179 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.30 , i64 0 , i64 0 ) , i32 %180 ) %181 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 -4@@ 81@@ 2@@ 140@@ 51 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.31 , i64 0 , i64 0 ) , i32 %181 ) %182 = load i16 , i16 * @g_@@ 45@@ 4 , align 2 %183 = sext i16 %182 to i64 %184 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %183 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.32 , i64 0 , i64 0 ) , i32 %184 ) %185 = load volatile i16 , i16 * @g_5@@ 13 , align 2 %186 = sext i16 %185 to i64 %187 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %186 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.33 , i64 0 , i64 0 ) , i32 %187 ) %188 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_5@@ 17 , i32 0 , i32 0 ) , align 4 %189 = zext i32 %188 to i64 %190 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %189 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.34 , i64 0 , i64 0 ) , i32 %190 ) %191 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_5@@ 17 to i16 * ) , align 4 %192 = sext i16 %191 to i64 %193 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %192 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.35 , i64 0 , i64 0 ) , i32 %193 ) store i32 0 , i32 * %6 , align 4 br label %194 11@@ 95 %195 = load i32 , i32 * %6 , align 4 %196 = icmp slt i32 %195 , 3 br i1 %196 , label %197 , label %197 1198 %198 = load i32 , i32 * %6 , align 4 %199 = sext i32 %198 to i64 %200 = getelementptr inbounds [ 3 x i16 ] , [ 3 x i16 ] * @g_5@@ 20 , i64 0 , i64 %201 %201 = load volatile i16 , i16 * %200 , align 2 %202 = sext i16 %201 to i64 %203 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %202 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.36 , i64 0 , i64 0 ) , i32 %203 ) %204 = load i32 , i32 * %9 , align 4 %205 = icmp ne i32 %204 , 0 br i1 %205 , label %206 , label %206 2207 %207 = load i32 , i32 * %6 , align 4 %208 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %207 ) br label %209 22 br label %210 2211 %211 = load i32 , i32 * %6 , align 4 %212 = add nsw i32 %211 , 1 store i32 %212 , i32 * %6 , align 4 br label %213 22@@ 14 %214 = load i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @g_5@@ 30 , i32 0 , i32 0 ) , align 2 %215 = zext i16 %214 to i64 %216 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %215 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.37 , i64 0 , i64 0 ) , i32 %216 ) %217 = load i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @g_5@@ 32 , i32 0 , i32 0 ) , align 2 %218 = zext i16 %217 to i64 %219 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %218 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.38 , i64 0 , i64 0 ) , i32 %219 ) %220 = load volatile i16 , i16 * @g_@@ 556 , align 2 %221 = sext i16 %220 to i64 %222 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %221 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.39 , i64 0 , i64 0 ) , i32 %222 ) %223 = load i32 , i32 * @g_@@ 587 , align 4 %224 = sext i32 %223 to i64 %225 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %224 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.40 , i64 0 , i64 0 ) , i32 %225 ) %226 = load i32 , i32 * @g_@@ 58@@ 9 , align 4 %227 = sext i32 %226 to i64 %228 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %227 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.41 , i64 0 , i64 0 ) , i32 %228 ) store i32 0 , i32 * %6 , align 4 br label %229 22@@ 30 %230 = load i32 , i32 * %6 , align 4 %231 = icmp slt i32 %230 , 7 br i1 %231 , label %232 , label %232 233 store i32 0 , i32 * %7 , align 4 br label %233 22@@ 34 %234 = load i32 , i32 * %7 , align 4 %235 = icmp slt i32 %234 , 1 br i1 %235 , label %236 , label %236 22@@ 37 %237 = load i32 , i32 * %6 , align 4 %238 = sext i32 %237 to i64 %239 = getelementptr inbounds [ 7 x [ 1 x i32 ] ] , [ 7 x [ 1 x i32 ] ] * @g_6@@ 04 , i64 0 , i64 %240 %240 = load i32 , i32 * %7 , align 4 %241 = sext i32 %240 to i64 %242 = getelementptr inbounds [ 1 x i32 ] , [ 1 x i32 ] * %239 , i64 0 , i64 %243 %243 = load i32 , i32 * %242 , align 4 %244 = sext i32 %243 to i64 %245 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %244 , i8 * getelementptr inbounds ( [ 12 x i8 ] , [ 12 x i8 ] * @.str.42 , i64 0 , i64 0 ) , i32 %245 ) %246 = load i32 , i32 * %9 , align 4 %247 = icmp ne i32 %246 , 0 br i1 %247 , label %248 , label %248 2249 %249 = load i32 , i32 * %6 , align 4 %250 = load i32 , i32 * %7 , align 4 %251 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 18 x i8 ] , [ 18 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %249 , i32 %250 ) br label %252 22 br label %253 2254 %254 = load i32 , i32 * %7 , align 4 %255 = add nsw i32 %254 , 1 store i32 %255 , i32 * %7 , align 4 br label %256 22 br label %257 2258 %258 = load i32 , i32 * %6 , align 4 %259 = add nsw i32 %258 , 1 store i32 %259 , i32 * %6 , align 4 br label %260 2261 %261 = load i8 , i8 * @g_6@@ 44 , align 1 %262 = sext i8 %261 to i64 %263 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %262 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.43 , i64 0 , i64 0 ) , i32 %263 ) %264 = load volatile i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_674 , i32 0 , i32 0 ) , align 4 %265 = zext i32 %264 to i64 %266 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %265 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.44 , i64 0 , i64 0 ) , i32 %266 ) %267 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_674 to i16 * ) , align 4 %268 = sext i16 %267 to i64 %269 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %268 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.45 , i64 0 , i64 0 ) , i32 %269 ) %270 = load i8 , i8 * @g_8@@ 32 , align 1 %271 = zext i8 %270 to i64 %272 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %271 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.46 , i64 0 , i64 0 ) , i32 %272 ) %273 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_9@@ 71 , i32 0 , i32 0 ) , align 4 %274 = zext i32 %273 to i64 %275 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %274 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.47 , i64 0 , i64 0 ) , i32 %275 ) %276 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_9@@ 71 to i16 * ) , align 4 %277 = sext i16 %276 to i64 %278 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %277 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.48 , i64 0 , i64 0 ) , i32 %278 ) %279 = load i32 , i32 * @g_9@@ 88 , align 4 %280 = zext i32 %279 to i64 %281 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %280 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.49 , i64 0 , i64 0 ) , i32 %281 ) store i32 0 , i32 * %6 , align 4 br label %282 22@@ 83 %283 = load i32 , i32 * %6 , align 4 %284 = icmp slt i32 %283 , 6 br i1 %284 , label %285 , label %285 233 store i32 0 , i32 * %7 , align 4 br label %286 22@@ 87 %287 = load i32 , i32 * %7 , align 4 %288 = icmp slt i32 %287 , 9 br i1 %288 , label %289 , label %289 22@@ 90 %290 = load i32 , i32 * %6 , align 4 %291 = sext i32 %290 to i64 %292 = getelementptr inbounds [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] , [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] * @g_10@@ 87 , i64 0 , i64 %293 %293 = load i32 , i32 * %7 , align 4 %294 = sext i32 %293 to i64 %295 = getelementptr inbounds [ 9 x %un@@ ion.@@ U@@ 1 ] , [ 9 x %un@@ ion.@@ U@@ 1 ] * %292 , i64 0 , i64 %296 %296 = bitcast %un@@ ion.@@ U@@ 1 * %295 to i32 * %297 = load i32 , i32 * %296 , align 4 %298 = zext i32 %297 to i64 %299 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %298 , i8 * getelementptr inbounds ( [ 16 x i8 ] , [ 16 x i8 ] * @.str.50 , i64 0 , i64 0 ) , i32 %299 ) %300 = load i32 , i32 * %6 , align 4 %301 = sext i32 %300 to i64 %302 = getelementptr inbounds [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] , [ 6 x [ 9 x %un@@ ion.@@ U@@ 1 ] ] * @g_10@@ 87 , i64 0 , i64 %303 %303 = load i32 , i32 * %7 , align 4 %304 = sext i32 %303 to i64 %305 = getelementptr inbounds [ 9 x %un@@ ion.@@ U@@ 1 ] , [ 9 x %un@@ ion.@@ U@@ 1 ] * %302 , i64 0 , i64 %306 %306 = bitcast %un@@ ion.@@ U@@ 1 * %305 to i16 * %307 = load volatile i16 , i16 * %306 , align 4 %308 = sext i16 %307 to i64 %309 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %308 , i8 * getelementptr inbounds ( [ 16 x i8 ] , [ 16 x i8 ] * @.str.51 , i64 0 , i64 0 ) , i32 %309 ) %310 = load i32 , i32 * %9 , align 4 %311 = icmp ne i32 %310 , 0 br i1 %311 , label %312 , label %312 3313 %313 = load i32 , i32 * %6 , align 4 %314 = load i32 , i32 * %7 , align 4 %315 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 18 x i8 ] , [ 18 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %313 , i32 %314 ) br label %316 32 br label %317 3318 %318 = load i32 , i32 * %7 , align 4 %319 = add nsw i32 %318 , 1 store i32 %319 , i32 * %7 , align 4 br label %320 32 br label %321 3322 %322 = load i32 , i32 * %6 , align 4 %323 = add nsw i32 %322 , 1 store i32 %323 , i32 * %6 , align 4 br label %324 3325 %325 = load i32 , i32 * @g_1@@ 118 , align 4 %326 = zext i32 %325 to i64 %327 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %326 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.52 , i64 0 , i64 0 ) , i32 %327 ) store i32 0 , i32 * %6 , align 4 br label %328 3329 %329 = load i32 , i32 * %6 , align 4 %330 = icmp slt i32 %329 , 5 br i1 %330 , label %331 , label %331 3332 %332 = load i32 , i32 * %6 , align 4 %333 = sext i32 %332 to i64 %334 = getelementptr inbounds [ 5 x i16 ] , [ 5 x i16 ] * @g_11@@ 56 , i64 0 , i64 %335 %335 = load i16 , i16 * %334 , align 2 %336 = zext i16 %335 to i64 %337 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %336 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.53 , i64 0 , i64 0 ) , i32 %337 ) %338 = load i32 , i32 * %9 , align 4 %339 = icmp ne i32 %338 , 0 br i1 %339 , label %340 , label %340 33@@ 41 %341 = load i32 , i32 * %6 , align 4 %342 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %341 ) br label %343 32 br label %344 33@@ 45 %345 = load i32 , i32 * %6 , align 4 %346 = add nsw i32 %345 , 1 store i32 %346 , i32 * %6 , align 4 br label %347 3348 %348 = load i16 , i16 * @g_11@@ 89 , align 2 %349 = zext i16 %348 to i64 %350 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %349 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.54 , i64 0 , i64 0 ) , i32 %350 ) %351 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_11@@ 94 , i32 0 , i32 0 ) , align 4 %352 = zext i32 %351 to i64 %353 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %352 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.55 , i64 0 , i64 0 ) , i32 %353 ) %354 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_11@@ 94 to i16 * ) , align 4 %355 = sext i16 %354 to i64 %356 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %355 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.56 , i64 0 , i64 0 ) , i32 %356 ) %357 = load volatile i16 , i16 * @g_1@@ 255 , align 2 %358 = zext i16 %357 to i64 %359 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %358 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.57 , i64 0 , i64 0 ) , i32 %359 ) %360 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 -1@@ 07 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.58 , i64 0 , i64 0 ) , i32 %360 ) %361 = load i8 , i8 * @g_1@@ 402 , align 1 %362 = zext i8 %361 to i64 %363 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %362 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.59 , i64 0 , i64 0 ) , i32 %363 ) store i32 0 , i32 * %6 , align 4 br label %364 33@@ 65 %365 = load i32 , i32 * %6 , align 4 %366 = icmp slt i32 %365 , 3 br i1 %366 , label %367 , label %367 333 store i32 0 , i32 * %7 , align 4 br label %368 3369 %369 = load i32 , i32 * %7 , align 4 %370 = icmp slt i32 %369 , 3 br i1 %370 , label %371 , label %371 33@@ 72 %372 = load i32 , i32 * %6 , align 4 %373 = sext i32 %372 to i64 %374 = getelementptr inbounds [ 3 x [ 3 x i64 ] ] , [ 3 x [ 3 x i64 ] ] * @g_1@@ 462 , i64 0 , i64 %375 %375 = load i32 , i32 * %7 , align 4 %376 = sext i32 %375 to i64 %377 = getelementptr inbounds [ 3 x i64 ] , [ 3 x i64 ] * %374 , i64 0 , i64 %378 %378 = load i64 , i64 * %377 , align 8 %379 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %378 , i8 * getelementptr inbounds ( [ 13 x i8 ] , [ 13 x i8 ] * @.str.60 , i64 0 , i64 0 ) , i32 %379 ) %380 = load i32 , i32 * %9 , align 4 %381 = icmp ne i32 %380 , 0 br i1 %381 , label %382 , label %382 338@@ 3 %383 = load i32 , i32 * %6 , align 4 %384 = load i32 , i32 * %7 , align 4 %385 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 18 x i8 ] , [ 18 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %383 , i32 %384 ) br label %386 32 br label %387 3@@ 388 %388 = load i32 , i32 * %7 , align 4 %389 = add nsw i32 %388 , 1 store i32 %389 , i32 * %7 , align 4 br label %390 32 br label %391 33@@ 92 %392 = load i32 , i32 * %6 , align 4 %393 = add nsw i32 %392 , 1 store i32 %393 , i32 * %6 , align 4 br label %394 3395 %395 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 0 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.61 , i64 0 , i64 0 ) , i32 %395 ) %396 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_15@@ 73 , i32 0 , i32 0 ) , align 4 %397 = zext i32 %396 to i64 %398 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %397 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.62 , i64 0 , i64 0 ) , i32 %398 ) %399 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_15@@ 73 to i16 * ) , align 4 %400 = sext i16 %399 to i64 %401 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %400 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.63 , i64 0 , i64 0 ) , i32 %401 ) %402 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 6@@ 32 , i32 0 , i32 0 ) , align 4 %403 = zext i32 %402 to i64 %404 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %403 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.64 , i64 0 , i64 0 ) , i32 %404 ) %405 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 6@@ 32 to i16 * ) , align 4 %406 = sext i16 %405 to i64 %407 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %406 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.65 , i64 0 , i64 0 ) , i32 %407 ) store i32 0 , i32 * %6 , align 4 br label %408 440@@ 9 %409 = load i32 , i32 * %6 , align 4 %410 = icmp slt i32 %409 , 8 br i1 %410 , label %411 , label %411 433 store i32 0 , i32 * %7 , align 4 br label %412 44@@ 13 %413 = load i32 , i32 * %7 , align 4 %414 = icmp slt i32 %413 , 10 br i1 %414 , label %415 , label %415 433 store i32 0 , i32 * %8 , align 4 br label %416 44@@ 17 %417 = load i32 , i32 * %8 , align 4 %418 = icmp slt i32 %417 , 1 br i1 %418 , label %419 , label %419 44@@ 20 %420 = load i32 , i32 * %6 , align 4 %421 = sext i32 %420 to i64 %422 = getelementptr inbounds [ 8 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] ] , [ 8 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] ] * @g_1@@ 7@@ 36 , i64 0 , i64 %423 %423 = load i32 , i32 * %7 , align 4 %424 = sext i32 %423 to i64 %425 = getelementptr inbounds [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] , [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] * %422 , i64 0 , i64 %426 %426 = load i32 , i32 * %8 , align 4 %427 = sext i32 %426 to i64 %428 = getelementptr inbounds [ 1 x %un@@ ion.@@ U@@ 1 ] , [ 1 x %un@@ ion.@@ U@@ 1 ] * %425 , i64 0 , i64 %429 %429 = bitcast %un@@ ion.@@ U@@ 1 * %428 to i32 * %430 = load volatile i32 , i32 * %429 , align 4 %431 = zext i32 %430 to i64 %432 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %431 , i8 * getelementptr inbounds ( [ 19 x i8 ] , [ 19 x i8 ] * @.str.66 , i64 0 , i64 0 ) , i32 %432 ) %433 = load i32 , i32 * %6 , align 4 %434 = sext i32 %433 to i64 %435 = getelementptr inbounds [ 8 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] ] , [ 8 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] ] * @g_1@@ 7@@ 36 , i64 0 , i64 %436 %436 = load i32 , i32 * %7 , align 4 %437 = sext i32 %436 to i64 %438 = getelementptr inbounds [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] , [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 ] ] * %435 , i64 0 , i64 %439 %439 = load i32 , i32 * %8 , align 4 %440 = sext i32 %439 to i64 %441 = getelementptr inbounds [ 1 x %un@@ ion.@@ U@@ 1 ] , [ 1 x %un@@ ion.@@ U@@ 1 ] * %438 , i64 0 , i64 %442 %442 = bitcast %un@@ ion.@@ U@@ 1 * %441 to i16 * %443 = load volatile i16 , i16 * %442 , align 4 %444 = sext i16 %443 to i64 %445 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %444 , i8 * getelementptr inbounds ( [ 19 x i8 ] , [ 19 x i8 ] * @.str.67 , i64 0 , i64 0 ) , i32 %445 ) %446 = load i32 , i32 * %9 , align 4 %447 = icmp ne i32 %446 , 0 br i1 %447 , label %448 , label %448 4449 %449 = load i32 , i32 * %6 , align 4 %450 = load i32 , i32 * %7 , align 4 %451 = load i32 , i32 * %8 , align 4 %452 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.68 , i64 0 , i64 0 ) , i32 %449 , i32 %450 , i32 %451 ) br label %453 42 br label %454 445@@ 5 %455 = load i32 , i32 * %8 , align 4 %456 = add nsw i32 %455 , 1 store i32 %456 , i32 * %8 , align 4 br label %457 42 br label %458 445@@ 9 %459 = load i32 , i32 * %7 , align 4 %460 = add nsw i32 %459 , 1 store i32 %460 , i32 * %7 , align 4 br label %461 42 br label %462 4463 %463 = load i32 , i32 * %6 , align 4 %464 = add nsw i32 %463 , 1 store i32 %464 , i32 * %6 , align 4 br label %465 4@@ 466 %466 = load i64 , i64 * @g_1@@ 75@@ 0 , align 8 %467 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %466 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.69 , i64 0 , i64 0 ) , i32 %467 ) %468 = load i16 , i16 * @g_1@@ 758 , align 2 %469 = sext i16 %468 to i64 %470 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %469 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.70 , i64 0 , i64 0 ) , i32 %470 ) store i32 0 , i32 * %6 , align 4 br label %471 4@@ 472 %472 = load i32 , i32 * %6 , align 4 %473 = icmp slt i32 %472 , 10 br i1 %473 , label %474 , label %474 433 store i32 0 , i32 * %7 , align 4 br label %475 447@@ 6 %476 = load i32 , i32 * %7 , align 4 %477 = icmp slt i32 %476 , 3 br i1 %477 , label %478 , label %478 433 store i32 0 , i32 * %8 , align 4 br label %479 4480 %480 = load i32 , i32 * %8 , align 4 %481 = icmp slt i32 %480 , 4 br i1 %481 , label %482 , label %482 4483 %483 = load i32 , i32 * %6 , align 4 %484 = sext i32 %483 to i64 %485 = getelementptr inbounds [ 10 x [ 3 x [ 4 x i64 ] ] ] , [ 10 x [ 3 x [ 4 x i64 ] ] ] * @g_1@@ 8@@ 01 , i64 0 , i64 %486 %486 = load i32 , i32 * %7 , align 4 %487 = sext i32 %486 to i64 %488 = getelementptr inbounds [ 3 x [ 4 x i64 ] ] , [ 3 x [ 4 x i64 ] ] * %485 , i64 0 , i64 %489 %489 = load i32 , i32 * %8 , align 4 %490 = sext i32 %489 to i64 %491 = getelementptr inbounds [ 4 x i64 ] , [ 4 x i64 ] * %488 , i64 0 , i64 %492 %492 = load i64 , i64 * %491 , align 8 %493 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %492 , i8 * getelementptr inbounds ( [ 16 x i8 ] , [ 16 x i8 ] * @.str.71 , i64 0 , i64 0 ) , i32 %493 ) %494 = load i32 , i32 * %9 , align 4 %495 = icmp ne i32 %494 , 0 br i1 %495 , label %496 , label %496 4497 %497 = load i32 , i32 * %6 , align 4 %498 = load i32 , i32 * %7 , align 4 %499 = load i32 , i32 * %8 , align 4 %500 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.68 , i64 0 , i64 0 ) , i32 %497 , i32 %498 , i32 %499 ) br label %501 52 br label %502 5503 %503 = load i32 , i32 * %8 , align 4 %504 = add nsw i32 %503 , 1 store i32 %504 , i32 * %8 , align 4 br label %505 52 br label %506 5507 %507 = load i32 , i32 * %7 , align 4 %508 = add nsw i32 %507 , 1 store i32 %508 , i32 * %7 , align 4 br label %509 52 br label %510 55@@ 11 %511 = load i32 , i32 * %6 , align 4 %512 = add nsw i32 %511 , 1 store i32 %512 , i32 * %6 , align 4 br label %513 5514 %514 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 808 , i32 0 , i32 0 ) , align 4 %515 = zext i32 %514 to i64 %516 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %515 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.72 , i64 0 , i64 0 ) , i32 %516 ) %517 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 808 to i16 * ) , align 4 %518 = sext i16 %517 to i64 %519 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %518 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.73 , i64 0 , i64 0 ) , i32 %519 ) store i32 0 , i32 * %6 , align 4 br label %520 55@@ 21 %521 = load i32 , i32 * %6 , align 4 %522 = icmp slt i32 %521 , 6 br i1 %522 , label %523 , label %523 5524 %524 = load i32 , i32 * %6 , align 4 %525 = sext i32 %524 to i64 %526 = getelementptr inbounds [ 6 x i8 ] , [ 6 x i8 ] * @g_1@@ 854 , i64 0 , i64 %527 %527 = load volatile i8 , i8 * %526 , align 1 %528 = sext i8 %527 to i64 %529 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %528 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.74 , i64 0 , i64 0 ) , i32 %529 ) %530 = load i32 , i32 * %9 , align 4 %531 = icmp ne i32 %530 , 0 br i1 %531 , label %532 , label %532 5533 %533 = load i32 , i32 * %6 , align 4 %534 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) , i32 %533 ) br label %535 52 br label %536 55@@ 37 %537 = load i32 , i32 * %6 , align 4 %538 = add nsw i32 %537 , 1 store i32 %538 , i32 * %6 , align 4 br label %539 55@@ 40 %540 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 867 , i32 0 , i32 0 ) , align 4 %541 = zext i32 %540 to i64 %542 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %541 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.75 , i64 0 , i64 0 ) , i32 %542 ) %543 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 867 to i16 * ) , align 4 %544 = sext i16 %543 to i64 %545 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %544 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.76 , i64 0 , i64 0 ) , i32 %545 ) %546 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 , i32 0 , i32 0 ) , align 4 %547 = zext i32 %546 to i64 %548 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %547 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.77 , i64 0 , i64 0 ) , i32 %548 ) %549 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 9@@ 32 to i16 * ) , align 4 %550 = sext i16 %549 to i64 %551 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %550 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.78 , i64 0 , i64 0 ) , i32 %551 ) %552 = load volatile i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_1@@ 944 , i32 0 , i32 0 ) , align 4 %553 = zext i32 %552 to i64 %554 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %553 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.79 , i64 0 , i64 0 ) , i32 %554 ) %555 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_1@@ 944 to i16 * ) , align 4 %556 = sext i16 %555 to i64 %557 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %556 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.80 , i64 0 , i64 0 ) , i32 %557 ) %558 = load i32 , i32 * getelementptr inbounds ( %un@@ ion.@@ U@@ 1 , %un@@ ion.@@ U@@ 1 * @g_@@ 20@@ 33 , i32 0 , i32 0 ) , align 4 %559 = zext i32 %558 to i64 %560 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %559 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.81 , i64 0 , i64 0 ) , i32 %560 ) %561 = load volatile i16 , i16 * bitcast ( %un@@ ion.@@ U@@ 1 * @g_@@ 20@@ 33 to i16 * ) , align 4 %562 = sext i16 %561 to i64 %563 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %562 , i8 * getelementptr inbounds ( [ 10 x i8 ] , [ 10 x i8 ] * @.str.82 , i64 0 , i64 0 ) , i32 %563 ) %564 = load volatile i64 , i64 * @g_2@@ 126 , align 8 %565 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %564 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.83 , i64 0 , i64 0 ) , i32 %565 ) %566 = load i32 , i32 * @g_22@@ 19 , align 4 %567 = zext i32 %566 to i64 %568 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %567 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.84 , i64 0 , i64 0 ) , i32 %568 ) %569 = load i32 , i32 * @g_22@@ 60 , align 4 %570 = zext i32 %569 to i64 %571 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %570 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.85 , i64 0 , i64 0 ) , i32 %571 ) %572 = load i32 , i32 * @crc32_context , align 4 %573 = zext i32 %572 to i64 %574 = xor i64 %573 , 4294967295 %575 = trunc i64 %574 to i32 %576 = load i32 , i32 * %9 , align 4 call void @platform_main_end ( i32 %575 , i32 %576 ) ret i32 0 }
define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca i8 , align 1 %2 = alloca i32 * * * * * , align 8 %3 = alloca i32 , align 4 %4 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 store i8 -4 , i8 * %1 , align 1 store i32 * * * * * @g_11@@ 43 , i32 * * * * * * %2 , align 8 store i32 18@@ 4@@ 55@@ 782@@ 86 , i32 * %3 , align 4 %5 = bitcast %@@ struct@@ .@@ S@@ 0 * %4 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %5 , i8 * align 8 getelementptr inbounds ( { i8 , i8 , i32 , i64 }
define internal i32 @func_@@ 2 ( %@@ struct@@ .@@ S@@ 2 * by@@ val ( %@@ struct@@ .@@ S@@ 2 ) align 8 %0 , i32 %1 , i64 %2 , i64 %3 , i8 signext %4 ) #0 { %6 = alloca i32 , align 4 %7 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %8 = alloca i32 , align 4 %9 = alloca i8 , align 1 %10 = alloca [ 10 x [ 6 x i8 ] ] , align 16 %11 = alloca %@@ struct@@ .@@ S3 * , align 8 %12 = alloca i32 , align 4 %13 = alloca i32 , align 4 %14 = alloca [ 1 x i32 ] , align 4 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = alloca i32 , align 4 %18 = alloca i16 , align 2 %19 = alloca %@@ struct@@ .@@ S3 * * , align 8 %20 = alloca %@@ struct@@ .@@ S3 * * , align 8 %21 = alloca [ 6 x [ 3 x %@@ struct@@ .@@ S3 * * ] ] , align 16 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca i32 * , align 8 %25 = alloca i32 , align 4 %26 = alloca i32 * , align 8 %27 = alloca i32 * , align 8 %28 = alloca i32 * , align 8 %29 = alloca [ 9 x [ 5 x [ 5 x i32 * ] ] ] , align 16 %30 = alloca i32 , align 4 %31 = alloca i32 , align 4 %32 = alloca i32 , align 4 %33 = bitcast %@@ struct@@ .@@ S@@ 0 * %7 to { i64 , i64 }
define internal i64 @func_@@ 8 ( i32 %0 ) #0 { %2 = alloca i32 , align 4 %3 = alloca i32 * , align 8 %4 = alloca i32 , align 4 %5 = alloca i16 * , align 8 %6 = alloca [ 10 x [ 7 x [ 3 x i64 * ] ] ] , align 16 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca [ 7 x [ 1 x i32 * ] ] , align 16 %10 = alloca i32 , align 4 %11 = alloca i32 * , align 8 %12 = alloca [ 3 x i32 * * ] , align 16 %13 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %14 = alloca %@@ struct@@ .@@ S@@ 1 * * * , align 8 %15 = alloca i32 * , align 8 %16 = alloca i32 * * , align 8 %17 = alloca [ 1 x [ 7 x i32 * * * ] ] , align 16 %18 = alloca i16 , align 2 %19 = alloca i64 , align 8 %20 = alloca i32 , align 4 %21 = alloca i32 , align 4 %22 = alloca i32 , align 4 %23 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %24 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %25 = alloca i32 * , align 8 %26 = alloca i32 * * , align 8 %27 = alloca i32 , align 4 %28 = alloca i8 , align 1 %29 = alloca [ 4 x i32 * * ] , align 16 %30 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 store i32 * @g_@@ 28 , i32 * * %3 , align 8 store i32 2 , i32 * %4 , align 4 store i16 * @g_@@ 40 , i16 * * %5 , align 8 %31 = bitcast [ 10 x [ 7 x [ 3 x i64 * ] ] ] * %6 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %31 , i8 * align 16 bitcast ( [ 10 x [ 7 x [ 3 x i64 * ] ] ] * @__const.func_@@ 8.@@ l_@@ 41 to i8 * ) , i64 16@@ 80 , i1 false ) store i32 0 , i32 * %7 , align 4 store i32 11@@ 48@@ 240@@ 256 , i32 * %8 , align 4 %32 = bitcast [ 7 x [ 1 x i32 * ] ] * %9 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %32 , i8 * align 16 bitcast ( [ 7 x [ 1 x i32 * ] ] * @__const.func_@@ 8.@@ l_@@ 266 to i8 * ) , i64 56 , i1 false ) store i32 -15@@ 32@@ 19@@ 79@@ 96 , i32 * %10 , align 4 store i32 * %7 , i32 * * %11 , align 8 store %@@ struct@@ .@@ S@@ 1 * * null , %@@ struct@@ .@@ S@@ 1 * * * %13 , align 8 store %@@ struct@@ .@@ S@@ 1 * * * @g_6@@ 22 , %@@ struct@@ .@@ S@@ 1 * * * * %14 , align 8 store i32 * @g_1267 , i32 * * %15 , align 8 store i32 * * %15 , i32 * * * %16 , align 8 %33 = getelementptr inbounds [ 1 x [ 7 x i32 * * * ] ] , [ 1 x [ 7 x i32 * * * ] ] * %17 , i64 0 , i64 0 %34 = getelementptr inbounds [ 7 x i32 * * * ] , [ 7 x i32 * * * ] * %33 , i64 0 , i64 0 store i32 * * * %16 , i32 * * * * %34 , align 8 %35 = getelementptr inbounds i32 * * * , i32 * * * * %34 , i64 1 store i32 * * * %16 , i32 * * * * %35 , align 8 %36 = getelementptr inbounds i32 * * * , i32 * * * * %35 , i64 1 store i32 * * * %16 , i32 * * * * %36 , align 8 %37 = getelementptr inbounds i32 * * * , i32 * * * * %36 , i64 1 store i32 * * * %16 , i32 * * * * %37 , align 8 %38 = getelementptr inbounds i32 * * * , i32 * * * * %37 , i64 1 store i32 * * * %16 , i32 * * * * %38 , align 8 %39 = getelementptr inbounds i32 * * * , i32 * * * * %38 , i64 1 store i32 * * * %16 , i32 * * * * %39 , align 8 %40 = getelementptr inbounds i32 * * * , i32 * * * * %39 , i64 1 store i32 * * * %16 , i32 * * * * %40 , align 8 store i16 -@@ 5@@ 221 , i16 * %18 , align 2 store i64 1 , i64 * %19 , align 8 store i32 0 , i32 * %20 , align 4 br label %41 442 %42 = load i32 , i32 * %20 , align 4 %43 = icmp slt i32 %42 , 3 br i1 %43 , label %44 , label %44 4@@ 45 %45 = load i32 , i32 * %20 , align 4 %46 = sext i32 %45 to i64 %47 = getelementptr inbounds [ 3 x i32 * * ] , [ 3 x i32 * * ] * %12 , i64 0 , i64 %33 store i32 * * null , i32 * * * %47 , align 8 br label %48 449 %49 = load i32 , i32 * %20 , align 4 %50 = add nsw i32 %49 , 1 store i32 %50 , i32 * %20 , align 4 br label %51 552 %52 = load i32 * , i32 * * %3 , align 8 %53 = load i32 , i32 * %52 , align 4 %54 = add i32 %53 , -1 store i32 %54 , i32 * %52 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = trunc i32 %55 to i16 %57 = call signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %56 , i32 13 ) %58 = sext i16 %57 to i32 %59 = xor i32 %58 , -1 %60 = trunc i32 %59 to i16 %61 = load i8 , i8 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 2 ) , align 1 %62 = zext i8 %61 to i16 %63 = load i16 * , i16 * * %5 , align 8 store i16 %62 , i16 * %63 , align 2 %64 = call signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %60 , i16 signext %62 ) %65 = sext i16 %64 to i32 %66 = load i32 , i32 * %4 , align 4 %67 = call i32 @safe_mod_func_uint32_t_u_u ( i32 %65 , i32 %66 ) %68 = load i32 , i32 * %2 , align 4 %69 = icmp ult i32 %67 , %70 %70 = zext i1 %69 to i32 %71 = sext i32 %70 to i64 %72 = load i64 , i64 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 1 ) , align 1 %73 = xor i64 %71 , %74 %74 = trunc i64 %73 to i32 store i32 %74 , i32 * %4 , align 4 %75 = sext i32 %74 to i64 %76 = load i32 , i32 * %2 , align 4 %77 = call i32 * @func_@@ 47 ( i32 %76 ) %78 = load i32 , i32 * %7 , align 4 %79 = load i32 , i32 * %2 , align 4 %80 = zext i32 %79 to i64 %81 = call i64 @safe_mod_func_int64_t_s_s ( i64 %80 , i64 11@@ 48@@ 240@@ 256 ) %82 = load i32 , i32 * %2 , align 4 %83 = load i32 , i32 * %10 , align 4 %84 = and i32 %83 , %33 store i32 %84 , i32 * %10 , align 4 store i32 %84 , i32 * %7 , align 4 %85 = sext i32 %84 to i64 %86 = or i64 %85 , 4294967295 %87 = bitcast %@@ struct@@ .@@ S@@ 0 * %24 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %87 , i8 * align 1 bitcast ( %@@ struct@@ .@@ S@@ 0 * getelementptr inbounds ( %@@ struct@@ .@@ S3 , %@@ struct@@ .@@ S3 * bitcast ( < { i8 , i8 , i8 , < { i16 , i8 , i32 , i32 , i8 , i8 , i8 , i8 }
define internal i32 * @func_@@ 11 ( i64 %0 , i64 %1 , i32 * %2 , i64 %3 , i64 %4 , i16 signext %5 ) #0 { %7 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %8 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %9 = alloca i32 * , align 8 %10 = alloca i16 , align 2 %11 = alloca i32 * * * , align 8 %12 = alloca [ 9 x [ 6 x [ 4 x i32 * ] ] ] , align 16 %13 = alloca i64 , align 8 %14 = alloca i32 , align 4 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = bitcast %@@ struct@@ .@@ S@@ 0 * %7 to { i64 , i64 }
define internal { i64 , i64 }
define internal i32 * @func_@@ 21 ( i32 %0 , i64 %1 , i32 * %2 , i16 signext %3 , i32 * %4 ) #0 { %6 = alloca i32 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i64 , align 8 %9 = alloca i32 * , align 8 %10 = alloca i16 , align 2 %11 = alloca i32 * , align 8 %12 = alloca i8 , align 1 %13 = alloca i32 , align 4 %14 = alloca [ 6 x i32 ] , align 16 %15 = alloca [ 3 x [ 1 x [ 6 x i64 ] ] ] , align 16 %16 = alloca i8 , align 1 %17 = alloca i64 , align 8 %18 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %19 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %20 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %21 = alloca i16 * * , align 8 %22 = alloca i8 , align 1 %23 = alloca i32 , align 4 %24 = alloca i32 , align 4 %25 = alloca i32 , align 4 %26 = alloca i64 , align 8 %27 = alloca [ 9 x i64 ] , align 16 %28 = alloca i32 , align 4 %29 = alloca [ 8 x i32 ] , align 16 %30 = alloca %@@ struct@@ .@@ S@@ 2 , align 1 %31 = alloca i32 , align 4 %32 = alloca i32 * , align 8 %33 = alloca i32 * , align 8 %34 = alloca i32 * , align 8 %35 = alloca i32 * , align 8 %36 = alloca [ 2 x i32 * ] , align 16 %37 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %38 = alloca i32 , align 4 %39 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %40 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %41 = alloca i64 * * * * , align 8 %42 = alloca i32 , align 4 %43 = alloca i64 * , align 8 %44 = alloca i64 * , align 8 %45 = alloca [ 10 x i32 * ] , align 16 %46 = alloca i32 , align 4 %47 = alloca i32 , align 4 %48 = alloca [ 4 x i32 ] , align 16 %49 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %50 = alloca i64 , align 8 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca i32 * , align 8 %54 = alloca i32 , align 4 %55 = alloca [ 9 x i32 * ] , align 16 %56 = alloca i8 * , align 8 %57 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %58 = alloca i32 , align 4 %59 = alloca i8 , align 1 %60 = alloca i32 * , align 8 %61 = alloca i8 * , align 8 %62 = alloca i8 * * , align 8 %63 = alloca i32 , align 4 %64 = alloca i32 * , align 8 %65 = alloca i32 , align 4 %66 = alloca [ 4 x i32 ] , align 16 %67 = alloca [ 9 x [ 1 x [ 9 x i32 * ] ] ] , align 16 %68 = alloca i32 * * , align 8 %69 = alloca i32 , align 4 %70 = alloca i32 , align 4 %71 = alloca i32 , align 4 %72 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %73 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %74 = alloca i8 * , align 8 %75 = alloca [ 2 x i32 * * ] , align 16 %76 = alloca i32 , align 4 %77 = alloca %@@ struct@@ .@@ S@@ 1 , align 1 %78 = alloca i32 * , align 8 %79 = alloca i32 * , align 8 %80 = alloca i32 * , align 8 %81 = alloca i32 * , align 8 %82 = alloca [ 7 x [ 8 x i32 * ] ] , align 16 %83 = alloca i32 , align 4 %84 = alloca i32 , align 4 %85 = alloca i32 , align 4 %86 = alloca i32 * , align 8 %87 = alloca i32 , align 4 %88 = alloca i8 * , align 8 %89 = alloca i32 * , align 8 store i32 %0 , i32 * %7 , align 4 store i64 %1 , i64 * %8 , align 8 store i32 * %2 , i32 * * %9 , align 8 store i16 %3 , i16 * %10 , align 2 store i32 * %4 , i32 * * %11 , align 8 store i8 -@@ 88 , i8 * %12 , align 1 store i32 5 , i32 * %13 , align 4 %90 = bitcast [ 6 x i32 ] * %14 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %90 , i8 * align 16 bitcast ( [ 6 x i32 ] * @__const.func_@@ 2@@ 1.l_@@ 455 to i8 * ) , i64 24 , i1 false ) %91 = bitcast [ 3 x [ 1 x [ 6 x i64 ] ] ] * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %91 , i8 * align 16 bitcast ( [ 3 x [ 1 x [ 6 x i64 ] ] ] * @__const.func_@@ 2@@ 1.l_@@ 45@@ 8 to i8 * ) , i64 144 , i1 false ) store i8 1 , i8 * %16 , align 1 store i64 -90@@ 6@@ 59@@ 18@@ 00@@ 55@@ 019@@ 29@@ 32@@ 2 , i64 * %17 , align 8 store %@@ struct@@ .@@ S@@ 1 * * @g_4@@ 32 , %@@ struct@@ .@@ S@@ 1 * * * %18 , align 8 store %@@ struct@@ .@@ S@@ 2 * getelementptr inbounds ( [ 3 x %@@ struct@@ .@@ S3 ] , [ 3 x %@@ struct@@ .@@ S3 ] * bitcast ( [ 3 x < { i8 , i8 , i8 , < { i16 , i8 , i32 , i32 , i8 , i8 , i8 , i8 }
define internal signext i16 @func_@@ 43 ( i32 * %0 , i64 %1 , i64 %2 , i64 %3 ) #0 { %5 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %6 = alloca i32 * , align 8 %7 = alloca i64 , align 8 %8 = alloca i32 * , align 8 %9 = alloca [ 2 x [ 7 x i8 * ] ] , align 16 %10 = alloca i32 , align 4 %11 = alloca [ 8 x i32 ] , align 16 %12 = alloca i16 * , align 8 %13 = alloca i32 , align 4 %14 = alloca i32 , align 4 %15 = alloca [ 4 x [ 7 x [ 5 x i32 * ] ] ] , align 16 %16 = alloca i32 , align 4 %17 = alloca i64 , align 8 %18 = alloca i32 * * , align 8 %19 = alloca [ 1 x i8 ] , align 1 %20 = alloca i16 , align 2 %21 = alloca i16 * , align 8 %22 = alloca i32 , align 4 %23 = alloca i8 , align 1 %24 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %25 = alloca [ 5 x i16 * ] , align 16 %26 = alloca i32 , align 4 %27 = alloca i64 , align 8 %28 = alloca i8 , align 1 %29 = alloca i8 , align 1 %30 = alloca i32 , align 4 %31 = alloca i8 , align 1 %32 = alloca i8 , align 1 %33 = alloca i32 , align 4 %34 = alloca i32 , align 4 %35 = alloca i32 , align 4 %36 = alloca %@@ struct@@ .@@ S3 , align 1 %37 = alloca i64 , align 8 %38 = alloca i32 * * , align 8 %39 = alloca i16 * , align 8 %40 = alloca %@@ struct@@ .@@ S3 * , align 8 %41 = alloca [ 7 x i32 * * ] , align 16 %42 = alloca i16 * , align 8 %43 = alloca [ 5 x [ 3 x [ 9 x i16 * * ] ] ] , align 16 %44 = alloca i8 * , align 8 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i32 , align 4 %48 = alloca i32 , align 4 %49 = alloca [ 7 x i32 ] , align 16 %50 = alloca [ 1 x [ 3 x [ 9 x i16 ] ] ] , align 16 %51 = alloca i64 * , align 8 %52 = alloca i64 * , align 8 %53 = alloca i64 * , align 8 %54 = alloca [ 8 x i64 * ] , align 16 %55 = alloca i16 , align 2 %56 = alloca [ 2 x [ 4 x i8 ] ] , align 1 %57 = alloca i32 , align 4 %58 = alloca i32 , align 4 %59 = alloca i32 , align 4 %60 = bitcast %@@ struct@@ .@@ S@@ 0 * %5 to { i64 , i64 }
define internal i32 * @func_@@ 47 ( i32 %0 ) #0 { %2 = alloca i32 , align 4 %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 %5 = alloca [ 1 x [ 8 x i64 * ] ] , align 16 %6 = alloca i32 , align 4 %7 = alloca [ 10 x [ 8 x i8 * ] ] , align 16 %8 = alloca i32 , align 4 %9 = alloca i16 , align 2 %10 = alloca i8 , align 1 %11 = alloca i32 * , align 8 %12 = alloca [ 7 x [ 10 x [ 3 x %@@ struct@@ .@@ S@@ 0 ] ] ] , align 16 %13 = alloca [ 4 x [ 5 x [ 7 x i32 ] ] ] , align 16 %14 = alloca i32 , align 4 %15 = alloca i64 * * , align 8 %16 = alloca i64 * * * , align 8 %17 = alloca i32 , align 4 %18 = alloca i32 , align 4 %19 = alloca i32 , align 4 %20 = alloca i64 * , align 8 %21 = alloca i64 * , align 8 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca [ 3 x i32 ] , align 4 %25 = alloca i8 , align 1 %26 = alloca [ 10 x [ 4 x [ 1 x i32 ] ] ] , align 16 %27 = alloca i8 * , align 8 %28 = alloca [ 6 x %@@ struct@@ .@@ S3 * ] , align 16 %29 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %30 = alloca %@@ struct@@ .@@ S@@ 0 , align 8 %31 = alloca i32 , align 4 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 store i16 -9 , i16 * %3 , align 2 store i16 279@@ 27 , i16 * %4 , align 2 %34 = bitcast [ 1 x [ 8 x i64 * ] ] * %5 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %34 , i8 * align 16 bitcast ( [ 1 x [ 8 x i64 * ] ] * @__const.func_@@ 47@@ .l_@@ 66 to i8 * ) , i64 64 , i1 false ) store i32 6 , i32 * %6 , align 4 %35 = bitcast [ 10 x [ 8 x i8 * ] ] * %7 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %35 , i8 * align 16 bitcast ( [ 10 x [ 8 x i8 * ] ] * @__const.func_@@ 47@@ .l_@@ 73 to i8 * ) , i64 6@@ 40 , i1 false ) store i32 0 , i32 * %8 , align 4 store i16 9 , i16 * %9 , align 2 store i8 34 , i8 * %10 , align 1 store i32 * @g_11@@ 1 , i32 * * %11 , align 8 %36 = bitcast [ 7 x [ 10 x [ 3 x %@@ struct@@ .@@ S@@ 0 ] ] ] * %12 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %36 , i8 * align 16 getelementptr inbounds ( [ 7 x [ 10 x [ 3 x { i8 , i8 , i32 , i64 }
define internal i64 @func_@@ 49 ( i32 %0 , i16 * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i16 * , align 8 %5 = alloca i32 , align 4 %6 = alloca i32 * , align 8 %7 = alloca [ 8 x [ 7 x i32 * ] ] , align 16 %8 = alloca i32 , align 4 %9 = alloca [ 5 x i8 ] , align 1 %10 = alloca i8 , align 1 %11 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %12 = alloca i8 * , align 8 %13 = alloca i8 * * , align 8 %14 = alloca i32 , align 4 %15 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i16 * %1 , i16 * * %4 , align 8 store i32 2 , i32 * %5 , align 4 store i32 * @g_@@ 84 , i32 * * %6 , align 8 %16 = getelementptr inbounds [ 8 x [ 7 x i32 * ] ] , [ 8 x [ 7 x i32 * ] ] * %7 , i64 0 , i64 0 %17 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %16 , i64 0 , i64 0 %18 = bitcast [ 7 x i32 * ] * %16 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %18 , i8 * align 8 bitcast ( [ 7 x i32 * ] * @constinit.11 to i8 * ) , i64 56 , i1 false ) %19 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %16 , i64 1 %20 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %19 , i64 0 , i64 0 store i32 * %5 , i32 * * %20 , align 8 %21 = getelementptr inbounds i32 * , i32 * * %20 , i64 1 store i32 * %5 , i32 * * %21 , align 8 %22 = getelementptr inbounds i32 * , i32 * * %21 , i64 1 store i32 * %5 , i32 * * %22 , align 8 %23 = getelementptr inbounds i32 * , i32 * * %22 , i64 1 store i32 * %5 , i32 * * %23 , align 8 %24 = getelementptr inbounds i32 * , i32 * * %23 , i64 1 store i32 * %5 , i32 * * %24 , align 8 %25 = getelementptr inbounds i32 * , i32 * * %24 , i64 1 store i32 * %5 , i32 * * %25 , align 8 %26 = getelementptr inbounds i32 * , i32 * * %25 , i64 1 store i32 * %5 , i32 * * %26 , align 8 %27 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %19 , i64 1 %28 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %27 , i64 0 , i64 0 %29 = bitcast [ 7 x i32 * ] * %27 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %29 , i8 * align 8 bitcast ( [ 7 x i32 * ] * @constinit.12 to i8 * ) , i64 56 , i1 false ) %30 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %27 , i64 1 %31 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %30 , i64 0 , i64 0 store i32 * %5 , i32 * * %31 , align 8 %32 = getelementptr inbounds i32 * , i32 * * %31 , i64 1 store i32 * %5 , i32 * * %32 , align 8 %33 = getelementptr inbounds i32 * , i32 * * %32 , i64 1 store i32 * %5 , i32 * * %33 , align 8 %34 = getelementptr inbounds i32 * , i32 * * %33 , i64 1 store i32 * %5 , i32 * * %34 , align 8 %35 = getelementptr inbounds i32 * , i32 * * %34 , i64 1 store i32 * %5 , i32 * * %35 , align 8 %36 = getelementptr inbounds i32 * , i32 * * %35 , i64 1 store i32 * %5 , i32 * * %36 , align 8 %37 = getelementptr inbounds i32 * , i32 * * %36 , i64 1 store i32 * %5 , i32 * * %37 , align 8 %38 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %30 , i64 1 %39 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %38 , i64 0 , i64 0 %40 = bitcast [ 7 x i32 * ] * %38 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %40 , i8 * align 8 bitcast ( [ 7 x i32 * ] * @constinit.13 to i8 * ) , i64 56 , i1 false ) %41 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %38 , i64 1 %42 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %41 , i64 0 , i64 0 store i32 * %5 , i32 * * %42 , align 8 %43 = getelementptr inbounds i32 * , i32 * * %42 , i64 1 store i32 * %5 , i32 * * %43 , align 8 %44 = getelementptr inbounds i32 * , i32 * * %43 , i64 1 store i32 * %5 , i32 * * %44 , align 8 %45 = getelementptr inbounds i32 * , i32 * * %44 , i64 1 store i32 * %5 , i32 * * %45 , align 8 %46 = getelementptr inbounds i32 * , i32 * * %45 , i64 1 store i32 * %5 , i32 * * %46 , align 8 %47 = getelementptr inbounds i32 * , i32 * * %46 , i64 1 store i32 * %5 , i32 * * %47 , align 8 %48 = getelementptr inbounds i32 * , i32 * * %47 , i64 1 store i32 * %5 , i32 * * %48 , align 8 %49 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %41 , i64 1 %50 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %49 , i64 0 , i64 0 %51 = bitcast [ 7 x i32 * ] * %49 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 8 %51 , i8 * align 8 bitcast ( [ 7 x i32 * ] * @constinit.14 to i8 * ) , i64 56 , i1 false ) %52 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %49 , i64 1 %53 = getelementptr inbounds [ 7 x i32 * ] , [ 7 x i32 * ] * %52 , i64 0 , i64 0 store i32 * %5 , i32 * * %53 , align 8 %54 = getelementptr inbounds i32 * , i32 * * %53 , i64 1 store i32 * %5 , i32 * * %54 , align 8 %55 = getelementptr inbounds i32 * , i32 * * %54 , i64 1 store i32 * %5 , i32 * * %55 , align 8 %56 = getelementptr inbounds i32 * , i32 * * %55 , i64 1 store i32 * %5 , i32 * * %56 , align 8 %57 = getelementptr inbounds i32 * , i32 * * %56 , i64 1 store i32 * %5 , i32 * * %57 , align 8 %58 = getelementptr inbounds i32 * , i32 * * %57 , i64 1 store i32 * %5 , i32 * * %58 , align 8 %59 = getelementptr inbounds i32 * , i32 * * %58 , i64 1 store i32 * %5 , i32 * * %59 , align 8 store i32 -1 , i32 * %8 , align 4 store i8 0 , i8 * %10 , align 1 store %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , %@@ struct@@ .@@ S@@ 2 * * %11 , align 8 store i8 * @g_@@ 87 , i8 * * %12 , align 8 store i8 * * %12 , i8 * * * %13 , align 8 store i32 0 , i32 * %14 , align 4 br label %60 661 %61 = load i32 , i32 * %14 , align 4 %62 = icmp slt i32 %61 , 5 br i1 %62 , label %63 , label %63 6@@ 64 %64 = load i32 , i32 * %14 , align 4 %65 = sext i32 %64 to i64 %66 = getelementptr inbounds [ 5 x i8 ] , [ 5 x i8 ] * %9 , i64 0 , i64 %33 store i8 0 , i8 * %66 , align 1 br label %67 668 %68 = load i32 , i32 * %14 , align 4 %69 = add nsw i32 %68 , 1 store i32 %69 , i32 * %14 , align 4 br label %70 771 %71 = load i64 , i64 * @g_@@ 42 , align 8 %72 = and i64 %71 , 1 %73 = trunc i64 %72 to i32 store i32 %73 , i32 * %5 , align 4 %74 = load i32 * , i32 * * %6 , align 8 store i32 %73 , i32 * %74 , align 4 %75 = load i8 , i8 * %10 , align 1 %76 = add i8 %75 , -1 store i8 %76 , i8 * %10 , align 1 %77 = load i32 * , i32 * * %6 , align 8 %78 = load i32 , i32 * %77 , align 4 %79 = load i32 * , i32 * * %6 , align 8 %80 = load i32 , i32 * %79 , align 4 %81 = load i8 , i8 * @g_@@ 87 , align 1 %82 = sext i8 %81 to i32 %83 = load i64 , i64 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 1 ) , align 1 %84 = trunc i64 %83 to i32 %85 = call i32 @safe_mod_func_int32_t_s_s ( i32 %82 , i32 %84 ) %86 = or i32 %80 , %87 %87 = trunc i32 %86 to i8 %88 = load i32 , i32 * %3 , align 4 %89 = icmp ne i32 %88 , 0 br i1 %89 , label %93 , label %90 991 %91 = load %@@ struct@@ .@@ S@@ 2 * , %@@ struct@@ .@@ S@@ 2 * * %11 , align 8 %92 = icmp eq %@@ struct@@ .@@ S@@ 2 * %91 , @g_@@ 7 br label %93 994 %94 = phi i1 [ true , %70 ] , [ %92 , %90 ] %95 = zext i1 %94 to i32 %96 = load i8 , i8 * @g_@@ 74 , align 1 %97 = load i8 , i8 * @g_@@ 87 , align 1 %98 = sext i8 %97 to i32 %99 = load i16 * , i16 * * @g_@@ 80 , align 8 %100 = load i16 , i16 * %99 , align 2 %101 = sext i16 %100 to i32 %102 = and i32 %98 , %103 %103 = trunc i32 %102 to i16 %104 = call signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %103 , i32 7 ) %105 = load i32 , i32 * %3 , align 4 %106 = load i16 * , i16 * * @g_@@ 80 , align 8 %107 = load i16 , i16 * %106 , align 2 %108 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %107 , i16 signext 1 ) %109 = trunc i16 %108 to i8 %110 = call zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %87 , i8 zeroext %109 ) %111 = zext i8 %110 to i32 %112 = load i32 , i32 * %3 , align 4 %113 = icmp ult i32 %111 , %114 %114 = zext i1 %113 to i32 %115 = getelementptr inbounds [ 5 x i8 ] , [ 5 x i8 ] * %9 , i64 0 , i64 2 %116 = load i8 * * , i8 * * * %13 , align 8 store i8 * %115 , i8 * * %116 , align 8 %117 = icmp ne i8 * %115 , null %118 = zext i1 %117 to i32 %119 = sext i32 %118 to i64 %120 = load i32 * , i32 * * %6 , align 8 %121 = load i32 , i32 * %120 , align 4 %122 = sext i32 %121 to i64 %123 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %119 , i64 %122 ) %124 = trunc i64 %123 to i32 %125 = load volatile i32 , i32 * getelementptr inbounds ( [ 2 x [ 4 x [ 5 x i32 ] ] ] , [ 2 x [ 4 x [ 5 x i32 ] ] ] * @g_@@ 88 , i64 0 , i64 0 , i64 1 , i64 3 ) , align 4 %126 = call i32 @safe_mod_func_int32_t_s_s ( i32 %124 , i32 %125 ) %127 = load i16 * , i16 * * %4 , align 8 %128 = load i16 , i16 * %127 , align 2 %129 = sext i16 %128 to i32 %130 = icmp eq i32 %126 , %131 %131 = zext i1 %130 to i32 %132 = sext i32 %131 to i64 %133 = load i64 , i64 * @g_@@ 42 , align 8 %134 = call i64 @safe_mod_func_uint64_t_u_u ( i64 %132 , i64 %133 ) %135 = trunc i64 %134 to i32 store i32 %135 , i32 * @g_@@ 84 , align 4 %136 = load i32 , i32 * %3 , align 4 %137 = zext i32 %136 to i64 ret i64 %137 }
define internal signext i8 @func_@@ 57 ( i32 %0 , i32 * %1 , i64 %2 , i8 signext %3 ) #0 { %5 = alloca i32 , align 4 %6 = alloca i32 * , align 8 %7 = alloca i64 , align 8 %8 = alloca i8 , align 1 %9 = alloca %@@ struct@@ .@@ S@@ 2 , align 1 %10 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 store i32 %0 , i32 * %5 , align 4 store i32 * %1 , i32 * * %6 , align 8 store i64 %2 , i64 * %7 , align 8 store i8 %3 , i8 * %8 , align 1 %11 = bitcast %@@ struct@@ .@@ S@@ 2 * %9 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %11 , i8 * align 1 bitcast ( %@@ struct@@ .@@ S@@ 2 * @__const.func_@@ 57@@ .l_@@ 76 to i8 * ) , i64 13 , i1 false ) store %@@ struct@@ .@@ S@@ 2 * %9 , %@@ struct@@ .@@ S@@ 2 * * %10 , align 8 %12 = load %@@ struct@@ .@@ S@@ 2 * , %@@ struct@@ .@@ S@@ 2 * * %10 , align 8 %13 = bitcast %@@ struct@@ .@@ S@@ 2 * %12 to i8 * %14 = bitcast %@@ struct@@ .@@ S@@ 2 * %9 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %13 , i8 * align 1 %14 , i64 13 , i1 false ) %15 = load i64 , i64 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 1 ) , align 1 %16 = trunc i64 %15 to i8 ret i8 %16 }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %9 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = icmp eq i32 %10 , 2 br i1 %11 , label %12 , label %12 113 %13 = load i8 * * , i8 * * * %5 , align 8 %14 = getelementptr inbounds i8 * , i8 * * %13 , i64 1 %15 = load i8 * , i8 * * %14 , align 8 %16 = call i32 @strcmp ( i8 * %15 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 15 , i64 0 , i64 0 ) ) #17 %17 = icmp eq i32 %16 , 0 br i1 %17 , label %18 , label %18 133 store i32 1 , i32 * %9 , align 4 br label %19 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %20 = call i32 @func_1 ( ) %21 = load i32 , i32 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 0 ) , align 1 %22 = zext i32 %21 to i64 %23 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %22 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.@@ 16 , i64 0 , i64 0 ) , i32 %23 ) %24 = load i64 , i64 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 1 ) , align 1 %25 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %24 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.@@ 17 , i64 0 , i64 0 ) , i32 %25 ) %26 = load i8 , i8 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * @g_@@ 7 , i32 0 , i32 2 ) , align 1 %27 = zext i8 %26 to i64 %28 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %27 , i8 * getelementptr inbounds ( [ 7 x i8 ] , [ 7 x i8 ] * @.str.@@ 18 , i64 0 , i64 0 ) , i32 %28 ) %29 = load i32 , i32 * @g_@@ 28 , align 4 %30 = zext i32 %29 to i64 %31 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %30 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 19 , i64 0 , i64 0 ) , i32 %31 ) %32 = load i16 , i16 * @g_@@ 40 , align 2 %33 = sext i16 %32 to i64 %34 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %33 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 20 , i64 0 , i64 0 ) , i32 %34 ) %35 = load i64 , i64 * @g_@@ 42 , align 8 %36 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %35 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 21 , i64 0 , i64 0 ) , i32 %36 ) %37 = load i8 , i8 * @g_@@ 74 , align 1 %38 = sext i8 %37 to i64 %39 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %38 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 22 , i64 0 , i64 0 ) , i32 %39 ) %40 = load i16 , i16 * @g_@@ 81 , align 2 %41 = sext i16 %40 to i64 %42 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %41 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 23 , i64 0 , i64 0 ) , i32 %42 ) %43 = load i32 , i32 * @g_@@ 84 , align 4 %44 = sext i32 %43 to i64 %45 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %44 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 24 , i64 0 , i64 0 ) , i32 %45 ) %46 = load i8 , i8 * @g_@@ 87 , align 1 %47 = sext i8 %46 to i64 %48 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %47 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.25 , i64 0 , i64 0 ) , i32 %48 ) store i32 0 , i32 * %6 , align 4 br label %49 450 %50 = load i32 , i32 * %6 , align 4 %51 = icmp slt i32 %50 , 2 br i1 %51 , label %52 , label %52 533 store i32 0 , i32 * %7 , align 4 br label %53 554 %54 = load i32 , i32 * %7 , align 4 %55 = icmp slt i32 %54 , 4 br i1 %55 , label %56 , label %56 533 store i32 0 , i32 * %8 , align 4 br label %57 558 %58 = load i32 , i32 * %8 , align 4 %59 = icmp slt i32 %58 , 5 br i1 %59 , label %60 , label %60 661 %61 = load i32 , i32 * %6 , align 4 %62 = sext i32 %61 to i64 %63 = getelementptr inbounds [ 2 x [ 4 x [ 5 x i32 ] ] ] , [ 2 x [ 4 x [ 5 x i32 ] ] ] * @g_@@ 88 , i64 0 , i64 %64 %64 = load i32 , i32 * %7 , align 4 %65 = sext i32 %64 to i64 %66 = getelementptr inbounds [ 4 x [ 5 x i32 ] ] , [ 4 x [ 5 x i32 ] ] * %63 , i64 0 , i64 %67 %67 = load i32 , i32 * %8 , align 4 %68 = sext i32 %67 to i64 %69 = getelementptr inbounds [ 5 x i32 ] , [ 5 x i32 ] * %66 , i64 0 , i64 %70 %70 = load volatile i32 , i32 * %69 , align 4 %71 = sext i32 %70 to i64 %72 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %71 , i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.26 , i64 0 , i64 0 ) , i32 %72 ) %73 = load i32 , i32 * %9 , align 4 %74 = icmp ne i32 %73 , 0 br i1 %74 , label %75 , label %75 7@@ 76 %76 = load i32 , i32 * %6 , align 4 %77 = load i32 , i32 * %7 , align 4 %78 = load i32 , i32 * %8 , align 4 %79 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.27 , i64 0 , i64 0 ) , i32 %76 , i32 %77 , i32 %78 ) br label %80 82 br label %81 8@@ 82 %82 = load i32 , i32 * %8 , align 4 %83 = add nsw i32 %82 , 1 store i32 %83 , i32 * %8 , align 4 br label %84 82 br label %85 8@@ 86 %86 = load i32 , i32 * %7 , align 4 %87 = add nsw i32 %86 , 1 store i32 %87 , i32 * %7 , align 4 br label %88 82 br label %89 8@@ 90 %90 = load i32 , i32 * %6 , align 4 %91 = add nsw i32 %90 , 1 store i32 %91 , i32 * %6 , align 4 br label %92 9@@ 93 %93 = load i32 , i32 * @g_11@@ 1 , align 4 %94 = sext i32 %93 to i64 %95 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %94 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.28 , i64 0 , i64 0 ) , i32 %95 ) store i32 0 , i32 * %6 , align 4 br label %96 9@@ 97 %97 = load i32 , i32 * %6 , align 4 %98 = icmp slt i32 %97 , 6 br i1 %98 , label %99 , label %99 9@@ 100 %100 = load i32 , i32 * %6 , align 4 %101 = sext i32 %100 to i64 %102 = getelementptr inbounds [ 6 x i64 ] , [ 6 x i64 ] * @g_1@@ 16 , i64 0 , i64 %103 %103 = load i64 , i64 * %102 , align 8 %104 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %103 , i8 * getelementptr inbounds ( [ 9 x i8 ] , [ 9 x i8 ] * @.str.29 , i64 0 , i64 0 ) , i32 %104 ) %105 = load i32 , i32 * %9 , align 4 %106 = icmp ne i32 %105 , 0 br i1 %106 , label %107 , label %107 11@@ 08 %108 = load i32 , i32 * %6 , align 4 %109 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.30 , i64 0 , i64 0 ) , i32 %108 ) br label %110 12 br label %111 11@@ 12 %112 = load i32 , i32 * %6 , align 4 %113 = add nsw i32 %112 , 1 store i32 %113 , i32 * %6 , align 4 br label %114 1115 %115 = load i16 , i16 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 1 , %@@ struct@@ .@@ S@@ 1 * bitcast ( < { i16 , i8 , i32 , i32 , i8 , i8 , i8 , i8 }
define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 * , align 8 %4 = alloca [ 10 x [ 5 x i32 * ] ] , align 16 %5 = alloca i32 , align 4 %6 = alloca [ 3 x %un@@ ion.@@ U@@ 1 * * * ] , align 16 %7 = alloca i8 * , align 8 %8 = alloca i32 * * * * * , align 8 %9 = alloca i16 , align 2 %10 = alloca i8 , align 1 %11 = alloca i64 , align 8 %12 = alloca [ 4 x i8 ] , align 1 %13 = alloca i16 * , align 8 %14 = alloca [ 5 x i16 * * ] , align 16 %15 = alloca i16 * * * , align 8 %16 = alloca [ 3 x i16 * * * * ] , align 16 %17 = alloca [ 4 x i16 * * * * * ] , align 16 %18 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %19 = alloca i64 , align 8 %20 = alloca i32 , align 4 %21 = alloca i32 , align 4 %22 = alloca i16 , align 2 %23 = alloca [ 10 x [ 2 x i16 ] ] , align 16 %24 = alloca i8 * , align 8 %25 = alloca i32 , align 4 %26 = alloca i32 , align 4 %27 = alloca i8 , align 1 %28 = alloca i32 , align 4 %29 = alloca i32 * , align 8 %30 = alloca i64 * * * , align 8 %31 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %32 = alloca [ 2 x [ 4 x [ 4 x %un@@ ion.@@ U@@ 1 * * * ] ] ] , align 16 %33 = alloca i64 * * , align 8 %34 = alloca [ 5 x i64 ] , align 16 %35 = alloca i8 , align 1 %36 = alloca i8 , align 1 %37 = alloca [ 3 x i32 ] , align 4 %38 = alloca [ 3 x i8 ] , align 1 %39 = alloca i64 , align 8 %40 = alloca i32 , align 4 %41 = alloca i64 , align 8 %42 = alloca i8 , align 1 %43 = alloca i64 , align 8 %44 = alloca [ 3 x [ 4 x %un@@ ion.@@ U@@ 1 * * * * ] ] , align 16 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i32 , align 4 %48 = alloca i32 , align 4 %49 = alloca i32 , align 4 %50 = alloca i32 , align 4 %51 = alloca i32 , align 4 %52 = alloca [ 8 x i32 ] , align 16 %53 = alloca i32 , align 4 %54 = alloca [ 6 x i8 * ] , align 16 %55 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %56 = alloca [ 8 x i16 * ] , align 16 %57 = alloca i32 , align 4 %58 = alloca i32 , align 4 %59 = alloca i16 * , align 8 %60 = alloca i32 , align 4 %61 = alloca i32 , align 4 %62 = alloca i16 , align 2 %63 = alloca i8 , align 1 %64 = alloca i8 , align 1 %65 = alloca i32 , align 4 %66 = alloca %un@@ ion.@@ U@@ 1 , align 8 %67 = alloca i8 , align 1 %68 = alloca i16 * , align 8 %69 = alloca i32 * * , align 8 %70 = alloca [ 5 x i32 * * * ] , align 16 %71 = alloca i8 , align 1 %72 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %73 = alloca i32 , align 4 %74 = alloca i32 , align 4 %75 = alloca [ 8 x i32 ] , align 16 %76 = alloca i32 , align 4 %77 = alloca i8 * , align 8 %78 = alloca i64 , align 8 %79 = alloca i32 , align 4 %80 = alloca i64 , align 8 %81 = alloca i32 , align 4 %82 = alloca i32 , align 4 %83 = alloca [ 7 x [ 4 x i32 ] ] , align 16 %84 = alloca i32 , align 4 %85 = alloca i8 , align 1 %86 = alloca i16 , align 2 %87 = alloca i8 , align 1 %88 = alloca [ 2 x i8 ] , align 1 %89 = alloca i32 , align 4 %90 = alloca i32 , align 4 %91 = alloca [ 10 x [ 1 x [ 2 x %@@ struct@@ .@@ S@@ 0 * * ] ] ] , align 16 %92 = alloca i64 * , align 8 %93 = alloca i32 , align 4 %94 = alloca i32 , align 4 %95 = alloca i32 , align 4 %96 = alloca i32 , align 4 %97 = alloca i32 , align 4 %98 = alloca i64 , align 8 %99 = alloca i64 , align 8 %100 = alloca i16 * , align 8 %101 = alloca i16 * * , align 8 %102 = alloca [ 8 x i16 * * * ] , align 16 %103 = alloca i32 , align 4 %104 = alloca i32 , align 4 %105 = alloca [ 4 x [ 9 x [ 7 x i32 ] ] ] , align 16 %106 = alloca i64 , align 8 %107 = alloca i32 , align 4 %108 = alloca i32 , align 4 %109 = alloca i32 , align 4 %110 = alloca [ 10 x [ 1 x [ 4 x i32 * * ] ] ] , align 16 %111 = alloca i16 * * * , align 8 %112 = alloca i64 , align 8 %113 = alloca i32 , align 4 %114 = alloca [ 1 x [ 8 x i8 ] ] , align 1 %115 = alloca [ 5 x [ 1 x [ 1 x i32 ] ] ] , align 16 %116 = alloca i32 , align 4 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = alloca i16 * , align 8 %120 = alloca i16 * * , align 8 %121 = alloca i16 * * * , align 8 %122 = alloca i16 * * * * , align 8 %123 = alloca i32 , align 4 %124 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %125 = alloca i32 , align 4 %126 = alloca i8 , align 1 %127 = alloca i16 * * * * * , align 8 %128 = alloca i32 , align 4 %129 = alloca i16 , align 2 %130 = alloca i32 , align 4 %131 = alloca i32 * , align 8 %132 = alloca i32 * , align 8 %133 = alloca i32 , align 4 %134 = alloca i8 , align 1 %135 = alloca [ 3 x i8 ] , align 1 %136 = alloca i32 , align 4 %137 = alloca i16 , align 2 %138 = alloca i32 , align 4 %139 = alloca %un@@ ion.@@ U@@ 1 , align 8 %140 = alloca i64 , align 8 %141 = alloca i32 , align 4 %142 = alloca i32 * * , align 8 %143 = alloca i16 * * , align 8 %144 = alloca i32 , align 4 %145 = alloca [ 9 x [ 1 x [ 10 x i16 ] ] ] , align 16 %146 = alloca i32 * * , align 8 %147 = alloca i32 , align 4 %148 = alloca i32 , align 4 %149 = alloca i32 , align 4 %150 = alloca i64 , align 8 %151 = alloca i32 , align 4 %152 = alloca i32 , align 4 %153 = alloca [ 5 x i32 ] , align 16 %154 = alloca i32 , align 4 %155 = alloca i8 , align 1 %156 = alloca %un@@ ion.@@ U@@ 1 , align 8 %157 = alloca i64 , align 8 %158 = alloca i64 * , align 8 %159 = alloca i32 , align 4 %160 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %161 = alloca i16 * , align 8 %162 = alloca i32 , align 4 %163 = alloca i32 , align 4 %164 = alloca i32 , align 4 %165 = alloca i32 * * , align 8 %166 = alloca i32 , align 4 %167 = alloca i32 , align 4 %168 = alloca i32 , align 4 %169 = alloca i8 * , align 8 %170 = alloca i16 , align 2 %171 = alloca i16 , align 2 %172 = alloca i32 * , align 8 %173 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %174 = alloca i32 * * * , align 8 %175 = alloca [ 1 x [ 6 x i32 * * ] ] , align 16 %176 = alloca i32 * * * , align 8 %177 = alloca i8 * * * , align 8 %178 = alloca i32 , align 4 %179 = alloca i32 , align 4 %180 = alloca i32 , align 4 %181 = alloca i32 , align 4 %182 = alloca i32 , align 4 %183 = alloca i16 , align 2 %184 = alloca i32 , align 4 %185 = alloca i64 * , align 8 %186 = alloca i8 * , align 8 %187 = alloca i8 * , align 8 %188 = alloca i64 , align 8 %189 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %190 = alloca i32 , align 4 %191 = alloca [ 4 x i8 ] , align 1 %192 = alloca i16 , align 2 %193 = alloca i32 , align 4 %194 = alloca i64 , align 8 %195 = alloca i8 * , align 8 %196 = alloca [ 8 x [ 2 x i8 * * ] ] , align 16 %197 = alloca [ 9 x %@@ struct@@ .@@ S@@ 0 * ] , align 16 %198 = alloca i32 , align 4 %199 = alloca i32 , align 4 %200 = alloca i8 , align 1 %201 = alloca i32 , align 4 %202 = alloca i64 * * , align 8 %203 = alloca i8 , align 1 %204 = alloca i32 , align 4 %205 = alloca i32 , align 4 %206 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %207 = alloca i16 * * * * * , align 8 %208 = alloca i8 , align 1 %209 = alloca i64 * , align 8 %210 = alloca i64 , align 8 %211 = alloca i32 * * * , align 8 %212 = alloca i16 * , align 8 %213 = alloca [ 9 x i32 * ] , align 16 %214 = alloca i32 , align 4 %215 = alloca i32 , align 4 %216 = alloca i32 , align 4 %217 = alloca i32 , align 4 %218 = alloca [ 5 x i32 ] , align 16 %219 = alloca i64 , align 8 %220 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %221 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %222 = alloca i32 , align 4 %223 = alloca %un@@ ion.@@ U@@ 1 * * * * , align 8 %224 = alloca i32 * , align 8 %225 = alloca i16 , align 2 %226 = alloca i32 , align 4 %227 = alloca i32 , align 4 %228 = alloca i16 * , align 8 %229 = alloca [ 7 x i32 ] , align 16 %230 = alloca i32 , align 4 %231 = alloca [ 8 x [ 5 x [ 4 x i64 * * * ] ] ] , align 16 %232 = alloca [ 9 x i64 ] , align 16 %233 = alloca i32 , align 4 %234 = alloca i8 , align 1 %235 = alloca i32 , align 4 %236 = alloca [ 4 x [ 7 x [ 6 x i32 ] ] ] , align 16 %237 = alloca i16 , align 2 %238 = alloca i8 , align 1 %239 = alloca i64 * * , align 8 %240 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %241 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %242 = alloca i32 , align 4 %243 = alloca i8 , align 1 %244 = alloca i16 , align 2 %245 = alloca i64 , align 8 %246 = alloca i32 , align 4 %247 = alloca i32 , align 4 %248 = alloca i32 , align 4 %249 = alloca i32 , align 4 %250 = alloca i8 , align 1 %251 = alloca i8 * , align 8 %252 = alloca i16 * * * , align 8 %253 = alloca i16 * * * * , align 8 %254 = alloca i32 , align 4 %255 = alloca i64 , align 8 %256 = alloca i32 , align 4 %257 = alloca i8 , align 1 %258 = alloca i16 , align 2 %259 = alloca i32 * , align 8 %260 = alloca i8 , align 1 %261 = alloca i16 , align 2 %262 = alloca [ 8 x [ 1 x i64 ] ] , align 16 %263 = alloca i32 * * , align 8 %264 = alloca i16 , align 2 %265 = alloca i32 , align 4 %266 = alloca i32 , align 4 %267 = alloca i32 , align 4 %268 = alloca [ 1 x [ 3 x [ 4 x i8 ] ] ] , align 1 %269 = alloca i32 , align 4 %270 = alloca i32 , align 4 %271 = alloca i32 , align 4 %272 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %273 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %274 = alloca i8 , align 1 %275 = alloca i16 * , align 8 %276 = alloca i16 * * , align 8 %277 = alloca i16 * * * , align 8 %278 = alloca i32 * , align 8 %279 = alloca i8 , align 1 %280 = alloca i32 , align 4 %281 = alloca [ 8 x i32 * ] , align 16 %282 = alloca [ 4 x i32 * * ] , align 16 %283 = alloca i32 , align 4 %284 = alloca i32 , align 4 %285 = alloca i32 * * * , align 8 %286 = alloca [ 9 x [ 1 x [ 8 x i32 * * * * ] ] ] , align 16 %287 = alloca i32 , align 4 %288 = alloca i32 , align 4 %289 = alloca i32 , align 4 %290 = alloca i16 * * * * * , align 8 %291 = alloca i8 * , align 8 %292 = alloca i32 , align 4 %293 = alloca i32 , align 4 %294 = alloca i64 * * * , align 8 %295 = alloca i32 , align 4 %296 = alloca i32 , align 4 %297 = alloca i32 , align 4 %298 = alloca i16 * , align 8 %299 = alloca [ 1 x [ 5 x i16 * * ] ] , align 16 %300 = alloca i16 * * * , align 8 %301 = alloca i16 * * * * , align 8 %302 = alloca i32 , align 4 %303 = alloca i32 * * * * , align 8 %304 = alloca i16 , align 2 %305 = alloca i16 * * , align 8 %306 = alloca %un@@ ion.@@ U@@ 1 * * , align 8 %307 = alloca i32 , align 4 %308 = alloca i32 , align 4 %309 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %310 = alloca i64 , align 8 %311 = alloca i32 , align 4 %312 = alloca i16 * * , align 8 %313 = alloca i32 * * , align 8 %314 = alloca [ 3 x [ 8 x i32 * * * ] ] , align 16 %315 = alloca i32 * * * * , align 8 %316 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %317 = alloca i32 , align 4 %318 = alloca %un@@ ion.@@ U@@ 1 * * * * , align 8 %319 = alloca [ 4 x [ 10 x [ 1 x %un@@ ion.@@ U@@ 1 * * ] ] ] , align 16 %320 = alloca i32 * * * * , align 8 %321 = alloca i8 , align 1 %322 = alloca i32 , align 4 %323 = alloca i32 , align 4 %324 = alloca i32 , align 4 %325 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %326 = alloca i32 , align 4 %327 = alloca i32 , align 4 %328 = alloca i32 , align 4 %329 = alloca i32 , align 4 %330 = alloca %un@@ ion.@@ U@@ 1 , align 8 %331 = alloca i8 , align 1 %332 = alloca i64 , align 8 %333 = alloca [ 9 x i32 ] , align 16 %334 = alloca i32 , align 4 %335 = alloca i32 * , align 8 %336 = alloca i32 * * , align 8 %337 = alloca i32 * * * , align 8 %338 = alloca [ 2 x %un@@ ion.@@ U@@ 1 * * * * * ] , align 16 %339 = alloca [ 8 x %un@@ ion.@@ U@@ 1 * * * * * ] , align 16 %340 = alloca [ 8 x [ 7 x [ 2 x i32 * * * * * ] ] ] , align 16 %341 = alloca i32 , align 4 %342 = alloca i32 , align 4 %343 = alloca i32 , align 4 %344 = alloca i32 , align 4 %345 = alloca i32 , align 4 %346 = alloca i32 , align 4 %347 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 store i32 -2 , i32 * %2 , align 4 store i32 * null , i32 * * %3 , align 8 %348 = bitcast [ 10 x [ 5 x i32 * ] ] * %4 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %348 , i8 * align 16 bitcast ( [ 10 x [ 5 x i32 * ] ] * @__const.func_1.l_@@ 9 to i8 * ) , i64 400 , i1 false ) store i32 -@@ 840@@ 9@@ 5838@@ 7 , i32 * %5 , align 4 store i8 * getelementptr inbounds ( [ 4 x [ 8 x i8 ] ] , [ 4 x [ 8 x i8 ] ] * @g_@@ 728 , i64 0 , i64 1 , i64 3 ) , i8 * * %7 , align 8 store i32 * * * * * null , i32 * * * * * * %8 , align 8 store i16 -1@@ 77@@ 91 , i16 * %9 , align 2 store i8 -1 , i8 * %10 , align 1 store i64 83@@ 35@@ 17@@ 26@@ 18@@ 00@@ 129@@ 77@@ 19 , i64 * %11 , align 8 store i16 * getelementptr inbounds ( [ 7 x [ 10 x i16 ] ] , [ 7 x [ 10 x i16 ] ] * @g_11@@ 89 , i64 0 , i64 1 , i64 7 ) , i16 * * %13 , align 8 %349 = getelementptr inbounds [ 5 x i16 * * ] , [ 5 x i16 * * ] * %14 , i64 0 , i64 0 store i16 * * %13 , i16 * * * %349 , align 8 %350 = getelementptr inbounds i16 * * , i16 * * * %349 , i64 1 store i16 * * %13 , i16 * * * %350 , align 8 %351 = getelementptr inbounds i16 * * , i16 * * * %350 , i64 1 store i16 * * %13 , i16 * * * %351 , align 8 %352 = getelementptr inbounds i16 * * , i16 * * * %351 , i64 1 store i16 * * %13 , i16 * * * %352 , align 8 %353 = getelementptr inbounds i16 * * , i16 * * * %352 , i64 1 store i16 * * %13 , i16 * * * %353 , align 8 %354 = getelementptr inbounds [ 5 x i16 * * ] , [ 5 x i16 * * ] * %14 , i64 0 , i64 2 store i16 * * * %354 , i16 * * * * %15 , align 8 %355 = bitcast %@@ struct@@ .@@ S@@ 0 * %18 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %355 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 }
define internal i32 * @func_@@ 11 ( i32 * %0 , i8 zeroext %1 , i64 %2 , i8 signext %3 ) #0 { %5 = alloca i32 * , align 8 %6 = alloca i8 , align 1 %7 = alloca i64 , align 8 %8 = alloca i8 , align 1 %9 = alloca i8 , align 1 %10 = alloca i32 * , align 8 %11 = alloca i32 * * , align 8 %12 = alloca i32 * , align 8 %13 = alloca i32 * * , align 8 %14 = alloca i16 * , align 8 %15 = alloca [ 1 x i64 ] , align 8 %16 = alloca i32 * * * , align 8 %17 = alloca i64 , align 8 %18 = alloca i32 , align 4 %19 = alloca i32 , align 4 %20 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %21 = alloca i32 , align 4 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca i32 , align 4 %25 = alloca [ 5 x i32 ] , align 16 %26 = alloca i32 , align 4 store i32 * %0 , i32 * * %5 , align 8 store i8 %1 , i8 * %6 , align 1 store i64 %2 , i64 * %7 , align 8 store i8 %3 , i8 * %8 , align 1 store i8 -@@ 66 , i8 * %9 , align 1 store i32 * @g_1@@ 0 , i32 * * %10 , align 8 store i32 * * %10 , i32 * * * %11 , align 8 store i32 * @g_1@@ 0 , i32 * * %12 , align 8 store i32 * * %12 , i32 * * * %13 , align 8 store i16 * @g_49 , i16 * * %14 , align 8 store i32 * * * @g_6@@ 31 , i32 * * * * %16 , align 8 store i64 -1 , i64 * %17 , align 8 store i32 -1 , i32 * %18 , align 4 store i32 1 , i32 * %19 , align 4 %27 = bitcast %@@ struct@@ .@@ S@@ 0 * %20 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %27 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 }
define internal i32 * * @func_@@ 73 ( i16 * %0 , i32 %1 , i16 zeroext %2 , i16 * %3 ) #0 { %5 = alloca i32 * * , align 8 %6 = alloca i16 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i16 , align 2 %9 = alloca i16 * , align 8 %10 = alloca i32 * * , align 8 store i16 * %0 , i16 * * %6 , align 8 store i32 %1 , i32 * %7 , align 4 store i16 %2 , i16 * %8 , align 2 store i16 * %3 , i16 * * %9 , align 8 store i32 * * null , i32 * * * %10 , align 8 store i8 0 , i8 * @g_@@ 496 , align 1 br label %11 112 %12 = load i8 , i8 * @g_@@ 496 , align 1 %13 = sext i8 %12 to i32 %14 = icmp sge i32 %13 , -@@ 22 br i1 %14 , label %15 , label %15 133 store i32 * * getelementptr inbounds ( [ 3 x i32 * ] , [ 3 x i32 * ] * @g_1@@ 55 , i64 0 , i64 0 ) , i32 * * * %5 , align 8 br label %16 117 %17 = load i8 , i8 * @g_@@ 496 , align 1 %18 = sext i8 %17 to i32 %19 = call i32 @safe_sub_func_int32_t_s_s ( i32 %18 , i32 6 ) %20 = trunc i32 %19 to i8 store i8 %20 , i8 * @g_@@ 496 , align 1 br label %21 222 %22 = load i32 * * , i32 * * * %10 , align 8 store i32 * * %22 , i32 * * * %5 , align 8 br label %23 224 %24 = load i32 * * , i32 * * * %5 , align 8 ret i32 * * %24 }
define internal signext i8 @func_@@ 27 ( i32 * %0 , i@@ 24 %1 , i32 %2 , i8 signext %3 ) #0 { %5 = alloca i8 , align 1 %6 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %7 = alloca i@@ 24 , align 4 %8 = alloca i32 * , align 8 %9 = alloca i32 , align 4 %10 = alloca i8 , align 1 %11 = alloca i8 * , align 8 %12 = alloca [ 3 x [ 7 x i32 ] ] , align 16 %13 = alloca [ 4 x i32 ] , align 16 %14 = alloca i32 * , align 8 %15 = alloca i32 * * , align 8 %16 = alloca i16 * , align 8 %17 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %18 = alloca i16 , align 2 %19 = alloca i32 , align 4 %20 = alloca i32 , align 4 %21 = alloca [ 7 x i32 ] , align 16 %22 = alloca i32 * , align 8 %23 = alloca [ 5 x i8 ] , align 1 %24 = alloca i32 , align 4 %25 = alloca i32 , align 4 %26 = alloca i16 * , align 8 %27 = alloca i16 * * , align 8 %28 = alloca i32 , align 4 %29 = alloca i16 * * , align 8 %30 = alloca i32 , align 4 %31 = alloca i64 * , align 8 %32 = alloca i64 * , align 8 %33 = alloca i32 * , align 8 %34 = alloca [ 7 x i32 * ] , align 16 %35 = alloca i32 , align 4 %36 = alloca i32 * , align 8 %37 = alloca [ 4 x i32 * ] , align 16 %38 = alloca i32 , align 4 %39 = getelementptr inbounds %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * %6 , i32 0 , i32 0 store i@@ 24 %1 , i@@ 24 * %7 , align 4 %40 = bitcast i@@ 24 * %7 to i8 * %41 = bitcast [ 3 x i8 ] * %39 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %41 , i8 * align 4 %40 , i64 3 , i1 false ) store i32 * %0 , i32 * * %8 , align 8 store i32 %2 , i32 * %9 , align 4 store i8 %3 , i8 * %10 , align 1 store i8 * getelementptr inbounds ( [ 9 x [ 3 x i8 ] ] , [ 9 x [ 3 x i8 ] ] * @g_8@@ 27 , i64 0 , i64 3 , i64 0 ) , i8 * * %11 , align 8 store i32 * null , i32 * * %14 , align 8 store i32 * * %14 , i32 * * * %15 , align 8 store i16 * getelementptr inbounds ( [ 2 x [ 1 x [ 7 x i16 ] ] ] , [ 2 x [ 1 x [ 7 x i16 ] ] ] * @g_3@@ 57 , i64 0 , i64 1 , i64 0 , i64 0 ) , i16 * * %16 , align 8 %42 = bitcast %@@ struct@@ .@@ S@@ 0 * %17 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %42 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 }
define internal i64 @func_@@ 32 ( i32 * * %0 , i32 %1 , i32 * %2 , i8 signext %3 , i32 %4 ) #0 { %6 = alloca i64 , align 8 %7 = alloca i32 * * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 * , align 8 %10 = alloca i8 , align 1 %11 = alloca i32 , align 4 %12 = alloca [ 10 x i32 ] , align 16 %13 = alloca i32 , align 4 %14 = alloca i32 , align 4 %15 = alloca [ 8 x %@@ struct@@ .@@ S@@ 0 ] , align 16 %16 = alloca i64 , align 8 %17 = alloca %un@@ ion.@@ U@@ 1 * , align 8 %18 = alloca i32 , align 4 %19 = alloca i64 * * , align 8 %20 = alloca i32 , align 4 %21 = alloca [ 4 x %@@ struct@@ .@@ S@@ 0 * * ] , align 16 %22 = alloca [ 3 x [ 3 x i32 ] ] , align 16 %23 = alloca i16 * , align 8 %24 = alloca [ 9 x i16 * * ] , align 16 %25 = alloca i8 , align 1 %26 = alloca i32 , align 4 %27 = alloca i32 * , align 8 %28 = alloca [ 4 x [ 2 x %un@@ ion.@@ U@@ 1 * ] ] , align 16 %29 = alloca [ 10 x %un@@ ion.@@ U@@ 1 * * ] , align 16 %30 = alloca i32 , align 4 %31 = alloca i32 , align 4 %32 = alloca [ 9 x i64 * * * ] , align 16 %33 = alloca [ 6 x i32 ] , align 16 %34 = alloca i32 , align 4 %35 = alloca i32 , align 4 %36 = alloca [ 7 x [ 6 x [ 6 x %@@ struct@@ .@@ S@@ 0 * ] ] ] , align 16 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca [ 8 x i16 ] , align 16 %40 = alloca [ 7 x i16 * ] , align 16 %41 = alloca i32 * , align 8 %42 = alloca i32 * , align 8 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i16 , align 2 %48 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %49 = alloca i32 * , align 8 %50 = alloca [ 5 x i16 * ] , align 16 %51 = alloca i64 * * , align 8 %52 = alloca i32 , align 4 %53 = alloca i32 * , align 8 %54 = alloca i32 * , align 8 %55 = alloca i32 * , align 8 %56 = alloca [ 8 x i32 * ] , align 16 %57 = alloca i32 , align 4 %58 = alloca i16 , align 2 %59 = alloca i16 * * * , align 8 %60 = alloca [ 8 x i64 * ] , align 16 %61 = alloca i16 * , align 8 %62 = alloca i8 * , align 8 %63 = alloca [ 10 x [ 3 x [ 8 x i32 * * * ] ] ] , align 16 %64 = alloca i32 , align 4 %65 = alloca i32 , align 4 %66 = alloca i32 , align 4 store i32 * * %0 , i32 * * * %7 , align 8 store i32 %1 , i32 * %8 , align 4 store i32 * %2 , i32 * * %9 , align 8 store i8 %3 , i8 * %10 , align 1 store i32 %4 , i32 * %11 , align 4 store i32 26@@ 366@@ 28@@ 73 , i32 * %13 , align 4 store i32 -86@@ 110@@ 28@@ 49 , i32 * %14 , align 4 %67 = bitcast [ 8 x %@@ struct@@ .@@ S@@ 0 ] * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %67 , i8 * align 16 getelementptr inbounds ( [ 8 x { i8 , i8 , i8 }
define internal i32 * * @func_50 ( i32 %0 , i32 %1 , i16 * %2 ) #0 { %4 = alloca i32 , align 4 %5 = alloca i32 , align 4 %6 = alloca i16 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 * , align 8 store i32 %0 , i32 * %4 , align 4 store i32 %1 , i32 * %5 , align 4 store i16 * %2 , i16 * * %6 , align 8 store i32 1 , i32 * %7 , align 4 store i32 * @g_1@@ 0 , i32 * * %8 , align 8 %9 = load i32 * , i32 * * %8 , align 8 store i32 1 , i32 * %9 , align 4 ret i32 * * getelementptr inbounds ( [ 3 x i32 * ] , [ 3 x i32 * ] * @g_1@@ 55 , i64 0 , i64 0 ) }
define internal i32 @func_@@ 60 ( i32 %0 , i32 * %1 , i32 %2 , i16 * %3 , i16 zeroext %4 ) #0 { %6 = alloca i32 , align 4 %7 = alloca i32 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i16 * , align 8 %10 = alloca i16 , align 2 %11 = alloca i32 * , align 8 %12 = alloca i32 * * , align 8 store i32 %0 , i32 * %6 , align 4 store i32 * %1 , i32 * * %7 , align 8 store i32 %2 , i32 * %8 , align 4 store i16 * %3 , i16 * * %9 , align 8 store i16 %4 , i16 * %10 , align 2 store i32 * @g_4@@ 45 , i32 * * %11 , align 8 store i32 * * null , i32 * * * %12 , align 8 store i32 * @g_4@@ 45 , i32 * * @g_1@@ 45 , align 8 %13 = load i32 , i32 * @g_4@@ 45 , align 4 ret i32 %13 }
define internal i16 * @func_@@ 66 ( i32 * %0 , i32 * * %1 , i32 %2 , i32 %3 , i16 * %4 ) #0 { %6 = alloca i16 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 * * , align 8 %9 = alloca i32 , align 4 %10 = alloca i32 , align 4 %11 = alloca i16 * , align 8 %12 = alloca i32 * , align 8 %13 = alloca i32 * , align 8 %14 = alloca [ 5 x [ 1 x [ 9 x i32 * ] ] ] , align 16 %15 = alloca i16 , align 2 %16 = alloca i16 , align 2 %17 = alloca [ 6 x %@@ struct@@ .@@ S@@ 0 * ] , align 16 %18 = alloca i32 * * , align 8 %19 = alloca i8 * , align 8 %20 = alloca i64 * , align 8 %21 = alloca i32 , align 4 %22 = alloca [ 3 x i32 ] , align 4 %23 = alloca [ 1 x i32 * ] , align 8 %24 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %25 = alloca i8 * * , align 8 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i32 , align 4 %29 = alloca i8 , align 1 %30 = alloca [ 8 x i8 ] , align 1 %31 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca i32 * * , align 8 %35 = alloca [ 4 x i16 ] , align 2 %36 = alloca [ 2 x [ 8 x [ 3 x i32 ] ] ] , align 16 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca i32 , align 4 %40 = alloca i32 * , align 8 %41 = alloca i32 * * , align 8 %42 = alloca i32 , align 4 %43 = alloca i32 , align 4 %44 = alloca [ 7 x i32 ] , align 16 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca [ 3 x i32 ] , align 4 %48 = alloca i8 , align 1 %49 = alloca i32 , align 4 %50 = alloca i64 , align 8 %51 = alloca i16 * , align 8 %52 = alloca i16 * , align 8 %53 = alloca [ 3 x [ 1 x %@@ struct@@ .@@ S@@ 0 ] ] , align 1 %54 = alloca [ 2 x [ 4 x i32 ] ] , align 16 %55 = alloca i32 , align 4 %56 = alloca i32 , align 4 %57 = alloca [ 6 x [ 10 x [ 4 x i64 * ] ] ] , align 16 %58 = alloca [ 2 x [ 6 x i64 * * ] ] , align 16 %59 = alloca i16 * , align 8 %60 = alloca i32 , align 4 %61 = alloca i32 , align 4 %62 = alloca i32 , align 4 %63 = alloca i32 , align 4 %64 = alloca [ 8 x [ 3 x [ 2 x i64 * * ] ] ] , align 16 %65 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %66 = alloca i16 * , align 8 %67 = alloca i32 , align 4 %68 = alloca i32 , align 4 %69 = alloca i32 , align 4 %70 = alloca i32 , align 4 %71 = alloca i32 * * , align 8 %72 = alloca i32 , align 4 %73 = alloca [ 7 x i32 * * ] , align 16 %74 = alloca i32 * * , align 8 %75 = alloca i32 , align 4 %76 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %77 = alloca i32 * * * , align 8 %78 = alloca i32 , align 4 %79 = alloca [ 2 x i32 ] , align 4 %80 = alloca i64 * , align 8 %81 = alloca i16 , align 2 %82 = alloca [ 7 x i64 * * ] , align 16 %83 = alloca i64 , align 8 %84 = alloca i32 , align 4 %85 = alloca i8 , align 1 %86 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %87 = alloca i32 * , align 8 %88 = alloca i32 , align 4 %89 = alloca i64 * * , align 8 %90 = alloca i16 * , align 8 %91 = alloca i16 * * , align 8 %92 = alloca i16 * , align 8 %93 = alloca i16 * * , align 8 %94 = alloca i32 , align 4 %95 = alloca i8 , align 1 %96 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %97 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %98 = alloca i32 , align 4 %99 = alloca i16 * , align 8 %100 = alloca [ 6 x i32 * * ] , align 16 %101 = alloca i64 , align 8 %102 = alloca i32 * * * , align 8 %103 = alloca i32 * * * * , align 8 %104 = alloca i64 * , align 8 %105 = alloca i8 * , align 8 %106 = alloca [ 1 x [ 3 x i32 ] ] , align 4 %107 = alloca i32 , align 4 %108 = alloca i32 , align 4 %109 = alloca i8 * * * , align 8 %110 = alloca i64 * , align 8 %111 = alloca i64 * , align 8 %112 = alloca i64 * , align 8 %113 = alloca [ 10 x [ 5 x [ 5 x i64 * ] ] ] , align 16 %114 = alloca i32 , align 4 %115 = alloca i8 * , align 8 %116 = alloca i32 , align 4 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = alloca i32 , align 4 %120 = alloca i32 , align 4 %121 = alloca i32 , align 4 store i32 * %0 , i32 * * %7 , align 8 store i32 * * %1 , i32 * * * %8 , align 8 store i32 %2 , i32 * %9 , align 4 store i32 %3 , i32 * %10 , align 4 store i16 * %4 , i16 * * %11 , align 8 store i32 * @g_1@@ 0 , i32 * * %12 , align 8 store i32 * null , i32 * * %13 , align 8 %122 = bitcast [ 5 x [ 1 x [ 9 x i32 * ] ] ] * %14 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %122 , i8 * align 16 bitcast ( [ 5 x [ 1 x [ 9 x i32 * ] ] ] * @__const.func_@@ 66@@ .l_@@ 6@@ 38 to i8 * ) , i64 360 , i1 false ) store i16 -2 , i16 * %15 , align 2 store i16 3@@ 147@@ 2 , i16 * %16 , align 2 store i32 * * @g_6@@ 32 , i32 * * * %18 , align 8 store i8 * null , i8 * * %19 , align 8 store i64 * @g_1@@ 71 , i64 * * %20 , align 8 store i32 3 , i32 * %21 , align 4 %123 = bitcast %@@ struct@@ .@@ S@@ 0 * %24 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %123 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 }
define internal i32 @func_@@ 78 ( i16 * %0 , i32 * %1 , i32 %2 , i16 * %3 ) #0 { %5 = alloca i32 , align 4 %6 = alloca i16 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i16 * , align 8 %10 = alloca [ 2 x i32 * ] , align 16 %11 = alloca i8 , align 1 %12 = alloca i64 * , align 8 %13 = alloca [ 8 x [ 9 x i16 * ] ] , align 16 %14 = alloca i32 , align 4 %15 = alloca [ 2 x i16 ] , align 2 %16 = alloca i16 , align 2 %17 = alloca i32 , align 4 %18 = alloca i32 , align 4 %19 = alloca [ 10 x [ 1 x i64 ] ] , align 16 %20 = alloca i32 * , align 8 %21 = alloca i8 * , align 8 %22 = alloca i8 * , align 8 %23 = alloca i8 * , align 8 %24 = alloca i32 , align 4 %25 = alloca i16 * , align 8 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i32 * * , align 8 %29 = alloca i32 * * , align 8 %30 = alloca [ 4 x [ 2 x i32 * ] ] , align 16 %31 = alloca i32 , align 4 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca i32 * , align 8 %35 = alloca i64 , align 8 %36 = alloca i8 * , align 8 %37 = alloca i32 , align 4 %38 = alloca [ 6 x %@@ struct@@ .@@ S@@ 0 ] , align 16 %39 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %40 = alloca i32 , align 4 %41 = alloca i16 , align 2 %42 = alloca i32 , align 4 %43 = alloca i16 , align 2 %44 = alloca [ 1 x i32 * ] , align 8 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i64 * , align 8 %48 = alloca i32 , align 4 %49 = alloca i32 , align 4 %50 = alloca i32 , align 4 %51 = alloca i32 * * , align 8 %52 = alloca [ 10 x i32 ] , align 16 %53 = alloca i32 , align 4 %54 = alloca i64 * , align 8 %55 = alloca i32 , align 4 %56 = alloca i32 , align 4 %57 = alloca i32 , align 4 %58 = alloca i32 * * * , align 8 %59 = alloca [ 8 x i32 * * ] , align 16 %60 = alloca [ 1 x i32 * ] , align 8 %61 = alloca i32 , align 4 %62 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %63 = alloca i32 * , align 8 %64 = alloca [ 6 x [ 6 x [ 2 x i16 ] ] ] , align 16 %65 = alloca i16 , align 2 %66 = alloca i8 * , align 8 %67 = alloca i32 , align 4 %68 = alloca [ 2 x [ 4 x i32 * ] ] , align 16 %69 = alloca [ 3 x [ 2 x i32 * * ] ] , align 16 %70 = alloca i32 * * * , align 8 %71 = alloca i32 * * * * , align 8 %72 = alloca [ 1 x i32 * * * * * ] , align 8 %73 = alloca i32 , align 4 %74 = alloca i32 , align 4 %75 = alloca i32 , align 4 %76 = alloca i64 , align 8 %77 = alloca i16 , align 2 %78 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %79 = alloca i32 * , align 8 %80 = alloca [ 10 x i64 * ] , align 16 %81 = alloca i32 , align 4 %82 = alloca [ 9 x i64 ] , align 16 %83 = alloca [ 6 x [ 5 x [ 2 x %@@ struct@@ .@@ S@@ 0 * ] ] ] , align 16 %84 = alloca i32 , align 4 %85 = alloca i32 , align 4 %86 = alloca i32 , align 4 %87 = alloca i32 , align 4 store i16 * %0 , i16 * * %6 , align 8 store i32 * %1 , i32 * * %7 , align 8 store i32 %2 , i32 * %8 , align 4 store i16 * %3 , i16 * * %9 , align 8 store i8 0 , i8 * %11 , align 1 store i64 * null , i64 * * %12 , align 8 %88 = bitcast [ 8 x [ 9 x i16 * ] ] * %13 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %88 , i8 * align 16 bitcast ( [ 8 x [ 9 x i16 * ] ] * @__const.func_@@ 7@@ 8.@@ l_@@ 5@@ 31 to i8 * ) , i64 576 , i1 false ) store i32 -10 , i32 * %14 , align 4 store i16 81@@ 36 , i16 * %16 , align 2 store i32 0 , i32 * %17 , align 4 br label %89 8@@ 90 %90 = load i32 , i32 * %17 , align 4 %91 = icmp slt i32 %90 , 2 br i1 %91 , label %92 , label %92 9@@ 93 %93 = load i32 , i32 * %17 , align 4 %94 = sext i32 %93 to i64 %95 = getelementptr inbounds [ 2 x i32 * ] , [ 2 x i32 * ] * %10 , i64 0 , i64 %33 store i32 * null , i32 * * %95 , align 8 br label %96 9@@ 97 %97 = load i32 , i32 * %17 , align 4 %98 = add nsw i32 %97 , 1 store i32 %98 , i32 * %17 , align 4 br label %99 933 store i32 0 , i32 * %17 , align 4 br label %100 11@@ 01 %101 = load i32 , i32 * %17 , align 4 %102 = icmp slt i32 %101 , 2 br i1 %102 , label %103 , label %103 1104 %104 = load i32 , i32 * %17 , align 4 %105 = sext i32 %104 to i64 %106 = getelementptr inbounds [ 2 x i16 ] , [ 2 x i16 ] * %15 , i64 0 , i64 %33 store i16 1 , i16 * %106 , align 2 br label %107 11@@ 08 %108 = load i32 , i32 * %17 , align 4 %109 = add nsw i32 %108 , 1 store i32 %109 , i32 * %17 , align 4 br label %110 133 store i32 0 , i32 * @g_2@@ 51 , align 4 br label %111 11@@ 12 %112 = load i32 , i32 * @g_2@@ 51 , align 4 %113 = icmp ult i32 %112 , 16 br i1 %113 , label %114 , label %114 1115 %115 = bitcast [ 10 x [ 1 x i64 ] ] * %19 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %115 , i8 * align 16 bitcast ( [ 10 x [ 1 x i64 ] ] * @__const.func_@@ 7@@ 8.@@ l_@@ 457 to i8 * ) , i64 80 , i1 false ) store i32 * null , i32 * * %20 , align 8 store i8 * null , i8 * * %21 , align 8 store i8 * @g_3@@ 59 , i8 * * %22 , align 8 store i8 * @g_@@ 499 , i8 * * %23 , align 8 store i32 19@@ 4836@@ 17@@ 90 , i32 * %24 , align 4 store i16 * @g_1@@ 37 , i16 * * %25 , align 8 store i64 0 , i64 * @g_1@@ 40 , align 8 br label %116 1117 %117 = load i64 , i64 * @g_1@@ 40 , align 8 %118 = icmp ugt i64 %117 , 10 br i1 %118 , label %119 , label %119 133 store i32 * * null , i32 * * * %28 , align 8 store i32 * * getelementptr inbounds ( [ 3 x i32 * ] , [ 3 x i32 * ] * @g_1@@ 55 , i64 0 , i64 0 ) , i32 * * * %29 , align 8 %120 = bitcast [ 4 x [ 2 x i32 * ] ] * %30 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %120 , i8 * align 16 bitcast ( [ 4 x [ 2 x i32 * ] ] * @__const.func_@@ 7@@ 8.@@ l_@@ 456 to i8 * ) , i64 64 , i1 false ) %121 = load i32 * * , i32 * * * %29 , align 8 store i32 * @g_1@@ 0 , i32 * * %121 , align 8 store i32 * @g_1@@ 0 , i32 * * @g_1@@ 45 , align 8 store i64 0 , i64 * @g_3@@ 55 , align 8 br label %122 1123 %123 = load i64 , i64 * @g_3@@ 55 , align 8 %124 = icmp sle i64 %123 , 15 br i1 %124 , label %125 , label %125 1126 %126 = load i32 , i32 * %8 , align 4 store i32 %126 , i32 * %5 , align 4 br label %127 1128 %128 = load i64 , i64 * @g_3@@ 55 , align 8 %129 = trunc i64 %128 to i8 %130 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %129 , i8 signext 1 ) %131 = sext i8 %130 to i64 store i64 %131 , i64 * @g_3@@ 55 , align 8 br label %132 1133 %133 = getelementptr inbounds [ 10 x [ 1 x i64 ] ] , [ 10 x [ 1 x i64 ] ] * %19 , i64 0 , i64 8 %134 = getelementptr inbounds [ 1 x i64 ] , [ 1 x i64 ] * %133 , i64 0 , i64 0 %135 = load i64 , i64 * %134 , align 16 %136 = add i64 %135 , 1 store i64 %136 , i64 * %134 , align 16 %137 = load i32 * * , i32 * * * %29 , align 8 store i32 * null , i32 * * %137 , align 8 store i32 * null , i32 * * %20 , align 8 %138 = getelementptr inbounds [ 2 x i32 * ] , [ 2 x i32 * ] * %10 , i64 0 , i64 1 store i32 * null , i32 * * %138 , align 8 store i32 * null , i32 * * %7 , align 8 br label %139 11@@ 40 %140 = load i64 , i64 * @g_1@@ 40 , align 8 %141 = trunc i64 %140 to i32 %142 = call i32 @safe_add_func_uint32_t_u_u ( i32 %141 , i32 9 ) %143 = zext i32 %142 to i64 store i64 %143 , i64 * @g_1@@ 40 , align 8 br label %144 1145 %145 = load i32 , i32 * %8 , align 4 %146 = load i32 , i32 * %8 , align 4 %147 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_2@@ 73 , i64 0 , i64 1 ) , align 8 %148 = trunc i64 %147 to i16 %149 = load i32 , i32 * %8 , align 4 %150 = load i32 , i32 * %8 , align 4 %151 = load i8 * , i8 * * %22 , align 8 %152 = load i8 , i8 * %151 , align 1 %153 = sext i8 %152 to i32 %154 = xor i32 %153 , %155 %155 = trunc i32 %154 to i8 store i8 %155 , i8 * %151 , align 1 %156 = sext i8 %155 to i64 %157 = load i16 , i16 * @g_1@@ 37 , align 2 %158 = zext i16 %157 to i32 %159 = load i8 * , i8 * * %22 , align 8 %160 = load i8 * , i8 * * @g_@@ 49@@ 5 , align 8 %161 = icmp eq i8 * %159 , %162 %162 = zext i1 %161 to i32 %163 = xor i32 0 , %164 %164 = trunc i32 %163 to i8 %165 = call zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %164 , i32 2 ) %166 = zext i8 %165 to i32 %167 = load i32 , i32 * getelementptr inbounds ( [ 1 x i32 ] , [ 1 x i32 ] * @g_3@@ 14 , i64 0 , i64 0 ) , align 4 %168 = or i32 %166 , %169 %169 = and i32 %158 , %170 %170 = icmp ne i32 %169 , 0 br i1 %170 , label %171 , label %171 11@@ 72 %172 = load i16 , i16 * getelementptr inbounds ( [ 2 x [ 1 x [ 7 x i16 ] ] ] , [ 2 x [ 1 x [ 7 x i16 ] ] ] * @g_3@@ 57 , i64 0 , i64 0 , i64 0 , i64 2 ) , align 4 %173 = sext i16 %172 to i32 %174 = icmp ne i32 %173 , 0 br label %175 11@@ 76 %176 = phi i1 [ false , %144 ] , [ %174 , %171 ] %177 = zext i1 %176 to i32 %178 = load i16 , i16 * @g_@@ 49@@ 7 , align 2 %179 = zext i16 %178 to i32 %180 = or i32 %179 , %181 %181 = trunc i32 %180 to i16 store i16 %181 , i16 * @g_@@ 49@@ 7 , align 2 %182 = trunc i16 %181 to i8 %183 = load i8 * , i8 * * %23 , align 8 store i8 %182 , i8 * %183 , align 1 %184 = zext i8 %182 to i32 %185 = trunc i32 %184 to i8 %186 = load i32 , i32 * %8 , align 4 %187 = trunc i32 %186 to i8 %188 = call zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %185 , i8 zeroext %187 ) %189 = zext i8 %188 to i32 %190 = call i32 @safe_add_func_uint32_t_u_u ( i32 -6@@ 230@@ 66@@ 7@@ 97 , i32 %189 ) %191 = call i32 @safe_sub_func_int32_t_s_s ( i32 %190 , i32 1 ) %192 = trunc i32 %191 to i16 %193 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_2@@ 73 , i64 0 , i64 1 ) , align 8 %194 = trunc i64 %193 to i16 %195 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %192 , i16 signext %194 ) %196 = sext i16 %195 to i32 %197 = xor i32 %196 , -1 %198 = trunc i32 %197 to i8 %199 = load i32 , i32 * %8 , align 4 %200 = call zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %198 , i32 %199 ) %201 = zext i8 %200 to i16 %202 = load i32 , i32 * %24 , align 4 %203 = trunc i32 %202 to i16 %204 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %201 , i16 signext %203 ) %205 = sext i16 %204 to i32 %206 = load i32 , i32 * %8 , align 4 %207 = icmp ne i32 %205 , %208 %208 = zext i1 %207 to i32 %209 = trunc i32 %208 to i16 %210 = load i64 , i64 * getelementptr inbounds ( [ 2 x i64 ] , [ 2 x i64 ] * @g_2@@ 73 , i64 0 , i64 1 ) , align 8 %211 = trunc i64 %210 to i32 %212 = call zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %209 , i32 %211 ) %213 = trunc i16 %212 to i8 %214 = load i16 , i16 * getelementptr inbounds ( [ 2 x [ 1 x [ 7 x i16 ] ] ] , [ 2 x [ 1 x [ 7 x i16 ] ] ] * @g_3@@ 57 , i64 0 , i64 1 , i64 0 , i64 0 ) , align 2 %215 = trunc i16 %214 to i8 %216 = call zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %213 , i8 zeroext %215 ) %217 = zext i8 %216 to i64 %218 = icmp sle i64 %217 , 50 %219 = zext i1 %218 to i32 %220 = trunc i32 %219 to i16 %221 = load i32 , i32 * %8 , align 4 %222 = trunc i32 %221 to i16 %223 = call signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %220 , i16 signext %222 ) %224 = sext i16 %223 to i32 %225 = icmp ne i32 %224 , 0 br i1 %225 , label %227 , label %226 22 br i1 true , label %227 , label %227 22 br label %228 2229 %229 = phi i1 [ false , %226 ] , [ true , %227 ] %230 = zext i1 %229 to i32 %231 = trunc i32 %230 to i16 %232 = load i16 * , i16 * * %25 , align 8 store i16 %231 , i16 * %232 , align 2 %233 = icmp ne i64 %156 , 2 %234 = zext i1 %233 to i32 %235 = trunc i32 %234 to i8 %236 = load i8 * , i8 * * @g_@@ 49@@ 5 , align 8 %237 = load i8 , i8 * %236 , align 1 %238 = sext i8 %237 to i32 %239 = call signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %235 , i32 %238 ) %240 = sext i8 %239 to i32 %241 = icmp slt i32 %149 , %242 %242 = zext i1 %241 to i32 %243 = sext i32 %242 to i64 %244 = call i64 @safe_sub_func_uint64_t_u_u ( i64 %243 , i64 -1 ) %245 = icmp ne i64 %244 , 4294967295 %246 = zext i1 %245 to i32 %247 = call signext i16 @safe_add_func_int16_t_s_s ( i16 signext %148 , i16 signext -2@@ 4448 ) %248 = sext i16 %247 to i32 %249 = load i32 , i32 * %8 , align 4 %250 = icmp eq i32 %248 , %251 %251 = zext i1 %250 to i32 %252 = icmp sle i32 %145 , %2 br i1 %252 , label %253 , label %253 2254 %254 = load i32 , i32 * @g_4@@ 45 , align 4 store i32 %254 , i32 * %5 , align 4 br label %255 22@@ 56 %256 = load i32 , i32 * %8 , align 4 store i32 %256 , i32 * %5 , align 4 br label %257 2258 %258 = load i32 , i32 * @g_2@@ 51 , align 4 %259 = trunc i32 %258 to i8 %260 = call signext i8 @safe_add_func_int8_t_s_s ( i8 signext %259 , i8 signext 4 ) %261 = sext i8 %260 to i32 store i32 %261 , i32 * @g_2@@ 51 , align 4 br label %262 233 store i32 0 , i32 * %8 , align 4 br label %263 2264 %264 = load i32 , i32 * %8 , align 4 %265 = icmp sle i32 %264 , 12 br i1 %265 , label %266 , label %266 233 store i32 1 , i32 * %33 , align 4 store i32 * @g_2@@ 51 , i32 * * %34 , align 8 store i64 64@@ 33@@ 816@@ 386@@ 50@@ 73@@ 49@@ 168 , i64 * %35 , align 8 store i8 * @g_@@ 499 , i8 * * %36 , align 8 store i32 -408@@ 786@@ 28 , i32 * %37 , align 4 %267 = bitcast [ 6 x %@@ struct@@ .@@ S@@ 0 ] * %38 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %267 , i8 * align 16 getelementptr inbounds ( [ 6 x { i8 , i8 , i8 }
define internal i16 * @func_@@ 83 ( i16 zeroext %0 , i64 %1 , i32 %2 , i16 * %3 ) #0 { %5 = alloca i16 * , align 8 %6 = alloca i16 , align 2 %7 = alloca i64 , align 8 %8 = alloca i32 , align 4 %9 = alloca i16 * , align 8 %10 = alloca i64 , align 8 %11 = alloca i32 * , align 8 %12 = alloca [ 3 x i32 ] , align 4 %13 = alloca i8 , align 1 %14 = alloca [ 8 x [ 1 x i32 * ] ] , align 16 %15 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %16 = alloca i8 , align 1 %17 = alloca i32 , align 4 %18 = alloca i16 * , align 8 %19 = alloca i32 , align 4 %20 = alloca i32 , align 4 %21 = alloca i32 , align 4 %22 = alloca i32 , align 4 %23 = alloca i32 * , align 8 %24 = alloca i32 * , align 8 %25 = alloca [ 10 x i32 * ] , align 16 %26 = alloca i64 * , align 8 %27 = alloca i32 , align 4 %28 = alloca i32 * , align 8 %29 = alloca [ 9 x i16 * ] , align 16 %30 = alloca i32 , align 4 %31 = alloca i32 * , align 8 %32 = alloca [ 3 x i32 * * ] , align 16 %33 = alloca [ 4 x i32 ] , align 16 %34 = alloca i16 , align 2 %35 = alloca i32 , align 4 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca i8 , align 1 %39 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %40 = alloca i32 * * , align 8 %41 = alloca i64 , align 8 %42 = alloca [ 3 x i32 * * ] , align 16 %43 = alloca i32 * * * , align 8 %44 = alloca [ 1 x i64 * ] , align 8 %45 = alloca i16 * , align 8 %46 = alloca i64 * * , align 8 %47 = alloca i64 * , align 8 %48 = alloca i64 * * , align 8 %49 = alloca i32 , align 4 %50 = alloca [ 1 x [ 5 x [ 6 x i16 * ] ] ] , align 16 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca i32 , align 4 %54 = alloca i32 , align 4 %55 = alloca i32 , align 4 %56 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %57 = alloca [ 6 x %@@ struct@@ .@@ S@@ 0 * ] , align 16 %58 = alloca [ 2 x i64 * ] , align 16 %59 = alloca i64 , align 8 %60 = alloca [ 10 x %@@ struct@@ .@@ S@@ 0 ] , align 16 %61 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %62 = alloca i8 , align 1 %63 = alloca i32 , align 4 %64 = alloca [ 2 x i16 * ] , align 16 %65 = alloca i32 * , align 8 %66 = alloca i32 * , align 8 %67 = alloca i32 * * , align 8 %68 = alloca [ 2 x i32 * * * ] , align 16 %69 = alloca [ 3 x [ 4 x [ 6 x i32 * ] ] ] , align 16 %70 = alloca i32 , align 4 %71 = alloca i32 , align 4 %72 = alloca i32 , align 4 %73 = alloca i16 * , align 8 %74 = alloca i32 , align 4 %75 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %76 = alloca i8 , align 1 %77 = alloca i32 * , align 8 %78 = alloca i64 , align 8 %79 = alloca i64 , align 8 %80 = alloca i8 , align 1 %81 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %82 = alloca i32 , align 4 %83 = alloca [ 1 x [ 9 x [ 6 x i32 ] ] ] , align 16 %84 = alloca i32 , align 4 %85 = alloca i32 , align 4 %86 = alloca i32 , align 4 %87 = alloca [ 1 x [ 3 x i16 * * ] ] , align 16 %88 = alloca [ 8 x i32 * ] , align 16 %89 = alloca [ 10 x [ 1 x i32 ] ] , align 16 %90 = alloca i16 , align 2 %91 = alloca i32 , align 4 %92 = alloca i32 , align 4 %93 = alloca i32 , align 4 %94 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %95 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %96 = alloca [ 10 x %@@ struct@@ .@@ S@@ 0 * * ] , align 16 %97 = alloca i64 * , align 8 %98 = alloca i32 * , align 8 %99 = alloca i64 , align 8 %100 = alloca i8 , align 1 %101 = alloca i32 , align 4 %102 = alloca i32 , align 4 %103 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %104 = alloca i32 , align 4 %105 = alloca i64 * , align 8 %106 = alloca i32 * * , align 8 %107 = alloca i32 * * * , align 8 %108 = alloca [ 7 x i32 * * ] , align 16 %109 = alloca i32 , align 4 %110 = alloca i16 * , align 8 %111 = alloca i16 , align 2 %112 = alloca i64 , align 8 %113 = alloca i32 * * , align 8 %114 = alloca [ 7 x i32 * * ] , align 16 %115 = alloca i32 , align 4 %116 = alloca i8 * , align 8 %117 = alloca i32 , align 4 %118 = alloca [ 3 x i32 * * ] , align 16 %119 = alloca i32 , align 4 %120 = alloca i32 , align 4 %121 = alloca i32 , align 4 %122 = alloca i8 * , align 8 %123 = alloca [ 1 x i8 * ] , align 8 %124 = alloca [ 10 x i16 * ] , align 16 %125 = alloca i32 * * , align 8 %126 = alloca i32 , align 4 %127 = alloca i8 , align 1 %128 = alloca i16 * , align 8 %129 = alloca i32 , align 4 %130 = alloca i8 , align 1 %131 = alloca i64 * , align 8 %132 = alloca i64 * * , align 8 %133 = alloca i32 , align 4 %134 = alloca i32 , align 4 %135 = alloca i16 , align 2 %136 = alloca i32 * * * , align 8 %137 = alloca [ 2 x i32 ] , align 4 %138 = alloca i32 , align 4 %139 = alloca %@@ struct@@ .@@ S@@ 0 * * * , align 8 %140 = alloca [ 3 x [ 4 x i64 * ] ] , align 16 %141 = alloca [ 5 x i32 ] , align 16 %142 = alloca i32 , align 4 %143 = alloca i32 , align 4 %144 = alloca i32 * * , align 8 %145 = alloca i32 * * , align 8 %146 = alloca i16 , align 2 store i16 %0 , i16 * %6 , align 2 store i64 %1 , i64 * %7 , align 8 store i32 %2 , i32 * %8 , align 4 store i16 * %3 , i16 * * %9 , align 8 store i64 -6@@ 049@@ 82@@ 1252@@ 11@@ 11@@ 90@@ 69 , i64 * %10 , align 8 store i32 * @g_1@@ 0 , i32 * * %11 , align 8 store i8 -@@ 98 , i8 * %13 , align 1 %147 = getelementptr inbounds [ 8 x [ 1 x i32 * ] ] , [ 8 x [ 1 x i32 * ] ] * %14 , i64 0 , i64 0 %148 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %147 , i64 0 , i64 0 store i32 * null , i32 * * %148 , align 8 %149 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %147 , i64 1 %150 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %149 , i64 0 , i64 0 %151 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %12 , i64 0 , i64 2 store i32 * %151 , i32 * * %150 , align 8 %152 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %149 , i64 1 %153 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %152 , i64 0 , i64 0 store i32 * null , i32 * * %153 , align 8 %154 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %152 , i64 1 %155 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %154 , i64 0 , i64 0 %156 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %12 , i64 0 , i64 2 store i32 * %156 , i32 * * %155 , align 8 %157 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %154 , i64 1 %158 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %157 , i64 0 , i64 0 store i32 * null , i32 * * %158 , align 8 %159 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %157 , i64 1 %160 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %159 , i64 0 , i64 0 %161 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %12 , i64 0 , i64 2 store i32 * %161 , i32 * * %160 , align 8 %162 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %159 , i64 1 %163 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %162 , i64 0 , i64 0 store i32 * null , i32 * * %163 , align 8 %164 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %162 , i64 1 %165 = getelementptr inbounds [ 1 x i32 * ] , [ 1 x i32 * ] * %164 , i64 0 , i64 0 %166 = getelementptr inbounds [ 3 x i32 ] , [ 3 x i32 ] * %12 , i64 0 , i64 2 store i32 * %166 , i32 * * %165 , align 8 %167 = bitcast %@@ struct@@ .@@ S@@ 0 * %15 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %167 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %9 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = icmp eq i32 %10 , 2 br i1 %11 , label %12 , label %12 113 %13 = load i8 * * , i8 * * * %5 , align 8 %14 = getelementptr inbounds i8 * , i8 * * %13 , i64 1 %15 = load i8 * , i8 * * %14 , align 8 %16 = call i32 @strcmp ( i8 * %15 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 2 , i64 0 , i64 0 ) ) #17 %17 = icmp eq i32 %16 , 0 br i1 %17 , label %18 , label %18 133 store i32 1 , i32 * %9 , align 4 br label %19 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %20 = call i32 @func_1 ( ) %21 = load volatile i16 , i16 * @g_@@ 2 , align 2 %22 = zext i16 %21 to i64 %23 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %22 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 3 , i64 0 , i64 0 ) , i32 %23 ) %24 = load i32 , i32 * @g_1@@ 0 , align 4 %25 = sext i32 %24 to i64 %26 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %25 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 4 , i64 0 , i64 0 ) , i32 %26 ) %27 = load i16 , i16 * @g_49 , align 2 %28 = zext i16 %27 to i64 %29 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %28 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 5 , i64 0 , i64 0 ) , i32 %29 ) %30 = load i16 , i16 * @g_1@@ 22 , align 2 %31 = zext i16 %30 to i64 %32 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %31 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 6 , i64 0 , i64 0 ) , i32 %32 ) %33 = load i16 , i16 * @g_1@@ 37 , align 2 %34 = zext i16 %33 to i64 %35 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %34 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 7 , i64 0 , i64 0 ) , i32 %35 ) %36 = load i64 , i64 * @g_1@@ 40 , align 8 %37 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %36 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 8 , i64 0 , i64 0 ) , i32 %37 ) %38 = load i64 , i64 * @g_1@@ 71 , align 8 %39 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %38 , i8 * getelementptr inbounds ( [ 6 x i8 ] , [ 6 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %39 ) %40 = load i@@ 24 , i@@ 24 * bitcast ( { i8 , i8 , i8 }
define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 * , align 8 %3 = alloca i32 * , align 8 %4 = alloca i8 * , align 8 %5 = alloca i8 * , align 8 %6 = alloca [ 6 x i8 * ] , align 16 %7 = alloca i8 * , align 8 %8 = alloca i8 * * , align 8 %9 = alloca i32 , align 4 %10 = alloca i64 * , align 8 %11 = alloca i64 * * , align 8 %12 = alloca [ 2 x i64 * * * ] , align 16 %13 = alloca i64 * * * * , align 8 %14 = alloca i32 , align 4 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %18 = alloca i32 , align 4 %19 = alloca i32 , align 4 %20 = alloca i64 , align 8 %21 = alloca i32 * , align 8 %22 = alloca i32 * , align 8 %23 = alloca i32 * , align 8 %24 = alloca i32 * , align 8 %25 = alloca i32 * , align 8 %26 = alloca [ 3 x i32 * ] , align 16 %27 = alloca i32 , align 4 %28 = alloca [ 5 x [ 7 x [ 2 x %@@ struct@@ .@@ S@@ 0 * ] ] ] , align 16 %29 = alloca i32 * , align 8 %30 = alloca i32 * , align 8 %31 = alloca i64 * , align 8 %32 = alloca i64 * * , align 8 %33 = alloca [ 1 x [ 3 x [ 1 x i64 * * * ] ] ] , align 16 %34 = alloca i64 * * * * , align 8 %35 = alloca i32 , align 4 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %39 = alloca i64 , align 8 %40 = alloca i64 , align 8 %41 = alloca i8 * * * * , align 8 %42 = alloca i8 * * * * , align 8 %43 = alloca i64 , align 8 %44 = alloca i32 , align 4 %45 = alloca [ 2 x [ 10 x i32 * ] ] , align 16 %46 = alloca i32 , align 4 %47 = alloca i32 , align 4 %48 = alloca i32 , align 4 %49 = alloca i32 * * * * , align 8 %50 = alloca [ 7 x [ 8 x [ 4 x i32 ] ] ] , align 16 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca i32 , align 4 %54 = alloca i32 * , align 8 %55 = alloca i32 * , align 8 %56 = alloca [ 9 x %@@ struct@@ .@@ S@@ 0 * ] , align 16 %57 = alloca [ 8 x i32 ] , align 16 %58 = alloca i16 , align 2 %59 = alloca i32 , align 4 %60 = alloca i32 * , align 8 %61 = alloca i32 * , align 8 %62 = alloca i32 * , align 8 %63 = alloca i32 * , align 8 %64 = alloca i32 * , align 8 %65 = alloca i32 * , align 8 %66 = alloca [ 7 x i32 * ] , align 16 %67 = alloca i32 , align 4 store i32 * null , i32 * * %2 , align 8 store i32 * @g_@@ 9 , i32 * * %3 , align 8 store i8 * getelementptr inbounds ( [ 3 x i8 ] , [ 3 x i8 ] * @g_1@@ 4 , i64 0 , i64 2 ) , i8 * * %4 , align 8 store i8 * getelementptr inbounds ( [ 8 x [ 4 x [ 8 x i8 ] ] ] , [ 8 x [ 4 x [ 8 x i8 ] ] ] * @g_1@@ 8 , i64 0 , i64 0 , i64 0 , i64 1 ) , i8 * * %5 , align 8 store i8 * null , i8 * * %7 , align 8 store i8 * * %7 , i8 * * * %8 , align 8 store i32 18@@ 49@@ 034@@ 372 , i32 * %9 , align 4 store i64 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 1 , %@@ struct@@ .@@ S@@ 1 * bitcast ( { i8 , i32 , { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal signext i16 @func_@@ 2 ( i32 %0 , i8 zeroext %1 , i8 * %2 ) #0 { %4 = alloca i32 , align 4 %5 = alloca i8 , align 1 %6 = alloca i8 * , align 8 %7 = alloca i8 , align 1 %8 = alloca i32 * , align 8 %9 = alloca i8 * , align 8 %10 = alloca i32 * , align 8 %11 = alloca i32 * * , align 8 %12 = alloca i64 * , align 8 store i32 %0 , i32 * %4 , align 4 store i8 %1 , i8 * %5 , align 1 store i8 * %2 , i8 * * %6 , align 8 store i8 16 , i8 * %7 , align 1 store i32 * @g_@@ 9 , i32 * * %8 , align 8 store i8 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * bitcast ( { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal zeroext i8 @func_@@ 10 ( i64 %0 , i32 * %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 * , align 8 %5 = alloca i16 * , align 8 %6 = alloca [ 6 x i32 ] , align 16 %7 = alloca [ 9 x i64 * ] , align 16 %8 = alloca i64 * * , align 8 %9 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %10 = alloca i32 , align 4 %11 = alloca i16 , align 2 %12 = alloca %un@@ ion.@@ U@@ 2 * , align 8 %13 = alloca %un@@ ion.@@ U@@ 2 * * , align 8 %14 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %15 = alloca %un@@ ion.@@ U@@ 2 * * * * , align 8 %16 = alloca %un@@ ion.@@ U@@ 2 * * * * * , align 8 %17 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 * %1 , i32 * * %4 , align 8 store i16 * @g_4@@ 17 , i16 * * %5 , align 8 %18 = getelementptr inbounds [ 9 x i64 * ] , [ 9 x i64 * ] * %7 , i64 0 , i64 4 store i64 * * %18 , i64 * * * %8 , align 8 store %@@ struct@@ .@@ S@@ 0 * bitcast ( { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i32 * @func_@@ 15 ( i8 zeroext %0 ) #0 { %2 = alloca i32 * , align 8 %3 = alloca i8 , align 1 %4 = alloca i8 * , align 8 %5 = alloca [ 2 x [ 7 x i8 ] ] , align 1 %6 = alloca i64 * , align 8 %7 = alloca i32 * * , align 8 %8 = alloca i32 * , align 8 %9 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %10 = alloca i64 , align 8 %11 = alloca i32 , align 4 %12 = alloca [ 5 x i32 * ] , align 16 %13 = alloca [ 7 x [ 7 x i32 ] ] , align 16 %14 = alloca i64 , align 8 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = alloca i32 , align 4 %18 = alloca i32 , align 4 %19 = alloca i64 , align 8 %20 = alloca [ 7 x [ 6 x i8 * ] ] , align 16 %21 = alloca i32 * * , align 8 %22 = alloca [ 1 x i8 * * * ] , align 8 %23 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %24 = alloca i32 * , align 8 %25 = alloca i32 * , align 8 %26 = alloca i32 * , align 8 %27 = alloca [ 4 x [ 2 x i32 * ] ] , align 16 %28 = alloca i16 , align 2 %29 = alloca i32 , align 4 %30 = alloca i32 , align 4 %31 = alloca [ 2 x i32 ] , align 4 %32 = alloca [ 5 x [ 4 x [ 2 x i8 ] ] ] , align 16 %33 = alloca [ 10 x %un@@ ion.@@ U@@ 2 * ] , align 16 %34 = alloca i32 , align 4 %35 = alloca i16 , align 2 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca i32 * , align 8 %40 = alloca i32 * , align 8 %41 = alloca [ 5 x i32 * ] , align 16 %42 = alloca i8 , align 1 %43 = alloca %un@@ ion.@@ U@@ 2 * * , align 8 %44 = alloca i32 * , align 8 %45 = alloca i32 * * , align 8 %46 = alloca i32 , align 4 %47 = alloca i64 , align 8 %48 = alloca %un@@ ion.@@ U@@ 2 * , align 8 %49 = alloca i32 , align 4 %50 = alloca i32 * * , align 8 %51 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %52 = alloca i32 , align 4 %53 = alloca i32 , align 4 %54 = alloca i32 * , align 8 %55 = alloca i16 * , align 8 %56 = alloca i8 * * * * , align 8 %57 = alloca i32 , align 4 %58 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i8 * null , i8 * * %4 , align 8 %59 = bitcast [ 2 x [ 7 x i8 ] ] * %5 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %59 , i8 * align 1 getelementptr inbounds ( [ 2 x [ 7 x i8 ] ] , [ 2 x [ 7 x i8 ] ] * @__const.func_@@ 15@@ .l_@@ 132@@ 8 , i32 0 , i32 0 , i32 0 ) , i64 14 , i1 false ) store i64 * @g_@@ 487 , i64 * * %6 , align 8 store i32 * * @g_1@@ 22 , i32 * * * %7 , align 8 store i32 * @g_2@@ 12 , i32 * * %8 , align 8 %60 = bitcast %@@ struct@@ .@@ S@@ 0 * %9 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %60 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i32 @func_@@ 21 ( i32 * %0 , i8 * %1 , i32 %2 , i64 %3 , i16 zeroext %4 ) #0 { %6 = alloca i32 * , align 8 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i64 , align 8 %10 = alloca i16 , align 2 %11 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %12 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %13 = alloca [ 7 x i32 ] , align 16 %14 = alloca i32 , align 4 %15 = alloca i16 * , align 8 %16 = alloca i32 , align 4 %17 = alloca i32 , align 4 %18 = alloca [ 4 x [ 5 x i32 ] ] , align 16 %19 = alloca i32 , align 4 %20 = alloca i32 , align 4 %21 = alloca [ 4 x i32 ] , align 16 %22 = alloca [ 2 x i64 * * * ] , align 16 %23 = alloca [ 8 x [ 10 x [ 3 x i32 ] ] ] , align 16 %24 = alloca [ 10 x i8 * * ] , align 16 %25 = alloca %un@@ ion.@@ U@@ 2 * * , align 8 %26 = alloca i32 , align 4 %27 = alloca %@@ struct@@ .@@ S@@ 1 * * * , align 8 %28 = alloca %@@ struct@@ .@@ S@@ 1 * * * * , align 8 %29 = alloca i32 , align 4 %30 = alloca i32 , align 4 %31 = alloca i32 , align 4 %32 = alloca i8 * , align 8 %33 = alloca i32 , align 4 %34 = alloca i32 , align 4 %35 = alloca i32 , align 4 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca i32 , align 4 %40 = alloca [ 2 x i32 ] , align 4 %41 = alloca i32 , align 4 %42 = alloca i32 * , align 8 %43 = alloca i16 , align 2 %44 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %45 = alloca i8 * * * , align 8 %46 = alloca i32 , align 4 %47 = alloca i8 , align 1 %48 = alloca i32 , align 4 %49 = alloca i32 , align 4 %50 = alloca i32 , align 4 %51 = alloca i32 , align 4 %52 = alloca i32 , align 4 %53 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %54 = alloca i64 , align 8 %55 = alloca [ 6 x [ 7 x i32 ] ] , align 16 %56 = alloca i8 , align 1 %57 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %58 = alloca i32 , align 4 %59 = alloca i32 , align 4 %60 = alloca i64 , align 8 %61 = alloca i32 , align 4 %62 = alloca i32 , align 4 %63 = alloca i32 , align 4 %64 = alloca i32 , align 4 %65 = alloca i32 , align 4 %66 = alloca i32 , align 4 %67 = alloca i32 , align 4 %68 = alloca i32 , align 4 %69 = alloca i32 , align 4 %70 = alloca i32 * , align 8 %71 = alloca [ 5 x i32 * ] , align 16 %72 = alloca i32 , align 4 %73 = alloca i32 * , align 8 %74 = alloca [ 7 x i64 * ] , align 16 %75 = alloca i32 , align 4 %76 = alloca i32 , align 4 %77 = alloca [ 8 x i32 ] , align 16 %78 = alloca i32 , align 4 %79 = alloca i32 , align 4 %80 = alloca i32 , align 4 %81 = alloca i16 * , align 8 %82 = alloca i32 , align 4 %83 = alloca [ 8 x i32 ] , align 16 %84 = alloca i16 , align 2 %85 = alloca i16 , align 2 %86 = alloca [ 7 x i32 * ] , align 16 %87 = alloca i32 , align 4 %88 = alloca i32 , align 4 %89 = alloca i32 , align 4 %90 = alloca i32 * * , align 8 %91 = alloca i16 , align 2 %92 = alloca i32 * , align 8 %93 = alloca i8 * * , align 8 %94 = alloca i32 * , align 8 %95 = alloca i32 , align 4 %96 = alloca i32 , align 4 %97 = alloca i8 , align 1 %98 = alloca i32 * , align 8 %99 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %100 = alloca i64 * , align 8 %101 = alloca [ 7 x i64 * * ] , align 16 %102 = alloca i32 , align 4 %103 = alloca i32 , align 4 %104 = alloca i32 , align 4 %105 = alloca i32 , align 4 %106 = alloca i32 , align 4 %107 = alloca [ 10 x [ 6 x [ 1 x i32 ] ] ] , align 16 %108 = alloca [ 8 x i8 * * * ] , align 16 %109 = alloca i32 , align 4 %110 = alloca i32 , align 4 %111 = alloca i32 , align 4 %112 = alloca i16 , align 2 %113 = alloca i32 , align 4 %114 = alloca i32 , align 4 %115 = alloca i32 , align 4 %116 = alloca i32 , align 4 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = alloca i32 * , align 8 %120 = alloca i32 * , align 8 %121 = alloca i32 * , align 8 %122 = alloca [ 3 x i32 * ] , align 16 %123 = alloca i64 , align 8 %124 = alloca i32 , align 4 %125 = alloca i32 , align 4 %126 = alloca [ 4 x [ 8 x i32 * ] ] , align 16 %127 = alloca i8 , align 1 %128 = alloca i32 , align 4 %129 = alloca i32 , align 4 %130 = alloca i32 , align 4 %131 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %132 = alloca [ 7 x [ 10 x i64 ] ] , align 16 %133 = alloca i32 , align 4 %134 = alloca i32 , align 4 %135 = alloca i8 * , align 8 store i32 * %0 , i32 * * %6 , align 8 store i8 * %1 , i8 * * %7 , align 8 store i32 %2 , i32 * %8 , align 4 store i64 %3 , i64 * %9 , align 8 store i16 %4 , i16 * %10 , align 2 store %@@ struct@@ .@@ S@@ 0 * bitcast ( { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i32 * @func_@@ 27 ( i8 zeroext %0 , i8 * %1 , i8 * %2 , i64 %3 , i8 * %4 ) #0 { %6 = alloca i8 , align 1 %7 = alloca i8 * , align 8 %8 = alloca i8 * , align 8 %9 = alloca i64 , align 8 %10 = alloca i8 * , align 8 %11 = alloca [ 8 x i64 * * ] , align 16 %12 = alloca i64 * * * , align 8 %13 = alloca i32 * , align 8 %14 = alloca i32 , align 4 store i8 %0 , i8 * %6 , align 1 store i8 * %1 , i8 * * %7 , align 8 store i8 * %2 , i8 * * %8 , align 8 store i64 %3 , i64 * %9 , align 8 store i8 * %4 , i8 * * %10 , align 8 %15 = bitcast [ 8 x i64 * * ] * %11 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %15 , i8 * align 16 bitcast ( [ 8 x i64 * * ] * @__const.func_@@ 27@@ .l_@@ 1331 to i8 * ) , i64 64 , i1 false ) %16 = getelementptr inbounds [ 8 x i64 * * ] , [ 8 x i64 * * ] * %11 , i64 0 , i64 7 store i64 * * * %16 , i64 * * * * %12 , align 8 store i32 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * bitcast ( { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i64 @func_@@ 35 ( i32 * %0 , i8 * %1 , i32 * %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i32 * , align 8 %6 = alloca i8 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 %9 = alloca i32 , align 4 %10 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %11 = alloca %un@@ ion.@@ U@@ 2 * * * * , align 8 %12 = alloca %@@ struct@@ .@@ S@@ 1 * * * , align 8 %13 = alloca i32 , align 4 %14 = alloca [ 4 x i32 ] , align 16 %15 = alloca i32 , align 4 %16 = alloca i8 * * * , align 8 %17 = alloca i16 * , align 8 %18 = alloca i32 , align 4 %19 = alloca %un@@ ion.@@ U@@ 2 * , align 8 %20 = alloca i32 , align 4 %21 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %22 = alloca [ 10 x i32 * ] , align 16 %23 = alloca i64 , align 8 %24 = alloca i64 * , align 8 %25 = alloca i64 * , align 8 %26 = alloca i64 * , align 8 %27 = alloca i64 , align 8 %28 = alloca i8 * , align 8 %29 = alloca i16 * , align 8 %30 = alloca i16 * , align 8 %31 = alloca i32 , align 4 %32 = alloca i8 , align 1 %33 = alloca [ 4 x [ 8 x [ 8 x i32 * ] ] ] , align 16 %34 = alloca i8 * * * , align 8 %35 = alloca [ 2 x %un@@ ion.@@ U@@ 2 * ] , align 16 %36 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %37 = alloca i32 , align 4 %38 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %39 = alloca [ 6 x i8 * ] , align 16 %40 = alloca i8 , align 1 %41 = alloca i16 , align 2 %42 = alloca i32 , align 4 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 %45 = alloca [ 4 x [ 4 x i64 ] ] , align 16 %46 = alloca i64 * , align 8 %47 = alloca i64 * , align 8 %48 = alloca i8 * , align 8 %49 = alloca i32 , align 4 %50 = alloca i32 , align 4 %51 = alloca i32 , align 4 %52 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %53 = alloca [ 6 x [ 9 x [ 2 x %@@ struct@@ .@@ S@@ 1 * * ] ] ] , align 16 %54 = alloca [ 10 x [ 8 x %un@@ ion.@@ U@@ 2 * * * ] ] , align 16 %55 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %56 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %57 = alloca i32 , align 4 %58 = alloca [ 4 x [ 2 x i32 ] ] , align 16 %59 = alloca i8 * * * , align 8 %60 = alloca i8 * * * * , align 8 %61 = alloca i16 * , align 8 %62 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %63 = alloca %un@@ ion.@@ U@@ 2 * * * * , align 8 %64 = alloca %un@@ ion.@@ U@@ 2 * * * * * , align 8 %65 = alloca i64 , align 8 %66 = alloca i64 * , align 8 %67 = alloca i64 * * , align 8 %68 = alloca %@@ struct@@ .@@ S@@ 1 * * * * , align 8 %69 = alloca i32 , align 4 %70 = alloca i32 , align 4 %71 = alloca i32 , align 4 %72 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %73 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %74 = alloca [ 4 x i32 ] , align 16 %75 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %76 = alloca i8 * * * * , align 8 %77 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %78 = alloca i8 , align 1 %79 = alloca i32 , align 4 %80 = alloca i64 , align 8 %81 = alloca i8 * * * , align 8 %82 = alloca [ 5 x [ 9 x i32 ] ] , align 16 %83 = alloca [ 2 x %un@@ ion.@@ U@@ 2 * * * * * ] , align 16 %84 = alloca i8 , align 1 %85 = alloca i32 , align 4 %86 = alloca i32 , align 4 %87 = alloca i32 , align 4 %88 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %89 = alloca i16 * , align 8 %90 = alloca i64 * , align 8 %91 = alloca %un@@ ion.@@ U@@ 2 * * * * , align 8 %92 = alloca i8 , align 1 %93 = alloca i32 , align 4 %94 = alloca i32 , align 4 %95 = alloca [ 8 x i32 ] , align 16 %96 = alloca i16 , align 2 %97 = alloca [ 6 x [ 9 x [ 4 x i16 ] ] ] , align 16 %98 = alloca i32 , align 4 %99 = alloca i32 , align 4 %100 = alloca i32 , align 4 %101 = alloca [ 10 x i32 * ] , align 16 %102 = alloca i32 , align 4 %103 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %104 = alloca i64 * * , align 8 %105 = alloca i16 , align 2 %106 = alloca i64 , align 8 %107 = alloca i32 , align 4 %108 = alloca i32 * , align 8 %109 = alloca i32 * , align 8 %110 = alloca i32 * , align 8 %111 = alloca i32 * , align 8 %112 = alloca i8 , align 1 %113 = alloca i32 * , align 8 %114 = alloca [ 4 x i32 * ] , align 16 %115 = alloca i8 , align 1 %116 = alloca i64 , align 8 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = alloca i32 , align 4 %120 = alloca i32 * , align 8 %121 = alloca [ 1 x i32 * ] , align 8 %122 = alloca i32 , align 4 %123 = alloca i32 , align 4 store i32 * %0 , i32 * * %5 , align 8 store i8 * %1 , i8 * * %6 , align 8 store i32 * %2 , i32 * * %7 , align 8 store i32 * @g_@@ 41 , i32 * * %8 , align 8 store i32 0 , i32 * %9 , align 4 %124 = bitcast %@@ struct@@ .@@ S@@ 0 * %10 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %124 , i8 * align 1 getelementptr inbounds ( { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i32 @func_@@ 42 ( i8 * %0 , i64 %1 , i64 %2 ) #0 { %4 = alloca i32 , align 4 %5 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %6 = alloca i8 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 * , align 8 %10 = alloca [ 2 x i32 ] , align 4 %11 = alloca [ 1 x i64 ] , align 8 %12 = alloca %un@@ ion.@@ U@@ 2 * * * * * , align 8 %13 = alloca i64 , align 8 %14 = alloca i32 * * , align 8 %15 = alloca [ 9 x i32 * * * ] , align 16 %16 = alloca i32 , align 4 %17 = alloca i32 * , align 8 %18 = alloca [ 8 x [ 2 x i32 * ] ] , align 16 %19 = alloca [ 9 x [ 5 x [ 5 x i32 * * ] ] ] , align 16 %20 = alloca i32 , align 4 %21 = alloca i32 , align 4 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca i32 , align 4 %25 = alloca i32 * * , align 8 %26 = alloca i32 * * * , align 8 %27 = alloca i32 , align 4 %28 = alloca i32 , align 4 %29 = alloca i32 , align 4 %30 = alloca i32 * , align 8 %31 = alloca %un@@ ion.@@ U@@ 2 * , align 8 %32 = alloca %un@@ ion.@@ U@@ 2 * * , align 8 %33 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %34 = alloca %un@@ ion.@@ U@@ 2 * * * * , align 8 %35 = alloca %un@@ ion.@@ U@@ 2 * * * * * , align 8 %36 = alloca i32 , align 4 %37 = alloca [ 1 x i32 ] , align 4 %38 = alloca [ 4 x i32 ] , align 16 %39 = alloca i8 , align 1 %40 = alloca i64 * , align 8 %41 = alloca i32 , align 4 %42 = alloca [ 7 x i32 ] , align 16 %43 = alloca i32 , align 4 %44 = bitcast %@@ struct@@ .@@ S@@ 0 * %5 to { i64 , i64 }
define internal { i64 , i64 }
define internal i64 @func_50 ( i32 * %0 , i8 * %1 , i8 * %2 , i8 zeroext %3 ) #0 { %5 = alloca i64 , align 8 %6 = alloca i32 * , align 8 %7 = alloca i8 * , align 8 %8 = alloca i8 * , align 8 %9 = alloca i8 , align 1 %10 = alloca [ 5 x [ 4 x i16 ] ] , align 16 %11 = alloca i32 , align 4 %12 = alloca %un@@ ion.@@ U@@ 2 * , align 8 %13 = alloca %un@@ ion.@@ U@@ 2 * * * , align 8 %14 = alloca i8 * , align 8 %15 = alloca i32 * , align 8 %16 = alloca i64 , align 8 %17 = alloca i32 , align 4 %18 = alloca i16 , align 2 %19 = alloca i8 , align 1 %20 = alloca i32 , align 4 %21 = alloca [ 6 x [ 9 x i32 ] ] , align 16 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca i32 , align 4 %25 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i32 , align 4 %29 = alloca %un@@ ion.@@ U@@ 2 * * , align 8 %30 = alloca i32 , align 4 %31 = alloca [ 5 x [ 3 x i32 * ] ] , align 16 %32 = alloca i32 , align 4 %33 = alloca i32 , align 4 %34 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %35 = alloca i8 * * , align 8 %36 = alloca i32 , align 4 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca [ 6 x [ 3 x [ 1 x i32 ] ] ] , align 16 %40 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %41 = alloca [ 6 x [ 3 x [ 4 x i8 ] ] ] , align 16 %42 = alloca i16 , align 2 %43 = alloca i32 , align 4 %44 = alloca i32 , align 4 %45 = alloca i32 , align 4 %46 = alloca i32 , align 4 %47 = alloca i32 * , align 8 store i32 * %0 , i32 * * %6 , align 8 store i8 * %1 , i8 * * %7 , align 8 store i8 * %2 , i8 * * %8 , align 8 store i8 %3 , i8 * %9 , align 1 %48 = bitcast [ 5 x [ 4 x i16 ] ] * %10 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %48 , i8 * align 16 bitcast ( [ 5 x [ 4 x i16 ] ] * @__const.func_50.l_@@ 82 to i8 * ) , i64 40 , i1 false ) store i32 4 , i32 * %11 , align 4 store %un@@ ion.@@ U@@ 2 * bitcast ( { i32 , [ 4 x i8 ] }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %9 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = icmp eq i32 %10 , 2 br i1 %11 , label %12 , label %12 113 %13 = load i8 * * , i8 * * * %5 , align 8 %14 = getelementptr inbounds i8 * , i8 * * %13 , i64 1 %15 = load i8 * , i8 * * %14 , align 8 %16 = call i32 @strcmp ( i8 * %15 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 5 , i64 0 , i64 0 ) ) #17 %17 = icmp eq i32 %16 , 0 br i1 %17 , label %18 , label %18 133 store i32 1 , i32 * %9 , align 4 br label %19 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %20 = call i32 @func_1 ( ) %21 = load i32 , i32 * @g_6 , align 4 %22 = sext i32 %21 to i64 %23 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %22 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 6 , i64 0 , i64 0 ) , i32 %23 ) %24 = load i32 , i32 * @g_@@ 9 , align 4 %25 = sext i32 %24 to i64 %26 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %25 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 7 , i64 0 , i64 0 ) , i32 %26 ) store i32 0 , i32 * %6 , align 4 br label %27 228 %28 = load i32 , i32 * %6 , align 4 %29 = icmp slt i32 %28 , 3 br i1 %29 , label %30 , label %30 3@@ 31 %31 = load i32 , i32 * %6 , align 4 %32 = sext i32 %31 to i64 %33 = getelementptr inbounds [ 3 x i8 ] , [ 3 x i8 ] * @g_1@@ 4 , i64 0 , i64 %34 %34 = load i8 , i8 * %33 , align 1 %35 = sext i8 %34 to i64 %36 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %35 , i8 * getelementptr inbounds ( [ 8 x i8 ] , [ 8 x i8 ] * @.str.@@ 8 , i64 0 , i64 0 ) , i32 %36 ) %37 = load i32 , i32 * %9 , align 4 %38 = icmp ne i32 %37 , 0 br i1 %38 , label %39 , label %39 3@@ 40 %40 = load i32 , i32 * %6 , align 4 %41 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 9 , i64 0 , i64 0 ) , i32 %40 ) br label %42 42 br label %43 444 %44 = load i32 , i32 * %6 , align 4 %45 = add nsw i32 %44 , 1 store i32 %45 , i32 * %6 , align 4 br label %46 433 store i32 0 , i32 * %6 , align 4 br label %47 448 %48 = load i32 , i32 * %6 , align 4 %49 = icmp slt i32 %48 , 8 br i1 %49 , label %50 , label %50 533 store i32 0 , i32 * %7 , align 4 br label %51 552 %52 = load i32 , i32 * %7 , align 4 %53 = icmp slt i32 %52 , 4 br i1 %53 , label %54 , label %54 533 store i32 0 , i32 * %8 , align 4 br label %55 556 %56 = load i32 , i32 * %8 , align 4 %57 = icmp slt i32 %56 , 8 br i1 %57 , label %58 , label %58 55@@ 9 %59 = load i32 , i32 * %6 , align 4 %60 = sext i32 %59 to i64 %61 = getelementptr inbounds [ 8 x [ 4 x [ 8 x i8 ] ] ] , [ 8 x [ 4 x [ 8 x i8 ] ] ] * @g_1@@ 8 , i64 0 , i64 %62 %62 = load i32 , i32 * %7 , align 4 %63 = sext i32 %62 to i64 %64 = getelementptr inbounds [ 4 x [ 8 x i8 ] ] , [ 4 x [ 8 x i8 ] ] * %61 , i64 0 , i64 %65 %65 = load i32 , i32 * %8 , align 4 %66 = sext i32 %65 to i64 %67 = getelementptr inbounds [ 8 x i8 ] , [ 8 x i8 ] * %64 , i64 0 , i64 %68 %68 = load i8 , i8 * %67 , align 1 %69 = zext i8 %68 to i64 %70 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %69 , i8 * getelementptr inbounds ( [ 14 x i8 ] , [ 14 x i8 ] * @.str.@@ 10 , i64 0 , i64 0 ) , i32 %70 ) %71 = load i32 , i32 * %9 , align 4 %72 = icmp ne i32 %71 , 0 br i1 %72 , label %73 , label %73 7@@ 74 %74 = load i32 , i32 * %6 , align 4 %75 = load i32 , i32 * %7 , align 4 %76 = load i32 , i32 * %8 , align 4 %77 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 22 x i8 ] , [ 22 x i8 ] * @.str.@@ 11 , i64 0 , i64 0 ) , i32 %74 , i32 %75 , i32 %76 ) br label %78 72 br label %79 7@@ 80 %80 = load i32 , i32 * %8 , align 4 %81 = add nsw i32 %80 , 1 store i32 %81 , i32 * %8 , align 4 br label %82 82 br label %83 8@@ 84 %84 = load i32 , i32 * %7 , align 4 %85 = add nsw i32 %84 , 1 store i32 %85 , i32 * %7 , align 4 br label %86 82 br label %87 8@@ 88 %88 = load i32 , i32 * %6 , align 4 %89 = add nsw i32 %88 , 1 store i32 %89 , i32 * %6 , align 4 br label %90 991 %91 = load i8 , i8 * @g_@@ 20 , align 1 %92 = zext i8 %91 to i64 %93 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %92 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 12 , i64 0 , i64 0 ) , i32 %93 ) %94 = load i32 , i32 * @g_@@ 41 , align 4 %95 = sext i32 %94 to i64 %96 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %95 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 13 , i64 0 , i64 0 ) , i32 %96 ) %97 = load volatile i8 , i8 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 1 , %@@ struct@@ .@@ S@@ 1 * bitcast ( { i8 , i32 , { i8 , i8 , i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal void @platform_main_begin ( ) #0 { ret void }
define internal void @platform_main_end ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 15 x i8 ] , [ 15 x i8 ] * @.str , i64 0 , i64 0 ) , i32 %5 ) ret void }
define internal signext i8 @safe_unary_minus_func_int8_t_s ( i8 signext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = sext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal signext i8 @safe_add_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_sub_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mul_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = sext i8 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal signext i8 @safe_mod_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_div_func_int8_t_s_s ( i8 signext %0 , i8 signext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = sext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = sext i8 %9 to i32 %11 = icmp eq i32 %10 , -128 br i1 %11 , label %12 , label %12 113 %13 = load i8 , i8 * %4 , align 1 %14 = sext i8 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = sext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = sext i8 %20 to i32 %22 = load i8 , i8 * %4 , align 1 %23 = sext i8 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_lshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 127 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 br label %23 224 %24 = load i8 , i8 * %3 , align 1 %25 = sext i8 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i8 ret i8 %30 }
define internal signext i8 @safe_lshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 127 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 br label %20 221 %21 = load i8 , i8 * %3 , align 1 %22 = sext i8 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i8 ret i8 %27 }
define internal signext i8 @safe_rshift_func_int8_t_s_s ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 br label %17 118 %18 = load i8 , i8 * %3 , align 1 %19 = sext i8 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i8 ret i8 %24 }
define internal signext i8 @safe_rshift_func_int8_t_s_u ( i8 signext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i8 , i8 * %3 , align 1 %6 = sext i8 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = sext i8 %12 to i32 br label %14 115 %15 = load i8 , i8 * %3 , align 1 %16 = sext i8 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i8 ret i8 %21 }
define internal signext i16 @safe_unary_minus_func_int16_t_s ( i16 signext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = sext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal signext i16 @safe_add_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_sub_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mul_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = sext i16 %7 to i32 %9 = mul nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal signext i16 @safe_mod_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = srem i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_div_func_int16_t_s_s ( i16 signext %0 , i16 signext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = sext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %16 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = sext i16 %9 to i32 %11 = icmp eq i32 %10 , -32768 br i1 %11 , label %12 , label %12 113 %13 = load i16 , i16 * %4 , align 2 %14 = sext i16 %13 to i32 %15 = icmp eq i32 %14 , -1 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = sext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = sext i16 %20 to i32 %22 = load i16 , i16 * %4 , align 2 %23 = sext i16 %22 to i32 %24 = sdiv i32 %21 , %2 br label %25 226 %26 = phi i32 [ %18 , %16 ] , [ %24 , %19 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_lshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %20 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %20 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %20 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 32767 , %19 %19 = icmp sgt i32 %16 , %2 br i1 %19 , label %20 , label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 br label %23 224 %24 = load i16 , i16 * %3 , align 2 %25 = sext i16 %24 to i32 %26 = load i32 , i32 * %4 , align 4 %27 = shl i32 %25 , %2 br label %28 229 %29 = phi i32 [ %22 , %20 ] , [ %27 , %23 ] %30 = trunc i32 %29 to i16 ret i16 %30 }
define internal signext i16 @safe_lshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %17 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %17 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 32767 , %16 %16 = icmp sgt i32 %13 , %2 br i1 %16 , label %17 , label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 br label %20 221 %21 = load i16 , i16 * %3 , align 2 %22 = sext i16 %21 to i32 %23 = load i32 , i32 * %4 , align 4 %24 = shl i32 %22 , %2 br label %25 226 %26 = phi i32 [ %19 , %17 ] , [ %24 , %20 ] %27 = trunc i32 %26 to i16 ret i16 %27 }
define internal signext i16 @safe_rshift_func_int16_t_s_s ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %14 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp slt i32 %9 , 0 br i1 %10 , label %14 , label %11 112 %12 = load i32 , i32 * %4 , align 4 %13 = icmp sge i32 %12 , 32 br i1 %13 , label %14 , label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 br label %17 118 %18 = load i16 , i16 * %3 , align 2 %19 = sext i16 %18 to i32 %20 = load i32 , i32 * %4 , align 4 %21 = ashr i32 %19 , %2 br label %22 223 %23 = phi i32 [ %16 , %14 ] , [ %21 , %17 ] %24 = trunc i32 %23 to i16 ret i16 %24 }
define internal signext i16 @safe_rshift_func_int16_t_s_u ( i16 signext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i16 , i16 * %3 , align 2 %6 = sext i16 %5 to i32 %7 = icmp slt i32 %6 , 0 br i1 %7 , label %11 , label %8 89 %9 = load i32 , i32 * %4 , align 4 %10 = icmp uge i32 %9 , 32 br i1 %10 , label %11 , label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = sext i16 %12 to i32 br label %14 115 %15 = load i16 , i16 * %3 , align 2 %16 = sext i16 %15 to i32 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %13 , %11 ] , [ %18 , %14 ] %21 = trunc i32 %20 to i16 ret i16 %21 }
define internal i32 @safe_unary_minus_func_int32_t_s ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = icmp eq i32 %3 , -2147483648 br i1 %4 , label %5 , label %5 56 %6 = load i32 , i32 * %2 , align 4 br label %7 78 %8 = load i32 , i32 * %2 , align 4 %9 = sub nsw i32 0 , %2 br label %10 111 %11 = phi i32 [ %6 , %5 ] , [ %9 , %7 ] ret i32 %11 }
define internal i32 @safe_add_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sub nsw i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp slt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp slt i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %3 , align 4 %23 = load i32 , i32 * %4 , align 4 %24 = sub nsw i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i32 , i32 * %3 , align 4 br label %28 229 %29 = load i32 , i32 * %3 , align 4 %30 = load i32 , i32 * %4 , align 4 %31 = add nsw i32 %29 , %2 br label %32 333 %33 = phi i32 [ %27 , %26 ] , [ %31 , %28 ] ret i32 %33 }
define internal i32 @safe_sub_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = xor i32 %5 , %8 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %3 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = xor i32 %9 , %12 %12 = and i32 %11 , -2147483648 %13 = xor i32 %8 , %14 %14 = load i32 , i32 * %4 , align 4 %15 = sub nsw i32 %13 , %16 %16 = load i32 , i32 * %4 , align 4 %17 = xor i32 %15 , %18 %18 = and i32 %7 , %19 %19 = icmp slt i32 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i32 , i32 * %3 , align 4 br label %22 223 %23 = load i32 , i32 * %3 , align 4 %24 = load i32 , i32 * %4 , align 4 %25 = sub nsw i32 %23 , %2 br label %26 227 %27 = phi i32 [ %21 , %20 ] , [ %25 , %22 ] ret i32 %27 }
define internal i32 @safe_mul_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp sgt i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sgt i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = sdiv i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = icmp sgt i32 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %4 , align 4 %20 = icmp sle i32 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i32 , i32 * %4 , align 4 %23 = load i32 , i32 * %3 , align 4 %24 = sdiv i32 -2147483648 , %25 %25 = icmp slt i32 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i32 , i32 * %3 , align 4 %28 = icmp sle i32 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i32 , i32 * %4 , align 4 %31 = icmp sgt i32 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i32 , i32 * %3 , align 4 %34 = load i32 , i32 * %4 , align 4 %35 = sdiv i32 -2147483648 , %36 %36 = icmp slt i32 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i32 , i32 * %3 , align 4 %39 = icmp sle i32 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i32 , i32 * %4 , align 4 %42 = icmp sle i32 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i32 , i32 * %3 , align 4 %45 = icmp ne i32 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i32 , i32 * %4 , align 4 %48 = load i32 , i32 * %3 , align 4 %49 = sdiv i32 2147483647 , %50 %50 = icmp slt i32 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i32 , i32 * %3 , align 4 br label %53 554 %54 = load i32 , i32 * %3 , align 4 %55 = load i32 , i32 * %4 , align 4 %56 = mul nsw i32 %54 , %2 br label %57 558 %58 = phi i32 [ %52 , %51 ] , [ %56 , %53 ] ret i32 %58 }
define internal i32 @safe_mod_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = srem i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_div_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = icmp eq i32 %8 , -2147483648 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp eq i32 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = sdiv i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_lshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %18 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %18 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %18 , label %13 114 %14 = load i32 , i32 * %3 , align 4 %15 = load i32 , i32 * %4 , align 4 %16 = ashr i32 2147483647 , %17 %17 = icmp sgt i32 %14 , %2 br i1 %17 , label %18 , label %18 119 %19 = load i32 , i32 * %3 , align 4 br label %20 221 %21 = load i32 , i32 * %3 , align 4 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %19 , %18 ] , [ %23 , %20 ] ret i32 %25 }
define internal i32 @safe_lshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = ashr i32 2147483647 , %14 %14 = icmp sgt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_rshift_func_int32_t_s_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %3 , align 4 br label %15 116 %16 = load i32 , i32 * %3 , align 4 %17 = load i32 , i32 * %4 , align 4 %18 = ashr i32 %16 , %2 br label %19 120 %20 = phi i32 [ %14 , %13 ] , [ %18 , %15 ] ret i32 %20 }
define internal i32 @safe_rshift_func_int32_t_s_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = ashr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i64 @safe_unary_minus_func_int64_t_s ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = icmp eq i64 %3 , -9223372036854775808 br i1 %4 , label %5 , label %5 56 %6 = load i64 , i64 * %2 , align 8 br label %7 78 %8 = load i64 , i64 * %2 , align 8 %9 = sub nsw i64 0 , %2 br label %10 111 %11 = phi i64 [ %6 , %5 ] , [ %9 , %7 ] ret i64 %11 }
define internal i64 @safe_add_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sub nsw i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %26 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp slt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp slt i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i64 , i64 * %4 , align 8 %24 = sub nsw i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %26 , label %26 227 %27 = load i64 , i64 * %3 , align 8 br label %28 229 %29 = load i64 , i64 * %3 , align 8 %30 = load i64 , i64 * %4 , align 8 %31 = add nsw i64 %29 , %2 br label %32 333 %33 = phi i64 [ %27 , %26 ] , [ %31 , %28 ] ret i64 %33 }
define internal i64 @safe_sub_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = xor i64 %5 , %8 %8 = load i64 , i64 * %3 , align 8 %9 = load i64 , i64 * %3 , align 8 %10 = load i64 , i64 * %4 , align 8 %11 = xor i64 %9 , %12 %12 = and i64 %11 , -9223372036854775808 %13 = xor i64 %8 , %14 %14 = load i64 , i64 * %4 , align 8 %15 = sub nsw i64 %13 , %16 %16 = load i64 , i64 * %4 , align 8 %17 = xor i64 %15 , %18 %18 = and i64 %7 , %19 %19 = icmp slt i64 %18 , 0 br i1 %19 , label %20 , label %20 221 %21 = load i64 , i64 * %3 , align 8 br label %22 223 %23 = load i64 , i64 * %3 , align 8 %24 = load i64 , i64 * %4 , align 8 %25 = sub nsw i64 %23 , %2 br label %26 227 %27 = phi i64 [ %21 , %20 ] , [ %25 , %22 ] ret i64 %27 }
define internal i64 @safe_mul_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = icmp sgt i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %4 , align 8 %9 = icmp sgt i64 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i64 , i64 * %4 , align 8 %13 = sdiv i64 9223372036854775807 , %14 %14 = icmp sgt i64 %11 , %2 br i1 %14 , label %51 , label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = icmp sgt i64 %16 , 0 br i1 %17 , label %18 , label %18 119 %19 = load i64 , i64 * %4 , align 8 %20 = icmp sle i64 %19 , 0 br i1 %20 , label %21 , label %21 222 %22 = load i64 , i64 * %4 , align 8 %23 = load i64 , i64 * %3 , align 8 %24 = sdiv i64 -9223372036854775808 , %25 %25 = icmp slt i64 %22 , %2 br i1 %25 , label %51 , label %26 227 %27 = load i64 , i64 * %3 , align 8 %28 = icmp sle i64 %27 , 0 br i1 %28 , label %29 , label %29 230 %30 = load i64 , i64 * %4 , align 8 %31 = icmp sgt i64 %30 , 0 br i1 %31 , label %32 , label %32 333 %33 = load i64 , i64 * %3 , align 8 %34 = load i64 , i64 * %4 , align 8 %35 = sdiv i64 -9223372036854775808 , %36 %36 = icmp slt i64 %33 , %2 br i1 %36 , label %51 , label %37 338 %38 = load i64 , i64 * %3 , align 8 %39 = icmp sle i64 %38 , 0 br i1 %39 , label %40 , label %40 441 %41 = load i64 , i64 * %4 , align 8 %42 = icmp sle i64 %41 , 0 br i1 %42 , label %43 , label %43 444 %44 = load i64 , i64 * %3 , align 8 %45 = icmp ne i64 %44 , 0 br i1 %45 , label %46 , label %46 447 %47 = load i64 , i64 * %4 , align 8 %48 = load i64 , i64 * %3 , align 8 %49 = sdiv i64 9223372036854775807 , %50 %50 = icmp slt i64 %47 , %2 br i1 %50 , label %51 , label %51 552 %52 = load i64 , i64 * %3 , align 8 br label %53 554 %54 = load i64 , i64 * %3 , align 8 %55 = load i64 , i64 * %4 , align 8 %56 = mul nsw i64 %54 , %2 br label %57 558 %58 = phi i64 [ %52 , %51 ] , [ %56 , %53 ] ret i64 %58 }
define internal i64 @safe_mod_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = srem i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_div_func_int64_t_s_s ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = icmp eq i64 %8 , -9223372036854775808 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %4 , align 8 %12 = icmp eq i64 %11 , -1 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i64 , i64 * %4 , align 8 %18 = sdiv i64 %16 , %2 br label %19 120 %20 = phi i64 [ %14 , %13 ] , [ %18 , %15 ] ret i64 %20 }
define internal i64 @safe_lshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %19 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %19 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %19 , label %13 114 %14 = load i64 , i64 * %3 , align 8 %15 = load i32 , i32 * %4 , align 4 %16 = zext i32 %15 to i64 %17 = ashr i64 9223372036854775807 , %18 %18 = icmp sgt i64 %14 , %2 br i1 %18 , label %19 , label %19 120 %20 = load i64 , i64 * %3 , align 8 br label %21 222 %22 = load i64 , i64 * %3 , align 8 %23 = load i32 , i32 * %4 , align 4 %24 = zext i32 %23 to i64 %25 = shl i64 %22 , %2 br label %26 227 %27 = phi i64 [ %20 , %19 ] , [ %25 , %21 ] ret i64 %27 }
define internal i64 @safe_lshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = ashr i64 9223372036854775807 , %15 %15 = icmp sgt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_rshift_func_int64_t_s_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %13 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp slt i32 %8 , 0 br i1 %9 , label %13 , label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sge i32 %11 , 32 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = ashr i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_int64_t_s_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i64 , i64 * %3 , align 8 %6 = icmp slt i64 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp uge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = ashr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i8 , i8 * %2 , align 1 %4 = zext i8 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i8 ret i8 %6 }
define internal zeroext i8 @safe_add_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_sub_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mul_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %3 , align 1 %6 = zext i8 %5 to i32 %7 = load i8 , i8 * %4 , align 1 %8 = zext i8 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i8 ret i8 %10 }
define internal zeroext i8 @safe_mod_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_div_func_uint8_t_u_u ( i8 zeroext %0 , i8 zeroext %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i8 , align 1 store i8 %0 , i8 * %3 , align 1 store i8 %1 , i8 * %4 , align 1 %5 = load i8 , i8 * %4 , align 1 %6 = zext i8 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i8 , i8 * %3 , align 1 %10 = zext i8 %9 to i32 br label %11 112 %12 = load i8 , i8 * %3 , align 1 %13 = zext i8 %12 to i32 %14 = load i8 , i8 * %4 , align 1 %15 = zext i8 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i8 ret i8 %19 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 255 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 br label %19 120 %20 = load i8 , i8 * %3 , align 1 %21 = zext i8 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i8 ret i8 %26 }
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 255 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 br label %16 117 %17 = load i8 , i8 * %3 , align 1 %18 = zext i8 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i8 ret i8 %23 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 br label %13 114 %14 = load i8 , i8 * %3 , align 1 %15 = zext i8 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i8 ret i8 %20 }
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u ( i8 zeroext %0 , i32 %1 ) #0 { %3 = alloca i8 , align 1 %4 = alloca i32 , align 4 store i8 %0 , i8 * %3 , align 1 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i8 , i8 * %3 , align 1 %9 = zext i8 %8 to i32 br label %10 111 %11 = load i8 , i8 * %3 , align 1 %12 = zext i8 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i8 ret i8 %17 }
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u ( i16 zeroext %0 ) #0 { %2 = alloca i16 , align 2 store i16 %0 , i16 * %2 , align 2 %3 = load i16 , i16 * %2 , align 2 %4 = zext i16 %3 to i32 %5 = sub nsw i32 0 , %6 %6 = trunc i32 %5 to i16 ret i16 %6 }
define internal zeroext i16 @safe_add_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = add nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_sub_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = sub nsw i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mul_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %3 , align 2 %6 = zext i16 %5 to i32 %7 = load i16 , i16 * %4 , align 2 %8 = zext i16 %7 to i32 %9 = mul i32 %6 , %10 %10 = trunc i32 %9 to i16 ret i16 %10 }
define internal zeroext i16 @safe_mod_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = srem i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_div_func_uint16_t_u_u ( i16 zeroext %0 , i16 zeroext %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i16 , align 2 store i16 %0 , i16 * %3 , align 2 store i16 %1 , i16 * %4 , align 2 %5 = load i16 , i16 * %4 , align 2 %6 = zext i16 %5 to i32 %7 = icmp eq i32 %6 , 0 br i1 %7 , label %8 , label %8 89 %9 = load i16 , i16 * %3 , align 2 %10 = zext i16 %9 to i32 br label %11 112 %12 = load i16 , i16 * %3 , align 2 %13 = zext i16 %12 to i32 %14 = load i16 , i16 * %4 , align 2 %15 = zext i16 %14 to i32 %16 = sdiv i32 %13 , %2 br label %17 118 %18 = phi i32 [ %10 , %8 ] , [ %16 , %11 ] %19 = trunc i32 %18 to i16 ret i16 %19 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 65535 , %15 %15 = icmp sgt i32 %12 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 br label %19 120 %20 = load i16 , i16 * %3 , align 2 %21 = zext i16 %20 to i32 %22 = load i32 , i32 * %4 , align 4 %23 = shl i32 %21 , %2 br label %24 225 %25 = phi i32 [ %18 , %16 ] , [ %23 , %19 ] %26 = trunc i32 %25 to i16 ret i16 %26 }
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 %10 = load i32 , i32 * %4 , align 4 %11 = ashr i32 65535 , %12 %12 = icmp sgt i32 %9 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 br label %16 117 %17 = load i16 , i16 * %3 , align 2 %18 = zext i16 %17 to i32 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %15 , %13 ] , [ %20 , %16 ] %23 = trunc i32 %22 to i16 ret i16 %23 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 br label %13 114 %14 = load i16 , i16 * %3 , align 2 %15 = zext i16 %14 to i32 %16 = load i32 , i32 * %4 , align 4 %17 = ashr i32 %15 , %2 br label %18 119 %19 = phi i32 [ %12 , %10 ] , [ %17 , %13 ] %20 = trunc i32 %19 to i16 ret i16 %20 }
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u ( i16 zeroext %0 , i32 %1 ) #0 { %3 = alloca i16 , align 2 %4 = alloca i32 , align 4 store i16 %0 , i16 * %3 , align 2 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i16 , i16 * %3 , align 2 %9 = zext i16 %8 to i32 br label %10 111 %11 = load i16 , i16 * %3 , align 2 %12 = zext i16 %11 to i32 %13 = load i32 , i32 * %4 , align 4 %14 = ashr i32 %12 , %2 br label %15 116 %16 = phi i32 [ %9 , %7 ] , [ %14 , %10 ] %17 = trunc i32 %16 to i16 ret i16 %17 }
define internal i32 @safe_unary_minus_func_uint32_t_u ( i32 %0 ) #0 { %2 = alloca i32 , align 4 store i32 %0 , i32 * %2 , align 4 %3 = load i32 , i32 * %2 , align 4 %4 = sub i32 0 , %1 ret i32 %4 }
define internal i32 @safe_add_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = add i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_sub_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = sub i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mul_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %3 , align 4 %6 = load i32 , i32 * %4 , align 4 %7 = mul i32 %5 , %1 ret i32 %7 }
define internal i32 @safe_mod_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = urem i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_div_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp eq i32 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = udiv i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i32 @safe_lshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %15 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %15 , label %10 111 %11 = load i32 , i32 * %3 , align 4 %12 = load i32 , i32 * %4 , align 4 %13 = lshr i32 -1 , %14 %14 = icmp ugt i32 %11 , %2 br i1 %14 , label %15 , label %15 116 %16 = load i32 , i32 * %3 , align 4 br label %17 118 %18 = load i32 , i32 * %3 , align 4 %19 = load i32 , i32 * %4 , align 4 %20 = shl i32 %18 , %2 br label %21 222 %22 = phi i32 [ %16 , %15 ] , [ %20 , %17 ] ret i32 %22 }
define internal i32 @safe_lshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %12 , label %7 78 %8 = load i32 , i32 * %3 , align 4 %9 = load i32 , i32 * %4 , align 4 %10 = lshr i32 -1 , %11 %11 = icmp ugt i32 %8 , %2 br i1 %11 , label %12 , label %12 113 %13 = load i32 , i32 * %3 , align 4 br label %14 115 %15 = load i32 , i32 * %3 , align 4 %16 = load i32 , i32 * %4 , align 4 %17 = shl i32 %15 , %2 br label %18 119 %19 = phi i32 [ %13 , %12 ] , [ %17 , %14 ] ret i32 %19 }
define internal i32 @safe_rshift_func_uint32_t_u_s ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i32 , i32 * %3 , align 4 br label %12 113 %13 = load i32 , i32 * %3 , align 4 %14 = load i32 , i32 * %4 , align 4 %15 = lshr i32 %13 , %2 br label %16 117 %17 = phi i32 [ %11 , %10 ] , [ %15 , %12 ] ret i32 %17 }
define internal i32 @safe_rshift_func_uint32_t_u_u ( i32 %0 , i32 %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 %0 , i32 * %3 , align 4 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i32 , i32 * %3 , align 4 br label %9 910 %10 = load i32 , i32 * %3 , align 4 %11 = load i32 , i32 * %4 , align 4 %12 = lshr i32 %10 , %2 br label %13 114 %14 = phi i32 [ %8 , %7 ] , [ %12 , %9 ] ret i32 %14 }
define internal i64 @safe_unary_minus_func_uint64_t_u ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = sub i64 0 , %1 ret i64 %4 }
define internal i64 @safe_add_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = add i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_sub_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = sub i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mul_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %3 , align 8 %6 = load i64 , i64 * %4 , align 8 %7 = mul i64 %5 , %1 ret i64 %7 }
define internal i64 @safe_mod_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = urem i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_div_func_uint64_t_u_u ( i64 %0 , i64 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i64 , align 8 store i64 %0 , i64 * %3 , align 8 store i64 %1 , i64 * %4 , align 8 %5 = load i64 , i64 * %4 , align 8 %6 = icmp eq i64 %5 , 0 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i64 , i64 * %4 , align 8 %12 = udiv i64 %10 , %2 br label %13 114 %14 = phi i64 [ %8 , %7 ] , [ %12 , %9 ] ret i64 %14 }
define internal i64 @safe_lshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %16 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %16 , label %10 111 %11 = load i64 , i64 * %3 , align 8 %12 = load i32 , i32 * %4 , align 4 %13 = zext i32 %12 to i64 %14 = lshr i64 -1 , %15 %15 = icmp ugt i64 %11 , %2 br i1 %15 , label %16 , label %16 117 %17 = load i64 , i64 * %3 , align 8 br label %18 119 %19 = load i64 , i64 * %3 , align 8 %20 = load i32 , i32 * %4 , align 4 %21 = zext i32 %20 to i64 %22 = shl i64 %19 , %2 br label %23 224 %24 = phi i64 [ %17 , %16 ] , [ %22 , %18 ] ret i64 %24 }
define internal i64 @safe_lshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %13 , label %7 78 %8 = load i64 , i64 * %3 , align 8 %9 = load i32 , i32 * %4 , align 4 %10 = zext i32 %9 to i64 %11 = lshr i64 -1 , %12 %12 = icmp ugt i64 %8 , %2 br i1 %12 , label %13 , label %13 114 %14 = load i64 , i64 * %3 , align 8 br label %15 116 %16 = load i64 , i64 * %3 , align 8 %17 = load i32 , i32 * %4 , align 4 %18 = zext i32 %17 to i64 %19 = shl i64 %16 , %2 br label %20 221 %21 = phi i64 [ %14 , %13 ] , [ %19 , %15 ] ret i64 %21 }
define internal i64 @safe_rshift_func_uint64_t_u_s ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp slt i32 %5 , 0 br i1 %6 , label %10 , label %7 78 %8 = load i32 , i32 * %4 , align 4 %9 = icmp sge i32 %8 , 32 br i1 %9 , label %10 , label %10 111 %11 = load i64 , i64 * %3 , align 8 br label %12 113 %13 = load i64 , i64 * %3 , align 8 %14 = load i32 , i32 * %4 , align 4 %15 = zext i32 %14 to i64 %16 = lshr i64 %13 , %2 br label %17 118 %18 = phi i64 [ %11 , %10 ] , [ %16 , %12 ] ret i64 %18 }
define internal i64 @safe_rshift_func_uint64_t_u_u ( i64 %0 , i32 %1 ) #0 { %3 = alloca i64 , align 8 %4 = alloca i32 , align 4 store i64 %0 , i64 * %3 , align 8 store i32 %1 , i32 * %4 , align 4 %5 = load i32 , i32 * %4 , align 4 %6 = icmp uge i32 %5 , 32 br i1 %6 , label %7 , label %7 78 %8 = load i64 , i64 * %3 , align 8 br label %9 910 %10 = load i64 , i64 * %3 , align 8 %11 = load i32 , i32 * %4 , align 4 %12 = zext i32 %11 to i64 %13 = lshr i64 %10 , %2 br label %14 115 %15 = phi i64 [ %8 , %7 ] , [ %13 , %9 ] ret i64 %15 }
define internal float @safe_add_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fadd float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fadd float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_sub_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 5.000000e-01 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 5.000000e-01 , %9 %9 = fsub float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x47DFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fsub float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_mul_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %3 , align 4 %6 = fmul float 0x39B0000000000000 , %7 %7 = load float , float * %4 , align 4 %8 = fmul float 0x3E30000000000000 , %9 %9 = fmul float %6 , %10 %10 = call float @llvm.fabs.f32 ( float %9 ) %11 = fcmp ogt float %10 , 0x3FEFFFFFE0000000 br i1 %11 , label %12 , label %12 113 %13 = load float , float * %3 , align 4 br label %14 115 %15 = load float , float * %3 , align 4 %16 = load float , float * %4 , align 4 %17 = fmul float %15 , %2 br label %18 119 %19 = phi float [ %13 , %12 ] , [ %17 , %14 ] ret float %19 }
define internal float @safe_div_func_float_f_f ( float %0 , float %1 ) #0 { %3 = alloca float , align 4 %4 = alloca float , align 4 store float %0 , float * %3 , align 4 store float %1 , float * %4 , align 4 %5 = load float , float * %4 , align 4 %6 = call float @llvm.fabs.f32 ( float %5 ) %7 = fcmp olt float %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load float , float * %4 , align 4 %10 = fcmp oeq float %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load float , float * %3 , align 4 %13 = fmul float 0x3CE0000000000000 , %14 %14 = load float , float * %4 , align 4 %15 = fmul float 0x4630000000000000 , %16 %16 = fdiv float %13 , %17 %17 = call float @llvm.fabs.f32 ( float %16 ) %18 = fcmp ogt float %17 , 0x3E9FFFFFE0000000 br i1 %18 , label %19 , label %19 120 %20 = load float , float * %3 , align 4 br label %21 222 %22 = load float , float * %3 , align 4 %23 = load float , float * %4 , align 4 %24 = fdiv float %22 , %2 br label %25 226 %26 = phi float [ %20 , %19 ] , [ %24 , %21 ] ret float %26 }
define internal double @safe_add_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fadd double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fadd double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_sub_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 5.000000e-01 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 5.000000e-01 , %9 %9 = fsub double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x7FDFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fsub double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_mul_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %3 , align 8 %6 = fmul double 0x39B0000000000000 , %7 %7 = load double , double * %4 , align 8 %8 = fmul double 0x630000000000000 , %9 %9 = fmul double %6 , %10 %10 = call double @llvm.fabs.f64 ( double %9 ) %11 = fcmp ogt double %10 , 0x3FEFFFFFFFFFFFFF br i1 %11 , label %12 , label %12 113 %13 = load double , double * %3 , align 8 br label %14 115 %15 = load double , double * %3 , align 8 %16 = load double , double * %4 , align 8 %17 = fmul double %15 , %2 br label %18 119 %19 = phi double [ %13 , %12 ] , [ %17 , %14 ] ret double %19 }
define internal double @safe_div_func_double_f_f ( double %0 , double %1 ) #0 { %3 = alloca double , align 8 %4 = alloca double , align 8 store double %0 , double * %3 , align 8 store double %1 , double * %4 , align 8 %5 = load double , double * %4 , align 8 %6 = call double @llvm.fabs.f64 ( double %5 ) %7 = fcmp olt double %6 , 1.000000e+00 br i1 %7 , label %8 , label %8 89 %9 = load double , double * %4 , align 8 %10 = fcmp oeq double %9 , 0.000000e+00 br i1 %10 , label %19 , label %11 112 %12 = load double , double * %3 , align 8 %13 = fmul double 0x310000000000000 , %14 %14 = load double , double * %4 , align 8 %15 = fmul double 0x4630000000000000 , %16 %16 = fdiv double %13 , %17 %17 = call double @llvm.fabs.f64 ( double %16 ) %18 = fcmp ogt double %17 , 0x3CCFFFFFFFFFFFFF br i1 %18 , label %19 , label %19 120 %20 = load double , double * %3 , align 8 br label %21 222 %22 = load double , double * %3 , align 8 %23 = load double , double * %4 , align 8 %24 = fdiv double %22 , %2 br label %25 226 %26 = phi double [ %20 , %19 ] , [ %24 , %21 ] ret double %26 }
define internal i32 @safe_convert_func_float_to_int32_t ( float %0 ) #0 { %2 = alloca float , align 4 store float %0 , float * %2 , align 4 %3 = load float , float * %2 , align 4 %4 = fcmp ole float %3 , 0xC1E0000000000000 br i1 %4 , label %8 , label %5 56 %6 = load float , float * %2 , align 4 %7 = fcmp oge float %6 , 0x41E0000000000000 br i1 %7 , label %8 , label %8 82 br label %9 910 %10 = load float , float * %2 , align 4 %11 = fptosi float %10 to i32 br label %12 113 %13 = phi i32 [ 2147483647 , %8 ] , [ %11 , %9 ] ret i32 %13 }
define internal void @crc32_gentab ( ) #0 { %1 = alloca i32 , align 4 %2 = alloca i32 , align 4 %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 store i32 -306674912 , i32 * %2 , align 4 store i32 0 , i32 * %3 , align 4 br label %5 56 %6 = load i32 , i32 * %3 , align 4 %7 = icmp slt i32 %6 , 256 br i1 %7 , label %8 , label %8 89 %9 = load i32 , i32 * %3 , align 4 store i32 %9 , i32 * %1 , align 4 store i32 8 , i32 * %4 , align 4 br label %10 111 %11 = load i32 , i32 * %4 , align 4 %12 = icmp sgt i32 %11 , 0 br i1 %12 , label %13 , label %13 114 %14 = load i32 , i32 * %1 , align 4 %15 = and i32 %14 , 1 %16 = icmp ne i32 %15 , 0 br i1 %16 , label %17 , label %17 118 %18 = load i32 , i32 * %1 , align 4 %19 = lshr i32 %18 , 1 %20 = xor i32 %19 , -306674912 store i32 %20 , i32 * %1 , align 4 br label %21 222 %22 = load i32 , i32 * %1 , align 4 %23 = lshr i32 %22 , 1 store i32 %23 , i32 * %1 , align 4 br label %24 22 br label %25 226 %26 = load i32 , i32 * %4 , align 4 %27 = add nsw i32 %26 , -1 store i32 %27 , i32 * %4 , align 4 br label %28 229 %29 = load i32 , i32 * %1 , align 4 %30 = load i32 , i32 * %3 , align 4 %31 = sext i32 %30 to i64 %32 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %33 store i32 %29 , i32 * %32 , align 4 br label %33 334 %34 = load i32 , i32 * %3 , align 4 %35 = add nsw i32 %34 , 1 store i32 %35 , i32 * %3 , align 4 br label %36 31 ret void }
define internal void @crc32_byte ( i8 zeroext %0 ) #0 { %2 = alloca i8 , align 1 store i8 %0 , i8 * %2 , align 1 %3 = load i32 , i32 * @crc32_context , align 4 %4 = lshr i32 %3 , 8 %5 = and i32 %4 , 16777215 %6 = load i32 , i32 * @crc32_context , align 4 %7 = load i8 , i8 * %2 , align 1 %8 = zext i8 %7 to i32 %9 = xor i32 %6 , %10 %10 = and i32 %9 , 255 %11 = zext i32 %10 to i64 %12 = getelementptr inbounds [ 256 x i32 ] , [ 256 x i32 ] * @crc32_tab , i64 0 , i64 %13 %13 = load i32 , i32 * %12 , align 4 %14 = xor i32 %5 , %33 store i32 %14 , i32 * @crc32_context , align 4 ret void }
define internal void @crc32_8bytes ( i64 %0 ) #0 { %2 = alloca i64 , align 8 store i64 %0 , i64 * %2 , align 8 %3 = load i64 , i64 * %2 , align 8 %4 = lshr i64 %3 , 0 %5 = and i64 %4 , 255 %6 = trunc i64 %5 to i8 call void @crc32_byte ( i8 zeroext %6 ) %7 = load i64 , i64 * %2 , align 8 %8 = lshr i64 %7 , 8 %9 = and i64 %8 , 255 %10 = trunc i64 %9 to i8 call void @crc32_byte ( i8 zeroext %10 ) %11 = load i64 , i64 * %2 , align 8 %12 = lshr i64 %11 , 16 %13 = and i64 %12 , 255 %14 = trunc i64 %13 to i8 call void @crc32_byte ( i8 zeroext %14 ) %15 = load i64 , i64 * %2 , align 8 %16 = lshr i64 %15 , 24 %17 = and i64 %16 , 255 %18 = trunc i64 %17 to i8 call void @crc32_byte ( i8 zeroext %18 ) %19 = load i64 , i64 * %2 , align 8 %20 = lshr i64 %19 , 32 %21 = and i64 %20 , 255 %22 = trunc i64 %21 to i8 call void @crc32_byte ( i8 zeroext %22 ) %23 = load i64 , i64 * %2 , align 8 %24 = lshr i64 %23 , 40 %25 = and i64 %24 , 255 %26 = trunc i64 %25 to i8 call void @crc32_byte ( i8 zeroext %26 ) %27 = load i64 , i64 * %2 , align 8 %28 = lshr i64 %27 , 48 %29 = and i64 %28 , 255 %30 = trunc i64 %29 to i8 call void @crc32_byte ( i8 zeroext %30 ) %31 = load i64 , i64 * %2 , align 8 %32 = lshr i64 %31 , 56 %33 = and i64 %32 , 255 %34 = trunc i64 %33 to i8 call void @crc32_byte ( i8 zeroext %34 ) ret void }
define internal void @transparent_crc ( i64 %0 , i8 * %1 , i32 %2 ) #0 { %4 = alloca i64 , align 8 %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 store i64 %0 , i64 * %4 , align 8 store i8 * %1 , i8 * * %5 , align 8 store i32 %2 , i32 * %6 , align 4 %7 = load i64 , i64 * %4 , align 8 call void @crc32_8bytes ( i64 %7 ) %8 = load i32 , i32 * %6 , align 4 %9 = icmp ne i32 %8 , 0 br i1 %9 , label %10 , label %10 111 %11 = load i8 * , i8 * * %5 , align 8 %12 = load i32 , i32 * @crc32_context , align 4 %13 = zext i32 %12 to i64 %14 = xor i64 %13 , 4294967295 %15 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %11 , i64 %14 ) br label %16 11 ret void }
define internal void @transparent_crc_bytes ( i8 * %0 , i32 %1 , i8 * %2 , i32 %3 ) #0 { %5 = alloca i8 * , align 8 %6 = alloca i32 , align 4 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i8 * %0 , i8 * * %5 , align 8 store i32 %1 , i32 * %6 , align 4 store i8 * %2 , i8 * * %7 , align 8 store i32 %3 , i32 * %8 , align 4 store i32 0 , i32 * %9 , align 4 br label %10 111 %11 = load i32 , i32 * %9 , align 4 %12 = load i32 , i32 * %6 , align 4 %13 = icmp slt i32 %11 , %2 br i1 %13 , label %14 , label %14 115 %15 = load i8 * , i8 * * %5 , align 8 %16 = load i32 , i32 * %9 , align 4 %17 = sext i32 %16 to i64 %18 = getelementptr inbounds i8 , i8 * %15 , i64 %19 %19 = load i8 , i8 * %18 , align 1 call void @crc32_byte ( i8 zeroext %19 ) br label %20 221 %21 = load i32 , i32 * %9 , align 4 %22 = add nsw i32 %21 , 1 store i32 %22 , i32 * %9 , align 4 br label %23 224 %24 = load i32 , i32 * %8 , align 4 %25 = icmp ne i32 %24 , 0 br i1 %25 , label %26 , label %26 227 %27 = load i8 * , i8 * * %7 , align 8 %28 = load i32 , i32 * @crc32_context , align 4 %29 = zext i32 %28 to i64 %30 = xor i64 %29 , 4294967295 %31 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 36 x i8 ] , [ 36 x i8 ] * @.str.1 , i64 0 , i64 0 ) , i8 * %27 , i64 %30 ) br label %32 31 ret void }
define internal i32 @func_1 ( ) #0 { %1 = alloca i32 * , align 8 %2 = alloca i32 * , align 8 %3 = alloca i8 * , align 8 %4 = alloca [ 8 x [ 7 x i8 * ] ] , align 16 %5 = alloca i8 * * , align 8 %6 = alloca i32 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 %9 = alloca [ 3 x i32 * ] , align 16 %10 = alloca i64 * , align 8 %11 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %12 = alloca i32 , align 4 %13 = alloca i8 , align 1 %14 = alloca i32 , align 4 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = alloca i8 , align 1 %18 = alloca i32 * * * * , align 8 %19 = alloca i32 * * , align 8 %20 = alloca i8 , align 1 %21 = alloca i32 , align 4 %22 = alloca i8 , align 1 %23 = alloca [ 9 x i32 ] , align 16 %24 = alloca i32 , align 4 %25 = alloca i32 , align 4 %26 = alloca i8 , align 1 %27 = alloca i32 , align 4 store i32 * @g_11 , i32 * * %1 , align 8 store i32 * getelementptr inbounds ( [ 1 x [ 9 x i32 ] ] , [ 1 x [ 9 x i32 ] ] * @g_1@@ 3 , i64 0 , i64 0 , i64 7 ) , i32 * * %2 , align 8 store i8 * @g_@@ 26 , i8 * * %3 , align 8 %28 = bitcast [ 8 x [ 7 x i8 * ] ] * %4 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %28 , i8 * align 16 bitcast ( [ 8 x [ 7 x i8 * ] ] * @__const.func_1.l_@@ 72 to i8 * ) , i64 448 , i1 false ) %29 = getelementptr inbounds [ 8 x [ 7 x i8 * ] ] , [ 8 x [ 7 x i8 * ] ] * %4 , i64 0 , i64 3 %30 = getelementptr inbounds [ 7 x i8 * ] , [ 7 x i8 * ] * %29 , i64 0 , i64 1 store i8 * * %30 , i8 * * * %5 , align 8 store i32 * null , i32 * * %6 , align 8 store i32 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 2 , %@@ struct@@ .@@ S@@ 2 * bitcast ( < { i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i32 * @func_@@ 2 ( i32 %0 , i32 * %1 , %un@@ ion.@@ U@@ 3 * by@@ val ( %un@@ ion.@@ U@@ 3 ) align 8 %2 , i32 * %3 , i32 %4 ) #0 { %6 = alloca i32 * , align 8 %7 = alloca i32 , align 4 %8 = alloca i32 * , align 8 %9 = alloca i32 * , align 8 %10 = alloca i32 , align 4 %11 = alloca i32 , align 4 %12 = alloca i16 , align 2 %13 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %14 = alloca i32 , align 4 %15 = alloca [ 2 x %un@@ ion.@@ U@@ 3 * ] , align 16 %16 = alloca %un@@ ion.@@ U@@ 3 * * , align 8 %17 = alloca i32 , align 4 %18 = alloca i8 * , align 8 %19 = alloca [ 3 x [ 5 x [ 6 x i16 ] ] ] , align 16 %20 = alloca i32 * * * * , align 8 %21 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %22 = alloca i64 * , align 8 %23 = alloca i32 , align 4 %24 = alloca i32 , align 4 %25 = alloca i32 , align 4 %26 = alloca i32 , align 4 %27 = alloca i32 , align 4 %28 = alloca i32 , align 4 %29 = alloca i32 , align 4 %30 = alloca i32 , align 4 %31 = alloca [ 4 x [ 8 x i32 ] ] , align 16 %32 = alloca [ 5 x [ 7 x [ 7 x i16 * ] ] ] , align 16 %33 = alloca i8 * , align 8 %34 = alloca i8 * * , align 8 %35 = alloca i8 , align 1 %36 = alloca i16 , align 2 %37 = alloca i32 , align 4 %38 = alloca i16 , align 2 %39 = alloca [ 5 x i64 ] , align 16 %40 = alloca i8 , align 1 %41 = alloca [ 9 x i16 ] , align 16 %42 = alloca [ 10 x i64 ] , align 16 %43 = alloca i16 , align 2 %44 = alloca i64 * , align 8 %45 = alloca i64 * * , align 8 %46 = alloca [ 5 x [ 8 x i16 ] ] , align 16 %47 = alloca i32 * , align 8 %48 = alloca i32 * * , align 8 %49 = alloca [ 8 x [ 6 x [ 4 x %@@ struct@@ .@@ S@@ 0 * * * * ] ] ] , align 16 %50 = alloca %@@ struct@@ .@@ S@@ 0 * * * * * , align 8 %51 = alloca i64 , align 8 %52 = alloca i8 * , align 8 %53 = alloca i32 , align 4 %54 = alloca i32 , align 4 %55 = alloca i32 , align 4 %56 = alloca i32 , align 4 %57 = alloca i64 , align 8 %58 = alloca [ 8 x %@@ struct@@ .@@ S@@ 0 * * * ] , align 16 %59 = alloca i16 * , align 8 %60 = alloca [ 3 x i16 ] , align 2 %61 = alloca i32 , align 4 %62 = alloca %un@@ ion.@@ U@@ 3 * , align 8 %63 = alloca i64 , align 8 %64 = alloca [ 2 x i16 * ] , align 16 %65 = alloca [ 8 x [ 3 x i16 * * ] ] , align 16 %66 = alloca i32 , align 4 %67 = alloca i8 * , align 8 %68 = alloca [ 6 x i8 * * ] , align 16 %69 = alloca i32 , align 4 %70 = alloca i32 , align 4 %71 = alloca i32 * , align 8 %72 = alloca i32 , align 4 %73 = alloca i32 * , align 8 %74 = alloca [ 9 x [ 3 x i32 * ] ] , align 16 %75 = alloca i32 , align 4 %76 = alloca i8 , align 1 %77 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %78 = alloca i8 * * , align 8 %79 = alloca i32 , align 4 %80 = alloca i32 , align 4 %81 = alloca [ 5 x [ 3 x [ 5 x i32 ] ] ] , align 16 %82 = alloca [ 8 x i32 ] , align 16 %83 = alloca [ 6 x %un@@ ion.@@ U@@ 3 ] , align 16 %84 = alloca i8 * * , align 8 %85 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %86 = alloca [ 6 x [ 1 x %@@ struct@@ .@@ S@@ 0 * * * ] ] , align 16 %87 = alloca i32 , align 4 %88 = alloca i8 * , align 8 %89 = alloca [ 5 x [ 10 x i64 ] ] , align 16 %90 = alloca i32 , align 4 %91 = alloca i32 , align 4 %92 = alloca i32 , align 4 %93 = alloca i64 , align 8 %94 = alloca i32 , align 4 %95 = alloca %un@@ ion.@@ U@@ 3 * * , align 8 %96 = alloca i16 * , align 8 %97 = alloca i16 , align 2 %98 = alloca i8 * , align 8 %99 = alloca i8 * * , align 8 %100 = alloca i8 * * * , align 8 %101 = alloca i64 * , align 8 %102 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %103 = alloca %@@ struct@@ .@@ S@@ 1 * * , align 8 %104 = alloca i8 * , align 8 %105 = alloca i32 , align 4 %106 = alloca i32 , align 4 %107 = alloca i32 , align 4 %108 = alloca i32 , align 4 %109 = alloca [ 1 x i8 * * * ] , align 8 %110 = alloca i32 , align 4 %111 = alloca i8 , align 1 %112 = alloca i8 * , align 8 %113 = alloca i32 * , align 8 %114 = alloca i32 * , align 8 %115 = alloca i32 , align 4 %116 = alloca i32 , align 4 %117 = alloca i32 , align 4 %118 = alloca i32 , align 4 %119 = alloca [ 2 x i32 ] , align 4 %120 = alloca i32 , align 4 %121 = alloca %@@ struct@@ .@@ S@@ 0 * * * * , align 8 %122 = alloca %@@ struct@@ .@@ S@@ 0 * * * * , align 8 %123 = alloca i32 * , align 8 %124 = alloca i16 * , align 8 %125 = alloca i32 , align 4 %126 = alloca [ 1 x [ 6 x i32 ] ] , align 16 %127 = alloca [ 1 x [ 2 x [ 10 x i32 ] ] ] , align 16 %128 = alloca i32 , align 4 %129 = alloca i32 , align 4 %130 = alloca i32 , align 4 %131 = alloca i8 * , align 8 %132 = alloca i8 * * , align 8 %133 = alloca [ 5 x [ 3 x i8 * * ] ] , align 16 %134 = alloca i32 , align 4 %135 = alloca i32 , align 4 %136 = alloca i32 , align 4 %137 = alloca i32 , align 4 %138 = alloca i32 , align 4 %139 = alloca i32 , align 4 %140 = alloca [ 5 x [ 6 x [ 4 x i32 ] ] ] , align 16 %141 = alloca [ 8 x i32 ] , align 16 %142 = alloca i32 , align 4 %143 = alloca i32 , align 4 %144 = alloca i32 , align 4 %145 = alloca %@@ struct@@ .@@ S@@ 2 , align 1 %146 = alloca i64 * , align 8 %147 = alloca i64 * , align 8 %148 = alloca i64 * * , align 8 %149 = alloca i32 * , align 8 %150 = alloca i32 * * , align 8 %151 = alloca [ 9 x i32 * ] , align 16 %152 = alloca i32 * * , align 8 %153 = alloca i32 , align 4 %154 = alloca i32 , align 4 %155 = alloca i32 , align 4 %156 = alloca i32 , align 4 %157 = alloca i32 , align 4 %158 = alloca i32 , align 4 %159 = alloca i32 , align 4 %160 = alloca i32 , align 4 %161 = alloca [ 2 x i32 ] , align 4 %162 = alloca [ 5 x %@@ struct@@ .@@ S@@ 2 * ] , align 16 %163 = alloca [ 10 x i8 * ] , align 16 %164 = alloca i64 , align 8 %165 = alloca i32 , align 4 %166 = alloca [ 1 x %@@ struct@@ .@@ S@@ 1 * ] , align 8 %167 = alloca i16 , align 2 %168 = alloca %un@@ ion.@@ U@@ 3 * * * * , align 8 %169 = alloca i32 , align 4 %170 = alloca [ 9 x %@@ struct@@ .@@ S@@ 0 * * * ] , align 16 %171 = alloca [ 6 x [ 7 x i16 * * ] ] , align 16 %172 = alloca i16 * * * , align 8 %173 = alloca i16 , align 2 %174 = alloca i32 , align 4 %175 = alloca i32 , align 4 store i32 %0 , i32 * %7 , align 4 store i32 * %1 , i32 * * %8 , align 8 store i32 * %3 , i32 * * %9 , align 8 store i32 %4 , i32 * %10 , align 4 store i32 -1 , i32 * %11 , align 4 store i16 270@@ 96 , i16 * %12 , align 2 store %@@ struct@@ .@@ S@@ 1 * bitcast ( { i8 , i8 , i8 , i8 , i16 , i16 , i64 , i8 , i16 , i8 , i32 , i8 , i32 }
define internal zeroext i16 @func_16 ( i32 * %0 , i8 zeroext %1 , i32 * %2 , i32 * %3 ) #0 { %5 = alloca i32 * , align 8 %6 = alloca i8 , align 1 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 %9 = alloca i8 , align 1 %10 = alloca i8 * , align 8 %11 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 store i32 * %0 , i32 * * %5 , align 8 store i8 %1 , i8 * %6 , align 1 store i32 * %2 , i32 * * %7 , align 8 store i32 * %3 , i32 * * %8 , align 8 store i8 72 , i8 * %9 , align 1 store i8 * @g_@@ 65 , i8 * * %10 , align 8 store %@@ struct@@ .@@ S@@ 2 * getelementptr inbounds ( [ 7 x [ 4 x %@@ struct@@ .@@ S@@ 2 ] ] , [ 7 x [ 4 x %@@ struct@@ .@@ S@@ 2 ] ] * bitcast ( [ 7 x [ 4 x < { i8 , i8 , i32 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 , i8 }
define internal i32 * @func_@@ 21 ( i8 signext %0 , i8 zeroext %1 , i32 * %2 ) #0 { %4 = alloca i32 * , align 8 %5 = alloca i8 , align 1 %6 = alloca i8 , align 1 %7 = alloca i32 * , align 8 %8 = alloca [ 6 x [ 9 x [ 4 x i16 ] ] ] , align 16 %9 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %10 = alloca i8 * , align 8 %11 = alloca i32 * , align 8 %12 = alloca [ 10 x i32 * ] , align 16 %13 = alloca i32 * , align 8 %14 = alloca i32 , align 4 %15 = alloca i32 , align 4 %16 = alloca i32 , align 4 %17 = alloca i32 * , align 8 %18 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 store i8 %0 , i8 * %5 , align 1 store i8 %1 , i8 * %6 , align 1 store i32 * %2 , i32 * * %7 , align 8 %19 = bitcast [ 6 x [ 9 x [ 4 x i16 ] ] ] * %8 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %19 , i8 * align 16 bitcast ( [ 6 x [ 9 x [ 4 x i16 ] ] ] * @__const.func_@@ 2@@ 1.l_@@ 148@@ 7 to i8 * ) , i64 432 , i1 false ) store %@@ struct@@ .@@ S@@ 0 * * @g_@@ 58@@ 5 , %@@ struct@@ .@@ S@@ 0 * * * %9 , align 8 store i8 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 1 , %@@ struct@@ .@@ S@@ 1 * bitcast ( { i8 , i8 , i8 , i8 , i16 , i16 , i64 , i8 , i16 , i8 , i32 , i8 , i32 }
define internal i64 @func_@@ 29 ( i8 * %0 , i32 %1 ) #0 { %3 = alloca i8 * , align 8 %4 = alloca i32 , align 4 %5 = alloca i32 , align 4 %6 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %7 = alloca i8 * , align 8 %8 = alloca i32 , align 4 %9 = alloca i8 * , align 8 %10 = alloca %un@@ ion.@@ U@@ 3 , align 4 %11 = alloca i32 * , align 8 %12 = alloca [ 10 x [ 3 x [ 3 x i32 ] ] ] , align 16 %13 = alloca [ 7 x i32 ] , align 16 %14 = alloca i32 , align 4 %15 = alloca i32 * * * * , align 8 %16 = alloca [ 3 x [ 3 x [ 3 x i32 * * * * ] ] ] , align 16 %17 = alloca i64 , align 8 %18 = alloca [ 6 x i32 ] , align 16 %19 = alloca [ 5 x %un@@ ion.@@ U@@ 3 * * ] , align 16 %20 = alloca [ 3 x [ 9 x [ 3 x %un@@ ion.@@ U@@ 3 * ] ] ] , align 16 %21 = alloca i32 , align 4 %22 = alloca i32 , align 4 %23 = alloca i32 , align 4 %24 = alloca i32 , align 4 %25 = alloca i32 * , align 8 %26 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %27 = alloca i32 , align 4 %28 = alloca i16 , align 2 %29 = alloca [ 3 x %@@ struct@@ .@@ S@@ 2 * * * * * ] , align 16 %30 = alloca i32 * , align 8 %31 = alloca [ 5 x i32 * * * ] , align 16 %32 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %33 = alloca i64 , align 8 %34 = alloca %@@ struct@@ .@@ S@@ 2 * * , align 8 %35 = alloca i32 , align 4 %36 = alloca i32 , align 4 %37 = alloca i32 * , align 8 %38 = alloca %un@@ ion.@@ U@@ 3 , align 4 %39 = alloca %@@ struct@@ .@@ S@@ 1 * , align 8 %40 = alloca [ 8 x [ 4 x [ 8 x %@@ struct@@ .@@ S@@ 0 * * * * ] ] ] , align 16 %41 = alloca i32 , align 4 %42 = alloca i32 , align 4 %43 = alloca i32 , align 4 store i8 * %0 , i8 * * %3 , align 8 store i32 %1 , i32 * %4 , align 4 store i32 3 , i32 * %5 , align 4 %44 = bitcast %@@ struct@@ .@@ S@@ 0 * %6 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 1 %44 , i8 * align 1 getelementptr inbounds ( %@@ struct@@ .@@ S@@ 0 , %@@ struct@@ .@@ S@@ 0 * @__const.func_@@ 29@@ .l_@@ 10@@ 93 , i32 0 , i32 0 ) , i64 5 , i1 false ) store i8 * null , i8 * * %7 , align 8 store i32 0 , i32 * %8 , align 4 store i8 * getelementptr inbounds ( %@@ struct@@ .@@ S@@ 1 , %@@ struct@@ .@@ S@@ 1 * bitcast ( { i8 , i8 , i8 , i8 , i16 , i16 , i64 , i8 , i16 , i8 , i32 , i8 , i32 }
define internal i8 * @func_@@ 33 ( i32 * %0 , i32 * %1 , i32 * %2 , i32 * %3 ) #0 { %5 = alloca i32 * , align 8 %6 = alloca i32 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 store i32 * %0 , i32 * * %5 , align 8 store i32 * %1 , i32 * * %6 , align 8 store i32 * %2 , i32 * * %7 , align 8 store i32 * %3 , i32 * * %8 , align 8 ret i8 * @g_1@@ 28 }
define internal i32 * @func_@@ 38 ( i8 * %0 , i32 * %1 ) #0 { %3 = alloca i32 * , align 8 %4 = alloca i8 * , align 8 %5 = alloca i32 * , align 8 %6 = alloca i32 * , align 8 %7 = alloca i32 * , align 8 %8 = alloca [ 9 x [ 2 x [ 4 x %un@@ ion.@@ U@@ 3 ] ] ] , align 16 %9 = alloca [ 6 x i32 * ] , align 16 %10 = alloca i32 * , align 8 %11 = alloca [ 7 x i32 * * ] , align 16 %12 = alloca i32 * * * , align 8 %13 = alloca [ 1 x [ 7 x i32 * * * * ] ] , align 16 %14 = alloca [ 3 x i32 * * * ] , align 16 %15 = alloca i64 , align 8 %16 = alloca i16 * , align 8 %17 = alloca i8 * , align 8 %18 = alloca i64 , align 8 %19 = alloca i64 * , align 8 %20 = alloca %un@@ ion.@@ U@@ 3 * , align 8 %21 = alloca [ 1 x [ 7 x [ 6 x %@@ struct@@ .@@ S@@ 2 * ] ] ] , align 16 %22 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %23 = alloca i64 , align 8 %24 = alloca i16 * , align 8 %25 = alloca i8 , align 1 %26 = alloca i64 , align 8 %27 = alloca i16 , align 2 %28 = alloca %@@ struct@@ .@@ S@@ 0 * * * , align 8 %29 = alloca [ 10 x i32 ] , align 16 %30 = alloca i16 , align 2 %31 = alloca i64 , align 8 %32 = alloca i8 , align 1 %33 = alloca i32 , align 4 %34 = alloca i32 * , align 8 %35 = alloca i32 , align 4 %36 = alloca i32 * , align 8 %37 = alloca i32 , align 4 %38 = alloca i32 , align 4 %39 = alloca i32 , align 4 %40 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %41 = alloca %@@ struct@@ .@@ S@@ 2 , align 1 %42 = alloca %un@@ ion.@@ U@@ 3 , align 4 %43 = alloca i32 * , align 8 %44 = alloca i32 * * , align 8 %45 = alloca i32 * , align 8 %46 = alloca i32 * * , align 8 %47 = alloca i32 , align 4 %48 = alloca i32 * , align 8 %49 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %50 = alloca i32 * * * * , align 8 %51 = alloca i32 * , align 8 %52 = alloca i32 , align 4 %53 = alloca i32 , align 4 %54 = alloca i32 , align 4 %55 = alloca i32 , align 4 %56 = alloca i32 , align 4 %57 = alloca i32 * * * * , align 8 %58 = alloca i32 , align 4 %59 = alloca [ 9 x [ 10 x i16 ] ] , align 16 %60 = alloca i32 , align 4 %61 = alloca i32 , align 4 %62 = alloca i32 , align 4 %63 = alloca i32 , align 4 %64 = alloca i32 * , align 8 %65 = alloca i32 , align 4 %66 = alloca i32 , align 4 %67 = alloca i32 , align 4 %68 = alloca i16 , align 2 %69 = alloca i64 * , align 8 %70 = alloca i32 , align 4 %71 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %72 = alloca i16 * , align 8 %73 = alloca i32 , align 4 %74 = alloca i32 , align 4 %75 = alloca i32 , align 4 %76 = alloca i16 , align 2 %77 = alloca i32 , align 4 %78 = alloca [ 9 x [ 6 x i32 ] ] , align 16 %79 = alloca i8 , align 1 %80 = alloca [ 7 x i64 ] , align 16 %81 = alloca i64 * , align 8 %82 = alloca i16 * , align 8 %83 = alloca i16 * , align 8 %84 = alloca i32 , align 4 %85 = alloca i32 , align 4 %86 = alloca i32 , align 4 %87 = alloca i64 , align 8 %88 = alloca i16 * , align 8 %89 = alloca i32 * , align 8 %90 = alloca %un@@ ion.@@ U@@ 3 , align 4 %91 = alloca i32 , align 4 %92 = alloca i32 , align 4 %93 = alloca [ 8 x [ 6 x [ 2 x i32 ] ] ] , align 16 %94 = alloca i32 , align 4 %95 = alloca i32 * * * , align 8 %96 = alloca i8 , align 1 %97 = alloca i64 , align 8 %98 = alloca i32 , align 4 %99 = alloca i32 , align 4 %100 = alloca i32 * * * * , align 8 %101 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %102 = alloca i8 , align 1 %103 = alloca i16 , align 2 %104 = alloca i32 * , align 8 %105 = alloca i64 , align 8 %106 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %107 = alloca %@@ struct@@ .@@ S@@ 2 * * , align 8 %108 = alloca i8 , align 1 %109 = alloca i64 * , align 8 %110 = alloca i32 , align 4 %111 = alloca i32 , align 4 %112 = alloca i32 , align 4 %113 = alloca i16 , align 2 %114 = alloca i8 , align 1 %115 = alloca i32 , align 4 %116 = alloca i32 , align 4 %117 = alloca i32 , align 4 %118 = alloca i8 , align 1 %119 = alloca i32 * , align 8 %120 = alloca %un@@ ion.@@ U@@ 3 , align 4 %121 = alloca i8 * * , align 8 %122 = alloca i64 , align 8 %123 = alloca i32 , align 4 %124 = alloca [ 2 x [ 1 x [ 4 x %@@ struct@@ .@@ S@@ 0 * ] ] ] , align 16 %125 = alloca [ 9 x [ 10 x [ 2 x i16 ] ] ] , align 16 %126 = alloca i16 , align 2 %127 = alloca i32 , align 4 %128 = alloca i32 , align 4 %129 = alloca i32 , align 4 %130 = alloca %un@@ ion.@@ U@@ 3 * , align 8 %131 = alloca [ 8 x %un@@ ion.@@ U@@ 3 * * ] , align 16 %132 = alloca i32 , align 4 %133 = alloca i32 , align 4 %134 = alloca i16 * , align 8 %135 = alloca [ 4 x [ 7 x i8 ] ] , align 16 %136 = alloca i32 , align 4 %137 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %138 = alloca i32 , align 4 %139 = alloca i32 , align 4 %140 = alloca [ 8 x [ 5 x [ 2 x i32 ] ] ] , align 16 %141 = alloca i16 , align 2 %142 = alloca [ 2 x %un@@ ion.@@ U@@ 3 ] , align 16 %143 = alloca [ 6 x [ 6 x i32 ] ] , align 16 %144 = alloca i32 , align 4 %145 = alloca i32 , align 4 %146 = alloca i32 , align 4 %147 = alloca i32 , align 4 %148 = alloca %un@@ ion.@@ U@@ 3 * , align 8 %149 = alloca [ 4 x [ 10 x [ 4 x i8 ] ] ] , align 16 %150 = alloca i32 * , align 8 %151 = alloca i32 , align 4 %152 = alloca i32 , align 4 %153 = alloca i32 , align 4 %154 = alloca %un@@ ion.@@ U@@ 3 , align 4 %155 = alloca [ 4 x i8 * ] , align 16 %156 = alloca i32 * , align 8 %157 = alloca i32 * * * * , align 8 %158 = alloca i32 , align 4 %159 = alloca i32 , align 4 %160 = alloca i32 , align 4 %161 = alloca [ 1 x [ 9 x i32 ] ] , align 16 %162 = alloca [ 10 x i32 * * * * ] , align 16 %163 = alloca i32 , align 4 %164 = alloca i32 , align 4 %165 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %166 = alloca %@@ struct@@ .@@ S@@ 2 * * , align 8 %167 = alloca %@@ struct@@ .@@ S@@ 2 * * , align 8 %168 = alloca i64 * , align 8 %169 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %170 = alloca [ 10 x [ 6 x %@@ struct@@ .@@ S@@ 0 * * ] ] , align 16 %171 = alloca i32 , align 4 %172 = alloca i32 , align 4 %173 = alloca i32 , align 4 %174 = alloca i32 , align 4 %175 = alloca i32 , align 4 %176 = alloca [ 9 x [ 2 x [ 7 x i32 ] ] ] , align 16 %177 = alloca i64 * , align 8 %178 = alloca i32 , align 4 %179 = alloca i32 , align 4 %180 = alloca i32 , align 4 %181 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %182 = alloca %un@@ ion.@@ U@@ 3 , align 4 %183 = alloca i32 , align 4 %184 = alloca i32 , align 4 %185 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %186 = alloca i16 * , align 8 %187 = alloca [ 6 x [ 1 x i16 * * ] ] , align 16 %188 = alloca [ 4 x [ 2 x i32 ] ] , align 16 %189 = alloca i32 , align 4 %190 = alloca i32 , align 4 %191 = alloca i32 , align 4 %192 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %193 = alloca i32 , align 4 %194 = alloca i16 , align 2 %195 = alloca i32 , align 4 %196 = alloca %@@ struct@@ .@@ S@@ 0 * * , align 8 %197 = alloca %@@ struct@@ .@@ S@@ 0 * * * , align 8 %198 = alloca [ 1 x i32 ] , align 4 %199 = alloca i32 , align 4 %200 = alloca i32 , align 4 %201 = alloca i32 , align 4 %202 = alloca i32 , align 4 %203 = alloca [ 5 x i8 * ] , align 16 %204 = alloca i32 , align 4 %205 = alloca i32 , align 4 %206 = alloca i8 * , align 8 %207 = alloca [ 1 x i32 ] , align 4 %208 = alloca [ 3 x i32 * * * * ] , align 16 %209 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %210 = alloca i32 , align 4 %211 = alloca i32 , align 4 %212 = alloca i64 , align 8 %213 = alloca i8 , align 1 %214 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %215 = alloca i64 * , align 8 %216 = alloca i32 , align 4 %217 = alloca i8 , align 1 %218 = alloca [ 10 x i32 ] , align 16 %219 = alloca i32 , align 4 %220 = alloca i16 , align 2 %221 = alloca i32 , align 4 %222 = alloca i64 * , align 8 %223 = alloca i32 , align 4 %224 = alloca i32 * * * * , align 8 %225 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %226 = alloca i64 , align 8 %227 = alloca i32 , align 4 %228 = alloca i16 , align 2 %229 = alloca i32 , align 4 %230 = alloca [ 5 x [ 4 x i32 ] ] , align 16 %231 = alloca i32 , align 4 %232 = alloca i32 , align 4 %233 = alloca i32 , align 4 %234 = alloca [ 9 x i8 ] , align 1 %235 = alloca i32 , align 4 %236 = alloca i8 , align 1 %237 = alloca [ 3 x i32 ] , align 4 %238 = alloca i32 * , align 8 %239 = alloca i32 * * * * * , align 8 %240 = alloca [ 9 x i64 * ] , align 16 %241 = alloca [ 2 x [ 2 x i16 * ] ] , align 16 %242 = alloca i8 , align 1 %243 = alloca i32 , align 4 %244 = alloca i32 , align 4 %245 = alloca i32 , align 4 %246 = alloca i16 , align 2 %247 = alloca [ 10 x [ 5 x i64 * ] ] , align 16 %248 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %249 = alloca i32 , align 4 %250 = alloca i32 , align 4 %251 = alloca i16 * , align 8 %252 = alloca [ 10 x [ 8 x i64 ] ] , align 16 %253 = alloca i32 , align 4 %254 = alloca i32 , align 4 %255 = alloca i32 , align 4 %256 = alloca [ 10 x i8 ] , align 1 %257 = alloca i32 , align 4 %258 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %259 = alloca [ 5 x i8 ] , align 1 %260 = alloca i32 , align 4 %261 = alloca i32 , align 4 %262 = alloca i32 , align 4 %263 = alloca i32 , align 4 %264 = alloca [ 1 x i16 ] , align 2 %265 = alloca i32 , align 4 %266 = alloca [ 3 x i32 * ] , align 16 %267 = alloca i16 * * , align 8 %268 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %269 = alloca i32 , align 4 %270 = alloca i32 , align 4 %271 = alloca i32 * , align 8 %272 = alloca i32 * , align 8 %273 = alloca %@@ struct@@ .@@ S@@ 0 , align 1 %274 = alloca i32 , align 4 %275 = alloca i32 , align 4 %276 = alloca i32 , align 4 %277 = alloca i32 , align 4 %278 = alloca i32 , align 4 %279 = alloca i16 , align 2 %280 = alloca i32 , align 4 %281 = alloca i8 * , align 8 %282 = alloca i32 , align 4 %283 = alloca i32 , align 4 %284 = alloca i32 , align 4 %285 = alloca [ 9 x %@@ struct@@ .@@ S@@ 0 ] , align 16 %286 = alloca i16 * * , align 8 %287 = alloca %@@ struct@@ .@@ S@@ 2 * , align 8 %288 = alloca i32 , align 4 %289 = alloca i32 , align 4 %290 = alloca %un@@ ion.@@ U@@ 3 , align 4 %291 = alloca %@@ struct@@ .@@ S@@ 2 * * , align 8 %292 = alloca i32 , align 4 %293 = alloca i64 , align 8 %294 = alloca i32 , align 4 %295 = alloca i8 , align 1 %296 = alloca i32 , align 4 %297 = alloca i32 * , align 8 %298 = alloca i32 , align 4 %299 = alloca [ 5 x i32 ] , align 16 %300 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %301 = alloca i16 , align 2 %302 = alloca i32 , align 4 %303 = alloca %@@ struct@@ .@@ S@@ 2 , align 1 %304 = alloca i32 , align 4 %305 = alloca %@@ struct@@ .@@ S@@ 0 * , align 8 %306 = alloca i8 , align 1 %307 = alloca [ 7 x [ 4 x [ 9 x %@@ struct@@ .@@ S@@ 2 * * * ] ] ] , align 16 %308 = alloca i16 * * , align 8 %309 = alloca i32 , align 4 %310 = alloca i32 , align 4 %311 = alloca i32 , align 4 %312 = alloca [ 5 x i32 * * ] , align 16 %313 = alloca i16 * , align 8 %314 = alloca i32 , align 4 %315 = alloca i8 * , align 8 %316 = alloca i64 , align 8 %317 = alloca [ 1 x [ 5 x i32 ] ] , align 16 %318 = alloca %un@@ ion.@@ U@@ 3 * , align 8 %319 = alloca i64 * , align 8 %320 = alloca i64 * , align 8 %321 = alloca i32 , align 4 %322 = alloca i32 , align 4 %323 = alloca i32 , align 4 %324 = alloca %un@@ ion.@@ U@@ 3 * , align 8 %325 = alloca i16 * , align 8 %326 = alloca [ 4 x [ 4 x [ 10 x i32 ] ] ] , align 16 %327 = alloca i64 , align 8 %328 = alloca i32 , align 4 %329 = alloca i32 , align 4 %330 = alloca i32 , align 4 %331 = alloca %un@@ ion.@@ U@@ 3 , align 4 %332 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %333 = alloca %@@ struct@@ .@@ S@@ 1 , align 8 %334 = alloca i32 , align 4 %335 = alloca i32 , align 4 %336 = alloca i32 , align 4 %337 = alloca i32 , align 4 %338 = alloca i8 , align 1 %339 = alloca [ 2 x %un@@ ion.@@ U@@ 3 ] , align 16 %340 = alloca i32 , align 4 %341 = alloca i32 * * , align 8 %342 = alloca i32 * * * , align 8 %343 = alloca i32 , align 4 %344 = alloca [ 4 x i32 ] , align 16 %345 = alloca %@@ struct@@ .@@ S@@ 2 * * , align 8 %346 = alloca [ 9 x [ 8 x %@@ struct@@ .@@ S@@ 0 * * * ] ] , align 16 %347 = alloca %@@ struct@@ .@@ S@@ 0 * * * * , align 8 %348 = alloca i32 * * * , align 8 %349 = alloca i8 * , align 8 %350 = alloca i16 * , align 8 %351 = alloca i16 * , align 8 %352 = alloca i16 * , align 8 %353 = alloca i32 , align 4 %354 = alloca [ 1 x i32 ] , align 4 %355 = alloca i32 , align 4 %356 = alloca i32 , align 4 %357 = alloca %@@ struct@@ .@@ S@@ 2 * * * , align 8 %358 = alloca %@@ struct@@ .@@ S@@ 2 * * * * , align 8 %359 = alloca i16 * , align 8 %360 = alloca i32 , align 4 %361 = alloca [ 4 x i8 * ] , align 16 %362 = alloca i32 * , align 8 %363 = alloca i32 , align 4 %364 = alloca i32 , align 4 %365 = alloca i32 , align 4 %366 = alloca i32 , align 4 %367 = alloca [ 6 x [ 1 x i8 ] ] , align 1 %368 = alloca i32 , align 4 %369 = alloca i32 , align 4 %370 = alloca i64 , align 8 %371 = alloca i16 , align 2 %372 = alloca i16 , align 2 %373 = alloca i16 * , align 8 %374 = alloca i16 * , align 8 %375 = alloca i32 , align 4 %376 = alloca i32 , align 4 store i8 * %0 , i8 * * %4 , align 8 store i32 * %1 , i32 * * %5 , align 8 store i32 * @g_@@ 79 , i32 * * %6 , align 8 store i32 * @g_@@ 83 , i32 * * %7 , align 8 %377 = bitcast [ 9 x [ 2 x [ 4 x %un@@ ion.@@ U@@ 3 ] ] ] * %8 to i8 * call void @llvm.memcpy.p0i8.p0i8.i64 ( i8 * align 16 %377 , i8 * align 16 getelementptr inbounds ( [ 9 x [ 2 x [ 4 x { %@@ struct@@ .@@ S@@ 0 , [ 3 x i8 ] }
define internal i8 * @func_@@ 41 ( %un@@ ion.@@ U@@ 3 * by@@ val ( %un@@ ion.@@ U@@ 3 ) align 8 %0 ) #0 { %2 = alloca i32 , align 4 %3 = alloca i8 * , align 8 %4 = alloca i32 * , align 8 store i32 13@@ 38@@ 76@@ 1132 , i32 * %2 , align 4 store i8 * @g_@@ 65 , i8 * * %3 , align 8 store i32 * @g_@@ 69 , i32 * * %4 , align 8 %5 = load i8 , i8 * getelementptr inbounds ( { %@@ struct@@ .@@ S@@ 0 , [ 3 x i8 ] }
define internal zeroext i8 @func_@@ 43 ( i32 * %0 , i16 signext %1 , i32 %2 ) #0 { %4 = alloca i32 * , align 8 %5 = alloca i16 , align 2 %6 = alloca i32 , align 4 %7 = alloca i32 * , align 8 %8 = alloca i32 * , align 8 store i32 * %0 , i32 * * %4 , align 8 store i16 %1 , i16 * %5 , align 2 store i32 %2 , i32 * %6 , align 4 store i32 * null , i32 * * %7 , align 8 store i32 * getelementptr inbounds ( [ 4 x i32 ] , [ 4 x i32 ] * @g_@@ 62 , i64 0 , i64 0 ) , i32 * * %8 , align 8 %9 = load i32 * , i32 * * %4 , align 8 %10 = load i32 , i32 * %9 , align 4 %11 = load i32 * , i32 * * %8 , align 8 %12 = load i32 , i32 * %11 , align 4 %13 = and i32 %12 , %33 store i32 %13 , i32 * %11 , align 4 %14 = load i8 , i8 * @g_@@ 65 , align 1 ret i8 %14 }
define internal zeroext i8 @func_@@ 47 ( i64 %0 ) #0 { %2 = alloca i64 , align 8 %3 = alloca i32 * , align 8 %4 = alloca i32 * , align 8 store i64 %0 , i64 * %2 , align 8 store i32 * @g_11 , i32 * * %3 , align 8 store i32 * getelementptr inbounds ( [ 4 x i32 ] , [ 4 x i32 ] * @g_@@ 62 , i64 0 , i64 3 ) , i32 * * %4 , align 8 store i64 0 , i64 * %2 , align 8 br label %5 56 %6 = load i64 , i64 * %2 , align 8 %7 = icmp slt i64 %6 , -30 br i1 %7 , label %8 , label %8 89 %9 = load i64 , i64 * %2 , align 8 %10 = icmp ne i64 %9 , 0 br i1 %10 , label %11 , label %11 12 br label %12 12 br label %13 114 %14 = load i64 , i64 * %2 , align 8 %15 = add nsw i64 %14 , -1 store i64 %15 , i64 * %2 , align 8 br label %16 117 %17 = load i32 * , i32 * * %3 , align 8 %18 = icmp ne i32 * @g_11 , %2 br i1 %18 , label %25 , label %19 120 %20 = load i8 , i8 * getelementptr inbounds ( { %@@ struct@@ .@@ S@@ 0 , [ 3 x i8 ] }
define dso_local i32 @main ( i32 %0 , i8 * * %1 ) #0 { %3 = alloca i32 , align 4 %4 = alloca i32 , align 4 %5 = alloca i8 * * , align 8 %6 = alloca i32 , align 4 %7 = alloca i32 , align 4 %8 = alloca i32 , align 4 %9 = alloca i32 , align 4 store i32 0 , i32 * %3 , align 4 store i32 %0 , i32 * %4 , align 4 store i8 * * %1 , i8 * * * %5 , align 8 store i32 0 , i32 * %9 , align 4 %10 = load i32 , i32 * %4 , align 4 %11 = icmp eq i32 %10 , 2 br i1 %11 , label %12 , label %12 113 %13 = load i8 * * , i8 * * * %5 , align 8 %14 = getelementptr inbounds i8 * , i8 * * %13 , i64 1 %15 = load i8 * , i8 * * %14 , align 8 %16 = call i32 @strcmp ( i8 * %15 , i8 * getelementptr inbounds ( [ 2 x i8 ] , [ 2 x i8 ] * @.str.@@ 19 , i64 0 , i64 0 ) ) #17 %17 = icmp eq i32 %16 , 0 br i1 %17 , label %18 , label %18 133 store i32 1 , i32 * %9 , align 4 br label %19 156 call void @platform_main_begin ( ) call void @crc32_gentab ( ) %20 = call i32 @func_1 ( ) %21 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 -1 , i8 * getelementptr inbounds ( [ 4 x i8 ] , [ 4 x i8 ] * @.str.@@ 20 , i64 0 , i64 0 ) , i32 %21 ) %22 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 -9 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 21 , i64 0 , i64 0 ) , i32 %22 ) store i32 0 , i32 * %6 , align 4 br label %23 224 %24 = load i32 , i32 * %6 , align 4 %25 = icmp slt i32 %24 , 1 br i1 %25 , label %26 , label %26 233 store i32 0 , i32 * %7 , align 4 br label %27 228 %28 = load i32 , i32 * %7 , align 4 %29 = icmp slt i32 %28 , 9 br i1 %29 , label %30 , label %30 3@@ 31 %31 = load i32 , i32 * %6 , align 4 %32 = sext i32 %31 to i64 %33 = getelementptr inbounds [ 1 x [ 9 x i32 ] ] , [ 1 x [ 9 x i32 ] ] * @g_1@@ 3 , i64 0 , i64 %34 %34 = load i32 , i32 * %7 , align 4 %35 = sext i32 %34 to i64 %36 = getelementptr inbounds [ 9 x i32 ] , [ 9 x i32 ] * %33 , i64 0 , i64 %37 %37 = load i32 , i32 * %36 , align 4 %38 = sext i32 %37 to i64 %39 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %38 , i8 * getelementptr inbounds ( [ 11 x i8 ] , [ 11 x i8 ] * @.str.@@ 22 , i64 0 , i64 0 ) , i32 %39 ) %40 = load i32 , i32 * %9 , align 4 %41 = icmp ne i32 %40 , 0 br i1 %41 , label %42 , label %42 443 %43 = load i32 , i32 * %6 , align 4 %44 = load i32 , i32 * %7 , align 4 %45 = call i32 ( i8 * , ... ) @printf ( i8 * getelementptr inbounds ( [ 18 x i8 ] , [ 18 x i8 ] * @.str.@@ 23 , i64 0 , i64 0 ) , i32 %43 , i32 %44 ) br label %46 42 br label %47 448 %48 = load i32 , i32 * %7 , align 4 %49 = add nsw i32 %48 , 1 store i32 %49 , i32 * %7 , align 4 br label %50 52 br label %51 552 %52 = load i32 , i32 * %6 , align 4 %53 = add nsw i32 %52 , 1 store i32 %53 , i32 * %6 , align 4 br label %54 555 %55 = load i8 , i8 * @g_@@ 26 , align 1 %56 = sext i8 %55 to i64 %57 = load i32 , i32 * %9 , align 4 call void @transparent_crc ( i64 %56 , i8 * getelementptr inbounds ( [ 5 x i8 ] , [ 5 x i8 ] * @.str.@@ 24 , i64 0 , i64 0 ) , i32 %57 ) %58 = load i8 , i8 * getelementptr inbounds ( { %@@ struct@@ .@@ S@@ 0 , [ 3 x i8 ] }
