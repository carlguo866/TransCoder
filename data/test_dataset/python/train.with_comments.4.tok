<DOCUMENT_ID="andyzsf/edx/tree/master/common/djangoapps/student/migrations/0020_add_test_center_user.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE # ▁ Adding ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . create_table ( ' student _ testcenteruser ' , ( ( ' id ' , self . gf ( ' django . db . models . fields . AutoField ' ) ( primary_key = True ) ) , ( ' user ' , self . gf ( ' django . db . models . fields . related . ForeignKey ' ) ( default = None , to = orm [ ' auth . User ' ] , unique = True ) ) , ( ' created _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now_add = True , db_index = True , blank = True ) ) , ( ' updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now = True , db_index = True , blank = True ) ) , ( ' user _ updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( db_index = True ) ) , ( ' candidate _ id ' , self . gf ( ' django . db . models . fields . IntegerField ' ) ( null = True , db_index = True ) ) , ( ' client _ candidate _ id ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' first _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , db_index = True ) ) , ( ' last _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' middle _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , blank = True ) ) , ( ' suffix ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 255 , blank = True ) ) , ( ' salutation ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ( ' address _ 1' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 ) ) , ( ' address _ 2' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' address _ 3' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' city ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 32 , db_index = True ) ) , ( ' state ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 20 , blank = True ) ) , ( ' postal _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 16 , blank = True ) ) , ( ' country ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' phone ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 ) ) , ( ' extension ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 8 , blank = True ) ) , ( ' phone _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' fax ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 , blank = True ) ) , ( ' fax _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , blank = True ) ) , ( ' company _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ) ) NEW_LINE db . send_create_signal ( ' student ' , [ ' TestCenterUser ' ] ) NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE # ▁ Deleting ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . delete_table ( ' student _ testcenteruser ' ) NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , ' auth . user ' : { ' Meta ' : { ' object _ name ' : ' User ' } , ' about ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' avatar _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' n ' " , ' max _ length ' : '1' } ) , ' bronze ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' consecutive _ days _ visit _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' country ' : ( ' django _ countries . fields . CountryField ' , [ ] , { ' max _ length ' : '2' , ' blank ' : ' True ' } ) , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' date _ of _ birth ' : ( ' django . db . models . fields . DateField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' display _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' email _ isvalid ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' email _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' null ' : ' True ' } ) , ' email _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' gold ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' gravatar ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' ignored _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' interesting _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' last _ seen ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' new _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' questions _ per _ page ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '10' } ) , ' real _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' reputation ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' default ' : '1' } ) , ' seen _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' show _ country ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' silver ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' status ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' w ' " , ' max _ length ' : '2' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) , ' website ' : ( ' django . db . models . fields . URLField ' , [ ] , { ' max _ length ' : '200' , ' blank ' : ' True ' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' student . courseenrollment ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' user ' , ▁ ' course _ id ' ) , ) " , ' object _ name ' : ' CourseEnrollment ' } , ' course _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " } ) } , ' student . pendingemailchange ' : { ' Meta ' : { ' object _ name ' : ' PendingEmailChange ' } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ email ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . pendingnamechange ' : { ' Meta ' : { ' object _ name ' : ' PendingNameChange ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' rationale ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '1024' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . registration ' : { ' Meta ' : { ' object _ name ' : ' Registration ' , ' db _ table ' : " ' auth _ registration ' " } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . testcenteruser ' : { ' Meta ' : { ' object _ name ' : ' TestCenterUser ' } , ' address _ 1' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' } ) , ' address _ 2' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' address _ 3' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' candidate _ id ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' null ' : ' True ' , ' db _ index ' : ' True ' } ) , ' city ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' client _ candidate _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' company _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' country ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' created _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' extension ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '8' , ' blank ' : ' True ' } ) , ' fax ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' , ' blank ' : ' True ' } ) , ' fax _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' middle _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' phone ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' } ) , ' phone _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' postal _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '16' , ' blank ' : ' True ' } ) , ' salutation ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' state ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '20' , ' blank ' : ' True ' } ) , ' suffix ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' default ' : ' None ' , ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) , ' user _ updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' student . userprofile ' : { ' Meta ' : { ' object _ name ' : ' UserProfile ' , ' db _ table ' : " ' auth _ userprofile ' " } , ' courseware ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' course . xml ' " , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' gender ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' goals ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' level _ of _ education ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' mailing _ address ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' profile ' " , ' unique ' : ' True ' , ' to ' : " orm [ ' auth . User ' ] " } ) , ' year _ of _ birth ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' student . usertestgroup ' : { ' Meta ' : { ' object _ name ' : ' UserTestGroup ' } , ' description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' users ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' db _ index ' : ' True ' , ' symmetrical ' : ' False ' } ) } } NEW_LINE complete_apps = [ ' student ' ] NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="ffantast/magnum/tree/master/magnum/tests/unit/objects/test_objects.py"> # ▁ Copyright ▁ 2015 ▁ IBM ▁ Corp . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM import datetime NEW_LINE import gettext NEW_LINE import iso8601 NEW_LINE import netaddr NEW_LINE from oslo_utils import timeutils NEW_LINE from oslo_versionedobjects import fields NEW_LINE from magnum . common import context as magnum_context NEW_LINE from magnum . common import exception NEW_LINE from magnum . objects import base NEW_LINE from magnum . objects import utils NEW_LINE from magnum . tests import base as test_base NEW_LINE gettext . install ( ' magnum ' ) NEW_LINE @ base . MagnumObjectRegistry . register NEW_LINE class MyObj ( base . MagnumObject ) : NEW_LINE INDENT VERSION = '1.0' NEW_LINE fields = { ' foo ' : fields . IntegerField ( ) , ' bar ' : fields . StringField ( ) , ' missing ' : fields . StringField ( ) , } NEW_LINE def obj_load_attr ( self , attrname ) : NEW_LINE INDENT setattr ( self , attrname , ' loaded ! ' ) NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def query ( cls , context ) : NEW_LINE INDENT obj = cls ( context ) NEW_LINE obj . foo = 1 NEW_LINE obj . bar = ' bar ' NEW_LINE obj . obj_reset_changes ( ) NEW_LINE return obj NEW_LINE DEDENT @ base . remotable NEW_LINE def marco ( self , context ) : NEW_LINE INDENT return ' polo ' NEW_LINE DEDENT @ base . remotable NEW_LINE def update_test ( self , context ) : NEW_LINE INDENT if context . project_id == ' alternate ' : NEW_LINE INDENT self . bar = ' alternate - context ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bar = ' updated ' NEW_LINE DEDENT DEDENT @ base . remotable NEW_LINE def save ( self , context ) : NEW_LINE INDENT self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def refresh ( self , context ) : NEW_LINE INDENT self . foo = 321 NEW_LINE self . bar = ' refreshed ' NEW_LINE self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def modify_save_modify ( self , context ) : NEW_LINE INDENT self . bar = ' meow ' NEW_LINE self . save ( ) NEW_LINE self . foo = 42 NEW_LINE DEDENT DEDENT class MyObj2 ( object ) : NEW_LINE INDENT @ classmethod NEW_LINE def obj_name ( cls ) : NEW_LINE INDENT return ' MyObj ' NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def get ( cls , * args , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class TestSubclassedObject ( MyObj ) : NEW_LINE INDENT fields = { ' new _ field ' : fields . StringField ( ) } NEW_LINE DEDENT class TestUtils ( test_base . TestCase ) : NEW_LINE INDENT def test_datetime_or_none ( self ) : NEW_LINE INDENT naive_dt = datetime . datetime . now ( ) NEW_LINE dt = timeutils . parse_isotime ( timeutils . isotime ( naive_dt ) ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , dt ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , naive_dt . replace ( tzinfo = iso8601 . iso8601 . Utc ( ) , microsecond = 0 ) ) NEW_LINE self . assertIsNone ( utils . datetime_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_none , ' foo ' ) NEW_LINE DEDENT def test_datetime_or_str_or_none ( self ) : NEW_LINE INDENT dts = timeutils . isotime ( ) NEW_LINE dt = timeutils . parse_isotime ( dts ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dt ) , dt ) NEW_LINE self . assertIsNone ( utils . datetime_or_str_or_none ( None ) ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dts ) , dt ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_str_or_none , ' foo ' ) NEW_LINE DEDENT def test_int_or_none ( self ) : NEW_LINE INDENT self . assertEqual ( utils . int_or_none ( 1 ) , 1 ) NEW_LINE self . assertEqual ( utils . int_or_none ( '1' ) , 1 ) NEW_LINE self . assertIsNone ( utils . int_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . int_or_none , ' foo ' ) NEW_LINE DEDENT def test_str_or_none ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT pass NEW_LINE DEDENT self . assertEqual ( utils . str_or_none ( ' foo ' ) , ' foo ' ) NEW_LINE self . assertEqual ( utils . str_or_none ( 1 ) , '1' ) NEW_LINE self . assertIsNone ( utils . str_or_none ( None ) ) NEW_LINE DEDENT def test_ip_or_none ( self ) : NEW_LINE INDENT ip4 = netaddr . IPAddress ( '1.2.3.4' , 4 ) NEW_LINE ip6 = netaddr . IPAddress ( '1 : : 2' , 6 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 4 ) ( '1.2.3.4' ) , ip4 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 6 ) ( '1 : : 2' ) , ip6 ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 4 ) ( None ) ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 6 ) ( None ) ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 4 ) , ' foo ' ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 6 ) , ' foo ' ) NEW_LINE DEDENT def test_dt_serializer ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT foo = utils . dt_serializer ( ' bar ' ) NEW_LINE DEDENT obj = Obj ( ) NEW_LINE obj . bar = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( '1955-11-05T00:00:00Z ' , obj . foo ( ) ) NEW_LINE obj . bar = None NEW_LINE self . assertIsNone ( obj . foo ( ) ) NEW_LINE obj . bar = ' foo ' NEW_LINE self . assertRaises ( AttributeError , obj . foo ) NEW_LINE DEDENT def test_dt_deserializer ( self ) : NEW_LINE INDENT dt = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( utils . dt_deserializer ( None , timeutils . isotime ( dt ) ) , dt ) NEW_LINE self . assertIsNone ( utils . dt_deserializer ( None , None ) ) NEW_LINE self . assertRaises ( ValueError , utils . dt_deserializer , None , ' foo ' ) NEW_LINE DEDENT DEDENT class _TestObject ( object ) : NEW_LINE INDENT def test_hydration_type_error ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : ' a ' } } NEW_LINE self . assertRaises ( ValueError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_hydration ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_hydration_bad_ns ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' foo ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE self . assertRaises ( exception . UnsupportedObjectError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_dehydration ( self ) : NEW_LINE INDENT expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_get_updates ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_object_property ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_object_property_type_error ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE def fail ( ) : NEW_LINE INDENT obj . foo = ' a ' NEW_LINE DEDENT self . assertRaises ( ValueError , fail ) NEW_LINE DEDENT def test_load ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE DEDENT def test_load_in_base ( self ) : NEW_LINE INDENT class Foo ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foobar ' : fields . IntegerField ( ) } NEW_LINE DEDENT obj = Foo ( self . context ) NEW_LINE # ▁ NOTE ( danms ) : ▁ Can ' t ▁ use ▁ assertRaisesRegexp ( ) ▁ because ▁ of ▁ py26 ENDCOM raised = False NEW_LINE try : NEW_LINE INDENT obj . foobar NEW_LINE DEDENT except NotImplementedError as ex : NEW_LINE INDENT raised = True NEW_LINE DEDENT self . assertTrue ( raised ) NEW_LINE self . assertTrue ( ' foobar ' in str ( ex ) ) NEW_LINE DEDENT def test_loaded_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' bar ' ] , ' magnum _ object . data ' : { ' foo ' : 1 , ' bar ' : ' loaded ! ' } } NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_changes_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE primitive = obj . obj_to_primitive ( ) NEW_LINE self . assertTrue ( ' magnum _ object . changes ' in primitive ) NEW_LINE obj2 = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj2 . obj_what_changed ( ) ) NEW_LINE obj2 . obj_reset_changes ( ) NEW_LINE self . assertEqual ( set ( ) , obj2 . obj_what_changed ( ) ) NEW_LINE DEDENT def test_unknown_objtype ( self ) : NEW_LINE INDENT self . assertRaises ( exception . UnsupportedObjectError , base . MagnumObject . obj_class_from_name , ' foo ' , '1.0' ) NEW_LINE DEDENT def test_with_alternate_context ( self ) : NEW_LINE INDENT context1 = magnum_context . RequestContext ( ' foo ' , ' foo ' ) NEW_LINE context2 = magnum_context . RequestContext ( ' bar ' , project_id = ' alternate ' ) NEW_LINE obj = MyObj . query ( context1 ) NEW_LINE obj . update_test ( context2 ) NEW_LINE self . assertEqual ( ' alternate - context ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_orphaned_object ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . _context = None NEW_LINE self . assertRaises ( exception . OrphanedObjectError , obj . update_test ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_1 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . update_test ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_2 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . save ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_3 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . refresh ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 321 , obj . foo ) NEW_LINE self . assertEqual ( ' refreshed ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_4 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . bar = ' something ' NEW_LINE self . assertEqual ( set ( [ ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . modify_save_modify ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 42 , obj . foo ) NEW_LINE self . assertEqual ( ' meow ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_static_result ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( ' bar ' , obj . bar ) NEW_LINE result = obj . marco ( ) NEW_LINE self . assertEqual ( ' polo ' , result ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_updates ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE obj . update_test ( ) NEW_LINE self . assertEqual ( ' updated ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_base_attributes ( self ) : NEW_LINE INDENT dt = datetime . datetime ( 1955 , 11 , 5 ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . created_at = dt NEW_LINE obj . updated_at = dt NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' created _ at ' , ' updated _ at ' ] , ' magnum _ object . data ' : { ' created _ at ' : timeutils . isotime ( dt ) , ' updated _ at ' : timeutils . isotime ( dt ) } } NEW_LINE actual = obj . obj_to_primitive ( ) NEW_LINE # ▁ magnum _ object . changes ▁ is ▁ built ▁ from ▁ a ▁ set ▁ and ▁ order ▁ is ▁ undefined ENDCOM self . assertEqual ( sorted ( expected [ ' magnum _ object . changes ' ] ) , sorted ( actual [ ' magnum _ object . changes ' ] ) ) NEW_LINE del expected [ ' magnum _ object . changes ' ] , actual [ ' magnum _ object . changes ' ] NEW_LINE self . assertEqual ( expected , actual ) NEW_LINE DEDENT def test_contains ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertFalse ( ' foo ' in obj ) NEW_LINE obj . foo = 1 NEW_LINE self . assertTrue ( ' foo ' in obj ) NEW_LINE self . assertFalse ( ' does _ not _ exist ' in obj ) NEW_LINE DEDENT def test_obj_attr_is_set ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertTrue ( obj . obj_attr_is_set ( ' foo ' ) ) NEW_LINE self . assertFalse ( obj . obj_attr_is_set ( ' bar ' ) ) NEW_LINE self . assertRaises ( AttributeError , obj . obj_attr_is_set , ' bang ' ) NEW_LINE DEDENT def test_get ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE # ▁ Foo ▁ has ▁ value , ▁ should ▁ not ▁ get ▁ the ▁ default ENDCOM self . assertEqual ( obj . get ( ' foo ' , 2 ) , 1 ) NEW_LINE # ▁ Foo ▁ has ▁ value , ▁ should ▁ return ▁ the ▁ value ▁ without ▁ error ENDCOM self . assertEqual ( obj . get ( ' foo ' ) , 1 ) NEW_LINE # ▁ Bar ▁ is ▁ not ▁ loaded , ▁ so ▁ we ▁ should ▁ get ▁ the ▁ default ENDCOM self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' not - loaded ' ) NEW_LINE # ▁ Bar ▁ without ▁ a ▁ default ▁ should ▁ lazy - load ENDCOM self . assertEqual ( obj . get ( ' bar ' ) , ' loaded ! ' ) NEW_LINE # ▁ Bar ▁ now ▁ has ▁ a ▁ default , ▁ but ▁ loaded ▁ value ▁ should ▁ be ▁ returned ENDCOM self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' loaded ! ' ) NEW_LINE # ▁ Invalid ▁ attribute ▁ should ▁ raise ▁ AttributeError ENDCOM self . assertRaises ( AttributeError , obj . get , ' nothing ' ) NEW_LINE # ▁ . . . even ▁ with ▁ a ▁ default ENDCOM self . assertRaises ( AttributeError , obj . get , ' nothing ' , 3 ) NEW_LINE DEDENT def test_object_inheritance ( self ) : NEW_LINE INDENT base_fields = list ( base . MagnumObject . fields . keys ( ) ) NEW_LINE myobj_fields = [ ' foo ' , ' bar ' , ' missing ' ] + base_fields NEW_LINE myobj3_fields = [ ' new _ field ' ] NEW_LINE self . assertTrue ( issubclass ( TestSubclassedObject , MyObj ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) , len ( MyObj . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) , set ( MyObj . fields . keys ( ) ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) + len ( myobj3_fields ) , len ( TestSubclassedObject . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) | set ( myobj3_fields ) , set ( TestSubclassedObject . fields . keys ( ) ) ) NEW_LINE DEDENT def test_get_changes ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_obj_fields ( self ) : NEW_LINE INDENT class TestObj ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foo ' : fields . IntegerField ( ) } NEW_LINE obj_extra_fields = [ ' bar ' ] NEW_LINE @ property NEW_LINE def bar ( self ) : NEW_LINE INDENT return ' this ▁ is ▁ bar ' NEW_LINE DEDENT DEDENT obj = TestObj ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' created _ at ' , ' updated _ at ' , ' foo ' , ' bar ' ] ) , set ( obj . obj_fields ) ) NEW_LINE DEDENT def test_obj_constructor ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 123 , bar = ' abc ' ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertEqual ( ' abc ' , obj . bar ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE DEDENT DEDENT class TestObjectSerializer ( test_base . TestCase ) : NEW_LINE INDENT def test_object_serialization ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE primitive = ser . serialize_entity ( self . context , obj ) NEW_LINE self . assertTrue ( ' magnum _ object . name ' in primitive ) NEW_LINE obj2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertIsInstance ( obj2 , MyObj ) NEW_LINE self . assertEqual ( self . context , obj2 . _context ) NEW_LINE DEDENT def test_object_serialization_iterables ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE for iterable in ( list , tuple , set ) : NEW_LINE INDENT thing = iterable ( [ obj ] ) NEW_LINE primitive = ser . serialize_entity ( self . context , thing ) NEW_LINE self . assertEqual ( 1 , len ( primitive ) ) NEW_LINE for item in primitive : NEW_LINE INDENT self . assertFalse ( isinstance ( item , base . MagnumObject ) ) NEW_LINE DEDENT thing2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertEqual ( 1 , len ( thing2 ) ) NEW_LINE for item in thing2 : NEW_LINE INDENT self . assertIsInstance ( item , MyObj ) NEW_LINE DEDENT DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="tangyiyong/odoo/tree/master/addons/mrp/wizard/stock_move.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ OpenERP , ▁ Open ▁ Source ▁ Management ▁ Solution ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2004-2010 ▁ Tiny ▁ SPRL ▁ ( < http : / / tiny . be > ) . ENDCOM # ▁ This ▁ program ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ as ENDCOM # ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ENDCOM # ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ this ▁ program . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM from openerp . osv import fields , osv NEW_LINE from openerp . tools import float_compare NEW_LINE from openerp . tools . translate import _ NEW_LINE import openerp . addons . decimal_precision as dp NEW_LINE class stock_move_consume ( osv . osv_memory ) : NEW_LINE INDENT _name = " stock . move . consume " NEW_LINE _description = " Consume ▁ Products " NEW_LINE _columns = { ' product _ id ' : fields . many2one ( ' product . product ' , ' Product ' , required = True , select = True ) , ' product _ qty ' : fields . float ( ' Quantity ' , digits_compute = dp . get_precision ( ' Product ▁ Unit ▁ of ▁ Measure ' ) , required = True ) , ' product _ uom ' : fields . many2one ( ' product . uom ' , ' Product ▁ Unit ▁ of ▁ Measure ' , required = True ) , ' location _ id ' : fields . many2one ( ' stock . location ' , ' Location ' , required = True ) , ' restrict _ lot _ id ' : fields . many2one ( ' stock . production . lot ' , ' Lot ' ) , } NEW_LINE # TOFIX : ▁ product _ uom ▁ should ▁ not ▁ have ▁ different ▁ category ▁ of ▁ default ▁ UOM ▁ of ▁ product . ▁ Qty ▁ should ▁ be ▁ convert ▁ into ▁ UOM ▁ of ▁ original ▁ move ▁ line ▁ before ▁ going ▁ in ▁ consume ▁ and ▁ scrap ENDCOM def default_get ( self , cr , uid , fields , context = None ) : NEW_LINE INDENT if context is None : NEW_LINE INDENT context = { } NEW_LINE DEDENT res = super ( stock_move_consume , self ) . default_get ( cr , uid , fields , context = context ) NEW_LINE move = self . pool . get ( ' stock . move ' ) . browse ( cr , uid , context [ ' active _ id ' ] , context = context ) NEW_LINE if ' product _ id ' in fields : NEW_LINE INDENT res . update ( { ' product _ id ' : move . product_id . id } ) NEW_LINE DEDENT if ' product _ uom ' in fields : NEW_LINE INDENT res . update ( { ' product _ uom ' : move . product_uom . id } ) NEW_LINE DEDENT if ' product _ qty ' in fields : NEW_LINE INDENT res . update ( { ' product _ qty ' : move . product_uom_qty } ) NEW_LINE DEDENT if ' location _ id ' in fields : NEW_LINE INDENT res . update ( { ' location _ id ' : move . location_id . id } ) NEW_LINE DEDENT return res NEW_LINE DEDENT def do_move_consume ( self , cr , uid , ids , context = None ) : NEW_LINE INDENT if context is None : NEW_LINE INDENT context = { } NEW_LINE DEDENT move_obj = self . pool . get ( ' stock . move ' ) NEW_LINE uom_obj = self . pool . get ( ' product . uom ' ) NEW_LINE production_obj = self . pool . get ( ' mrp . production ' ) NEW_LINE move_ids = context [ ' active _ ids ' ] NEW_LINE move = move_obj . browse ( cr , uid , move_ids [ 0 ] , context = context ) NEW_LINE production_id = move . raw_material_production_id . id NEW_LINE production = production_obj . browse ( cr , uid , production_id , context = context ) NEW_LINE precision = self . pool [ ' decimal . precision ' ] . precision_get ( cr , uid , ' Product ▁ Unit ▁ of ▁ Measure ' ) NEW_LINE for data in self . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT qty = uom_obj . _compute_qty ( cr , uid , data [ ' product _ uom ' ] . id , data . product_qty , data . product_id . uom_id . id ) NEW_LINE remaining_qty = move . product_qty - qty NEW_LINE # check ▁ for ▁ product ▁ quantity ▁ is ▁ less ▁ than ▁ previously ▁ planned ENDCOM if float_compare ( remaining_qty , 0 , precision_digits = precision ) >= 0 : NEW_LINE INDENT move_obj . action_consume ( cr , uid , move_ids , qty , data . location_id . id , restrict_lot_id = data . restrict_lot_id . id , context = context ) NEW_LINE DEDENT else : NEW_LINE INDENT consumed_qty = min ( move . product_qty , qty ) NEW_LINE new_moves = move_obj . action_consume ( cr , uid , move_ids , consumed_qty , data . location_id . id , restrict_lot_id = data . restrict_lot_id . id , context = context ) NEW_LINE # consumed ▁ more ▁ in ▁ wizard ▁ than ▁ previously ▁ planned ENDCOM extra_more_qty = qty - consumed_qty NEW_LINE # create ▁ new ▁ line ▁ for ▁ a ▁ remaining ▁ qty ▁ of ▁ the ▁ product ENDCOM extra_move_id = production_obj . _make_consume_line_from_data ( cr , uid , production , data . product_id , data . product_id . uom_id . id , extra_more_qty , False , 0 , context = context ) NEW_LINE move_obj . write ( cr , uid , [ extra_move_id ] , { ' restrict _ lot _ id ' : data . restrict_lot_id . id } , context = context ) NEW_LINE move_obj . action_done ( cr , uid , [ extra_move_id ] , context = context ) NEW_LINE DEDENT DEDENT return { ' type ' : ' ir . actions . act _ window _ close ' } NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="itsjeyd/edx-platform/tree/master/cms/djangoapps/contentstore/tests/test_import_draft_order.py"> """ STRNEWLINE Tests ▁ Draft ▁ import ▁ order . STRNEWLINE """ NEW_LINE from xmodule . modulestore . xml_importer import import_course_from_xml NEW_LINE from xmodule . modulestore . tests . django_utils import ModuleStoreTestCase NEW_LINE from xmodule . modulestore . django import modulestore NEW_LINE from django . conf import settings NEW_LINE TEST_DATA_DIR = settings . COMMON_TEST_DATA_ROOT NEW_LINE # ▁ This ▁ test ▁ is ▁ in ▁ the ▁ CMS ▁ module ▁ because ▁ the ▁ test ▁ configuration ▁ to ▁ use ▁ a ▁ draft ENDCOM # ▁ modulestore ▁ is ▁ dependent ▁ on ▁ django . ENDCOM class DraftReorderTestCase ( ModuleStoreTestCase ) : NEW_LINE INDENT def test_order ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Verify ▁ that ▁ drafts ▁ are ▁ imported ▁ in ▁ the ▁ correct ▁ order . STRNEWLINE ▁ """ NEW_LINE store = modulestore ( ) NEW_LINE course_items = import_course_from_xml ( store , self . user . id , TEST_DATA_DIR , [ ' import _ draft _ order ' ] , create_if_not_present = True ) NEW_LINE course_key = course_items [ 0 ] . id NEW_LINE sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , '0f4f7649b10141b0bdc9922dcf94515a ' ) ) NEW_LINE verticals = sequential . children NEW_LINE # ▁ The ▁ order ▁ that ▁ files ▁ are ▁ read ▁ in ▁ from ▁ the ▁ file ▁ system ▁ is ▁ not ▁ guaranteed ▁ ( cannot ▁ rely ▁ on ENDCOM # ▁ alphabetical ▁ ordering , ▁ for ▁ example ) . ▁ Therefore , ▁ I ▁ have ▁ added ▁ a ▁ lot ▁ of ▁ variation ▁ in ▁ filename ▁ and ▁ desired ENDCOM # ▁ ordering ▁ so ▁ that ▁ the ▁ test ▁ reliably ▁ failed ▁ with ▁ the ▁ bug , ▁ at ▁ least ▁ on ▁ Linux . ENDCOM # ▁ ' a ' , ▁ ' b ' , ▁ ' c ' , ▁ ' d ' , ▁ and ▁ ' z ' ▁ are ▁ all ▁ drafts , ▁ with ▁ ' index _ in _ children _ list ' ▁ of ENDCOM # ▁ 2 ▁ , ▁ 4 ▁ , ▁ 6 ▁ , ▁ 5 ▁ , ▁ and ▁ 0 ▁ respectively . ENDCOM # ▁ ' 5a05be9d59fc4bb79282c94c9e6b88c7 ' ▁ and ▁ ' second ' ▁ are ▁ public ▁ verticals . ENDCOM self . assertEqual ( 7 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' z ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , '5a05be9d59fc4bb79282c94c9e6b88c7' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' a ' ) , verticals [ 2 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' second ' ) , verticals [ 3 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' b ' ) , verticals [ 4 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' d ' ) , verticals [ 5 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' c ' ) , verticals [ 6 ] ) NEW_LINE # ▁ Now ▁ also ▁ test ▁ that ▁ the ▁ verticals ▁ in ▁ a ▁ second ▁ sequential ▁ are ▁ correct . ENDCOM sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , ' secondseq ' ) ) NEW_LINE verticals = sequential . children NEW_LINE # ▁ ' asecond ' ▁ and ▁ ' zsecond ' ▁ are ▁ drafts ▁ with ▁ ' index _ in _ children _ list ' ▁ 0 ▁ and ▁ 2 , ▁ respectively . ENDCOM # ▁ ' secondsubsection ' ▁ is ▁ a ▁ public ▁ vertical . ENDCOM self . assertEqual ( 3 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' asecond ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' secondsubsection ' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' zsecond ' ) , verticals [ 2 ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="mjtamlyn/django/tree/master/django/contrib/auth/hashers.py"> import base64 NEW_LINE import binascii NEW_LINE import functools NEW_LINE import hashlib NEW_LINE import importlib NEW_LINE import warnings NEW_LINE from collections import OrderedDict NEW_LINE from django . conf import settings NEW_LINE from django . core . exceptions import ImproperlyConfigured NEW_LINE from django . core . signals import setting_changed NEW_LINE from django . dispatch import receiver NEW_LINE from django . utils . crypto import ( constant_time_compare , get_random_string , pbkdf2 , ) NEW_LINE from django . utils . encoding import force_bytes , force_text NEW_LINE from django . utils . module_loading import import_string NEW_LINE from django . utils . translation import gettext_noop as _ NEW_LINE UNUSABLE_PASSWORD_PREFIX = ' ! ' # ▁ This ▁ will ▁ never ▁ be ▁ a ▁ valid ▁ encoded ▁ hash ENDCOM NEW_LINE UNUSABLE_PASSWORD_SUFFIX_LENGTH = 40 # ▁ number ▁ of ▁ random ▁ chars ▁ to ▁ add ▁ after ▁ UNUSABLE _ PASSWORD _ PREFIX ENDCOM NEW_LINE def is_password_usable ( encoded ) : NEW_LINE INDENT if encoded is None or encoded . startswith ( UNUSABLE_PASSWORD_PREFIX ) : NEW_LINE INDENT return False NEW_LINE DEDENT try : NEW_LINE INDENT identify_hasher ( encoded ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT def check_password ( password , encoded , setter = None , preferred = ' default ' ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ a ▁ boolean ▁ of ▁ whether ▁ the ▁ raw ▁ password ▁ matches ▁ the ▁ three STRNEWLINE ▁ part ▁ encoded ▁ digest . STRNEWLINE STRNEWLINE ▁ If ▁ setter ▁ is ▁ specified , ▁ it ' ll ▁ be ▁ called ▁ when ▁ you ▁ need ▁ to STRNEWLINE ▁ regenerate ▁ the ▁ password . STRNEWLINE ▁ """ NEW_LINE if password is None or not is_password_usable ( encoded ) : NEW_LINE INDENT return False NEW_LINE DEDENT preferred = get_hasher ( preferred ) NEW_LINE hasher = identify_hasher ( encoded ) NEW_LINE hasher_changed = hasher . algorithm != preferred . algorithm NEW_LINE must_update = hasher_changed or preferred . must_update ( encoded ) NEW_LINE is_correct = hasher . verify ( password , encoded ) NEW_LINE # ▁ If ▁ the ▁ hasher ▁ didn ' t ▁ change ▁ ( we ▁ don ' t ▁ protect ▁ against ▁ enumeration ▁ if ▁ it ENDCOM # ▁ does ) ▁ and ▁ the ▁ password ▁ should ▁ get ▁ updated , ▁ try ▁ to ▁ close ▁ the ▁ timing ▁ gap ENDCOM # ▁ between ▁ the ▁ work ▁ factor ▁ of ▁ the ▁ current ▁ encoded ▁ password ▁ and ▁ the ▁ default ENDCOM # ▁ work ▁ factor . ENDCOM if not is_correct and not hasher_changed and must_update : NEW_LINE INDENT hasher . harden_runtime ( password , encoded ) NEW_LINE DEDENT if setter and is_correct and must_update : NEW_LINE INDENT setter ( password ) NEW_LINE DEDENT return is_correct NEW_LINE DEDENT def make_password ( password , salt = None , hasher = ' default ' ) : NEW_LINE INDENT """ STRNEWLINE ▁ Turn ▁ a ▁ plain - text ▁ password ▁ into ▁ a ▁ hash ▁ for ▁ database ▁ storage STRNEWLINE STRNEWLINE ▁ Same ▁ as ▁ encode ( ) ▁ but ▁ generate ▁ a ▁ new ▁ random ▁ salt . ▁ If ▁ password ▁ is ▁ None ▁ then STRNEWLINE ▁ return ▁ a ▁ concatenation ▁ of ▁ UNUSABLE _ PASSWORD _ PREFIX ▁ and ▁ a ▁ random ▁ string , STRNEWLINE ▁ which ▁ disallows ▁ logins . ▁ Additional ▁ random ▁ string ▁ reduces ▁ chances ▁ of ▁ gaining STRNEWLINE ▁ access ▁ to ▁ staff ▁ or ▁ superuser ▁ accounts . ▁ See ▁ ticket ▁ # 20079 ▁ for ▁ more ▁ info . STRNEWLINE ▁ """ NEW_LINE if password is None : NEW_LINE INDENT return UNUSABLE_PASSWORD_PREFIX + get_random_string ( UNUSABLE_PASSWORD_SUFFIX_LENGTH ) NEW_LINE DEDENT hasher = get_hasher ( hasher ) NEW_LINE if not salt : NEW_LINE INDENT salt = hasher . salt ( ) NEW_LINE DEDENT return hasher . encode ( password , salt ) NEW_LINE DEDENT @ functools . lru_cache ( ) NEW_LINE def get_hashers ( ) : NEW_LINE INDENT hashers = [ ] NEW_LINE for hasher_path in settings . PASSWORD_HASHERS : NEW_LINE INDENT hasher_cls = import_string ( hasher_path ) NEW_LINE hasher = hasher_cls ( ) NEW_LINE if not getattr ( hasher , ' algorithm ' ) : NEW_LINE INDENT raise ImproperlyConfigured ( " hasher ▁ doesn ' t ▁ specify ▁ an ▁ " " algorithm ▁ name : ▁ % s " % hasher_path ) NEW_LINE DEDENT hashers . append ( hasher ) NEW_LINE DEDENT return hashers NEW_LINE DEDENT @ functools . lru_cache ( ) NEW_LINE def get_hashers_by_algorithm ( ) : NEW_LINE INDENT return { hasher . algorithm : hasher for hasher in get_hashers ( ) } NEW_LINE DEDENT @ receiver ( setting_changed ) NEW_LINE def reset_hashers ( ** kwargs ) : NEW_LINE INDENT if kwargs [ ' setting ' ] == ' PASSWORD _ HASHERS ' : NEW_LINE INDENT get_hashers . cache_clear ( ) NEW_LINE get_hashers_by_algorithm . cache_clear ( ) NEW_LINE DEDENT DEDENT def get_hasher ( algorithm = ' default ' ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ an ▁ instance ▁ of ▁ a ▁ loaded ▁ password ▁ hasher . STRNEWLINE STRNEWLINE ▁ If ▁ algorithm ▁ is ▁ ' default ' , ▁ return ▁ the ▁ default ▁ hasher . ▁ Lazily ▁ import ▁ hashers STRNEWLINE ▁ specified ▁ in ▁ the ▁ project ' s ▁ settings ▁ file ▁ if ▁ needed . STRNEWLINE ▁ """ NEW_LINE if hasattr ( algorithm , ' algorithm ' ) : NEW_LINE INDENT return algorithm NEW_LINE DEDENT elif algorithm == ' default ' : NEW_LINE INDENT return get_hashers ( ) [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT hashers = get_hashers_by_algorithm ( ) NEW_LINE try : NEW_LINE INDENT return hashers [ algorithm ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ValueError ( " Unknown ▁ password ▁ hashing ▁ algorithm ▁ ' % s ' . ▁ " " Did ▁ you ▁ specify ▁ it ▁ in ▁ the ▁ PASSWORD _ HASHERS ▁ " " setting ? " % algorithm ) NEW_LINE DEDENT DEDENT DEDENT def identify_hasher ( encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ an ▁ instance ▁ of ▁ a ▁ loaded ▁ password ▁ hasher . STRNEWLINE STRNEWLINE ▁ Identify ▁ hasher ▁ algorithm ▁ by ▁ examining ▁ encoded ▁ hash , ▁ and ▁ call STRNEWLINE ▁ get _ hasher ( ) ▁ to ▁ return ▁ hasher . ▁ Raise ▁ ValueError ▁ if STRNEWLINE ▁ algorithm ▁ cannot ▁ be ▁ identified , ▁ or ▁ if ▁ hasher ▁ is ▁ not ▁ loaded . STRNEWLINE ▁ """ NEW_LINE # ▁ Ancient ▁ versions ▁ of ▁ Django ▁ created ▁ plain ▁ MD5 ▁ passwords ▁ and ▁ accepted ENDCOM # ▁ MD5 ▁ passwords ▁ with ▁ an ▁ empty ▁ salt . ENDCOM if ( ( len ( encoded ) == 32 and ' $ ' not in encoded ) or ( len ( encoded ) == 37 and encoded . startswith ( ' md5 $ $ ' ) ) ) : NEW_LINE INDENT algorithm = ' unsalted _ md5' NEW_LINE # ▁ Ancient ▁ versions ▁ of ▁ Django ▁ accepted ▁ SHA1 ▁ passwords ▁ with ▁ an ▁ empty ▁ salt . ENDCOM DEDENT elif len ( encoded ) == 46 and encoded . startswith ( ' sha1 $ $ ' ) : NEW_LINE INDENT algorithm = ' unsalted _ sha1' NEW_LINE DEDENT else : NEW_LINE INDENT algorithm = encoded . split ( ' $ ' , 1 ) [ 0 ] NEW_LINE DEDENT return get_hasher ( algorithm ) NEW_LINE DEDENT def mask_hash ( hash , show = 6 , char = " * " ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ the ▁ given ▁ hash , ▁ with ▁ only ▁ the ▁ first ▁ ` ` show ` ` ▁ number ▁ shown . ▁ The STRNEWLINE ▁ rest ▁ are ▁ masked ▁ with ▁ ` ` char ` ` ▁ for ▁ security ▁ reasons . STRNEWLINE ▁ """ NEW_LINE masked = hash [ : show ] NEW_LINE masked += char * len ( hash [ show : ] ) NEW_LINE return masked NEW_LINE DEDENT class BasePasswordHasher : NEW_LINE INDENT """ STRNEWLINE ▁ Abstract ▁ base ▁ class ▁ for ▁ password ▁ hashers STRNEWLINE STRNEWLINE ▁ When ▁ creating ▁ your ▁ own ▁ hasher , ▁ you ▁ need ▁ to ▁ override ▁ algorithm , STRNEWLINE ▁ verify ( ) , ▁ encode ( ) ▁ and ▁ safe _ summary ( ) . STRNEWLINE STRNEWLINE ▁ PasswordHasher ▁ objects ▁ are ▁ immutable . STRNEWLINE ▁ """ NEW_LINE algorithm = None NEW_LINE library = None NEW_LINE def _load_library ( self ) : NEW_LINE INDENT if self . library is not None : NEW_LINE INDENT if isinstance ( self . library , ( tuple , list ) ) : NEW_LINE INDENT name , mod_path = self . library NEW_LINE DEDENT else : NEW_LINE INDENT mod_path = self . library NEW_LINE DEDENT try : NEW_LINE INDENT module = importlib . import_module ( mod_path ) NEW_LINE DEDENT except ImportError as e : NEW_LINE INDENT raise ValueError ( " Couldn ' t ▁ load ▁ % r ▁ algorithm ▁ library : ▁ % s " % ( self . __class__ . __name__ , e ) ) NEW_LINE DEDENT return module NEW_LINE DEDENT raise ValueError ( " Hasher ▁ % r ▁ doesn ' t ▁ specify ▁ a ▁ library ▁ attribute " % self . __class__ . __name__ ) NEW_LINE DEDENT def salt ( self ) : NEW_LINE INDENT """ Generate ▁ a ▁ cryptographically ▁ secure ▁ nonce ▁ salt ▁ in ▁ ASCII . """ NEW_LINE return get_random_string ( ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT """ Check ▁ if ▁ the ▁ given ▁ password ▁ is ▁ correct . """ NEW_LINE raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ a ▁ verify ( ) ▁ method ' ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ an ▁ encoded ▁ database ▁ value . STRNEWLINE STRNEWLINE ▁ The ▁ result ▁ is ▁ normally ▁ formatted ▁ as ▁ " algorithm $ salt $ hash " ▁ and STRNEWLINE ▁ must ▁ be ▁ fewer ▁ than ▁ 128 ▁ characters . STRNEWLINE ▁ """ NEW_LINE raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ an ▁ encode ( ) ▁ method ' ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ a ▁ summary ▁ of ▁ safe ▁ values . STRNEWLINE STRNEWLINE ▁ The ▁ result ▁ is ▁ a ▁ dictionary ▁ and ▁ will ▁ be ▁ used ▁ where ▁ the ▁ password ▁ field STRNEWLINE ▁ must ▁ be ▁ displayed ▁ to ▁ construct ▁ a ▁ safe ▁ representation ▁ of ▁ the ▁ password . STRNEWLINE ▁ """ NEW_LINE raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ a ▁ safe _ summary ( ) ▁ method ' ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT return False NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Bridge ▁ the ▁ runtime ▁ gap ▁ between ▁ the ▁ work ▁ factor ▁ supplied ▁ in ▁ ` encoded ` STRNEWLINE ▁ and ▁ the ▁ work ▁ factor ▁ suggested ▁ by ▁ this ▁ hasher . STRNEWLINE STRNEWLINE ▁ Taking ▁ PBKDF2 ▁ as ▁ an ▁ example , ▁ if ▁ ` encoded ` ▁ contains ▁ 20000 ▁ iterations ▁ and STRNEWLINE ▁ ` self . iterations ` ▁ is ▁ 30000 , ▁ this ▁ method ▁ should ▁ run ▁ password ▁ through STRNEWLINE ▁ another ▁ 10000 ▁ iterations ▁ of ▁ PBKDF2 . ▁ Similar ▁ approaches ▁ should ▁ exist STRNEWLINE ▁ for ▁ any ▁ hasher ▁ that ▁ has ▁ a ▁ work ▁ factor . ▁ If ▁ not , ▁ this ▁ method ▁ should ▁ be STRNEWLINE ▁ defined ▁ as ▁ a ▁ no - op ▁ to ▁ silence ▁ the ▁ warning . STRNEWLINE ▁ """ NEW_LINE warnings . warn ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ should ▁ provide ▁ a ▁ harden _ runtime ( ) ▁ method ' ) NEW_LINE DEDENT DEDENT class PBKDF2PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ PBKDF2 ▁ algorithm ▁ ( recommended ) STRNEWLINE STRNEWLINE ▁ Configured ▁ to ▁ use ▁ PBKDF2 ▁ + ▁ HMAC ▁ + ▁ SHA256 . STRNEWLINE ▁ The ▁ result ▁ is ▁ a ▁ 64 ▁ byte ▁ binary ▁ string . ▁ Iterations ▁ may ▁ be ▁ changed STRNEWLINE ▁ safely ▁ but ▁ you ▁ must ▁ rename ▁ the ▁ algorithm ▁ if ▁ you ▁ change ▁ SHA256 . STRNEWLINE ▁ """ NEW_LINE algorithm = " pbkdf2 _ sha256" NEW_LINE iterations = 100000 NEW_LINE digest = hashlib . sha256 NEW_LINE def encode ( self , password , salt , iterations = None ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE if not iterations : NEW_LINE INDENT iterations = self . iterations NEW_LINE DEDENT hash = pbkdf2 ( password , salt , iterations , digest = self . digest ) NEW_LINE hash = base64 . b64encode ( hash ) . decode ( ' ascii ' ) . strip ( ) NEW_LINE return " % s $ % d $ % s $ % s " % ( self . algorithm , iterations , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt , int ( iterations ) ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' iterations ' ) , iterations ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE return int ( iterations ) != self . iterations NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE extra_iterations = self . iterations - int ( iterations ) NEW_LINE if extra_iterations > 0 : NEW_LINE INDENT self . encode ( password , salt , extra_iterations ) NEW_LINE DEDENT DEDENT DEDENT class PBKDF2SHA1PasswordHasher ( PBKDF2PasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Alternate ▁ PBKDF2 ▁ hasher ▁ which ▁ uses ▁ SHA1 , ▁ the ▁ default ▁ PRF STRNEWLINE ▁ recommended ▁ by ▁ PKCS ▁ # 5 . ▁ This ▁ is ▁ compatible ▁ with ▁ other STRNEWLINE ▁ implementations ▁ of ▁ PBKDF2 , ▁ such ▁ as ▁ openssl ' s STRNEWLINE ▁ PKCS5 _ PBKDF2 _ HMAC _ SHA1 ( ) . STRNEWLINE ▁ """ NEW_LINE algorithm = " pbkdf2 _ sha1" NEW_LINE digest = hashlib . sha1 NEW_LINE DEDENT class Argon2PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ argon2 ▁ algorithm . STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ the ▁ winner ▁ of ▁ the ▁ Password ▁ Hashing ▁ Competition ▁ 2013-2015 STRNEWLINE ▁ ( https : / / password - hashing . net ) . ▁ It ▁ requires ▁ the ▁ argon2 - cffi ▁ library ▁ which STRNEWLINE ▁ depends ▁ on ▁ native ▁ C ▁ code ▁ and ▁ might ▁ cause ▁ portability ▁ issues . STRNEWLINE ▁ """ NEW_LINE algorithm = ' argon2' NEW_LINE library = ' argon2' NEW_LINE time_cost = 2 NEW_LINE memory_cost = 512 NEW_LINE parallelism = 2 NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT argon2 = self . _load_library ( ) NEW_LINE data = argon2 . low_level . hash_secret ( force_bytes ( password ) , force_bytes ( salt ) , time_cost = self . time_cost , memory_cost = self . memory_cost , parallelism = self . parallelism , hash_len = argon2 . DEFAULT_HASH_LENGTH , type = argon2 . low_level . Type . I , ) NEW_LINE return self . algorithm + data . decode ( ' ascii ' ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT argon2 = self . _load_library ( ) NEW_LINE algorithm , rest = encoded . split ( ' $ ' , 1 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE try : NEW_LINE INDENT return argon2 . low_level . verify_secret ( force_bytes ( ' $ ' + rest ) , force_bytes ( password ) , type = argon2 . low_level . Type . I , ) NEW_LINE DEDENT except argon2 . exceptions . VerificationError : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data ) = self . _decode ( encoded ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' variety ' ) , variety ) , ( _ ( ' version ' ) , version ) , ( _ ( ' memory ▁ cost ' ) , memory_cost ) , ( _ ( ' time ▁ cost ' ) , time_cost ) , ( _ ( ' parallelism ' ) , parallelism ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' hash ' ) , mask_hash ( data ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data ) = self . _decode ( encoded ) NEW_LINE assert algorithm == self . algorithm NEW_LINE argon2 = self . _load_library ( ) NEW_LINE return ( argon2 . low_level . ARGON2_VERSION != version or self . time_cost != time_cost or self . memory_cost != memory_cost or self . parallelism != parallelism ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE # ▁ The ▁ runtime ▁ for ▁ Argon2 ▁ is ▁ too ▁ complicated ▁ to ▁ implement ▁ a ▁ sensible ENDCOM # ▁ hardening ▁ algorithm . ENDCOM INDENT pass NEW_LINE DEDENT def _decode ( self , encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Split ▁ an ▁ encoded ▁ hash ▁ and ▁ return : ▁ ( STRNEWLINE ▁ algorithm , ▁ variety , ▁ version , ▁ time _ cost , ▁ memory _ cost , STRNEWLINE ▁ parallelism , ▁ salt , ▁ data , STRNEWLINE ▁ ) . STRNEWLINE ▁ """ NEW_LINE bits = encoded . split ( ' $ ' ) NEW_LINE if len ( bits ) == 5 : NEW_LINE # ▁ Argon2 ▁ < ▁ 1.3 ENDCOM INDENT algorithm , variety , raw_params , salt , data = bits NEW_LINE version = 0x10 NEW_LINE DEDENT else : NEW_LINE INDENT assert len ( bits ) == 6 NEW_LINE algorithm , variety , raw_version , raw_params , salt , data = bits NEW_LINE assert raw_version . startswith ( ' v = ' ) NEW_LINE version = int ( raw_version [ len ( ' v = ' ) : ] ) NEW_LINE DEDENT params = dict ( bit . split ( ' = ' , 1 ) for bit in raw_params . split ( ' , ' ) ) NEW_LINE assert len ( params ) == 3 and all ( x in params for x in ( ' t ' , ' m ' , ' p ' ) ) NEW_LINE time_cost = int ( params [ ' t ' ] ) NEW_LINE memory_cost = int ( params [ ' m ' ] ) NEW_LINE parallelism = int ( params [ ' p ' ] ) NEW_LINE return ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data , ) NEW_LINE DEDENT DEDENT class BCryptSHA256PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ bcrypt ▁ algorithm ▁ ( recommended ) STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ considered ▁ by ▁ many ▁ to ▁ be ▁ the ▁ most ▁ secure ▁ algorithm ▁ but ▁ you STRNEWLINE ▁ must ▁ first ▁ install ▁ the ▁ bcrypt ▁ library . ▁ Please ▁ be ▁ warned ▁ that STRNEWLINE ▁ this ▁ library ▁ depends ▁ on ▁ native ▁ C ▁ code ▁ and ▁ might ▁ cause ▁ portability STRNEWLINE ▁ issues . STRNEWLINE ▁ """ NEW_LINE algorithm = " bcrypt _ sha256" NEW_LINE digest = hashlib . sha256 NEW_LINE library = ( " bcrypt " , " bcrypt " ) NEW_LINE rounds = 12 NEW_LINE def salt ( self ) : NEW_LINE INDENT bcrypt = self . _load_library ( ) NEW_LINE return bcrypt . gensalt ( self . rounds ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT bcrypt = self . _load_library ( ) NEW_LINE # ▁ Hash ▁ the ▁ password ▁ prior ▁ to ▁ using ▁ bcrypt ▁ to ▁ prevent ▁ password ENDCOM # ▁ truncation ▁ as ▁ described ▁ in ▁ # 20138 . ENDCOM if self . digest is not None : NEW_LINE # ▁ Use ▁ binascii . hexlify ( ) ▁ because ▁ a ▁ hex ▁ encoded ▁ bytestring ▁ is ▁ str . ENDCOM INDENT password = binascii . hexlify ( self . digest ( force_bytes ( password ) ) . digest ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT password = force_bytes ( password ) NEW_LINE DEDENT data = bcrypt . hashpw ( password , salt ) NEW_LINE return " % s $ % s " % ( self . algorithm , force_text ( data ) ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , data = encoded . split ( ' $ ' , 1 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , force_bytes ( data ) ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , empty , algostr , work_factor , data = encoded . split ( ' $ ' , 4 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE salt , checksum = data [ : 22 ] , data [ 22 : ] NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' work ▁ factor ' ) , work_factor ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' checksum ' ) , mask_hash ( checksum ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT algorithm , empty , algostr , rounds , data = encoded . split ( ' $ ' , 4 ) NEW_LINE return int ( rounds ) != self . rounds NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT _ , data = encoded . split ( ' $ ' , 1 ) NEW_LINE salt = data [ : 29 ] # ▁ Length ▁ of ▁ the ▁ salt ▁ in ▁ bcrypt . ENDCOM NEW_LINE rounds = data . split ( ' $ ' ) [ 2 ] NEW_LINE # ▁ work ▁ factor ▁ is ▁ logarithmic , ▁ adding ▁ one ▁ doubles ▁ the ▁ load . ENDCOM diff = 2 ** ( self . rounds - int ( rounds ) ) - 1 NEW_LINE while diff > 0 : NEW_LINE INDENT self . encode ( password , force_bytes ( salt ) ) NEW_LINE diff -= 1 NEW_LINE DEDENT DEDENT DEDENT class BCryptPasswordHasher ( BCryptSHA256PasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ bcrypt ▁ algorithm STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ considered ▁ by ▁ many ▁ to ▁ be ▁ the ▁ most ▁ secure ▁ algorithm ▁ but ▁ you STRNEWLINE ▁ must ▁ first ▁ install ▁ the ▁ bcrypt ▁ library . ▁ Please ▁ be ▁ warned ▁ that STRNEWLINE ▁ this ▁ library ▁ depends ▁ on ▁ native ▁ C ▁ code ▁ and ▁ might ▁ cause ▁ portability STRNEWLINE ▁ issues . STRNEWLINE STRNEWLINE ▁ This ▁ hasher ▁ does ▁ not ▁ first ▁ hash ▁ the ▁ password ▁ which ▁ means ▁ it ▁ is ▁ subject ▁ to STRNEWLINE ▁ the ▁ 72 ▁ character ▁ bcrypt ▁ password ▁ truncation , ▁ most ▁ use ▁ cases ▁ should ▁ prefer STRNEWLINE ▁ the ▁ BCryptSHA256PasswordHasher . STRNEWLINE STRNEWLINE ▁ See : ▁ https : / / code . djangoproject . com / ticket / 20138 STRNEWLINE ▁ """ NEW_LINE algorithm = " bcrypt " NEW_LINE digest = None NEW_LINE DEDENT class SHA1PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ SHA1 ▁ password ▁ hashing ▁ algorithm ▁ ( not ▁ recommended ) STRNEWLINE ▁ """ NEW_LINE algorithm = " sha1" NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE hash = hashlib . sha1 ( force_bytes ( salt + password ) ) . hexdigest ( ) NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , mask_hash ( salt , show = 2 ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class MD5PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ Salted ▁ MD5 ▁ password ▁ hashing ▁ algorithm ▁ ( not ▁ recommended ) STRNEWLINE ▁ """ NEW_LINE algorithm = " md5" NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE hash = hashlib . md5 ( force_bytes ( salt + password ) ) . hexdigest ( ) NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , mask_hash ( salt , show = 2 ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class UnsaltedSHA1PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Very ▁ insecure ▁ algorithm ▁ that ▁ you ▁ should ▁ * never * ▁ use ; ▁ store ▁ SHA1 ▁ hashes STRNEWLINE ▁ with ▁ an ▁ empty ▁ salt . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ is ▁ implemented ▁ because ▁ Django ▁ used ▁ to ▁ accept ▁ such ▁ password STRNEWLINE ▁ hashes . ▁ Some ▁ older ▁ Django ▁ installs ▁ still ▁ have ▁ these ▁ values ▁ lingering STRNEWLINE ▁ around ▁ so ▁ we ▁ need ▁ to ▁ handle ▁ and ▁ upgrade ▁ them ▁ properly . STRNEWLINE ▁ """ NEW_LINE algorithm = " unsalted _ sha1" NEW_LINE def salt ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT assert salt == ' ' NEW_LINE hash = hashlib . sha1 ( force_bytes ( password ) ) . hexdigest ( ) NEW_LINE return ' sha1 $ $ % s ' % hash NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT encoded_2 = self . encode ( password , ' ' ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT assert encoded . startswith ( ' sha1 $ $ ' ) NEW_LINE hash = encoded [ 6 : ] NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , self . algorithm ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class UnsaltedMD5PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Incredibly ▁ insecure ▁ algorithm ▁ that ▁ you ▁ should ▁ * never * ▁ use ; ▁ stores ▁ unsalted STRNEWLINE ▁ MD5 ▁ hashes ▁ without ▁ the ▁ algorithm ▁ prefix , ▁ also ▁ accepts ▁ MD5 ▁ hashes ▁ with ▁ an STRNEWLINE ▁ empty ▁ salt . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ is ▁ implemented ▁ because ▁ Django ▁ used ▁ to ▁ store ▁ passwords ▁ this ▁ way STRNEWLINE ▁ and ▁ to ▁ accept ▁ such ▁ password ▁ hashes . ▁ Some ▁ older ▁ Django ▁ installs ▁ still ▁ have STRNEWLINE ▁ these ▁ values ▁ lingering ▁ around ▁ so ▁ we ▁ need ▁ to ▁ handle ▁ and ▁ upgrade ▁ them STRNEWLINE ▁ properly . STRNEWLINE ▁ """ NEW_LINE algorithm = " unsalted _ md5" NEW_LINE def salt ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT assert salt == ' ' NEW_LINE return hashlib . md5 ( force_bytes ( password ) ) . hexdigest ( ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT if len ( encoded ) == 37 and encoded . startswith ( ' md5 $ $ ' ) : NEW_LINE INDENT encoded = encoded [ 5 : ] NEW_LINE DEDENT encoded_2 = self . encode ( password , ' ' ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT return OrderedDict ( [ ( _ ( ' algorithm ' ) , self . algorithm ) , ( _ ( ' hash ' ) , mask_hash ( encoded , show = 3 ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class CryptPasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Password ▁ hashing ▁ using ▁ UNIX ▁ crypt ▁ ( not ▁ recommended ) STRNEWLINE STRNEWLINE ▁ The ▁ crypt ▁ module ▁ is ▁ not ▁ supported ▁ on ▁ all ▁ platforms . STRNEWLINE ▁ """ NEW_LINE algorithm = " crypt " NEW_LINE library = " crypt " NEW_LINE def salt ( self ) : NEW_LINE INDENT return get_random_string ( 2 ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT crypt = self . _load_library ( ) NEW_LINE assert len ( salt ) == 2 NEW_LINE data = crypt . crypt ( password , salt ) NEW_LINE assert data is not None # ▁ A ▁ platform ▁ like ▁ OpenBSD ▁ with ▁ a ▁ dummy ▁ crypt ▁ module . ENDCOM NEW_LINE # ▁ we ▁ don ' t ▁ need ▁ to ▁ store ▁ the ▁ salt , ▁ but ▁ Django ▁ used ▁ to ▁ do ▁ this ENDCOM return " % s $ % s $ % s " % ( self . algorithm , ' ' , data ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT crypt = self . _load_library ( ) NEW_LINE algorithm , salt , data = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return constant_time_compare ( data , crypt . crypt ( password , data ) ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , data = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , salt ) , ( _ ( ' hash ' ) , mask_hash ( data , show = 3 ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="helenst/django/tree/master/django/contrib/gis/db/backends/mysql/introspection.py"> from MySQLdb . constants import FIELD_TYPE NEW_LINE from django . contrib . gis . gdal import OGRGeomType NEW_LINE from django . db . backends . mysql . introspection import DatabaseIntrospection NEW_LINE class MySQLIntrospection ( DatabaseIntrospection ) : NEW_LINE # ▁ Updating ▁ the ▁ data _ types _ reverse ▁ dictionary ▁ with ▁ the ▁ appropriate ENDCOM # ▁ type ▁ for ▁ Geometry ▁ fields . ENDCOM INDENT data_types_reverse = DatabaseIntrospection . data_types_reverse . copy ( ) NEW_LINE data_types_reverse [ FIELD_TYPE . GEOMETRY ] = ' GeometryField ' NEW_LINE def get_geometry_type ( self , table_name , geo_col ) : NEW_LINE INDENT cursor = self . connection . cursor ( ) NEW_LINE try : NEW_LINE # ▁ In ▁ order ▁ to ▁ get ▁ the ▁ specific ▁ geometry ▁ type ▁ of ▁ the ▁ field , ENDCOM # ▁ we ▁ introspect ▁ on ▁ the ▁ table ▁ definition ▁ using ▁ ` DESCRIBE ` . ENDCOM INDENT cursor . execute ( ' DESCRIBE ▁ % s ' % self . connection . ops . quote_name ( table_name ) ) NEW_LINE # ▁ Increment ▁ over ▁ description ▁ info ▁ until ▁ we ▁ get ▁ to ▁ the ▁ geometry ENDCOM # ▁ column . ENDCOM for column , typ , null , key , default , extra in cursor . fetchall ( ) : NEW_LINE INDENT if column == geo_col : NEW_LINE # ▁ Using ▁ OGRGeomType ▁ to ▁ convert ▁ from ▁ OGC ▁ name ▁ to ▁ Django ▁ field . ENDCOM # ▁ MySQL ▁ does ▁ not ▁ support ▁ 3D ▁ or ▁ SRIDs , ▁ so ▁ the ▁ field ▁ params ENDCOM # ▁ are ▁ empty . ENDCOM INDENT field_type = OGRGeomType ( typ ) . django NEW_LINE field_params = { } NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT finally : NEW_LINE INDENT cursor . close ( ) NEW_LINE DEDENT return field_type , field_params NEW_LINE DEDENT def supports_spatial_index ( self , cursor , table_name ) : NEW_LINE # ▁ Supported ▁ with ▁ MyISAM , ▁ or ▁ InnoDB ▁ on ▁ MySQL ▁ 5.7.5 + ENDCOM INDENT storage_engine = self . get_storage_engine ( cursor , table_name ) NEW_LINE return ( ( storage_engine == ' InnoDB ' and self . connection . mysql_version >= ( 5 , 7 , 5 ) ) or storage_engine == ' MyISAM ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="BhallaLab/moose/tree/master/moose-examples/passive/passive_soma.py"> """ ▁ passive _ soma . py : ▁ STRNEWLINE STRNEWLINE In ▁ this ▁ script , ▁ we ▁ simulate ▁ a ▁ single ▁ compartment ▁ soma ▁ in ▁ MOOSE . STRNEWLINE STRNEWLINE This ▁ soma ▁ does ▁ not ▁ have ▁ any ▁ ion - channels , ▁ only ▁ passive ▁ properties . ▁ It ▁ should STRNEWLINE behave ▁ like ▁ a ▁ RC ▁ circuit . ▁ A ▁ current ▁ is ▁ injected ▁ into ▁ soma . STRNEWLINE STRNEWLINE """ NEW_LINE __author__ = " Dilawar ▁ Singh " NEW_LINE __copyright__ = " Copyright ▁ 2015 , ▁ Dilawar ▁ Singh ▁ and ▁ NCBS ▁ Bangalore " NEW_LINE __credits__ = [ " NCBS ▁ Bangalore " ] NEW_LINE __license__ = " GNU ▁ GPL " NEW_LINE __version__ = "1.0.0" NEW_LINE __maintainer__ = " Dilawar ▁ Singh " NEW_LINE __email__ = " dilawars @ ncbs . res . in " NEW_LINE __status__ = " Development " NEW_LINE import moose NEW_LINE import pylab NEW_LINE model = None NEW_LINE soma = None NEW_LINE vmtab = None NEW_LINE def buildModel ( ) : NEW_LINE INDENT global model NEW_LINE global soma NEW_LINE model = moose . Neutral ( ' / model ' ) NEW_LINE soma = moose . Compartment ( ' / model / soma ' ) NEW_LINE soma . Em = - 60e-3 NEW_LINE soma . Rm = 1e10 NEW_LINE soma . Cm = 1e-10 NEW_LINE return model NEW_LINE DEDENT def stimulus ( ) : NEW_LINE INDENT global soma NEW_LINE global vmtab NEW_LINE pulse = moose . PulseGen ( ' / model / pulse ' ) NEW_LINE pulse . delay [ 0 ] = 50e-3 NEW_LINE pulse . width [ 0 ] = 100e-3 NEW_LINE pulse . level [ 0 ] = 1e-9 NEW_LINE pulse . delay [ 1 ] = 1e9 NEW_LINE vmtab = moose . Table ( ' / soma _ Vm ' ) NEW_LINE moose . connect ( pulse , ' output ' , soma , ' injectMsg ' ) NEW_LINE moose . connect ( vmtab , ' requestOut ' , soma , ' getVm ' ) NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT global vmtab NEW_LINE buildModel ( ) NEW_LINE stimulus ( ) NEW_LINE moose . reinit ( ) NEW_LINE t = 500e-2 NEW_LINE moose . start ( t ) NEW_LINE time_vector = pylab . linspace ( 0 , t , len ( vmtab . vector ) ) NEW_LINE pylab . plot ( time_vector , vmtab . vector ) NEW_LINE pylab . show ( ) NEW_LINE # ▁ pylab . savefig ( ' soma _ passive . png ' ) ENDCOM DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="lordmos/blink/tree/master/Tools/TestResultServer/model/jsonresults_unittest.py"> # ▁ Copyright ▁ ( C ) ▁ 2010 ▁ Google ▁ Inc . ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ are ENDCOM # ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ENDCOM # ▁ copyright ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ENDCOM # ▁ in ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ENDCOM # ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ Google ▁ Inc . ▁ nor ▁ the ▁ names ▁ of ▁ its ENDCOM # ▁ contributors ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ENDCOM # ▁ this ▁ software ▁ without ▁ specific ▁ prior ▁ written ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ FOR ENDCOM # ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ COPYRIGHT ENDCOM # ▁ OWNER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ▁ INCIDENTAL , ENDCOM # ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ENDCOM # ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ENDCOM # ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ENDCOM # ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ▁ ARISING ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ENDCOM # ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM try : NEW_LINE INDENT import jsonresults NEW_LINE from jsonresults import * NEW_LINE DEDENT except ImportError : NEW_LINE INDENT print " ERROR : ▁ Add ▁ the ▁ TestResultServer , ▁ google _ appengine ▁ and ▁ yaml / lib ▁ directories ▁ to ▁ your ▁ PYTHONPATH " NEW_LINE raise NEW_LINE DEDENT import json NEW_LINE import logging NEW_LINE import unittest NEW_LINE FULL_RESULT_EXAMPLE = """ ADD _ RESULTS ( { STRNEWLINE ▁ ▁ ▁ ▁ " seconds _ since _ epoch " : ▁ 1368146629 , STRNEWLINE ▁ ▁ ▁ ▁ " tests " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - events . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " bugs " : ▁ [ " crbug . com / 1234 " ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - syntax . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " progress - events - generated - correctly . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " W3C " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " audio " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 3.5 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " video " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " notrun . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " NOTRUN " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - skip . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - fail . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " flaky - failed . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media - document - audio - repaint . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 0.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " skipped " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ regressions " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " build _ number " : ▁ " 3 " , STRNEWLINE ▁ ▁ ▁ ▁ " interrupted " : ▁ false , STRNEWLINE ▁ ▁ ▁ ▁ " layout _ tests _ dir " : ▁ " \ / tmp\ / cr\ / src\ / third _ party\ / WebKit\ / LayoutTests " , STRNEWLINE ▁ ▁ ▁ ▁ " version " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ " builder _ name " : ▁ " Webkit " , STRNEWLINE ▁ ▁ ▁ ▁ " num _ passes " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ " pixel _ tests _ enabled " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " blink _ revision " : ▁ " 1234 " , STRNEWLINE ▁ ▁ ▁ ▁ " has _ pretty _ patch " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " fixable " : ▁ 25 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ flaky " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ failures _ by _ type " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " CRASH " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " MISSING " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TEXT " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE " : ▁ 1 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " PASS " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " SKIP " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TIMEOUT " : ▁ 16 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE + TEXT " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " FAIL " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " AUDIO " : ▁ 0 STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " has _ wdiff " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " chromium _ revision " : ▁ " 5678 " STRNEWLINE } ) ; """ NEW_LINE JSON_RESULTS_OLD_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " allFixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " fixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " fixableCounts " : [ [ TESTDATA _ COUNTS ] ] , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' " version " : [ VERSION ] ' ' } ' ) % json . dumps ( CHAR_TO_FAILURE ) JSON_RESULTS_COUNTS = ' { " ' + ' " : [ [ TESTDATA _ COUNT ] ] , " ' . join ( [ char for char in CHAR_TO_FAILURE . values ( ) ] ) + ' " : [ [ TESTDATA _ COUNT ] ] } ' NEW_LINE JSON_RESULTS_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " num _ failures _ by _ type " : % s , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' " version " : [ VERSION ] ' ' } ' ) % ( json . dumps ( CHAR_TO_FAILURE ) , JSON_RESULTS_COUNTS ) JSON_RESULTS_COUNTS_TEMPLATE = ' { " ' + ' " : [ TESTDATA ] , " ' . join ( [ char for char in CHAR_TO_FAILURE ] ) + ' " : [ TESTDATA ] } ' NEW_LINE JSON_RESULTS_TEST_LIST_TEMPLATE = ' { " Webkit " : { " tests " : { [ TESTDATA _ TESTS ] } } } ' NEW_LINE class MockFile ( object ) : NEW_LINE INDENT def __init__ ( self , name = ' results . json ' , data = ' ' ) : NEW_LINE INDENT self . master = ' MockMasterName ' NEW_LINE self . builder = ' MockBuilderName ' NEW_LINE self . test_type = ' MockTestType ' NEW_LINE self . name = name NEW_LINE self . data = data NEW_LINE DEDENT def save ( self , data ) : NEW_LINE INDENT self . data = data NEW_LINE return True NEW_LINE DEDENT DEDENT class JsonResultsTest ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . _builder = " Webkit " NEW_LINE self . old_log_level = logging . root . level NEW_LINE logging . root . setLevel ( logging . ERROR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT logging . root . setLevel ( self . old_log_level ) NEW_LINE # ▁ Use ▁ this ▁ to ▁ get ▁ better ▁ error ▁ messages ▁ than ▁ just ▁ string ▁ compare ▁ gives . ENDCOM DEDENT def assert_json_equal ( self , a , b ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE a = json . loads ( a ) if isinstance ( a , str ) else a NEW_LINE b = json . loads ( b ) if isinstance ( b , str ) else b NEW_LINE self . assertEqual ( a , b ) NEW_LINE DEDENT def test_strip_prefix_suffix ( self ) : NEW_LINE INDENT json = " [ ' contents ' ] " NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( " ADD _ RESULTS ( " + json + " ) ; " ) , json ) NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( json ) , json ) NEW_LINE DEDENT def _make_test_json ( self , test_data , json_string = JSON_RESULTS_TEMPLATE , builder_name = " Webkit " ) : NEW_LINE INDENT if not test_data : NEW_LINE INDENT return " " NEW_LINE DEDENT builds = test_data [ " builds " ] NEW_LINE tests = test_data [ " tests " ] NEW_LINE if not builds or not tests : NEW_LINE INDENT return " " NEW_LINE DEDENT counts = [ ] NEW_LINE build_numbers = [ ] NEW_LINE webkit_revision = [ ] NEW_LINE chrome_revision = [ ] NEW_LINE times = [ ] NEW_LINE for build in builds : NEW_LINE INDENT counts . append ( JSON_RESULTS_COUNTS_TEMPLATE . replace ( " [ TESTDATA ] " , build ) ) NEW_LINE build_numbers . append ( "1000 % s " % build ) NEW_LINE webkit_revision . append ( "2000 % s " % build ) NEW_LINE chrome_revision . append ( "3000 % s " % build ) NEW_LINE times . append ( "100000 % s000" % build ) NEW_LINE DEDENT json_string = json_string . replace ( " [ BUILDER _ NAME ] " , builder_name ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNTS ] " , " , " . join ( counts ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNT ] " , " , " . join ( builds ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ BUILDNUMBERS ] " , " , " . join ( build_numbers ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ WEBKITREVISION ] " , " , " . join ( webkit_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ CHROMEREVISION ] " , " , " . join ( chrome_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ TIMES ] " , " , " . join ( times ) ) NEW_LINE version = str ( test_data [ " version " ] ) if " version " in test_data else "4" NEW_LINE json_string = json_string . replace ( " [ VERSION ] " , version ) NEW_LINE json_string = json_string . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( tests , separators = ( ' , ' , ' : ' ) , sort_keys = True ) ) NEW_LINE return json_string NEW_LINE DEDENT def _test_merge ( self , aggregated_data , incremental_data , expected_data , max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( aggregated_data , builder_name = self . _builder ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data , builder_name = self . _builder ) , is_full_results_format = False ) NEW_LINE merged_results , status_code = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = max_builds , sort_keys = True ) NEW_LINE if expected_data : NEW_LINE INDENT expected_results = self . _make_test_json ( expected_data , builder_name = self . _builder ) NEW_LINE self . assert_json_equal ( merged_results , expected_results ) NEW_LINE self . assertEqual ( status_code , 200 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertTrue ( status_code != 200 ) NEW_LINE DEDENT DEDENT def _test_get_test_list ( self , input_data , expected_data ) : NEW_LINE INDENT input_results = self . _make_test_json ( input_data ) NEW_LINE expected_results = JSON_RESULTS_TEST_LIST_TEMPLATE . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( expected_data , separators = ( ' , ' , ' : ' ) ) ) NEW_LINE actual_results = JsonResults . get_test_list ( self . _builder , input_results ) NEW_LINE self . assert_json_equal ( actual_results , expected_results ) NEW_LINE DEDENT def test_update_files_empty_aggregate_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertTrue ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) ) NEW_LINE self . assert_json_equal ( small_file . data , incremental_string ) NEW_LINE self . assert_json_equal ( large_file . data , incremental_string ) NEW_LINE DEDENT def test_update_files_null_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_string = " " NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_update_files_empty_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_data = { " builds " : [ ] , " tests " : { } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_merge_with_empty_aggregated_results ( self ) : NEW_LINE INDENT incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_results , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data ) , is_full_results_format = False ) NEW_LINE aggregated_results = " " NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_results , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , incremental_results ) NEW_LINE DEDENT def test_failures_by_type_added ( self ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 200 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_results = self . _make_test_json ( { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , incremental_results , is_full_results_format = False ) NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = 201 , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , self . _make_test_json ( { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 101 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 201 , 0 ] ] , } } } ) ) NEW_LINE DEDENT def test_merge_full_results_format ( self ) : NEW_LINE INDENT expected_incremental_results = { " Webkit " : { " blinkRevision " : [ "1234" ] , " buildNumbers " : [ "3" ] , " chromeRevision " : [ "5678" ] , " failure _ map " : CHAR_TO_FAILURE , " num _ failures _ by _ type " : { " AUDIO " : [ 0 ] , " CRASH " : [ 3 ] , " FAIL " : [ 2 ] , " IMAGE " : [ 1 ] , " IMAGE + TEXT " : [ 0 ] , " MISSING " : [ 0 ] , " PASS " : [ 10 ] , " SKIP " : [ 2 ] , " TEXT " : [ 3 ] , " TIMEOUT " : [ 16 ] } , " secondsSinceEpoch " : [ 1368146629 ] , " tests " : { " media " : { " W3C " : { " audio " : { " src " : { " src _ removal _ does _ not _ trigger _ loadstart . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 4 ] ] , } } } } , " encrypted - media " : { " encrypted - media - v2 - events . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " encrypted - media - v2 - syntax . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 0 ] ] , } } , " media - document - audio - repaint . html " : { " expected " : " IMAGE " , " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] , } , " progress - events - generated - correctly . html " : { " expected " : " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " flaky - failed . html " : { " expected " : " PASS ▁ FAIL " , " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , " unexpected - fail . html " : { " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , } } } , " version " : 4 } NEW_LINE aggregated_results = " " NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , FULL_RESULT_EXAMPLE , is_full_results_format = True ) NEW_LINE merged_results , _ = JsonResults . merge ( " Webkit " , aggregated_results , incremental_json , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , expected_incremental_results ) NEW_LINE DEDENT def test_merge_empty_aggregated_results ( self ) : NEW_LINE # ▁ No ▁ existing ▁ aggregated ▁ results . ENDCOM # ▁ Merged ▁ results ▁ = = ▁ new ▁ incremental ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM None , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Expected ▁ result ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_duplicate_build_number ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] ] , " times " : [ [ 100 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM None ) NEW_LINE DEDENT def test_merge_incremental_single_test_single_run_same_result ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ and ▁ same ▁ test ▁ results ▁ for ENDCOM # ▁ that ▁ run . ENDCOM # ▁ Insert ▁ the ▁ incremental ▁ results ▁ at ▁ the ▁ first ▁ place ▁ and ▁ sum ▁ number ENDCOM # ▁ of ▁ runs ▁ for ▁ TEXT ▁ ( 200 ▁ + ▁ 1 ) ▁ to ▁ get ▁ merged ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_different_result ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ but ▁ different ▁ test ▁ results ENDCOM # ▁ for ▁ that ▁ run . ENDCOM # ▁ Insert ▁ the ▁ incremental ▁ results ▁ at ▁ the ▁ first ▁ place . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_result_changed ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ but ▁ results ▁ which ▁ differ ▁ from ENDCOM # ▁ the ▁ latest ▁ result ▁ ( but ▁ are ▁ the ▁ same ▁ as ▁ an ▁ older ▁ result ) . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 200 , 0 ] , [ 10 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] , [ 10 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run ( self ) : NEW_LINE # ▁ All ▁ tests ▁ have ▁ incremental ▁ updates . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run_one_no_result ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 200 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 1 , FAIL ] ] , " times " : [ [ 3 , 2 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , FAIL ] , [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 3 , 2 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] ] , " times " : [ [ 2 , 2 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 2 , 2 ] , [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] , [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 10 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_older_build ( self ) : NEW_LINE # ▁ Test ▁ the ▁ build ▁ in ▁ incremental ▁ results ▁ is ▁ older ▁ than ▁ the ▁ most ▁ recent ENDCOM # ▁ build ▁ in ▁ aggregated ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ no ▁ merge ▁ happens . ENDCOM { " builds " : [ "2" , "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 6 , TEXT ] ] , " times " : [ [ 6 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_same_build ( self ) : NEW_LINE # ▁ Test ▁ the ▁ build ▁ in ▁ incremental ▁ results ▁ is ▁ same ▁ as ▁ the ▁ build ▁ in ENDCOM # ▁ aggregated ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" , "2" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , TEXT ] ] , " times " : [ [ 2 , 0 ] ] } } } , # ▁ Expected ▁ no ▁ merge ▁ happens . ENDCOM { " builds " : [ "3" , "2" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 7 , TEXT ] ] , " times " : [ [ 7 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_remove_new_test ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 199 , TEXT ] ] , " times " : [ [ 199 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , " notrun . html " : { " results " : [ [ 1 , NOTRUN ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_remove_test ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_updates_expected ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " expected " : " FAIL " , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " FAIL " , " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " expected " : " FAIL " , " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " results " : [ [ 199 , PASS ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "002 . html " : { " expected " : " PASS " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 191 , PASS ] , [ 9 , NO_DATA ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_keep_test_with_all_pass_but_slow_time ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_pruning_slow_tests_for_debug_builders ( self ) : NEW_LINE INDENT self . _builder = " MockBuilder ( dbg ) " NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results ( self ) : NEW_LINE # ▁ Remove ▁ items ▁ from ▁ test ▁ results ▁ and ▁ times ▁ that ▁ exceed ▁ the ▁ max ▁ number ENDCOM # ▁ of ▁ builds ▁ to ▁ track . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results_small ( self ) : NEW_LINE # ▁ Remove ▁ items ▁ from ▁ test ▁ results ▁ and ▁ times ▁ that ▁ exceed ▁ the ▁ max ▁ number ENDCOM # ▁ of ▁ builds ▁ to ▁ track , ▁ using ▁ smaller ▁ threshold . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_prune_extra_results_with_new_result_of_same_type ( self ) : NEW_LINE # ▁ Test ▁ that ▁ merging ▁ in ▁ a ▁ new ▁ result ▁ of ▁ the ▁ same ▁ type ▁ as ▁ the ▁ last ▁ result ENDCOM # ▁ causes ▁ old ▁ results ▁ to ▁ fall ▁ off . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , NO_DATA ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] ] , " times " : [ [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_build_directory_hierarchy ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 25 , TEXT ] ] , " times " : [ [ 25 , 0 ] ] } } } , " foo " : { "001 . html " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } } } , " version " : 4 } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } } , " version " : 4 } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 25 , TEXT ] ] , " times " : [ [ 26 , 0 ] ] } } } , " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 51 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } } } , " version " : 4 } ) NEW_LINE # ▁ FIXME ( aboxhall ) : ▁ Add ▁ some ▁ tests ▁ for ▁ xhtml / svg ▁ test ▁ results . ENDCOM DEDENT def test_get_test_name_list ( self ) : NEW_LINE # ▁ Get ▁ test ▁ name ▁ list ▁ only . ▁ Don ' t ▁ include ▁ non - test - list ▁ data ▁ and ENDCOM # ▁ of ▁ test ▁ result ▁ details . ENDCOM # ▁ FIXME : ▁ This ▁ also ▁ tests ▁ a ▁ temporary ▁ bug ▁ in ▁ the ▁ data ▁ where ▁ directory - level ENDCOM # ▁ results ▁ have ▁ a ▁ results ▁ and ▁ times ▁ values . ▁ Once ▁ that ▁ bug ▁ is ▁ fixed , ENDCOM # ▁ remove ▁ this ▁ test - case ▁ and ▁ assert ▁ we ▁ don ' t ▁ ever ▁ hit ▁ it . ENDCOM INDENT self . _test_get_test_list ( # ▁ Input ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " foo " : { "001 . html " : { } } , "002 . html " : { } } ) NEW_LINE DEDENT def test_gtest ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 3 } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " foo . bar2" : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 4 } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 1 , NO_DATA ] , [ 50 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 10 , FAIL ] ] , " times " : [ [ 10 , 0 ] ] } , } , " version " : 4 } ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT unittest . main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="bert9bert/statsmodels/tree/master/statsmodels/sandbox/nonparametric/kernel_extras.py"> """ STRNEWLINE Multivariate ▁ Conditional ▁ and ▁ Unconditional ▁ Kernel ▁ Density ▁ Estimation STRNEWLINE with ▁ Mixed ▁ Data ▁ Types STRNEWLINE STRNEWLINE References STRNEWLINE - - - - - STRNEWLINE [ 1 ] ▁ Racine , ▁ J . , ▁ Li , ▁ Q . ▁ Nonparametric ▁ econometrics : ▁ theory ▁ and ▁ practice . STRNEWLINE ▁ Princeton ▁ University ▁ Press . ▁ ( 2007 ) STRNEWLINE [ 2 ] ▁ Racine , ▁ Jeff . ▁ " Nonparametric ▁ Econometrics : ▁ A ▁ Primer , " ▁ Foundation STRNEWLINE ▁ and ▁ Trends ▁ in ▁ Econometrics : ▁ Vol ▁ 3 : ▁ No ▁ 1 , ▁ pp1-88 . ▁ ( 2008 ) STRNEWLINE ▁ http : / / dx . doi . org / 10.1561/08000009 STRNEWLINE [ 3 ] ▁ Racine , ▁ J . , ▁ Li , ▁ Q . ▁ " Nonparametric ▁ Estimation ▁ of ▁ Distributions STRNEWLINE ▁ with ▁ Categorical ▁ and ▁ Continuous ▁ Data . " ▁ Working ▁ Paper . ▁ ( 2000 ) STRNEWLINE [ 4 ] ▁ Racine , ▁ J . ▁ Li , ▁ Q . ▁ " Kernel ▁ Estimation ▁ of ▁ Multivariate ▁ Conditional STRNEWLINE ▁ Distributions ▁ Annals ▁ of ▁ Economics ▁ and ▁ Finance ▁ 5 , ▁ 211-235 ▁ ( 2004 ) STRNEWLINE [ 5 ] ▁ Liu , ▁ R . , ▁ Yang , ▁ L . ▁ " Kernel ▁ estimation ▁ of ▁ multivariate STRNEWLINE ▁ cumulative ▁ distribution ▁ function . " STRNEWLINE ▁ Journal ▁ of ▁ Nonparametric ▁ Statistics ▁ ( 2008 ) STRNEWLINE [ 6 ] ▁ Li , ▁ R . , ▁ Ju , ▁ G . ▁ " Nonparametric ▁ Estimation ▁ of ▁ Multivariate ▁ CDF STRNEWLINE ▁ with ▁ Categorical ▁ and ▁ Continuous ▁ Data . " ▁ Working ▁ Paper STRNEWLINE [ 7 ] ▁ Li , ▁ Q . , ▁ Racine , ▁ J . ▁ " Cross - validated ▁ local ▁ linear ▁ nonparametric STRNEWLINE ▁ regression " ▁ Statistica ▁ Sinica ▁ 14(2004 ) , ▁ pp . ▁ 485-512 STRNEWLINE [ 8 ] ▁ Racine , ▁ J . : ▁ " Consistent ▁ Significance ▁ Testing ▁ for ▁ Nonparametric STRNEWLINE ▁ Regression " ▁ Journal ▁ of ▁ Business ▁ & ▁ Economics ▁ Statistics STRNEWLINE [ 9 ] ▁ Racine , ▁ J . , ▁ Hart , ▁ J . , ▁ Li , ▁ Q . , ▁ " Testing ▁ the ▁ Significance ▁ of STRNEWLINE ▁ Categorical ▁ Predictor ▁ Variables ▁ in ▁ Nonparametric ▁ Regression STRNEWLINE ▁ Models " , ▁ 2006 , ▁ Econometric ▁ Reviews ▁ 25 , ▁ 523-544 STRNEWLINE STRNEWLINE """ NEW_LINE # ▁ TODO : ▁ make ▁ default ▁ behavior ▁ efficient = True ▁ above ▁ a ▁ certain ▁ n _ obs ENDCOM from statsmodels . compat . python import range , next NEW_LINE import numpy as np NEW_LINE from scipy import optimize NEW_LINE from scipy . stats . mstats import mquantiles NEW_LINE from statsmodels . nonparametric . api import KDEMultivariate , KernelReg NEW_LINE from statsmodels . nonparametric . _kernel_base import gpke , LeaveOneOut , _get_type_pos , _adjust_shape NEW_LINE __all__ = [ ' SingleIndexModel ' , ' SemiLinear ' , ' TestFForm ' ] NEW_LINE class TestFForm ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ Nonparametric ▁ test ▁ for ▁ functional ▁ form . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ endog : ▁ list STRNEWLINE ▁ Dependent ▁ variable ▁ ( training ▁ set ) STRNEWLINE ▁ exog : ▁ list ▁ of ▁ array _ like ▁ objects STRNEWLINE ▁ The ▁ independent ▁ ( right - hand - side ) ▁ variables STRNEWLINE ▁ bw : ▁ array _ like , ▁ str STRNEWLINE ▁ Bandwidths ▁ for ▁ exog ▁ or ▁ specify ▁ method ▁ for ▁ bandwidth ▁ selection STRNEWLINE ▁ fform : ▁ function STRNEWLINE ▁ The ▁ functional ▁ form ▁ ` ` y ▁ = ▁ g ( b , ▁ x ) ` ` ▁ to ▁ be ▁ tested . ▁ Takes ▁ as ▁ inputs STRNEWLINE ▁ the ▁ RHS ▁ variables ▁ ` exog ` ▁ and ▁ the ▁ coefficients ▁ ` ` b ` ` ▁ ( betas ) STRNEWLINE ▁ and ▁ returns ▁ a ▁ fitted ▁ ` ` y _ hat ` ` . STRNEWLINE ▁ var _ type : ▁ str STRNEWLINE ▁ The ▁ type ▁ of ▁ the ▁ independent ▁ ` exog ` ▁ variables : STRNEWLINE STRNEWLINE ▁ - ▁ c : ▁ continuous STRNEWLINE ▁ - ▁ o : ▁ ordered STRNEWLINE ▁ - ▁ u : ▁ unordered STRNEWLINE STRNEWLINE ▁ estimator : ▁ function STRNEWLINE ▁ Must ▁ return ▁ the ▁ estimated ▁ coefficients ▁ b ▁ ( betas ) . ▁ Takes ▁ as ▁ inputs STRNEWLINE ▁ ` ` ( endog , ▁ exog ) ` ` . ▁ E . g . ▁ least ▁ square ▁ estimator : : STRNEWLINE STRNEWLINE ▁ lambda ▁ ( x , y ) : ▁ np . dot ( np . pinv ( np . dot ( x . T , ▁ x ) ) , ▁ np . dot ( x . T , ▁ y ) ) STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ Racine , ▁ J . : ▁ " Consistent ▁ Significance ▁ Testing ▁ for ▁ Nonparametric STRNEWLINE ▁ Regression " ▁ Journal ▁ of ▁ Business ▁ \ & ▁ Economics ▁ Statistics . STRNEWLINE STRNEWLINE ▁ See ▁ chapter ▁ 12 ▁ in ▁ [ 1 ] ▁ pp . ▁ 355-357 . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , endog , exog , bw , var_type , fform , estimator , nboot = 100 ) : NEW_LINE INDENT self . endog = endog NEW_LINE self . exog = exog NEW_LINE self . var_type = var_type NEW_LINE self . fform = fform NEW_LINE self . estimator = estimator NEW_LINE self . nboot = nboot NEW_LINE self . bw = KDEMultivariate ( exog , bw = bw , var_type = var_type ) . bw NEW_LINE self . sig = self . _compute_sig ( ) NEW_LINE DEDENT def _compute_sig ( self ) : NEW_LINE INDENT Y = self . endog NEW_LINE X = self . exog NEW_LINE b = self . estimator ( Y , X ) NEW_LINE m = self . fform ( X , b ) NEW_LINE n = np . shape ( X ) [ 0 ] NEW_LINE resid = Y - m NEW_LINE resid = resid - np . mean ( resid ) # ▁ center ▁ residuals ENDCOM NEW_LINE self . test_stat = self . _compute_test_stat ( resid ) NEW_LINE sqrt5 = np . sqrt ( 5. ) NEW_LINE fct1 = ( 1 - sqrt5 ) / 2. NEW_LINE fct2 = ( 1 + sqrt5 ) / 2. NEW_LINE u1 = fct1 * resid NEW_LINE u2 = fct2 * resid NEW_LINE r = fct2 / sqrt5 NEW_LINE I_dist = np . empty ( ( self . nboot , 1 ) ) NEW_LINE for j in range ( self . nboot ) : NEW_LINE INDENT u_boot = u2 . copy ( ) NEW_LINE prob = np . random . uniform ( 0 , 1 , size = ( n , ) ) NEW_LINE ind = prob < r NEW_LINE u_boot [ ind ] = u1 [ ind ] NEW_LINE Y_boot = m + u_boot NEW_LINE b_hat = self . estimator ( Y_boot , X ) NEW_LINE m_hat = self . fform ( X , b_hat ) NEW_LINE u_boot_hat = Y_boot - m_hat NEW_LINE I_dist [ j ] = self . _compute_test_stat ( u_boot_hat ) NEW_LINE DEDENT self . boots_results = I_dist NEW_LINE sig = " Not ▁ Significant " NEW_LINE if self . test_stat > mquantiles ( I_dist , 0.9 ) : NEW_LINE INDENT sig = " * " NEW_LINE DEDENT if self . test_stat > mquantiles ( I_dist , 0.95 ) : NEW_LINE INDENT sig = " * * " NEW_LINE DEDENT if self . test_stat > mquantiles ( I_dist , 0.99 ) : NEW_LINE INDENT sig = " * * * " NEW_LINE DEDENT return sig NEW_LINE DEDENT def _compute_test_stat ( self , u ) : NEW_LINE INDENT n = np . shape ( u ) [ 0 ] NEW_LINE XLOO = LeaveOneOut ( self . exog ) NEW_LINE uLOO = LeaveOneOut ( u [ : , None ] ) . __iter__ ( ) NEW_LINE I = 0 NEW_LINE S2 = 0 NEW_LINE for i , X_not_i in enumerate ( XLOO ) : NEW_LINE INDENT u_j = next ( uLOO ) NEW_LINE u_j = np . squeeze ( u_j ) NEW_LINE # ▁ See ▁ Bootstrapping ▁ procedure ▁ on ▁ p . ▁ 357 ▁ in ▁ [ 1 ] ENDCOM K = gpke ( self . bw , data = - X_not_i , data_predict = - self . exog [ i , : ] , var_type = self . var_type , tosum = False ) NEW_LINE f_i = ( u [ i ] * u_j * K ) NEW_LINE assert u_j . shape == K . shape NEW_LINE I += f_i . sum ( ) # ▁ See ▁ eq . ▁ 12.7 ▁ on ▁ p . ▁ 355 ▁ in ▁ [ 1 ] ENDCOM NEW_LINE S2 += ( f_i ** 2 ) . sum ( ) # ▁ See ▁ Theorem ▁ 12.1 ▁ on ▁ p . 356 ▁ in ▁ [ 1 ] ENDCOM NEW_LINE assert np . size ( I ) == 1 NEW_LINE assert np . size ( S2 ) == 1 NEW_LINE DEDENT I *= 1. / ( n * ( n - 1 ) ) NEW_LINE ix_cont = _get_type_pos ( self . var_type ) [ 0 ] NEW_LINE hp = self . bw [ ix_cont ] . prod ( ) NEW_LINE S2 *= 2 * hp / ( n * ( n - 1 ) ) NEW_LINE T = n * I * np . sqrt ( hp / S2 ) NEW_LINE return T NEW_LINE DEDENT DEDENT class SingleIndexModel ( KernelReg ) : NEW_LINE INDENT """ STRNEWLINE ▁ Single ▁ index ▁ semiparametric ▁ model ▁ ` ` y ▁ = ▁ g ( X ▁ * ▁ b ) ▁ + ▁ e ` ` . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ endog : ▁ array _ like STRNEWLINE ▁ The ▁ dependent ▁ variable STRNEWLINE ▁ exog : ▁ array _ like STRNEWLINE ▁ The ▁ independent ▁ variable ( s ) STRNEWLINE ▁ var _ type : ▁ str STRNEWLINE ▁ The ▁ type ▁ of ▁ variables ▁ in ▁ X : STRNEWLINE STRNEWLINE ▁ - ▁ c : ▁ continuous STRNEWLINE ▁ - ▁ o : ▁ ordered STRNEWLINE ▁ - ▁ u : ▁ unordered STRNEWLINE STRNEWLINE ▁ Attributes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ b : ▁ array _ like STRNEWLINE ▁ The ▁ linear ▁ coefficients ▁ b ▁ ( betas ) STRNEWLINE ▁ bw : ▁ array _ like STRNEWLINE ▁ Bandwidths STRNEWLINE STRNEWLINE ▁ Methods STRNEWLINE ▁ - - - - - STRNEWLINE ▁ fit ( ) : ▁ Computes ▁ the ▁ fitted ▁ values ▁ ` ` E [ Y | X ] ▁ = ▁ g ( X ▁ * ▁ b ) ` ` STRNEWLINE ▁ and ▁ the ▁ marginal ▁ effects ▁ ` ` dY / dX ` ` . STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ chapter ▁ on ▁ semiparametric ▁ models ▁ in ▁ [ 1 ] STRNEWLINE STRNEWLINE ▁ Notes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ This ▁ model ▁ resembles ▁ the ▁ binary ▁ choice ▁ models . ▁ The ▁ user ▁ knows STRNEWLINE ▁ that ▁ X ▁ and ▁ b ▁ interact ▁ linearly , ▁ but ▁ ` ` g ( X ▁ * ▁ b ) ` ` ▁ is ▁ unknown . STRNEWLINE ▁ In ▁ the ▁ parametric ▁ binary ▁ choice ▁ models ▁ the ▁ user ▁ usually ▁ assumes STRNEWLINE ▁ some ▁ distribution ▁ of ▁ g ( ) ▁ such ▁ as ▁ normal ▁ or ▁ logistic . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , endog , exog , var_type ) : NEW_LINE INDENT self . var_type = var_type NEW_LINE self . K = len ( var_type ) NEW_LINE self . var_type = self . var_type [ 0 ] NEW_LINE self . endog = _adjust_shape ( endog , 1 ) NEW_LINE self . exog = _adjust_shape ( exog , self . K ) NEW_LINE self . nobs = np . shape ( self . exog ) [ 0 ] NEW_LINE self . data_type = self . var_type NEW_LINE self . func = self . _est_loc_linear NEW_LINE self . b , self . bw = self . _est_b_bw ( ) NEW_LINE DEDENT def _est_b_bw ( self ) : NEW_LINE INDENT params0 = np . random . uniform ( size = ( self . K + 1 , ) ) NEW_LINE b_bw = optimize . fmin ( self . cv_loo , params0 , disp = 0 ) NEW_LINE b = b_bw [ 0 : self . K ] NEW_LINE bw = b_bw [ self . K : ] NEW_LINE bw = self . _set_bw_bounds ( bw ) NEW_LINE return b , bw NEW_LINE DEDENT def cv_loo ( self , params ) : NEW_LINE # ▁ See ▁ p . ▁ 254 ▁ in ▁ Textbook ENDCOM INDENT params = np . asarray ( params ) NEW_LINE b = params [ 0 : self . K ] NEW_LINE bw = params [ self . K : ] NEW_LINE LOO_X = LeaveOneOut ( self . exog ) NEW_LINE LOO_Y = LeaveOneOut ( self . endog ) . __iter__ ( ) NEW_LINE L = 0 NEW_LINE for i , X_not_i in enumerate ( LOO_X ) : NEW_LINE INDENT Y = next ( LOO_Y ) NEW_LINE # print ▁ b . shape , ▁ np . dot ( self . exog [ i : i + 1 , ▁ : ] , ▁ b ) . shape , ▁ bw , ENDCOM G = self . func ( bw , endog = Y , exog = - np . dot ( X_not_i , b ) [ : , None ] , # data _ predict = - b * self . exog [ i , ▁ : ] ) [0 ] ENDCOM data_predict = - np . dot ( self . exog [ i : i + 1 , : ] , b ) ) [ 0 ] NEW_LINE # print ▁ G . shape ENDCOM L += ( self . endog [ i ] - G ) ** 2 NEW_LINE # ▁ Note : ▁ There ▁ might ▁ be ▁ a ▁ way ▁ to ▁ vectorize ▁ this . ▁ See ▁ p . 72 ▁ in ▁ [ 1 ] ENDCOM DEDENT return L / self . nobs NEW_LINE DEDENT def fit ( self , data_predict = None ) : NEW_LINE INDENT if data_predict is None : NEW_LINE INDENT data_predict = self . exog NEW_LINE DEDENT else : NEW_LINE INDENT data_predict = _adjust_shape ( data_predict , self . K ) NEW_LINE DEDENT N_data_predict = np . shape ( data_predict ) [ 0 ] NEW_LINE mean = np . empty ( ( N_data_predict , ) ) NEW_LINE mfx = np . empty ( ( N_data_predict , self . K ) ) NEW_LINE for i in range ( N_data_predict ) : NEW_LINE INDENT mean_mfx = self . func ( self . bw , self . endog , np . dot ( self . exog , self . b ) [ : , None ] , data_predict = np . dot ( data_predict [ i : i + 1 , : ] , self . b ) ) NEW_LINE mean [ i ] = mean_mfx [ 0 ] NEW_LINE mfx_c = np . squeeze ( mean_mfx [ 1 ] ) NEW_LINE mfx [ i , : ] = mfx_c NEW_LINE DEDENT return mean , mfx NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT """ Provide ▁ something ▁ sane ▁ to ▁ print . """ NEW_LINE repr = " Single ▁ Index ▁ Model ▁ \n " NEW_LINE repr += " Number ▁ of ▁ variables : ▁ K ▁ = ▁ " + str ( self . K ) + " \n " NEW_LINE repr += " Number ▁ of ▁ samples : ▁ ▁ ▁ nobs ▁ = ▁ " + str ( self . nobs ) + " \n " NEW_LINE repr += " Variable ▁ types : ▁ ▁ ▁ ▁ ▁ ▁ " + self . var_type + " \n " NEW_LINE repr += " BW ▁ selection ▁ method : ▁ cv _ ls " + " \n " NEW_LINE repr += " Estimator ▁ type : ▁ local ▁ constant " + " \n " NEW_LINE return repr NEW_LINE DEDENT DEDENT class SemiLinear ( KernelReg ) : NEW_LINE INDENT """ STRNEWLINE ▁ Semiparametric ▁ partially ▁ linear ▁ model , ▁ ` ` Y ▁ = ▁ Xb ▁ + ▁ g ( Z ) ▁ + ▁ e ` ` . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ endog : ▁ array _ like STRNEWLINE ▁ The ▁ dependent ▁ variable STRNEWLINE ▁ exog : ▁ array _ like STRNEWLINE ▁ The ▁ linear ▁ component ▁ in ▁ the ▁ regression STRNEWLINE ▁ exog _ nonparametric : ▁ array _ like STRNEWLINE ▁ The ▁ nonparametric ▁ component ▁ in ▁ the ▁ regression STRNEWLINE ▁ var _ type : ▁ str STRNEWLINE ▁ The ▁ type ▁ of ▁ the ▁ variables ▁ in ▁ the ▁ nonparametric ▁ component ; STRNEWLINE STRNEWLINE ▁ - ▁ c : ▁ continuous STRNEWLINE ▁ - ▁ o : ▁ ordered STRNEWLINE ▁ - ▁ u : ▁ unordered STRNEWLINE STRNEWLINE ▁ k _ linear ▁ : ▁ int STRNEWLINE ▁ The ▁ number ▁ of ▁ variables ▁ that ▁ comprise ▁ the ▁ linear ▁ component . STRNEWLINE STRNEWLINE ▁ Attributes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bw : ▁ array _ like STRNEWLINE ▁ Bandwidths ▁ for ▁ the ▁ nonparametric ▁ component ▁ exog _ nonparametric STRNEWLINE ▁ b : ▁ array _ like STRNEWLINE ▁ Coefficients ▁ in ▁ the ▁ linear ▁ component STRNEWLINE ▁ nobs ▁ : ▁ int STRNEWLINE ▁ The ▁ number ▁ of ▁ observations . STRNEWLINE ▁ k _ linear ▁ : ▁ int STRNEWLINE ▁ The ▁ number ▁ of ▁ variables ▁ that ▁ comprise ▁ the ▁ linear ▁ component . STRNEWLINE STRNEWLINE ▁ Methods STRNEWLINE ▁ - - - - - STRNEWLINE ▁ fit ( ) : ▁ Returns ▁ the ▁ fitted ▁ mean ▁ and ▁ marginal ▁ effects ▁ dy / dz STRNEWLINE STRNEWLINE ▁ Notes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ This ▁ model ▁ uses ▁ only ▁ the ▁ local ▁ constant ▁ regression ▁ estimator STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ chapter ▁ on ▁ Semiparametric ▁ Models ▁ in ▁ [ 1 ] STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , endog , exog , exog_nonparametric , var_type , k_linear ) : NEW_LINE INDENT self . endog = _adjust_shape ( endog , 1 ) NEW_LINE self . exog = _adjust_shape ( exog , k_linear ) NEW_LINE self . K = len ( var_type ) NEW_LINE self . exog_nonparametric = _adjust_shape ( exog_nonparametric , self . K ) NEW_LINE self . k_linear = k_linear NEW_LINE self . nobs = np . shape ( self . exog ) [ 0 ] NEW_LINE self . var_type = var_type NEW_LINE self . data_type = self . var_type NEW_LINE self . func = self . _est_loc_linear NEW_LINE self . b , self . bw = self . _est_b_bw ( ) NEW_LINE DEDENT def _est_b_bw ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Computes ▁ the ▁ ( beta ) ▁ coefficients ▁ and ▁ the ▁ bandwidths . STRNEWLINE STRNEWLINE ▁ Minimizes ▁ ` ` cv _ loo ` ` ▁ with ▁ respect ▁ to ▁ ` ` b ` ` ▁ and ▁ ` ` bw ` ` . STRNEWLINE ▁ """ NEW_LINE params0 = np . random . uniform ( size = ( self . k_linear + self . K , ) ) NEW_LINE b_bw = optimize . fmin ( self . cv_loo , params0 , disp = 0 ) NEW_LINE b = b_bw [ 0 : self . k_linear ] NEW_LINE bw = b_bw [ self . k_linear : ] NEW_LINE # bw ▁ = ▁ self . _ set _ bw _ bounds ( np . asarray ( bw ) ) ENDCOM return b , bw NEW_LINE DEDENT def cv_loo ( self , params ) : NEW_LINE INDENT """ STRNEWLINE ▁ Similar ▁ to ▁ the ▁ cross ▁ validation ▁ leave - one - out ▁ estimator . STRNEWLINE STRNEWLINE ▁ Modified ▁ to ▁ reflect ▁ the ▁ linear ▁ components . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ params : ▁ array _ like STRNEWLINE ▁ Vector ▁ consisting ▁ of ▁ the ▁ coefficients ▁ ( b ) ▁ and ▁ the ▁ bandwidths ▁ ( bw ) . STRNEWLINE ▁ The ▁ first ▁ ` ` k _ linear ` ` ▁ elements ▁ are ▁ the ▁ coefficients . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ L : ▁ float STRNEWLINE ▁ The ▁ value ▁ of ▁ the ▁ objective ▁ function STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ p . 254 ▁ in ▁ [ 1 ] STRNEWLINE ▁ """ NEW_LINE params = np . asarray ( params ) NEW_LINE b = params [ 0 : self . k_linear ] NEW_LINE bw = params [ self . k_linear : ] NEW_LINE LOO_X = LeaveOneOut ( self . exog ) NEW_LINE LOO_Y = LeaveOneOut ( self . endog ) . __iter__ ( ) NEW_LINE LOO_Z = LeaveOneOut ( self . exog_nonparametric ) . __iter__ ( ) NEW_LINE Xb = np . dot ( self . exog , b ) [ : , None ] NEW_LINE L = 0 NEW_LINE for ii , X_not_i in enumerate ( LOO_X ) : NEW_LINE INDENT Y = next ( LOO_Y ) NEW_LINE Z = next ( LOO_Z ) NEW_LINE Xb_j = np . dot ( X_not_i , b ) [ : , None ] NEW_LINE Yx = Y - Xb_j NEW_LINE G = self . func ( bw , endog = Yx , exog = - Z , data_predict = - self . exog_nonparametric [ ii , : ] ) [ 0 ] NEW_LINE lt = Xb [ ii , : ] # . sum ( ) ▁ # ▁ linear ▁ term ENDCOM NEW_LINE L += ( self . endog [ ii ] - lt - G ) ** 2 NEW_LINE DEDENT return L NEW_LINE DEDENT def fit ( self , exog_predict = None , exog_nonparametric_predict = None ) : NEW_LINE INDENT """ Computes ▁ fitted ▁ values ▁ and ▁ marginal ▁ effects """ NEW_LINE if exog_predict is None : NEW_LINE INDENT exog_predict = self . exog NEW_LINE DEDENT else : NEW_LINE INDENT exog_predict = _adjust_shape ( exog_predict , self . k_linear ) NEW_LINE DEDENT if exog_nonparametric_predict is None : NEW_LINE INDENT exog_nonparametric_predict = self . exog_nonparametric NEW_LINE DEDENT else : NEW_LINE INDENT exog_nonparametric_predict = _adjust_shape ( exog_nonparametric_predict , self . K ) NEW_LINE DEDENT N_data_predict = np . shape ( exog_nonparametric_predict ) [ 0 ] NEW_LINE mean = np . empty ( ( N_data_predict , ) ) NEW_LINE mfx = np . empty ( ( N_data_predict , self . K ) ) NEW_LINE Y = self . endog - np . dot ( exog_predict , self . b ) [ : , None ] NEW_LINE for i in range ( N_data_predict ) : NEW_LINE INDENT mean_mfx = self . func ( self . bw , Y , self . exog_nonparametric , data_predict = exog_nonparametric_predict [ i , : ] ) NEW_LINE mean [ i ] = mean_mfx [ 0 ] NEW_LINE mfx_c = np . squeeze ( mean_mfx [ 1 ] ) NEW_LINE mfx [ i , : ] = mfx_c NEW_LINE DEDENT return mean , mfx NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT """ Provide ▁ something ▁ sane ▁ to ▁ print . """ NEW_LINE repr = " Semiparamatric ▁ Partially ▁ Linear ▁ Model ▁ \n " NEW_LINE repr += " Number ▁ of ▁ variables : ▁ K ▁ = ▁ " + str ( self . K ) + " \n " NEW_LINE repr += " Number ▁ of ▁ samples : ▁ ▁ ▁ N ▁ = ▁ " + str ( self . nobs ) + " \n " NEW_LINE repr += " Variable ▁ types : ▁ ▁ ▁ ▁ ▁ ▁ " + self . var_type + " \n " NEW_LINE repr += " BW ▁ selection ▁ method : ▁ cv _ ls " + " \n " NEW_LINE repr += " Estimator ▁ type : ▁ local ▁ constant " + " \n " NEW_LINE return repr NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="octacoin-project/beta/tree/master/share/qt/extract_strings_qt.py"> # ! / usr / bin / python ENDCOM ''' STRNEWLINE Extract ▁ _ ( " . . . " ) ▁ strings ▁ for ▁ translation ▁ and ▁ convert ▁ to ▁ Qt4 ▁ stringdefs ▁ so ▁ that STRNEWLINE they ▁ can ▁ be ▁ picked ▁ up ▁ by ▁ Qt ▁ linguist . STRNEWLINE ''' NEW_LINE from subprocess import Popen , PIPE NEW_LINE import glob NEW_LINE import operator NEW_LINE import os NEW_LINE import sys NEW_LINE OUT_CPP = " qt / bitcoinstrings . cpp " NEW_LINE EMPTY = [ ' " " ' ] NEW_LINE def parse_po ( text ) : NEW_LINE INDENT """ STRNEWLINE ▁ Parse ▁ ' po ' ▁ format ▁ produced ▁ by ▁ xgettext . STRNEWLINE ▁ Return ▁ a ▁ list ▁ of ▁ ( msgid , msgstr ) ▁ tuples . STRNEWLINE ▁ """ NEW_LINE messages = [ ] NEW_LINE msgid = [ ] NEW_LINE msgstr = [ ] NEW_LINE in_msgid = False NEW_LINE in_msgstr = False NEW_LINE for line in text . split ( ' \n ' ) : NEW_LINE INDENT line = line . rstrip ( ' ' ) NEW_LINE if line . startswith ( ' msgid ▁ ' ) : NEW_LINE INDENT if in_msgstr : NEW_LINE INDENT messages . append ( ( msgid , msgstr ) ) NEW_LINE in_msgstr = False NEW_LINE # ▁ message ▁ start ENDCOM DEDENT in_msgid = True NEW_LINE msgid = [ line [ 6 : ] ] NEW_LINE DEDENT elif line . startswith ( ' msgstr ▁ ' ) : NEW_LINE INDENT in_msgid = False NEW_LINE in_msgstr = True NEW_LINE msgstr = [ line [ 7 : ] ] NEW_LINE DEDENT elif line . startswith ( ' " ' ) : NEW_LINE INDENT if in_msgid : NEW_LINE INDENT msgid . append ( line ) NEW_LINE DEDENT if in_msgstr : NEW_LINE INDENT msgstr . append ( line ) NEW_LINE DEDENT DEDENT DEDENT if in_msgstr : NEW_LINE INDENT messages . append ( ( msgid , msgstr ) ) NEW_LINE DEDENT return messages NEW_LINE DEDENT files = sys . argv [ 1 : ] NEW_LINE # ▁ xgettext ▁ - n ▁ - - keyword = _ ▁ $ FILES ENDCOM XGETTEXT = os . getenv ( ' XGETTEXT ' , ' xgettext ' ) NEW_LINE child = Popen ( [ XGETTEXT , ' - - output = - ' , ' - n ' , ' - - keyword = _ ' ] + files , stdout = PIPE ) NEW_LINE ( out , err ) = child . communicate ( ) NEW_LINE messages = parse_po ( out ) NEW_LINE f = open ( OUT_CPP , ' w ' ) NEW_LINE f . write ( """ STRNEWLINE STRNEWLINE # include ▁ < QtGlobal > STRNEWLINE STRNEWLINE / / ▁ Automatically ▁ generated ▁ by ▁ extract _ strings . py STRNEWLINE # ifdef ▁ _ _ GNUC _ _ STRNEWLINE # define ▁ UNUSED ▁ _ _ attribute _ _ ( ( unused ) ) STRNEWLINE # else STRNEWLINE # define ▁ UNUSED STRNEWLINE # endif STRNEWLINE """ ) NEW_LINE f . write ( ' static ▁ const ▁ char ▁ UNUSED ▁ * bitcoin _ strings [ ] ▁ = ▁ { \n ' ) NEW_LINE messages . sort ( key = operator . itemgetter ( 0 ) ) NEW_LINE for ( msgid , msgstr ) in messages : NEW_LINE INDENT if msgid != EMPTY : NEW_LINE INDENT f . write ( ' QT _ TRANSLATE _ NOOP ( " bitcoin - core " , ▁ % s ) , \n ' % ( ' \n ' . join ( msgid ) ) ) NEW_LINE DEDENT DEDENT f . write ( ' } ; \n ' ) NEW_LINE f . close ( ) NEW_LINE </DOCUMENT>
