<DOCUMENT_ID="astronaut1712/taiga-back/tree/master/taiga/projects/wiki/models.py"> # ▁ Copyright ▁ ( C ) ▁ 2014 ▁ Andrey ▁ Antukh ▁ < niwi @ niwi . be > ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2014 ▁ Jesús ▁ Espino ▁ < jespinog @ gmail . com > ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2014 ▁ David ▁ Barragán ▁ < bameda @ dbarragan . com > ENDCOM # ▁ This ▁ program ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ as ENDCOM # ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ENDCOM # ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ this ▁ program . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM from django . db import models NEW_LINE from django . contrib . contenttypes import generic NEW_LINE from django . conf import settings NEW_LINE from django . utils . translation import ugettext_lazy as _ NEW_LINE from django . utils import timezone NEW_LINE from taiga . projects . notifications . mixins import WatchedModelMixin NEW_LINE from taiga . projects . occ import OCCModelMixin NEW_LINE class WikiPage ( OCCModelMixin , WatchedModelMixin , models . Model ) : NEW_LINE INDENT project = models . ForeignKey ( " projects . Project " , null = False , blank = False , related_name = " wiki _ pages " , verbose_name = _ ( " project " ) ) NEW_LINE slug = models . SlugField ( max_length = 500 , db_index = True , null = False , blank = False , verbose_name = _ ( " slug " ) ) NEW_LINE content = models . TextField ( null = False , blank = True , verbose_name = _ ( " content " ) ) NEW_LINE owner = models . ForeignKey ( settings . AUTH_USER_MODEL , null = True , blank = True , related_name = " owned _ wiki _ pages " , verbose_name = _ ( " owner " ) ) NEW_LINE last_modifier = models . ForeignKey ( settings . AUTH_USER_MODEL , null = True , blank = True , related_name = " last _ modified _ wiki _ pages " , verbose_name = _ ( " last ▁ modifier " ) ) NEW_LINE created_date = models . DateTimeField ( null = False , blank = False , verbose_name = _ ( " created ▁ date " ) , default = timezone . now ) NEW_LINE modified_date = models . DateTimeField ( null = False , blank = False , verbose_name = _ ( " modified ▁ date " ) ) NEW_LINE attachments = generic . GenericRelation ( " attachments . Attachment " ) NEW_LINE _importing = None NEW_LINE class Meta : NEW_LINE INDENT verbose_name = " wiki ▁ page " NEW_LINE verbose_name_plural = " wiki ▁ pages " NEW_LINE ordering = [ " project " , " slug " ] NEW_LINE unique_together = ( " project " , " slug " , ) NEW_LINE permissions = ( ( " view _ wikipage " , " Can ▁ view ▁ wiki ▁ page " ) , ) NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return " project ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . project_id , self . slug ) NEW_LINE DEDENT def save ( self , * args , ** kwargs ) : NEW_LINE INDENT if not self . _importing or not self . modified_date : NEW_LINE INDENT self . modified_date = timezone . now ( ) NEW_LINE DEDENT return super ( ) . save ( * args , ** kwargs ) NEW_LINE DEDENT DEDENT class WikiLink ( models . Model ) : NEW_LINE INDENT project = models . ForeignKey ( " projects . Project " , null = False , blank = False , related_name = " wiki _ links " , verbose_name = _ ( " project " ) ) NEW_LINE title = models . CharField ( max_length = 500 , null = False , blank = False ) NEW_LINE href = models . SlugField ( max_length = 500 , db_index = True , null = False , blank = False , verbose_name = _ ( " href " ) ) NEW_LINE order = models . PositiveSmallIntegerField ( default = 1 , null = False , blank = False , verbose_name = _ ( " order " ) ) NEW_LINE class Meta : NEW_LINE INDENT verbose_name = " wiki ▁ link " NEW_LINE verbose_name_plural = " wiki ▁ links " NEW_LINE ordering = [ " project " , " order " ] NEW_LINE unique_together = ( " project " , " href " ) NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return self . title NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="factorybuild/stbgui/tree/master/lib/python/Screens/ChannelSelection.py"> from Tools . Profile import profile NEW_LINE from Screen import Screen NEW_LINE import Screens . InfoBar NEW_LINE import Components . ParentalControl NEW_LINE from Components . Button import Button NEW_LINE from Components . ServiceList import ServiceList , refreshServiceList NEW_LINE from Components . ActionMap import NumberActionMap , ActionMap , HelpableActionMap NEW_LINE from Components . MenuList import MenuList NEW_LINE from Components . ServiceEventTracker import ServiceEventTracker , InfoBarBase NEW_LINE profile ( " ChannelSelection . py ▁ 1" ) NEW_LINE from EpgSelection import EPGSelection NEW_LINE from enigma import eServiceReference , eEPGCache , eServiceCenter , eRCInput , eTimer , eDVBDB , iPlayableService , iServiceInformation , getPrevAsciiCode , eEnv NEW_LINE from Components . config import config , configfile , ConfigSubsection , ConfigText , ConfigYesNo NEW_LINE from Tools . NumericalTextInput import NumericalTextInput NEW_LINE profile ( " ChannelSelection . py ▁ 2" ) NEW_LINE from Components . NimManager import nimmanager NEW_LINE profile ( " ChannelSelection . py ▁ 2.1" ) NEW_LINE from Components . Sources . RdsDecoder import RdsDecoder NEW_LINE profile ( " ChannelSelection . py ▁ 2.2" ) NEW_LINE from Components . Sources . ServiceEvent import ServiceEvent NEW_LINE from Components . Sources . Event import Event NEW_LINE profile ( " ChannelSelection . py ▁ 2.3" ) NEW_LINE from Components . Input import Input NEW_LINE profile ( " ChannelSelection . py ▁ 3" ) NEW_LINE from Components . ChoiceList import ChoiceList , ChoiceEntryComponent NEW_LINE from Components . SystemInfo import SystemInfo NEW_LINE from Screens . InputBox import PinInput NEW_LINE from Screens . VirtualKeyBoard import VirtualKeyBoard NEW_LINE from Screens . MessageBox import MessageBox NEW_LINE from Screens . ServiceInfo import ServiceInfo NEW_LINE from Screens . Hotkey import InfoBarHotkey , hotkeyActionMap , getHotkeyFunctions NEW_LINE profile ( " ChannelSelection . py ▁ 4" ) NEW_LINE from Screens . PictureInPicture import PictureInPicture NEW_LINE from Screens . RdsDisplay import RassInteractive NEW_LINE from ServiceReference import ServiceReference NEW_LINE from Tools . BoundFunction import boundFunction NEW_LINE from Tools import Notifications NEW_LINE from Tools . Alternatives import CompareWithAlternatives , GetWithAlternative NEW_LINE from Tools . Directories import fileExists NEW_LINE from Plugins . Plugin import PluginDescriptor NEW_LINE from Components . PluginComponent import plugins NEW_LINE from Screens . ChoiceBox import ChoiceBox NEW_LINE from Screens . EventView import EventViewEPGSelect NEW_LINE import os , unicodedata NEW_LINE profile ( " ChannelSelection . py ▁ after ▁ imports " ) NEW_LINE FLAG_SERVICE_NEW_FOUND = 64 NEW_LINE FLAG_IS_DEDICATED_3D = 128 NEW_LINE FLAG_HIDE_VBI = 512 # define ▁ in ▁ lib / dvb / idvb . h ▁ as ▁ dxNewFound ▁ = ▁ 64 ▁ and ▁ dxIsDedicated3D ▁ = ▁ 128 ENDCOM NEW_LINE class BouquetSelector ( Screen ) : NEW_LINE INDENT def __init__ ( self , session , bouquets , selectedFunc , enableWrapAround = True ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self . setTitle ( _ ( " Choose ▁ bouquet " ) ) NEW_LINE self . selectedFunc = selectedFunc NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " ] , { " ok " : self . okbuttonClick , " cancel " : self . cancelClick } ) NEW_LINE entrys = [ ( x [ 0 ] , x [ 1 ] ) for x in bouquets ] NEW_LINE self [ " menu " ] = MenuList ( entrys , enableWrapAround ) NEW_LINE DEDENT def getCurrent ( self ) : NEW_LINE INDENT cur = self [ " menu " ] . getCurrent ( ) NEW_LINE return cur and cur [ 1 ] NEW_LINE DEDENT def okbuttonClick ( self ) : NEW_LINE INDENT self . selectedFunc ( self . getCurrent ( ) ) NEW_LINE DEDENT def up ( self ) : NEW_LINE INDENT self [ " menu " ] . up ( ) NEW_LINE DEDENT def down ( self ) : NEW_LINE INDENT self [ " menu " ] . down ( ) NEW_LINE DEDENT def cancelClick ( self ) : NEW_LINE INDENT self . close ( False ) NEW_LINE DEDENT DEDENT class SilentBouquetSelector : NEW_LINE INDENT def __init__ ( self , bouquets , enableWrapAround = False , current = 0 ) : NEW_LINE INDENT self . bouquets = [ b [ 1 ] for b in bouquets ] NEW_LINE self . pos = current NEW_LINE self . count = len ( bouquets ) NEW_LINE self . enableWrapAround = enableWrapAround NEW_LINE DEDENT def up ( self ) : NEW_LINE INDENT if self . pos > 0 or self . enableWrapAround : NEW_LINE INDENT self . pos = ( self . pos - 1 ) % self . count NEW_LINE DEDENT DEDENT def down ( self ) : NEW_LINE INDENT if self . pos < ( self . count - 1 ) or self . enableWrapAround : NEW_LINE INDENT self . pos = ( self . pos + 1 ) % self . count NEW_LINE DEDENT DEDENT def getCurrent ( self ) : NEW_LINE INDENT return self . bouquets [ self . pos ] NEW_LINE # ▁ csel . bouquet _ mark _ edit ▁ values ENDCOM DEDENT DEDENT OFF = 0 NEW_LINE EDIT_BOUQUET = 1 NEW_LINE EDIT_ALTERNATIVES = 2 NEW_LINE def append_when_current_valid ( current , menu , args , level = 0 , key = " " ) : NEW_LINE INDENT if current and current . valid ( ) and level <= config . usage . setup_level . index : NEW_LINE INDENT menu . append ( ChoiceEntryComponent ( key , args ) ) NEW_LINE DEDENT DEDENT def removed_userbouquets_available ( ) : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT class ChannelContextMenu ( Screen ) : NEW_LINE INDENT def __init__ ( self , session , csel ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self . csel = csel NEW_LINE self . bsel = None NEW_LINE if self . isProtected ( ) : NEW_LINE INDENT self . onFirstExecBegin . append ( boundFunction ( self . session . openWithCallback , self . protectResult , PinInput , pinList = [ x . value for x in config . ParentalControl . servicepin ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( " Please ▁ enter ▁ the ▁ correct ▁ pin ▁ code " ) , windowTitle = _ ( " Enter ▁ pin ▁ code " ) ) ) NEW_LINE DEDENT self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " ColorActions " , " NumberActions " , " MenuActions " ] , { " ok " : self . okbuttonClick , " cancel " : self . cancelClick , " blue " : self . showServiceInPiP , " red " : self . playMain , " menu " : self . openSetup , "2" : self . renameEntry , "3" : self . findCurrentlyPlayed , "5" : self . addServiceToBouquetOrAlternative , "6" : self . toggleMoveModeSelect , "8" : self . removeEntry } ) NEW_LINE menu = [ ] NEW_LINE self . removeFunction = False NEW_LINE self . addFunction = False NEW_LINE current = csel . getCurrentSelection ( ) NEW_LINE current_root = csel . getRoot ( ) NEW_LINE current_sel_path = current . getPath ( ) NEW_LINE current_sel_flags = current . flags NEW_LINE inBouquetRootList = current_root and ' FROM ▁ BOUQUET ▁ " bouquets . ' in current_root . getPath ( ) # FIXME ▁ HACK ENDCOM NEW_LINE inAlternativeList = current_root and ' FROM ▁ BOUQUET ▁ " alternatives ' in current_root . getPath ( ) NEW_LINE self . inBouquet = csel . getMutableList ( ) is not None NEW_LINE haveBouquets = config . usage . multibouquet . value NEW_LINE from Components . ParentalControl import parentalControl NEW_LINE self . parentalControl = parentalControl NEW_LINE self . parentalControlEnabled = config . ParentalControl . servicepin [ 0 ] . value and config . ParentalControl . servicepinactive . value NEW_LINE if not ( current_sel_path or current_sel_flags & ( eServiceReference . isDirectory | eServiceReference . isMarker ) ) or current_sel_flags & eServiceReference . isGroup : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " show ▁ transponder ▁ info " ) , self . showServiceInformations ) , level = 2 ) NEW_LINE DEDENT if csel . bouquet_mark_edit == OFF and not csel . entry_marked : NEW_LINE INDENT if not inBouquetRootList : NEW_LINE INDENT isPlayable = not ( current_sel_flags & ( eServiceReference . isMarker | eServiceReference . isDirectory ) ) NEW_LINE if isPlayable : NEW_LINE INDENT for p in plugins . getPlugins ( PluginDescriptor . WHERE_CHANNEL_CONTEXT_MENU ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( p . name , boundFunction ( self . runPlugin , p ) ) , key = " bullet " ) NEW_LINE DEDENT if config . servicelist . startupservice . value == current . toString ( ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " stop ▁ using ▁ as ▁ startup ▁ service " ) , self . unsetStartupService ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " set ▁ as ▁ startup ▁ service " ) , self . setStartupService ) , level = 0 ) NEW_LINE DEDENT if self . parentalControlEnabled : NEW_LINE INDENT if self . parentalControl . getProtectionLevel ( current . toCompareString ( ) ) == - 1 : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ to ▁ parental ▁ protection " ) , boundFunction ( self . addParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT if self . parentalControl . isServiceProtectionBouquet ( current . toCompareString ( ) ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " service ▁ is ▁ in ▁ bouquet ▁ parental ▁ protection " ) , self . cancelClick ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ from ▁ parental ▁ protection " ) , boundFunction ( self . removeParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT DEDENT if config . ParentalControl . hideBlacklist . value and not parentalControl . sessionPinCached and config . ParentalControl . storeservicepin . value != " never " : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Unhide ▁ parental ▁ control ▁ services " ) , self . unhideParentalServices ) , level = 0 , key = "1" ) NEW_LINE DEDENT DEDENT if SystemInfo [ "3DMode " ] and fileExists ( " / usr / lib / enigma2 / python / Plugins / SystemPlugins / OSD3DSetup / plugin . py " ) : NEW_LINE INDENT if eDVBDB . getInstance ( ) . getFlag ( eServiceReference ( current . toString ( ) ) ) & FLAG_IS_DEDICATED_3D : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Unmark ▁ service ▁ as ▁ dedicated ▁ 3D ▁ service " ) , self . removeDedicated3DFlag ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Mark ▁ service ▁ as ▁ dedicated ▁ 3D ▁ service " ) , self . addDedicated3DFlag ) , level = 0 ) NEW_LINE DEDENT DEDENT if not ( current_sel_path ) : NEW_LINE INDENT if eDVBDB . getInstance ( ) . getFlag ( eServiceReference ( current . toString ( ) ) ) & FLAG_HIDE_VBI : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Uncover ▁ dashed ▁ flickering ▁ line ▁ for ▁ this ▁ service " ) , self . removeHideVBIFlag ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Cover ▁ dashed ▁ flickering ▁ line ▁ for ▁ this ▁ service " ) , self . addHideVBIFlag ) , level = 0 ) NEW_LINE DEDENT DEDENT if haveBouquets : NEW_LINE INDENT bouquets = self . csel . getBouquetList ( ) NEW_LINE if bouquets is None : NEW_LINE INDENT bouquetCnt = 0 NEW_LINE DEDENT else : NEW_LINE INDENT bouquetCnt = len ( bouquets ) NEW_LINE DEDENT if not self . inBouquet or bouquetCnt > 1 : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ service ▁ to ▁ bouquet " ) , self . addServiceToBouquetSelected ) , level = 0 , key = "5" ) NEW_LINE self . addFunction = self . addServiceToBouquetSelected NEW_LINE DEDENT if not self . inBouquet : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeSatelliteService NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if not self . inBouquet : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ service ▁ to ▁ favourites " ) , self . addServiceToBouquetSelected ) , level = 0 , key = "5" ) NEW_LINE self . addFunction = self . addServiceToBouquetSelected NEW_LINE DEDENT DEDENT if SystemInfo [ " PIPAvailable " ] : NEW_LINE INDENT if not self . parentalControlEnabled or self . parentalControl . getProtectionLevel ( current . toCompareString ( ) ) == - 1 : NEW_LINE INDENT if self . csel . dopipzap : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " play ▁ in ▁ mainwindow " ) , self . playMain ) , level = 0 , key = " red " ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " play ▁ as ▁ picture ▁ in ▁ picture " ) , self . showServiceInPiP ) , level = 0 , key = " blue " ) NEW_LINE DEDENT DEDENT DEDENT append_when_current_valid ( current , menu , ( _ ( " find ▁ currently ▁ played ▁ service " ) , self . findCurrentlyPlayed ) , level = 0 , key = "3" ) NEW_LINE DEDENT else : NEW_LINE INDENT if ' FROM ▁ SATELLITES ' in current_root . getPath ( ) and current and _ ( " Services " ) in eServiceCenter . getInstance ( ) . info ( current ) . getName ( current ) : NEW_LINE INDENT unsigned_orbpos = current . getUnsignedData ( 4 ) >> 16 NEW_LINE if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ cable ▁ services " ) , self . removeSatelliteServices ) , level = 0 ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ terrestrial ▁ services " ) , self . removeSatelliteServices ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ selected ▁ satellite " ) , self . removeSatelliteServices ) , level = 0 ) NEW_LINE DEDENT DEDENT if haveBouquets : NEW_LINE INDENT if not self . inBouquet and not " PROVIDERS " in current_sel_path : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " copy ▁ to ▁ bouquets " ) , self . copyCurrentToBouquetList ) , level = 0 ) NEW_LINE DEDENT DEDENT if ( " flags ▁ = = ▁ % d " % ( FLAG_SERVICE_NEW_FOUND ) ) in current_sel_path : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ all ▁ new ▁ found ▁ flags " ) , self . removeAllNewFoundFlags ) , level = 0 ) NEW_LINE DEDENT DEDENT if self . inBouquet : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " rename ▁ entry " ) , self . renameEntry ) , level = 0 , key = "2" ) NEW_LINE if not inAlternativeList : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeCurrentService NEW_LINE DEDENT DEDENT if current_root and ( " flags ▁ = = ▁ % d " % ( FLAG_SERVICE_NEW_FOUND ) ) in current_root . getPath ( ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ new ▁ found ▁ flag " ) , self . removeNewFoundFlag ) , level = 0 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if self . parentalControlEnabled : NEW_LINE INDENT if self . parentalControl . getProtectionLevel ( current . toCompareString ( ) ) == - 1 : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ bouquet ▁ to ▁ parental ▁ protection " ) , boundFunction ( self . addParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ bouquet ▁ from ▁ parental ▁ protection " ) , boundFunction ( self . removeParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT DEDENT menu . append ( ChoiceEntryComponent ( text = ( _ ( " add ▁ bouquet " ) , self . showBouquetInputBox ) ) ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " rename ▁ entry " ) , self . renameEntry ) , level = 0 , key = "2" ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeBouquet NEW_LINE if removed_userbouquets_available ( ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " purge ▁ deleted ▁ userbouquets " ) , self . purgeDeletedBouquets ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " restore ▁ deleted ▁ userbouquets " ) , self . restoreDeletedBouquets ) , level = 0 ) NEW_LINE DEDENT DEDENT DEDENT if self . inBouquet : # ▁ current ▁ list ▁ is ▁ editable ? ENDCOM NEW_LINE INDENT if csel . bouquet_mark_edit == OFF : NEW_LINE INDENT if csel . movemode : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " disable ▁ move ▁ mode " ) , self . toggleMoveMode ) , level = 0 , key = "6" ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " enable ▁ move ▁ mode " ) , self . toggleMoveMode ) , level = 1 , key = "6" ) NEW_LINE DEDENT if not csel . entry_marked and not inBouquetRootList and current_root and not ( current_root . flags & eServiceReference . isGroup ) : NEW_LINE INDENT if current . type != - 1 : NEW_LINE INDENT menu . append ( ChoiceEntryComponent ( text = ( _ ( " add ▁ marker " ) , self . showMarkerInputBox ) ) ) NEW_LINE DEDENT if not csel . movemode : NEW_LINE INDENT if haveBouquets : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " enable ▁ bouquet ▁ edit " ) , self . bouquetMarkStart ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " enable ▁ favourite ▁ edit " ) , self . bouquetMarkStart ) , level = 0 ) NEW_LINE DEDENT DEDENT if current_sel_flags & eServiceReference . isGroup : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " edit ▁ alternatives " ) , self . editAlternativeServices ) , level = 2 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " show ▁ alternatives " ) , self . showAlternativeServices ) , level = 2 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " remove ▁ all ▁ alternatives " ) , self . removeAlternativeServices ) , level = 2 ) NEW_LINE DEDENT elif not current_sel_flags & eServiceReference . isMarker : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ alternatives " ) , self . addAlternativeServices ) , level = 2 ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if csel . bouquet_mark_edit == EDIT_BOUQUET : NEW_LINE INDENT if haveBouquets : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " end ▁ bouquet ▁ edit " ) , self . bouquetMarkEnd ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " abort ▁ bouquet ▁ edit " ) , self . bouquetMarkAbort ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " end ▁ favourites ▁ edit " ) , self . bouquetMarkEnd ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " abort ▁ favourites ▁ edit " ) , self . bouquetMarkAbort ) , level = 0 ) NEW_LINE DEDENT if current_sel_flags & eServiceReference . isMarker : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " rename ▁ entry " ) , self . renameEntry ) , level = 0 , key = "2" ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeCurrentService NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " end ▁ alternatives ▁ edit " ) , self . bouquetMarkEnd ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " abort ▁ alternatives ▁ edit " ) , self . bouquetMarkAbort ) , level = 0 ) NEW_LINE DEDENT DEDENT DEDENT menu . append ( ChoiceEntryComponent ( " menu " , ( _ ( " Configuration . . . " ) , self . openSetup ) ) ) NEW_LINE self [ " menu " ] = ChoiceList ( menu ) NEW_LINE DEDENT def set3DMode ( self , value ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE if config . plugins . OSD3DSetup . mode . value == " auto " and ( playingref and playingref == self . csel . getCurrentSelection ( ) ) : NEW_LINE INDENT from Plugins . SystemPlugins . OSD3DSetup . plugin import applySettings NEW_LINE applySettings ( value and " sidebyside " or config . plugins . OSD3DSetup . mode . value ) NEW_LINE DEDENT DEDENT def addDedicated3DFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . addFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_IS_DEDICATED_3D ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE self . set3DMode ( True ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeDedicated3DFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_IS_DEDICATED_3D ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE self . set3DMode ( False ) NEW_LINE self . close ( ) NEW_LINE DEDENT def addHideVBIFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . addFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_HIDE_VBI ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE Screens . InfoBar . InfoBar . instance . showHideVBI ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeHideVBIFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_HIDE_VBI ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE Screens . InfoBar . InfoBar . instance . showHideVBI ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def isProtected ( self ) : NEW_LINE INDENT return self . csel . protectContextMenu and config . ParentalControl . setuppinactive . value and config . ParentalControl . config_sections . context_menus . value NEW_LINE DEDENT def protectResult ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . csel . protectContextMenu = False NEW_LINE DEDENT elif answer is not None : NEW_LINE INDENT self . session . openWithCallback ( self . close , MessageBox , _ ( " The ▁ pin ▁ code ▁ you ▁ entered ▁ is ▁ wrong . " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def addServiceToBouquetOrAlternative ( self ) : NEW_LINE INDENT if self . addFunction : NEW_LINE INDENT self . addFunction ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def getCurrentSelectionName ( self ) : NEW_LINE INDENT cur = self . csel . getCurrentSelection ( ) NEW_LINE if cur and cur . valid ( ) : NEW_LINE INDENT name = eServiceCenter . getInstance ( ) . info ( cur ) . getName ( cur ) or ServiceReference ( cur ) . getServiceName ( ) or " " NEW_LINE name = name . replace ( ' \xc2\x86' , ' ' ) . replace ( ' \xc2\x87' , ' ' ) NEW_LINE return name NEW_LINE DEDENT return " " NEW_LINE DEDENT def removeEntry ( self ) : NEW_LINE INDENT if self . removeFunction and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) : NEW_LINE INDENT if self . csel . confirmRemove : NEW_LINE INDENT list = [ ( _ ( " yes " ) , True ) , ( _ ( " no " ) , False ) , ( _ ( " yes " ) + " ▁ " + _ ( " and ▁ never ▁ ask ▁ again ▁ this ▁ session ▁ again " ) , " never " ) ] NEW_LINE self . session . openWithCallback ( self . removeFunction , MessageBox , _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ this ▁ entry ? " ) + " \n % s " % self . getCurrentSelectionName ( ) , list = list ) NEW_LINE DEDENT else : NEW_LINE INDENT self . removeFunction ( True ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def removeCurrentService ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT if answer == " never " : NEW_LINE INDENT self . csel . confirmRemove = False NEW_LINE DEDENT self . csel . removeCurrentService ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def removeSatelliteService ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT if answer == " never " : NEW_LINE INDENT self . csel . confirmRemove = False NEW_LINE DEDENT self . csel . removeSatelliteService ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def removeBouquet ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . csel . removeBouquet ( ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def purgeDeletedBouquets ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . purgeDeletedBouquetsCallback , MessageBox , _ ( " Are ▁ you ▁ sure ▁ to ▁ purge ▁ all ▁ deleted ▁ userbouquets ? " ) ) NEW_LINE DEDENT def purgeDeletedBouquetsCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT file = " / etc / enigma2 / " + file NEW_LINE print " permantly ▁ remove ▁ file ▁ " , file NEW_LINE os . remove ( file ) NEW_LINE DEDENT DEDENT self . close ( ) NEW_LINE DEDENT DEDENT def restoreDeletedBouquets ( self ) : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT file = " / etc / enigma2 / " + file NEW_LINE print " restore ▁ file ▁ " , file [ : - 4 ] NEW_LINE os . rename ( file , file [ : - 4 ] ) NEW_LINE DEDENT DEDENT eDVBDBInstance = eDVBDB . getInstance ( ) NEW_LINE eDVBDBInstance . setLoadUnlinkedUserbouquets ( True ) NEW_LINE eDVBDBInstance . reloadBouquets ( ) NEW_LINE eDVBDBInstance . setLoadUnlinkedUserbouquets ( config . misc . load_unlinked_userbouquets . value ) NEW_LINE refreshServiceList ( ) NEW_LINE self . csel . showFavourites ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def playMain ( self ) : NEW_LINE INDENT sel = self . csel . getCurrentSelection ( ) NEW_LINE if sel and sel . valid ( ) and self . csel . dopipzap and ( not self . parentalControlEnabled or self . parentalControl . getProtectionLevel ( self . csel . getCurrentSelection ( ) . toCompareString ( ) ) == - 1 ) : NEW_LINE INDENT self . csel . zap ( ) NEW_LINE self . csel . setCurrentSelection ( sel ) NEW_LINE self . close ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def okbuttonClick ( self ) : NEW_LINE INDENT self [ " menu " ] . getCurrent ( ) [ 0 ] [ 1 ] ( ) NEW_LINE DEDENT def openSetup ( self ) : NEW_LINE INDENT from Screens . Setup import Setup NEW_LINE self . session . openWithCallback ( self . cancelClick , Setup , " userinterface " ) NEW_LINE DEDENT def cancelClick ( self , dummy = False ) : NEW_LINE INDENT self . close ( False ) NEW_LINE DEDENT def showServiceInformations ( self ) : NEW_LINE INDENT current = self . csel . getCurrentSelection ( ) NEW_LINE if current . flags & eServiceReference . isGroup : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if playingref and playingref == current : NEW_LINE INDENT current = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE DEDENT else : NEW_LINE INDENT current = eServiceReference ( GetWithAlternative ( current . toString ( ) ) ) NEW_LINE DEDENT DEDENT self . session . open ( ServiceInfo , current ) NEW_LINE self . close ( ) NEW_LINE DEDENT def setStartupService ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . setStartupServiceCallback , MessageBox , _ ( " Set ▁ startup ▁ service " ) , list = [ ( _ ( " Only ▁ on ▁ startup " ) , " startup " ) , ( _ ( " Also ▁ on ▁ standby " ) , " standby " ) ] ) NEW_LINE DEDENT def setStartupServiceCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT config . servicelist . startupservice . value = self . csel . getCurrentSelection ( ) . toString ( ) NEW_LINE path = ' ; ' . join ( [ i . toString ( ) for i in self . csel . servicePath ] ) NEW_LINE config . servicelist . startuproot . value = path NEW_LINE config . servicelist . startupmode . value = config . servicelist . lastmode . value NEW_LINE config . servicelist . startupservice_onstandby . value = answer == " standby " NEW_LINE config . servicelist . save ( ) NEW_LINE configfile . save ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def unsetStartupService ( self ) : NEW_LINE INDENT config . servicelist . startupservice . value = ' ' NEW_LINE config . servicelist . startupservice_onstandby . value = False NEW_LINE config . servicelist . save ( ) NEW_LINE configfile . save ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def showBouquetInputBox ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . bouquetInputCallback , VirtualKeyBoard , title = _ ( " Please ▁ enter ▁ a ▁ name ▁ for ▁ the ▁ new ▁ bouquet " ) , text = " bouquetname " , maxSize = False , visible_width = 56 , type = Input . TEXT ) NEW_LINE DEDENT def bouquetInputCallback ( self , bouquet ) : NEW_LINE INDENT if bouquet is not None : NEW_LINE INDENT self . csel . addBouquet ( bouquet , None ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT def addParentalProtection ( self , service ) : NEW_LINE INDENT self . parentalControl . protectService ( service . toCompareString ( ) ) NEW_LINE if config . ParentalControl . hideBlacklist . value and not self . parentalControl . sessionPinCached : NEW_LINE INDENT self . csel . servicelist . resetRoot ( ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT def removeParentalProtection ( self , service ) : NEW_LINE INDENT self . session . openWithCallback ( boundFunction ( self . pinEntered , service . toCompareString ( ) ) , PinInput , pinList = [ config . ParentalControl . servicepin [ 0 ] . value ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( " Enter ▁ the ▁ service ▁ pin " ) , windowTitle = _ ( " Enter ▁ pin ▁ code " ) ) NEW_LINE DEDENT def pinEntered ( self , service , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . parentalControl . unProtectService ( service ) NEW_LINE self . close ( ) NEW_LINE DEDENT elif answer is not None : NEW_LINE INDENT self . session . openWithCallback ( self . close , MessageBox , _ ( " The ▁ pin ▁ code ▁ you ▁ entered ▁ is ▁ wrong . " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def unhideParentalServices ( self ) : NEW_LINE INDENT if self . csel . protectContextMenu : NEW_LINE INDENT self . session . openWithCallback ( self . unhideParentalServicesCallback , PinInput , pinList = [ config . ParentalControl . servicepin [ 0 ] . value ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( " Enter ▁ the ▁ service ▁ pin " ) , windowTitle = _ ( " Enter ▁ pin ▁ code " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . unhideParentalServicesCallback ( True ) NEW_LINE DEDENT DEDENT def unhideParentalServicesCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT service = self . csel . servicelist . getCurrent ( ) NEW_LINE self . parentalControl . setSessionPinCached ( ) NEW_LINE self . parentalControl . hideBlacklist ( ) NEW_LINE self . csel . servicelist . resetRoot ( ) NEW_LINE self . csel . servicelist . setCurrent ( service ) NEW_LINE self . close ( ) NEW_LINE DEDENT elif answer is not None : NEW_LINE INDENT self . session . openWithCallback ( self . close , MessageBox , _ ( " The ▁ pin ▁ code ▁ you ▁ entered ▁ is ▁ wrong . " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def showServiceInPiP ( self ) : NEW_LINE INDENT if self . csel . dopipzap or ( self . parentalControlEnabled and not self . parentalControl . getProtectionLevel ( self . csel . getCurrentSelection ( ) . toCompareString ( ) ) == - 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if self . session . pipshown : NEW_LINE INDENT del self . session . pip NEW_LINE DEDENT self . session . pip = self . session . instantiateDialog ( PictureInPicture ) NEW_LINE self . session . pip . show ( ) NEW_LINE newservice = self . csel . servicelist . getCurrent ( ) NEW_LINE currentBouquet = self . csel . servicelist and self . csel . servicelist . getRoot ( ) NEW_LINE if newservice and newservice . valid ( ) : NEW_LINE INDENT if self . session . pip . playService ( newservice ) : NEW_LINE INDENT self . session . pipshown = True NEW_LINE self . session . pip . servicePath = self . csel . getCurrentServicePath ( ) NEW_LINE self . session . pip . servicePath [ 1 ] = currentBouquet NEW_LINE self . close ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . session . pipshown = False NEW_LINE del self . session . pip NEW_LINE self . session . openWithCallback ( self . close , MessageBox , _ ( " Could ▁ not ▁ open ▁ Picture ▁ in ▁ Picture " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def addServiceToBouquetSelected ( self ) : NEW_LINE INDENT bouquets = self . csel . getBouquetList ( ) NEW_LINE if bouquets is None : NEW_LINE INDENT cnt = 0 NEW_LINE DEDENT else : NEW_LINE INDENT cnt = len ( bouquets ) NEW_LINE DEDENT if cnt > 1 : # ▁ show ▁ bouquet ▁ list ENDCOM NEW_LINE INDENT self . bsel = self . session . openWithCallback ( self . bouquetSelClosed , BouquetSelector , bouquets , self . addCurrentServiceToBouquet ) NEW_LINE DEDENT elif cnt == 1 : # ▁ add ▁ to ▁ only ▁ one ▁ existing ▁ bouquet ENDCOM NEW_LINE INDENT self . addCurrentServiceToBouquet ( bouquets [ 0 ] [ 1 ] , closeBouquetSelection = False ) NEW_LINE DEDENT DEDENT def bouquetSelClosed ( self , recursive ) : NEW_LINE INDENT self . bsel = None NEW_LINE if recursive : NEW_LINE INDENT self . close ( False ) NEW_LINE DEDENT DEDENT def removeSatelliteServices ( self ) : NEW_LINE INDENT self . csel . removeSatelliteServices ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def copyCurrentToBouquetList ( self ) : NEW_LINE INDENT self . csel . copyCurrentToBouquetList ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def showMarkerInputBox ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . markerInputCallback , VirtualKeyBoard , title = _ ( " Please ▁ enter ▁ a ▁ name ▁ for ▁ the ▁ new ▁ marker " ) , text = " markername " , maxSize = False , visible_width = 56 , type = Input . TEXT ) NEW_LINE DEDENT def markerInputCallback ( self , marker ) : NEW_LINE INDENT if marker is not None : NEW_LINE INDENT self . csel . addMarker ( marker ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT def addCurrentServiceToBouquet ( self , dest , closeBouquetSelection = True ) : NEW_LINE INDENT self . csel . addServiceToBouquet ( dest ) NEW_LINE if self . bsel is not None : NEW_LINE INDENT self . bsel . close ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( closeBouquetSelection ) # ▁ close ▁ bouquet ▁ selection ENDCOM NEW_LINE DEDENT DEDENT def renameEntry ( self ) : NEW_LINE INDENT if self . inBouquet and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) and not self . csel . entry_marked : NEW_LINE INDENT self . csel . renameEntry ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def toggleMoveMode ( self ) : NEW_LINE INDENT if self . inBouquet and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) : NEW_LINE INDENT self . csel . toggleMoveMode ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def toggleMoveModeSelect ( self ) : NEW_LINE INDENT if self . inBouquet and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) : NEW_LINE INDENT self . csel . toggleMoveMode ( True ) NEW_LINE self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def bouquetMarkStart ( self ) : NEW_LINE INDENT self . csel . startMarkedEdit ( EDIT_BOUQUET ) NEW_LINE self . close ( ) NEW_LINE DEDENT def bouquetMarkEnd ( self ) : NEW_LINE INDENT self . csel . endMarkedEdit ( abort = False ) NEW_LINE self . close ( ) NEW_LINE DEDENT def bouquetMarkAbort ( self ) : NEW_LINE INDENT self . csel . endMarkedEdit ( abort = True ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeNewFoundFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeFlag ( self . csel . getCurrentSelection ( ) , FLAG_SERVICE_NEW_FOUND ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeAllNewFoundFlags ( self ) : NEW_LINE INDENT curpath = self . csel . getCurrentSelection ( ) . getPath ( ) NEW_LINE idx = curpath . find ( " satellitePosition ▁ = = ▁ " ) NEW_LINE if idx != - 1 : NEW_LINE INDENT tmp = curpath [ idx + 21 : ] NEW_LINE idx = tmp . find ( ' ) ' ) NEW_LINE if idx != - 1 : NEW_LINE INDENT satpos = int ( tmp [ : idx ] ) NEW_LINE eDVBDB . getInstance ( ) . removeFlags ( FLAG_SERVICE_NEW_FOUND , - 1 , - 1 , - 1 , satpos ) NEW_LINE DEDENT DEDENT self . close ( ) NEW_LINE DEDENT def editAlternativeServices ( self ) : NEW_LINE INDENT self . csel . startMarkedEdit ( EDIT_ALTERNATIVES ) NEW_LINE self . close ( ) NEW_LINE DEDENT def showAlternativeServices ( self ) : NEW_LINE INDENT self . csel [ " Service " ] . editmode = True NEW_LINE self . csel . enterPath ( self . csel . getCurrentSelection ( ) ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeAlternativeServices ( self ) : NEW_LINE INDENT self . csel . removeAlternativeServices ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def addAlternativeServices ( self ) : NEW_LINE INDENT self . csel . addAlternativeServices ( ) NEW_LINE self . csel . startMarkedEdit ( EDIT_ALTERNATIVES ) NEW_LINE self . close ( ) NEW_LINE DEDENT def findCurrentlyPlayed ( self ) : NEW_LINE INDENT sel = self . csel . getCurrentSelection ( ) NEW_LINE if sel and sel . valid ( ) and not self . csel . entry_marked : NEW_LINE INDENT currentPlayingService = ( hasattr ( self . csel , " dopipzap " ) and self . csel . dopipzap ) and self . session . pip . getCurrentService ( ) or self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE self . csel . servicelist . setCurrent ( currentPlayingService , adjust = False ) NEW_LINE if self . csel . getCurrentSelection ( ) != currentPlayingService : NEW_LINE INDENT self . csel . setCurrentSelection ( sel ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def runPlugin ( self , plugin ) : NEW_LINE INDENT plugin ( session = self . session , service = self . csel . getCurrentSelection ( ) ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT class SelectionEventInfo : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self [ " Service " ] = self [ " ServiceEvent " ] = ServiceEvent ( ) NEW_LINE self [ " Event " ] = Event ( ) NEW_LINE self . servicelist . connectSelChanged ( self . __selectionChanged ) NEW_LINE self . timer = eTimer ( ) NEW_LINE self . timer . callback . append ( self . updateEventInfo ) NEW_LINE self . onShown . append ( self . __selectionChanged ) NEW_LINE DEDENT def __selectionChanged ( self ) : NEW_LINE INDENT if self . execing : NEW_LINE INDENT self . timer . start ( 100 , True ) NEW_LINE DEDENT DEDENT def updateEventInfo ( self ) : NEW_LINE INDENT cur = self . getCurrentSelection ( ) NEW_LINE service = self [ " Service " ] NEW_LINE service . newService ( cur ) NEW_LINE self [ " Event " ] . newEvent ( service . event ) NEW_LINE DEDENT DEDENT class ChannelSelectionEPG ( InfoBarHotkey ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . hotkeys = [ ( " Info ▁ ( EPG ) " , " info " , " Infobar / openEventView " ) , ( " Info ▁ ( EPG ) " + " ▁ " + _ ( " long " ) , " info _ long " , " Infobar / showEventInfoPlugins " ) , ( " Epg / Guide " , " epg " , " Plugins / Extensions / GraphMultiEPG / 1" ) , ( " Epg / Guide " + " ▁ " + _ ( " long " ) , " epg _ long " , " Infobar / showEventInfoPlugins " ) ] NEW_LINE self [ " ChannelSelectEPGActions " ] = hotkeyActionMap ( [ " ChannelSelectEPGActions " ] , dict ( ( x [ 1 ] , self . hotkeyGlobal ) for x in self . hotkeys ) ) NEW_LINE self . eventViewEPG = self . start_bouquet = self . epg_bouquet = None NEW_LINE self . currentSavedPath = [ ] NEW_LINE DEDENT def getKeyFunctions ( self , key ) : NEW_LINE INDENT selection = eval ( " config . misc . hotkey . " + key + " . value . split ( ' , ' ) " ) NEW_LINE selected = [ ] NEW_LINE for x in selection : NEW_LINE INDENT function = list ( function for function in getHotkeyFunctions ( ) if function [ 1 ] == x and function [ 2 ] == " EPG " ) NEW_LINE if function : NEW_LINE INDENT selected . append ( function [ 0 ] ) NEW_LINE DEDENT DEDENT return selected NEW_LINE DEDENT def runPlugin ( self , plugin ) : NEW_LINE INDENT Screens . InfoBar . InfoBar . instance . runPlugin ( plugin ) NEW_LINE DEDENT def getEPGPluginList ( self , getAll = False ) : NEW_LINE INDENT pluginlist = [ ( p . name , boundFunction ( self . runPlugin , p ) , p . path ) for p in plugins . getPlugins ( where = PluginDescriptor . WHERE_EVENTINFO ) if ' selectedevent ' not in p . __call__ . func_code . co_varnames ] or [ ] NEW_LINE from Components . ServiceEventTracker import InfoBarCount NEW_LINE if getAll or InfoBarCount == 1 : NEW_LINE INDENT pluginlist . append ( ( _ ( " Show ▁ EPG ▁ for ▁ current ▁ channel . . . " ) , self . openSingleServiceEPG , " current _ channel " ) ) NEW_LINE DEDENT pluginlist . append ( ( _ ( " Multi ▁ EPG " ) , self . openMultiServiceEPG , " multi _ epg " ) ) NEW_LINE pluginlist . append ( ( _ ( " Current ▁ event ▁ EPG " ) , self . openEventView , " event _ epg " ) ) NEW_LINE return pluginlist NEW_LINE DEDENT def showEventInfoPlugins ( self ) : NEW_LINE INDENT pluginlist = self . getEPGPluginList ( ) NEW_LINE if pluginlist : NEW_LINE INDENT self . session . openWithCallback ( self . EventInfoPluginChosen , ChoiceBox , title = _ ( " Please ▁ choose ▁ an ▁ extension . . . " ) , list = pluginlist , skin_name = " EPGExtensionsList " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . openSingleServiceEPG ( ) NEW_LINE DEDENT DEDENT def EventInfoPluginChosen ( self , answer ) : NEW_LINE INDENT if answer is not None : NEW_LINE INDENT answer [ 1 ] ( ) NEW_LINE DEDENT DEDENT def openEventView ( self ) : NEW_LINE INDENT epglist = [ ] NEW_LINE self . epglist = epglist NEW_LINE ref = self . getCurrentSelection ( ) NEW_LINE epg = eEPGCache . getInstance ( ) NEW_LINE now_event = epg . lookupEventTime ( ref , - 1 , 0 ) NEW_LINE if now_event : NEW_LINE INDENT epglist . append ( now_event ) NEW_LINE next_event = epg . lookupEventTime ( ref , - 1 , 1 ) NEW_LINE if next_event : NEW_LINE INDENT epglist . append ( next_event ) NEW_LINE DEDENT DEDENT if epglist : NEW_LINE INDENT self . eventViewEPG = self . session . openWithCallback ( self . eventViewEPGClosed , EventViewEPGSelect , epglist [ 0 ] , ServiceReference ( ref ) , self . eventViewEPGCallback , self . openSingleServiceEPG , self . openMultiServiceEPG , self . openSimilarList ) NEW_LINE DEDENT DEDENT def eventViewEPGCallback ( self , setEvent , setService , val ) : NEW_LINE INDENT epglist = self . epglist NEW_LINE if len ( epglist ) > 1 : NEW_LINE INDENT tmp = epglist [ 0 ] NEW_LINE epglist [ 0 ] = epglist [ 1 ] NEW_LINE epglist [ 1 ] = tmp NEW_LINE setEvent ( epglist [ 0 ] ) NEW_LINE DEDENT DEDENT def eventViewEPGClosed ( self , ret = False ) : NEW_LINE INDENT self . eventViewEPG = None NEW_LINE if ret : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def openMultiServiceEPG ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ref : NEW_LINE INDENT self . start_bouquet = self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE self . savedService = ref NEW_LINE self . currentSavedPath = self . servicePath [ : ] NEW_LINE services = self . getServicesList ( self . servicelist . getRoot ( ) ) NEW_LINE self . session . openWithCallback ( self . SingleMultiEPGClosed , EPGSelection , services , self . zapToService , None , bouquetChangeCB = self . changeBouquetForMultiEPG ) NEW_LINE DEDENT DEDENT def openSingleServiceEPG ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ref : NEW_LINE INDENT self . start_bouquet = self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE self . savedService = ref NEW_LINE self . currentSavedPath = self . servicePath [ : ] NEW_LINE self . session . openWithCallback ( self . SingleMultiEPGClosed , EPGSelection , ref , self . zapToService , serviceChangeCB = self . changeServiceCB , bouquetChangeCB = self . changeBouquetForSingleEPG ) NEW_LINE DEDENT DEDENT def openSimilarList ( self , eventid , refstr ) : NEW_LINE INDENT self . session . open ( EPGSelection , refstr , None , eventid ) NEW_LINE DEDENT def getServicesList ( self , root ) : NEW_LINE INDENT services = [ ] NEW_LINE servicelist = root and eServiceCenter . getInstance ( ) . list ( root ) NEW_LINE if not servicelist is None : NEW_LINE INDENT while True : NEW_LINE INDENT service = servicelist . getNext ( ) NEW_LINE if not service . valid ( ) : NEW_LINE INDENT break NEW_LINE DEDENT if service . flags & ( eServiceReference . isDirectory | eServiceReference . isMarker ) : NEW_LINE INDENT continue NEW_LINE DEDENT services . append ( ServiceReference ( service ) ) NEW_LINE DEDENT DEDENT return services NEW_LINE DEDENT def SingleMultiEPGClosed ( self , ret = False ) : NEW_LINE INDENT if ret : NEW_LINE INDENT service = self . getCurrentSelection ( ) NEW_LINE if self . eventViewEPG : NEW_LINE INDENT self . eventViewEPG . close ( service ) NEW_LINE DEDENT elif service is not None : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if self . start_bouquet != self . epg_bouquet and len ( self . currentSavedPath ) > 0 : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( self . bouquet_root ) NEW_LINE self . epg_bouquet = self . start_bouquet NEW_LINE self . enterPath ( self . epg_bouquet ) NEW_LINE DEDENT self . setCurrentSelection ( self . savedService ) NEW_LINE DEDENT DEDENT def changeBouquetForSingleEPG ( self , direction , epg ) : NEW_LINE INDENT if config . usage . multibouquet . value : NEW_LINE INDENT inBouquet = self . getMutableList ( ) is not None NEW_LINE if inBouquet and len ( self . servicePath ) > 1 : NEW_LINE INDENT self . pathUp ( ) NEW_LINE if direction < 0 : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT cur = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( cur ) NEW_LINE self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE epg . setService ( ServiceReference ( self . getCurrentSelection ( ) ) ) NEW_LINE DEDENT DEDENT DEDENT def changeBouquetForMultiEPG ( self , direction , epg ) : NEW_LINE INDENT if config . usage . multibouquet . value : NEW_LINE INDENT inBouquet = self . getMutableList ( ) is not None NEW_LINE if inBouquet and len ( self . servicePath ) > 1 : NEW_LINE INDENT self . pathUp ( ) NEW_LINE if direction < 0 : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT cur = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( cur ) NEW_LINE self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE services = self . getServicesList ( self . epg_bouquet ) NEW_LINE epg . setServices ( services ) NEW_LINE DEDENT DEDENT DEDENT def changeServiceCB ( self , direction , epg ) : NEW_LINE INDENT beg = self . getCurrentSelection ( ) NEW_LINE while True : NEW_LINE INDENT if direction > 0 : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT cur = self . getCurrentSelection ( ) NEW_LINE if cur == beg or not ( cur . flags & eServiceReference . isMarker ) : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT epg . setService ( ServiceReference ( self . getCurrentSelection ( ) ) ) NEW_LINE DEDENT def zapToService ( self , service , preview = False , zapback = False ) : NEW_LINE INDENT if self . startServiceRef is None : NEW_LINE INDENT self . startServiceRef = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE DEDENT if service is not None : NEW_LINE INDENT if self . servicelist . getRoot ( ) != self . epg_bouquet : NEW_LINE INDENT self . servicelist . clearPath ( ) NEW_LINE if self . servicelist . bouquet_root != self . epg_bouquet : NEW_LINE INDENT self . servicelist . enterPath ( self . servicelist . bouquet_root ) NEW_LINE DEDENT self . servicelist . enterPath ( self . epg_bouquet ) NEW_LINE DEDENT self . servicelist . setCurrent ( service ) NEW_LINE DEDENT if not zapback or preview : NEW_LINE INDENT self . zap ( enable_pipzap = True ) NEW_LINE DEDENT if ( self . dopipzap or zapback ) and not preview : NEW_LINE INDENT self . zapBack ( ) NEW_LINE DEDENT if not preview : NEW_LINE INDENT self . startServiceRef = None NEW_LINE self . startRoot = None NEW_LINE self . revertMode = None NEW_LINE DEDENT DEDENT DEDENT class ChannelSelectionEdit : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . entry_marked = False NEW_LINE self . bouquet_mark_edit = OFF NEW_LINE self . mutableList = None NEW_LINE self . __marked = [ ] NEW_LINE self . saved_title = None NEW_LINE self . saved_root = None NEW_LINE self . current_ref = None NEW_LINE self . editMode = False NEW_LINE self . confirmRemove = True NEW_LINE class ChannelSelectionEditActionMap ( ActionMap ) : NEW_LINE INDENT def __init__ ( self , csel , contexts = [ ] , actions = { } , prio = 0 ) : NEW_LINE INDENT ActionMap . __init__ ( self , contexts , actions , prio ) NEW_LINE self . csel = csel NEW_LINE DEDENT def action ( self , contexts , action ) : NEW_LINE INDENT if action == " cancel " : NEW_LINE INDENT self . csel . handleEditCancel ( ) NEW_LINE return 0 # ▁ fall - trough ENDCOM NEW_LINE DEDENT elif action == " ok " : NEW_LINE INDENT return 0 # ▁ fall - trough ENDCOM NEW_LINE DEDENT else : NEW_LINE INDENT return ActionMap . action ( self , contexts , action ) NEW_LINE DEDENT DEDENT DEDENT self [ " ChannelSelectEditActions " ] = ChannelSelectionEditActionMap ( self , [ " ChannelSelectEditActions " , " OkCancelActions " ] , { " contextMenu " : self . doContext , } ) NEW_LINE DEDENT def getMutableList ( self , root = eServiceReference ( ) ) : NEW_LINE INDENT if not self . mutableList is None : NEW_LINE INDENT return self . mutableList NEW_LINE DEDENT serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE if not root . valid ( ) : NEW_LINE INDENT root = self . getRoot ( ) NEW_LINE DEDENT list = root and serviceHandler . list ( root ) NEW_LINE if list is not None : NEW_LINE INDENT return list . startEdit ( ) NEW_LINE DEDENT return None NEW_LINE DEDENT def buildBouquetID ( self , name ) : NEW_LINE INDENT name = unicodedata . normalize ( ' NFKD ' , unicode ( name , ' utf _ 8' , errors = ' ignore ' ) ) . encode ( ' ASCII ' , ' ignore ' ) . translate ( None , ' < > : " / \ | ? * ( ) ▁ ' ) NEW_LINE while os . path . isfile ( ( self . mode == MODE_TV and " / etc / enigma2 / userbouquet . % s . tv " or " / etc / enigma2 / userbouquet . % s . radio " ) % name ) : NEW_LINE INDENT name = name . rsplit ( " _ " , 1 ) NEW_LINE name = " _ " . join ( ( name [ 0 ] , len ( name ) == 2 and name [ 1 ] . isdigit ( ) and str ( int ( name [ 1 ] ) + 1 ) or "1" ) ) NEW_LINE DEDENT return name NEW_LINE DEDENT def renameEntry ( self ) : NEW_LINE INDENT self . editMode = True NEW_LINE cur = self . getCurrentSelection ( ) NEW_LINE if cur and cur . valid ( ) : NEW_LINE INDENT name = eServiceCenter . getInstance ( ) . info ( cur ) . getName ( cur ) or ServiceReference ( cur ) . getServiceName ( ) or " " NEW_LINE name = name . replace ( ' \xc2\x86' , ' ' ) . replace ( ' \xc2\x87' , ' ' ) NEW_LINE if name : NEW_LINE INDENT self . session . openWithCallback ( self . renameEntryCallback , VirtualKeyBoard , title = _ ( " Please ▁ enter ▁ new ▁ name : " ) , text = name ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def renameEntryCallback ( self , name ) : NEW_LINE INDENT if name : NEW_LINE INDENT mutableList = self . getMutableList ( ) NEW_LINE if mutableList : NEW_LINE INDENT current = self . servicelist . getCurrent ( ) NEW_LINE current . setName ( name ) NEW_LINE index = self . servicelist . getCurrentIndex ( ) NEW_LINE mutableList . removeService ( current , False ) NEW_LINE mutableList . addService ( current ) NEW_LINE mutableList . moveService ( current , index ) NEW_LINE mutableList . flushChanges ( ) NEW_LINE self . servicelist . addService ( current , True ) NEW_LINE self . servicelist . removeCurrent ( ) NEW_LINE if not self . servicelist . atEnd ( ) : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def addMarker ( self , name ) : NEW_LINE INDENT current = self . servicelist . getCurrent ( ) NEW_LINE mutableList = self . getMutableList ( ) NEW_LINE cnt = 0 NEW_LINE while mutableList : NEW_LINE INDENT str = '1:64 : % d : 0:0:0:0:0:0:0 : : % s ' % ( cnt , name ) NEW_LINE ref = eServiceReference ( str ) NEW_LINE if current and current . valid ( ) : NEW_LINE INDENT if not mutableList . addService ( ref , current ) : NEW_LINE INDENT self . servicelist . addService ( ref , True ) NEW_LINE mutableList . flushChanges ( ) NEW_LINE break NEW_LINE DEDENT DEDENT elif not mutableList . addService ( ref ) : NEW_LINE INDENT self . servicelist . addService ( ref , True ) NEW_LINE mutableList . flushChanges ( ) NEW_LINE break NEW_LINE DEDENT cnt += 1 NEW_LINE DEDENT DEDENT def addAlternativeServices ( self ) : NEW_LINE INDENT cur_service = ServiceReference ( self . getCurrentSelection ( ) ) NEW_LINE end = self . atEnd ( ) NEW_LINE root = self . getRoot ( ) NEW_LINE cur_root = root and ServiceReference ( root ) NEW_LINE mutableBouquet = cur_root . list ( ) . startEdit ( ) NEW_LINE if mutableBouquet : NEW_LINE INDENT name = cur_service . getServiceName ( ) NEW_LINE refstr = ' _ ' . join ( cur_service . ref . toString ( ) . split ( ' : ' ) ) NEW_LINE if self . mode == MODE_TV : NEW_LINE INDENT str = '1:134:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ \ " alternatives . % s . tv\ " ▁ ORDER ▁ BY ▁ bouquet ' % ( refstr ) NEW_LINE DEDENT else : NEW_LINE INDENT str = '1:134:2:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ \ " alternatives . % s . radio\ " ▁ ORDER ▁ BY ▁ bouquet ' % ( refstr ) NEW_LINE DEDENT new_ref = ServiceReference ( str ) NEW_LINE if not mutableBouquet . addService ( new_ref . ref , cur_service . ref ) : NEW_LINE INDENT mutableBouquet . removeService ( cur_service . ref ) NEW_LINE mutableBouquet . flushChanges ( ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE mutableAlternatives = new_ref . list ( ) . startEdit ( ) NEW_LINE if mutableAlternatives : NEW_LINE INDENT mutableAlternatives . setListName ( name ) NEW_LINE if mutableAlternatives . addService ( cur_service . ref ) : NEW_LINE INDENT print " add " , cur_service . ref . toString ( ) , " to ▁ new ▁ alternatives ▁ failed " NEW_LINE DEDENT mutableAlternatives . flushChanges ( ) NEW_LINE self . servicelist . addService ( new_ref . ref , True ) NEW_LINE self . servicelist . removeCurrent ( ) NEW_LINE if not end : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT if cur_service . ref . toString ( ) == self . lastservice . value : NEW_LINE INDENT self . saveChannel ( new_ref . ref ) NEW_LINE DEDENT if self . startServiceRef and cur_service . ref == self . startServiceRef : NEW_LINE INDENT self . startServiceRef = new_ref . ref NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " get ▁ mutable ▁ list ▁ for ▁ new ▁ created ▁ alternatives ▁ failed " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " add " , str , " to " , cur_root . getServiceName ( ) , " failed " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " bouquetlist ▁ is ▁ not ▁ editable " NEW_LINE DEDENT DEDENT def addBouquet ( self , bName , services ) : NEW_LINE INDENT serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE mutableBouquetList = serviceHandler . list ( self . bouquet_root ) . startEdit ( ) NEW_LINE if mutableBouquetList : NEW_LINE INDENT bName = self . buildBouquetID ( bName ) NEW_LINE new_bouquet_ref = eServiceReference ( ( self . mode == MODE_TV and '1:7:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " userbouquet . % s . tv " ▁ ORDER ▁ BY ▁ bouquet ' or '1:7:2:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " userbouquet . % s . radio " ▁ ORDER ▁ BY ▁ bouquet ' ) % bName ) NEW_LINE if not mutableBouquetList . addService ( new_bouquet_ref ) : NEW_LINE INDENT mutableBouquetList . flushChanges ( ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE mutableBouquet = serviceHandler . list ( new_bouquet_ref ) . startEdit ( ) NEW_LINE if mutableBouquet : NEW_LINE INDENT mutableBouquet . setListName ( bName ) NEW_LINE if services is not None : NEW_LINE INDENT for service in services : NEW_LINE INDENT if mutableBouquet . addService ( service ) : NEW_LINE INDENT print " add " , service . toString ( ) , " to ▁ new ▁ bouquet ▁ failed " NEW_LINE DEDENT DEDENT DEDENT mutableBouquet . flushChanges ( ) NEW_LINE DEDENT else : NEW_LINE INDENT print " get ▁ mutable ▁ list ▁ for ▁ new ▁ created ▁ bouquet ▁ failed " NEW_LINE # ▁ do ▁ some ▁ voodoo ▁ to ▁ check ▁ if ▁ current _ root ▁ is ▁ equal ▁ to ▁ bouquet _ root ENDCOM DEDENT cur_root = self . getRoot ( ) ; NEW_LINE str1 = cur_root and cur_root . toString ( ) NEW_LINE pos1 = str1 and str1 . find ( " FROM ▁ BOUQUET " ) or - 1 NEW_LINE pos2 = self . bouquet_rootstr . find ( " FROM ▁ BOUQUET " ) NEW_LINE if pos1 != - 1 and pos2 != - 1 and str1 [ pos1 : ] == self . bouquet_rootstr [ pos2 : ] : NEW_LINE INDENT self . servicelist . addService ( new_bouquet_ref ) NEW_LINE self . servicelist . resetRoot ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " add " , str , " to ▁ bouquets ▁ failed " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " bouquetlist ▁ is ▁ not ▁ editable " NEW_LINE DEDENT DEDENT def copyCurrentToBouquetList ( self ) : NEW_LINE INDENT provider = ServiceReference ( self . getCurrentSelection ( ) ) NEW_LINE providerName = provider . getServiceName ( ) NEW_LINE serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE services = serviceHandler . list ( provider . ref ) NEW_LINE self . addBouquet ( providerName , services and services . getContent ( ' R ' , True ) ) NEW_LINE DEDENT def removeAlternativeServices ( self ) : NEW_LINE INDENT cur_service = ServiceReference ( self . getCurrentSelection ( ) ) NEW_LINE end = self . atEnd ( ) NEW_LINE root = self . getRoot ( ) NEW_LINE cur_root = root and ServiceReference ( root ) NEW_LINE list = cur_service . list ( ) NEW_LINE first_in_alternative = list and list . getNext ( ) NEW_LINE if first_in_alternative : NEW_LINE INDENT edit_root = cur_root and cur_root . list ( ) . startEdit ( ) NEW_LINE if edit_root : NEW_LINE INDENT if not edit_root . addService ( first_in_alternative , cur_service . ref ) : NEW_LINE INDENT self . servicelist . addService ( first_in_alternative , True ) NEW_LINE if cur_service . ref . toString ( ) == self . lastservice . value : NEW_LINE INDENT self . saveChannel ( first_in_alternative ) NEW_LINE DEDENT if self . startServiceRef and cur_service . ref == self . startServiceRef : NEW_LINE INDENT self . startServiceRef = first_in_alternative NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " couldn ' t ▁ add ▁ first ▁ alternative ▁ service ▁ to ▁ current ▁ root " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " couldn ' t ▁ edit ▁ current ▁ root ! ! " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " remove ▁ empty ▁ alternative ▁ list ▁ ! ! " NEW_LINE DEDENT self . removeBouquet ( ) NEW_LINE if not end : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT DEDENT def removeBouquet ( self ) : NEW_LINE INDENT refstr = self . getCurrentSelection ( ) . toString ( ) NEW_LINE print " removeBouquet " , refstr NEW_LINE pos = refstr . find ( ' FROM ▁ BOUQUET ▁ " ' ) NEW_LINE filename = None NEW_LINE self . removeCurrentService ( bouquet = True ) NEW_LINE DEDENT def removeSatelliteService ( self ) : NEW_LINE INDENT current = self . getCurrentSelection ( ) NEW_LINE eDVBDB . getInstance ( ) . removeService ( current ) NEW_LINE refreshServiceList ( ) NEW_LINE if not self . atEnd ( ) : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT DEDENT def removeSatelliteServices ( self ) : NEW_LINE INDENT current = self . getCurrentSelection ( ) NEW_LINE unsigned_orbpos = current . getUnsignedData ( 4 ) >> 16 NEW_LINE if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT messageText = _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ all ▁ cable ▁ services ? " ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT messageText = _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ all ▁ terrestrial ▁ services ? " ) NEW_LINE DEDENT else : NEW_LINE INDENT if unsigned_orbpos > 1800 : NEW_LINE INDENT unsigned_orbpos = 3600 - unsigned_orbpos NEW_LINE direction = _ ( " W " ) NEW_LINE DEDENT else : NEW_LINE INDENT direction = _ ( " E " ) NEW_LINE DEDENT messageText = _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ all ▁ % d . % d % s % s ▁ services ? " ) % ( unsigned_orbpos / 10 , unsigned_orbpos % 10 , " \xc2\xb0" , direction ) NEW_LINE DEDENT self . session . openWithCallback ( self . removeSatelliteServicesCallback , MessageBox , messageText ) NEW_LINE DEDENT def removeSatelliteServicesCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT currentIndex = self . servicelist . getCurrentIndex ( ) NEW_LINE current = self . getCurrentSelection ( ) NEW_LINE unsigned_orbpos = current . getUnsignedData ( 4 ) >> 16 NEW_LINE if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeServices ( int ( "0xFFFF0000" , 16 ) - 0x100000000 ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeServices ( int ( "0xEEEE0000" , 16 ) - 0x100000000 ) NEW_LINE DEDENT else : NEW_LINE INDENT curpath = current . getPath ( ) NEW_LINE idx = curpath . find ( " satellitePosition ▁ = = ▁ " ) NEW_LINE if idx != - 1 : NEW_LINE INDENT tmp = curpath [ idx + 21 : ] NEW_LINE idx = tmp . find ( ' ) ' ) NEW_LINE if idx != - 1 : NEW_LINE INDENT satpos = int ( tmp [ : idx ] ) NEW_LINE eDVBDB . getInstance ( ) . removeServices ( - 1 , - 1 , - 1 , satpos ) NEW_LINE DEDENT DEDENT DEDENT refreshServiceList ( ) NEW_LINE if hasattr ( self , ' showSatellites ' ) : NEW_LINE INDENT self . showSatellites ( ) NEW_LINE self . servicelist . moveToIndex ( currentIndex ) NEW_LINE if currentIndex != self . servicelist . getCurrentIndex ( ) : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . moveEnd ) NEW_LINE # ▁ multiple ▁ marked ▁ entry ▁ stuff ▁ ( ▁ edit ▁ mode , ▁ later ▁ multiepg ▁ selection ▁ ) ENDCOM DEDENT DEDENT DEDENT DEDENT def startMarkedEdit ( self , type ) : NEW_LINE INDENT self . savedPath = self . servicePath [ : ] NEW_LINE if type == EDIT_ALTERNATIVES : NEW_LINE INDENT self . current_ref = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( self . current_ref ) NEW_LINE DEDENT self . mutableList = self . getMutableList ( ) NEW_LINE # ▁ add ▁ all ▁ services ▁ from ▁ the ▁ current ▁ list ▁ to ▁ internal ▁ marked ▁ set ▁ in ▁ listboxservicecontent ENDCOM self . clearMarks ( ) # ▁ this ▁ clears ▁ the ▁ internal ▁ marked ▁ set ▁ in ▁ the ▁ listboxservicecontent ENDCOM NEW_LINE self . saved_title = self . getTitle ( ) NEW_LINE pos = self . saved_title . find ( ' ) ' ) NEW_LINE new_title = self . saved_title [ : pos + 1 ] NEW_LINE if type == EDIT_ALTERNATIVES : NEW_LINE INDENT self . bouquet_mark_edit = EDIT_ALTERNATIVES NEW_LINE new_title += ' ▁ ' + _ ( " [ alternative ▁ edit ] " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . bouquet_mark_edit = EDIT_BOUQUET NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT new_title += ' ▁ ' + _ ( " [ bouquet ▁ edit ] " ) NEW_LINE DEDENT else : NEW_LINE INDENT new_title += ' ▁ ' + _ ( " [ favourite ▁ edit ] " ) NEW_LINE DEDENT DEDENT self . setTitle ( new_title ) NEW_LINE self . __marked = self . servicelist . getRootServices ( ) NEW_LINE for x in self . __marked : NEW_LINE INDENT self . servicelist . addMarked ( eServiceReference ( x ) ) NEW_LINE DEDENT self [ " Service " ] . editmode = True NEW_LINE DEDENT def endMarkedEdit ( self , abort ) : NEW_LINE INDENT if not abort and self . mutableList is not None : NEW_LINE INDENT new_marked = set ( self . servicelist . getMarked ( ) ) NEW_LINE old_marked = set ( self . __marked ) NEW_LINE removed = old_marked - new_marked NEW_LINE added = new_marked - old_marked NEW_LINE changed = False NEW_LINE for x in removed : NEW_LINE INDENT changed = True NEW_LINE self . mutableList . removeService ( eServiceReference ( x ) ) NEW_LINE DEDENT for x in added : NEW_LINE INDENT changed = True NEW_LINE self . mutableList . addService ( eServiceReference ( x ) ) NEW_LINE DEDENT if changed : NEW_LINE INDENT if self . bouquet_mark_edit == EDIT_ALTERNATIVES and not new_marked and self . __marked : NEW_LINE INDENT self . mutableList . addService ( eServiceReference ( self . __marked [ 0 ] ) ) NEW_LINE DEDENT self . mutableList . flushChanges ( ) NEW_LINE DEDENT DEDENT self . __marked = [ ] NEW_LINE self . clearMarks ( ) NEW_LINE self . bouquet_mark_edit = OFF NEW_LINE self . mutableList = None NEW_LINE self . setTitle ( self . saved_title ) NEW_LINE self . saved_title = None NEW_LINE # ▁ self . servicePath ▁ is ▁ just ▁ a ▁ reference ▁ to ▁ servicePathTv ▁ or ▁ Radio . . . ENDCOM # ▁ so ▁ we ▁ never ▁ ever ▁ do ▁ use ▁ the ▁ asignment ▁ operator ▁ in ▁ self . servicePath ENDCOM del self . servicePath [ : ] # ▁ remove ▁ all ▁ elements ENDCOM NEW_LINE self . servicePath += self . savedPath # ▁ add ▁ saved ▁ elements ENDCOM NEW_LINE del self . savedPath NEW_LINE self . setRoot ( self . servicePath [ - 1 ] ) NEW_LINE if self . current_ref : NEW_LINE INDENT self . setCurrentSelection ( self . current_ref ) NEW_LINE self . current_ref = None NEW_LINE DEDENT DEDENT def clearMarks ( self ) : NEW_LINE INDENT self . servicelist . clearMarks ( ) NEW_LINE DEDENT def doMark ( self ) : NEW_LINE INDENT ref = self . servicelist . getCurrent ( ) NEW_LINE if self . servicelist . isMarked ( ref ) : NEW_LINE INDENT self . servicelist . removeMarked ( ref ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . addMarked ( ref ) NEW_LINE DEDENT DEDENT def removeCurrentEntry ( self , bouquet = False ) : NEW_LINE INDENT if self . confirmRemove : NEW_LINE INDENT list = [ ( _ ( " yes " ) , True ) , ( _ ( " no " ) , False ) , ( _ ( " yes " ) + " ▁ " + _ ( " and ▁ never ▁ ask ▁ again ▁ this ▁ session ▁ again " ) , " never " ) ] NEW_LINE self . session . openWithCallback ( boundFunction ( self . removeCurrentEntryCallback , bouquet ) , MessageBox , _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ this ▁ entry ? " ) , list = list ) NEW_LINE DEDENT else : NEW_LINE INDENT self . removeCurrentEntryCallback ( bouquet , True ) NEW_LINE DEDENT DEDENT def removeCurrentEntryCallback ( self , bouquet , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT if answer == " never " : NEW_LINE INDENT self . confirmRemove = False NEW_LINE DEDENT if bouquet : NEW_LINE INDENT self . removeBouquet ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . removeCurrentService ( ) NEW_LINE DEDENT DEDENT DEDENT def removeCurrentService ( self , bouquet = False ) : NEW_LINE INDENT self . editMode = True NEW_LINE ref = self . servicelist . getCurrent ( ) NEW_LINE mutableList = self . getMutableList ( ) NEW_LINE if ref . valid ( ) and mutableList is not None : NEW_LINE INDENT if not mutableList . removeService ( ref ) : NEW_LINE INDENT mutableList . flushChanges ( ) # FIXME ▁ dont ▁ flush ▁ on ▁ each ▁ single ▁ removed ▁ service ENDCOM NEW_LINE self . servicelist . removeCurrent ( ) NEW_LINE self . servicelist . resetRoot ( ) NEW_LINE playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if not bouquet and playingref and ref == playingref : NEW_LINE INDENT self . channelSelected ( doClose = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def addServiceToBouquet ( self , dest , service = None ) : NEW_LINE INDENT mutableList = self . getMutableList ( dest ) NEW_LINE if not mutableList is None : NEW_LINE INDENT if service is None : # use ▁ current ▁ selected ▁ service ENDCOM NEW_LINE INDENT service = self . servicelist . getCurrent ( ) NEW_LINE DEDENT if not mutableList . addService ( service ) : NEW_LINE INDENT mutableList . flushChanges ( ) NEW_LINE # ▁ do ▁ some ▁ voodoo ▁ to ▁ check ▁ if ▁ current _ root ▁ is ▁ equal ▁ to ▁ dest ENDCOM cur_root = self . getRoot ( ) ; NEW_LINE str1 = cur_root and cur_root . toString ( ) or - 1 NEW_LINE str2 = dest . toString ( ) NEW_LINE pos1 = str1 . find ( " FROM ▁ BOUQUET " ) NEW_LINE pos2 = str2 . find ( " FROM ▁ BOUQUET " ) NEW_LINE if pos1 != - 1 and pos2 != - 1 and str1 [ pos1 : ] == str2 [ pos2 : ] : NEW_LINE INDENT self . servicelist . addService ( service ) NEW_LINE DEDENT self . servicelist . resetRoot ( ) NEW_LINE DEDENT DEDENT DEDENT def toggleMoveMode ( self , select = False ) : NEW_LINE INDENT self . editMode = True NEW_LINE if self . movemode : NEW_LINE INDENT if self . entry_marked : NEW_LINE INDENT self . toggleMoveMarked ( ) # ▁ unmark ▁ current ▁ entry ENDCOM NEW_LINE DEDENT self . movemode = False NEW_LINE self . mutableList . flushChanges ( ) # ▁ FIXME ▁ add ▁ check ▁ if ▁ changes ▁ was ▁ made ENDCOM NEW_LINE self . mutableList = None NEW_LINE self . setTitle ( self . saved_title ) NEW_LINE self . saved_title = None NEW_LINE self . servicelist . resetRoot ( ) NEW_LINE self . servicelist . l . setHideNumberMarker ( config . usage . hide_number_markers . value ) NEW_LINE self . setCurrentSelection ( self . servicelist . getCurrent ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . mutableList = self . getMutableList ( ) NEW_LINE self . movemode = True NEW_LINE select and self . toggleMoveMarked ( ) NEW_LINE self . saved_title = self . getTitle ( ) NEW_LINE pos = self . saved_title . find ( ' ) ' ) NEW_LINE self . setTitle ( self . saved_title [ : pos + 1 ] + ' ▁ ' + _ ( " [ move ▁ mode ] " ) + self . saved_title [ pos + 1 : ] ) ; NEW_LINE self . servicelist . l . setHideNumberMarker ( False ) NEW_LINE self . setCurrentSelection ( self . servicelist . getCurrent ( ) ) NEW_LINE DEDENT self [ " Service " ] . editmode = True NEW_LINE DEDENT def handleEditCancel ( self ) : NEW_LINE INDENT if self . movemode : # movemode ▁ active ? ENDCOM NEW_LINE INDENT self . toggleMoveMode ( ) # ▁ disable ▁ move ▁ mode ENDCOM NEW_LINE DEDENT elif self . bouquet_mark_edit != OFF : NEW_LINE INDENT self . endMarkedEdit ( True ) # ▁ abort ▁ edit ▁ mode ENDCOM NEW_LINE DEDENT DEDENT def toggleMoveMarked ( self ) : NEW_LINE INDENT if self . entry_marked : NEW_LINE INDENT self . servicelist . setCurrentMarked ( False ) NEW_LINE self . entry_marked = False NEW_LINE self . pathChangeDisabled = False # ▁ re - enable ▁ path ▁ change ENDCOM NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . setCurrentMarked ( True ) NEW_LINE self . entry_marked = True NEW_LINE self . pathChangeDisabled = True # ▁ no ▁ path ▁ change ▁ allowed ▁ in ▁ movemod ENDCOM NEW_LINE DEDENT DEDENT def doContext ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . exitContext , ChannelContextMenu , self ) NEW_LINE DEDENT def exitContext ( self , close = False ) : NEW_LINE INDENT if close : NEW_LINE INDENT self . cancel ( ) NEW_LINE DEDENT DEDENT DEDENT MODE_TV = 0 NEW_LINE MODE_RADIO = 1 NEW_LINE # ▁ type ▁ 1 ▁ = ▁ digital ▁ television ▁ service ENDCOM # ▁ type ▁ 4 ▁ = ▁ nvod ▁ reference ▁ service ▁ ( NYI ) ENDCOM # ▁ type ▁ 17 ▁ = ▁ MPEG - 2 ▁ HD ▁ digital ▁ television ▁ service ENDCOM # ▁ type ▁ 22 ▁ = ▁ advanced ▁ codec ▁ SD ▁ digital ▁ television ENDCOM # ▁ type ▁ 24 ▁ = ▁ advanced ▁ codec ▁ SD ▁ NVOD ▁ reference ▁ service ▁ ( NYI ) ENDCOM # ▁ type ▁ 25 ▁ = ▁ advanced ▁ codec ▁ HD ▁ digital ▁ television ENDCOM # ▁ type ▁ 27 ▁ = ▁ advanced ▁ codec ▁ HD ▁ NVOD ▁ reference ▁ service ▁ ( NYI ) ENDCOM # ▁ type ▁ 2 ▁ = ▁ digital ▁ radio ▁ sound ▁ service ENDCOM # ▁ type ▁ 10 ▁ = ▁ advanced ▁ codec ▁ digital ▁ radio ▁ sound ▁ service ENDCOM # ▁ type ▁ 31 ▁ = ▁ High ▁ Efficiency ▁ Video ▁ Coing ▁ digital ▁ television ENDCOM service_types_tv = '1:7:1:0:0:0:0:0:0:0 : ( type ▁ = = ▁ 1 ) ▁ | | ▁ ( type ▁ = = ▁ 17 ) ▁ | | ▁ ( type ▁ = = ▁ 22 ) ▁ | | ▁ ( type ▁ = = ▁ 25 ) ▁ | | ▁ ( type ▁ = = ▁ 31 ) ▁ | | ▁ ( type ▁ = = ▁ 134 ) ▁ | | ▁ ( type ▁ = = ▁ 195 ) ' NEW_LINE service_types_radio = '1:7:2:0:0:0:0:0:0:0 : ( type ▁ = = ▁ 2 ) ▁ | | ▁ ( type ▁ = = ▁ 10 ) ' NEW_LINE class ChannelSelectionBase ( Screen ) : NEW_LINE INDENT def __init__ ( self , session ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self . setScreenPathMode ( None ) NEW_LINE self [ " key _ red " ] = Button ( _ ( " All " ) ) NEW_LINE self [ " key _ green " ] = Button ( _ ( " Satellites " ) ) NEW_LINE self [ " key _ yellow " ] = Button ( _ ( " Provider " ) ) NEW_LINE self [ " key _ blue " ] = Button ( _ ( " Favourites " ) ) NEW_LINE self [ " list " ] = ServiceList ( self ) NEW_LINE self . servicelist = self [ " list " ] NEW_LINE self . numericalTextInput = NumericalTextInput ( handleTimeout = False ) NEW_LINE self . numericalTextInput . setUseableChars ( u ' 1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ ' ) NEW_LINE self . servicePathTV = [ ] NEW_LINE self . servicePathRadio = [ ] NEW_LINE self . servicePath = [ ] NEW_LINE self . history = [ ] NEW_LINE self . rootChanged = False NEW_LINE self . startRoot = None NEW_LINE self . selectionNumber = " " NEW_LINE self . clearNumberSelectionNumberTimer = eTimer ( ) NEW_LINE self . clearNumberSelectionNumberTimer . callback . append ( self . clearNumberSelectionNumber ) NEW_LINE self . protectContextMenu = True NEW_LINE self . mode = MODE_TV NEW_LINE self . dopipzap = False NEW_LINE self . pathChangeDisabled = False NEW_LINE self . movemode = False NEW_LINE self . showSatDetails = False NEW_LINE self [ " ChannelSelectBaseActions " ] = NumberActionMap ( [ " ChannelSelectBaseActions " , " NumberActions " , " InputAsciiActions " ] , { " showFavourites " : self . showFavourites , " showAllServices " : self . showAllServices , " showProviders " : self . showProviders , " showSatellites " : boundFunction ( self . showSatellites , changeMode = True ) , " nextBouquet " : self . nextBouquet , " prevBouquet " : self . prevBouquet , " nextMarker " : self . nextMarker , " prevMarker " : self . prevMarker , " gotAsciiCode " : self . keyAsciiCode , " keyLeft " : self . keyLeft , " keyRight " : self . keyRight , " keyRecord " : self . keyRecord , "1" : self . keyNumberGlobal , "2" : self . keyNumberGlobal , "3" : self . keyNumberGlobal , "4" : self . keyNumberGlobal , "5" : self . keyNumberGlobal , "6" : self . keyNumberGlobal , "7" : self . keyNumberGlobal , "8" : self . keyNumberGlobal , "9" : self . keyNumberGlobal , "0" : self . keyNumber0 } , - 2 ) NEW_LINE self . maintitle = _ ( " Channel ▁ selection " ) NEW_LINE self . recallBouquetMode ( ) NEW_LINE DEDENT def getBouquetNumOffset ( self , bouquet ) : NEW_LINE INDENT if not config . usage . multibouquet . value : NEW_LINE INDENT return 0 NEW_LINE DEDENT str = bouquet . toString ( ) NEW_LINE offset = 0 NEW_LINE if ' userbouquet . ' in bouquet . toCompareString ( ) : NEW_LINE INDENT serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE servicelist = serviceHandler . list ( bouquet ) NEW_LINE if not servicelist is None : NEW_LINE INDENT while True : NEW_LINE INDENT serviceIterator = servicelist . getNext ( ) NEW_LINE if not serviceIterator . valid ( ) : # check ▁ if ▁ end ▁ of ▁ list ENDCOM NEW_LINE INDENT break NEW_LINE DEDENT number = serviceIterator . getChannelNum ( ) NEW_LINE if number > 0 : NEW_LINE INDENT offset = number - 1 NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT DEDENT return offset NEW_LINE DEDENT def recallBouquetMode ( self ) : NEW_LINE INDENT if self . mode == MODE_TV : NEW_LINE INDENT self . service_types = service_types_tv NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT self . bouquet_rootstr = '1:7:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " bouquets . tv " ▁ ORDER ▁ BY ▁ bouquet ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bouquet_rootstr = ' % s ▁ FROM ▁ BOUQUET ▁ " userbouquet . favourites . tv " ▁ ORDER ▁ BY ▁ bouquet ' % ( self . service_types ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . service_types = service_types_radio NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT self . bouquet_rootstr = '1:7:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " bouquets . radio " ▁ ORDER ▁ BY ▁ bouquet ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bouquet_rootstr = ' % s ▁ FROM ▁ BOUQUET ▁ " userbouquet . favourites . radio " ▁ ORDER ▁ BY ▁ bouquet ' % ( self . service_types ) NEW_LINE DEDENT DEDENT self . bouquet_root = eServiceReference ( self . bouquet_rootstr ) NEW_LINE DEDENT def setTvMode ( self ) : NEW_LINE INDENT self . mode = MODE_TV NEW_LINE self . servicePath = self . servicePathTV NEW_LINE self . recallBouquetMode ( ) NEW_LINE title = self . maintitle NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE DEDENT title += _ ( " ▁ ( TV ) " ) NEW_LINE self . setTitle ( title ) NEW_LINE DEDENT def setRadioMode ( self ) : NEW_LINE INDENT self . mode = MODE_RADIO NEW_LINE self . servicePath = self . servicePathRadio NEW_LINE self . recallBouquetMode ( ) NEW_LINE title = self . maintitle NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE DEDENT title += _ ( " ▁ ( Radio ) " ) NEW_LINE self . setTitle ( title ) NEW_LINE DEDENT def setRoot ( self , root , justSet = False ) : NEW_LINE INDENT if self . startRoot is None : NEW_LINE INDENT self . startRoot = self . getRoot ( ) NEW_LINE DEDENT path = root . getPath ( ) NEW_LINE isBouquet = ' FROM ▁ BOUQUET ' in path and ( root . flags & eServiceReference . isDirectory ) NEW_LINE inBouquetRootList = ' FROM ▁ BOUQUET ▁ " bouquets . ' in path # FIXME ▁ HACK ENDCOM NEW_LINE if not inBouquetRootList and isBouquet : NEW_LINE INDENT self . servicelist . setMode ( ServiceList . MODE_FAVOURITES ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . setMode ( ServiceList . MODE_NORMAL ) NEW_LINE DEDENT self . servicelist . setRoot ( root , justSet ) NEW_LINE self . rootChanged = True NEW_LINE self . buildTitleString ( ) NEW_LINE DEDENT def removeModeStr ( self , str ) : NEW_LINE INDENT if self . mode == MODE_TV : NEW_LINE INDENT pos = str . find ( _ ( " ▁ ( TV ) " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT pos = str . find ( _ ( " ▁ ( Radio ) " ) ) NEW_LINE DEDENT if pos != - 1 : NEW_LINE INDENT return str [ : pos ] NEW_LINE DEDENT return str NEW_LINE DEDENT def getServiceName ( self , ref ) : NEW_LINE INDENT str = self . removeModeStr ( ServiceReference ( ref ) . getServiceName ( ) ) NEW_LINE if ' bouquets ' in str . lower ( ) : NEW_LINE INDENT return _ ( " User ▁ - ▁ bouquets " ) NEW_LINE DEDENT if not str : NEW_LINE INDENT pathstr = ref . getPath ( ) NEW_LINE if ' FROM ▁ PROVIDERS ' in pathstr : NEW_LINE INDENT return _ ( " Provider " ) NEW_LINE DEDENT if ' FROM ▁ SATELLITES ' in pathstr : NEW_LINE INDENT return _ ( " Satellites " ) NEW_LINE DEDENT if ' ) ▁ ORDER ▁ BY ▁ name ' in pathstr : NEW_LINE INDENT return _ ( " All " ) NEW_LINE DEDENT DEDENT return str NEW_LINE DEDENT def buildTitleString ( self ) : NEW_LINE INDENT titleStr = self . getTitle ( ) NEW_LINE pos = titleStr . find ( ' ] ' ) NEW_LINE if pos == - 1 : NEW_LINE INDENT pos = titleStr . find ( ' ) ' ) NEW_LINE DEDENT if pos != - 1 : NEW_LINE INDENT titleStr = titleStr [ : pos + 1 ] NEW_LINE Len = len ( self . servicePath ) NEW_LINE if Len > 0 : NEW_LINE INDENT base_ref = self . servicePath [ 0 ] NEW_LINE if Len > 1 : NEW_LINE INDENT end_ref = self . servicePath [ Len - 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT end_ref = None NEW_LINE DEDENT nameStr = self . getServiceName ( base_ref ) NEW_LINE titleStr += ' ▁ - ▁ ' + nameStr NEW_LINE if end_ref is not None : NEW_LINE INDENT if Len > 2 : NEW_LINE INDENT titleStr += ' / . . / ' NEW_LINE DEDENT else : NEW_LINE INDENT titleStr += ' / ' NEW_LINE DEDENT nameStr = self . getServiceName ( end_ref ) NEW_LINE titleStr += nameStr NEW_LINE DEDENT self . setTitle ( titleStr ) NEW_LINE DEDENT DEDENT DEDENT def moveUp ( self ) : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT def moveDown ( self ) : NEW_LINE INDENT self . servicelist . moveDown ( ) NEW_LINE DEDENT def clearPath ( self ) : NEW_LINE INDENT del self . servicePath [ : ] NEW_LINE DEDENT def enterPath ( self , ref , justSet = False ) : NEW_LINE INDENT self . servicePath . append ( ref ) NEW_LINE self . setRoot ( ref , justSet ) NEW_LINE DEDENT def enterUserbouquet ( self , root , save_root = True ) : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . recallBouquetMode ( ) NEW_LINE if self . bouquet_root : NEW_LINE INDENT self . enterPath ( self . bouquet_root ) NEW_LINE DEDENT self . enterPath ( root ) NEW_LINE self . startRoot = None NEW_LINE if save_root : NEW_LINE INDENT self . saveRoot ( ) NEW_LINE DEDENT DEDENT def pathUp ( self , justSet = False ) : NEW_LINE INDENT prev = self . servicePath . pop ( ) NEW_LINE if self . servicePath : NEW_LINE INDENT current = self . servicePath [ - 1 ] NEW_LINE self . setRoot ( current , justSet ) NEW_LINE if not justSet : NEW_LINE INDENT self . setCurrentSelection ( prev ) NEW_LINE DEDENT DEDENT return prev NEW_LINE DEDENT def isBasePathEqual ( self , ref ) : NEW_LINE INDENT if len ( self . servicePath ) > 1 and self . servicePath [ 0 ] == ref : NEW_LINE INDENT return True NEW_LINE DEDENT return False NEW_LINE DEDENT def isPrevPathEqual ( self , ref ) : NEW_LINE INDENT length = len ( self . servicePath ) NEW_LINE if length > 1 and self . servicePath [ length - 2 ] == ref : NEW_LINE INDENT return True NEW_LINE DEDENT return False NEW_LINE DEDENT def preEnterPath ( self , refstr ) : NEW_LINE INDENT return False NEW_LINE DEDENT def showAllServices ( self ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT refstr = ' % s ▁ ORDER ▁ BY ▁ name ' % ( self . service_types ) NEW_LINE if not self . preEnterPath ( refstr ) : NEW_LINE INDENT ref = eServiceReference ( refstr ) NEW_LINE currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != ref : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( ref ) NEW_LINE playingref = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE if playingref : NEW_LINE INDENT self . setCurrentSelectionAlternative ( playingref ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def showSatellites ( self , changeMode = False ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT refstr = ' % s ▁ FROM ▁ SATELLITES ▁ ORDER ▁ BY ▁ satellitePosition ' % ( self . service_types ) NEW_LINE if not self . preEnterPath ( refstr ) : NEW_LINE INDENT ref = eServiceReference ( refstr ) NEW_LINE justSet = False NEW_LINE prev = None NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT if self . isPrevPathEqual ( ref ) : NEW_LINE INDENT justSet = True NEW_LINE DEDENT prev = self . pathUp ( justSet ) NEW_LINE DEDENT else : NEW_LINE INDENT currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != ref : NEW_LINE INDENT justSet = True NEW_LINE self . clearPath ( ) NEW_LINE self . enterPath ( ref , True ) NEW_LINE DEDENT if changeMode and currentRoot and currentRoot == ref : NEW_LINE INDENT self . showSatDetails = not self . showSatDetails NEW_LINE justSet = True NEW_LINE self . clearPath ( ) NEW_LINE self . enterPath ( ref , True ) NEW_LINE DEDENT DEDENT if justSet : NEW_LINE INDENT addCableAndTerrestrialLater = [ ] NEW_LINE serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE servicelist = serviceHandler . list ( ref ) NEW_LINE if not servicelist is None : NEW_LINE INDENT while True : NEW_LINE INDENT service = servicelist . getNext ( ) NEW_LINE if not service . valid ( ) : # check ▁ if ▁ end ▁ of ▁ list ENDCOM NEW_LINE INDENT break NEW_LINE DEDENT unsigned_orbpos = service . getUnsignedData ( 4 ) >> 16 NEW_LINE orbpos = service . getData ( 4 ) >> 16 NEW_LINE if orbpos < 0 : NEW_LINE INDENT orbpos += 3600 NEW_LINE DEDENT if " FROM ▁ PROVIDER " in service . getPath ( ) : NEW_LINE INDENT service_type = self . showSatDetails and _ ( " Providers " ) NEW_LINE DEDENT elif ( " flags ▁ = = ▁ % d " % ( FLAG_SERVICE_NEW_FOUND ) ) in service . getPath ( ) : NEW_LINE INDENT service_type = self . showSatDetails and _ ( " New " ) NEW_LINE DEDENT else : NEW_LINE INDENT service_type = _ ( " Services " ) NEW_LINE DEDENT if service_type : NEW_LINE INDENT if unsigned_orbpos == 0xFFFF : # Cable ENDCOM NEW_LINE INDENT service_name = _ ( " Cable " ) NEW_LINE addCableAndTerrestrialLater . append ( ( " % s ▁ - ▁ % s " % ( service_name , service_type ) , service . toString ( ) ) ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : # Terrestrial ENDCOM NEW_LINE INDENT service_name = _ ( " Terrestrial " ) NEW_LINE addCableAndTerrestrialLater . append ( ( " % s ▁ - ▁ % s " % ( service_name , service_type ) , service . toString ( ) ) ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT service_name = str ( nimmanager . getSatDescription ( orbpos ) ) NEW_LINE DEDENT except : NEW_LINE INDENT if orbpos > 1800 : # ▁ west ENDCOM NEW_LINE INDENT orbpos = 3600 - orbpos NEW_LINE h = _ ( " W " ) NEW_LINE DEDENT else : NEW_LINE INDENT h = _ ( " E " ) NEW_LINE DEDENT service_name = ( " % d . % d " + h ) % ( orbpos / 10 , orbpos % 10 ) NEW_LINE DEDENT service . setName ( " % s ▁ - ▁ % s " % ( service_name , service_type ) ) NEW_LINE self . servicelist . addService ( service ) NEW_LINE DEDENT DEDENT DEDENT cur_ref = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE self . servicelist . l . sort ( ) NEW_LINE if cur_ref : NEW_LINE INDENT pos = self . service_types . rfind ( ' : ' ) NEW_LINE refstr = ' % s ▁ ( channelID ▁ = = ▁ % 08x % 04x % 04x ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name ' % ( self . service_types [ : pos + 1 ] , cur_ref . getUnsignedData ( 4 ) , # ▁ NAMESPACE ENDCOM cur_ref . getUnsignedData ( 2 ) , # ▁ TSID ENDCOM cur_ref . getUnsignedData ( 3 ) , # ▁ ONID ENDCOM self . service_types [ pos + 1 : ] ) NEW_LINE ref = eServiceReference ( refstr ) NEW_LINE ref . setName ( _ ( " Current ▁ transponder " ) ) NEW_LINE self . servicelist . addService ( ref , beforeCurrent = True ) NEW_LINE DEDENT for ( service_name , service_ref ) in addCableAndTerrestrialLater : NEW_LINE INDENT ref = eServiceReference ( service_ref ) NEW_LINE ref . setName ( service_name ) NEW_LINE self . servicelist . addService ( ref , beforeCurrent = True ) NEW_LINE DEDENT self . servicelist . l . FillFinished ( ) NEW_LINE if prev is not None : NEW_LINE INDENT self . setCurrentSelection ( prev ) NEW_LINE DEDENT elif cur_ref : NEW_LINE INDENT refstr = cur_ref . toString ( ) NEW_LINE op = " " . join ( refstr . split ( ' : ' , 10 ) [ 6 : 7 ] ) NEW_LINE if len ( op ) >= 4 : NEW_LINE INDENT hop = int ( op [ : - 4 ] , 16 ) NEW_LINE if len ( op ) >= 7 and not op . endswith ( '0000' ) : NEW_LINE INDENT op = op [ : - 4 ] + '0000' NEW_LINE DEDENT refstr = '1:7:0:0:0:0 : % s : 0:0:0 : ( satellitePosition ▁ = = ▁ % s ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name ' % ( op , hop , self . service_types [ self . service_types . rfind ( ' : ' ) + 1 : ] ) NEW_LINE self . setCurrentSelectionAlternative ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT def showProviders ( self ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT refstr = ' % s ▁ FROM ▁ PROVIDERS ▁ ORDER ▁ BY ▁ name ' % ( self . service_types ) NEW_LINE if not self . preEnterPath ( refstr ) : NEW_LINE INDENT ref = eServiceReference ( refstr ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . pathUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != ref : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( ref ) NEW_LINE service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT provider = info . getInfoString ( iServiceInformation . sProvider ) NEW_LINE refstr = '1:7:0:0:0:0:0:0:0:0 : ( provider ▁ = = ▁ \ " % s\ " ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name : % s ' % ( provider , self . service_types [ self . service_types . rfind ( ' : ' ) + 1 : ] , provider ) NEW_LINE self . setCurrentSelectionAlternative ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT def changeBouquet ( self , direction ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT if len ( self . servicePath ) > 1 : NEW_LINE # when ▁ enter ▁ satellite ▁ root ▁ list ▁ we ▁ must ▁ do ▁ some ▁ magic ▁ stuff . . ENDCOM INDENT ref = eServiceReference ( ' % s ▁ FROM ▁ SATELLITES ▁ ORDER ▁ BY ▁ satellitePosition ' % ( self . service_types ) ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . showSatellites ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . pathUp ( ) NEW_LINE DEDENT if direction < 0 : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT ref = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( ref ) NEW_LINE DEDENT DEDENT DEDENT def inBouquet ( self ) : NEW_LINE INDENT if self . servicePath and self . servicePath [ 0 ] == self . bouquet_root : NEW_LINE INDENT return True NEW_LINE DEDENT return False NEW_LINE DEDENT def atBegin ( self ) : NEW_LINE INDENT return self . servicelist . atBegin ( ) NEW_LINE DEDENT def atEnd ( self ) : NEW_LINE INDENT return self . servicelist . atEnd ( ) NEW_LINE DEDENT def nextBouquet ( self ) : NEW_LINE INDENT if self . shown and config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageUp ) NEW_LINE DEDENT elif " reverseB " in config . usage . servicelist_cursor_behavior . value : NEW_LINE INDENT self . changeBouquet ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . changeBouquet ( + 1 ) NEW_LINE DEDENT DEDENT def prevBouquet ( self ) : NEW_LINE INDENT if self . shown and config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageDown ) NEW_LINE DEDENT elif " reverseB " in config . usage . servicelist_cursor_behavior . value : NEW_LINE INDENT self . changeBouquet ( + 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . changeBouquet ( - 1 ) NEW_LINE DEDENT DEDENT def keyLeft ( self ) : NEW_LINE INDENT if config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . changeBouquet ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageUp ) NEW_LINE DEDENT DEDENT def keyRight ( self ) : NEW_LINE INDENT if config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . changeBouquet ( + 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageDown ) NEW_LINE DEDENT DEDENT def keyRecord ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ref and not ( ref . flags & ( eServiceReference . isMarker | eServiceReference . isDirectory ) ) : NEW_LINE INDENT Screens . InfoBar . InfoBar . instance . instantRecord ( serviceRef = ref ) NEW_LINE DEDENT DEDENT def showFavourites ( self ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT if not self . preEnterPath ( self . bouquet_rootstr ) : NEW_LINE INDENT if self . isBasePathEqual ( self . bouquet_root ) : NEW_LINE INDENT self . pathUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != self . bouquet_root : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( self . bouquet_root ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def keyNumber0 ( self , number ) : NEW_LINE INDENT if len ( self . servicePath ) > 1 and not self . selectionNumber : NEW_LINE INDENT self . keyGoUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . keyNumberGlobal ( number ) NEW_LINE DEDENT DEDENT def keyNumberGlobal ( self , number ) : NEW_LINE INDENT if self . isBasePathEqual ( self . bouquet_root ) : NEW_LINE INDENT if hasattr ( self , " editMode " ) and self . editMode : NEW_LINE INDENT if number == 2 : NEW_LINE INDENT self . renameEntry ( ) NEW_LINE DEDENT if number == 6 : NEW_LINE INDENT self . toggleMoveMode ( select = True ) NEW_LINE DEDENT if number == 8 : NEW_LINE INDENT self . removeCurrentEntry ( bouquet = False ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . numberSelectionActions ( number ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT current_root = self . getRoot ( ) NEW_LINE if current_root and ' FROM ▁ BOUQUET ▁ " bouquets . ' in current_root . getPath ( ) : NEW_LINE INDENT if hasattr ( self , " editMode " ) and self . editMode : NEW_LINE INDENT if number == 2 : NEW_LINE INDENT self . renameEntry ( ) NEW_LINE DEDENT if number == 6 : NEW_LINE INDENT self . toggleMoveMode ( select = True ) NEW_LINE DEDENT if number == 8 : NEW_LINE INDENT self . removeCurrentEntry ( bouquet = True ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . numberSelectionActions ( number ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT unichar = self . numericalTextInput . getKey ( number ) NEW_LINE charstr = unichar . encode ( " utf - 8" ) NEW_LINE if len ( charstr ) == 1 : NEW_LINE INDENT self . servicelist . moveToChar ( charstr [ 0 ] ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def numberSelectionActions ( self , number ) : NEW_LINE INDENT if not ( hasattr ( self , " movemode " ) and self . movemode ) : NEW_LINE INDENT if len ( self . selectionNumber ) > 4 : NEW_LINE INDENT self . clearNumberSelectionNumber ( ) NEW_LINE DEDENT self . selectionNumber = self . selectionNumber + str ( number ) NEW_LINE ref , bouquet = Screens . InfoBar . InfoBar . instance . searchNumber ( int ( self . selectionNumber ) , bouquet = self . getRoot ( ) ) NEW_LINE if ref : NEW_LINE INDENT if not ref . flags & eServiceReference . isMarker : NEW_LINE INDENT self . enterUserbouquet ( bouquet , save_root = False ) NEW_LINE self . setCurrentSelection ( ref ) NEW_LINE DEDENT self . clearNumberSelectionNumberTimer . start ( 1000 , True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . clearNumberSelectionNumber ( ) NEW_LINE DEDENT DEDENT DEDENT def clearNumberSelectionNumber ( self ) : NEW_LINE INDENT self . clearNumberSelectionNumberTimer . stop ( ) NEW_LINE self . selectionNumber = " " NEW_LINE DEDENT def keyAsciiCode ( self ) : NEW_LINE INDENT unichar = unichr ( getPrevAsciiCode ( ) ) NEW_LINE charstr = unichar . encode ( " utf - 8" ) NEW_LINE if len ( charstr ) == 1 : NEW_LINE INDENT self . servicelist . moveToChar ( charstr [ 0 ] ) NEW_LINE DEDENT DEDENT def getRoot ( self ) : NEW_LINE INDENT return self . servicelist . getRoot ( ) NEW_LINE DEDENT def getCurrentSelection ( self ) : NEW_LINE INDENT return self . servicelist . getCurrent ( ) NEW_LINE DEDENT def setCurrentSelection ( self , service ) : NEW_LINE INDENT if service : NEW_LINE INDENT self . servicelist . setCurrent ( service , adjust = False ) NEW_LINE DEDENT DEDENT def setCurrentSelectionAlternative ( self , ref ) : NEW_LINE INDENT if self . bouquet_mark_edit == EDIT_ALTERNATIVES and not ( ref . flags & eServiceReference . isDirectory ) : NEW_LINE INDENT for markedService in self . servicelist . getMarked ( ) : NEW_LINE INDENT markedService = eServiceReference ( markedService ) NEW_LINE self . setCurrentSelection ( markedService ) NEW_LINE if markedService == self . getCurrentSelection ( ) : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT DEDENT self . setCurrentSelection ( ref ) NEW_LINE DEDENT def getBouquetList ( self ) : NEW_LINE INDENT bouquets = [ ] NEW_LINE serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT list = serviceHandler . list ( self . bouquet_root ) NEW_LINE if list : NEW_LINE INDENT while True : NEW_LINE INDENT s = list . getNext ( ) NEW_LINE if not s . valid ( ) : NEW_LINE INDENT break NEW_LINE DEDENT if s . flags & eServiceReference . isDirectory and not s . flags & eServiceReference . isInvisible : NEW_LINE INDENT info = serviceHandler . info ( s ) NEW_LINE if info : NEW_LINE INDENT bouquets . append ( ( info . getName ( s ) , s ) ) NEW_LINE DEDENT DEDENT DEDENT return bouquets NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT info = serviceHandler . info ( self . bouquet_root ) NEW_LINE if info : NEW_LINE INDENT bouquets . append ( ( info . getName ( self . bouquet_root ) , self . bouquet_root ) ) NEW_LINE DEDENT return bouquets NEW_LINE DEDENT return None NEW_LINE DEDENT def keyGoUp ( self ) : NEW_LINE INDENT if len ( self . servicePath ) > 1 : NEW_LINE INDENT if self . isBasePathEqual ( self . bouquet_root ) : NEW_LINE INDENT self . showFavourites ( ) NEW_LINE DEDENT else : NEW_LINE INDENT ref = eServiceReference ( ' % s ▁ FROM ▁ SATELLITES ▁ ORDER ▁ BY ▁ satellitePosition ' % ( self . service_types ) ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . showSatellites ( ) NEW_LINE DEDENT else : NEW_LINE INDENT ref = eServiceReference ( ' % s ▁ FROM ▁ PROVIDERS ▁ ORDER ▁ BY ▁ name ' % ( self . service_types ) ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . showProviders ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showAllServices ( ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def nextMarker ( self ) : NEW_LINE INDENT self . servicelist . moveToNextMarker ( ) NEW_LINE DEDENT def prevMarker ( self ) : NEW_LINE INDENT self . servicelist . moveToPrevMarker ( ) NEW_LINE DEDENT def gotoCurrentServiceOrProvider ( self , ref ) : NEW_LINE INDENT str = ref . toString ( ) NEW_LINE if _ ( " Providers " ) in str : NEW_LINE INDENT service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT provider = info . getInfoString ( iServiceInformation . sProvider ) NEW_LINE op = int ( self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) . toString ( ) . split ( ' : ' ) [ 6 ] [ : - 4 ] or "0" , 16 ) NEW_LINE refstr = '1:7:0:0:0:0:0:0:0:0 : ( provider ▁ = = ▁ \ " % s\ " ) ▁ & & ▁ ( satellitePosition ▁ = = ▁ % s ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name : % s ' % ( provider , op , self . service_types [ self . service_types . rfind ( ' : ' ) + 1 : ] , provider ) NEW_LINE self . setCurrentSelection ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT elif not self . isBasePathEqual ( self . bouquet_root ) or self . bouquet_mark_edit == EDIT_ALTERNATIVES : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if playingref : NEW_LINE INDENT self . setCurrentSelectionAlternative ( playingref ) NEW_LINE DEDENT DEDENT DEDENT DEDENT HISTORYSIZE = 20 NEW_LINE # config ▁ for ▁ lastservice ENDCOM config . tv = ConfigSubsection ( ) NEW_LINE config . tv . lastservice = ConfigText ( ) NEW_LINE config . tv . lastroot = ConfigText ( ) NEW_LINE config . radio = ConfigSubsection ( ) NEW_LINE config . radio . lastservice = ConfigText ( ) NEW_LINE config . radio . lastroot = ConfigText ( ) NEW_LINE config . servicelist = ConfigSubsection ( ) NEW_LINE config . servicelist . lastmode = ConfigText ( default = " tv " ) NEW_LINE config . servicelist . startupservice = ConfigText ( ) NEW_LINE config . servicelist . startupservice_onstandby = ConfigYesNo ( default = False ) NEW_LINE config . servicelist . startuproot = ConfigText ( ) NEW_LINE config . servicelist . startupmode = ConfigText ( default = " tv " ) NEW_LINE class ChannelSelection ( ChannelSelectionBase , ChannelSelectionEdit , ChannelSelectionEPG , SelectionEventInfo ) : NEW_LINE INDENT def __init__ ( self , session ) : NEW_LINE INDENT ChannelSelectionBase . __init__ ( self , session ) NEW_LINE ChannelSelectionEdit . __init__ ( self ) NEW_LINE ChannelSelectionEPG . __init__ ( self ) NEW_LINE SelectionEventInfo . __init__ ( self ) NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " TvRadioActions " ] , { " cancel " : self . cancel , " ok " : self . channelSelected , " keyRadio " : self . doRadioButton , " keyTV " : self . doTVButton , } ) NEW_LINE self . __event_tracker = ServiceEventTracker ( screen = self , eventmap = { iPlayableService . evStart : self . __evServiceStart , iPlayableService . evEnd : self . __evServiceEnd } ) NEW_LINE self . startServiceRef = None NEW_LINE self . history = [ ] NEW_LINE self . history_pos = 0 NEW_LINE if config . servicelist . startupservice . value and config . servicelist . startuproot . value : NEW_LINE INDENT config . servicelist . lastmode . value = config . servicelist . startupmode . value NEW_LINE if config . servicelist . lastmode . value == " tv " : NEW_LINE INDENT config . tv . lastservice . value = config . servicelist . startupservice . value NEW_LINE config . tv . lastroot . value = config . servicelist . startuproot . value NEW_LINE DEDENT elif config . servicelist . lastmode . value == " radio " : NEW_LINE INDENT config . radio . lastservice . value = config . servicelist . startupservice . value NEW_LINE config . radio . lastroot . value = config . servicelist . startuproot . value NEW_LINE DEDENT DEDENT self . lastservice = config . tv . lastservice NEW_LINE self . lastroot = config . tv . lastroot NEW_LINE self . revertMode = None NEW_LINE config . usage . multibouquet . addNotifier ( self . multibouquet_config_changed ) NEW_LINE self . new_service_played = False NEW_LINE self . dopipzap = False NEW_LINE self . onExecBegin . append ( self . asciiOn ) NEW_LINE self . mainScreenMode = None NEW_LINE self . mainScreenRoot = None NEW_LINE self . lastChannelRootTimer = eTimer ( ) NEW_LINE self . lastChannelRootTimer . callback . append ( self . __onCreate ) NEW_LINE self . lastChannelRootTimer . start ( 100 , True ) NEW_LINE self . pipzaptimer = eTimer ( ) NEW_LINE DEDENT def asciiOn ( self ) : NEW_LINE INDENT rcinput = eRCInput . getInstance ( ) NEW_LINE rcinput . setKeyboardMode ( rcinput . kmAscii ) NEW_LINE DEDENT def asciiOff ( self ) : NEW_LINE INDENT rcinput = eRCInput . getInstance ( ) NEW_LINE rcinput . setKeyboardMode ( rcinput . kmNone ) NEW_LINE DEDENT def multibouquet_config_changed ( self , val ) : NEW_LINE INDENT self . recallBouquetMode ( ) NEW_LINE DEDENT def __evServiceStart ( self ) : NEW_LINE INDENT if self . dopipzap and hasattr ( self . session , ' pip ' ) : NEW_LINE INDENT self . servicelist . setPlayableIgnoreService ( self . session . pip . getCurrentServiceReference ( ) or eServiceReference ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT refstr = info . getInfoString ( iServiceInformation . sServiceref ) NEW_LINE self . servicelist . setPlayableIgnoreService ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def __evServiceEnd ( self ) : NEW_LINE INDENT self . servicelist . setPlayableIgnoreService ( eServiceReference ( ) ) NEW_LINE DEDENT def setMode ( self ) : NEW_LINE INDENT self . rootChanged = True NEW_LINE self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT DEDENT def doTVButton ( self ) : NEW_LINE INDENT if self . mode == MODE_TV : NEW_LINE INDENT self . channelSelected ( doClose = False ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT DEDENT def setModeTv ( self ) : NEW_LINE INDENT if self . revertMode is None : NEW_LINE INDENT self . revertMode = self . mode NEW_LINE DEDENT self . lastservice = config . tv . lastservice NEW_LINE self . lastroot = config . tv . lastroot NEW_LINE config . servicelist . lastmode . value = " tv " NEW_LINE self . setTvMode ( ) NEW_LINE self . setMode ( ) NEW_LINE DEDENT def doRadioButton ( self ) : NEW_LINE INDENT if self . mode == MODE_RADIO : NEW_LINE INDENT self . channelSelected ( doClose = False ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT DEDENT def setModeRadio ( self ) : NEW_LINE INDENT if self . revertMode is None : NEW_LINE INDENT self . revertMode = self . mode NEW_LINE DEDENT if config . usage . e1like_radio_mode . value : NEW_LINE INDENT self . lastservice = config . radio . lastservice NEW_LINE self . lastroot = config . radio . lastroot NEW_LINE config . servicelist . lastmode . value = " radio " NEW_LINE self . setRadioMode ( ) NEW_LINE self . setMode ( ) NEW_LINE DEDENT DEDENT def __onCreate ( self ) : NEW_LINE INDENT if config . usage . e1like_radio_mode . value : NEW_LINE INDENT if config . servicelist . lastmode . value == " tv " : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . zap ( ) NEW_LINE DEDENT DEDENT def channelSelected ( self , doClose = True ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if config . usage . channelselection_preview . value and ( playingref is None or self . getCurrentSelection ( ) and self . getCurrentSelection ( ) != playingref ) : NEW_LINE INDENT doClose = False NEW_LINE DEDENT if not self . startServiceRef and not doClose : NEW_LINE INDENT self . startServiceRef = playingref NEW_LINE DEDENT ref = self . getCurrentSelection ( ) NEW_LINE if self . movemode and ( self . isBasePathEqual ( self . bouquet_root ) or " userbouquet . " in ref . toString ( ) ) : NEW_LINE INDENT self . toggleMoveMarked ( ) NEW_LINE DEDENT elif ( ref . flags & eServiceReference . flagDirectory ) == eServiceReference . flagDirectory : NEW_LINE INDENT if Components . ParentalControl . parentalControl . isServicePlayable ( ref , self . bouquetParentalControlCallback , self . session ) : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE self . revertMode = None NEW_LINE DEDENT DEDENT elif self . bouquet_mark_edit != OFF : NEW_LINE INDENT if not ( self . bouquet_mark_edit == EDIT_ALTERNATIVES and ref . flags & eServiceReference . isGroup ) : NEW_LINE INDENT self . doMark ( ) NEW_LINE DEDENT DEDENT elif not ( ref . flags & eServiceReference . isMarker or ref . type == - 1 ) : NEW_LINE INDENT root = self . getRoot ( ) NEW_LINE if not root or not ( root . flags & eServiceReference . isGroup ) : NEW_LINE INDENT self . zap ( enable_pipzap = doClose , preview_zap = not doClose ) NEW_LINE self . asciiOff ( ) NEW_LINE if doClose : NEW_LINE INDENT if self . dopipzap : NEW_LINE INDENT self . zapBack ( ) NEW_LINE DEDENT self . startServiceRef = None NEW_LINE self . startRoot = None NEW_LINE self . correctChannelNumber ( ) NEW_LINE self . movemode and self . toggleMoveMode ( ) NEW_LINE self . editMode = False NEW_LINE self . protectContextMenu = True NEW_LINE self . close ( ref ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def bouquetParentalControlCallback ( self , ref ) : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE self . revertMode = None NEW_LINE DEDENT def togglePipzap ( self ) : NEW_LINE INDENT assert ( self . session . pip ) NEW_LINE title = self . instance . getTitle ( ) NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE DEDENT if self . dopipzap : NEW_LINE # ▁ Mark ▁ PiP ▁ as ▁ inactive ▁ and ▁ effectively ▁ deactivate ▁ pipzap ENDCOM INDENT self . hidePipzapMessage ( ) NEW_LINE self . dopipzap = False NEW_LINE # ▁ Disable ▁ PiP ▁ if ▁ not ▁ playing ▁ a ▁ service ENDCOM if self . session . pip . pipservice is None : NEW_LINE INDENT self . session . pipshown = False NEW_LINE del self . session . pip NEW_LINE DEDENT self . __evServiceStart ( ) NEW_LINE # ▁ Move ▁ to ▁ playing ▁ service ENDCOM lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) and self . getCurrentSelection ( ) != lastservice : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE if self . getCurrentSelection ( ) != lastservice : NEW_LINE INDENT self . servicelist . setCurrent ( lastservice ) NEW_LINE DEDENT DEDENT title += _ ( " ▁ ( TV ) " ) NEW_LINE DEDENT else : NEW_LINE # ▁ Mark ▁ PiP ▁ as ▁ active ▁ and ▁ effectively ▁ active ▁ pipzap ENDCOM INDENT self . showPipzapMessage ( ) NEW_LINE self . dopipzap = True NEW_LINE self . __evServiceStart ( ) NEW_LINE # ▁ Move ▁ to ▁ service ▁ playing ▁ in ▁ pip ▁ ( will ▁ not ▁ work ▁ with ▁ subservices ) ENDCOM self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE title += _ ( " ▁ ( PiP ) " ) NEW_LINE DEDENT self . setTitle ( title ) NEW_LINE self . buildTitleString ( ) NEW_LINE DEDENT def showPipzapMessage ( self ) : NEW_LINE INDENT time = config . usage . infobar_timeout . index NEW_LINE if time : NEW_LINE INDENT self . pipzaptimer . callback . append ( self . hidePipzapMessage ) NEW_LINE self . pipzaptimer . startLongTimer ( time ) NEW_LINE DEDENT self . session . pip . active ( ) NEW_LINE DEDENT def hidePipzapMessage ( self ) : NEW_LINE INDENT if self . pipzaptimer . isActive ( ) : NEW_LINE INDENT self . pipzaptimer . callback . remove ( self . hidePipzapMessage ) NEW_LINE self . pipzaptimer . stop ( ) NEW_LINE DEDENT self . session . pip . inactive ( ) NEW_LINE # called ▁ from ▁ infoBar ▁ and ▁ channelSelected ENDCOM DEDENT def zap ( self , enable_pipzap = False , preview_zap = False , checkParentalControl = True , ref = None ) : NEW_LINE INDENT self . curRoot = self . startRoot NEW_LINE nref = ref or self . getCurrentSelection ( ) NEW_LINE ref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if enable_pipzap and self . dopipzap : NEW_LINE INDENT ref = self . session . pip . getCurrentService ( ) NEW_LINE if ref is None or ref != nref : NEW_LINE INDENT nref = self . session . pip . resolveAlternatePipService ( nref ) NEW_LINE if nref and ( not checkParentalControl or Components . ParentalControl . parentalControl . isServicePlayable ( nref , boundFunction ( self . zap , enable_pipzap = True , checkParentalControl = False ) ) ) : NEW_LINE INDENT self . session . pip . playService ( nref ) NEW_LINE self . __evServiceStart ( ) NEW_LINE self . showPipzapMessage ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setStartRoot ( self . curRoot ) NEW_LINE self . setCurrentSelection ( ref ) NEW_LINE DEDENT DEDENT DEDENT elif ref is None or ref != nref : NEW_LINE INDENT Screens . InfoBar . InfoBar . instance . checkTimeshiftRunning ( boundFunction ( self . zapCheckTimeshiftCallback , enable_pipzap , preview_zap , nref ) ) NEW_LINE DEDENT elif not preview_zap : NEW_LINE INDENT self . saveRoot ( ) NEW_LINE self . saveChannel ( nref ) NEW_LINE config . servicelist . lastmode . save ( ) NEW_LINE self . setCurrentSelection ( nref ) NEW_LINE if self . startServiceRef is None or nref != self . startServiceRef : NEW_LINE INDENT self . addToHistory ( nref ) NEW_LINE DEDENT self . rootChanged = False NEW_LINE self . revertMode = None NEW_LINE DEDENT DEDENT def zapCheckTimeshiftCallback ( self , enable_pipzap , preview_zap , nref , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . new_service_played = True NEW_LINE self . session . nav . playService ( nref ) NEW_LINE if not preview_zap : NEW_LINE INDENT self . saveRoot ( ) NEW_LINE self . saveChannel ( nref ) NEW_LINE config . servicelist . lastmode . save ( ) NEW_LINE if self . startServiceRef is None or nref != self . startServiceRef : NEW_LINE INDENT self . addToHistory ( nref ) NEW_LINE DEDENT if self . dopipzap : NEW_LINE INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . mainScreenMode = config . servicelist . lastmode . value NEW_LINE self . mainScreenRoot = self . getRoot ( ) NEW_LINE DEDENT self . revertMode = None NEW_LINE DEDENT else : NEW_LINE INDENT Notifications . RemovePopup ( " Parental ▁ control " ) NEW_LINE self . setCurrentSelection ( nref ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . setStartRoot ( self . curRoot ) NEW_LINE self . setCurrentSelection ( self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) ) NEW_LINE DEDENT if not preview_zap : NEW_LINE INDENT self . hide ( ) NEW_LINE DEDENT DEDENT def newServicePlayed ( self ) : NEW_LINE INDENT ret = self . new_service_played NEW_LINE self . new_service_played = False NEW_LINE return ret NEW_LINE DEDENT def addToHistory ( self , ref ) : NEW_LINE INDENT if self . servicePath is not None : NEW_LINE INDENT tmp = self . servicePath [ : ] NEW_LINE tmp . append ( ref ) NEW_LINE try : NEW_LINE INDENT del self . history [ self . history_pos + 1 : ] NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT self . history . append ( tmp ) NEW_LINE hlen = len ( self . history ) NEW_LINE if hlen > HISTORYSIZE : NEW_LINE INDENT del self . history [ 0 ] NEW_LINE hlen -= 1 NEW_LINE DEDENT self . history_pos = hlen - 1 NEW_LINE DEDENT DEDENT def historyBack ( self ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE currentPlayedRef = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if hlen > 0 and currentPlayedRef and self . history [ self . history_pos ] [ - 1 ] != currentPlayedRef : NEW_LINE INDENT self . addToHistory ( currentPlayedRef ) NEW_LINE hlen = len ( self . history ) NEW_LINE DEDENT if hlen > 1 and self . history_pos > 0 : NEW_LINE INDENT self . history_pos -= 1 NEW_LINE self . setHistoryPath ( ) NEW_LINE DEDENT DEDENT def historyNext ( self ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE if hlen > 1 and self . history_pos < ( hlen - 1 ) : NEW_LINE INDENT self . history_pos += 1 NEW_LINE self . setHistoryPath ( ) NEW_LINE DEDENT DEDENT def setHistoryPath ( self , doZap = True ) : NEW_LINE INDENT path = self . history [ self . history_pos ] [ : ] NEW_LINE ref = path . pop ( ) NEW_LINE del self . servicePath [ : ] NEW_LINE self . servicePath += path NEW_LINE self . saveRoot ( ) NEW_LINE root = path [ - 1 ] NEW_LINE cur_root = self . getRoot ( ) NEW_LINE if cur_root and cur_root != root : NEW_LINE INDENT self . setRoot ( root ) NEW_LINE DEDENT if doZap : NEW_LINE INDENT self . session . nav . playService ( ref , adjust = False ) NEW_LINE DEDENT if self . dopipzap : NEW_LINE INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setCurrentSelection ( ref ) NEW_LINE DEDENT self . saveChannel ( ref ) NEW_LINE DEDENT def saveRoot ( self ) : NEW_LINE INDENT path = ' ' NEW_LINE for i in self . servicePath : NEW_LINE INDENT path += i . toString ( ) NEW_LINE path += ' ; ' NEW_LINE DEDENT if path and path != self . lastroot . value : NEW_LINE INDENT if self . mode == MODE_RADIO and ' FROM ▁ BOUQUET ▁ " bouquets . tv " ' in path : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . mode == MODE_TV and ' FROM ▁ BOUQUET ▁ " bouquets . radio " ' in path : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . lastroot . value = path NEW_LINE self . lastroot . save ( ) NEW_LINE DEDENT DEDENT def restoreRoot ( self ) : NEW_LINE INDENT tmp = [ x for x in self . lastroot . value . split ( ' ; ' ) if x != ' ' ] NEW_LINE current = [ x . toString ( ) for x in self . servicePath ] NEW_LINE if tmp != current or self . rootChanged : NEW_LINE INDENT self . clearPath ( ) NEW_LINE cnt = 0 NEW_LINE for i in tmp : NEW_LINE INDENT self . servicePath . append ( eServiceReference ( i ) ) NEW_LINE cnt += 1 NEW_LINE DEDENT if cnt : NEW_LINE INDENT path = self . servicePath . pop ( ) NEW_LINE self . enterPath ( path ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showFavourites ( ) NEW_LINE self . saveRoot ( ) NEW_LINE DEDENT self . rootChanged = False NEW_LINE DEDENT DEDENT def preEnterPath ( self , refstr ) : NEW_LINE INDENT if self . servicePath and self . servicePath [ 0 ] != eServiceReference ( refstr ) : NEW_LINE INDENT pathstr = self . lastroot . value NEW_LINE if pathstr is not None and refstr in pathstr : NEW_LINE INDENT self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def saveChannel ( self , ref ) : NEW_LINE INDENT if ref is not None : NEW_LINE INDENT refstr = ref . toString ( ) NEW_LINE DEDENT else : NEW_LINE INDENT refstr = " " NEW_LINE DEDENT if refstr != self . lastservice . value and not Components . ParentalControl . parentalControl . isProtected ( ref ) : NEW_LINE INDENT self . lastservice . value = refstr NEW_LINE self . lastservice . save ( ) NEW_LINE DEDENT DEDENT def setCurrentServicePath ( self , path , doZap = True ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE if not hlen : NEW_LINE INDENT self . history . append ( path ) NEW_LINE self . history_pos = 0 NEW_LINE DEDENT if hlen == 1 : NEW_LINE INDENT self . history [ self . history_pos ] = path NEW_LINE DEDENT else : NEW_LINE INDENT if path in self . history : NEW_LINE INDENT self . history . remove ( path ) NEW_LINE self . history_pos -= 1 NEW_LINE DEDENT tmp = self . history [ self . history_pos ] [ : ] NEW_LINE self . history . append ( tmp ) NEW_LINE self . history_pos += 1 NEW_LINE self . history [ self . history_pos ] = path NEW_LINE DEDENT self . setHistoryPath ( doZap ) NEW_LINE DEDENT def getCurrentServicePath ( self ) : NEW_LINE INDENT if self . history : NEW_LINE INDENT return self . history [ self . history_pos ] NEW_LINE DEDENT return None NEW_LINE DEDENT def recallPrevService ( self ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE currentPlayedRef = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if hlen > 0 and currentPlayedRef and self . history [ self . history_pos ] [ - 1 ] != currentPlayedRef : NEW_LINE INDENT self . addToHistory ( currentPlayedRef ) NEW_LINE hlen = len ( self . history ) NEW_LINE DEDENT if hlen > 1 : NEW_LINE INDENT if self . history_pos == hlen - 1 : NEW_LINE INDENT tmp = self . history [ self . history_pos ] NEW_LINE self . history [ self . history_pos ] = self . history [ self . history_pos - 1 ] NEW_LINE self . history [ self . history_pos - 1 ] = tmp NEW_LINE DEDENT else : NEW_LINE INDENT tmp = self . history [ self . history_pos + 1 ] NEW_LINE self . history [ self . history_pos + 1 ] = self . history [ self . history_pos ] NEW_LINE self . history [ self . history_pos ] = tmp NEW_LINE DEDENT self . setHistoryPath ( ) NEW_LINE DEDENT DEDENT def cancel ( self ) : NEW_LINE INDENT if self . revertMode is None : NEW_LINE INDENT self . restoreRoot ( ) NEW_LINE if self . dopipzap : NEW_LINE # ▁ This ▁ unfortunately ▁ won ' t ▁ work ▁ with ▁ subservices ENDCOM INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) and self . getCurrentSelection ( ) != lastservice : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT DEDENT DEDENT self . asciiOff ( ) NEW_LINE self . zapBack ( ) NEW_LINE self . correctChannelNumber ( ) NEW_LINE self . editMode = False NEW_LINE self . protectContextMenu = True NEW_LINE self . close ( None ) NEW_LINE DEDENT def zapBack ( self ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if self . startServiceRef and ( playingref is None or playingref != self . startServiceRef ) : NEW_LINE INDENT self . setStartRoot ( self . startRoot ) NEW_LINE self . new_service_played = True NEW_LINE self . session . nav . playService ( self . startServiceRef ) NEW_LINE self . saveChannel ( self . startServiceRef ) NEW_LINE DEDENT else : NEW_LINE INDENT self . restoreMode ( ) NEW_LINE DEDENT self . startServiceRef = None NEW_LINE self . startRoot = None NEW_LINE if self . dopipzap : NEW_LINE # ▁ This ▁ unfortunately ▁ won ' t ▁ work ▁ with ▁ subservices ENDCOM INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) and self . getCurrentSelection ( ) == lastservice : NEW_LINE INDENT pass # ▁ keep ▁ current ▁ selection ENDCOM NEW_LINE DEDENT else : NEW_LINE INDENT self . setCurrentSelection ( playingref ) NEW_LINE DEDENT DEDENT DEDENT def setStartRoot ( self , root ) : NEW_LINE INDENT if root : NEW_LINE INDENT if self . revertMode == MODE_TV : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . revertMode == MODE_RADIO : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . revertMode = None NEW_LINE self . enterUserbouquet ( root ) NEW_LINE DEDENT DEDENT def restoreMode ( self ) : NEW_LINE INDENT if self . revertMode == MODE_TV : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . revertMode == MODE_RADIO : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . revertMode = None NEW_LINE DEDENT def correctChannelNumber ( self ) : NEW_LINE INDENT current_ref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if self . dopipzap : NEW_LINE INDENT tmp_mode = config . servicelist . lastmode . value NEW_LINE tmp_root = self . getRoot ( ) NEW_LINE tmp_ref = self . getCurrentSelection ( ) NEW_LINE pip_ref = self . session . pip . getCurrentService ( ) NEW_LINE if tmp_ref and pip_ref and tmp_ref != pip_ref : NEW_LINE INDENT self . revertMode = None NEW_LINE return NEW_LINE DEDENT if self . mainScreenMode == " tv " : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . mainScreenMode == " radio " : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT if self . mainScreenRoot : NEW_LINE INDENT self . setRoot ( self . mainScreenRoot ) NEW_LINE self . setCurrentSelection ( current_ref ) NEW_LINE DEDENT DEDENT selected_ref = self . getCurrentSelection ( ) NEW_LINE if selected_ref and current_ref and selected_ref . getChannelNum ( ) != current_ref . getChannelNum ( ) : NEW_LINE INDENT oldref = self . session . nav . currentlyPlayingServiceReference NEW_LINE if oldref and selected_ref == oldref or ( oldref != current_ref and selected_ref == current_ref ) : NEW_LINE INDENT self . session . nav . currentlyPlayingServiceOrGroup = selected_ref NEW_LINE self . session . nav . pnav . navEvent ( iPlayableService . evStart ) NEW_LINE DEDENT DEDENT if self . dopipzap : NEW_LINE INDENT if tmp_mode == " tv " : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif tmp_mode == " radio " : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . enterUserbouquet ( tmp_root ) NEW_LINE title = self . instance . getTitle ( ) NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE title += _ ( " ▁ ( PiP ) " ) NEW_LINE self . setTitle ( title ) NEW_LINE self . buildTitleString ( ) NEW_LINE DEDENT if tmp_ref and pip_ref and tmp_ref . getChannelNum ( ) != pip_ref . getChannelNum ( ) : NEW_LINE INDENT self . session . pip . currentService = tmp_ref NEW_LINE DEDENT self . setCurrentSelection ( tmp_ref ) NEW_LINE DEDENT self . revertMode = None NEW_LINE DEDENT DEDENT class RadioInfoBar ( Screen ) : NEW_LINE INDENT def __init__ ( self , session ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self [ " RdsDecoder " ] = RdsDecoder ( self . session . nav ) NEW_LINE DEDENT DEDENT class ChannelSelectionRadio ( ChannelSelectionBase , ChannelSelectionEdit , ChannelSelectionEPG , InfoBarBase , SelectionEventInfo ) : NEW_LINE INDENT ALLOW_SUSPEND = True NEW_LINE def __init__ ( self , session , infobar ) : NEW_LINE INDENT ChannelSelectionBase . __init__ ( self , session ) NEW_LINE ChannelSelectionEdit . __init__ ( self ) NEW_LINE ChannelSelectionEPG . __init__ ( self ) NEW_LINE InfoBarBase . __init__ ( self ) NEW_LINE SelectionEventInfo . __init__ ( self ) NEW_LINE self . infobar = infobar NEW_LINE self . startServiceRef = None NEW_LINE self . onLayoutFinish . append ( self . onCreate ) NEW_LINE self . info = session . instantiateDialog ( RadioInfoBar ) # ▁ our ▁ simple ▁ infobar ENDCOM NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " TvRadioActions " ] , { " keyTV " : self . cancel , " keyRadio " : self . cancel , " cancel " : self . cancel , " ok " : self . channelSelected , } ) NEW_LINE self . __event_tracker = ServiceEventTracker ( screen = self , eventmap = { iPlayableService . evStart : self . __evServiceStart , iPlayableService . evEnd : self . __evServiceEnd } ) NEW_LINE # # # # # ▁ RDS ▁ Radiotext ▁ / ▁ Rass ▁ Support ▁ BEGIN ENDCOM self . infobar = infobar # ▁ reference ▁ to ▁ real ▁ infobar ▁ ( the ▁ one ▁ and ▁ only ) ENDCOM NEW_LINE self [ " RdsDecoder " ] = self . info [ " RdsDecoder " ] NEW_LINE self [ " RdsActions " ] = HelpableActionMap ( self , " InfobarRdsActions " , { " startRassInteractive " : ( self . startRassInteractive , _ ( " View ▁ Rass ▁ interactive . . . " ) ) } , - 1 ) NEW_LINE self [ " RdsActions " ] . setEnabled ( False ) NEW_LINE infobar . rds_display . onRassInteractivePossibilityChanged . append ( self . RassInteractivePossibilityChanged ) NEW_LINE self . onClose . append ( self . __onClose ) NEW_LINE self . onExecBegin . append ( self . __onExecBegin ) NEW_LINE self . onExecEnd . append ( self . __onExecEnd ) NEW_LINE DEDENT def __onClose ( self ) : NEW_LINE INDENT lastservice = eServiceReference ( config . tv . lastservice . value ) NEW_LINE self . session . nav . playService ( lastservice ) NEW_LINE DEDENT def startRassInteractive ( self ) : NEW_LINE INDENT self . info . hide ( ) ; NEW_LINE self . infobar . rass_interactive = self . session . openWithCallback ( self . RassInteractiveClosed , RassInteractive ) NEW_LINE DEDENT def RassInteractiveClosed ( self ) : NEW_LINE INDENT self . info . show ( ) NEW_LINE self . infobar . rass_interactive = None NEW_LINE self . infobar . RassSlidePicChanged ( ) NEW_LINE DEDENT def RassInteractivePossibilityChanged ( self , state ) : NEW_LINE INDENT self [ " RdsActions " ] . setEnabled ( state ) NEW_LINE # # # # # ▁ RDS ▁ Radiotext ▁ / ▁ Rass ▁ Support ▁ END ENDCOM DEDENT def __onExecBegin ( self ) : NEW_LINE INDENT self . info . show ( ) NEW_LINE DEDENT def __onExecEnd ( self ) : NEW_LINE INDENT self . info . hide ( ) NEW_LINE DEDENT def cancel ( self ) : NEW_LINE INDENT self . infobar . rds_display . onRassInteractivePossibilityChanged . remove ( self . RassInteractivePossibilityChanged ) NEW_LINE self . info . hide ( ) NEW_LINE # set ▁ previous ▁ tv ▁ service ENDCOM self . close ( None ) NEW_LINE DEDENT def __evServiceStart ( self ) : NEW_LINE INDENT service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT refstr = info . getInfoString ( iServiceInformation . sServiceref ) NEW_LINE self . servicelist . setPlayableIgnoreService ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT def __evServiceEnd ( self ) : NEW_LINE INDENT self . servicelist . setPlayableIgnoreService ( eServiceReference ( ) ) NEW_LINE DEDENT def saveRoot ( self ) : NEW_LINE INDENT path = ' ' NEW_LINE for i in self . servicePathRadio : NEW_LINE INDENT path += i . toString ( ) NEW_LINE path += ' ; ' NEW_LINE DEDENT if path and path != config . radio . lastroot . value : NEW_LINE INDENT config . radio . lastroot . value = path NEW_LINE config . radio . lastroot . save ( ) NEW_LINE DEDENT DEDENT def restoreRoot ( self ) : NEW_LINE INDENT tmp = [ x for x in config . radio . lastroot . value . split ( ' ; ' ) if x != ' ' ] NEW_LINE current = [ x . toString ( ) for x in self . servicePath ] NEW_LINE if tmp != current or self . rootChanged : NEW_LINE INDENT cnt = 0 NEW_LINE for i in tmp : NEW_LINE INDENT self . servicePathRadio . append ( eServiceReference ( i ) ) NEW_LINE cnt += 1 NEW_LINE DEDENT if cnt : NEW_LINE INDENT path = self . servicePathRadio . pop ( ) NEW_LINE self . enterPath ( path ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showFavourites ( ) NEW_LINE self . saveRoot ( ) NEW_LINE DEDENT self . rootChanged = False NEW_LINE DEDENT DEDENT def preEnterPath ( self , refstr ) : NEW_LINE INDENT if self . servicePathRadio and self . servicePathRadio [ 0 ] != eServiceReference ( refstr ) : NEW_LINE INDENT pathstr = config . radio . lastroot . value NEW_LINE if pathstr is not None and refstr in pathstr : NEW_LINE INDENT self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( config . radio . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def onCreate ( self ) : NEW_LINE INDENT self . setRadioMode ( ) NEW_LINE self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( config . radio . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . servicelist . setCurrent ( lastservice ) NEW_LINE self . session . nav . playService ( lastservice ) NEW_LINE DEDENT else : NEW_LINE INDENT self . session . nav . stopService ( ) NEW_LINE DEDENT self . info . show ( ) NEW_LINE DEDENT def channelSelected ( self , doClose = False ) : # ▁ just ▁ return ▁ selected ▁ service ENDCOM NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if self . movemode : NEW_LINE INDENT self . toggleMoveMarked ( ) NEW_LINE DEDENT elif ( ref . flags & eServiceReference . flagDirectory ) == eServiceReference . flagDirectory : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE DEDENT elif self . bouquet_mark_edit != OFF : NEW_LINE INDENT if not ( self . bouquet_mark_edit == EDIT_ALTERNATIVES and ref . flags & eServiceReference . isGroup ) : NEW_LINE INDENT self . doMark ( ) NEW_LINE DEDENT DEDENT elif not ( ref . flags & eServiceReference . isMarker ) : # ▁ no ▁ marker ENDCOM NEW_LINE INDENT cur_root = self . getRoot ( ) NEW_LINE if not cur_root or not ( cur_root . flags & eServiceReference . isGroup ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if playingref is None or playingref != ref : NEW_LINE INDENT self . session . nav . playService ( ref ) NEW_LINE config . radio . lastservice . value = ref . toString ( ) NEW_LINE config . radio . lastservice . save ( ) NEW_LINE DEDENT self . saveRoot ( ) NEW_LINE DEDENT DEDENT DEDENT def zapBack ( self ) : NEW_LINE INDENT self . channelSelected ( ) NEW_LINE DEDENT DEDENT class SimpleChannelSelection ( ChannelSelectionBase , SelectionEventInfo ) : NEW_LINE INDENT def __init__ ( self , session , title , currentBouquet = False , returnBouquet = False , setService = None , setBouquet = None ) : NEW_LINE INDENT ChannelSelectionBase . __init__ ( self , session ) NEW_LINE SelectionEventInfo . __init__ ( self ) NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " TvRadioActions " ] , { " cancel " : self . close , " ok " : self . channelSelected , " keyRadio " : self . setModeRadio , " keyTV " : self . setModeTv , } ) NEW_LINE self . bouquet_mark_edit = OFF NEW_LINE if isinstance ( title , str ) : NEW_LINE INDENT self . maintitle = title NEW_LINE DEDENT self . currentBouquet = currentBouquet NEW_LINE self . returnBouquet = returnBouquet NEW_LINE self . setService = setService NEW_LINE self . setBouquet = setBouquet NEW_LINE self . onLayoutFinish . append ( self . layoutFinished ) NEW_LINE DEDENT def layoutFinished ( self ) : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE if self . currentBouquet or self . setBouquet : NEW_LINE INDENT ref = self . setBouquet or Screens . InfoBar . InfoBar . instance . servicelist . getRoot ( ) NEW_LINE if ref : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE DEDENT DEDENT if self . setService : NEW_LINE INDENT self . setCurrentSelection ( self . setService ) NEW_LINE DEDENT DEDENT def saveRoot ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def keyRecord ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT def channelSelected ( self ) : # ▁ just ▁ return ▁ selected ▁ service ENDCOM NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ( ref . flags & eServiceReference . flagDirectory ) == eServiceReference . flagDirectory : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE DEDENT elif not ( ref . flags & eServiceReference . isMarker ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if self . returnBouquet and len ( self . servicePath ) : NEW_LINE INDENT self . close ( ref , self . servicePath [ - 1 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ref ) NEW_LINE DEDENT DEDENT DEDENT def setModeTv ( self ) : NEW_LINE INDENT self . setTvMode ( ) NEW_LINE self . showFavourites ( ) NEW_LINE DEDENT def setModeRadio ( self ) : NEW_LINE INDENT self . setRadioMode ( ) NEW_LINE self . showFavourites ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="RPi-Distro/python-gpiozero/tree/master/gpiozerocli/pinout.py"> # ▁ GPIO ▁ Zero : ▁ a ▁ library ▁ for ▁ controlling ▁ the ▁ Raspberry ▁ Pi ' s ▁ GPIO ▁ pins ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2017-2019 ▁ Dave ▁ Jones ▁ < dave @ waveform . org . uk > ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2017 ▁ Ben ▁ Nuttall ▁ < ben @ bennuttall . com > ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ are ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ▁ notice , ENDCOM # ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ▁ copyright ▁ notice , ENDCOM # ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ▁ in ▁ the ▁ documentation ENDCOM # ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ the ▁ copyright ▁ holder ▁ nor ▁ the ▁ names ▁ of ▁ its ▁ contributors ENDCOM # ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ▁ this ▁ software ENDCOM # ▁ without ▁ specific ▁ prior ▁ written ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ▁ " AS ▁ IS " ENDCOM # ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ THE ENDCOM # ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ENDCOM # ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ COPYRIGHT ▁ HOLDER ▁ OR ▁ CONTRIBUTORS ▁ BE ENDCOM # ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ▁ INCIDENTAL , ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ENDCOM # ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ENDCOM # ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ENDCOM # ▁ INTERRUPTION ) ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ENDCOM # ▁ CONTRACT , ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ENDCOM # ▁ ARISING ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ENDCOM # ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM """ STRNEWLINE A ▁ utility ▁ for ▁ querying ▁ Raspberry ▁ Pi ▁ GPIO ▁ pin - out ▁ information . STRNEWLINE """ NEW_LINE from __future__ import ( unicode_literals , absolute_import , print_function , division , ) NEW_LINE import argparse NEW_LINE import sys NEW_LINE import textwrap NEW_LINE import warnings NEW_LINE import webbrowser NEW_LINE from gpiozero import pi_info NEW_LINE class PinoutTool ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . parser = argparse . ArgumentParser ( description = __doc__ ) NEW_LINE self . parser . add_argument ( ' - r ' , ' - - revision ' , dest = ' revision ' , default = ' ' , help = ' RPi ▁ revision . ▁ Default ▁ is ▁ to ▁ autodetect ▁ revision ▁ of ▁ current ▁ device ' ) NEW_LINE self . parser . add_argument ( ' - c ' , ' - - color ' , action = " store _ true " , default = None , help = ' Force ▁ colored ▁ output ▁ ( by ▁ default , ▁ the ▁ output ▁ will ▁ include ▁ ANSI ' ' color ▁ codes ▁ if ▁ run ▁ in ▁ a ▁ color - capable ▁ terminal ) . ▁ See ▁ also ▁ - - monochrome ' ) NEW_LINE self . parser . add_argument ( ' - m ' , ' - - monochrome ' , dest = ' color ' , action = ' store _ false ' , help = ' Force ▁ monochrome ▁ output . ▁ See ▁ also ▁ - - color ' ) NEW_LINE self . parser . add_argument ( ' - x ' , ' - - xyz ' , dest = ' xyz ' , action = ' store _ true ' , help = ' Open ▁ pinout . xyz ▁ in ▁ the ▁ default ▁ web ▁ browser ' ) NEW_LINE DEDENT def __call__ ( self , args = None ) : NEW_LINE INDENT if args is None : NEW_LINE INDENT args = sys . argv [ 1 : ] NEW_LINE DEDENT try : NEW_LINE INDENT return self . main ( self . parser . parse_args ( args ) ) or 0 NEW_LINE DEDENT except argparse . ArgumentError as e : NEW_LINE # ▁ argparse ▁ errors ▁ are ▁ already ▁ nicely ▁ formatted , ▁ print ▁ to ▁ stderr ▁ and ENDCOM # ▁ exit ▁ with ▁ code ▁ 2 ENDCOM INDENT raise e NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT raise NEW_LINE # ▁ Output ▁ anything ▁ else ▁ nicely ▁ formatted ▁ on ▁ stderr ▁ and ▁ exit ▁ code ▁ 1 ENDCOM self . parser . exit ( 1 , ' { prog } : ▁ error : ▁ { message } \n ' . format ( prog = self . parser . prog , message = e ) ) NEW_LINE DEDENT DEDENT def main ( self , args ) : NEW_LINE INDENT warnings . simplefilter ( ' ignore ' ) NEW_LINE if args . xyz : NEW_LINE INDENT webbrowser . open ( ' https : / / pinout . xyz ' ) NEW_LINE DEDENT else : NEW_LINE INDENT if args . revision == ' ' : NEW_LINE INDENT try : NEW_LINE INDENT pi_info ( ) . pprint ( color = args . color ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT formatter = self . parser . _get_formatter ( ) NEW_LINE formatter . add_text ( " Unable ▁ to ▁ initialize ▁ GPIO ▁ Zero . ▁ This ▁ usually ▁ means ▁ " " that ▁ you ▁ are ▁ not ▁ running ▁ % ( prog ) s ▁ on ▁ a ▁ Raspberry ▁ Pi . ▁ " " If ▁ you ▁ still ▁ wish ▁ to ▁ run ▁ % ( prog ) s , ▁ set ▁ the ▁ " " GPIOZERO _ PIN _ FACTORY ▁ environment ▁ variable ▁ to ▁ ' mock ' ▁ " " and ▁ retry , ▁ or ▁ refer ▁ to ▁ the ▁ Remote ▁ GPIO ▁ section ▁ of ▁ " " the ▁ manual * ▁ to ▁ configure ▁ your ▁ environment ▁ to ▁ " " remotely ▁ access ▁ your ▁ Pi . " ) NEW_LINE formatter . add_text ( " * ▁ https : / / gpiozero . readthedocs . io / en / stable / " " remote _ gpio . html " ) NEW_LINE sys . stderr . write ( formatter . format_help ( ) ) NEW_LINE DEDENT except IOError : NEW_LINE INDENT raise IOError ( ' This ▁ device ▁ is ▁ not ▁ a ▁ Raspberry ▁ Pi ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT pi_info ( args . revision ) . pprint ( color = args . color ) NEW_LINE DEDENT formatter = self . parser . _get_formatter ( ) NEW_LINE formatter . add_text ( " For ▁ further ▁ information , ▁ please ▁ refer ▁ to ▁ " " https : / / pinout . xyz / " ) NEW_LINE sys . stdout . write ( ' \n ' ) NEW_LINE sys . stdout . write ( formatter . format_help ( ) ) NEW_LINE DEDENT DEDENT DEDENT main = PinoutTool ( ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="mcrowson/django/tree/master/tests/choices/tests.py"> from django . test import TestCase NEW_LINE from . models import Person NEW_LINE class ChoicesTests ( TestCase ) : NEW_LINE INDENT def test_display ( self ) : NEW_LINE INDENT a = Person . objects . create ( name = ' Adrian ' , gender = ' M ' ) NEW_LINE s = Person . objects . create ( name = ' Sara ' , gender = ' F ' ) NEW_LINE self . assertEqual ( a . gender , ' M ' ) NEW_LINE self . assertEqual ( s . gender , ' F ' ) NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' Male ' ) NEW_LINE self . assertEqual ( s . get_gender_display ( ) , ' Female ' ) NEW_LINE # ▁ If ▁ the ▁ value ▁ for ▁ the ▁ field ▁ doesn ' t ▁ correspond ▁ to ▁ a ▁ valid ▁ choice , ENDCOM # ▁ the ▁ value ▁ itself ▁ is ▁ provided ▁ as ▁ a ▁ display ▁ value . ENDCOM a . gender = ' ' NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' ' ) NEW_LINE a . gender = ' U ' NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' U ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="mbrukman/libcloud/tree/master/libcloud/test/compute/test_gogrid.py"> # ▁ Licensed ▁ to ▁ the ▁ Apache ▁ Software ▁ Foundation ▁ ( ASF ) ▁ under ▁ one ▁ or ▁ more ENDCOM # ▁ contributor ▁ license ▁ agreements . ▁ See ▁ the ▁ NOTICE ▁ file ▁ distributed ▁ with ENDCOM # ▁ this ▁ work ▁ for ▁ additional ▁ information ▁ regarding ▁ copyright ▁ ownership . ENDCOM # ▁ The ▁ ASF ▁ licenses ▁ this ▁ file ▁ to ▁ You ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ENDCOM # ▁ ( the ▁ " License " ) ; ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ENDCOM # ▁ the ▁ License . ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM import sys NEW_LINE import unittest NEW_LINE from libcloud . utils . py3 import httplib NEW_LINE from libcloud . utils . py3 import urlparse NEW_LINE from libcloud . utils . py3 import parse_qs NEW_LINE from libcloud . compute . base import NodeState , NodeLocation NEW_LINE from libcloud . common . types import LibcloudError , InvalidCredsError NEW_LINE from libcloud . common . gogrid import GoGridIpAddress NEW_LINE from libcloud . compute . drivers . gogrid import GoGridNodeDriver NEW_LINE from libcloud . compute . base import Node , NodeImage , NodeSize NEW_LINE from libcloud . test import MockHttp # ▁ pylint : ▁ disable - msg = E0611 ENDCOM NEW_LINE from libcloud . test . compute import TestCaseMixin # ▁ pylint : ▁ disable - msg = E0611 ENDCOM NEW_LINE from libcloud . test . file_fixtures import ComputeFileFixtures # ▁ pylint : ▁ disable - msg = E0611 ENDCOM NEW_LINE class GoGridTests ( unittest . TestCase , TestCaseMixin ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT GoGridNodeDriver . connectionCls . conn_classes = ( None , GoGridMockHttp ) NEW_LINE GoGridMockHttp . type = None NEW_LINE self . driver = GoGridNodeDriver ( " foo " , " bar " ) NEW_LINE DEDENT def _get_test_512Mb_node_size ( self ) : NEW_LINE INDENT return NodeSize ( id = '512Mb ' , name = None , ram = None , disk = None , bandwidth = None , price = None , driver = self . driver ) NEW_LINE DEDENT def test_create_node ( self ) : NEW_LINE INDENT image = NodeImage ( 1531 , None , self . driver ) NEW_LINE node = self . driver . create_node ( name = ' test1' , image = image , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE self . assertEqual ( node . name , ' test1' ) NEW_LINE self . assertTrue ( node . id is not None ) NEW_LINE self . assertEqual ( node . extra [ ' password ' ] , ' bebebe ' ) NEW_LINE DEDENT def test_list_nodes ( self ) : NEW_LINE INDENT node = self . driver . list_nodes ( ) [ 0 ] NEW_LINE self . assertEqual ( node . id , '90967' ) NEW_LINE self . assertEqual ( node . extra [ ' password ' ] , ' bebebe ' ) NEW_LINE self . assertEqual ( node . extra [ ' description ' ] , ' test ▁ server ' ) NEW_LINE DEDENT def test_reboot_node ( self ) : NEW_LINE INDENT node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE ret = self . driver . reboot_node ( node ) NEW_LINE self . assertTrue ( ret ) NEW_LINE DEDENT def test_reboot_node_not_successful ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE try : NEW_LINE INDENT self . driver . reboot_node ( node ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Exception ▁ was ▁ not ▁ thrown ' ) NEW_LINE DEDENT DEDENT def test_destroy_node ( self ) : NEW_LINE INDENT node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE ret = self . driver . destroy_node ( node ) NEW_LINE self . assertTrue ( ret ) NEW_LINE DEDENT def test_list_images ( self ) : NEW_LINE INDENT images = self . driver . list_images ( ) NEW_LINE image = images [ 0 ] NEW_LINE self . assertEqual ( len ( images ) , 4 ) NEW_LINE self . assertEqual ( image . name , ' CentOS ▁ 5.3 ▁ ( 32 - bit ) ▁ w / ▁ None ' ) NEW_LINE self . assertEqual ( image . id , '1531' ) NEW_LINE location = NodeLocation ( id = ' gogrid / GSI - 939ef909-84b8-4a2f - ad56-02ccd7da05ff . img ' , name = ' test ▁ location ' , country = ' Slovenia ' , driver = self . driver ) NEW_LINE images = self . driver . list_images ( location = location ) NEW_LINE image = images [ 0 ] NEW_LINE self . assertEqual ( len ( images ) , 4 ) NEW_LINE self . assertEqual ( image . name , ' CentOS ▁ 5.3 ▁ ( 32 - bit ) ▁ w / ▁ None ' ) NEW_LINE self . assertEqual ( image . id , '1531' ) NEW_LINE DEDENT def test_malformed_reply ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE try : NEW_LINE INDENT self . driver . list_images ( ) NEW_LINE DEDENT except LibcloudError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( isinstance ( e , LibcloudError ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_invalid_creds ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE try : NEW_LINE INDENT self . driver . list_nodes ( ) NEW_LINE DEDENT except InvalidCredsError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( e . driver is not None ) NEW_LINE self . assertEqual ( e . driver . name , self . driver . name ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_node_creation_without_free_public_ips ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' NOPUBIPS ' NEW_LINE try : NEW_LINE INDENT image = NodeImage ( 1531 , None , self . driver ) NEW_LINE self . driver . create_node ( name = ' test1' , image = image , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE DEDENT except LibcloudError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( isinstance ( e , LibcloudError ) ) NEW_LINE self . assertTrue ( e . driver is not None ) NEW_LINE self . assertEqual ( e . driver . name , self . driver . name ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_list_locations ( self ) : NEW_LINE INDENT locations = self . driver . list_locations ( ) NEW_LINE location_names = [ location . name for location in locations ] NEW_LINE self . assertEqual ( len ( locations ) , 2 ) NEW_LINE for i in 0 , 1 : NEW_LINE INDENT self . assertTrue ( isinstance ( locations [ i ] , NodeLocation ) ) NEW_LINE DEDENT self . assertTrue ( " US - West - 1" in location_names ) NEW_LINE self . assertTrue ( " US - East - 1" in location_names ) NEW_LINE DEDENT def test_ex_save_image ( self ) : NEW_LINE INDENT node = self . driver . list_nodes ( ) [ 0 ] NEW_LINE image = self . driver . ex_save_image ( node , " testimage " ) NEW_LINE self . assertEqual ( image . name , " testimage " ) NEW_LINE DEDENT def test_ex_edit_image ( self ) : NEW_LINE INDENT image = self . driver . list_images ( ) [ 0 ] NEW_LINE ret = self . driver . ex_edit_image ( image = image , public = False , ex_description = " test " , name = " testname " ) NEW_LINE self . assertTrue ( isinstance ( ret , NodeImage ) ) NEW_LINE DEDENT def test_ex_edit_node ( self ) : NEW_LINE INDENT node = Node ( id = 90967 , name = None , state = None , public_ips = None , private_ips = None , driver = self . driver ) NEW_LINE ret = self . driver . ex_edit_node ( node = node , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE self . assertTrue ( isinstance ( ret , Node ) ) NEW_LINE DEDENT def test_ex_list_ips ( self ) : NEW_LINE INDENT ips = self . driver . ex_list_ips ( ) NEW_LINE expected_ips = { "192.168.75.66" : GoGridIpAddress ( id = "5348099" , ip = "192.168.75.66" , public = True , state = " Unassigned " , subnet = "192.168.75.64/255.255.255.240" ) , "192.168.75.67" : GoGridIpAddress ( id = "5348100" , ip = "192.168.75.67" , public = True , state = " Assigned " , subnet = "192.168.75.64/255.255.255.240" ) , "192.168.75.68" : GoGridIpAddress ( id = "5348101" , ip = "192.168.75.68" , public = False , state = " Unassigned " , subnet = "192.168.75.64/255.255.255.240" ) } NEW_LINE self . assertEqual ( len ( expected_ips ) , 3 ) NEW_LINE for ip in ips : NEW_LINE INDENT self . assertTrue ( ip . ip in expected_ips ) NEW_LINE self . assertEqual ( ip . public , expected_ips [ ip . ip ] . public ) NEW_LINE self . assertEqual ( ip . state , expected_ips [ ip . ip ] . state ) NEW_LINE self . assertEqual ( ip . subnet , expected_ips [ ip . ip ] . subnet ) NEW_LINE del expected_ips [ ip . ip ] NEW_LINE DEDENT self . assertEqual ( len ( expected_ips ) , 0 ) NEW_LINE DEDENT def test_get_state_invalid ( self ) : NEW_LINE INDENT state = self . driver . _get_state ( ' invalid ' ) NEW_LINE self . assertEqual ( state , NodeState . UNKNOWN ) NEW_LINE DEDENT DEDENT class GoGridMockHttp ( MockHttp ) : NEW_LINE INDENT fixtures = ComputeFileFixtures ( ' gogrid ' ) NEW_LINE def _api_grid_image_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_image_list_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT body = " < h3 > some ▁ non ▁ valid ▁ json ▁ here < / h3 > " NEW_LINE return ( httplib . SERVICE_UNAVAILABLE , body , { } , httplib . responses [ httplib . SERVICE_UNAVAILABLE ] ) NEW_LINE DEDENT def _api_grid_server_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_grid_server_list_NOPUBIPS = _api_grid_server_list NEW_LINE def _api_grid_server_list_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT return ( httplib . FORBIDDEN , "123" , { } , httplib . responses [ httplib . FORBIDDEN ] ) NEW_LINE DEDENT def _api_grid_ip_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' ip _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_ip_list_NOPUBIPS ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' ip _ list _ empty . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_power ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ power . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_power_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ power _ fail . json ' ) NEW_LINE return ( httplib . NOT_FOUND , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_add ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ add . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_grid_server_add_NOPUBIPS = _api_grid_server_add NEW_LINE def _api_grid_server_delete ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ delete . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_edit ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ edit . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_support_password_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' password _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_support_password_list_NOPUBIPS = _api_support_password_list NEW_LINE def _api_grid_image_save ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ save . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_image_edit ( self , method , url , body , headers ) : NEW_LINE # ▁ edit ▁ method ▁ is ▁ quite ▁ similar ▁ to ▁ save ▁ method ▁ from ▁ the ▁ response ENDCOM # ▁ perspective ENDCOM INDENT body = self . fixtures . load ( ' image _ save . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_common_lookup_list ( self , method , url , body , headers ) : NEW_LINE INDENT _valid_lookups = ( " ip . datacenter " , ) NEW_LINE lookup = parse_qs ( urlparse . urlparse ( url ) . query ) [ " lookup " ] [ 0 ] NEW_LINE if lookup in _valid_lookups : NEW_LINE INDENT fixture_path = " lookup _ list _ % s . json " % ( lookup . replace ( " . " , " _ " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT body = self . fixtures . load ( fixture_path ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT sys . exit ( unittest . main ( ) ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="eaglexmw/seascope/tree/master/src/view/filecontext/plugins/ctags_view/CtagsManager.py"> # ▁ Copyright ▁ ( c ) ▁ 2010 ▁ Anil ▁ Kumar ENDCOM # ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ License : ▁ BSD ▁ ENDCOM import subprocess NEW_LINE import re , os NEW_LINE def _eintr_retry_call ( func , * args ) : NEW_LINE INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT return func ( * args ) NEW_LINE DEDENT except OSError , e : NEW_LINE INDENT if e . errno == errno . EINTR : NEW_LINE INDENT continue NEW_LINE DEDENT raise NEW_LINE DEDENT DEDENT DEDENT def cmdForFile ( f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ▁ - - extra = + q ' ENDCOM # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + Ki ▁ - f ▁ - ' ENDCOM DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def ct_query ( filename ) : NEW_LINE INDENT args = cmdForFile ( filename ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( filename ) NEW_LINE try : NEW_LINE INDENT proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = _eintr_retry_call ( proc . communicate ) NEW_LINE out_data = out_data . split ( ' \n ' ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT out_data = [ ' Failed ▁ to ▁ run ▁ ctags ▁ cmd\tignore\t0 ; \t ▁ ' , ' cmd : ▁ % s\tignore\t0 ; \t ▁ ' % ' ▁ ' . join ( args ) , ' error : ▁ % s\tignore\t0 ; \t ▁ ' % str ( e ) , ' ctags ▁ not ▁ installed ▁ ? \tignore\t0 ; \t ▁ ' , ] NEW_LINE DEDENT res = [ ] NEW_LINE for line in out_data : NEW_LINE INDENT if ( line == ' ' ) : NEW_LINE INDENT break NEW_LINE DEDENT line = line . split ( ' \t ' ) NEW_LINE num = line [ 2 ] . split ( ' ; ' , 1 ) [ 0 ] NEW_LINE line = [ line [ 0 ] , num , line [ 3 ] ] NEW_LINE res . append ( line ) NEW_LINE DEDENT return res NEW_LINE DEDENT is_OrderedDict_available = False NEW_LINE try : NEW_LINE # ▁ OrderedDict ▁ available ▁ only ▁ in ▁ python ▁ > = ▁ 2.7 ENDCOM INDENT from collections import OrderedDict NEW_LINE is_OrderedDict_available = True NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT def emptyOrderedDict ( ) : NEW_LINE INDENT if is_OrderedDict_available : NEW_LINE INDENT return OrderedDict ( { } ) NEW_LINE DEDENT return { } NEW_LINE DEDENT class CtagsTreeBuilder : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . symTree = emptyOrderedDict ( ) NEW_LINE DEDENT def cmdForFile ( self , f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ▁ - - extra = + q ' ENDCOM # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + Ki ▁ - f ▁ - ' ENDCOM DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K - f - t ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def runCtags ( self , f ) : NEW_LINE INDENT args = self . cmdForFile ( f ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( f ) NEW_LINE # ▁ In ▁ python ▁ > = ▁ 2.7 ▁ can ▁ use ▁ subprocess . check _ output ENDCOM # ▁ output ▁ = ▁ subprocess . check _ output ( args ) ENDCOM # ▁ return ▁ output ENDCOM proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = proc . communicate ( ) NEW_LINE return out_data NEW_LINE DEDENT def parseCtagsOutput ( self , data ) : NEW_LINE INDENT data = re . split ( ' ? \n ' , data ) NEW_LINE res = [ ] NEW_LINE for line in data : NEW_LINE INDENT if line == ' ' : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT line = line . split ( ' \t ' , 4 ) NEW_LINE res . append ( line ) NEW_LINE DEDENT except : NEW_LINE INDENT print ' bad ▁ line : ' , line NEW_LINE DEDENT DEDENT return res NEW_LINE DEDENT def addToSymLayout ( self , sc ) : NEW_LINE INDENT t = self . symTree NEW_LINE if sc and sc != ' ' : NEW_LINE INDENT for s in re . split ( ' : : | \ . ' , sc ) : NEW_LINE INDENT if s not in t : NEW_LINE INDENT t [ s ] = emptyOrderedDict ( ) NEW_LINE DEDENT t = t [ s ] NEW_LINE DEDENT DEDENT DEDENT def addToSymTree ( self , sc , line ) : NEW_LINE INDENT t = self . symTree NEW_LINE if sc and sc != ' ' : NEW_LINE INDENT for s in re . split ( ' : : | \ . ' , sc ) : NEW_LINE INDENT assert s in t NEW_LINE t = t [ s ] NEW_LINE DEDENT DEDENT cline = [ line [ 0 ] , line [ 2 ] . split ( ' ; ' ) [ 0 ] , line [ 3 ] ] NEW_LINE if line [ 0 ] in t : NEW_LINE # print ▁ line [ 0 ] , ▁ ' in ' , ▁ t ENDCOM INDENT x = t [ line [ 0 ] ] NEW_LINE if ' + ' not in x : NEW_LINE INDENT x [ ' + ' ] = cline NEW_LINE return NEW_LINE DEDENT DEDENT if ' * ' not in t : NEW_LINE INDENT t [ ' * ' ] = [ ] NEW_LINE DEDENT t [ ' * ' ] . append ( cline ) NEW_LINE # print ▁ ' . . . ' , ▁ t , ▁ line ENDCOM DEDENT def buildTree ( self , data ) : NEW_LINE INDENT type_list = [ ' namespace ' , ' class ' , ' interface ' , ' struct ' , ' union ' , ' enum ' , ' function ' ] NEW_LINE # ▁ build ▁ layout ▁ using ▁ 5th ▁ field ENDCOM for line in data : NEW_LINE INDENT if len ( line ) == 4 : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT sd = dict ( [ x . split ( ' : ' , 1 ) for x in line [ 4 ] . split ( ' \t ' ) ] ) NEW_LINE DEDENT except : NEW_LINE INDENT print ' bad ▁ line ' , line NEW_LINE continue NEW_LINE DEDENT line [ 4 ] = sd NEW_LINE count = 0 NEW_LINE for t in type_list : NEW_LINE INDENT if t in sd : NEW_LINE INDENT self . addToSymLayout ( sd [ t ] ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT if count != 1 : NEW_LINE INDENT print ' * * * * * * * * ▁ count ▁ = = ▁ 1 ▁ * * * * * * * * * ' NEW_LINE print data NEW_LINE print line NEW_LINE # assert ▁ count ▁ = = ▁ 1 ENDCOM DEDENT DEDENT if len ( self . symTree ) == 0 : NEW_LINE INDENT return ( data , False ) NEW_LINE DEDENT for line in data : NEW_LINE INDENT if len ( line ) == 4 : NEW_LINE INDENT self . addToSymTree ( None , line ) NEW_LINE continue NEW_LINE DEDENT sd = line [ 4 ] NEW_LINE count = 0 NEW_LINE for t in type_list : NEW_LINE INDENT if t in sd : NEW_LINE INDENT self . addToSymTree ( sd [ t ] , line ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT if count != 1 : NEW_LINE INDENT print ' * * * * * * * * ▁ count ▁ = = ▁ 1 ▁ * * * * * * * * * ' NEW_LINE print data NEW_LINE print line NEW_LINE # assert ▁ count ▁ = = ▁ 1 ENDCOM DEDENT DEDENT return ( self . symTree , True ) NEW_LINE DEDENT def doQuery ( self , filename ) : NEW_LINE INDENT try : NEW_LINE INDENT output = self . runCtags ( filename ) NEW_LINE output = self . parseCtagsOutput ( output ) NEW_LINE output = self . buildTree ( output ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT print str ( e ) NEW_LINE output = [ None , False ] NEW_LINE DEDENT return output NEW_LINE DEDENT DEDENT def ct_tree_query ( filename ) : NEW_LINE INDENT ct = CtagsTreeBuilder ( ) NEW_LINE output = ct . doQuery ( filename ) NEW_LINE return output NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT import optparse NEW_LINE import sys NEW_LINE depth = 0 NEW_LINE def recursePrint ( t ) : NEW_LINE INDENT global depth NEW_LINE for k , v in t . items ( ) : NEW_LINE INDENT if k == ' * ' : NEW_LINE INDENT for line in v : NEW_LINE INDENT print ' % s % s ' % ( ' ▁ ' * depth , line ) NEW_LINE DEDENT continue NEW_LINE DEDENT if k == ' + ' : NEW_LINE INDENT continue NEW_LINE DEDENT if ' + ' in v : NEW_LINE INDENT k = v [ ' + ' ] NEW_LINE DEDENT print ' % s % s ' % ( ' ▁ ' * depth , k ) NEW_LINE depth = depth + 4 NEW_LINE recursePrint ( v ) NEW_LINE depth = depth - 4 NEW_LINE DEDENT DEDENT op = optparse . OptionParser ( ) NEW_LINE ( options , args ) = op . parse_args ( ) NEW_LINE if len ( args ) != 1 : NEW_LINE INDENT print ' Please ▁ specify ▁ a ▁ file ' NEW_LINE sys . exit ( - 1 ) NEW_LINE DEDENT ( output , isTree ) = ct_tree_query ( args [ 0 ] ) NEW_LINE if isTree : NEW_LINE INDENT recursePrint ( output ) NEW_LINE DEDENT else : NEW_LINE INDENT for line in output : NEW_LINE INDENT print line NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="patrickstocklin/chattR/tree/master/lib/python2.7/site-packages/pip/index.py"> """ Routines ▁ related ▁ to ▁ PyPI , ▁ indexes """ NEW_LINE from __future__ import absolute_import NEW_LINE import logging NEW_LINE import cgi NEW_LINE from collections import namedtuple NEW_LINE import itertools NEW_LINE import sys NEW_LINE import os NEW_LINE import re NEW_LINE import mimetypes NEW_LINE import posixpath NEW_LINE import warnings NEW_LINE from pip . _vendor . six . moves . urllib import parse as urllib_parse NEW_LINE from pip . _vendor . six . moves . urllib import request as urllib_request NEW_LINE from pip . compat import ipaddress NEW_LINE from pip . utils import ( Inf , cached_property , normalize_name , splitext , normalize_path , ARCHIVE_EXTENSIONS , SUPPORTED_EXTENSIONS ) NEW_LINE from pip . utils . deprecation import RemovedInPip8Warning NEW_LINE from pip . utils . logging import indent_log NEW_LINE from pip . exceptions import ( DistributionNotFound , BestVersionAlreadyInstalled , InvalidWheelFilename , UnsupportedWheel , ) NEW_LINE from pip . download import HAS_TLS , url_to_path , path_to_url NEW_LINE from pip . models import PyPI NEW_LINE from pip . wheel import Wheel , wheel_ext NEW_LINE from pip . pep425tags import supported_tags , supported_tags_noarch , get_platform NEW_LINE from pip . _vendor import html5lib , requests , pkg_resources , six NEW_LINE from pip . _vendor . packaging . version import parse as parse_version NEW_LINE from pip . _vendor . requests . exceptions import SSLError NEW_LINE __all__ = [ ' FormatControl ' , ' fmt _ ctl _ handle _ mutual _ exclude ' , ' PackageFinder ' ] NEW_LINE # ▁ Taken ▁ from ▁ Chrome ' s ▁ list ▁ of ▁ secure ▁ origins ▁ ( See : ▁ http : / / bit . ly / 1qrySKC ) ENDCOM SECURE_ORIGINS = [ # ▁ protocol , ▁ hostname , ▁ port ENDCOM ( " https " , " * " , " * " ) , ( " * " , " localhost " , " * " ) , ( " * " , "127.0.0.0/8" , " * " ) , ( " * " , " : :1/128" , " * " ) , ( " file " , " * " , None ) , ] NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE class InstallationCandidate ( object ) : NEW_LINE INDENT def __init__ ( self , project , version , location ) : NEW_LINE INDENT self . project = project NEW_LINE self . version = parse_version ( version ) NEW_LINE self . location = location NEW_LINE self . _key = ( self . project , self . version , self . location ) NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return " < InstallationCandidate ( {0 ! r } , ▁ { 1 ! r } , ▁ { 2 ! r } ) > " . format ( self . project , self . version , self . location , ) NEW_LINE DEDENT def __hash__ ( self ) : NEW_LINE INDENT return hash ( self . _key ) NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s < o ) NEW_LINE DEDENT def __le__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s <= o ) NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s == o ) NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s >= o ) NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s > o ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s != o ) NEW_LINE DEDENT def _compare ( self , other , method ) : NEW_LINE INDENT if not isinstance ( other , InstallationCandidate ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return method ( self . _key , other . _key ) NEW_LINE DEDENT DEDENT class PackageFinder ( object ) : NEW_LINE INDENT """ This ▁ finds ▁ packages . STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ meant ▁ to ▁ match ▁ easy _ install ' s ▁ technique ▁ for ▁ looking ▁ for STRNEWLINE ▁ packages , ▁ by ▁ reading ▁ pages ▁ and ▁ looking ▁ for ▁ appropriate ▁ links . STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , find_links , index_urls , allow_external = ( ) , allow_unverified = ( ) , allow_all_external = False , allow_all_prereleases = False , trusted_hosts = None , process_dependency_links = False , session = None , format_control = None ) : NEW_LINE INDENT """ Create ▁ a ▁ PackageFinder . STRNEWLINE STRNEWLINE ▁ : param ▁ format _ control : ▁ A ▁ FormatControl ▁ object ▁ or ▁ None . ▁ Used ▁ to ▁ control STRNEWLINE ▁ the ▁ selection ▁ of ▁ source ▁ packages ▁ / ▁ binary ▁ packages ▁ when ▁ consulting STRNEWLINE ▁ the ▁ index ▁ and ▁ links . STRNEWLINE ▁ """ NEW_LINE if session is None : NEW_LINE INDENT raise TypeError ( " PackageFinder ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ " " ' session ' " ) NEW_LINE # ▁ Build ▁ find _ links . ▁ If ▁ an ▁ argument ▁ starts ▁ with ▁ ~ , ▁ it ▁ may ▁ be ENDCOM # ▁ a ▁ local ▁ file ▁ relative ▁ to ▁ a ▁ home ▁ directory . ▁ So ▁ try ▁ normalizing ENDCOM # ▁ it ▁ and ▁ if ▁ it ▁ exists , ▁ use ▁ the ▁ normalized ▁ version . ENDCOM # ▁ This ▁ is ▁ deliberately ▁ conservative ▁ - ▁ it ▁ might ▁ be ▁ fine ▁ just ▁ to ENDCOM # ▁ blindly ▁ normalize ▁ anything ▁ starting ▁ with ▁ a ▁ ~ . . . ENDCOM DEDENT self . find_links = [ ] NEW_LINE for link in find_links : NEW_LINE INDENT if link . startswith ( ' ~ ' ) : NEW_LINE INDENT new_link = normalize_path ( link ) NEW_LINE if os . path . exists ( new_link ) : NEW_LINE INDENT link = new_link NEW_LINE DEDENT DEDENT self . find_links . append ( link ) NEW_LINE DEDENT self . index_urls = index_urls NEW_LINE self . dependency_links = [ ] NEW_LINE # ▁ These ▁ are ▁ boring ▁ links ▁ that ▁ have ▁ already ▁ been ▁ logged ▁ somehow : ENDCOM self . logged_links = set ( ) NEW_LINE self . format_control = format_control or FormatControl ( set ( ) , set ( ) ) NEW_LINE # ▁ Do ▁ we ▁ allow ▁ ( safe ▁ and ▁ verifiable ) ▁ externally ▁ hosted ▁ files ? ENDCOM self . allow_external = set ( normalize_name ( n ) for n in allow_external ) NEW_LINE # ▁ Which ▁ names ▁ are ▁ allowed ▁ to ▁ install ▁ insecure ▁ and ▁ unverifiable ▁ files ? ENDCOM self . allow_unverified = set ( normalize_name ( n ) for n in allow_unverified ) NEW_LINE # ▁ Anything ▁ that ▁ is ▁ allowed ▁ unverified ▁ is ▁ also ▁ allowed ▁ external ENDCOM self . allow_external |= self . allow_unverified NEW_LINE # ▁ Do ▁ we ▁ allow ▁ all ▁ ( safe ▁ and ▁ verifiable ) ▁ externally ▁ hosted ▁ files ? ENDCOM self . allow_all_external = allow_all_external NEW_LINE # ▁ Domains ▁ that ▁ we ▁ won ' t ▁ emit ▁ warnings ▁ for ▁ when ▁ not ▁ using ▁ HTTPS ENDCOM self . secure_origins = [ ( " * " , host , " * " ) for host in ( trusted_hosts if trusted_hosts else [ ] ) ] NEW_LINE # ▁ Stores ▁ if ▁ we ▁ ignored ▁ any ▁ external ▁ links ▁ so ▁ that ▁ we ▁ can ▁ instruct ENDCOM # ▁ end ▁ users ▁ how ▁ to ▁ install ▁ them ▁ if ▁ no ▁ distributions ▁ are ▁ available ENDCOM self . need_warn_external = False NEW_LINE # ▁ Stores ▁ if ▁ we ▁ ignored ▁ any ▁ unsafe ▁ links ▁ so ▁ that ▁ we ▁ can ▁ instruct ENDCOM # ▁ end ▁ users ▁ how ▁ to ▁ install ▁ them ▁ if ▁ no ▁ distributions ▁ are ▁ available ENDCOM self . need_warn_unverified = False NEW_LINE # ▁ Do ▁ we ▁ want ▁ to ▁ allow ▁ _ all _ ▁ pre - releases ? ENDCOM self . allow_all_prereleases = allow_all_prereleases NEW_LINE # ▁ Do ▁ we ▁ process ▁ dependency ▁ links ? ENDCOM self . process_dependency_links = process_dependency_links NEW_LINE # ▁ The ▁ Session ▁ we ' ll ▁ use ▁ to ▁ make ▁ requests ENDCOM self . session = session NEW_LINE # ▁ If ▁ we ▁ don ' t ▁ have ▁ TLS ▁ enabled , ▁ then ▁ WARN ▁ if ▁ anyplace ▁ we ' re ▁ looking ENDCOM # ▁ relies ▁ on ▁ TLS . ENDCOM if not HAS_TLS : NEW_LINE INDENT for link in itertools . chain ( self . index_urls , self . find_links ) : NEW_LINE INDENT parsed = urllib_parse . urlparse ( link ) NEW_LINE if parsed . scheme == " https " : NEW_LINE INDENT logger . warning ( " pip ▁ is ▁ configured ▁ with ▁ locations ▁ that ▁ require ▁ " " TLS / SSL , ▁ however ▁ the ▁ ssl ▁ module ▁ in ▁ Python ▁ is ▁ not ▁ " " available . " ) NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT DEDENT def add_dependency_links ( self , links ) : NEW_LINE # ▁ # ▁ FIXME : ▁ this ▁ shouldn ' t ▁ be ▁ global ▁ list ▁ this , ▁ it ▁ should ▁ only ENDCOM # ▁ # ▁ apply ▁ to ▁ requirements ▁ of ▁ the ▁ package ▁ that ▁ specifies ▁ the ENDCOM # ▁ # ▁ dependency _ links ▁ value ENDCOM # ▁ # ▁ FIXME : ▁ also , ▁ we ▁ should ▁ track ▁ comes _ from ▁ ( i . e . , ▁ use ▁ Link ) ENDCOM INDENT if self . process_dependency_links : NEW_LINE INDENT warnings . warn ( " Dependency ▁ Links ▁ processing ▁ has ▁ been ▁ deprecated ▁ and ▁ will ▁ be ▁ " " removed ▁ in ▁ a ▁ future ▁ release . " , RemovedInPip8Warning , ) NEW_LINE self . dependency_links . extend ( links ) NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def _sort_locations ( locations , expand_dir = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Sort ▁ locations ▁ into ▁ " files " ▁ ( archives ) ▁ and ▁ " urls " , ▁ and ▁ return STRNEWLINE ▁ a ▁ pair ▁ of ▁ lists ▁ ( files , urls ) STRNEWLINE ▁ """ NEW_LINE files = [ ] NEW_LINE urls = [ ] NEW_LINE # ▁ puts ▁ the ▁ url ▁ for ▁ the ▁ given ▁ file ▁ path ▁ into ▁ the ▁ appropriate ▁ list ENDCOM def sort_path ( path ) : NEW_LINE INDENT url = path_to_url ( path ) NEW_LINE if mimetypes . guess_type ( url , strict = False ) [ 0 ] == ' text / html ' : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT else : NEW_LINE INDENT files . append ( url ) NEW_LINE DEDENT DEDENT for url in locations : NEW_LINE INDENT is_local_path = os . path . exists ( url ) NEW_LINE is_file_url = url . startswith ( ' file : ' ) NEW_LINE if is_local_path or is_file_url : NEW_LINE INDENT if is_local_path : NEW_LINE INDENT path = url NEW_LINE DEDENT else : NEW_LINE INDENT path = url_to_path ( url ) NEW_LINE DEDENT if os . path . isdir ( path ) : NEW_LINE INDENT if expand_dir : NEW_LINE INDENT path = os . path . realpath ( path ) NEW_LINE for item in os . listdir ( path ) : NEW_LINE INDENT sort_path ( os . path . join ( path , item ) ) NEW_LINE DEDENT DEDENT elif is_file_url : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT elif os . path . isfile ( path ) : NEW_LINE INDENT sort_path ( path ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT return files , urls NEW_LINE DEDENT def _candidate_sort_key ( self , candidate ) : NEW_LINE INDENT """ STRNEWLINE ▁ Function ▁ used ▁ to ▁ generate ▁ link ▁ sort ▁ key ▁ for ▁ link ▁ tuples . STRNEWLINE ▁ The ▁ greater ▁ the ▁ return ▁ value , ▁ the ▁ more ▁ preferred ▁ it ▁ is . STRNEWLINE ▁ If ▁ not ▁ finding ▁ wheels , ▁ then ▁ sorted ▁ by ▁ version ▁ only . STRNEWLINE ▁ If ▁ finding ▁ wheels , ▁ then ▁ the ▁ sort ▁ order ▁ is ▁ by ▁ version , ▁ then : STRNEWLINE ▁ 1 . ▁ existing ▁ installs STRNEWLINE ▁ 2 . ▁ wheels ▁ ordered ▁ via ▁ Wheel . support _ index _ min ( ) STRNEWLINE ▁ 3 . ▁ source ▁ archives STRNEWLINE ▁ Note : ▁ it ▁ was ▁ considered ▁ to ▁ embed ▁ this ▁ logic ▁ into ▁ the ▁ Link STRNEWLINE ▁ comparison ▁ operators , ▁ but ▁ then ▁ different ▁ sdist ▁ links STRNEWLINE ▁ with ▁ the ▁ same ▁ version , ▁ would ▁ have ▁ to ▁ be ▁ considered ▁ equal STRNEWLINE ▁ """ NEW_LINE support_num = len ( supported_tags ) NEW_LINE if candidate . location == INSTALLED_VERSION : NEW_LINE INDENT pri = 1 NEW_LINE DEDENT elif candidate . location . is_wheel : NEW_LINE # ▁ can ▁ raise ▁ InvalidWheelFilename ENDCOM INDENT wheel = Wheel ( candidate . location . filename ) NEW_LINE if not wheel . supported ( ) : NEW_LINE INDENT raise UnsupportedWheel ( " % s ▁ is ▁ not ▁ a ▁ supported ▁ wheel ▁ for ▁ this ▁ platform . ▁ It ▁ " " can ' t ▁ be ▁ sorted . " % wheel . filename ) NEW_LINE DEDENT pri = - ( wheel . support_index_min ( ) ) NEW_LINE DEDENT else : # ▁ sdist ENDCOM NEW_LINE INDENT pri = - ( support_num ) NEW_LINE DEDENT return ( candidate . version , pri ) NEW_LINE DEDENT def _sort_versions ( self , applicable_versions ) : NEW_LINE INDENT """ STRNEWLINE ▁ Bring ▁ the ▁ latest ▁ version ▁ ( and ▁ wheels ) ▁ to ▁ the ▁ front , ▁ but ▁ maintain ▁ the STRNEWLINE ▁ existing ▁ ordering ▁ as ▁ secondary . ▁ See ▁ the ▁ docstring ▁ for ▁ ` _ link _ sort _ key ` STRNEWLINE ▁ for ▁ details . ▁ This ▁ function ▁ is ▁ isolated ▁ for ▁ easier ▁ unit ▁ testing . STRNEWLINE ▁ """ NEW_LINE return sorted ( applicable_versions , key = self . _candidate_sort_key , reverse = True ) NEW_LINE DEDENT def _validate_secure_origin ( self , logger , location ) : NEW_LINE # ▁ Determine ▁ if ▁ this ▁ url ▁ used ▁ a ▁ secure ▁ transport ▁ mechanism ENDCOM INDENT parsed = urllib_parse . urlparse ( str ( location ) ) NEW_LINE origin = ( parsed . scheme , parsed . hostname , parsed . port ) NEW_LINE # ▁ Determine ▁ if ▁ our ▁ origin ▁ is ▁ a ▁ secure ▁ origin ▁ by ▁ looking ▁ through ▁ our ENDCOM # ▁ hardcoded ▁ list ▁ of ▁ secure ▁ origins , ▁ as ▁ well ▁ as ▁ any ▁ additional ▁ ones ENDCOM # ▁ configured ▁ on ▁ this ▁ PackageFinder ▁ instance . ENDCOM for secure_origin in ( SECURE_ORIGINS + self . secure_origins ) : NEW_LINE # ▁ Check ▁ to ▁ see ▁ if ▁ the ▁ protocol ▁ matches ENDCOM INDENT if origin [ 0 ] != secure_origin [ 0 ] and secure_origin [ 0 ] != " * " : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE # ▁ We ▁ need ▁ to ▁ do ▁ this ▁ decode ▁ dance ▁ to ▁ ensure ▁ that ▁ we ▁ have ▁ a ENDCOM # ▁ unicode ▁ object , ▁ even ▁ on ▁ Python ▁ 2 . x . ENDCOM INDENT addr = ipaddress . ip_address ( origin [ 1 ] if ( isinstance ( origin [ 1 ] , six . text_type ) or origin [ 1 ] is None ) else origin [ 1 ] . decode ( " utf8" ) ) NEW_LINE network = ipaddress . ip_network ( secure_origin [ 1 ] if isinstance ( secure_origin [ 1 ] , six . text_type ) else secure_origin [ 1 ] . decode ( " utf8" ) ) NEW_LINE DEDENT except ValueError : NEW_LINE # ▁ We ▁ don ' t ▁ have ▁ both ▁ a ▁ valid ▁ address ▁ or ▁ a ▁ valid ▁ network , ▁ so ENDCOM # ▁ we ' ll ▁ check ▁ this ▁ origin ▁ against ▁ hostnames . ENDCOM INDENT if origin [ 1 ] != secure_origin [ 1 ] and secure_origin [ 1 ] != " * " : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT else : NEW_LINE # ▁ We ▁ have ▁ a ▁ valid ▁ address ▁ and ▁ network , ▁ so ▁ see ▁ if ▁ the ▁ address ENDCOM # ▁ is ▁ contained ▁ within ▁ the ▁ network . ENDCOM INDENT if addr not in network : NEW_LINE INDENT continue NEW_LINE # ▁ Check ▁ to ▁ see ▁ if ▁ the ▁ port ▁ patches ENDCOM DEDENT DEDENT if ( origin [ 2 ] != secure_origin [ 2 ] and secure_origin [ 2 ] != " * " and secure_origin [ 2 ] is not None ) : NEW_LINE INDENT continue NEW_LINE # ▁ If ▁ we ' ve ▁ gotten ▁ here , ▁ then ▁ this ▁ origin ▁ matches ▁ the ▁ current ENDCOM # ▁ secure ▁ origin ▁ and ▁ we ▁ should ▁ return ▁ True ENDCOM DEDENT return True NEW_LINE # ▁ If ▁ we ' ve ▁ gotten ▁ to ▁ this ▁ point , ▁ then ▁ the ▁ origin ▁ isn ' t ▁ secure ▁ and ▁ we ENDCOM # ▁ will ▁ not ▁ accept ▁ it ▁ as ▁ a ▁ valid ▁ location ▁ to ▁ search . ▁ We ▁ will ▁ however ENDCOM # ▁ log ▁ a ▁ warning ▁ that ▁ we ▁ are ▁ ignoring ▁ it . ENDCOM DEDENT logger . warning ( " The ▁ repository ▁ located ▁ at ▁ % s ▁ is ▁ not ▁ a ▁ trusted ▁ or ▁ secure ▁ host ▁ and ▁ " " is ▁ being ▁ ignored . ▁ If ▁ this ▁ repository ▁ is ▁ available ▁ via ▁ HTTPS ▁ it ▁ " " is ▁ recommended ▁ to ▁ use ▁ HTTPS ▁ instead , ▁ otherwise ▁ you ▁ may ▁ silence ▁ " " this ▁ warning ▁ and ▁ allow ▁ it ▁ anyways ▁ with ▁ ' - - trusted - host ▁ % s ' . " , parsed . hostname , parsed . hostname , ) NEW_LINE return False NEW_LINE DEDENT def _get_index_urls_locations ( self , project_name ) : NEW_LINE INDENT """ Returns ▁ the ▁ locations ▁ found ▁ via ▁ self . index _ urls STRNEWLINE STRNEWLINE ▁ Checks ▁ the ▁ url _ name ▁ on ▁ the ▁ main ▁ ( first ▁ in ▁ the ▁ list ) ▁ index ▁ and STRNEWLINE ▁ use ▁ this ▁ url _ name ▁ to ▁ produce ▁ all ▁ locations STRNEWLINE ▁ """ NEW_LINE def mkurl_pypi_url ( url ) : NEW_LINE INDENT loc = posixpath . join ( url , project_url_name ) NEW_LINE # ▁ For ▁ maximum ▁ compatibility ▁ with ▁ easy _ install , ▁ ensure ▁ the ▁ path ENDCOM # ▁ ends ▁ in ▁ a ▁ trailing ▁ slash . ▁ Although ▁ this ▁ isn ' t ▁ in ▁ the ▁ spec ENDCOM # ▁ ( and ▁ PyPI ▁ can ▁ handle ▁ it ▁ without ▁ the ▁ slash ) ▁ some ▁ other ▁ index ENDCOM # ▁ implementations ▁ might ▁ break ▁ if ▁ they ▁ relied ▁ on ▁ easy _ install ' s ENDCOM # ▁ behavior . ENDCOM if not loc . endswith ( ' / ' ) : NEW_LINE INDENT loc = loc + ' / ' NEW_LINE DEDENT return loc NEW_LINE DEDENT project_url_name = urllib_parse . quote ( project_name . lower ( ) ) NEW_LINE if self . index_urls : NEW_LINE # ▁ Check ▁ that ▁ we ▁ have ▁ the ▁ url _ name ▁ correctly ▁ spelled : ENDCOM # ▁ Only ▁ check ▁ main ▁ index ▁ if ▁ index ▁ URL ▁ is ▁ given ENDCOM INDENT main_index_url = Link ( mkurl_pypi_url ( self . index_urls [ 0 ] ) , trusted = True , ) NEW_LINE page = self . _get_page ( main_index_url ) NEW_LINE if page is None and PyPI . netloc not in str ( main_index_url ) : NEW_LINE INDENT warnings . warn ( " Failed ▁ to ▁ find ▁ % r ▁ at ▁ % s . ▁ It ▁ is ▁ suggested ▁ to ▁ upgrade ▁ " " your ▁ index ▁ to ▁ support ▁ normalized ▁ names ▁ as ▁ the ▁ name ▁ in ▁ " " / simple / { name } . " % ( project_name , main_index_url ) , RemovedInPip8Warning , ) NEW_LINE project_url_name = self . _find_url_name ( Link ( self . index_urls [ 0 ] , trusted = True ) , project_url_name , ) or project_url_name NEW_LINE DEDENT DEDENT if project_url_name is not None : NEW_LINE INDENT return [ mkurl_pypi_url ( url ) for url in self . index_urls ] NEW_LINE DEDENT return [ ] NEW_LINE DEDENT def _find_all_versions ( self , project_name ) : NEW_LINE INDENT """ Find ▁ all ▁ available ▁ versions ▁ for ▁ project _ name STRNEWLINE STRNEWLINE ▁ This ▁ checks ▁ index _ urls , ▁ find _ links ▁ and ▁ dependency _ links STRNEWLINE ▁ All ▁ versions ▁ found ▁ are ▁ returned STRNEWLINE STRNEWLINE ▁ See ▁ _ link _ package _ versions ▁ for ▁ details ▁ on ▁ which ▁ files ▁ are ▁ accepted STRNEWLINE ▁ """ NEW_LINE index_locations = self . _get_index_urls_locations ( project_name ) NEW_LINE index_file_loc , index_url_loc = self . _sort_locations ( index_locations ) NEW_LINE fl_file_loc , fl_url_loc = self . _sort_locations ( self . find_links , expand_dir = True ) NEW_LINE dep_file_loc , dep_url_loc = self . _sort_locations ( self . dependency_links ) NEW_LINE file_locations = ( Link ( url ) for url in itertools . chain ( index_file_loc , fl_file_loc , dep_file_loc ) ) NEW_LINE # ▁ We ▁ trust ▁ every ▁ url ▁ that ▁ the ▁ user ▁ has ▁ given ▁ us ▁ whether ▁ it ▁ was ▁ given ENDCOM # ▁ via ▁ - - index - url ▁ or ▁ - - find - links ENDCOM # ▁ We ▁ explicitly ▁ do ▁ not ▁ trust ▁ links ▁ that ▁ came ▁ from ▁ dependency _ links ENDCOM # ▁ We ▁ want ▁ to ▁ filter ▁ out ▁ any ▁ thing ▁ which ▁ does ▁ not ▁ have ▁ a ▁ secure ▁ origin . ENDCOM url_locations = [ link for link in itertools . chain ( ( Link ( url , trusted = True ) for url in index_url_loc ) , ( Link ( url , trusted = True ) for url in fl_url_loc ) , ( Link ( url ) for url in dep_url_loc ) , ) if self . _validate_secure_origin ( logger , link ) ] NEW_LINE logger . debug ( ' % d ▁ location ( s ) ▁ to ▁ search ▁ for ▁ versions ▁ of ▁ % s : ' , len ( url_locations ) , project_name ) NEW_LINE for location in url_locations : NEW_LINE INDENT logger . debug ( ' * ▁ % s ' , location ) NEW_LINE DEDENT canonical_name = pkg_resources . safe_name ( project_name ) . lower ( ) NEW_LINE formats = fmt_ctl_formats ( self . format_control , canonical_name ) NEW_LINE search = Search ( project_name . lower ( ) , canonical_name , formats ) NEW_LINE find_links_versions = self . _package_versions ( # ▁ We ▁ trust ▁ every ▁ directly ▁ linked ▁ archive ▁ in ▁ find _ links ENDCOM ( Link ( url , ' - f ' , trusted = True ) for url in self . find_links ) , search ) NEW_LINE page_versions = [ ] NEW_LINE for page in self . _get_pages ( url_locations , project_name ) : NEW_LINE INDENT logger . debug ( ' Analyzing ▁ links ▁ from ▁ page ▁ % s ' , page . url ) NEW_LINE with indent_log ( ) : NEW_LINE INDENT page_versions . extend ( self . _package_versions ( page . links , search ) ) NEW_LINE DEDENT DEDENT dependency_versions = self . _package_versions ( ( Link ( url ) for url in self . dependency_links ) , search ) NEW_LINE if dependency_versions : NEW_LINE INDENT logger . debug ( ' dependency _ links ▁ found : ▁ % s ' , ' , ▁ ' . join ( [ version . location . url for version in dependency_versions ] ) ) NEW_LINE DEDENT file_versions = self . _package_versions ( file_locations , search ) NEW_LINE if file_versions : NEW_LINE INDENT file_versions . sort ( reverse = True ) NEW_LINE logger . debug ( ' Local ▁ files ▁ found : ▁ % s ' , ' , ▁ ' . join ( [ url_to_path ( candidate . location . url ) for candidate in file_versions ] ) ) NEW_LINE # ▁ This ▁ is ▁ an ▁ intentional ▁ priority ▁ ordering ENDCOM DEDENT return ( file_versions + find_links_versions + page_versions + dependency_versions ) NEW_LINE DEDENT def find_requirement ( self , req , upgrade ) : NEW_LINE INDENT """ Try ▁ to ▁ find ▁ an ▁ InstallationCandidate ▁ for ▁ req STRNEWLINE STRNEWLINE ▁ Expects ▁ req , ▁ an ▁ InstallRequirement ▁ and ▁ upgrade , ▁ a ▁ boolean STRNEWLINE ▁ Returns ▁ an ▁ InstallationCandidate ▁ or ▁ None STRNEWLINE ▁ May ▁ raise ▁ DistributionNotFound ▁ or ▁ BestVersionAlreadyInstalled STRNEWLINE ▁ """ NEW_LINE all_versions = self . _find_all_versions ( req . name ) NEW_LINE # ▁ Filter ▁ out ▁ anything ▁ which ▁ doesn ' t ▁ match ▁ our ▁ specifier ENDCOM _versions = set ( req . specifier . filter ( # ▁ We ▁ turn ▁ the ▁ version ▁ object ▁ into ▁ a ▁ str ▁ here ▁ because ▁ otherwise ENDCOM # ▁ when ▁ we ' re ▁ debundled ▁ but ▁ setuptools ▁ isn ' t , ▁ Python ▁ will ▁ see ENDCOM # ▁ packaging . version . Version ▁ and ENDCOM # ▁ pkg _ resources . _ vendor . packaging . version . Version ▁ as ▁ different ENDCOM # ▁ types . ▁ This ▁ way ▁ we ' ll ▁ use ▁ a ▁ str ▁ as ▁ a ▁ common ▁ data ▁ interchange ENDCOM # ▁ format . ▁ If ▁ we ▁ stop ▁ using ▁ the ▁ pkg _ resources ▁ provided ▁ specifier ENDCOM # ▁ and ▁ start ▁ using ▁ our ▁ own , ▁ we ▁ can ▁ drop ▁ the ▁ cast ▁ to ▁ str ( ) . ENDCOM [ str ( x . version ) for x in all_versions ] , prereleases = ( self . allow_all_prereleases if self . allow_all_prereleases else None ) , ) ) NEW_LINE applicable_versions = [ # ▁ Again , ▁ converting ▁ to ▁ str ▁ to ▁ deal ▁ with ▁ debundling . ENDCOM x for x in all_versions if str ( x . version ) in _versions ] NEW_LINE if req . satisfied_by is not None : NEW_LINE # ▁ Finally ▁ add ▁ our ▁ existing ▁ versions ▁ to ▁ the ▁ front ▁ of ▁ our ▁ versions . ENDCOM INDENT applicable_versions . insert ( 0 , InstallationCandidate ( req . name , req . satisfied_by . version , INSTALLED_VERSION , ) ) NEW_LINE existing_applicable = True NEW_LINE DEDENT else : NEW_LINE INDENT existing_applicable = False NEW_LINE DEDENT applicable_versions = self . _sort_versions ( applicable_versions ) NEW_LINE if not upgrade and existing_applicable : NEW_LINE INDENT if applicable_versions [ 0 ] . location is INSTALLED_VERSION : NEW_LINE INDENT logger . debug ( ' Existing ▁ installed ▁ version ▁ ( % s ) ▁ is ▁ most ▁ up - to - date ▁ and ▁ ' ' satisfies ▁ requirement ' , req . satisfied_by . version , ) NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Existing ▁ installed ▁ version ▁ ( % s ) ▁ satisfies ▁ requirement ▁ ' ' ( most ▁ up - to - date ▁ version ▁ is ▁ % s ) ' , req . satisfied_by . version , applicable_versions [ 0 ] [ 2 ] , ) NEW_LINE DEDENT return None NEW_LINE DEDENT if not applicable_versions : NEW_LINE INDENT logger . critical ( ' Could ▁ not ▁ find ▁ a ▁ version ▁ that ▁ satisfies ▁ the ▁ requirement ▁ % s ▁ ' ' ( from ▁ versions : ▁ % s ) ' , req , ' , ▁ ' . join ( sorted ( set ( str ( i . version ) for i in all_versions ) , key = parse_version , ) ) ) NEW_LINE if self . need_warn_external : NEW_LINE INDENT logger . warning ( " Some ▁ externally ▁ hosted ▁ files ▁ were ▁ ignored ▁ as ▁ access ▁ to ▁ " " them ▁ may ▁ be ▁ unreliable ▁ ( use ▁ - - allow - external ▁ % s ▁ to ▁ " " allow ) . " , req . name , ) NEW_LINE DEDENT if self . need_warn_unverified : NEW_LINE INDENT logger . warning ( " Some ▁ insecure ▁ and ▁ unverifiable ▁ files ▁ were ▁ ignored " " ▁ ( use ▁ - - allow - unverified ▁ % s ▁ to ▁ allow ) . " , req . name , ) NEW_LINE DEDENT raise DistributionNotFound ( ' No ▁ matching ▁ distribution ▁ found ▁ for ▁ % s ' % req ) NEW_LINE DEDENT if applicable_versions [ 0 ] . location is INSTALLED_VERSION : NEW_LINE # ▁ We ▁ have ▁ an ▁ existing ▁ version , ▁ and ▁ its ▁ the ▁ best ▁ version ENDCOM INDENT logger . debug ( ' Installed ▁ version ▁ ( % s ) ▁ is ▁ most ▁ up - to - date ▁ ( past ▁ versions : ▁ ' ' % s ) ' , req . satisfied_by . version , ' , ▁ ' . join ( str ( i . version ) for i in applicable_versions [ 1 : ] ) or " none " , ) NEW_LINE raise BestVersionAlreadyInstalled NEW_LINE DEDENT if len ( applicable_versions ) > 1 : NEW_LINE INDENT logger . debug ( ' Using ▁ version ▁ % s ▁ ( newest ▁ of ▁ versions : ▁ % s ) ' , applicable_versions [ 0 ] . version , ' , ▁ ' . join ( str ( i . version ) for i in applicable_versions ) ) NEW_LINE DEDENT selected_version = applicable_versions [ 0 ] . location NEW_LINE if ( selected_version . verifiable is not None and not selected_version . verifiable ) : NEW_LINE INDENT logger . warning ( " % s ▁ is ▁ potentially ▁ insecure ▁ and ▁ unverifiable . " , req . name , ) NEW_LINE DEDENT return selected_version NEW_LINE DEDENT def _find_url_name ( self , index_url , url_name ) : NEW_LINE INDENT """ STRNEWLINE ▁ Finds ▁ the ▁ true ▁ URL ▁ name ▁ of ▁ a ▁ package , ▁ when ▁ the ▁ given ▁ name ▁ isn ' t ▁ quite STRNEWLINE ▁ correct . STRNEWLINE ▁ This ▁ is ▁ usually ▁ used ▁ to ▁ implement ▁ case - insensitivity . STRNEWLINE ▁ """ NEW_LINE if not index_url . url . endswith ( ' / ' ) : NEW_LINE # ▁ Vaguely ▁ part ▁ of ▁ the ▁ PyPI ▁ API . . . ▁ weird ▁ but ▁ true . ENDCOM # ▁ FIXME : ▁ bad ▁ to ▁ modify ▁ this ? ENDCOM INDENT index_url . url += ' / ' NEW_LINE DEDENT page = self . _get_page ( index_url ) NEW_LINE if page is None : NEW_LINE INDENT logger . critical ( ' Cannot ▁ fetch ▁ index ▁ base ▁ URL ▁ % s ' , index_url ) NEW_LINE return NEW_LINE DEDENT norm_name = normalize_name ( url_name ) NEW_LINE for link in page . links : NEW_LINE INDENT base = posixpath . basename ( link . path . rstrip ( ' / ' ) ) NEW_LINE if norm_name == normalize_name ( base ) : NEW_LINE INDENT logger . debug ( ' Real ▁ name ▁ of ▁ requirement ▁ % s ▁ is ▁ % s ' , url_name , base , ) NEW_LINE return base NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def _get_pages ( self , locations , project_name ) : NEW_LINE INDENT """ STRNEWLINE ▁ Yields ▁ ( page , ▁ page _ url ) ▁ from ▁ the ▁ given ▁ locations , ▁ skipping STRNEWLINE ▁ locations ▁ that ▁ have ▁ errors , ▁ and ▁ adding ▁ download / homepage ▁ links STRNEWLINE ▁ """ NEW_LINE all_locations = list ( locations ) NEW_LINE seen = set ( ) NEW_LINE normalized = normalize_name ( project_name ) NEW_LINE while all_locations : NEW_LINE INDENT location = all_locations . pop ( 0 ) NEW_LINE if location in seen : NEW_LINE INDENT continue NEW_LINE DEDENT seen . add ( location ) NEW_LINE page = self . _get_page ( location ) NEW_LINE if page is None : NEW_LINE INDENT continue NEW_LINE DEDENT yield page NEW_LINE for link in page . rel_links ( ) : NEW_LINE INDENT if ( normalized not in self . allow_external and not self . allow_all_external ) : NEW_LINE INDENT self . need_warn_external = True NEW_LINE logger . debug ( " Not ▁ searching ▁ % s ▁ for ▁ files ▁ because ▁ external ▁ " " urls ▁ are ▁ disallowed . " , link , ) NEW_LINE continue NEW_LINE DEDENT if ( link . trusted is not None and not link . trusted and normalized not in self . allow_unverified ) : NEW_LINE INDENT logger . debug ( " Not ▁ searching ▁ % s ▁ for ▁ urls , ▁ it ▁ is ▁ an ▁ " " untrusted ▁ link ▁ and ▁ cannot ▁ produce ▁ safe ▁ or ▁ " " verifiable ▁ files . " , link , ) NEW_LINE self . need_warn_unverified = True NEW_LINE continue NEW_LINE DEDENT all_locations . append ( link ) NEW_LINE DEDENT DEDENT DEDENT _py_version_re = re . compile ( r ' - py ( [123 ] \ . ? [ 0-9 ] ? ) $ ' ) NEW_LINE def _sort_links ( self , links ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ elements ▁ of ▁ links ▁ in ▁ order , ▁ non - egg ▁ links ▁ first , ▁ egg ▁ links STRNEWLINE ▁ second , ▁ while ▁ eliminating ▁ duplicates STRNEWLINE ▁ """ NEW_LINE eggs , no_eggs = [ ] , [ ] NEW_LINE seen = set ( ) NEW_LINE for link in links : NEW_LINE INDENT if link not in seen : NEW_LINE INDENT seen . add ( link ) NEW_LINE if link . egg_fragment : NEW_LINE INDENT eggs . append ( link ) NEW_LINE DEDENT else : NEW_LINE INDENT no_eggs . append ( link ) NEW_LINE DEDENT DEDENT DEDENT return no_eggs + eggs NEW_LINE DEDENT def _package_versions ( self , links , search ) : NEW_LINE INDENT result = [ ] NEW_LINE for link in self . _sort_links ( links ) : NEW_LINE INDENT v = self . _link_package_versions ( link , search ) NEW_LINE if v is not None : NEW_LINE INDENT result . append ( v ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT def _log_skipped_link ( self , link , reason ) : NEW_LINE INDENT if link not in self . logged_links : NEW_LINE INDENT logger . debug ( ' Skipping ▁ link ▁ % s ; ▁ % s ' , link , reason ) NEW_LINE self . logged_links . add ( link ) NEW_LINE DEDENT DEDENT def _link_package_versions ( self , link , search ) : NEW_LINE INDENT """ Return ▁ an ▁ InstallationCandidate ▁ or ▁ None """ NEW_LINE platform = get_platform ( ) NEW_LINE version = None NEW_LINE if link . egg_fragment : NEW_LINE INDENT egg_info = link . egg_fragment NEW_LINE ext = link . ext NEW_LINE DEDENT else : NEW_LINE INDENT egg_info , ext = link . splitext ( ) NEW_LINE if not ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' not ▁ a ▁ file ' ) NEW_LINE return NEW_LINE DEDENT if ext not in SUPPORTED_EXTENSIONS : NEW_LINE INDENT self . _log_skipped_link ( link , ' unsupported ▁ archive ▁ format : ▁ % s ' % ext ) NEW_LINE return NEW_LINE DEDENT if " binary " not in search . formats and ext == wheel_ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' No ▁ binaries ▁ permitted ▁ for ▁ % s ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if " macosx10" in link . path and ext == ' . zip ' : NEW_LINE INDENT self . _log_skipped_link ( link , ' macosx10 ▁ one ' ) NEW_LINE return NEW_LINE DEDENT if ext == wheel_ext : NEW_LINE INDENT try : NEW_LINE INDENT wheel = Wheel ( link . filename ) NEW_LINE DEDENT except InvalidWheelFilename : NEW_LINE INDENT self . _log_skipped_link ( link , ' invalid ▁ wheel ▁ filename ' ) NEW_LINE return NEW_LINE DEDENT if ( pkg_resources . safe_name ( wheel . name ) . lower ( ) != search . canonical ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' wrong ▁ project ▁ name ▁ ( not ▁ % s ) ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if not wheel . supported ( ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ not ▁ compatible ▁ with ▁ this ▁ Python ' ) NEW_LINE return NEW_LINE # ▁ This ▁ is ▁ a ▁ dirty ▁ hack ▁ to ▁ prevent ▁ installing ▁ Binary ▁ Wheels ▁ from ENDCOM # ▁ PyPI ▁ unless ▁ it ▁ is ▁ a ▁ Windows ▁ or ▁ Mac ▁ Binary ▁ Wheel . ▁ This ▁ is ENDCOM # ▁ paired ▁ with ▁ a ▁ change ▁ to ▁ PyPI ▁ disabling ▁ uploads ▁ for ▁ the ENDCOM # ▁ same . ▁ Once ▁ we ▁ have ▁ a ▁ mechanism ▁ for ▁ enabling ▁ support ▁ for ENDCOM # ▁ binary ▁ wheels ▁ on ▁ linux ▁ that ▁ deals ▁ with ▁ the ▁ inherent ▁ problems ENDCOM # ▁ of ▁ binary ▁ distribution ▁ this ▁ can ▁ be ▁ removed . ENDCOM DEDENT comes_from = getattr ( link , " comes _ from " , None ) NEW_LINE if ( ( not platform . startswith ( ' win ' ) and not platform . startswith ( ' macosx ' ) and not platform == ' cli ' ) and comes_from is not None and urllib_parse . urlparse ( comes_from . url ) . netloc . endswith ( PyPI . netloc ) ) : NEW_LINE INDENT if not wheel . supported ( tags = supported_tags_noarch ) : NEW_LINE INDENT self . _log_skipped_link ( link , " it ▁ is ▁ a ▁ pypi - hosted ▁ binary ▁ " " Wheel ▁ on ▁ an ▁ unsupported ▁ platform " , ) NEW_LINE return NEW_LINE DEDENT DEDENT version = wheel . version NEW_LINE # ▁ This ▁ should ▁ be ▁ up ▁ by ▁ the ▁ search . ok _ binary ▁ check , ▁ but ▁ see ▁ issue ▁ 2700 . ENDCOM DEDENT DEDENT if " source " not in search . formats and ext != wheel_ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' No ▁ sources ▁ permitted ▁ for ▁ % s ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if not version : NEW_LINE INDENT version = egg_info_matches ( egg_info , search . supplied , link ) NEW_LINE DEDENT if version is None : NEW_LINE INDENT self . _log_skipped_link ( link , ' wrong ▁ project ▁ name ▁ ( not ▁ % s ) ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if ( link . internal is not None and not link . internal and not normalize_name ( search . supplied ) . lower ( ) in self . allow_external and not self . allow_all_external ) : NEW_LINE # ▁ We ▁ have ▁ a ▁ link ▁ that ▁ we ▁ are ▁ sure ▁ is ▁ external , ▁ so ▁ we ▁ should ▁ skip ENDCOM # ▁ it ▁ unless ▁ we ▁ are ▁ allowing ▁ externals ENDCOM INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ externally ▁ hosted ' ) NEW_LINE self . need_warn_external = True NEW_LINE return NEW_LINE DEDENT if ( link . verifiable is not None and not link . verifiable and not ( normalize_name ( search . supplied ) . lower ( ) in self . allow_unverified ) ) : NEW_LINE # ▁ We ▁ have ▁ a ▁ link ▁ that ▁ we ▁ are ▁ sure ▁ we ▁ cannot ▁ verify ▁ its ▁ integrity , ENDCOM # ▁ so ▁ we ▁ should ▁ skip ▁ it ▁ unless ▁ we ▁ are ▁ allowing ▁ unsafe ▁ installs ENDCOM # ▁ for ▁ this ▁ requirement . ENDCOM INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ an ▁ insecure ▁ and ▁ unverifiable ▁ file ' ) NEW_LINE self . need_warn_unverified = True NEW_LINE return NEW_LINE DEDENT match = self . _py_version_re . search ( version ) NEW_LINE if match : NEW_LINE INDENT version = version [ : match . start ( ) ] NEW_LINE py_version = match . group ( 1 ) NEW_LINE if py_version != sys . version [ : 3 ] : NEW_LINE INDENT self . _log_skipped_link ( link , ' Python ▁ version ▁ is ▁ incorrect ' ) NEW_LINE return NEW_LINE DEDENT DEDENT logger . debug ( ' Found ▁ link ▁ % s , ▁ version : ▁ % s ' , link , version ) NEW_LINE return InstallationCandidate ( search . supplied , version , link ) NEW_LINE DEDENT def _get_page ( self , link ) : NEW_LINE INDENT return HTMLPage . get_page ( link , session = self . session ) NEW_LINE DEDENT DEDENT def egg_info_matches ( egg_info , search_name , link , _egg_info_re = re . compile ( r ' ( [ a - z0-9 _ . ] + ) - ( [ a - z0-9 _ . ! + - ] + ) ' , re . I ) ) : NEW_LINE INDENT """ Pull ▁ the ▁ version ▁ part ▁ out ▁ of ▁ a ▁ string . STRNEWLINE STRNEWLINE ▁ : param ▁ egg _ info : ▁ The ▁ string ▁ to ▁ parse . ▁ E . g . ▁ foo - 2.1 STRNEWLINE ▁ : param ▁ search _ name : ▁ The ▁ name ▁ of ▁ the ▁ package ▁ this ▁ belongs ▁ to . ▁ None ▁ to STRNEWLINE ▁ infer ▁ the ▁ name . ▁ Note ▁ that ▁ this ▁ cannot ▁ unambiguously ▁ parse ▁ strings STRNEWLINE ▁ like ▁ foo - 2-2 ▁ which ▁ might ▁ be ▁ foo , ▁ 2-2 ▁ or ▁ foo - 2 , ▁ 2 . STRNEWLINE ▁ : param ▁ link : ▁ The ▁ link ▁ the ▁ string ▁ came ▁ from , ▁ for ▁ logging ▁ on ▁ failure . STRNEWLINE ▁ """ NEW_LINE match = _egg_info_re . search ( egg_info ) NEW_LINE if not match : NEW_LINE INDENT logger . debug ( ' Could ▁ not ▁ parse ▁ version ▁ from ▁ link : ▁ % s ' , link ) NEW_LINE return None NEW_LINE DEDENT if search_name is None : NEW_LINE INDENT full_match = match . group ( 0 ) NEW_LINE return full_match [ full_match . index ( ' - ' ) : ] NEW_LINE DEDENT name = match . group ( 0 ) . lower ( ) NEW_LINE # ▁ To ▁ match ▁ the ▁ " safe " ▁ name ▁ that ▁ pkg _ resources ▁ creates : ENDCOM name = name . replace ( ' _ ' , ' - ' ) NEW_LINE # ▁ project ▁ name ▁ and ▁ version ▁ must ▁ be ▁ separated ▁ by ▁ a ▁ dash ENDCOM look_for = search_name . lower ( ) + " - " NEW_LINE if name . startswith ( look_for ) : NEW_LINE INDENT return match . group ( 0 ) [ len ( look_for ) : ] NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT class HTMLPage ( object ) : NEW_LINE INDENT """ Represents ▁ one ▁ page , ▁ along ▁ with ▁ its ▁ URL """ NEW_LINE def __init__ ( self , content , url , headers = None , trusted = None ) : NEW_LINE # ▁ Determine ▁ if ▁ we ▁ have ▁ any ▁ encoding ▁ information ▁ in ▁ our ▁ headers ENDCOM INDENT encoding = None NEW_LINE if headers and " Content - Type " in headers : NEW_LINE INDENT content_type , params = cgi . parse_header ( headers [ " Content - Type " ] ) NEW_LINE if " charset " in params : NEW_LINE INDENT encoding = params [ ' charset ' ] NEW_LINE DEDENT DEDENT self . content = content NEW_LINE self . parsed = html5lib . parse ( self . content , encoding = encoding , namespaceHTMLElements = False , ) NEW_LINE self . url = url NEW_LINE self . headers = headers NEW_LINE self . trusted = trusted NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return self . url NEW_LINE DEDENT @ classmethod NEW_LINE def get_page ( cls , link , skip_archives = True , session = None ) : NEW_LINE INDENT if session is None : NEW_LINE INDENT raise TypeError ( " get _ page ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ ' session ' " ) NEW_LINE DEDENT url = link . url NEW_LINE url = url . split ( ' # ' , 1 ) [ 0 ] NEW_LINE # ▁ Check ▁ for ▁ VCS ▁ schemes ▁ that ▁ do ▁ not ▁ support ▁ lookup ▁ as ▁ web ▁ pages . ENDCOM from pip . vcs import VcsSupport NEW_LINE for scheme in VcsSupport . schemes : NEW_LINE INDENT if url . lower ( ) . startswith ( scheme ) and url [ len ( scheme ) ] in ' + : ' : NEW_LINE INDENT logger . debug ( ' Cannot ▁ look ▁ at ▁ % s ▁ URL ▁ % s ' , scheme , link ) NEW_LINE return None NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT if skip_archives : NEW_LINE INDENT filename = link . filename NEW_LINE for bad_ext in ARCHIVE_EXTENSIONS : NEW_LINE INDENT if filename . endswith ( bad_ext ) : NEW_LINE INDENT content_type = cls . _get_content_type ( url , session = session , ) NEW_LINE if content_type . lower ( ) . startswith ( ' text / html ' ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT DEDENT DEDENT DEDENT logger . debug ( ' Getting ▁ page ▁ % s ' , url ) NEW_LINE # ▁ Tack ▁ index . html ▁ onto ▁ file : / / ▁ URLs ▁ that ▁ point ▁ to ▁ directories ENDCOM ( scheme , netloc , path , params , query , fragment ) = urllib_parse . urlparse ( url ) NEW_LINE if ( scheme == ' file ' and os . path . isdir ( urllib_request . url2pathname ( path ) ) ) : NEW_LINE # ▁ add ▁ trailing ▁ slash ▁ if ▁ not ▁ present ▁ so ▁ urljoin ▁ doesn ' t ▁ trim ENDCOM # ▁ final ▁ segment ENDCOM INDENT if not url . endswith ( ' / ' ) : NEW_LINE INDENT url += ' / ' NEW_LINE DEDENT url = urllib_parse . urljoin ( url , ' index . html ' ) NEW_LINE logger . debug ( ' ▁ file : ▁ URL ▁ is ▁ directory , ▁ getting ▁ % s ' , url ) NEW_LINE DEDENT resp = session . get ( url , headers = { " Accept " : " text / html " , " Cache - Control " : " max - age = 600" , } , ) NEW_LINE resp . raise_for_status ( ) NEW_LINE # ▁ The ▁ check ▁ for ▁ archives ▁ above ▁ only ▁ works ▁ if ▁ the ▁ url ▁ ends ▁ with ENDCOM # ▁ something ▁ that ▁ looks ▁ like ▁ an ▁ archive . ▁ However ▁ that ▁ is ▁ not ▁ a ENDCOM # ▁ requirement ▁ of ▁ an ▁ url . ▁ Unless ▁ we ▁ issue ▁ a ▁ HEAD ▁ request ▁ on ▁ every ENDCOM # ▁ url ▁ we ▁ cannot ▁ know ▁ ahead ▁ of ▁ time ▁ for ▁ sure ▁ if ▁ something ▁ is ▁ HTML ENDCOM # ▁ or ▁ not . ▁ However ▁ we ▁ can ▁ check ▁ after ▁ we ' ve ▁ downloaded ▁ it . ENDCOM content_type = resp . headers . get ( ' Content - Type ' , ' unknown ' ) NEW_LINE if not content_type . lower ( ) . startswith ( " text / html " ) : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT inst = cls ( resp . content , resp . url , resp . headers , trusted = link . trusted , ) NEW_LINE DEDENT except requests . HTTPError as exc : NEW_LINE INDENT level = 2 if exc . response . status_code == 404 else 1 NEW_LINE cls . _handle_fail ( link , exc , url , level = level ) NEW_LINE DEDENT except requests . ConnectionError as exc : NEW_LINE INDENT cls . _handle_fail ( link , " connection ▁ error : ▁ % s " % exc , url ) NEW_LINE DEDENT except requests . Timeout : NEW_LINE INDENT cls . _handle_fail ( link , " timed ▁ out " , url ) NEW_LINE DEDENT except SSLError as exc : NEW_LINE INDENT reason = ( " There ▁ was ▁ a ▁ problem ▁ confirming ▁ the ▁ ssl ▁ certificate : ▁ " " % s " % exc ) NEW_LINE cls . _handle_fail ( link , reason , url , level = 2 , meth = logger . info ) NEW_LINE DEDENT else : NEW_LINE INDENT return inst NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def _handle_fail ( link , reason , url , level = 1 , meth = None ) : NEW_LINE INDENT if meth is None : NEW_LINE INDENT meth = logger . debug NEW_LINE DEDENT meth ( " Could ▁ not ▁ fetch ▁ URL ▁ % s : ▁ % s ▁ - ▁ skipping " , link , reason ) NEW_LINE DEDENT @ staticmethod NEW_LINE def _get_content_type ( url , session ) : NEW_LINE INDENT """ Get ▁ the ▁ Content - Type ▁ of ▁ the ▁ given ▁ url , ▁ using ▁ a ▁ HEAD ▁ request """ NEW_LINE scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( url ) NEW_LINE if scheme not in ( ' http ' , ' https ' ) : NEW_LINE # ▁ FIXME : ▁ some ▁ warning ▁ or ▁ something ? ENDCOM # ▁ assertion ▁ error ? ENDCOM INDENT return ' ' NEW_LINE DEDENT resp = session . head ( url , allow_redirects = True ) NEW_LINE resp . raise_for_status ( ) NEW_LINE return resp . headers . get ( " Content - Type " , " " ) NEW_LINE DEDENT @ cached_property NEW_LINE def api_version ( self ) : NEW_LINE INDENT metas = [ x for x in self . parsed . findall ( " . / / meta " ) if x . get ( " name " , " " ) . lower ( ) == " api - version " ] NEW_LINE if metas : NEW_LINE INDENT try : NEW_LINE INDENT return int ( metas [ 0 ] . get ( " value " , None ) ) NEW_LINE DEDENT except ( TypeError , ValueError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT @ cached_property NEW_LINE def base_url ( self ) : NEW_LINE INDENT bases = [ x for x in self . parsed . findall ( " . / / base " ) if x . get ( " href " ) is not None ] NEW_LINE if bases and bases [ 0 ] . get ( " href " ) : NEW_LINE INDENT return bases [ 0 ] . get ( " href " ) NEW_LINE DEDENT else : NEW_LINE INDENT return self . url NEW_LINE DEDENT DEDENT @ property NEW_LINE def links ( self ) : NEW_LINE INDENT """ Yields ▁ all ▁ links ▁ in ▁ the ▁ page """ NEW_LINE for anchor in self . parsed . findall ( " . / / a " ) : NEW_LINE INDENT if anchor . get ( " href " ) : NEW_LINE INDENT href = anchor . get ( " href " ) NEW_LINE url = self . clean_link ( urllib_parse . urljoin ( self . base_url , href ) ) NEW_LINE # ▁ Determine ▁ if ▁ this ▁ link ▁ is ▁ internal . ▁ If ▁ that ▁ distinction ENDCOM # ▁ doesn ' t ▁ make ▁ sense ▁ in ▁ this ▁ context , ▁ then ▁ we ▁ don ' t ▁ make ENDCOM # ▁ any ▁ distinction . ENDCOM internal = None NEW_LINE if self . api_version and self . api_version >= 2 : NEW_LINE # ▁ Only ▁ api _ versions ▁ > = ▁ 2 ▁ have ▁ a ▁ distinction ▁ between ENDCOM # ▁ external ▁ and ▁ internal ▁ links ENDCOM INDENT internal = bool ( anchor . get ( " rel " ) and " internal " in anchor . get ( " rel " ) . split ( ) ) NEW_LINE DEDENT yield Link ( url , self , internal = internal ) NEW_LINE DEDENT DEDENT DEDENT def rel_links ( self , rels = ( ' homepage ' , ' download ' ) ) : NEW_LINE INDENT """ Yields ▁ all ▁ links ▁ with ▁ the ▁ given ▁ relations """ NEW_LINE rels = set ( rels ) NEW_LINE for anchor in self . parsed . findall ( " . / / a " ) : NEW_LINE INDENT if anchor . get ( " rel " ) and anchor . get ( " href " ) : NEW_LINE INDENT found_rels = set ( anchor . get ( " rel " ) . split ( ) ) NEW_LINE # ▁ Determine ▁ the ▁ intersection ▁ between ▁ what ▁ rels ▁ were ▁ found ▁ and ENDCOM # ▁ what ▁ rels ▁ were ▁ being ▁ looked ▁ for ENDCOM if found_rels & rels : NEW_LINE INDENT href = anchor . get ( " href " ) NEW_LINE url = self . clean_link ( urllib_parse . urljoin ( self . base_url , href ) ) NEW_LINE yield Link ( url , self , trusted = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT _clean_re = re . compile ( r ' [ ^ a - z0-9 $ & + , / : ; = ? @ . # % _ \\ | - ] ' , re . I ) NEW_LINE def clean_link ( self , url ) : NEW_LINE INDENT """ Makes ▁ sure ▁ a ▁ link ▁ is ▁ fully ▁ encoded . ▁ That ▁ is , ▁ if ▁ a ▁ ' ▁ ' ▁ shows ▁ up ▁ in STRNEWLINE ▁ the ▁ link , ▁ it ▁ will ▁ be ▁ rewritten ▁ to ▁ % 20 ▁ ( while ▁ not ▁ over - quoting STRNEWLINE ▁ % ▁ or ▁ other ▁ characters ) . """ NEW_LINE return self . _clean_re . sub ( lambda match : ' % % % 2x ' % ord ( match . group ( 0 ) ) , url ) NEW_LINE DEDENT DEDENT class Link ( object ) : NEW_LINE INDENT def __init__ ( self , url , comes_from = None , internal = None , trusted = None ) : NEW_LINE # ▁ url ▁ can ▁ be ▁ a ▁ UNC ▁ windows ▁ share ENDCOM INDENT if url != Inf and url . startswith ( ' \\\\ ' ) : NEW_LINE INDENT url = path_to_url ( url ) NEW_LINE DEDENT self . url = url NEW_LINE self . comes_from = comes_from NEW_LINE self . internal = internal NEW_LINE self . trusted = trusted NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT if self . comes_from : NEW_LINE INDENT return ' % s ▁ ( from ▁ % s ) ' % ( self . url , self . comes_from ) NEW_LINE DEDENT else : NEW_LINE INDENT return str ( self . url ) NEW_LINE DEDENT DEDENT def __repr__ ( self ) : NEW_LINE INDENT return ' < Link ▁ % s > ' % self NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url == other . url NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url != other . url NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url < other . url NEW_LINE DEDENT def __le__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url <= other . url NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url > other . url NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url >= other . url NEW_LINE DEDENT def __hash__ ( self ) : NEW_LINE INDENT return hash ( self . url ) NEW_LINE DEDENT @ property NEW_LINE def filename ( self ) : NEW_LINE INDENT _ , netloc , path , _ , _ = urllib_parse . urlsplit ( self . url ) NEW_LINE name = posixpath . basename ( path . rstrip ( ' / ' ) ) or netloc NEW_LINE name = urllib_parse . unquote ( name ) NEW_LINE assert name , ( ' URL ▁ % r ▁ produced ▁ no ▁ filename ' % self . url ) NEW_LINE return name NEW_LINE DEDENT @ property NEW_LINE def scheme ( self ) : NEW_LINE INDENT return urllib_parse . urlsplit ( self . url ) [ 0 ] NEW_LINE DEDENT @ property NEW_LINE def netloc ( self ) : NEW_LINE INDENT return urllib_parse . urlsplit ( self . url ) [ 1 ] NEW_LINE DEDENT @ property NEW_LINE def path ( self ) : NEW_LINE INDENT return urllib_parse . unquote ( urllib_parse . urlsplit ( self . url ) [ 2 ] ) NEW_LINE DEDENT def splitext ( self ) : NEW_LINE INDENT return splitext ( posixpath . basename ( self . path . rstrip ( ' / ' ) ) ) NEW_LINE DEDENT @ property NEW_LINE def ext ( self ) : NEW_LINE INDENT return self . splitext ( ) [ 1 ] NEW_LINE DEDENT @ property NEW_LINE def url_without_fragment ( self ) : NEW_LINE INDENT scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( self . url ) NEW_LINE return urllib_parse . urlunsplit ( ( scheme , netloc , path , query , None ) ) NEW_LINE DEDENT _egg_fragment_re = re . compile ( r ' # egg = ( [ ^ & ] * ) ' ) NEW_LINE @ property NEW_LINE def egg_fragment ( self ) : NEW_LINE INDENT match = self . _egg_fragment_re . search ( self . url ) NEW_LINE if not match : NEW_LINE INDENT return None NEW_LINE DEDENT return match . group ( 1 ) NEW_LINE DEDENT _hash_re = re . compile ( r ' ( sha1 | sha224 | sha384 | sha256 | sha512 | md5 ) = ( [ a - f0-9 ] + ) ' ) NEW_LINE @ property NEW_LINE def hash ( self ) : NEW_LINE INDENT match = self . _hash_re . search ( self . url ) NEW_LINE if match : NEW_LINE INDENT return match . group ( 2 ) NEW_LINE DEDENT return None NEW_LINE DEDENT @ property NEW_LINE def hash_name ( self ) : NEW_LINE INDENT match = self . _hash_re . search ( self . url ) NEW_LINE if match : NEW_LINE INDENT return match . group ( 1 ) NEW_LINE DEDENT return None NEW_LINE DEDENT @ property NEW_LINE def show_url ( self ) : NEW_LINE INDENT return posixpath . basename ( self . url . split ( ' # ' , 1 ) [ 0 ] . split ( ' ? ' , 1 ) [ 0 ] ) NEW_LINE DEDENT @ property NEW_LINE def verifiable ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ True ▁ if ▁ this ▁ link ▁ can ▁ be ▁ verified ▁ after ▁ download , ▁ False ▁ if ▁ it STRNEWLINE ▁ cannot , ▁ and ▁ None ▁ if ▁ we ▁ cannot ▁ determine . STRNEWLINE ▁ """ NEW_LINE trusted = self . trusted or getattr ( self . comes_from , " trusted " , None ) NEW_LINE if trusted is not None and trusted : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ a ▁ trusted ▁ source . ▁ It ▁ * may * ▁ be ▁ verifiable ▁ but ENDCOM # ▁ first ▁ we ▁ need ▁ to ▁ see ▁ if ▁ this ▁ page ▁ is ▁ operating ▁ under ▁ the ▁ new ENDCOM # ▁ API ▁ version . ENDCOM INDENT try : NEW_LINE INDENT api_version = getattr ( self . comes_from , " api _ version " , None ) NEW_LINE api_version = int ( api_version ) NEW_LINE DEDENT except ( ValueError , TypeError ) : NEW_LINE INDENT api_version = None NEW_LINE DEDENT if api_version is None or api_version <= 1 : NEW_LINE # ▁ This ▁ link ▁ is ▁ either ▁ trusted , ▁ or ▁ it ▁ came ▁ from ▁ a ▁ trusted , ENDCOM # ▁ however ▁ it ▁ is ▁ not ▁ operating ▁ under ▁ the ▁ API ▁ version ▁ 2 ▁ so ENDCOM # ▁ we ▁ can ' t ▁ make ▁ any ▁ claims ▁ about ▁ if ▁ it ' s ▁ safe ▁ or ▁ not ENDCOM INDENT return NEW_LINE DEDENT if self . hash : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ a ▁ trusted ▁ source ▁ and ▁ it ▁ has ▁ a ▁ hash , ▁ so ▁ we ENDCOM # ▁ can ▁ consider ▁ it ▁ safe . ENDCOM INDENT return True NEW_LINE DEDENT else : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ a ▁ trusted ▁ source , ▁ using ▁ the ▁ new ▁ API ENDCOM # ▁ version , ▁ and ▁ it ▁ does ▁ not ▁ have ▁ a ▁ hash . ▁ It ▁ is ▁ NOT ▁ verifiable ENDCOM INDENT return False NEW_LINE DEDENT DEDENT elif trusted is not None : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ an ▁ untrusted ▁ source ▁ and ▁ we ▁ cannot ▁ trust ▁ it ENDCOM INDENT return False NEW_LINE DEDENT DEDENT @ property NEW_LINE def is_wheel ( self ) : NEW_LINE INDENT return self . ext == wheel_ext NEW_LINE DEDENT @ property NEW_LINE def is_artifact ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Determines ▁ if ▁ this ▁ points ▁ to ▁ an ▁ actual ▁ artifact ▁ ( e . g . ▁ a ▁ tarball ) ▁ or ▁ if STRNEWLINE ▁ it ▁ points ▁ to ▁ an ▁ " abstract " ▁ thing ▁ like ▁ a ▁ path ▁ or ▁ a ▁ VCS ▁ location . STRNEWLINE ▁ """ NEW_LINE from pip . vcs import vcs NEW_LINE if self . scheme in vcs . all_schemes : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE # ▁ An ▁ object ▁ to ▁ represent ▁ the ▁ " link " ▁ for ▁ the ▁ installed ▁ version ▁ of ▁ a ▁ requirement . ENDCOM # ▁ Using ▁ Inf ▁ as ▁ the ▁ url ▁ makes ▁ it ▁ sort ▁ higher . ENDCOM DEDENT DEDENT INSTALLED_VERSION = Link ( Inf ) NEW_LINE FormatControl = namedtuple ( ' FormatControl ' , ' no _ binary ▁ only _ binary ' ) NEW_LINE """ This ▁ object ▁ has ▁ two ▁ fields , ▁ no _ binary ▁ and ▁ only _ binary . STRNEWLINE STRNEWLINE If ▁ a ▁ field ▁ is ▁ falsy , ▁ it ▁ isn ' t ▁ set . ▁ If ▁ it ▁ is ▁ { ' : all : ' } , ▁ it ▁ should ▁ match ▁ all STRNEWLINE packages ▁ except ▁ those ▁ listed ▁ in ▁ the ▁ other ▁ field . ▁ Only ▁ one ▁ field ▁ can ▁ be ▁ set STRNEWLINE to ▁ { ' : all : ' } ▁ at ▁ a ▁ time . ▁ The ▁ rest ▁ of ▁ the ▁ time ▁ exact ▁ package ▁ name ▁ matches STRNEWLINE are ▁ listed , ▁ with ▁ any ▁ given ▁ package ▁ only ▁ showing ▁ up ▁ in ▁ one ▁ field ▁ at ▁ a ▁ time . STRNEWLINE """ NEW_LINE def fmt_ctl_handle_mutual_exclude ( value , target , other ) : NEW_LINE INDENT new = value . split ( ' , ' ) NEW_LINE while ' : all : ' in new : NEW_LINE INDENT other . clear ( ) NEW_LINE target . clear ( ) NEW_LINE target . add ( ' : all : ' ) NEW_LINE del new [ : new . index ( ' : all : ' ) + 1 ] NEW_LINE if ' : none : ' not in new : NEW_LINE # ▁ Without ▁ a ▁ none , ▁ we ▁ want ▁ to ▁ discard ▁ everything ▁ as ▁ : all : ▁ covers ▁ it ENDCOM INDENT return NEW_LINE DEDENT DEDENT for name in new : NEW_LINE INDENT if name == ' : none : ' : NEW_LINE INDENT target . clear ( ) NEW_LINE continue NEW_LINE DEDENT name = pkg_resources . safe_name ( name ) . lower ( ) NEW_LINE other . discard ( name ) NEW_LINE target . add ( name ) NEW_LINE DEDENT DEDENT def fmt_ctl_formats ( fmt_ctl , canonical_name ) : NEW_LINE INDENT result = set ( [ " binary " , " source " ] ) NEW_LINE if canonical_name in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif canonical_name in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT return frozenset ( result ) NEW_LINE DEDENT def fmt_ctl_no_binary ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_handle_mutual_exclude ( ' : all : ' , fmt_ctl . no_binary , fmt_ctl . only_binary ) NEW_LINE DEDENT def fmt_ctl_no_use_wheel ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_no_binary ( fmt_ctl ) NEW_LINE warnings . warn ( ' - - no - use - wheel ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ removed ▁ in ▁ the ▁ future . ▁ ' ' ▁ Please ▁ use ▁ - - no - binary ▁ : all : ▁ instead . ' , DeprecationWarning , stacklevel = 2 ) NEW_LINE DEDENT Search = namedtuple ( ' Search ' , ' supplied ▁ canonical ▁ formats ' ) NEW_LINE """ Capture ▁ key ▁ aspects ▁ of ▁ a ▁ search . STRNEWLINE STRNEWLINE : attribute ▁ supplied : ▁ The ▁ user ▁ supplied ▁ package . STRNEWLINE : attribute ▁ canonical : ▁ The ▁ canonical ▁ package ▁ name . STRNEWLINE : attribute ▁ formats : ▁ The ▁ formats ▁ allowed ▁ for ▁ this ▁ package . ▁ Should ▁ be ▁ a ▁ set STRNEWLINE ▁ with ▁ ' binary ' ▁ or ▁ ' source ' ▁ or ▁ both ▁ in ▁ it . STRNEWLINE """ NEW_LINE </DOCUMENT>
<DOCUMENT_ID="nikolay-fedotov/tempest/tree/master/tempest/api/object_storage/test_account_services_negative.py"> # ▁ Copyright ▁ ( C ) ▁ 2013 ▁ eNovance ▁ SAS ▁ < licensing @ enovance . com > ENDCOM # ▁ Author : ▁ Joe ▁ H . ▁ Rahme ▁ < joe . hakim . rahme @ enovance . com > ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM from tempest . api . object_storage import base NEW_LINE from tempest import clients NEW_LINE from tempest import exceptions NEW_LINE from tempest import test NEW_LINE class AccountNegativeTest ( base . BaseObjectTest ) : NEW_LINE INDENT @ test . attr ( type = [ ' negative ' , ' gate ' ] ) NEW_LINE def test_list_containers_with_non_authorized_user ( self ) : NEW_LINE # ▁ list ▁ containers ▁ using ▁ non - authorized ▁ user ENDCOM # ▁ create ▁ user ENDCOM INDENT self . data . setup_test_user ( ) NEW_LINE test_os = clients . Manager ( self . data . test_credentials ) NEW_LINE test_auth_provider = test_os . auth_provider NEW_LINE # ▁ Get ▁ auth ▁ for ▁ the ▁ test ▁ user ENDCOM test_auth_provider . auth_data NEW_LINE # ▁ Get ▁ fresh ▁ auth ▁ for ▁ test ▁ user ▁ and ▁ set ▁ it ▁ to ▁ next ▁ auth ▁ request ▁ for ENDCOM # ▁ custom _ account _ client ENDCOM delattr ( test_auth_provider , ' auth _ data ' ) NEW_LINE test_auth_new_data = test_auth_provider . auth_data NEW_LINE self . custom_account_client . auth_provider . set_alt_auth_data ( request_part = ' headers ' , auth_data = test_auth_new_data ) NEW_LINE params = { ' format ' : ' json ' } NEW_LINE # ▁ list ▁ containers ▁ with ▁ non - authorized ▁ user ▁ token ENDCOM self . assertRaises ( exceptions . Unauthorized , self . custom_account_client . list_account_containers , params = params ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="xxxIsaacPeralxxx/anim-studio-tools/tree/master/kip/houdini/code/kip_houdini/convert.py"> # ▁ Dr . ▁ D ▁ Studios ▁ - ▁ Software ▁ Disclaimer ENDCOM # ▁ Copyright ▁ 2009 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited ▁ ( ACN ▁ 127 ▁ 184 ▁ 954 ) ▁ ( Dr . ▁ D ▁ Studios ) , ▁ its ENDCOM # ▁ affiliates ▁ and / or ▁ its ▁ licensors . ENDCOM """ STRNEWLINE This ▁ module ▁ will ▁ help ▁ TD ' s ▁ to ▁ convert ▁ houdini ▁ animation ▁ curve ▁ to ▁ nuke ▁ or ▁ maya STRNEWLINE the ▁ other ▁ way ▁ around ▁ also . STRNEWLINE STRNEWLINE . . ▁ note : : STRNEWLINE STRNEWLINE ▁ Please ▁ make ▁ sure ▁ you ▁ are ▁ running ▁ in ▁ proper ▁ kipHoudini ▁ environment STRNEWLINE STRNEWLINE . . ▁ warning : : STRNEWLINE STRNEWLINE ▁ Dont ▁ import ▁ this ▁ module ▁ as ▁ standalone ▁ , ▁ use ▁ this ▁ module ▁ with ▁ kip ▁ project STRNEWLINE STRNEWLINE """ NEW_LINE __authors__ = [ " kurian . os " ] NEW_LINE __version__ = " $ Revision : ▁ 104961 ▁ $ " . split ( ) [ 1 ] NEW_LINE __revision__ = __version__ NEW_LINE __date__ = " $ Date : ▁ ▁ July ▁ 19 , ▁ 2011 ▁ 12:00:00 ▁ PM $ " . split ( ) [ 1 ] NEW_LINE __copyright__ = "2011" NEW_LINE __license__ = " Copyright ▁ 2011 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited " NEW_LINE __contact__ = " kurian . os @ drdstudios . com " NEW_LINE __status__ = " Development " NEW_LINE import os NEW_LINE import traceback NEW_LINE # import ▁ hou ENDCOM import napalm . core as nap_core NEW_LINE import node_curves as node_curves NEW_LINE import kip . kip_reader as kip_reader NEW_LINE reload ( node_curves ) NEW_LINE reload ( kip_reader ) NEW_LINE from rodin import logging NEW_LINE from kip . kip_curve_class import * NEW_LINE from kip . kip_napalm_class import * NEW_LINE from kip . utils . kipError import * NEW_LINE from kip . template import * NEW_LINE rodin_logger = logging . get_logger ( ' kipHoudini ' ) NEW_LINE napalm_func = Napalm ( ) NEW_LINE GLOBAL_FPS = 24 NEW_LINE GLOBAL_TIME = 1 NEW_LINE class HoudiniWriter ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ Creating ▁ houdini ▁ curve ▁ writer ▁ class STRNEWLINE STRNEWLINE ▁ * Parents : * STRNEWLINE STRNEWLINE ▁ None STRNEWLINE STRNEWLINE ▁ * Children : * STRNEWLINE STRNEWLINE ▁ * ▁ : func : ` writeOutCurves ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Base ▁ init ▁ function ▁ for ▁ houdini ▁ convert . write ▁ Class . STRNEWLINE ▁ """ NEW_LINE rodin_logger . info ( " kip ▁ houdini ▁ writing ▁ class ▁ initialized " ) NEW_LINE self . houdini_version = " houdini , % s " % hou . applicationVersionString ( ) NEW_LINE self . kip_houdini_version = " kipHoudini % s " % os . getenv ( " DRD _ KIPHOUDINI _ VERSION " ) NEW_LINE DEDENT def writeOutCurves ( self , nap_file_name = None , houdini_nodes = [ ] , houdini_node_attributes = [ ] , start_frame = None , end_frame = None , write_xml = False , silent = False , left_eyes = [ ] , right_eyes = [ ] , map_file_name = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ function ▁ will ▁ create ▁ a ▁ curve ▁ class ▁ object ▁ first ▁ and ▁ then ▁ it ▁ will ▁ write ▁ out ▁ the ▁ napalm ▁ file . STRNEWLINE STRNEWLINE ▁ . . ▁ warning : : STRNEWLINE STRNEWLINE ▁ If ▁ you ▁ are ▁ unable ▁ to ▁ write ▁ out ▁ napalm ▁ file ▁ or ▁ write _ status = False ▁ that ▁ means ▁ napalm ▁ failed ▁ to ▁ write ▁ out . STRNEWLINE STRNEWLINE ▁ : param ▁ nap _ file _ name : ▁ User ▁ must ▁ pass ▁ a ▁ file ▁ where ▁ he ▁ want ▁ to ▁ write ▁ out ▁ curves ▁ and ▁ make ▁ sure ▁ you ▁ supply ▁ a ▁ . nap ▁ or ▁ . xml ▁ file ▁ format ( strict ) STRNEWLINE STRNEWLINE ▁ : type ▁ nap _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ nodes : ▁ list ▁ of ▁ houdini ▁ objects ( strict ) STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ nodes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ node _ attribute : ▁ if ▁ you ▁ want ▁ to ▁ replace ▁ attribute ▁ from ▁ the ▁ map ▁ file ▁ then ▁ you ▁ can ▁ specify ▁ the ▁ override ▁ attribute ▁ here STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ node _ attribute : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ start _ frame : ▁ start ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ start _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ end _ frame : ▁ end ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ end _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ write _ xml : ▁ If ▁ you ▁ want ▁ to ▁ write ▁ out ▁ a ▁ xml ▁ file ▁ instead ▁ of ▁ napalm ▁ file ▁ then ▁ this ▁ should ▁ be ▁ true STRNEWLINE STRNEWLINE ▁ : type ▁ end _ frame : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ left _ eyes : ▁ Left ▁ eye ▁ objects STRNEWLINE STRNEWLINE ▁ : type ▁ left _ eyes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ right _ eyes : ▁ Right ▁ eye ▁ objects STRNEWLINE STRNEWLINE ▁ : type ▁ right _ eyes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : return : ▁ Status , channel ▁ file ▁ , ▁ map ▁ file STRNEWLINE STRNEWLINE ▁ : rtype : ▁ boot , string , string STRNEWLINE STRNEWLINE ▁ Example STRNEWLINE STRNEWLINE ▁ > > > ▁ import ▁ kip _ houdini . convert ▁ as ▁ kh STRNEWLINE ▁ > > > ▁ reload ( kh ) STRNEWLINE ▁ > > > ▁ khcw ▁ = ▁ kh . HoudiniWriter ( ) STRNEWLINE ▁ > > > ▁ status , nap _ file , map _ file = khcw . writeOutCurves ( nap _ file _ name ▁ = ▁ " / tmp / houdini _ kip _ test _ s . nap " , map _ file _ name = ▁ " / tmp / houdini _ kip _ test _ m . nap " , houdini _ nodes ▁ = ▁ [ " / obj / geo / xform _ 1 " , " / obj / geo / xform _ 2 " ] , left _ eyes = [ " / obj / geo / xform _ 1 " ] , right _ eyes = [ " / obj / geo / xform _ 2 " ] ) STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if nap_file_name : NEW_LINE INDENT node_curv = node_curves . NodeCurves ( ) NEW_LINE get_all_curves = node_curv . getCurves ( houdini_node_curves = houdini_nodes , houdini_attribute_curves = houdini_node_attributes , start_frame = start_frame , end_frame = end_frame , silent = silent , left_eye_curves = left_eyes , right_eye_curves = right_eyes ) NEW_LINE if write_xml : NEW_LINE INDENT if not nap_file_name . endswith ( " . xml " ) : NEW_LINE INDENT split_base_ext = os . path . splitext ( nap_file_name ) NEW_LINE if split_base_ext [ - 1 ] : NEW_LINE INDENT nap_file_name = " % s / . xml " % ( split_base_ext [ 0 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT nap_file_name = " % s / . xml " % ( nap_file_name ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if not nap_file_name . endswith ( " . nap " ) : NEW_LINE INDENT raise KipBaseError ( " Unknown ▁ file ▁ extension ▁ found ▁ in ▁ % s ▁ ! " % nap_file_name ) NEW_LINE DEDENT DEDENT write_status , map_file , nap_file = napalm_func . write ( nap_file_name , get_all_curves , debug = True , map_file_name = map_file_name , software = self . houdini_version , app_version = self . kip_houdini_version ) NEW_LINE rodin_logger . info ( " % s ▁ % s ▁ % s " % ( write_status , map_file , nap_file ) ) NEW_LINE return ( write_status , map_file , nap_file ) NEW_LINE DEDENT else : NEW_LINE INDENT raise KipBaseError ( " Expected ▁ napalm ▁ file ▁ name ▁ for ▁ write ▁ curve ▁ ! " ) NEW_LINE DEDENT DEDENT DEDENT class HoudiniReader ( object ) : NEW_LINE INDENT """ STRNEWLINE STRNEWLINE ▁ Creating ▁ houdini ▁ curve ▁ reader ▁ class STRNEWLINE STRNEWLINE ▁ * Parents : * STRNEWLINE STRNEWLINE ▁ None STRNEWLINE STRNEWLINE ▁ * Children : * STRNEWLINE STRNEWLINE ▁ * ▁ : func : ` houSetAttr ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Base ▁ init ▁ function ▁ for ▁ houdini ▁ convert . write ▁ Class . STRNEWLINE ▁ """ NEW_LINE rodin_logger . info ( " kip ▁ houdini ▁ read ▁ class ▁ initialized " ) NEW_LINE self . nuke_tan_types = { " spline " : " spline ( ) " , " linear " : " linear ( ) " , " constant " : " constant ( ) " , " cubic " : " bezier ( ) " } NEW_LINE self . channel_match = { ' translateX ' : ' tx ' , ' translateY ' : ' ty ' , ' translateZ ' : ' tz ' , ' rotateX ' : ' rx ' , ' rotateY ' : ' ry ' , ' rotateZ ' : ' rz ' , ' scaleX ' : ' sx ' , ' scaleY ' : ' sy ' , ' scaleZ ' : ' sz ' } NEW_LINE DEDENT def houSetAttr ( self , nap_file_name = None , houdini_nodes = [ ] , houdini_node_attribute = None , map_file_name = None , offset_value = 0 , start_frame = None , end_frame = None , attribute_map = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ function ▁ will ▁ get ▁ all ▁ curve ▁ data ▁ from ▁ a ▁ map ▁ and ▁ channel ▁ file ▁ then ▁ those ▁ data ▁ will ▁ be ▁ applied ▁ to ▁ proper ▁ nodes STRNEWLINE STRNEWLINE ▁ : param ▁ nap _ file _ name : ▁ User ▁ must ▁ pass ▁ a ▁ file ▁ where ▁ he ▁ want ▁ to ▁ write ▁ out ▁ curves ▁ and ▁ make ▁ sure ▁ you ▁ supply ▁ a ▁ . nap ▁ or ▁ . xml ▁ file ▁ format STRNEWLINE STRNEWLINE ▁ : type ▁ nap _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ nodes : ▁ list ▁ of ▁ houdini ▁ objects STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ nodes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ node _ attribute : ▁ if ▁ you ▁ want ▁ to ▁ replace ▁ attribute ▁ from ▁ the ▁ map ▁ file ▁ then ▁ you ▁ can ▁ specify ▁ the ▁ override ▁ attribute ▁ here STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ node _ attribute : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ offset _ value : ▁ Animation ▁ key ▁ offset ▁ value STRNEWLINE STRNEWLINE ▁ : type ▁ offset _ value : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ start _ frame : ▁ start ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ start _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ end _ frame : ▁ end ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ end _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ attribute _ map : ▁ This ▁ a ▁ template ▁ object ▁ from ▁ template ▁ module STRNEWLINE STRNEWLINE ▁ : type ▁ attribute _ map : ▁ list ▁ of ▁ tuple STRNEWLINE STRNEWLINE ▁ Example STRNEWLINE STRNEWLINE ▁ > > > ▁ import ▁ kip _ houdini . convert ▁ as ▁ kh STRNEWLINE ▁ > > > ▁ reload ( kh ) STRNEWLINE ▁ > > > ▁ khpr = kh . HoudiniReader ( ) STRNEWLINE ▁ > > > ▁ import ▁ kip . template ▁ as ▁ template STRNEWLINE ▁ > > > ▁ attr _ mp ▁ = ▁ template . KipTemplates ( ) STRNEWLINE ▁ > > > ▁ attr _ mp . ATTRMAP = { " t1 . cutatt1 " : " / obj / geo1 / xform1 . ottr _ 1 " , " t1 . cutatt2 " : " / obj / geo1 / xform1 . ottr _ 2 " , " t2 . cutatt1 " : " / obj / geo1 / xform1 . ottr _ 3 " , " t2 . cutatt2 " : " / obj / geo1 / xform1 . ottr _ 4 " } STRNEWLINE ▁ > > > ▁ a ▁ = ▁ attr _ mp . ATTRMAP STRNEWLINE ▁ > > > ▁ khpr . houSetAttr ( nap _ file _ name = " / tmp / single _ maya _ test . nap " , houdini _ nodes = " / obj / geo1 / xform1 " , attribute _ map = a ) STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if nap_file_name : NEW_LINE INDENT if not map_file_name : NEW_LINE INDENT map_file_name = kip_reader . build_map_file_name ( nap_file_name ) NEW_LINE DEDENT header_info = kip_reader . header ( map_file_name ) NEW_LINE array_index = kip_reader . find_software_index ( header_info [ " client _ software " ] ) NEW_LINE houdini_node_list = houdini_nodes NEW_LINE knob_read = kip_reader . ReadCurve ( ) NEW_LINE get_curve_class = knob_read . getCurves ( nap_file_name = nap_file_name , map_file_name = map_file_name , offset_value = offset_value ) NEW_LINE DEDENT for each_node in get_curve_class : NEW_LINE INDENT node_key = get_curve_class . index ( each_node ) NEW_LINE current_node_curve = each_node [ 2 ] NEW_LINE curent_source_node = each_node [ 0 ] NEW_LINE for each_curve in current_node_curve : NEW_LINE INDENT curve_attr = each_curve [ 1 ] NEW_LINE current_key_dict = each_curve [ 2 ] NEW_LINE time_keys = current_key_dict [ " time " ] NEW_LINE key_value = current_key_dict [ " key _ value " ] NEW_LINE in_angle = current_key_dict [ " in _ angle " ] NEW_LINE out_angle = current_key_dict [ " out _ angle " ] NEW_LINE in_weight = current_key_dict [ " in _ weight " ] NEW_LINE out_weight = current_key_dict [ " out _ weight " ] NEW_LINE in_tan_type = current_key_dict [ " in _ tan _ type " ] NEW_LINE out_tan_type = current_key_dict [ " out _ tan _ type " ] NEW_LINE in_slope = current_key_dict [ " in _ slope " ] NEW_LINE out_slope = current_key_dict [ " out _ slope " ] NEW_LINE try : NEW_LINE INDENT for time in time_keys : NEW_LINE INDENT if houdini_node_attribute : NEW_LINE INDENT curve_attr = houdini_node_attribute NEW_LINE DEDENT else : NEW_LINE INDENT if attribute_map : NEW_LINE INDENT temp_attr_keys = attribute_map . keys ( ) NEW_LINE for each_template in temp_attr_keys : NEW_LINE INDENT source_details = each_template . split ( " . " ) NEW_LINE current_node_attr = " % s . % s " % ( curent_source_node , each_curve [ 1 ] ) NEW_LINE if current_node_attr == each_template : NEW_LINE INDENT destenation_details = attribute_map [ each_template ] . split ( " . " ) NEW_LINE curve_attr = destenation_details [ 1 ] NEW_LINE current_houdini_node = destenation_details [ 0 ] NEW_LINE current_houdini_node = hou . node ( current_houdini_node ) NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT current_houdini_node = hou . node ( houdini_node_list [ node_key ] ) NEW_LINE DEDENT DEDENT if start_frame and end_frame : NEW_LINE INDENT if time in range ( start_frame , end_frame + 1 ) : NEW_LINE INDENT key_index = time_keys . index ( time ) NEW_LINE DEDENT else : NEW_LINE INDENT print " % s ▁ not ▁ in ▁ range ▁ not ▁ applying ▁ the ▁ key " % time NEW_LINE continue NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT key_index = time_keys . index ( time ) NEW_LINE DEDENT in_tan_v = in_tan_type [ key_index ] NEW_LINE if self . nuke_tan_types . has_key ( in_tan_v ) : NEW_LINE INDENT in_tan_v = self . nuke_tan_types [ in_tan_v ] NEW_LINE DEDENT else : NEW_LINE INDENT in_tan_v = " bezier ( ) " NEW_LINE DEDENT hkey = hou . Keyframe ( ) NEW_LINE hkey . setTime ( ( time_keys [ key_index ] / GLOBAL_FPS ) ) NEW_LINE hkey . setValue ( key_value [ key_index ] ) NEW_LINE hkey . setExpression ( " bezier ( ) " ) NEW_LINE hkey . setExpression ( " spline ( ) " ) NEW_LINE hkey . setInAccel ( in_weight [ key_index ] ) NEW_LINE hkey . setAccel ( out_weight [ key_index ] ) NEW_LINE hkey . setInSlope ( in_slope [ key_index ] ) NEW_LINE hkey . setSlope ( out_slope [ key_index ] ) NEW_LINE this_node_attr = curve_attr NEW_LINE if self . channel_match . has_key ( curve_attr ) : NEW_LINE INDENT this_node_attr = self . channel_match [ curve_attr ] NEW_LINE DEDENT hou_nod = current_houdini_node . parm ( this_node_attr ) . setKeyframe ( hkey ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT traceback . print_exc ( ) NEW_LINE raise KipBaseError ( " No ▁ objects ▁ found ▁ in ▁ node ▁ list ! " ) NEW_LINE DEDENT DEDENT DEDENT rodin_logger . info ( " Aniamtion ▁ curve ▁ trasfer ▁ is ▁ finished ▁ ! " ) NEW_LINE return True NEW_LINE DEDENT DEDENT def header ( map_file_name ) : NEW_LINE INDENT """ STRNEWLINE STRNEWLINE ▁ This ▁ function ▁ will ▁ return ▁ a ▁ dict ▁ of ▁ header ▁ details ▁ from ▁ map ▁ file STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : return : ▁ header ▁ details STRNEWLINE STRNEWLINE ▁ : rtype : ▁ dict STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if os . path . exists ( map_file_name ) : NEW_LINE INDENT nap_header = kip_reader . header ( map_file_name ) NEW_LINE return nap_header NEW_LINE DEDENT return None NEW_LINE # ▁ Copyright ▁ 2008-2012 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited ▁ ( ACN ▁ 127 ▁ 184 ▁ 954 ) ▁ ( Dr . ▁ D ▁ Studios ) ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ anim - studio - tools . ENDCOM # ▁ anim - studio - tools ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ anim - studio - tools ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ anim - studio - tools . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM DEDENT </DOCUMENT>
<DOCUMENT_ID="peonycredit/peonycredit/tree/master/qa/pull-tester/pull-tester.py"> # ! / usr / bin / python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2013 ▁ The ▁ Bitcoin ▁ Core ▁ developers ENDCOM # ▁ Distributed ▁ under ▁ the ▁ MIT / X11 ▁ software ▁ license , ▁ see ▁ the ▁ accompanying ENDCOM # ▁ file ▁ COPYING ▁ or ▁ http : / / www . opensource . org / licenses / mit - license . php . ENDCOM import json NEW_LINE from urllib import urlopen NEW_LINE import requests NEW_LINE import getpass NEW_LINE from string import Template NEW_LINE import sys NEW_LINE import os NEW_LINE import subprocess NEW_LINE class RunError ( Exception ) : NEW_LINE INDENT def __init__ ( self , value ) : NEW_LINE INDENT self . value = value NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return repr ( self . value ) NEW_LINE DEDENT DEDENT def run ( command , ** kwargs ) : NEW_LINE INDENT fail_hard = kwargs . pop ( " fail _ hard " , True ) NEW_LINE # ▁ output ▁ to ▁ / dev / null ▁ by ▁ default : ENDCOM kwargs . setdefault ( " stdout " , open ( ' / dev / null ' , ' w ' ) ) NEW_LINE kwargs . setdefault ( " stderr " , open ( ' / dev / null ' , ' w ' ) ) NEW_LINE command = Template ( command ) . substitute ( os . environ ) NEW_LINE if " TRACE " in os . environ : NEW_LINE INDENT if ' cwd ' in kwargs : NEW_LINE INDENT print ( " [ cwd = % s ] ▁ % s " % ( kwargs [ ' cwd ' ] , command ) ) NEW_LINE DEDENT else : print ( command ) NEW_LINE DEDENT try : NEW_LINE INDENT process = subprocess . Popen ( command . split ( ' ▁ ' ) , ** kwargs ) NEW_LINE process . wait ( ) NEW_LINE DEDENT except KeyboardInterrupt : NEW_LINE INDENT process . terminate ( ) NEW_LINE raise NEW_LINE DEDENT if process . returncode != 0 and fail_hard : NEW_LINE INDENT raise RunError ( " Failed : ▁ " + command ) NEW_LINE DEDENT return process . returncode NEW_LINE DEDENT def checkout_pull ( clone_url , commit , out ) : NEW_LINE # ▁ Init ENDCOM INDENT build_dir = os . environ [ " BUILD _ DIR " ] NEW_LINE run ( " umount ▁ $ { CHROOT _ COPY } / proc " , fail_hard = False ) NEW_LINE run ( " rsync ▁ - - delete ▁ - apv ▁ $ { CHROOT _ MASTER } / ▁ $ { CHROOT _ COPY } " ) NEW_LINE run ( " rm ▁ - rf ▁ $ { CHROOT _ COPY } $ { SCRIPTS _ DIR } " ) NEW_LINE run ( " cp ▁ - a ▁ $ { SCRIPTS _ DIR } ▁ $ { CHROOT _ COPY } $ { SCRIPTS _ DIR } " ) NEW_LINE # ▁ Merge ▁ onto ▁ upstream / master ENDCOM run ( " rm ▁ - rf ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " mkdir ▁ - p ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " git ▁ clone ▁ $ { CLONE _ URL } ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " git ▁ remote ▁ add ▁ pull ▁ " + clone_url , cwd = build_dir , stdout = out , stderr = out ) NEW_LINE run ( " git ▁ fetch ▁ pull " , cwd = build_dir , stdout = out , stderr = out ) NEW_LINE if run ( " git ▁ merge ▁ " + commit , fail_hard = False , cwd = build_dir , stdout = out , stderr = out ) != 0 : NEW_LINE INDENT return False NEW_LINE DEDENT run ( " chown ▁ - R ▁ $ { BUILD _ USER } : $ { BUILD _ GROUP } ▁ $ { BUILD _ DIR } " , stdout = out , stderr = out ) NEW_LINE run ( " mount ▁ - - bind ▁ / proc ▁ $ { CHROOT _ COPY } / proc " ) NEW_LINE return True NEW_LINE DEDENT def commentOn ( commentUrl , success , inMerge , needTests , linkUrl ) : NEW_LINE INDENT common_message = """ STRNEWLINE This ▁ test ▁ script ▁ verifies ▁ pulls ▁ every ▁ time ▁ they ▁ are ▁ updated . ▁ It , ▁ however , ▁ dies ▁ sometimes ▁ and ▁ fails ▁ to ▁ test ▁ properly . ▁ ▁ If ▁ you ▁ are ▁ waiting ▁ on ▁ a ▁ test , ▁ please ▁ check ▁ timestamps ▁ to ▁ verify ▁ that ▁ the ▁ test . log ▁ is ▁ moving ▁ at ▁ http : / / jenkins . bluematt . me / pull - tester / current / STRNEWLINE Contact ▁ BlueMatt ▁ on ▁ freenode ▁ if ▁ something ▁ looks ▁ broken . """ NEW_LINE # ▁ Remove ▁ old ▁ BitcoinPullTester ▁ comments ▁ ( I ' m ▁ being ▁ lazy ▁ and ▁ not ▁ paginating ▁ here ) ENDCOM recentcomments = requests . get ( commentUrl + " ? sort = created & direction = desc " , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE for comment in recentcomments : NEW_LINE INDENT if comment [ " user " ] [ " login " ] == os . environ [ " GITHUB _ USER " ] and common_message in comment [ " body " ] : NEW_LINE INDENT requests . delete ( comment [ " url " ] , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) NEW_LINE DEDENT DEDENT if success == True : NEW_LINE INDENT if needTests : NEW_LINE INDENT message = " Automatic ▁ sanity - testing : ▁ PLEASE ▁ ADD ▁ TEST - CASES , ▁ though ▁ technically ▁ passed . ▁ See ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " NEW_LINE DEDENT else : NEW_LINE INDENT message = " Automatic ▁ sanity - testing : ▁ PASSED , ▁ see ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " NEW_LINE DEDENT post_data = { " body " : message + common_message } NEW_LINE DEDENT elif inMerge : NEW_LINE INDENT post_data = { " body " : " Automatic ▁ sanity - testing : ▁ FAILED ▁ MERGE , ▁ see ▁ " + linkUrl + " ▁ for ▁ test ▁ log . " + """ STRNEWLINE STRNEWLINE This ▁ pull ▁ does ▁ not ▁ merge ▁ cleanly ▁ onto ▁ current ▁ master """ + common_message } NEW_LINE DEDENT else : NEW_LINE INDENT post_data = { " body " : " Automatic ▁ sanity - testing : ▁ FAILED ▁ BUILD / TEST , ▁ see ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " + """ STRNEWLINE STRNEWLINE This ▁ could ▁ happen ▁ for ▁ one ▁ of ▁ several ▁ reasons : STRNEWLINE 1 . ▁ It ▁ chanages ▁ changes ▁ build ▁ scripts ▁ in ▁ a ▁ way ▁ that ▁ made ▁ them ▁ incompatible ▁ with ▁ the ▁ automated ▁ testing ▁ scripts ▁ ( please ▁ tweak ▁ those ▁ patches ▁ in ▁ qa / pull - tester ) STRNEWLINE 2 . ▁ It ▁ adds / modifies ▁ tests ▁ which ▁ test ▁ network ▁ rules ▁ ( thanks ▁ for ▁ doing ▁ that ) , ▁ which ▁ conflicts ▁ with ▁ a ▁ patch ▁ applied ▁ at ▁ test ▁ time STRNEWLINE 3 . ▁ It ▁ does ▁ not ▁ build ▁ on ▁ either ▁ Linux ▁ i386 ▁ or ▁ Win32 ▁ ( via ▁ MinGW ▁ cross ▁ compile ) STRNEWLINE 4 . ▁ The ▁ test ▁ suite ▁ fails ▁ on ▁ either ▁ Linux ▁ i386 ▁ or ▁ Win32 STRNEWLINE 5 . ▁ The ▁ block ▁ test - cases ▁ failed ▁ ( lookup ▁ the ▁ first ▁ bNN ▁ identifier ▁ which ▁ failed ▁ in ▁ https : / / github . com / TheBlueMatt / test - scripts / blob / master / FullBlockTestGenerator . java ) STRNEWLINE STRNEWLINE If ▁ you ▁ believe ▁ this ▁ to ▁ be ▁ in ▁ error , ▁ please ▁ ping ▁ BlueMatt ▁ on ▁ freenode ▁ or ▁ TheBlueMatt ▁ here . STRNEWLINE """ + common_message } NEW_LINE DEDENT resp = requests . post ( commentUrl , json . dumps ( post_data ) , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) NEW_LINE DEDENT def testpull ( number , comment_url , clone_url , commit ) : NEW_LINE INDENT print ( " Testing ▁ pull ▁ % d : ▁ % s ▁ : ▁ % s " % ( number , clone_url , commit ) ) NEW_LINE dir = os . environ [ " RESULTS _ DIR " ] + " / " + commit + " / " NEW_LINE print ( " ▁ ouput ▁ to ▁ % s " % dir ) NEW_LINE if os . path . exists ( dir ) : NEW_LINE INDENT os . system ( " rm ▁ - r ▁ " + dir ) NEW_LINE DEDENT os . makedirs ( dir ) NEW_LINE currentdir = os . environ [ " RESULTS _ DIR " ] + " / current " NEW_LINE os . system ( " rm ▁ - r ▁ " + currentdir ) NEW_LINE os . system ( " ln ▁ - s ▁ " + dir + " ▁ " + currentdir ) NEW_LINE out = open ( dir + " test . log " , ' w + ' ) NEW_LINE resultsurl = os . environ [ " RESULTS _ URL " ] + commit NEW_LINE checkedout = checkout_pull ( clone_url , commit , out ) NEW_LINE if checkedout != True : NEW_LINE INDENT print ( " Failed ▁ to ▁ test ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , False , True , False , resultsurl ) NEW_LINE open ( os . environ [ " TESTED _ DB " ] , " a " ) . write ( commit + " \n " ) NEW_LINE return NEW_LINE DEDENT run ( " rm ▁ - rf ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) ; NEW_LINE run ( " mkdir ▁ - p ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) ; NEW_LINE run ( " chown ▁ - R ▁ $ { BUILD _ USER } : $ { BUILD _ GROUP } ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) NEW_LINE script = os . environ [ " BUILD _ PATH " ] + " / qa / pull - tester / pull - tester . sh " NEW_LINE script += " ▁ $ { BUILD _ PATH } ▁ $ { MINGW _ DEPS _ DIR } ▁ $ { SCRIPTS _ DIR } / BitcoindComparisonTool _ jar / BitcoindComparisonTool . jar ▁ 0 ▁ 6 ▁ $ { OUT _ DIR } " NEW_LINE returncode = run ( " chroot ▁ $ { CHROOT _ COPY } ▁ sudo ▁ - u ▁ $ { BUILD _ USER } ▁ - H ▁ timeout ▁ $ { TEST _ TIMEOUT } ▁ " + script , fail_hard = False , stdout = out , stderr = out ) NEW_LINE run ( " mv ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } ▁ " + dir ) NEW_LINE run ( " mv ▁ $ { BUILD _ DIR } ▁ " + dir ) NEW_LINE if returncode == 42 : NEW_LINE INDENT print ( " Successfully ▁ tested ▁ pull ▁ ( needs ▁ tests ) ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , True , False , True , resultsurl ) NEW_LINE DEDENT elif returncode != 0 : NEW_LINE INDENT print ( " Failed ▁ to ▁ test ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , False , False , False , resultsurl ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " Successfully ▁ tested ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , True , False , False , resultsurl ) NEW_LINE DEDENT open ( os . environ [ " TESTED _ DB " ] , " a " ) . write ( commit + " \n " ) NEW_LINE DEDENT def environ_default ( setting , value ) : NEW_LINE INDENT if not setting in os . environ : NEW_LINE INDENT os . environ [ setting ] = value NEW_LINE DEDENT DEDENT if getpass . getuser ( ) != " root " : NEW_LINE INDENT print ( " Run ▁ me ▁ as ▁ root ! " ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT if " GITHUB _ USER " not in os . environ or " GITHUB _ AUTH _ TOKEN " not in os . environ : NEW_LINE INDENT print ( " GITHUB _ USER ▁ and / or ▁ GITHUB _ AUTH _ TOKEN ▁ environment ▁ variables ▁ not ▁ set " ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT environ_default ( " CLONE _ URL " , " https : / / github . com / bitcoin / bitcoin . git " ) NEW_LINE environ_default ( " MINGW _ DEPS _ DIR " , " / mnt / w32deps " ) NEW_LINE environ_default ( " SCRIPTS _ DIR " , " / mnt / test - scripts " ) NEW_LINE environ_default ( " CHROOT _ COPY " , " / mnt / chroot - tmp " ) NEW_LINE environ_default ( " CHROOT _ MASTER " , " / mnt / chroot " ) NEW_LINE environ_default ( " OUT _ DIR " , " / mnt / out " ) NEW_LINE environ_default ( " BUILD _ PATH " , " / mnt / bitcoin " ) NEW_LINE os . environ [ " BUILD _ DIR " ] = os . environ [ " CHROOT _ COPY " ] + os . environ [ " BUILD _ PATH " ] NEW_LINE environ_default ( " RESULTS _ DIR " , " / mnt / www / pull - tester " ) NEW_LINE environ_default ( " RESULTS _ URL " , " http : / / jenkins . bluematt . me / pull - tester / " ) NEW_LINE environ_default ( " GITHUB _ REPO " , " bitcoin / bitcoin " ) NEW_LINE environ_default ( " TESTED _ DB " , " / mnt / commits - tested . txt " ) NEW_LINE environ_default ( " BUILD _ USER " , " matt " ) NEW_LINE environ_default ( " BUILD _ GROUP " , " matt " ) NEW_LINE environ_default ( " TEST _ TIMEOUT " , str ( 60 * 60 * 2 ) ) NEW_LINE print ( " Optional ▁ usage : ▁ pull - tester . py ▁ 2112" ) NEW_LINE f = open ( os . environ [ " TESTED _ DB " ] ) NEW_LINE tested = set ( line . rstrip ( ) for line in f . readlines ( ) ) NEW_LINE f . close ( ) NEW_LINE if len ( sys . argv ) > 1 : NEW_LINE INDENT pull = requests . get ( " https : / / api . github . com / repos / " + os . environ [ " GITHUB _ REPO " ] + " / pulls / " + sys . argv [ 1 ] , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE testpull ( pull [ " number " ] , pull [ " _ links " ] [ " comments " ] [ " href " ] , pull [ " head " ] [ " repo " ] [ " clone _ url " ] , pull [ " head " ] [ " sha " ] ) NEW_LINE DEDENT else : NEW_LINE INDENT for page in range ( 1 , 100 ) : NEW_LINE INDENT result = requests . get ( " https : / / api . github . com / repos / " + os . environ [ " GITHUB _ REPO " ] + " / pulls ? state = open & page = % d " % ( page , ) , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE if len ( result ) == 0 : break ; NEW_LINE for pull in result : NEW_LINE INDENT if pull [ " head " ] [ " sha " ] in tested : NEW_LINE INDENT print ( " Pull ▁ % d ▁ already ▁ tested " % ( pull [ " number " ] , ) ) NEW_LINE continue NEW_LINE DEDENT testpull ( pull [ " number " ] , pull [ " _ links " ] [ " comments " ] [ " href " ] , pull [ " head " ] [ " repo " ] [ " clone _ url " ] , pull [ " head " ] [ " sha " ] ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="odoousers2014/odoo/tree/master/addons/website_sale_delivery/models/sale_order.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM from openerp . osv import orm , fields NEW_LINE from openerp import SUPERUSER_ID NEW_LINE from openerp . addons import decimal_precision NEW_LINE class delivery_carrier ( orm . Model ) : NEW_LINE INDENT _name = ' delivery . carrier ' NEW_LINE _inherit = [ ' delivery . carrier ' , ' website . published . mixin ' ] NEW_LINE _columns = { ' website _ description ' : fields . text ( ' Description ▁ for ▁ the ▁ website ' ) , } NEW_LINE _defaults = { ' website _ published ' : True } NEW_LINE DEDENT class SaleOrder ( orm . Model ) : NEW_LINE INDENT _inherit = ' sale . order ' NEW_LINE def _amount_all_wrapper ( self , cr , uid , ids , field_name , arg , context = None ) : NEW_LINE INDENT """ ▁ Wrapper ▁ because ▁ of ▁ direct ▁ method ▁ passing ▁ as ▁ parameter ▁ for ▁ function ▁ fields ▁ """ NEW_LINE return self . _amount_all ( cr , uid , ids , field_name , arg , context = context ) NEW_LINE DEDENT def _amount_all ( self , cr , uid , ids , field_name , arg , context = None ) : NEW_LINE INDENT res = super ( SaleOrder , self ) . _amount_all ( cr , uid , ids , field_name , arg , context = context ) NEW_LINE currency_pool = self . pool . get ( ' res . currency ' ) NEW_LINE for order in self . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT line_amount = sum ( [ line . price_subtotal for line in order . order_line if line . is_delivery ] ) NEW_LINE currency = order . pricelist_id . currency_id NEW_LINE res [ order . id ] [ ' amount _ delivery ' ] = currency_pool . round ( cr , uid , currency , line_amount ) NEW_LINE DEDENT return res NEW_LINE DEDENT def _get_order ( self , cr , uid , ids , context = None ) : NEW_LINE INDENT result = { } NEW_LINE for line in self . pool . get ( ' sale . order . line ' ) . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT result [ line . order_id . id ] = True NEW_LINE DEDENT return result . keys ( ) NEW_LINE DEDENT _columns = { ' amount _ delivery ' : fields . function ( _amount_all_wrapper , type = ' float ' , digits_compute = decimal_precision . get_precision ( ' Account ' ) , string = ' Delivery ▁ Amount ' , store = { ' sale . order ' : ( lambda self , cr , uid , ids , c = { } : ids , [ ' order _ line ' ] , 10 ) , ' sale . order . line ' : ( _get_order , [ ' price _ unit ' , ' tax _ id ' , ' discount ' , ' product _ uom _ qty ' ] , 10 ) , } , multi = ' sums ' , help = " The ▁ amount ▁ without ▁ tax . " , track_visibility = ' always ' ) , ' website _ order _ line ' : fields . one2many ( ' sale . order . line ' , ' order _ id ' , string = ' Order ▁ Lines ▁ displayed ▁ on ▁ Website ' , readonly = True , domain = [ ( ' is _ delivery ' , ' = ' , False ) ] , help = ' Order ▁ Lines ▁ to ▁ be ▁ displayed ▁ on ▁ the ▁ website . ▁ They ▁ should ▁ not ▁ be ▁ used ▁ for ▁ computation ▁ purpose . ' , ) , } NEW_LINE def _check_carrier_quotation ( self , cr , uid , order , force_carrier_id = None , context = None ) : NEW_LINE INDENT carrier_obj = self . pool . get ( ' delivery . carrier ' ) NEW_LINE # ▁ check ▁ to ▁ add ▁ or ▁ remove ▁ carrier _ id ENDCOM if not order : NEW_LINE INDENT return False NEW_LINE DEDENT if all ( line . product_id . type == " service " for line in order . website_order_line ) : NEW_LINE INDENT order . write ( { ' carrier _ id ' : None } ) NEW_LINE self . pool [ ' sale . order ' ] . _delivery_unset ( cr , SUPERUSER_ID , [ order . id ] , context = context ) NEW_LINE return True NEW_LINE DEDENT else : NEW_LINE INDENT carrier_id = force_carrier_id or order . carrier_id . id NEW_LINE carrier_ids = self . _get_delivery_methods ( cr , uid , order , context = context ) NEW_LINE if carrier_id : NEW_LINE INDENT if carrier_id not in carrier_ids : NEW_LINE INDENT carrier_id = False NEW_LINE DEDENT else : NEW_LINE INDENT carrier_ids . remove ( carrier_id ) NEW_LINE carrier_ids . insert ( 0 , carrier_id ) NEW_LINE DEDENT DEDENT if force_carrier_id or not carrier_id or not carrier_id in carrier_ids : NEW_LINE INDENT for delivery_id in carrier_ids : NEW_LINE INDENT grid_id = carrier_obj . grid_get ( cr , SUPERUSER_ID , [ delivery_id ] , order . partner_shipping_id . id ) NEW_LINE if grid_id : NEW_LINE INDENT carrier_id = delivery_id NEW_LINE break NEW_LINE DEDENT DEDENT order . write ( { ' carrier _ id ' : carrier_id } ) NEW_LINE DEDENT if carrier_id : NEW_LINE INDENT order . delivery_set ( ) NEW_LINE DEDENT else : NEW_LINE INDENT order . _delivery_unset ( ) NEW_LINE DEDENT DEDENT return bool ( carrier_id ) NEW_LINE DEDENT def _get_delivery_methods ( self , cr , uid , order , context = None ) : NEW_LINE INDENT carrier_obj = self . pool . get ( ' delivery . carrier ' ) NEW_LINE delivery_ids = carrier_obj . search ( cr , uid , [ ( ' website _ published ' , ' = ' , True ) ] , context = context ) NEW_LINE # ▁ Following ▁ loop ▁ is ▁ done ▁ to ▁ avoid ▁ displaying ▁ delivery ▁ methods ▁ who ▁ are ▁ not ▁ available ▁ for ▁ this ▁ order ENDCOM # ▁ This ▁ can ▁ surely ▁ be ▁ done ▁ in ▁ a ▁ more ▁ efficient ▁ way , ▁ but ▁ at ▁ the ▁ moment , ▁ it ▁ mimics ▁ the ▁ way ▁ it ' s ENDCOM # ▁ done ▁ in ▁ delivery _ set ▁ method ▁ of ▁ sale . py , ▁ from ▁ delivery ▁ module ENDCOM for delivery_id in carrier_obj . browse ( cr , SUPERUSER_ID , delivery_ids , context = dict ( context , order_id = order . id ) ) : NEW_LINE INDENT if not delivery_id . available : NEW_LINE INDENT delivery_ids . remove ( delivery_id . id ) NEW_LINE DEDENT DEDENT return delivery_ids NEW_LINE DEDENT def _get_errors ( self , cr , uid , order , context = None ) : NEW_LINE INDENT errors = super ( SaleOrder , self ) . _get_errors ( cr , uid , order , context = context ) NEW_LINE if not self . _get_delivery_methods ( cr , uid , order , context = context ) : NEW_LINE INDENT errors . append ( ( ' No ▁ delivery ▁ method ▁ available ' , ' There ▁ is ▁ no ▁ available ▁ delivery ▁ method ▁ for ▁ your ▁ order ' ) ) NEW_LINE DEDENT return errors NEW_LINE DEDENT def _get_website_data ( self , cr , uid , order , context = None ) : NEW_LINE INDENT """ ▁ Override ▁ to ▁ add ▁ delivery - related ▁ website ▁ data . ▁ """ NEW_LINE values = super ( SaleOrder , self ) . _get_website_data ( cr , uid , order , context = context ) NEW_LINE # ▁ We ▁ need ▁ a ▁ delivery ▁ only ▁ if ▁ we ▁ have ▁ stockable ▁ products ENDCOM has_stockable_products = False NEW_LINE for line in order . order_line : NEW_LINE INDENT if line . product_id . type in ( ' consu ' , ' product ' ) : NEW_LINE INDENT has_stockable_products = True NEW_LINE DEDENT DEDENT if not has_stockable_products : NEW_LINE INDENT return values NEW_LINE DEDENT delivery_ctx = dict ( context , order_id = order . id ) NEW_LINE DeliveryCarrier = self . pool . get ( ' delivery . carrier ' ) NEW_LINE delivery_ids = self . _get_delivery_methods ( cr , uid , order , context = context ) NEW_LINE values [ ' deliveries ' ] = DeliveryCarrier . browse ( cr , SUPERUSER_ID , delivery_ids , context = delivery_ctx ) NEW_LINE return values NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="vqw/frappe/tree/master/frappe/model/delete_doc.py"> # ▁ Copyright ▁ ( c ) ▁ 2015 , ▁ Frappe ▁ Technologies ▁ Pvt . ▁ Ltd . ▁ and ▁ Contributors ENDCOM # ▁ MIT ▁ License . ▁ See ▁ license . txt ENDCOM from __future__ import unicode_literals NEW_LINE import frappe NEW_LINE import frappe . model . meta NEW_LINE from frappe . model . dynamic_links import get_dynamic_link_map NEW_LINE import frappe . defaults NEW_LINE from frappe . utils . file_manager import remove_all NEW_LINE from frappe . utils . password import delete_all_passwords_for NEW_LINE from frappe import _ NEW_LINE from frappe . model . naming import revert_series_if_last NEW_LINE def delete_doc ( doctype = None , name = None , force = 0 , ignore_doctypes = None , for_reload = False , ignore_permissions = False , flags = None , ignore_on_trash = False ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Deletes ▁ a ▁ doc ( dt , ▁ dn ) ▁ and ▁ validates ▁ if ▁ it ▁ is ▁ not ▁ submitted ▁ and ▁ not ▁ linked ▁ in ▁ a ▁ live ▁ record STRNEWLINE TABSYMBOL """ NEW_LINE if not ignore_doctypes : ignore_doctypes = [ ] NEW_LINE # ▁ get ▁ from ▁ form ENDCOM if not doctype : NEW_LINE INDENT doctype = frappe . form_dict . get ( ' dt ' ) NEW_LINE name = frappe . form_dict . get ( ' dn ' ) NEW_LINE DEDENT names = name NEW_LINE if isinstance ( name , basestring ) : NEW_LINE INDENT names = [ name ] NEW_LINE DEDENT for name in names or [ ] : NEW_LINE # ▁ already ▁ deleted . . ? ENDCOM INDENT if not frappe . db . exists ( doctype , name ) : NEW_LINE INDENT return NEW_LINE # ▁ delete ▁ attachments ENDCOM DEDENT remove_all ( doctype , name ) NEW_LINE # ▁ delete ▁ passwords ENDCOM delete_all_passwords_for ( doctype , name ) NEW_LINE doc = None NEW_LINE if doctype == " DocType " : NEW_LINE INDENT if for_reload : NEW_LINE INDENT try : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE DEDENT except frappe . DoesNotExistError : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT doc . run_method ( " before _ reload " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE update_flags ( doc , flags , ignore_permissions ) NEW_LINE check_permission_and_not_submitted ( doc ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabCustom ▁ Field ` ▁ where ▁ dt ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabCustom ▁ Script ` ▁ where ▁ dt ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabProperty ▁ Setter ` ▁ where ▁ doc _ type ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabReport ` ▁ where ▁ ref _ doctype = % s " , name ) NEW_LINE DEDENT delete_from_table ( doctype , name , ignore_doctypes , None ) NEW_LINE DEDENT else : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE if not for_reload : NEW_LINE INDENT update_flags ( doc , flags , ignore_permissions ) NEW_LINE check_permission_and_not_submitted ( doc ) NEW_LINE if not ignore_on_trash : NEW_LINE INDENT doc . run_method ( " on _ trash " ) NEW_LINE doc . run_method ( ' on _ change ' ) NEW_LINE DEDENT dynamic_linked_doctypes = [ df . parent for df in get_dynamic_link_map ( ) . get ( doc . doctype , [ ] ) ] NEW_LINE if " ToDo " in dynamic_linked_doctypes : NEW_LINE INDENT delete_linked_todos ( doc ) NEW_LINE DEDENT if " Communication " in dynamic_linked_doctypes : NEW_LINE INDENT delete_linked_communications ( doc ) NEW_LINE DEDENT if " DocShare " in dynamic_linked_doctypes : NEW_LINE INDENT delete_shared ( doc ) NEW_LINE DEDENT if " Email ▁ Unsubscribe " in dynamic_linked_doctypes : NEW_LINE INDENT delete_email_subscribe ( doc ) NEW_LINE # ▁ check ▁ if ▁ links ▁ exist ENDCOM DEDENT if not force : NEW_LINE INDENT check_if_doc_is_linked ( doc ) NEW_LINE check_if_doc_is_dynamically_linked ( doc ) NEW_LINE DEDENT DEDENT update_naming_series ( doc ) NEW_LINE delete_from_table ( doctype , name , ignore_doctypes , doc ) NEW_LINE doc . run_method ( " after _ delete " ) NEW_LINE DEDENT if doc and not frappe . flags . in_patch : NEW_LINE INDENT try : NEW_LINE INDENT doc . notify_update ( ) NEW_LINE insert_feed ( doc ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass NEW_LINE # ▁ delete ▁ user _ permissions ENDCOM DEDENT DEDENT frappe . defaults . clear_default ( parenttype = " User ▁ Permission " , key = doctype , value = name ) NEW_LINE DEDENT DEDENT def update_naming_series ( doc ) : NEW_LINE INDENT if doc . meta . autoname : NEW_LINE INDENT if doc . meta . autoname . startswith ( " naming _ series : " ) and getattr ( doc , " naming _ series " , None ) : NEW_LINE INDENT revert_series_if_last ( doc . naming_series , doc . name ) NEW_LINE DEDENT elif doc . meta . autoname . split ( " : " ) [ 0 ] not in ( " Prompt " , " field " , " hash " ) : NEW_LINE INDENT revert_series_if_last ( doc . meta . autoname , doc . name ) NEW_LINE DEDENT DEDENT DEDENT def delete_from_table ( doctype , name , ignore_doctypes , doc ) : NEW_LINE INDENT if doctype != " DocType " and doctype == name : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tabSingles ` ▁ where ▁ doctype = % s " , name ) NEW_LINE DEDENT else : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tab % s ` ▁ where ▁ name = % s " % ( frappe . db . escape ( doctype ) , " % s " ) , ( name , ) ) NEW_LINE # ▁ get ▁ child ▁ tables ENDCOM DEDENT if doc : NEW_LINE INDENT tables = [ d . options for d in doc . meta . get_table_fields ( ) ] NEW_LINE DEDENT else : NEW_LINE INDENT def get_table_fields ( field_doctype ) : NEW_LINE INDENT return frappe . db . sql_list ( """ select ▁ options ▁ from ▁ ` tab { } ` ▁ where ▁ fieldtype = ' Table ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL TABSYMBOL and ▁ parent = % s """ . format ( field_doctype ) , doctype ) NEW_LINE DEDENT tables = get_table_fields ( " DocField " ) NEW_LINE if not frappe . flags . in_install == " frappe " : NEW_LINE INDENT tables += get_table_fields ( " Custom ▁ Field " ) NEW_LINE # ▁ delete ▁ from ▁ child ▁ tables ENDCOM DEDENT DEDENT for t in list ( set ( tables ) ) : NEW_LINE INDENT if t not in ignore_doctypes : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tab % s ` ▁ where ▁ parenttype = % s ▁ and ▁ parent ▁ = ▁ % s " % ( t , ' % s ' , ' % s ' ) , ( doctype , name ) ) NEW_LINE DEDENT DEDENT DEDENT def update_flags ( doc , flags = None , ignore_permissions = False ) : NEW_LINE INDENT if ignore_permissions : NEW_LINE INDENT if not flags : flags = { } NEW_LINE flags [ " ignore _ permissions " ] = ignore_permissions NEW_LINE DEDENT if flags : NEW_LINE INDENT doc . flags . update ( flags ) NEW_LINE DEDENT DEDENT def check_permission_and_not_submitted ( doc ) : NEW_LINE # ▁ permission ENDCOM INDENT if not doc . flags . ignore_permissions and frappe . session . user != " Administrator " and ( not doc . has_permission ( " delete " ) or ( doc . doctype == " DocType " and not doc . custom ) ) : NEW_LINE INDENT frappe . msgprint ( _ ( " User ▁ not ▁ allowed ▁ to ▁ delete ▁ { 0 } : ▁ { 1 } " ) . format ( doc . doctype , doc . name ) , raise_exception = True ) NEW_LINE # ▁ check ▁ if ▁ submitted ENDCOM DEDENT if doc . docstatus == 1 : NEW_LINE INDENT frappe . msgprint ( _ ( " { 0 } ▁ { 1 } : ▁ Submitted ▁ Record ▁ cannot ▁ be ▁ deleted . " ) . format ( doc . doctype , doc . name ) , raise_exception = True ) NEW_LINE DEDENT DEDENT def check_if_doc_is_linked ( doc , method = " Delete " ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Raises ▁ excption ▁ if ▁ the ▁ given ▁ doc ( dt , ▁ dn ) ▁ is ▁ linked ▁ in ▁ another ▁ record . STRNEWLINE TABSYMBOL """ NEW_LINE from frappe . model . rename_doc import get_link_fields NEW_LINE link_fields = get_link_fields ( doc . doctype ) NEW_LINE link_fields = [ [ lf [ ' parent ' ] , lf [ ' fieldname ' ] , lf [ ' issingle ' ] ] for lf in link_fields ] NEW_LINE for link_dt , link_field , issingle in link_fields : NEW_LINE INDENT if not issingle : NEW_LINE INDENT item = frappe . db . get_value ( link_dt , { link_field : doc . name } , [ " name " , " parent " , " parenttype " , " docstatus " ] , as_dict = True ) NEW_LINE if item and ( ( item . parent or item . name ) != doc . name ) and ( ( method == " Delete " and item . docstatus < 2 ) or ( method == " Cancel " and item . docstatus == 1 ) ) : NEW_LINE # ▁ raise ▁ exception ▁ only ▁ if ENDCOM # ▁ linked ▁ to ▁ an ▁ non - cancelled ▁ doc ▁ when ▁ deleting ENDCOM # ▁ or ▁ linked ▁ to ▁ a ▁ submitted ▁ doc ▁ when ▁ cancelling ENDCOM INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , item . parenttype if item . parent else link_dt , item . parent or item . name ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def check_if_doc_is_dynamically_linked ( doc , method = " Delete " ) : NEW_LINE INDENT ''' Raise ▁ ` frappe . LinkExistsError ` ▁ if ▁ the ▁ document ▁ is ▁ dynamically ▁ linked ''' NEW_LINE for df in get_dynamic_link_map ( ) . get ( doc . doctype , [ ] ) : NEW_LINE INDENT if df . parent in ( " Communication " , " ToDo " , " DocShare " , " Email ▁ Unsubscribe " ) : NEW_LINE # ▁ don ' t ▁ check ▁ for ▁ communication ▁ and ▁ todo ! ENDCOM INDENT continue NEW_LINE DEDENT meta = frappe . get_meta ( df . parent ) NEW_LINE if meta . issingle : NEW_LINE # ▁ dynamic ▁ link ▁ in ▁ single ▁ doc ENDCOM INDENT refdoc = frappe . db . get_singles_dict ( df . parent ) NEW_LINE if ( refdoc . get ( df . options ) == doc . doctype and refdoc . get ( df . fieldname ) == doc . name and ( ( method == " Delete " and refdoc . docstatus < 2 ) or ( method == " Cancel " and refdoc . docstatus == 1 ) ) ) : NEW_LINE # ▁ raise ▁ exception ▁ only ▁ if ENDCOM # ▁ linked ▁ to ▁ an ▁ non - cancelled ▁ doc ▁ when ▁ deleting ENDCOM # ▁ or ▁ linked ▁ to ▁ a ▁ submitted ▁ doc ▁ when ▁ cancelling ENDCOM INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , df . parent , " " ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT else : NEW_LINE # ▁ dynamic ▁ link ▁ in ▁ table ENDCOM INDENT for refdoc in frappe . db . sql ( """ select ▁ name , ▁ docstatus ▁ from ▁ ` tab { parent } ` ▁ where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL TABSYMBOL { options } = % s ▁ and ▁ { fieldname } = % s """ . format ( ** df ) , ( doc . doctype , doc . name ) , as_dict = True ) : NEW_LINE INDENT if ( ( method == " Delete " and refdoc . docstatus < 2 ) or ( method == " Cancel " and refdoc . docstatus == 1 ) ) : NEW_LINE # ▁ raise ▁ exception ▁ only ▁ if ENDCOM # ▁ linked ▁ to ▁ an ▁ non - cancelled ▁ doc ▁ when ▁ deleting ENDCOM # ▁ or ▁ linked ▁ to ▁ a ▁ submitted ▁ doc ▁ when ▁ cancelling ENDCOM INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , df . parent , refdoc . name ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def delete_linked_todos ( doc ) : NEW_LINE INDENT delete_doc ( " ToDo " , frappe . db . sql_list ( """ select ▁ name ▁ from ▁ ` tabToDo ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ reference _ type = % s ▁ and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) , ignore_permissions = True ) NEW_LINE DEDENT def delete_email_subscribe ( doc ) : NEW_LINE INDENT frappe . db . sql ( ''' delete ▁ from ▁ ` tabEmail ▁ Unsubscribe ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ reference _ doctype = % s ▁ and ▁ reference _ name = % s ''' , ( doc . doctype , doc . name ) ) NEW_LINE DEDENT def delete_linked_communications ( doc ) : NEW_LINE # ▁ delete ▁ comments ENDCOM INDENT frappe . db . sql ( """ delete ▁ from ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL communication _ type ▁ = ▁ ' Comment ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ doctype = % s ▁ and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE # ▁ make ▁ communications ▁ orphans ENDCOM frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ reference _ doctype = null , ▁ reference _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL communication _ type ▁ = ▁ ' Communication ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ doctype = % s STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE # ▁ make ▁ secondary ▁ references ▁ orphans ENDCOM frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ link _ doctype = null , ▁ link _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where ▁ link _ doctype = % s ▁ and ▁ link _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ timeline _ doctype = null , ▁ timeline _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where ▁ timeline _ doctype = % s ▁ and ▁ timeline _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE DEDENT def insert_feed ( doc ) : NEW_LINE INDENT from frappe . utils import get_fullname NEW_LINE if frappe . flags . in_install or frappe . flags . in_import or getattr ( doc , " no _ feed _ on _ delete " , False ) : NEW_LINE INDENT return NEW_LINE DEDENT frappe . get_doc ( { " doctype " : " Communication " , " communication _ type " : " Comment " , " comment _ type " : " Deleted " , " reference _ doctype " : doc . doctype , " subject " : " { 0 } ▁ { 1 } " . format ( _ ( doc . doctype ) , doc . name ) , " full _ name " : get_fullname ( doc . owner ) } ) . insert ( ignore_permissions = True ) NEW_LINE DEDENT def delete_shared ( doc ) : NEW_LINE INDENT delete_doc ( " DocShare " , frappe . db . sql_list ( """ select ▁ name ▁ from ▁ ` tabDocShare ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ share _ doctype = % s ▁ and ▁ share _ name = % s """ , ( doc . doctype , doc . name ) ) , ignore_on_trash = True ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="mjtamlyn/django/tree/master/tests/mail/tests.py"> import asyncore NEW_LINE import base64 NEW_LINE import mimetypes NEW_LINE import os NEW_LINE import shutil NEW_LINE import smtpd NEW_LINE import socket NEW_LINE import sys NEW_LINE import tempfile NEW_LINE import threading NEW_LINE from email import message_from_binary_file , message_from_bytes NEW_LINE from email . header import Header NEW_LINE from email . mime . text import MIMEText NEW_LINE from email . utils import parseaddr NEW_LINE from io import StringIO NEW_LINE from smtplib import SMTP , SMTPAuthenticationError , SMTPException NEW_LINE from ssl import SSLError NEW_LINE from django . core import mail NEW_LINE from django . core . mail import ( EmailMessage , EmailMultiAlternatives , mail_admins , mail_managers , send_mail , send_mass_mail , ) NEW_LINE from django . core . mail . backends import console , dummy , filebased , locmem , smtp NEW_LINE from django . core . mail . message import BadHeaderError , sanitize_address NEW_LINE from django . test import SimpleTestCase , override_settings NEW_LINE from django . test . utils import requires_tz_support NEW_LINE from django . utils . encoding import force_bytes , force_text NEW_LINE from django . utils . translation import gettext_lazy NEW_LINE class HeadersCheckMixin : NEW_LINE INDENT def assertMessageHasHeaders ( self , message , headers ) : NEW_LINE INDENT """ STRNEWLINE ▁ Asserts ▁ that ▁ the ▁ ` message ` ▁ has ▁ all ▁ ` headers ` . STRNEWLINE STRNEWLINE ▁ message : ▁ can ▁ be ▁ an ▁ instance ▁ of ▁ an ▁ email . Message ▁ subclass ▁ or ▁ a ▁ string STRNEWLINE ▁ with ▁ the ▁ contents ▁ of ▁ an ▁ email ▁ message . STRNEWLINE ▁ headers : ▁ should ▁ be ▁ a ▁ set ▁ of ▁ ( header - name , ▁ header - value ) ▁ tuples . STRNEWLINE ▁ """ NEW_LINE if isinstance ( message , bytes ) : NEW_LINE INDENT message = message_from_bytes ( message ) NEW_LINE DEDENT msg_headers = set ( message . items ( ) ) NEW_LINE self . assertTrue ( headers . issubset ( msg_headers ) , msg = ' Message ▁ is ▁ missing ▁ ' ' the ▁ following ▁ headers : ▁ % s ' % ( headers - msg_headers ) , ) NEW_LINE DEDENT DEDENT class MailTests ( HeadersCheckMixin , SimpleTestCase ) : NEW_LINE INDENT """ STRNEWLINE ▁ Non - backend ▁ specific ▁ tests . STRNEWLINE ▁ """ NEW_LINE def get_decoded_attachments ( self , django_message ) : NEW_LINE INDENT """ STRNEWLINE ▁ Encode ▁ the ▁ specified ▁ django . core . mail . message . EmailMessage , ▁ then ▁ decode STRNEWLINE ▁ it ▁ using ▁ Python ' s ▁ email . parser ▁ module ▁ and , ▁ for ▁ each ▁ attachment ▁ of ▁ the STRNEWLINE ▁ message , ▁ return ▁ a ▁ list ▁ of ▁ tuples ▁ with ▁ ( filename , ▁ content , ▁ mimetype ) . STRNEWLINE ▁ """ NEW_LINE msg_bytes = django_message . message ( ) . as_bytes ( ) NEW_LINE email_message = message_from_bytes ( msg_bytes ) NEW_LINE def iter_attachments ( ) : NEW_LINE INDENT for i in email_message . walk ( ) : NEW_LINE # ▁ Once ▁ support ▁ for ▁ Python < 3.5 ▁ has ▁ been ▁ dropped , ▁ we ▁ can ▁ use ENDCOM # ▁ i . get _ content _ disposition ( ) ▁ here ▁ instead . ENDCOM INDENT content_disposition = i . get ( ' content - disposition ' , ' ' ) . split ( ' ; ' ) [ 0 ] . lower ( ) NEW_LINE if content_disposition == ' attachment ' : NEW_LINE INDENT filename = i . get_filename ( ) NEW_LINE content = i . get_payload ( decode = True ) NEW_LINE mimetype = i . get_content_type ( ) NEW_LINE yield filename , content , mimetype NEW_LINE DEDENT DEDENT DEDENT return list ( iter_attachments ( ) ) NEW_LINE DEDENT def test_ascii ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' to @ example . com ' ) NEW_LINE DEDENT def test_multiple_recipients ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' other @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' to @ example . com , ▁ other @ example . com ' ) NEW_LINE DEDENT def test_recipients_with_empty_strings ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Empty ▁ strings ▁ in ▁ various ▁ recipient ▁ arguments ▁ are ▁ always ▁ stripped STRNEWLINE ▁ off ▁ the ▁ final ▁ recipient ▁ list . STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' ' ] , cc = [ ' cc @ example . com ' , ' ' ] , bcc = [ ' ' , ' bcc @ example . com ' ] , reply_to = [ ' ' , None ] , ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' cc @ example . com ' , ' bcc @ example . com ' ] ) NEW_LINE DEDENT def test_cc ( self ) : NEW_LINE INDENT """ Regression ▁ test ▁ for ▁ # 7722 """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , cc = [ ' cc @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' cc @ example . com ' ] ) NEW_LINE # ▁ Test ▁ multiple ▁ CC ▁ with ▁ multiple ▁ To ENDCOM email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' other @ example . com ' ] , cc = [ ' cc @ example . com ' , ' cc . other @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com , ▁ cc . other @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' other @ example . com ' , ' cc @ example . com ' , ' cc . other @ example . com ' ] ) NEW_LINE # ▁ Testing ▁ with ▁ Bcc ENDCOM email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' other @ example . com ' ] , cc = [ ' cc @ example . com ' , ' cc . other @ example . com ' ] , bcc = [ ' bcc @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com , ▁ cc . other @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' other @ example . com ' , ' cc @ example . com ' , ' cc . other @ example . com ' , ' bcc @ example . com ' ] ) NEW_LINE DEDENT def test_reply_to ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , reply_to = [ ' reply _ to @ example . com ' ] , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Reply - To ' ] , ' reply _ to @ example . com ' ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , reply_to = [ ' reply _ to1 @ example . com ' , ' reply _ to2 @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Reply - To ' ] , ' reply _ to1 @ example . com , ▁ reply _ to2 @ example . com ' ) NEW_LINE DEDENT def test_recipients_as_tuple ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , ( ' to @ example . com ' , ' other @ example . com ' ) , cc = ( ' cc @ example . com ' , ' cc . other @ example . com ' ) , bcc = ( ' bcc @ example . com ' , ) ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com , ▁ cc . other @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' other @ example . com ' , ' cc @ example . com ' , ' cc . other @ example . com ' , ' bcc @ example . com ' ] ) NEW_LINE DEDENT def test_recipients_as_string ( self ) : NEW_LINE INDENT with self . assertRaisesMessage ( TypeError , ' " to " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( to = ' foo @ example . com ' ) NEW_LINE DEDENT with self . assertRaisesMessage ( TypeError , ' " cc " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( cc = ' foo @ example . com ' ) NEW_LINE DEDENT with self . assertRaisesMessage ( TypeError , ' " bcc " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( bcc = ' foo @ example . com ' ) NEW_LINE DEDENT with self . assertRaisesMessage ( TypeError , ' " reply _ to " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( reply_to = ' reply _ to @ example . com ' ) NEW_LINE DEDENT DEDENT def test_header_injection ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject \n Injection ▁ Test ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE with self . assertRaises ( BadHeaderError ) : NEW_LINE INDENT email . message ( ) NEW_LINE DEDENT email = EmailMessage ( gettext_lazy ( ' Subject \n Injection ▁ Test ' ) , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE with self . assertRaises ( BadHeaderError ) : NEW_LINE INDENT email . message ( ) NEW_LINE DEDENT DEDENT def test_space_continuation ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Test ▁ for ▁ space ▁ continuation ▁ character ▁ in ▁ long ▁ ( ASCII ) ▁ subject ▁ headers ▁ ( # 7747 ) STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Long ▁ subject ▁ lines ▁ that ▁ get ▁ wrapped ▁ should ▁ contain ▁ a ▁ space ▁ ' ' continuation ▁ character ▁ to ▁ get ▁ expected ▁ behavior ▁ in ▁ Outlook ▁ and ▁ Thunderbird ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] . encode ( ) , b ' Long ▁ subject ▁ lines ▁ that ▁ get ▁ wrapped ▁ should ▁ contain ▁ a ▁ space ▁ continuation \n ' b ' ▁ character ▁ to ▁ get ▁ expected ▁ behavior ▁ in ▁ Outlook ▁ and ▁ Thunderbird ' ) NEW_LINE DEDENT def test_message_header_overrides ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Specifying ▁ dates ▁ or ▁ message - ids ▁ in ▁ the ▁ extra ▁ headers ▁ overrides ▁ the STRNEWLINE ▁ default ▁ values ▁ ( # 9233 ) STRNEWLINE ▁ """ NEW_LINE headers = { " date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE email = EmailMessage ( ' subject ' , ' content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , headers = headers ) NEW_LINE self . assertMessageHasHeaders ( email . message ( ) , { ( ' Content - Transfer - Encoding ' , '7bit ' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' MIME - Version ' , '1.0' ) , ( ' Message - ID ' , ' foo ' ) , ( ' Subject ' , ' subject ' ) , ( ' To ' , ' to @ example . com ' ) , ( ' date ' , ' Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000' ) , } ) NEW_LINE DEDENT def test_from_header ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Make ▁ sure ▁ we ▁ can ▁ manually ▁ set ▁ the ▁ From ▁ header ▁ ( # 9214 ) STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE DEDENT def test_to_header ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Make ▁ sure ▁ we ▁ can ▁ manually ▁ set ▁ the ▁ To ▁ header ▁ ( # 17444 ) STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] , headers = { ' To ' : ' mailing - list @ example . com ' } ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' mailing - list @ example . com ' ) NEW_LINE self . assertEqual ( email . to , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] ) NEW_LINE # ▁ If ▁ we ▁ don ' t ▁ set ▁ the ▁ To ▁ header ▁ manually , ▁ it ▁ should ▁ default ▁ to ▁ the ▁ ` to ` ▁ argument ▁ to ▁ the ▁ constructor ENDCOM email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' list - subscriber @ example . com , ▁ list - subscriber2 @ example . com ' ) NEW_LINE self . assertEqual ( email . to , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] ) NEW_LINE DEDENT def test_reply_to_header ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Specifying ▁ ' Reply - To ' ▁ in ▁ headers ▁ should ▁ override ▁ reply _ to . STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , reply_to = [ ' foo @ example . com ' ] , headers = { ' Reply - To ' : ' override @ example . com ' } , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Reply - To ' ] , ' override @ example . com ' ) NEW_LINE DEDENT def test_multiple_message_call ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Regression ▁ for ▁ # 13259 ▁ - ▁ Make ▁ sure ▁ that ▁ headers ▁ are ▁ not ▁ changed ▁ when STRNEWLINE ▁ calling ▁ EmailMessage . message ( ) STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE DEDENT def test_unicode_address_header ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Regression ▁ for ▁ # 11144 ▁ - ▁ When ▁ a ▁ to / from / cc ▁ header ▁ contains ▁ unicode , STRNEWLINE ▁ make ▁ sure ▁ the ▁ email ▁ addresses ▁ are ▁ parsed ▁ correctly ▁ ( especially ▁ with STRNEWLINE ▁ regards ▁ to ▁ commas ) STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' " Firstname ▁ Sürname " ▁ < to @ example . com > ' , ' other @ example . com ' ] , ) NEW_LINE self . assertEqual ( email . message ( ) [ ' To ' ] , ' = ? utf - 8 ? q ? Firstname _ S = C3 = BCrname ? = ▁ < to @ example . com > , ▁ other @ example . com ' ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' " Sürname , ▁ Firstname " ▁ < to @ example . com > ' , ' other @ example . com ' ] , ) NEW_LINE self . assertEqual ( email . message ( ) [ ' To ' ] , ' = ? utf - 8 ? q ? S = C3 = BCrname = 2C _ Firstname ? = ▁ < to @ example . com > , ▁ other @ example . com ' ) NEW_LINE DEDENT def test_unicode_headers ( self ) : NEW_LINE INDENT email = EmailMessage ( " Gżegżółka " , " Content " , " from @ example . com " , [ " to @ example . com " ] , headers = { " Sender " : ' " Firstname ▁ Sürname " ▁ < sender @ example . com > ' , " Comments " : ' My ▁ Sürname ▁ is ▁ non - ASCII ' } ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] , ' = ? utf - 8 ? b ? R8W8ZWfFvMOzxYJrYQ = = ? = ' ) NEW_LINE self . assertEqual ( message [ ' Sender ' ] , ' = ? utf - 8 ? q ? Firstname _ S = C3 = BCrname ? = ▁ < sender @ example . com > ' ) NEW_LINE self . assertEqual ( message [ ' Comments ' ] , ' = ? utf - 8 ? q ? My _ S = C3 = BCrname _ is _ non - ASCII ? = ' ) NEW_LINE DEDENT def test_safe_mime_multipart ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Make ▁ sure ▁ headers ▁ can ▁ be ▁ set ▁ with ▁ a ▁ different ▁ encoding ▁ than ▁ utf - 8 ▁ in STRNEWLINE ▁ SafeMIMEMultipart ▁ as ▁ well STRNEWLINE ▁ """ NEW_LINE headers = { " Date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE from_email , to = ' from @ example . com ' , ' " Sürname , ▁ Firstname " ▁ < to @ example . com > ' NEW_LINE text_content = ' This ▁ is ▁ an ▁ important ▁ message . ' NEW_LINE html_content = ' < p > This ▁ is ▁ an ▁ < strong > important < / strong > ▁ message . < / p > ' NEW_LINE msg = EmailMultiAlternatives ( ' Message ▁ from ▁ Firstname ▁ Sürname ' , text_content , from_email , [ to ] , headers = headers ) NEW_LINE msg . attach_alternative ( html_content , " text / html " ) NEW_LINE msg . encoding = ' iso - 8859-1' NEW_LINE self . assertEqual ( msg . message ( ) [ ' To ' ] , ' = ? iso - 8859-1 ? q ? S = FCrname = 2C _ Firstname ? = ▁ < to @ example . com > ' ) NEW_LINE self . assertEqual ( msg . message ( ) [ ' Subject ' ] , ' = ? iso - 8859-1 ? q ? Message _ from _ Firstname _ S = FCrname ? = ' ) NEW_LINE DEDENT def test_encoding ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Regression ▁ for ▁ # 12791 ▁ - ▁ Encode ▁ body ▁ correctly ▁ with ▁ other ▁ encodings STRNEWLINE ▁ than ▁ utf - 8 STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Firstname ▁ Sürname ▁ is ▁ a ▁ great ▁ guy . ' , ' from @ example . com ' , [ ' other @ example . com ' ] ) NEW_LINE email . encoding = ' iso - 8859-1' NEW_LINE message = email . message ( ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " iso - 8859-1 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) , ( ' Subject ' , ' Subject ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' To ' , ' other @ example . com ' ) } ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Firstname ▁ S = FCrname ▁ is ▁ a ▁ great ▁ guy . ' ) NEW_LINE # ▁ Make ▁ sure ▁ MIME ▁ attachments ▁ also ▁ works ▁ correctly ▁ with ▁ other ▁ encodings ▁ than ▁ utf - 8 ENDCOM text_content = ' Firstname ▁ Sürname ▁ is ▁ a ▁ great ▁ guy . ' NEW_LINE html_content = ' < p > Firstname ▁ Sürname ▁ is ▁ a ▁ < strong > great < / strong > ▁ guy . < / p > ' NEW_LINE msg = EmailMultiAlternatives ( ' Subject ' , text_content , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . encoding = ' iso - 8859-1' NEW_LINE msg . attach_alternative ( html_content , " text / html " ) NEW_LINE payload0 = msg . message ( ) . get_payload ( 0 ) NEW_LINE self . assertMessageHasHeaders ( payload0 , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " iso - 8859-1 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) } ) NEW_LINE self . assertTrue ( payload0 . as_bytes ( ) . endswith ( b ' \n \n Firstname ▁ S = FCrname ▁ is ▁ a ▁ great ▁ guy . ' ) ) NEW_LINE payload1 = msg . message ( ) . get_payload ( 1 ) NEW_LINE self . assertMessageHasHeaders ( payload1 , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / html ; ▁ charset = " iso - 8859-1 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) } ) NEW_LINE self . assertTrue ( payload1 . as_bytes ( ) . endswith ( b ' \n \n < p > Firstname ▁ S = FCrname ▁ is ▁ a ▁ < strong > great < / strong > ▁ guy . < / p > ' ) ) NEW_LINE DEDENT def test_attachments ( self ) : NEW_LINE INDENT """ Regression ▁ test ▁ for ▁ # 9367 """ NEW_LINE headers = { " Date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE subject , from_email , to = ' hello ' , ' from @ example . com ' , ' to @ example . com ' NEW_LINE text_content = ' This ▁ is ▁ an ▁ important ▁ message . ' NEW_LINE html_content = ' < p > This ▁ is ▁ an ▁ < strong > important < / strong > ▁ message . < / p > ' NEW_LINE msg = EmailMultiAlternatives ( subject , text_content , from_email , [ to ] , headers = headers ) NEW_LINE msg . attach_alternative ( html_content , " text / html " ) NEW_LINE msg . attach ( " an ▁ attachment . pdf " , b " % PDF - 1.4 . % . . . " , mimetype = " application / pdf " ) NEW_LINE msg_bytes = msg . message ( ) . as_bytes ( ) NEW_LINE message = message_from_bytes ( msg_bytes ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( message . get_content_type ( ) , ' multipart / mixed ' ) NEW_LINE self . assertEqual ( message . get_default_type ( ) , ' text / plain ' ) NEW_LINE payload = message . get_payload ( ) NEW_LINE self . assertEqual ( payload [ 0 ] . get_content_type ( ) , ' multipart / alternative ' ) NEW_LINE self . assertEqual ( payload [ 1 ] . get_content_type ( ) , ' application / pdf ' ) NEW_LINE DEDENT def test_non_ascii_attachment_filename ( self ) : NEW_LINE INDENT """ Regression ▁ test ▁ for ▁ # 14964 """ NEW_LINE headers = { " Date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE subject , from_email , to = ' hello ' , ' from @ example . com ' , ' to @ example . com ' NEW_LINE content = ' This ▁ is ▁ the ▁ message . ' NEW_LINE msg = EmailMessage ( subject , content , from_email , [ to ] , headers = headers ) NEW_LINE # ▁ Unicode ▁ in ▁ file ▁ name ENDCOM msg . attach ( " une ▁ pièce ▁ jointe . pdf " , b " % PDF - 1.4 . % . . . " , mimetype = " application / pdf " ) NEW_LINE msg_bytes = msg . message ( ) . as_bytes ( ) NEW_LINE message = message_from_bytes ( msg_bytes ) NEW_LINE payload = message . get_payload ( ) NEW_LINE self . assertEqual ( payload [ 1 ] . get_filename ( ) , ' une ▁ pièce ▁ jointe . pdf ' ) NEW_LINE DEDENT def test_attach_file ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Test ▁ attaching ▁ a ▁ file ▁ against ▁ different ▁ mimetypes ▁ and ▁ make ▁ sure ▁ that STRNEWLINE ▁ a ▁ file ▁ will ▁ be ▁ attached ▁ and ▁ sent ▁ properly ▁ even ▁ if ▁ an ▁ invalid ▁ mimetype STRNEWLINE ▁ is ▁ specified . STRNEWLINE ▁ """ NEW_LINE files = ( # ▁ filename , ▁ actual ▁ mimetype ENDCOM ( ' file . txt ' , ' text / plain ' ) , ( ' file . png ' , ' image / png ' ) , ( ' file _ txt ' , None ) , ( ' file _ png ' , None ) , ( ' file _ txt . png ' , ' image / png ' ) , ( ' file _ png . txt ' , ' text / plain ' ) , ( ' file . eml ' , ' message / rfc822' ) , ) NEW_LINE test_mimetypes = [ ' text / plain ' , ' image / png ' , None ] NEW_LINE for basename , real_mimetype in files : NEW_LINE INDENT for mimetype in test_mimetypes : NEW_LINE INDENT email = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertEqual ( mimetypes . guess_type ( basename ) [ 0 ] , real_mimetype ) NEW_LINE self . assertEqual ( email . attachments , [ ] ) NEW_LINE file_path = os . path . join ( os . path . dirname ( __file__ ) , ' attachments ' , basename ) NEW_LINE email . attach_file ( file_path , mimetype = mimetype ) NEW_LINE self . assertEqual ( len ( email . attachments ) , 1 ) NEW_LINE self . assertIn ( basename , email . attachments [ 0 ] ) NEW_LINE msgs_sent_num = email . send ( ) NEW_LINE self . assertEqual ( msgs_sent_num , 1 ) NEW_LINE DEDENT DEDENT DEDENT def test_attach_text_as_bytes ( self ) : NEW_LINE INDENT msg = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . attach ( ' file . txt ' , b ' file ▁ content ' ) NEW_LINE sent_num = msg . send ( ) NEW_LINE self . assertEqual ( sent_num , 1 ) NEW_LINE filename , content , mimetype = self . get_decoded_attachments ( msg ) [ 0 ] NEW_LINE self . assertEqual ( filename , ' file . txt ' ) NEW_LINE self . assertEqual ( content , b ' file ▁ content ' ) NEW_LINE self . assertEqual ( mimetype , ' text / plain ' ) NEW_LINE DEDENT def test_attach_utf8_text_as_bytes ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Non - ASCII ▁ characters ▁ encoded ▁ as ▁ valid ▁ UTF - 8 ▁ are ▁ correctly ▁ transported STRNEWLINE ▁ and ▁ decoded . STRNEWLINE ▁ """ NEW_LINE msg = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . attach ( ' file . txt ' , b ' \xc3\xa4' ) # ▁ UTF - 8 ▁ encoded ▁ a ▁ umlaut . ENDCOM NEW_LINE filename , content , mimetype = self . get_decoded_attachments ( msg ) [ 0 ] NEW_LINE self . assertEqual ( filename , ' file . txt ' ) NEW_LINE self . assertEqual ( content , b ' \xc3\xa4' ) NEW_LINE self . assertEqual ( mimetype , ' text / plain ' ) NEW_LINE DEDENT def test_attach_non_utf8_text_as_bytes ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Binary ▁ data ▁ that ▁ can ' t ▁ be ▁ decoded ▁ as ▁ UTF - 8 ▁ overrides ▁ the ▁ MIME ▁ type STRNEWLINE ▁ instead ▁ of ▁ decoding ▁ the ▁ data . STRNEWLINE ▁ """ NEW_LINE msg = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . attach ( ' file . txt ' , b ' \xff ' ) # ▁ Invalid ▁ UTF - 8 . ENDCOM NEW_LINE filename , content , mimetype = self . get_decoded_attachments ( msg ) [ 0 ] NEW_LINE self . assertEqual ( filename , ' file . txt ' ) NEW_LINE # ▁ Content ▁ should ▁ be ▁ passed ▁ through ▁ unmodified . ENDCOM self . assertEqual ( content , b ' \xff ' ) NEW_LINE self . assertEqual ( mimetype , ' application / octet - stream ' ) NEW_LINE DEDENT def test_dummy_backend ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Make ▁ sure ▁ that ▁ dummy ▁ backends ▁ returns ▁ correct ▁ number ▁ of ▁ sent ▁ messages STRNEWLINE ▁ """ NEW_LINE connection = dummy . EmailBackend ( ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE self . assertEqual ( connection . send_messages ( [ email , email , email ] ) , 3 ) NEW_LINE DEDENT def test_arbitrary_keyword ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Make ▁ sure ▁ that ▁ get _ connection ( ) ▁ accepts ▁ arbitrary ▁ keyword ▁ that ▁ might ▁ be STRNEWLINE ▁ used ▁ with ▁ custom ▁ backends . STRNEWLINE ▁ """ NEW_LINE c = mail . get_connection ( fail_silently = True , foo = ' bar ' ) NEW_LINE self . assertTrue ( c . fail_silently ) NEW_LINE DEDENT def test_custom_backend ( self ) : NEW_LINE INDENT """ Test ▁ custom ▁ backend ▁ defined ▁ in ▁ this ▁ suite . """ NEW_LINE conn = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE self . assertTrue ( hasattr ( conn , ' test _ outbox ' ) ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE conn . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( len ( conn . test_outbox ) , 1 ) NEW_LINE DEDENT def test_backend_arg ( self ) : NEW_LINE INDENT """ Test ▁ backend ▁ argument ▁ of ▁ mail . get _ connection ( ) """ NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . smtp . EmailBackend ' ) , smtp . EmailBackend ) NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . locmem . EmailBackend ' ) , locmem . EmailBackend ) NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . dummy . EmailBackend ' ) , dummy . EmailBackend ) NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . console . EmailBackend ' ) , console . EmailBackend ) NEW_LINE with tempfile . TemporaryDirectory ( ) as tmp_dir : NEW_LINE INDENT self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . filebased . EmailBackend ' , file_path = tmp_dir ) , filebased . EmailBackend ) NEW_LINE DEDENT self . assertIsInstance ( mail . get_connection ( ) , locmem . EmailBackend ) NEW_LINE DEDENT @ override_settings ( EMAIL_BACKEND = ' django . core . mail . backends . locmem . EmailBackend ' , ADMINS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] , MANAGERS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] ) NEW_LINE def test_connection_arg ( self ) : NEW_LINE INDENT """ Test ▁ connection ▁ argument ▁ to ▁ send _ mail ( ) , ▁ et . ▁ al . """ NEW_LINE mail . outbox = [ ] NEW_LINE # ▁ Send ▁ using ▁ non - default ▁ connection ENDCOM connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE send_mail ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 1 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' Subject ' ) NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE send_mass_mail ( [ ( ' Subject1' , ' Content1' , ' from1 @ example . com ' , [ ' to1 @ example . com ' ] ) , ( ' Subject2' , ' Content2' , ' from2 @ example . com ' , [ ' to2 @ example . com ' ] ) , ] , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 2 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' Subject1' ) NEW_LINE self . assertEqual ( connection . test_outbox [ 1 ] . subject , ' Subject2' ) NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE mail_admins ( ' Admin ▁ message ' , ' Content ' , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 1 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' [ Django ] ▁ Admin ▁ message ' ) NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE mail_managers ( ' Manager ▁ message ' , ' Content ' , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 1 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' [ Django ] ▁ Manager ▁ message ' ) NEW_LINE DEDENT def test_dont_mangle_from_in_body ( self ) : NEW_LINE # ▁ Regression ▁ for ▁ # 13433 ▁ - ▁ Make ▁ sure ▁ that ▁ EmailMessage ▁ doesn ' t ▁ mangle ENDCOM # ▁ ' From ▁ ' ▁ in ▁ message ▁ body . ENDCOM INDENT email = EmailMessage ( ' Subject ' , ' From ▁ the ▁ future ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE self . assertNotIn ( b ' > From ▁ the ▁ future ' , email . message ( ) . as_bytes ( ) ) NEW_LINE DEDENT def test_dont_base64_encode ( self ) : NEW_LINE # ▁ Ticket ▁ # 3472 ENDCOM # ▁ Shouldn ' t ▁ use ▁ Base64 ▁ encoding ▁ at ▁ all ENDCOM INDENT msg = EmailMessage ( ' Subject ' , ' UTF - 8 ▁ encoded ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE self . assertIn ( b ' Content - Transfer - Encoding : ▁ 7bit ' , msg . message ( ) . as_bytes ( ) ) NEW_LINE # ▁ Ticket ▁ # 11212 ENDCOM # ▁ Shouldn ' t ▁ use ▁ quoted ▁ printable , ▁ should ▁ detect ▁ it ▁ can ▁ represent ▁ content ▁ with ▁ 7 ▁ bit ▁ data ENDCOM msg = EmailMessage ( ' Subject ' , ' Body ▁ with ▁ only ▁ ASCII ▁ characters . ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE s = msg . message ( ) . as_bytes ( ) NEW_LINE self . assertIn ( b ' Content - Transfer - Encoding : ▁ 7bit ' , s ) NEW_LINE # ▁ Shouldn ' t ▁ use ▁ quoted ▁ printable , ▁ should ▁ detect ▁ it ▁ can ▁ represent ▁ content ▁ with ▁ 8 ▁ bit ▁ data ENDCOM msg = EmailMessage ( ' Subject ' , ' Body ▁ with ▁ latin ▁ characters : ▁ àáä . ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE s = msg . message ( ) . as_bytes ( ) NEW_LINE self . assertIn ( b ' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE s = msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE msg = EmailMessage ( ' Subject ' , ' Body ▁ with ▁ non ▁ latin ▁ characters : ▁ А ▁ Б ▁ В ▁ Г ▁ Д ▁ Е ▁ Ж ▁ Ѕ ▁ З ▁ И ▁ І ▁ К ▁ Л ▁ М ▁ Н ▁ О ▁ П . ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE s = msg . message ( ) . as_bytes ( ) NEW_LINE self . assertIn ( b ' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE s = msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE DEDENT def test_dont_base64_encode_message_rfc822 ( self ) : NEW_LINE # ▁ Ticket ▁ # 18967 ENDCOM # ▁ Shouldn ' t ▁ use ▁ base64 ▁ encoding ▁ for ▁ a ▁ child ▁ EmailMessage ▁ attachment . ENDCOM # ▁ Create ▁ a ▁ child ▁ message ▁ first ENDCOM INDENT child_msg = EmailMessage ( ' Child ▁ Subject ' , ' Some ▁ body ▁ of ▁ child ▁ message ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE child_s = child_msg . message ( ) . as_string ( ) NEW_LINE # ▁ Now ▁ create ▁ a ▁ parent ENDCOM parent_msg = EmailMessage ( ' Parent ▁ Subject ' , ' Some ▁ parent ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE # ▁ Attach ▁ to ▁ parent ▁ as ▁ a ▁ string ENDCOM parent_msg . attach ( content = child_s , mimetype = ' message / rfc822' ) NEW_LINE parent_s = parent_msg . message ( ) . as_string ( ) NEW_LINE # ▁ The ▁ child ▁ message ▁ header ▁ is ▁ not ▁ base64 ▁ encoded ENDCOM self . assertIn ( ' Child ▁ Subject ' , parent_s ) NEW_LINE # ▁ Feature ▁ test : ▁ try ▁ attaching ▁ email . Message ▁ object ▁ directly ▁ to ▁ the ▁ mail . ENDCOM parent_msg = EmailMessage ( ' Parent ▁ Subject ' , ' Some ▁ parent ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE parent_msg . attach ( content = child_msg . message ( ) , mimetype = ' message / rfc822' ) NEW_LINE parent_s = parent_msg . message ( ) . as_string ( ) NEW_LINE # ▁ The ▁ child ▁ message ▁ header ▁ is ▁ not ▁ base64 ▁ encoded ENDCOM self . assertIn ( ' Child ▁ Subject ' , parent_s ) NEW_LINE # ▁ Feature ▁ test : ▁ try ▁ attaching ▁ Django ' s ▁ EmailMessage ▁ object ▁ directly ▁ to ▁ the ▁ mail . ENDCOM parent_msg = EmailMessage ( ' Parent ▁ Subject ' , ' Some ▁ parent ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE parent_msg . attach ( content = child_msg , mimetype = ' message / rfc822' ) NEW_LINE parent_s = parent_msg . message ( ) . as_string ( ) NEW_LINE # ▁ The ▁ child ▁ message ▁ header ▁ is ▁ not ▁ base64 ▁ encoded ENDCOM self . assertIn ( ' Child ▁ Subject ' , parent_s ) NEW_LINE DEDENT def test_sanitize_address ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Email ▁ addresses ▁ are ▁ properly ▁ sanitized . STRNEWLINE ▁ """ NEW_LINE # ▁ Simple ▁ ASCII ▁ address ▁ - ▁ string ▁ form ENDCOM self . assertEqual ( sanitize_address ( ' to @ example . com ' , ' ascii ' ) , ' to @ example . com ' ) NEW_LINE self . assertEqual ( sanitize_address ( ' to @ example . com ' , ' utf - 8' ) , ' to @ example . com ' ) NEW_LINE # ▁ Simple ▁ ASCII ▁ address ▁ - ▁ tuple ▁ form ENDCOM self . assertEqual ( sanitize_address ( ( ' A ▁ name ' , ' to @ example . com ' ) , ' ascii ' ) , ' A ▁ name ▁ < to @ example . com > ' ) NEW_LINE self . assertEqual ( sanitize_address ( ( ' A ▁ name ' , ' to @ example . com ' ) , ' utf - 8' ) , ' = ? utf - 8 ? q ? A _ name ? = ▁ < to @ example . com > ' ) NEW_LINE # ▁ Unicode ▁ characters ▁ are ▁ are ▁ supported ▁ in ▁ RFC - 6532 . ENDCOM self . assertEqual ( sanitize_address ( ' tó @ example . com ' , ' utf - 8' ) , ' = ? utf - 8 ? b ? dMOz ? = @ example . com ' ) NEW_LINE self . assertEqual ( sanitize_address ( ( ' Tó ▁ Example ' , ' tó @ example . com ' ) , ' utf - 8' ) , ' = ? utf - 8 ? q ? T = C3 = B3 _ Example ? = ▁ < = ? utf - 8 ? b ? dMOz ? = @ example . com > ' ) NEW_LINE DEDENT DEDENT @ requires_tz_support NEW_LINE class MailTimeZoneTests ( SimpleTestCase ) : NEW_LINE INDENT @ override_settings ( EMAIL_USE_LOCALTIME = False , USE_TZ = True , TIME_ZONE = ' Africa / Algiers ' ) NEW_LINE def test_date_header_utc ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ EMAIL _ USE _ LOCALTIME = False ▁ creates ▁ a ▁ datetime ▁ in ▁ UTC . STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertTrue ( email . message ( ) [ ' Date ' ] . endswith ( ' - 0000' ) ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_LOCALTIME = True , USE_TZ = True , TIME_ZONE = ' Africa / Algiers ' ) NEW_LINE def test_date_header_localtime ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ EMAIL _ USE _ LOCALTIME = True ▁ creates ▁ a ▁ datetime ▁ in ▁ the ▁ local ▁ time ▁ zone . STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertTrue ( email . message ( ) [ ' Date ' ] . endswith ( ' + 0100' ) ) # ▁ Africa / Algiers ▁ is ▁ UTC + 1 ENDCOM NEW_LINE DEDENT DEDENT class PythonGlobalState ( SimpleTestCase ) : NEW_LINE INDENT """ STRNEWLINE ▁ Tests ▁ for ▁ # 12422 ▁ - - ▁ Django ▁ smarts ▁ ( # 2472 / # 11212 ) ▁ with ▁ charset ▁ of ▁ utf - 8 ▁ text STRNEWLINE ▁ parts ▁ shouldn ' t ▁ pollute ▁ global ▁ email ▁ Python ▁ package ▁ charset ▁ registry ▁ when STRNEWLINE ▁ django . mail . message ▁ is ▁ imported . STRNEWLINE ▁ """ NEW_LINE def test_utf8 ( self ) : NEW_LINE INDENT txt = MIMEText ( ' UTF - 8 ▁ encoded ▁ body ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT def test_7bit ( self ) : NEW_LINE INDENT txt = MIMEText ( ' Body ▁ with ▁ only ▁ ASCII ▁ characters . ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT def test_8bit_latin ( self ) : NEW_LINE INDENT txt = MIMEText ( ' Body ▁ with ▁ latin ▁ characters : ▁ àáä . ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT def test_8bit_non_latin ( self ) : NEW_LINE INDENT txt = MIMEText ( ' Body ▁ with ▁ non ▁ latin ▁ characters : ▁ А ▁ Б ▁ В ▁ Г ▁ Д ▁ Е ▁ Ж ▁ Ѕ ▁ З ▁ И ▁ І ▁ К ▁ Л ▁ М ▁ Н ▁ О ▁ П . ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT DEDENT class BaseEmailBackendTests ( HeadersCheckMixin ) : NEW_LINE INDENT email_backend = None NEW_LINE def setUp ( self ) : NEW_LINE INDENT self . settings_override = override_settings ( EMAIL_BACKEND = self . email_backend ) NEW_LINE self . settings_override . enable ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT self . settings_override . disable ( ) NEW_LINE DEDENT def assertStartsWith ( self , first , second ) : NEW_LINE INDENT if not first . startswith ( second ) : NEW_LINE INDENT self . longMessage = True NEW_LINE self . assertEqual ( first [ : len ( second ) ] , second , " First ▁ string ▁ doesn ' t ▁ start ▁ with ▁ the ▁ second . " ) NEW_LINE DEDENT DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BaseEmailBackendTests ▁ must ▁ provide ▁ a ▁ get _ mailbox _ content ( ) ▁ method ' ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BaseEmailBackendTests ▁ may ▁ require ▁ a ▁ flush _ mailbox ( ) ▁ method ' ) NEW_LINE DEDENT def get_the_message ( self ) : NEW_LINE INDENT mailbox = self . get_mailbox_content ( ) NEW_LINE self . assertEqual ( len ( mailbox ) , 1 , " Expected ▁ exactly ▁ one ▁ message , ▁ got ▁ % d . \n % r " % ( len ( mailbox ) , [ m . as_string ( ) for m in mailbox ] ) ) NEW_LINE return mailbox [ 0 ] NEW_LINE DEDENT def test_send ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE num_sent = mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( num_sent , 1 ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message [ " subject " ] , " Subject " ) NEW_LINE self . assertEqual ( message . get_payload ( ) , " Content " ) NEW_LINE self . assertEqual ( message [ " from " ] , " from @ example . com " ) NEW_LINE self . assertEqual ( message . get_all ( " to " ) , [ " to @ example . com " ] ) NEW_LINE DEDENT def test_send_unicode ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Chère ▁ maman ' , ' Je ▁ t\ ' aime ▁ très ▁ fort ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE num_sent = mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( num_sent , 1 ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message [ " subject " ] , ' = ? utf - 8 ? q ? Ch = C3 = A8re _ maman ? = ' ) NEW_LINE self . assertEqual ( force_text ( message . get_payload ( decode = True ) ) , ' Je ▁ t\ ' aime ▁ très ▁ fort ' ) NEW_LINE DEDENT def test_send_long_lines ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Email ▁ line ▁ length ▁ is ▁ limited ▁ to ▁ 998 ▁ chars ▁ by ▁ the ▁ RFC : STRNEWLINE ▁ https : / / tools . ietf . org / html / rfc5322 # section - 2.1.1 STRNEWLINE ▁ Message ▁ body ▁ containing ▁ longer ▁ lines ▁ are ▁ converted ▁ to ▁ Quoted - Printable STRNEWLINE ▁ to ▁ avoid ▁ having ▁ to ▁ insert ▁ newlines , ▁ which ▁ could ▁ be ▁ hairy ▁ to ▁ do ▁ properly . STRNEWLINE ▁ """ NEW_LINE # ▁ Unencoded ▁ body ▁ length ▁ is ▁ < ▁ 998 ▁ ( 840 ) ▁ but ▁ > ▁ 998 ▁ when ▁ utf - 8 ▁ encoded . ENDCOM email = EmailMessage ( ' Subject ' , ' В ▁ южных ▁ морях ▁ ' * 60 , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE email . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) , } ) NEW_LINE DEDENT def test_send_many ( self ) : NEW_LINE INDENT email1 = EmailMessage ( ' Subject ' , ' Content1' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE email2 = EmailMessage ( ' Subject ' , ' Content2' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE # ▁ send _ messages ( ) ▁ may ▁ take ▁ a ▁ list ▁ or ▁ a ▁ generator . ENDCOM emails_lists = ( [ email1 , email2 ] , ( email for email in [ email1 , email2 ] ) ) NEW_LINE for emails_list in emails_lists : NEW_LINE INDENT num_sent = mail . get_connection ( ) . send_messages ( emails_list ) NEW_LINE self . assertEqual ( num_sent , 2 ) NEW_LINE messages = self . get_mailbox_content ( ) NEW_LINE self . assertEqual ( len ( messages ) , 2 ) NEW_LINE self . assertEqual ( messages [ 0 ] . get_payload ( ) , ' Content1' ) NEW_LINE self . assertEqual ( messages [ 1 ] . get_payload ( ) , ' Content2' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE DEDENT DEDENT def test_send_verbose_name ( self ) : NEW_LINE INDENT email = EmailMessage ( " Subject " , " Content " , ' " Firstname ▁ Sürname " ▁ < from @ example . com > ' , [ " to @ example . com " ] ) NEW_LINE email . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message [ " subject " ] , " Subject " ) NEW_LINE self . assertEqual ( message . get_payload ( ) , " Content " ) NEW_LINE self . assertEqual ( message [ " from " ] , " = ? utf - 8 ? q ? Firstname _ S = C3 = BCrname ? = ▁ < from @ example . com > " ) NEW_LINE DEDENT def test_plaintext_send_mail ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Test ▁ send _ mail ▁ without ▁ the ▁ html _ message STRNEWLINE ▁ regression ▁ test ▁ for ▁ adding ▁ html _ message ▁ parameter ▁ to ▁ send _ mail ( ) STRNEWLINE ▁ """ NEW_LINE send_mail ( ' Subject ' , ' Content ' , ' sender @ example . com ' , [ ' nobody @ example . com ' ] ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertFalse ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_content_type ( ) , ' text / plain ' ) NEW_LINE DEDENT def test_html_send_mail ( self ) : NEW_LINE INDENT """ Test ▁ html _ message ▁ argument ▁ to ▁ send _ mail """ NEW_LINE send_mail ( ' Subject ' , ' Content ' , ' sender @ example . com ' , [ ' nobody @ example . com ' ] , html_message = ' HTML ▁ Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( len ( message . get_payload ( ) ) , 2 ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_payload ( ) , ' HTML ▁ Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_content_type ( ) , ' text / html ' ) NEW_LINE DEDENT @ override_settings ( MANAGERS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] ) NEW_LINE def test_html_mail_managers ( self ) : NEW_LINE INDENT """ Test ▁ html _ message ▁ argument ▁ to ▁ mail _ managers """ NEW_LINE mail_managers ( ' Subject ' , ' Content ' , html_message = ' HTML ▁ Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( len ( message . get_payload ( ) ) , 2 ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_payload ( ) , ' HTML ▁ Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_content_type ( ) , ' text / html ' ) NEW_LINE DEDENT @ override_settings ( ADMINS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] ) NEW_LINE def test_html_mail_admins ( self ) : NEW_LINE INDENT """ Test ▁ html _ message ▁ argument ▁ to ▁ mail _ admins ▁ """ NEW_LINE mail_admins ( ' Subject ' , ' Content ' , html_message = ' HTML ▁ Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( len ( message . get_payload ( ) ) , 2 ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_payload ( ) , ' HTML ▁ Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_content_type ( ) , ' text / html ' ) NEW_LINE DEDENT @ override_settings ( ADMINS = [ ( ' nobody ' , ' nobody + admin @ example . com ' ) ] , MANAGERS = [ ( ' nobody ' , ' nobody + manager @ example . com ' ) ] ) NEW_LINE def test_manager_and_admin_mail_prefix ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ String ▁ prefix ▁ + ▁ lazy ▁ translated ▁ subject ▁ = ▁ bad ▁ output STRNEWLINE ▁ Regression ▁ for ▁ # 13494 STRNEWLINE ▁ """ NEW_LINE mail_managers ( gettext_lazy ( ' Subject ' ) , ' Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE mail_admins ( gettext_lazy ( ' Subject ' ) , ' Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE DEDENT @ override_settings ( ADMINS = [ ] , MANAGERS = [ ] ) NEW_LINE def test_empty_admins ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ mail _ admins / mail _ managers ▁ doesn ' t ▁ connect ▁ to ▁ the ▁ mail ▁ server STRNEWLINE ▁ if ▁ there ▁ are ▁ no ▁ recipients ▁ ( # 9383 ) STRNEWLINE ▁ """ NEW_LINE mail_admins ( ' hi ' , ' there ' ) NEW_LINE self . assertEqual ( self . get_mailbox_content ( ) , [ ] ) NEW_LINE mail_managers ( ' hi ' , ' there ' ) NEW_LINE self . assertEqual ( self . get_mailbox_content ( ) , [ ] ) NEW_LINE DEDENT def test_message_cc_header ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Regression ▁ test ▁ for ▁ # 7722 STRNEWLINE ▁ """ NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , cc = [ ' cc @ example . com ' ] ) NEW_LINE mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' Content - Transfer - Encoding ' , '7bit ' ) , ( ' Subject ' , ' Subject ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' To ' , ' to @ example . com ' ) , ( ' Cc ' , ' cc @ example . com ' ) } ) NEW_LINE self . assertIn ( ' \n Date : ▁ ' , message . as_string ( ) ) NEW_LINE DEDENT def test_idn_send ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Regression ▁ test ▁ for ▁ # 14301 STRNEWLINE ▁ """ NEW_LINE self . assertTrue ( send_mail ( ' Subject ' , ' Content ' , ' from @ öäü . com ' , [ ' to @ öäü . com ' ] ) ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' from @ xn - -4ca9at . com ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to @ xn - -4ca9at . com ' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE m = EmailMessage ( ' Subject ' , ' Content ' , ' from @ öäü . com ' , [ ' to @ öäü . com ' ] , cc = [ ' cc @ öäü . com ' ] ) NEW_LINE m . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' from @ xn - -4ca9at . com ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to @ xn - -4ca9at . com ' ) NEW_LINE self . assertEqual ( message . get ( ' cc ' ) , ' cc @ xn - -4ca9at . com ' ) NEW_LINE DEDENT def test_recipient_without_domain ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Regression ▁ test ▁ for ▁ # 15042 STRNEWLINE ▁ """ NEW_LINE self . assertTrue ( send_mail ( " Subject " , " Content " , " tester " , [ " django " ] ) ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , " tester " ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , " django " ) NEW_LINE DEDENT def test_lazy_addresses ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Email ▁ sending ▁ should ▁ support ▁ lazy ▁ email ▁ addresses ▁ ( # 24416 ) . STRNEWLINE ▁ """ NEW_LINE _ = gettext_lazy NEW_LINE self . assertTrue ( send_mail ( ' Subject ' , ' Content ' , _ ( ' tester ' ) , [ _ ( ' django ' ) ] ) ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' tester ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' django ' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE m = EmailMessage ( ' Subject ' , ' Content ' , _ ( ' tester ' ) , [ _ ( ' to1' ) , _ ( ' to2' ) ] , cc = [ _ ( ' cc1' ) , _ ( ' cc2' ) ] , bcc = [ _ ( ' bcc ' ) ] , reply_to = [ _ ( ' reply ' ) ] , ) NEW_LINE self . assertEqual ( m . recipients ( ) , [ ' to1' , ' to2' , ' cc1' , ' cc2' , ' bcc ' ] ) NEW_LINE m . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' tester ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to1 , ▁ to2' ) NEW_LINE self . assertEqual ( message . get ( ' cc ' ) , ' cc1 , ▁ cc2' ) NEW_LINE self . assertEqual ( message . get ( ' Reply - To ' ) , ' reply ' ) NEW_LINE DEDENT def test_close_connection ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Connection ▁ can ▁ be ▁ closed ▁ ( even ▁ when ▁ not ▁ explicitly ▁ opened ) STRNEWLINE ▁ """ NEW_LINE conn = mail . get_connection ( username = ' ' , password = ' ' ) NEW_LINE conn . close ( ) NEW_LINE DEDENT def test_use_as_contextmanager ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ connection ▁ can ▁ be ▁ used ▁ as ▁ a ▁ contextmanager . STRNEWLINE ▁ """ NEW_LINE opened = [ False ] NEW_LINE closed = [ False ] NEW_LINE conn = mail . get_connection ( username = ' ' , password = ' ' ) NEW_LINE def open ( ) : NEW_LINE INDENT opened [ 0 ] = True NEW_LINE DEDENT conn . open = open NEW_LINE def close ( ) : NEW_LINE INDENT closed [ 0 ] = True NEW_LINE DEDENT conn . close = close NEW_LINE with conn as same_conn : NEW_LINE INDENT self . assertTrue ( opened [ 0 ] ) NEW_LINE self . assertIs ( same_conn , conn ) NEW_LINE self . assertFalse ( closed [ 0 ] ) NEW_LINE DEDENT self . assertTrue ( closed [ 0 ] ) NEW_LINE DEDENT DEDENT class LocmemBackendTests ( BaseEmailBackendTests , SimpleTestCase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . locmem . EmailBackend ' NEW_LINE def get_mailbox_content ( self ) : NEW_LINE INDENT return [ m . message ( ) for m in mail . outbox ] NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT mail . outbox = [ ] NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT super ( ) . tearDown ( ) NEW_LINE mail . outbox = [ ] NEW_LINE DEDENT def test_locmem_shared_messages ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Make ▁ sure ▁ that ▁ the ▁ locmen ▁ backend ▁ populates ▁ the ▁ outbox . STRNEWLINE ▁ """ NEW_LINE connection = locmem . EmailBackend ( ) NEW_LINE connection2 = locmem . EmailBackend ( ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE connection . send_messages ( [ email ] ) NEW_LINE connection2 . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( len ( mail . outbox ) , 2 ) NEW_LINE DEDENT def test_validate_multiline_headers ( self ) : NEW_LINE # ▁ Ticket ▁ # 18861 ▁ - ▁ Validate ▁ emails ▁ when ▁ using ▁ the ▁ locmem ▁ backend ENDCOM INDENT with self . assertRaises ( BadHeaderError ) : NEW_LINE INDENT send_mail ( ' Subject \n Multiline ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE DEDENT DEDENT DEDENT class FileBackendTests ( BaseEmailBackendTests , SimpleTestCase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . filebased . EmailBackend ' NEW_LINE def setUp ( self ) : NEW_LINE INDENT super ( ) . setUp ( ) NEW_LINE self . tmp_dir = tempfile . mkdtemp ( ) NEW_LINE self . addCleanup ( shutil . rmtree , self . tmp_dir ) NEW_LINE self . _settings_override = override_settings ( EMAIL_FILE_PATH = self . tmp_dir ) NEW_LINE self . _settings_override . enable ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT self . _settings_override . disable ( ) NEW_LINE super ( ) . tearDown ( ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT for filename in os . listdir ( self . tmp_dir ) : NEW_LINE INDENT os . unlink ( os . path . join ( self . tmp_dir , filename ) ) NEW_LINE DEDENT DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT messages = [ ] NEW_LINE for filename in os . listdir ( self . tmp_dir ) : NEW_LINE INDENT with open ( os . path . join ( self . tmp_dir , filename ) , ' rb ' ) as fp : NEW_LINE INDENT session = fp . read ( ) . split ( force_bytes ( ' \n ' + ( ' - ' * 79 ) + ' \n ' , encoding = ' ascii ' ) ) NEW_LINE DEDENT messages . extend ( message_from_bytes ( m ) for m in session if m ) NEW_LINE DEDENT return messages NEW_LINE DEDENT def test_file_sessions ( self ) : NEW_LINE INDENT """ Make ▁ sure ▁ opening ▁ a ▁ connection ▁ creates ▁ a ▁ new ▁ file """ NEW_LINE msg = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE connection = mail . get_connection ( ) NEW_LINE connection . send_messages ( [ msg ] ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 1 ) NEW_LINE with open ( os . path . join ( self . tmp_dir , os . listdir ( self . tmp_dir ) [ 0 ] ) , ' rb ' ) as fp : NEW_LINE INDENT message = message_from_binary_file ( fp ) NEW_LINE DEDENT self . assertEqual ( message . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' from @ example . com ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to @ example . com ' ) NEW_LINE connection2 = mail . get_connection ( ) NEW_LINE connection2 . send_messages ( [ msg ] ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 2 ) NEW_LINE connection . send_messages ( [ msg ] ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 2 ) NEW_LINE msg . connection = mail . get_connection ( ) NEW_LINE self . assertTrue ( connection . open ( ) ) NEW_LINE msg . send ( ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 3 ) NEW_LINE msg . send ( ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 3 ) NEW_LINE connection . close ( ) NEW_LINE DEDENT DEDENT class ConsoleBackendTests ( BaseEmailBackendTests , SimpleTestCase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . console . EmailBackend ' NEW_LINE def setUp ( self ) : NEW_LINE INDENT super ( ) . setUp ( ) NEW_LINE self . __stdout = sys . stdout NEW_LINE self . stream = sys . stdout = StringIO ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT del self . stream NEW_LINE sys . stdout = self . __stdout NEW_LINE del self . __stdout NEW_LINE super ( ) . tearDown ( ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT self . stream = sys . stdout = StringIO ( ) NEW_LINE DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT messages = self . stream . getvalue ( ) . split ( ' \n ' + ( ' - ' * 79 ) + ' \n ' ) NEW_LINE return [ message_from_bytes ( force_bytes ( m ) ) for m in messages if m ] NEW_LINE DEDENT def test_console_stream_kwarg ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ console ▁ backend ▁ can ▁ be ▁ pointed ▁ at ▁ an ▁ arbitrary ▁ stream . STRNEWLINE ▁ """ NEW_LINE s = StringIO ( ) NEW_LINE connection = mail . get_connection ( ' django . core . mail . backends . console . EmailBackend ' , stream = s ) NEW_LINE send_mail ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , connection = connection ) NEW_LINE message = force_bytes ( s . getvalue ( ) . split ( ' \n ' + ( ' - ' * 79 ) + ' \n ' ) [ 0 ] ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' Content - Transfer - Encoding ' , '7bit ' ) , ( ' Subject ' , ' Subject ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' To ' , ' to @ example . com ' ) } ) NEW_LINE self . assertIn ( b ' \n Date : ▁ ' , message ) NEW_LINE DEDENT DEDENT class FakeSMTPChannel ( smtpd . SMTPChannel ) : NEW_LINE INDENT def collect_incoming_data ( self , data ) : NEW_LINE INDENT try : NEW_LINE INDENT smtpd . SMTPChannel . collect_incoming_data ( self , data ) NEW_LINE DEDENT except UnicodeDecodeError : NEW_LINE # ▁ ignore ▁ decode ▁ error ▁ in ▁ SSL / TLS ▁ connection ▁ tests ▁ as ▁ we ▁ only ▁ care ENDCOM # ▁ whether ▁ the ▁ connection ▁ attempt ▁ was ▁ made ENDCOM INDENT pass NEW_LINE DEDENT DEDENT def smtp_AUTH ( self , arg ) : NEW_LINE INDENT if arg == ' CRAM - MD5' : NEW_LINE # ▁ This ▁ is ▁ only ▁ the ▁ first ▁ part ▁ of ▁ the ▁ login ▁ process . ▁ But ▁ it ' s ▁ enough ENDCOM # ▁ for ▁ our ▁ tests . ENDCOM INDENT challenge = base64 . b64encode ( b ' somerandomstring13579' ) NEW_LINE self . push ( '334 ▁ % s ' % challenge . decode ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . push ( '502 ▁ Error : ▁ login ▁ " % s " ▁ not ▁ implemented ' % arg ) NEW_LINE DEDENT DEDENT DEDENT class FakeSMTPServer ( smtpd . SMTPServer , threading . Thread ) : NEW_LINE INDENT """ STRNEWLINE ▁ Asyncore ▁ SMTP ▁ server ▁ wrapped ▁ into ▁ a ▁ thread . ▁ Based ▁ on ▁ DummyFTPServer ▁ from : STRNEWLINE ▁ http : / / svn . python . org / view / python / branches / py3k / Lib / test / test _ ftplib . py ? revision = 86061 & view = markup STRNEWLINE ▁ """ NEW_LINE channel_class = FakeSMTPChannel NEW_LINE def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT threading . Thread . __init__ ( self ) NEW_LINE # ▁ New ▁ kwarg ▁ added ▁ in ▁ Python ▁ 3.5 ; ▁ default ▁ switching ▁ to ▁ False ▁ in ▁ 3.6 . ENDCOM if sys . version_info >= ( 3 , 5 ) : NEW_LINE INDENT kwargs [ ' decode _ data ' ] = True NEW_LINE DEDENT smtpd . SMTPServer . __init__ ( self , * args , ** kwargs ) NEW_LINE self . _sink = [ ] NEW_LINE self . active = False NEW_LINE self . active_lock = threading . Lock ( ) NEW_LINE self . sink_lock = threading . Lock ( ) NEW_LINE DEDENT def process_message ( self , peer , mailfrom , rcpttos , data ) : NEW_LINE INDENT data = data . encode ( ) NEW_LINE m = message_from_bytes ( data ) NEW_LINE maddr = parseaddr ( m . get ( ' from ' ) ) [ 1 ] NEW_LINE if mailfrom != maddr : NEW_LINE # ▁ According ▁ to ▁ the ▁ spec , ▁ mailfrom ▁ does ▁ not ▁ necessarily ▁ match ▁ the ENDCOM # ▁ From ▁ header ▁ - ▁ this ▁ is ▁ the ▁ case ▁ where ▁ the ▁ local ▁ part ▁ isn ' t ENDCOM # ▁ encoded , ▁ so ▁ try ▁ to ▁ correct ▁ that . ENDCOM INDENT lp , domain = mailfrom . split ( ' @ ' , 1 ) NEW_LINE lp = Header ( lp , ' utf - 8' ) . encode ( ) NEW_LINE mailfrom = ' @ ' . join ( [ lp , domain ] ) NEW_LINE DEDENT if mailfrom != maddr : NEW_LINE INDENT return "553 ▁ ' % s ' ▁ ! = ▁ ' % s ' " % ( mailfrom , maddr ) NEW_LINE DEDENT with self . sink_lock : NEW_LINE INDENT self . _sink . append ( m ) NEW_LINE DEDENT DEDENT def get_sink ( self ) : NEW_LINE INDENT with self . sink_lock : NEW_LINE INDENT return self . _sink [ : ] NEW_LINE DEDENT DEDENT def flush_sink ( self ) : NEW_LINE INDENT with self . sink_lock : NEW_LINE INDENT self . _sink [ : ] = [ ] NEW_LINE DEDENT DEDENT def start ( self ) : NEW_LINE INDENT assert not self . active NEW_LINE self . __flag = threading . Event ( ) NEW_LINE threading . Thread . start ( self ) NEW_LINE self . __flag . wait ( ) NEW_LINE DEDENT def run ( self ) : NEW_LINE INDENT self . active = True NEW_LINE self . __flag . set ( ) NEW_LINE while self . active and asyncore . socket_map : NEW_LINE INDENT with self . active_lock : NEW_LINE INDENT asyncore . loop ( timeout = 0.1 , count = 1 ) NEW_LINE DEDENT DEDENT asyncore . close_all ( ) NEW_LINE DEDENT def stop ( self ) : NEW_LINE INDENT if self . active : NEW_LINE INDENT self . active = False NEW_LINE self . join ( ) NEW_LINE DEDENT DEDENT DEDENT class FakeAUTHSMTPConnection ( SMTP ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ SMTP ▁ connection ▁ pretending ▁ support ▁ for ▁ the ▁ AUTH ▁ command . ▁ It ▁ does ▁ not , ▁ but STRNEWLINE ▁ at ▁ least ▁ this ▁ can ▁ allow ▁ testing ▁ the ▁ first ▁ part ▁ of ▁ the ▁ AUTH ▁ process . STRNEWLINE ▁ """ NEW_LINE def ehlo ( self , name = ' ' ) : NEW_LINE INDENT response = SMTP . ehlo ( self , name = name ) NEW_LINE self . esmtp_features . update ( { ' auth ' : ' CRAM - MD5 ▁ PLAIN ▁ LOGIN ' , } ) NEW_LINE return response NEW_LINE DEDENT DEDENT class SMTPBackendTestsBase ( SimpleTestCase ) : NEW_LINE INDENT @ classmethod NEW_LINE def setUpClass ( cls ) : NEW_LINE INDENT super ( ) . setUpClass ( ) NEW_LINE cls . server = FakeSMTPServer ( ( '127.0.0.1' , 0 ) , None ) NEW_LINE cls . _settings_override = override_settings ( EMAIL_HOST = "127.0.0.1" , EMAIL_PORT = cls . server . socket . getsockname ( ) [ 1 ] ) NEW_LINE cls . _settings_override . enable ( ) NEW_LINE cls . server . start ( ) NEW_LINE DEDENT @ classmethod NEW_LINE def tearDownClass ( cls ) : NEW_LINE INDENT cls . _settings_override . disable ( ) NEW_LINE cls . server . stop ( ) NEW_LINE super ( ) . tearDownClass ( ) NEW_LINE DEDENT DEDENT class SMTPBackendTests ( BaseEmailBackendTests , SMTPBackendTestsBase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . smtp . EmailBackend ' NEW_LINE def setUp ( self ) : NEW_LINE INDENT super ( ) . setUp ( ) NEW_LINE self . server . flush_sink ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT self . server . flush_sink ( ) NEW_LINE super ( ) . tearDown ( ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT self . server . flush_sink ( ) NEW_LINE DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT return self . server . get_sink ( ) NEW_LINE DEDENT @ override_settings ( EMAIL_HOST_USER = " not ▁ empty ▁ username " , EMAIL_HOST_PASSWORD = " not ▁ empty ▁ password " ) NEW_LINE def test_email_authentication_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . username , ' not ▁ empty ▁ username ' ) NEW_LINE self . assertEqual ( backend . password , ' not ▁ empty ▁ password ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_HOST_USER = " not ▁ empty ▁ username " , EMAIL_HOST_PASSWORD = " not ▁ empty ▁ password " ) NEW_LINE def test_email_authentication_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( username = ' username ' , password = ' password ' ) NEW_LINE self . assertEqual ( backend . username , ' username ' ) NEW_LINE self . assertEqual ( backend . password , ' password ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_HOST_USER = " not ▁ empty ▁ username " , EMAIL_HOST_PASSWORD = " not ▁ empty ▁ password " ) NEW_LINE def test_email_disabled_authentication ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( username = ' ' , password = ' ' ) NEW_LINE self . assertEqual ( backend . username , ' ' ) NEW_LINE self . assertEqual ( backend . password , ' ' ) NEW_LINE DEDENT def test_auth_attempted ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Opening ▁ the ▁ backend ▁ with ▁ non ▁ empty ▁ username / password ▁ tries STRNEWLINE ▁ to ▁ authenticate ▁ against ▁ the ▁ SMTP ▁ server . STRNEWLINE ▁ """ NEW_LINE backend = smtp . EmailBackend ( username = ' not ▁ empty ▁ username ' , password = ' not ▁ empty ▁ password ' ) NEW_LINE with self . assertRaisesMessage ( SMTPException , ' SMTP ▁ AUTH ▁ extension ▁ not ▁ supported ▁ by ▁ server . ' ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT def test_server_open ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ open ( ) ▁ returns ▁ whether ▁ it ▁ opened ▁ a ▁ connection . STRNEWLINE ▁ """ NEW_LINE backend = smtp . EmailBackend ( username = ' ' , password = ' ' ) NEW_LINE self . assertFalse ( backend . connection ) NEW_LINE opened = backend . open ( ) NEW_LINE backend . close ( ) NEW_LINE self . assertTrue ( opened ) NEW_LINE DEDENT def test_server_login ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Even ▁ if ▁ the ▁ Python ▁ SMTP ▁ server ▁ doesn ' t ▁ support ▁ authentication , ▁ the STRNEWLINE ▁ login ▁ process ▁ starts ▁ and ▁ the ▁ appropriate ▁ exception ▁ is ▁ raised . STRNEWLINE ▁ """ NEW_LINE class CustomEmailBackend ( smtp . EmailBackend ) : NEW_LINE INDENT connection_class = FakeAUTHSMTPConnection NEW_LINE DEDENT backend = CustomEmailBackend ( username = ' username ' , password = ' password ' ) NEW_LINE with self . assertRaises ( SMTPAuthenticationError ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT @ override_settings ( EMAIL_USE_TLS = True ) NEW_LINE def test_email_tls_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_tls ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_TLS = True ) NEW_LINE def test_email_tls_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( use_tls = False ) NEW_LINE self . assertFalse ( backend . use_tls ) NEW_LINE DEDENT def test_email_tls_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertFalse ( backend . use_tls ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_SSL = True ) NEW_LINE def test_email_ssl_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_ssl ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_SSL = True ) NEW_LINE def test_email_ssl_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( use_ssl = False ) NEW_LINE self . assertFalse ( backend . use_ssl ) NEW_LINE DEDENT def test_email_ssl_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertFalse ( backend . use_ssl ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_CERTFILE = ' foo ' ) NEW_LINE def test_email_ssl_certfile_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . ssl_certfile , ' foo ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_CERTFILE = ' foo ' ) NEW_LINE def test_email_ssl_certfile_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ssl_certfile = ' bar ' ) NEW_LINE self . assertEqual ( backend . ssl_certfile , ' bar ' ) NEW_LINE DEDENT def test_email_ssl_certfile_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertIsNone ( backend . ssl_certfile ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_KEYFILE = ' foo ' ) NEW_LINE def test_email_ssl_keyfile_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . ssl_keyfile , ' foo ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_KEYFILE = ' foo ' ) NEW_LINE def test_email_ssl_keyfile_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ssl_keyfile = ' bar ' ) NEW_LINE self . assertEqual ( backend . ssl_keyfile , ' bar ' ) NEW_LINE DEDENT def test_email_ssl_keyfile_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertIsNone ( backend . ssl_keyfile ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_TLS = True ) NEW_LINE def test_email_tls_attempts_starttls ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_tls ) NEW_LINE with self . assertRaisesMessage ( SMTPException , ' STARTTLS ▁ extension ▁ not ▁ supported ▁ by ▁ server . ' ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT @ override_settings ( EMAIL_USE_SSL = True ) NEW_LINE def test_email_ssl_attempts_ssl_connection ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_ssl ) NEW_LINE with self . assertRaises ( SSLError ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT def test_connection_timeout_default ( self ) : NEW_LINE INDENT """ The ▁ connection ' s ▁ timeout ▁ value ▁ is ▁ None ▁ by ▁ default . """ NEW_LINE connection = mail . get_connection ( ' django . core . mail . backends . smtp . EmailBackend ' ) NEW_LINE self . assertIsNone ( connection . timeout ) NEW_LINE DEDENT def test_connection_timeout_custom ( self ) : NEW_LINE INDENT """ The ▁ timeout ▁ parameter ▁ can ▁ be ▁ customized . """ NEW_LINE class MyEmailBackend ( smtp . EmailBackend ) : NEW_LINE INDENT def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT kwargs . setdefault ( ' timeout ' , 42 ) NEW_LINE super ( ) . __init__ ( * args , ** kwargs ) NEW_LINE DEDENT DEDENT myemailbackend = MyEmailBackend ( ) NEW_LINE myemailbackend . open ( ) NEW_LINE self . assertEqual ( myemailbackend . timeout , 42 ) NEW_LINE self . assertEqual ( myemailbackend . connection . timeout , 42 ) NEW_LINE myemailbackend . close ( ) NEW_LINE DEDENT @ override_settings ( EMAIL_TIMEOUT = 10 ) NEW_LINE def test_email_timeout_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . timeout , 10 ) NEW_LINE DEDENT def test_email_msg_uses_crlf ( self ) : NEW_LINE INDENT """ # 23063 ▁ - - ▁ RFC - compliant ▁ messages ▁ are ▁ sent ▁ over ▁ SMTP . """ NEW_LINE send = SMTP . send NEW_LINE try : NEW_LINE INDENT smtp_messages = [ ] NEW_LINE def mock_send ( self , s ) : NEW_LINE INDENT smtp_messages . append ( s ) NEW_LINE return send ( self , s ) NEW_LINE DEDENT SMTP . send = mock_send NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE # ▁ Find ▁ the ▁ actual ▁ message ENDCOM msg = None NEW_LINE for i , m in enumerate ( smtp_messages ) : NEW_LINE INDENT if m [ : 4 ] == ' data ' : NEW_LINE INDENT msg = smtp_messages [ i + 1 ] NEW_LINE break NEW_LINE DEDENT DEDENT self . assertTrue ( msg ) NEW_LINE msg = msg . decode ( ) NEW_LINE # ▁ The ▁ message ▁ only ▁ contains ▁ CRLF ▁ and ▁ not ▁ combinations ▁ of ▁ CRLF , ▁ LF , ▁ and ▁ CR . ENDCOM msg = msg . replace ( ' \n ' , ' ' ) NEW_LINE self . assertNotIn ( ' ' , msg ) NEW_LINE self . assertNotIn ( ' \n ' , msg ) NEW_LINE DEDENT finally : NEW_LINE INDENT SMTP . send = send NEW_LINE DEDENT DEDENT def test_send_messages_after_open_failed ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ send _ messages ( ) ▁ shouldn ' t ▁ try ▁ to ▁ send ▁ messages ▁ if ▁ open ( ) ▁ raises ▁ an STRNEWLINE ▁ exception ▁ after ▁ initializing ▁ the ▁ connection . STRNEWLINE ▁ """ NEW_LINE backend = smtp . EmailBackend ( ) NEW_LINE # ▁ Simulate ▁ connection ▁ initialization ▁ success ▁ and ▁ a ▁ subsequent ENDCOM # ▁ connection ▁ exception . ENDCOM backend . connection = True NEW_LINE backend . open = lambda : None NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertEqual ( backend . send_messages ( [ email ] ) , None ) NEW_LINE DEDENT DEDENT class SMTPBackendStoppedServerTests ( SMTPBackendTestsBase ) : NEW_LINE INDENT """ STRNEWLINE ▁ These ▁ tests ▁ require ▁ a ▁ separate ▁ class , ▁ because ▁ the ▁ FakeSMTPServer ▁ is ▁ shut STRNEWLINE ▁ down ▁ in ▁ setUpClass ( ) , ▁ and ▁ it ▁ cannot ▁ be ▁ restarted ▁ ( " RuntimeError : ▁ threads STRNEWLINE ▁ can ▁ only ▁ be ▁ started ▁ once " ) . STRNEWLINE ▁ """ NEW_LINE @ classmethod NEW_LINE def setUpClass ( cls ) : NEW_LINE INDENT super ( ) . setUpClass ( ) NEW_LINE cls . backend = smtp . EmailBackend ( username = ' ' , password = ' ' ) NEW_LINE cls . server . stop ( ) NEW_LINE DEDENT def test_server_stopped ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Closing ▁ the ▁ backend ▁ while ▁ the ▁ SMTP ▁ server ▁ is ▁ stopped ▁ doesn ' t ▁ raise ▁ an STRNEWLINE ▁ exception . STRNEWLINE ▁ """ NEW_LINE self . backend . close ( ) NEW_LINE DEDENT def test_fail_silently_on_connection_error ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ socket ▁ connection ▁ error ▁ is ▁ silenced ▁ with ▁ fail _ silently = True . STRNEWLINE ▁ """ NEW_LINE with self . assertRaises ( socket . error ) : NEW_LINE INDENT self . backend . open ( ) NEW_LINE DEDENT self . backend . fail_silently = True NEW_LINE self . backend . open ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="tommy-u/chaco/tree/master/chaco/base_plot_container.py"> """ ▁ Defines ▁ the ▁ BasePlotContainer ▁ class . STRNEWLINE """ NEW_LINE import warnings NEW_LINE # ▁ Enthought ▁ library ▁ imports ENDCOM from enable . api import Container NEW_LINE from traits . api import Bool , Instance , Property , Str , Tuple NEW_LINE # ▁ Local , ▁ relative ▁ imports ENDCOM from plot_component import DEFAULT_DRAWING_ORDER , PlotComponent NEW_LINE class BasePlotContainer ( Container ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ container ▁ for ▁ PlotComponents ▁ that ▁ conforms ▁ to ▁ being ▁ laid ▁ out ▁ by STRNEWLINE ▁ PlotFrames . ▁ Serves ▁ as ▁ the ▁ base ▁ class ▁ for ▁ other ▁ PlotContainers . STRNEWLINE STRNEWLINE ▁ PlotContainers ▁ define ▁ a ▁ layout , ▁ i . e . , ▁ a ▁ spatial ▁ relationship ▁ between STRNEWLINE ▁ their ▁ contained ▁ components . ▁ ( BasePlotContainer ▁ doesn ' t ▁ define ▁ one , STRNEWLINE ▁ but ▁ its ▁ various ▁ subclasses ▁ do . ) STRNEWLINE STRNEWLINE ▁ BasePlotContainer ▁ is ▁ a ▁ subclass ▁ of ▁ Enable ▁ Container , ▁ so ▁ it ▁ is ▁ possible ▁ to STRNEWLINE ▁ insert ▁ Enable - level ▁ components ▁ into ▁ it . ▁ However , ▁ because ▁ Enable STRNEWLINE ▁ components ▁ don ' t ▁ have ▁ the ▁ correct ▁ interfaces ▁ to ▁ participate ▁ in ▁ layout , STRNEWLINE ▁ the ▁ visual ▁ results ▁ will ▁ probably ▁ be ▁ incorrect . STRNEWLINE ▁ """ NEW_LINE # ▁ Redefine ▁ the ▁ container ▁ layers ▁ to ▁ name ▁ the ▁ main ▁ layer ▁ as ▁ " plot " ▁ instead ENDCOM # ▁ of ▁ the ▁ Enable ▁ default ▁ of ▁ " mainlayer " ENDCOM container_under_layers = Tuple ( " background " , " image " , " underlay " , " plot " ) NEW_LINE # ▁ Duplicate ▁ trait ▁ declarations ▁ from ▁ PlotComponent . ▁ We ▁ don ' t ▁ subclass ENDCOM # ▁ PlotComponent ▁ to ▁ avoid ▁ MRO ▁ complications ▁ with ▁ trait ▁ handlers ▁ and ▁ property ENDCOM # ▁ getters / setters . ENDCOM draw_order = Instance ( list , args = ( DEFAULT_DRAWING_ORDER , ) ) NEW_LINE draw_layer = Str ( " plot " ) NEW_LINE # ▁ Deprecated ▁ traits ENDCOM # ▁ Deprecated ▁ flag ▁ to ▁ indicate ▁ that ▁ a ▁ component ▁ needed ▁ to ▁ do ▁ old - style ENDCOM # ▁ drawing . ▁ Unused ▁ by ▁ any ▁ recent ▁ Chaco ▁ component . ENDCOM use_draw_order = Bool ( True ) NEW_LINE # ▁ Deprecated ▁ property ▁ for ▁ accessing ▁ the ▁ components ▁ in ▁ the ▁ container . ENDCOM plot_components = Property NEW_LINE def _get_plot_components ( self ) : NEW_LINE INDENT warnings . warn ( " Use ▁ of ▁ plot _ components ▁ attribute ▁ deprecated . " " Use ▁ components ▁ attribute ▁ instead . " , DeprecationWarning ) NEW_LINE return self . _components NEW_LINE DEDENT def _set_plot_components ( self , new ) : NEW_LINE INDENT warnings . warn ( " Use ▁ of ▁ plot _ components ▁ attribute ▁ deprecated . " " Use ▁ components ▁ attribute ▁ instead . " , DeprecationWarning ) NEW_LINE self . _components = new NEW_LINE DEDENT def _use_draw_order_changed ( self , old , new ) : NEW_LINE INDENT """ ▁ Handler ▁ to ▁ catch ▁ the ▁ case ▁ when ▁ someone ▁ is ▁ trying ▁ to ▁ use ▁ the STRNEWLINE ▁ old - style ▁ drawing ▁ mechanism , ▁ which ▁ is ▁ now ▁ unsupported . STRNEWLINE ▁ """ NEW_LINE if new == False : NEW_LINE INDENT raise RuntimeError ( " The ▁ old - style ▁ drawing ▁ mechanism ▁ is ▁ no ▁ longer ▁ " " supported ▁ in ▁ Chaco . " ) NEW_LINE # ▁ EOF ENDCOM DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="indevgr/django/tree/master/tests/servers/tests.py"> # ▁ - * - ▁ encoding : ▁ utf - 8 ▁ - * - ENDCOM """ STRNEWLINE Tests ▁ for ▁ django . core . servers . STRNEWLINE """ NEW_LINE from __future__ import unicode_literals NEW_LINE import contextlib NEW_LINE import errno NEW_LINE import os NEW_LINE import socket NEW_LINE from django . core . exceptions import ImproperlyConfigured NEW_LINE from django . test import LiveServerTestCase , override_settings NEW_LINE from django . utils . _os import upath NEW_LINE from django . utils . http import urlencode NEW_LINE from django . utils . six import text_type NEW_LINE from django . utils . six . moves . urllib . error import HTTPError NEW_LINE from django . utils . six . moves . urllib . request import urlopen NEW_LINE from . models import Person NEW_LINE TEST_ROOT = os . path . dirname ( upath ( __file__ ) ) NEW_LINE TEST_SETTINGS = { ' MEDIA _ URL ' : ' / media / ' , ' MEDIA _ ROOT ' : os . path . join ( TEST_ROOT , ' media ' ) , ' STATIC _ URL ' : ' / static / ' , ' STATIC _ ROOT ' : os . path . join ( TEST_ROOT , ' static ' ) , } NEW_LINE @ override_settings ( ROOT_URLCONF = ' servers . urls ' , ** TEST_SETTINGS ) NEW_LINE class LiveServerBase ( LiveServerTestCase ) : NEW_LINE INDENT available_apps = [ ' servers ' , ' django . contrib . auth ' , ' django . contrib . contenttypes ' , ' django . contrib . sessions ' , ] NEW_LINE fixtures = [ ' testdata . json ' ] NEW_LINE def urlopen ( self , url ) : NEW_LINE INDENT return urlopen ( self . live_server_url + url ) NEW_LINE DEDENT DEDENT class LiveServerAddress ( LiveServerBase ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ the ▁ address ▁ set ▁ in ▁ the ▁ environment ▁ variable ▁ is ▁ valid . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE @ classmethod NEW_LINE def setUpClass ( cls ) : NEW_LINE # ▁ Backup ▁ original ▁ environment ▁ variable ENDCOM INDENT address_predefined = ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' in os . environ NEW_LINE old_address = os . environ . get ( ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ) NEW_LINE # ▁ Just ▁ the ▁ host ▁ is ▁ not ▁ accepted ENDCOM cls . raises_exception ( ' localhost ' , ImproperlyConfigured ) NEW_LINE # ▁ The ▁ host ▁ must ▁ be ▁ valid ENDCOM cls . raises_exception ( ' blahblahblah : 8081' , socket . error ) NEW_LINE # ▁ The ▁ list ▁ of ▁ ports ▁ must ▁ be ▁ in ▁ a ▁ valid ▁ format ENDCOM cls . raises_exception ( ' localhost : 8081 , ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081 , blah ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081 - ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081 - blah ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081-8082-8083' , ImproperlyConfigured ) NEW_LINE # ▁ Restore ▁ original ▁ environment ▁ variable ENDCOM if address_predefined : NEW_LINE INDENT os . environ [ ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ] = old_address NEW_LINE DEDENT else : NEW_LINE INDENT del os . environ [ ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ] NEW_LINE # ▁ put ▁ it ▁ in ▁ a ▁ list ▁ to ▁ prevent ▁ descriptor ▁ lookups ▁ in ▁ test ENDCOM DEDENT cls . live_server_url_test = [ cls . live_server_url ] NEW_LINE DEDENT @ classmethod NEW_LINE def tearDownClass ( cls ) : NEW_LINE # ▁ skip ▁ it , ▁ as ▁ setUpClass ▁ doesn ' t ▁ call ▁ its ▁ parent ▁ either ENDCOM INDENT pass NEW_LINE DEDENT @ classmethod NEW_LINE def raises_exception ( cls , address , exception ) : NEW_LINE INDENT os . environ [ ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ] = address NEW_LINE try : NEW_LINE INDENT super ( LiveServerAddress , cls ) . setUpClass ( ) NEW_LINE raise Exception ( " The ▁ line ▁ above ▁ should ▁ have ▁ raised ▁ an ▁ exception " ) NEW_LINE DEDENT except exception : NEW_LINE INDENT pass NEW_LINE DEDENT finally : NEW_LINE INDENT super ( LiveServerAddress , cls ) . tearDownClass ( ) NEW_LINE DEDENT DEDENT def test_live_server_url_is_class_property ( self ) : NEW_LINE INDENT self . assertIsInstance ( self . live_server_url_test [ 0 ] , text_type ) NEW_LINE self . assertEqual ( self . live_server_url_test [ 0 ] , self . live_server_url ) NEW_LINE DEDENT DEDENT class LiveServerViews ( LiveServerBase ) : NEW_LINE INDENT def test_404 ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ the ▁ LiveServerTestCase ▁ serves ▁ 404s . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE try : NEW_LINE INDENT self . urlopen ( ' / ' ) NEW_LINE DEDENT except HTTPError as err : NEW_LINE INDENT self . assertEqual ( err . code , 404 , ' Expected ▁ 404 ▁ response ' ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Expected ▁ 404 ▁ response ' ) NEW_LINE DEDENT DEDENT def test_view ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ the ▁ LiveServerTestCase ▁ serves ▁ views . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE with contextlib . closing ( self . urlopen ( ' / example _ view / ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) , b ' example ▁ view ' ) NEW_LINE DEDENT DEDENT def test_static_files ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ the ▁ LiveServerTestCase ▁ serves ▁ static ▁ files . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE with contextlib . closing ( self . urlopen ( ' / static / example _ static _ file . txt ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) . rstrip ( b ' \n ' ) , b ' example ▁ static ▁ file ' ) NEW_LINE DEDENT DEDENT def test_no_collectstatic_emulation ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Test ▁ that ▁ LiveServerTestCase ▁ reports ▁ a ▁ 404 ▁ status ▁ code ▁ when ▁ HTTP ▁ client STRNEWLINE ▁ tries ▁ to ▁ access ▁ a ▁ static ▁ file ▁ that ▁ isn ' t ▁ explicitly ▁ put ▁ under STRNEWLINE ▁ STATIC _ ROOT . STRNEWLINE ▁ """ NEW_LINE try : NEW_LINE INDENT self . urlopen ( ' / static / another _ app / another _ app _ static _ file . txt ' ) NEW_LINE DEDENT except HTTPError as err : NEW_LINE INDENT self . assertEqual ( err . code , 404 , ' Expected ▁ 404 ▁ response ' ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Expected ▁ 404 ▁ response ▁ ( got ▁ % d ) ' % err . code ) NEW_LINE DEDENT DEDENT def test_media_files ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ the ▁ LiveServerTestCase ▁ serves ▁ media ▁ files . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE with contextlib . closing ( self . urlopen ( ' / media / example _ media _ file . txt ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) . rstrip ( b ' \n ' ) , b ' example ▁ media ▁ file ' ) NEW_LINE DEDENT DEDENT def test_environ ( self ) : NEW_LINE INDENT with contextlib . closing ( self . urlopen ( ' / environ _ view / ? % s ' % urlencode ( { ' q ' : ' тест ' } ) ) ) as f : NEW_LINE INDENT self . assertIn ( b " QUERY _ STRING : ▁ ' q = % D1%82 % D0 % B5 % D1%81 % D1%82 ' " , f . read ( ) ) NEW_LINE DEDENT DEDENT DEDENT class LiveServerDatabase ( LiveServerBase ) : NEW_LINE INDENT def test_fixtures_loaded ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ fixtures ▁ are ▁ properly ▁ loaded ▁ and ▁ visible ▁ to ▁ the STRNEWLINE ▁ live ▁ server ▁ thread . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE with contextlib . closing ( self . urlopen ( ' / model _ view / ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) . splitlines ( ) , [ b ' jane ' , b ' robert ' ] ) NEW_LINE DEDENT DEDENT def test_database_writes ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Ensure ▁ that ▁ data ▁ written ▁ to ▁ the ▁ database ▁ by ▁ a ▁ view ▁ can ▁ be ▁ read . STRNEWLINE ▁ Refs ▁ # 2879 . STRNEWLINE ▁ """ NEW_LINE self . urlopen ( ' / create _ model _ instance / ' ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) . order_by ( ' pk ' ) , [ ' jane ' , ' robert ' , ' emily ' ] , lambda b : b . name ) NEW_LINE DEDENT DEDENT class LiveServerPort ( LiveServerBase ) : NEW_LINE INDENT def test_port_bind ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Each ▁ LiveServerTestCase ▁ binds ▁ to ▁ a ▁ unique ▁ port ▁ or ▁ fails ▁ to ▁ start ▁ a STRNEWLINE ▁ server ▁ thread ▁ when ▁ run ▁ concurrently ▁ ( # 26011 ) . STRNEWLINE ▁ """ NEW_LINE TestCase = type ( str ( " TestCase " ) , ( LiveServerBase , ) , { } ) NEW_LINE try : NEW_LINE INDENT TestCase . setUpClass ( ) NEW_LINE DEDENT except socket . error as e : NEW_LINE INDENT if e . errno == errno . EADDRINUSE : NEW_LINE # ▁ We ' re ▁ out ▁ of ▁ ports , ▁ LiveServerTestCase ▁ correctly ▁ fails ▁ with ENDCOM # ▁ a ▁ socket ▁ error . ENDCOM INDENT return NEW_LINE # ▁ Unexpected ▁ error . ENDCOM DEDENT raise NEW_LINE DEDENT try : NEW_LINE # ▁ We ' ve ▁ acquired ▁ a ▁ port , ▁ ensure ▁ our ▁ server ▁ threads ▁ acquired ENDCOM # ▁ different ▁ addresses . ENDCOM INDENT self . assertNotEqual ( self . live_server_url , TestCase . live_server_url , " Acquired ▁ duplicate ▁ server ▁ addresses ▁ for ▁ server ▁ threads : ▁ % s " % self . live_server_url ) NEW_LINE DEDENT finally : NEW_LINE INDENT TestCase . tearDownClass ( ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="thierry1985/project-1022/tree/master/MISC/TFD-0.2.2/translate/pddl/parser.py"> __all__ = [ " ParseError " , " parse _ nested _ list " ] NEW_LINE class ParseError ( Exception ) : NEW_LINE INDENT pass NEW_LINE # ▁ Basic ▁ functions ▁ for ▁ parsing ▁ PDDL ▁ ( Lisp ) ▁ files . ENDCOM DEDENT def parse_nested_list ( input_file ) : NEW_LINE INDENT tokens = tokenize ( input_file ) NEW_LINE next_token = tokens . next ( ) NEW_LINE if next_token != " ( " : NEW_LINE INDENT raise ParseError ( " Expected ▁ ' ( ' , ▁ got ▁ % s . " % next_token ) NEW_LINE DEDENT result = list ( parse_list_aux ( tokens ) ) NEW_LINE for tok in tokens : # ▁ Check ▁ that ▁ generator ▁ is ▁ exhausted . ENDCOM NEW_LINE INDENT raise ParseError ( " Unexpected ▁ token : ▁ % s . " % tok ) NEW_LINE DEDENT return result NEW_LINE DEDENT def tokenize ( input ) : NEW_LINE INDENT for line in input : NEW_LINE INDENT line = line . split ( " ; " , 1 ) [ 0 ] # ▁ Strip ▁ comments . ENDCOM NEW_LINE line = line . replace ( " ( " , " ▁ ( ▁ " ) . replace ( " ) " , " ▁ ) ▁ " ) . replace ( " ? " , " ▁ ? " ) NEW_LINE for token in line . split ( ) : NEW_LINE INDENT yield token . lower ( ) NEW_LINE DEDENT DEDENT DEDENT def parse_list_aux ( tokenstream ) : NEW_LINE # ▁ Leading ▁ " ( " ▁ has ▁ already ▁ been ▁ swallowed . ENDCOM INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT token = tokenstream . next ( ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise ParseError ( ) NEW_LINE DEDENT if token == " ) " : NEW_LINE INDENT return NEW_LINE DEDENT elif token == " ( " : NEW_LINE INDENT yield list ( parse_list_aux ( tokenstream ) ) NEW_LINE DEDENT else : NEW_LINE INDENT yield token NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Baumelbi/IntroPython2016/tree/master/Solutions/Session06/test_mailroom2.py"> # ! / usr / bin / env ▁ python ENDCOM """ STRNEWLINE unit ▁ tests ▁ for ▁ the ▁ mailroom ▁ program STRNEWLINE """ NEW_LINE import os NEW_LINE import mailroom2 as mailroom NEW_LINE # ▁ so ▁ that ▁ it ' s ▁ there ▁ for ▁ the ▁ tests ENDCOM mailroom . donor_db = mailroom . get_donor_db ( ) NEW_LINE def test_list_donors ( ) : NEW_LINE INDENT listing = mailroom . list_donors ( ) NEW_LINE # ▁ hard ▁ to ▁ test ▁ this ▁ throughly ▁ - - ▁ better ▁ not ▁ to ▁ hard ▁ code ▁ the ▁ entire ENDCOM # ▁ thing . ▁ But ▁ check ▁ for ▁ a ▁ few ▁ aspects ▁ - - ▁ this ▁ will ▁ catch ▁ the ▁ likely ENDCOM # ▁ errors ENDCOM assert listing . startswith ( " Donor ▁ list : \n " ) NEW_LINE assert " Jeff ▁ Bezos " in listing NEW_LINE assert " William ▁ Gates ▁ III " in listing NEW_LINE assert len ( listing . split ( ' \n ' ) ) == 5 NEW_LINE DEDENT def test_find_donor ( ) : NEW_LINE INDENT """ ▁ checks ▁ a ▁ donor ▁ that ▁ is ▁ there , ▁ but ▁ with ▁ odd ▁ case ▁ and ▁ spaces """ NEW_LINE donor = mailroom . find_donor ( " jefF ▁ beZos ▁ " ) NEW_LINE assert donor [ 0 ] == " Jeff ▁ Bezos " NEW_LINE DEDENT def test_find_donor_not ( ) : NEW_LINE INDENT " test ▁ one ▁ that ' s ▁ not ▁ there " NEW_LINE donor = mailroom . find_donor ( " Jeff ▁ Bzos " ) NEW_LINE assert donor is None NEW_LINE DEDENT def test_gen_letter ( ) : NEW_LINE INDENT """ ▁ test ▁ the ▁ donor ▁ letter ▁ """ NEW_LINE # ▁ create ▁ a ▁ sample ▁ donor ENDCOM donor = ( " Fred ▁ Flintstone " , [ 432.45 , 65.45 , 230.0 ] ) NEW_LINE letter = mailroom . gen_letter ( donor ) NEW_LINE # ▁ what ▁ to ▁ test ? ▁ tricky ! ENDCOM assert letter . startswith ( " Dear ▁ Fred ▁ Flintstone " ) NEW_LINE assert letter . endswith ( " - The ▁ Team \n " ) NEW_LINE assert " donation ▁ of ▁ $ 230.00" in letter NEW_LINE DEDENT def test_add_donor ( ) : NEW_LINE INDENT name = " Fred ▁ Flintstone ▁ ▁ " NEW_LINE donor = mailroom . add_donor ( name ) NEW_LINE donor [ 1 ] . append ( 300 ) NEW_LINE assert donor [ 0 ] == " Fred ▁ Flintstone " NEW_LINE assert donor [ 1 ] == [ 300 ] NEW_LINE assert mailroom . find_donor ( name ) == donor NEW_LINE DEDENT def test_generate_donor_report ( ) : NEW_LINE INDENT report = mailroom . generate_donor_report ( ) NEW_LINE print ( report ) # ▁ printing ▁ so ▁ you ▁ can ▁ see ▁ it ▁ if ▁ it ▁ fails ENDCOM NEW_LINE # ▁ this ▁ is ▁ pretty ▁ tough ▁ to ▁ test ENDCOM # ▁ these ▁ are ▁ not ▁ great , ▁ because ▁ they ▁ will ▁ fail ▁ if ▁ unimportant ▁ parts ▁ of ▁ the ENDCOM # ▁ report ▁ are ▁ changed . ENDCOM # ▁ but ▁ at ▁ least ▁ you ▁ know ▁ that ▁ codes ▁ working ▁ now . ENDCOM assert report . startswith ( " Donor ▁ Name ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ | ▁ Total ▁ Given ▁ | ▁ Num ▁ Gifts ▁ | ▁ Average ▁ Gift " ) NEW_LINE assert " Jeff ▁ Bezos ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ $ ▁ ▁ ▁ ▁ 877.33 ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ 1 ▁ ▁ ▁ $ ▁ ▁ ▁ ▁ ▁ 877.33" in report NEW_LINE DEDENT def test_save_letters_to_disk ( ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ only ▁ tests ▁ that ▁ the ▁ files ▁ get ▁ created , ▁ but ▁ that ' s ▁ a ▁ start STRNEWLINE STRNEWLINE ▁ Note ▁ that ▁ the ▁ contents ▁ of ▁ the ▁ letter ▁ was ▁ already STRNEWLINE ▁ tested ▁ with ▁ test _ gen _ letter STRNEWLINE ▁ """ NEW_LINE mailroom . save_letters_to_disk ( ) NEW_LINE assert os . path . isfile ( ' Jeff _ Bezos . txt ' ) NEW_LINE assert os . path . isfile ( ' William _ Gates _ III . txt ' ) NEW_LINE # ▁ check ▁ that ▁ it ' snot ▁ empty : ENDCOM with open ( ' William _ Gates _ III . txt ' ) as f : NEW_LINE INDENT size = len ( f . read ( ) ) NEW_LINE DEDENT assert size > 0 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE # ▁ this ▁ is ▁ best ▁ run ▁ with ▁ a ▁ test ▁ runner , ▁ like ▁ pytest ENDCOM # ▁ But ▁ if ▁ not , ▁ at ▁ least ▁ this ▁ will ▁ run ▁ them ▁ all . ENDCOM INDENT test_list_donors ( ) NEW_LINE test_find_donor ( ) NEW_LINE test_find_donor_not ( ) NEW_LINE test_gen_letter ( ) NEW_LINE test_add_donor ( ) NEW_LINE test_generate_donor_report ( ) NEW_LINE test_save_letters_to_disk ( ) NEW_LINE print ( " All ▁ tests ▁ Passed " ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="rpmcpp/Audacity/tree/master/lib-src/lv2/lv2/plugins/eg03-metro.lv2/waflib/Tools/vala.py"> # ! ▁ / usr / bin / env ▁ python ENDCOM # ▁ encoding : ▁ utf - 8 ENDCOM # ▁ WARNING ! ▁ Do ▁ not ▁ edit ! ▁ http : / / waf . googlecode . com / git / docs / wafbook / single . html # _ obtaining _ the _ waf _ file ENDCOM import os . path , shutil , re NEW_LINE from waflib import Context , Task , Utils , Logs , Options , Errors NEW_LINE from waflib . TaskGen import extension , taskgen_method NEW_LINE from waflib . Configure import conf NEW_LINE class valac ( Task . Task ) : NEW_LINE INDENT vars = [ " VALAC " , " VALAC _ VERSION " , " VALAFLAGS " ] NEW_LINE ext_out = [ ' . h ' ] NEW_LINE def run ( self ) : NEW_LINE INDENT cmd = [ self . env [ ' VALAC ' ] ] + self . env [ ' VALAFLAGS ' ] NEW_LINE cmd . extend ( [ a . abspath ( ) for a in self . inputs ] ) NEW_LINE ret = self . exec_command ( cmd , cwd = self . outputs [ 0 ] . parent . abspath ( ) ) NEW_LINE if ret : NEW_LINE INDENT return ret NEW_LINE DEDENT for x in self . outputs : NEW_LINE INDENT if id ( x . parent ) != id ( self . outputs [ 0 ] . parent ) : NEW_LINE INDENT shutil . move ( self . outputs [ 0 ] . parent . abspath ( ) + os . sep + x . name , x . abspath ( ) ) NEW_LINE DEDENT DEDENT if self . generator . dump_deps_node : NEW_LINE INDENT self . generator . dump_deps_node . write ( ' \n ' . join ( self . generator . packages ) ) NEW_LINE DEDENT return ret NEW_LINE DEDENT DEDENT valac = Task . update_outputs ( valac ) NEW_LINE @ taskgen_method NEW_LINE def init_vala_task ( self ) : NEW_LINE INDENT self . profile = getattr ( self , ' profile ' , ' gobject ' ) NEW_LINE if self . profile == ' gobject ' : NEW_LINE INDENT self . uselib = Utils . to_list ( getattr ( self , ' uselib ' , [ ] ) ) NEW_LINE if not ' GOBJECT ' in self . uselib : NEW_LINE INDENT self . uselib . append ( ' GOBJECT ' ) NEW_LINE DEDENT DEDENT def addflags ( flags ) : NEW_LINE INDENT self . env . append_value ( ' VALAFLAGS ' , flags ) NEW_LINE DEDENT if self . profile : NEW_LINE INDENT addflags ( ' - - profile = % s ' % self . profile ) NEW_LINE DEDENT if hasattr ( self , ' threading ' ) : NEW_LINE INDENT if self . profile == ' gobject ' : NEW_LINE INDENT if not ' GTHREAD ' in self . uselib : NEW_LINE INDENT self . uselib . append ( ' GTHREAD ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT Logs . warn ( " Profile ▁ % s ▁ means ▁ no ▁ threading ▁ support " % self . profile ) NEW_LINE self . threading = False NEW_LINE DEDENT if self . threading : NEW_LINE INDENT addflags ( ' - - threading ' ) NEW_LINE DEDENT DEDENT valatask = self . valatask NEW_LINE self . is_lib = ' cprogram ' not in self . features NEW_LINE if self . is_lib : NEW_LINE INDENT addflags ( ' - - library = % s ' % self . target ) NEW_LINE h_node = self . path . find_or_declare ( ' % s . h ' % self . target ) NEW_LINE valatask . outputs . append ( h_node ) NEW_LINE addflags ( ' - - header = % s ' % h_node . name ) NEW_LINE valatask . outputs . append ( self . path . find_or_declare ( ' % s . vapi ' % self . target ) ) NEW_LINE if getattr ( self , ' gir ' , None ) : NEW_LINE INDENT gir_node = self . path . find_or_declare ( ' % s . gir ' % self . gir ) NEW_LINE addflags ( ' - - gir = % s ' % gir_node . name ) NEW_LINE valatask . outputs . append ( gir_node ) NEW_LINE DEDENT DEDENT self . vala_target_glib = getattr ( self , ' vala _ target _ glib ' , getattr ( Options . options , ' vala _ target _ glib ' , None ) ) NEW_LINE if self . vala_target_glib : NEW_LINE INDENT addflags ( ' - - target - glib = % s ' % self . vala_target_glib ) NEW_LINE DEDENT addflags ( [ ' - - define = % s ' % x for x in getattr ( self , ' vala _ defines ' , [ ] ) ] ) NEW_LINE packages_private = Utils . to_list ( getattr ( self , ' packages _ private ' , [ ] ) ) NEW_LINE addflags ( [ ' - - pkg = % s ' % x for x in packages_private ] ) NEW_LINE def _get_api_version ( ) : NEW_LINE INDENT api_version = '1.0' NEW_LINE if hasattr ( Context . g_module , ' API _ VERSION ' ) : NEW_LINE INDENT version = Context . g_module . API_VERSION . split ( " . " ) NEW_LINE if version [ 0 ] == "0" : NEW_LINE INDENT api_version = "0 . " + version [ 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT api_version = version [ 0 ] + " . 0" NEW_LINE DEDENT DEDENT return api_version NEW_LINE DEDENT self . includes = Utils . to_list ( getattr ( self , ' includes ' , [ ] ) ) NEW_LINE self . uselib = self . to_list ( getattr ( self , ' uselib ' , [ ] ) ) NEW_LINE valatask . install_path = getattr ( self , ' install _ path ' , ' ' ) NEW_LINE valatask . vapi_path = getattr ( self , ' vapi _ path ' , ' $ { DATAROOTDIR } / vala / vapi ' ) NEW_LINE valatask . pkg_name = getattr ( self , ' pkg _ name ' , self . env [ ' PACKAGE ' ] ) NEW_LINE valatask . header_path = getattr ( self , ' header _ path ' , ' $ { INCLUDEDIR } / % s - % s ' % ( valatask . pkg_name , _get_api_version ( ) ) ) NEW_LINE valatask . install_binding = getattr ( self , ' install _ binding ' , True ) NEW_LINE self . packages = packages = Utils . to_list ( getattr ( self , ' packages ' , [ ] ) ) NEW_LINE self . vapi_dirs = vapi_dirs = Utils . to_list ( getattr ( self , ' vapi _ dirs ' , [ ] ) ) NEW_LINE includes = [ ] NEW_LINE if hasattr ( self , ' use ' ) : NEW_LINE INDENT local_packages = Utils . to_list ( self . use ) [ : ] NEW_LINE seen = [ ] NEW_LINE while len ( local_packages ) > 0 : NEW_LINE INDENT package = local_packages . pop ( ) NEW_LINE if package in seen : NEW_LINE INDENT continue NEW_LINE DEDENT seen . append ( package ) NEW_LINE try : NEW_LINE INDENT package_obj = self . bld . get_tgen_by_name ( package ) NEW_LINE DEDENT except Errors . WafError : NEW_LINE INDENT continue NEW_LINE DEDENT package_name = package_obj . target NEW_LINE package_node = package_obj . path NEW_LINE package_dir = package_node . path_from ( self . path ) NEW_LINE for task in package_obj . tasks : NEW_LINE INDENT for output in task . outputs : NEW_LINE INDENT if output . name == package_name + " . vapi " : NEW_LINE INDENT valatask . set_run_after ( task ) NEW_LINE if package_name not in packages : NEW_LINE INDENT packages . append ( package_name ) NEW_LINE DEDENT if package_dir not in vapi_dirs : NEW_LINE INDENT vapi_dirs . append ( package_dir ) NEW_LINE DEDENT if package_dir not in includes : NEW_LINE INDENT includes . append ( package_dir ) NEW_LINE DEDENT DEDENT DEDENT DEDENT if hasattr ( package_obj , ' use ' ) : NEW_LINE INDENT lst = self . to_list ( package_obj . use ) NEW_LINE lst . reverse ( ) NEW_LINE local_packages = [ pkg for pkg in lst if pkg not in seen ] + local_packages NEW_LINE DEDENT DEDENT DEDENT addflags ( [ ' - - pkg = % s ' % p for p in packages ] ) NEW_LINE for vapi_dir in vapi_dirs : NEW_LINE INDENT v_node = self . path . find_dir ( vapi_dir ) NEW_LINE if not v_node : NEW_LINE INDENT Logs . warn ( ' Unable ▁ to ▁ locate ▁ Vala ▁ API ▁ directory : ▁ % r ' % vapi_dir ) NEW_LINE DEDENT else : NEW_LINE INDENT addflags ( ' - - vapidir = % s ' % v_node . abspath ( ) ) NEW_LINE addflags ( ' - - vapidir = % s ' % v_node . get_bld ( ) . abspath ( ) ) NEW_LINE DEDENT DEDENT self . dump_deps_node = None NEW_LINE if self . is_lib and self . packages : NEW_LINE INDENT self . dump_deps_node = self . path . find_or_declare ( ' % s . deps ' % self . target ) NEW_LINE valatask . outputs . append ( self . dump_deps_node ) NEW_LINE DEDENT self . includes . append ( self . bld . srcnode . abspath ( ) ) NEW_LINE self . includes . append ( self . bld . bldnode . abspath ( ) ) NEW_LINE for include in includes : NEW_LINE INDENT try : NEW_LINE INDENT self . includes . append ( self . path . find_dir ( include ) . abspath ( ) ) NEW_LINE self . includes . append ( self . path . find_dir ( include ) . get_bld ( ) . abspath ( ) ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT Logs . warn ( " Unable ▁ to ▁ locate ▁ include ▁ directory : ▁ ' % s ' " % include ) NEW_LINE DEDENT DEDENT if self . is_lib and valatask . install_binding : NEW_LINE INDENT headers_list = [ o for o in valatask . outputs if o . suffix ( ) == " . h " ] NEW_LINE try : NEW_LINE INDENT self . install_vheader . source = headers_list NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT self . install_vheader = self . bld . install_files ( valatask . header_path , headers_list , self . env ) NEW_LINE DEDENT vapi_list = [ o for o in valatask . outputs if ( o . suffix ( ) in ( " . vapi " , " . deps " ) ) ] NEW_LINE try : NEW_LINE INDENT self . install_vapi . source = vapi_list NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT self . install_vapi = self . bld . install_files ( valatask . vapi_path , vapi_list , self . env ) NEW_LINE DEDENT gir_list = [ o for o in valatask . outputs if o . suffix ( ) == ' . gir ' ] NEW_LINE try : NEW_LINE INDENT self . install_gir . source = gir_list NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT self . install_gir = self . bld . install_files ( getattr ( self , ' gir _ path ' , ' $ { DATAROOTDIR } / gir - 1.0' ) , gir_list , self . env ) NEW_LINE DEDENT DEDENT DEDENT @ extension ( ' . vala ' , ' . gs ' ) NEW_LINE def vala_file ( self , node ) : NEW_LINE INDENT try : NEW_LINE INDENT valatask = self . valatask NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT valatask = self . valatask = self . create_task ( ' valac ' ) NEW_LINE self . init_vala_task ( ) NEW_LINE DEDENT valatask . inputs . append ( node ) NEW_LINE c_node = node . change_ext ( ' . c ' ) NEW_LINE valatask . outputs . append ( c_node ) NEW_LINE self . source . append ( c_node ) NEW_LINE DEDENT @ conf NEW_LINE def find_valac ( self , valac_name , min_version ) : NEW_LINE INDENT valac = self . find_program ( valac_name , var = ' VALAC ' ) NEW_LINE try : NEW_LINE INDENT output = self . cmd_and_log ( valac + ' ▁ - - version ' ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT valac_version = None NEW_LINE DEDENT else : NEW_LINE INDENT ver = re . search ( r ' \d + . \d + . \d + ' , output ) . group ( 0 ) . split ( ' . ' ) NEW_LINE valac_version = tuple ( [ int ( x ) for x in ver ] ) NEW_LINE DEDENT self . msg ( ' Checking ▁ for ▁ % s ▁ version ▁ > = ▁ % r ' % ( valac_name , min_version ) , valac_version , valac_version and valac_version >= min_version ) NEW_LINE if valac and valac_version < min_version : NEW_LINE INDENT self . fatal ( " % s ▁ version ▁ % r ▁ is ▁ too ▁ old , ▁ need ▁ > = ▁ % r " % ( valac_name , valac_version , min_version ) ) NEW_LINE DEDENT self . env [ ' VALAC _ VERSION ' ] = valac_version NEW_LINE return valac NEW_LINE DEDENT @ conf NEW_LINE def check_vala ( self , min_version = ( 0 , 8 , 0 ) , branch = None ) : NEW_LINE INDENT if not branch : NEW_LINE INDENT branch = min_version [ : 2 ] NEW_LINE DEDENT try : NEW_LINE INDENT find_valac ( self , ' valac - % d . % d ' % ( branch [ 0 ] , branch [ 1 ] ) , min_version ) NEW_LINE DEDENT except self . errors . ConfigurationError : NEW_LINE INDENT find_valac ( self , ' valac ' , min_version ) NEW_LINE DEDENT DEDENT @ conf NEW_LINE def check_vala_deps ( self ) : NEW_LINE INDENT if not self . env [ ' HAVE _ GOBJECT ' ] : NEW_LINE INDENT pkg_args = { ' package ' : ' gobject - 2.0' , ' uselib _ store ' : ' GOBJECT ' , ' args ' : ' - - cflags ▁ - - libs ' } NEW_LINE if getattr ( Options . options , ' vala _ target _ glib ' , None ) : NEW_LINE INDENT pkg_args [ ' atleast _ version ' ] = Options . options . vala_target_glib NEW_LINE DEDENT self . check_cfg ( ** pkg_args ) NEW_LINE DEDENT if not self . env [ ' HAVE _ GTHREAD ' ] : NEW_LINE INDENT pkg_args = { ' package ' : ' gthread - 2.0' , ' uselib _ store ' : ' GTHREAD ' , ' args ' : ' - - cflags ▁ - - libs ' } NEW_LINE if getattr ( Options . options , ' vala _ target _ glib ' , None ) : NEW_LINE INDENT pkg_args [ ' atleast _ version ' ] = Options . options . vala_target_glib NEW_LINE DEDENT self . check_cfg ( ** pkg_args ) NEW_LINE DEDENT DEDENT def configure ( self ) : NEW_LINE INDENT self . load ( ' gnu _ dirs ' ) NEW_LINE self . check_vala_deps ( ) NEW_LINE self . check_vala ( ) NEW_LINE self . env . VALAFLAGS = [ ' - C ' , ' - - quiet ' ] NEW_LINE DEDENT def options ( opt ) : NEW_LINE INDENT opt . load ( ' gnu _ dirs ' ) NEW_LINE valaopts = opt . add_option_group ( ' Vala ▁ Compiler ▁ Options ' ) NEW_LINE valaopts . add_option ( ' - - vala - target - glib ' , default = None , dest = ' vala _ target _ glib ' , metavar = ' MAJOR . MINOR ' , help = ' Target ▁ version ▁ of ▁ glib ▁ for ▁ Vala ▁ GObject ▁ code ▁ generation ' ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="Nirlendu/Dummy-Search-Engine/tree/master/tornado-3.2/build/lib.win32-2.7/tornado/wsgi.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Copyright ▁ 2009 ▁ Facebook ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM """ WSGI ▁ support ▁ for ▁ the ▁ Tornado ▁ web ▁ framework . STRNEWLINE STRNEWLINE WSGI ▁ is ▁ the ▁ Python ▁ standard ▁ for ▁ web ▁ servers , ▁ and ▁ allows ▁ for ▁ interoperability STRNEWLINE between ▁ Tornado ▁ and ▁ other ▁ Python ▁ web ▁ frameworks ▁ and ▁ servers . ▁ This ▁ module STRNEWLINE provides ▁ WSGI ▁ support ▁ in ▁ two ▁ ways : STRNEWLINE STRNEWLINE * ▁ ` WSGIApplication ` ▁ is ▁ a ▁ version ▁ of ▁ ` tornado . web . Application ` ▁ that ▁ can ▁ run STRNEWLINE ▁ inside ▁ a ▁ WSGI ▁ server . ▁ This ▁ is ▁ useful ▁ for ▁ running ▁ a ▁ Tornado ▁ app ▁ on ▁ another STRNEWLINE ▁ HTTP ▁ server , ▁ such ▁ as ▁ Google ▁ App ▁ Engine . ▁ See ▁ the ▁ ` WSGIApplication ` ▁ class STRNEWLINE ▁ documentation ▁ for ▁ limitations ▁ that ▁ apply . STRNEWLINE * ▁ ` WSGIContainer ` ▁ lets ▁ you ▁ run ▁ other ▁ WSGI ▁ applications ▁ and ▁ frameworks ▁ on ▁ the STRNEWLINE ▁ Tornado ▁ HTTP ▁ server . ▁ For ▁ example , ▁ with ▁ this ▁ class ▁ you ▁ can ▁ mix ▁ Django STRNEWLINE ▁ and ▁ Tornado ▁ handlers ▁ in ▁ a ▁ single ▁ server . STRNEWLINE """ NEW_LINE from __future__ import absolute_import , division , print_function , with_statement NEW_LINE import sys NEW_LINE import time NEW_LINE import copy NEW_LINE import tornado NEW_LINE from tornado import escape NEW_LINE from tornado import httputil NEW_LINE from tornado . log import access_log NEW_LINE from tornado import web NEW_LINE from tornado . escape import native_str , parse_qs_bytes NEW_LINE from tornado . util import bytes_type , unicode_type NEW_LINE try : NEW_LINE INDENT from io import BytesIO # ▁ python ▁ 3 ENDCOM NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from cStringIO import StringIO as BytesIO # ▁ python ▁ 2 ENDCOM NEW_LINE DEDENT try : NEW_LINE INDENT import Cookie # ▁ py2 ENDCOM NEW_LINE DEDENT except ImportError : NEW_LINE INDENT import http . cookies as Cookie # ▁ py3 ENDCOM NEW_LINE DEDENT try : NEW_LINE INDENT import urllib . parse as urllib_parse # ▁ py3 ENDCOM NEW_LINE DEDENT except ImportError : NEW_LINE INDENT import urllib as urllib_parse NEW_LINE # ▁ PEP ▁ 3333 ▁ specifies ▁ that ▁ WSGI ▁ on ▁ python ▁ 3 ▁ generally ▁ deals ▁ with ▁ byte ▁ strings ENDCOM # ▁ that ▁ are ▁ smuggled ▁ inside ▁ objects ▁ of ▁ type ▁ unicode ▁ ( via ▁ the ▁ latin1 ▁ encoding ) . ENDCOM # ▁ These ▁ functions ▁ are ▁ like ▁ those ▁ in ▁ the ▁ tornado . escape ▁ module , ▁ but ▁ defined ENDCOM # ▁ here ▁ to ▁ minimize ▁ the ▁ temptation ▁ to ▁ use ▁ them ▁ in ▁ non - wsgi ▁ contexts . ENDCOM DEDENT if str is unicode_type : NEW_LINE INDENT def to_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , bytes_type ) NEW_LINE return s . decode ( ' latin1' ) NEW_LINE DEDENT def from_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , str ) NEW_LINE return s . encode ( ' latin1' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def to_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , bytes_type ) NEW_LINE return s NEW_LINE DEDENT def from_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , str ) NEW_LINE return s NEW_LINE DEDENT DEDENT class WSGIApplication ( web . Application ) : NEW_LINE INDENT """ A ▁ WSGI ▁ equivalent ▁ of ▁ ` tornado . web . Application ` . STRNEWLINE STRNEWLINE ▁ ` WSGIApplication ` ▁ is ▁ very ▁ similar ▁ to ▁ ` tornado . web . Application ` , STRNEWLINE ▁ except ▁ no ▁ asynchronous ▁ methods ▁ are ▁ supported ▁ ( since ▁ WSGI ▁ does ▁ not STRNEWLINE ▁ support ▁ non - blocking ▁ requests ▁ properly ) . ▁ If ▁ you ▁ call STRNEWLINE ▁ ` ` self . flush ( ) ` ` ▁ or ▁ other ▁ asynchronous ▁ methods ▁ in ▁ your ▁ request STRNEWLINE ▁ handlers ▁ running ▁ in ▁ a ▁ ` WSGIApplication ` , ▁ we ▁ throw ▁ an ▁ exception . STRNEWLINE STRNEWLINE ▁ Example ▁ usage : : STRNEWLINE STRNEWLINE ▁ import ▁ tornado . web STRNEWLINE ▁ import ▁ tornado . wsgi STRNEWLINE ▁ import ▁ wsgiref . simple _ server STRNEWLINE STRNEWLINE ▁ class ▁ MainHandler ( tornado . web . RequestHandler ) : STRNEWLINE ▁ def ▁ get ( self ) : STRNEWLINE ▁ self . write ( " Hello , ▁ world " ) STRNEWLINE STRNEWLINE ▁ if ▁ _ _ name _ _ ▁ = = ▁ " _ _ main _ _ " : STRNEWLINE ▁ application ▁ = ▁ tornado . wsgi . WSGIApplication ( [ STRNEWLINE ▁ ( r " / " , ▁ MainHandler ) , STRNEWLINE ▁ ] ) STRNEWLINE ▁ server ▁ = ▁ wsgiref . simple _ server . make _ server ( ' ' , ▁ 8888 , ▁ application ) STRNEWLINE ▁ server . serve _ forever ( ) STRNEWLINE STRNEWLINE ▁ See ▁ the ▁ ` appengine ▁ demo STRNEWLINE ▁ < https : / / github . com / facebook / tornado / tree / master / demos / appengine > ` _ STRNEWLINE ▁ for ▁ an ▁ example ▁ of ▁ using ▁ this ▁ module ▁ to ▁ run ▁ a ▁ Tornado ▁ app ▁ on ▁ Google STRNEWLINE ▁ App ▁ Engine . STRNEWLINE STRNEWLINE ▁ WSGI ▁ applications ▁ use ▁ the ▁ same ▁ ` . RequestHandler ` ▁ class , ▁ but ▁ not STRNEWLINE ▁ ` ` @ asynchronous ` ` ▁ methods ▁ or ▁ ` ` flush ( ) ` ` . ▁ This ▁ means ▁ that ▁ it ▁ is STRNEWLINE ▁ not ▁ possible ▁ to ▁ use ▁ ` . AsyncHTTPClient ` , ▁ or ▁ the ▁ ` tornado . auth ` ▁ or STRNEWLINE ▁ ` tornado . websocket ` ▁ modules . STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , handlers = None , default_host = " " , ** settings ) : NEW_LINE INDENT web . Application . __init__ ( self , handlers , default_host , transforms = [ ] , wsgi = True , ** settings ) NEW_LINE DEDENT def __call__ ( self , environ , start_response ) : NEW_LINE INDENT handler = web . Application . __call__ ( self , HTTPRequest ( environ ) ) NEW_LINE assert handler . _finished NEW_LINE reason = handler . _reason NEW_LINE status = str ( handler . _status_code ) + " ▁ " + reason NEW_LINE headers = list ( handler . _headers . get_all ( ) ) NEW_LINE if hasattr ( handler , " _ new _ cookie " ) : NEW_LINE INDENT for cookie in handler . _new_cookie . values ( ) : NEW_LINE INDENT headers . append ( ( " Set - Cookie " , cookie . OutputString ( None ) ) ) NEW_LINE DEDENT DEDENT start_response ( status , [ ( native_str ( k ) , native_str ( v ) ) for ( k , v ) in headers ] ) NEW_LINE return handler . _write_buffer NEW_LINE DEDENT DEDENT class HTTPRequest ( object ) : NEW_LINE INDENT """ Mimics ▁ ` tornado . httpserver . HTTPRequest ` ▁ for ▁ WSGI ▁ applications . """ NEW_LINE def __init__ ( self , environ ) : NEW_LINE INDENT """ Parses ▁ the ▁ given ▁ WSGI ▁ environment ▁ to ▁ construct ▁ the ▁ request . """ NEW_LINE self . method = environ [ " REQUEST _ METHOD " ] NEW_LINE self . path = urllib_parse . quote ( from_wsgi_str ( environ . get ( " SCRIPT _ NAME " , " " ) ) ) NEW_LINE self . path += urllib_parse . quote ( from_wsgi_str ( environ . get ( " PATH _ INFO " , " " ) ) ) NEW_LINE self . uri = self . path NEW_LINE self . arguments = { } NEW_LINE self . query_arguments = { } NEW_LINE self . body_arguments = { } NEW_LINE self . query = environ . get ( " QUERY _ STRING " , " " ) NEW_LINE if self . query : NEW_LINE INDENT self . uri += " ? " + self . query NEW_LINE self . arguments = parse_qs_bytes ( native_str ( self . query ) , keep_blank_values = True ) NEW_LINE self . query_arguments = copy . deepcopy ( self . arguments ) NEW_LINE DEDENT self . version = " HTTP / 1.1" NEW_LINE self . headers = httputil . HTTPHeaders ( ) NEW_LINE if environ . get ( " CONTENT _ TYPE " ) : NEW_LINE INDENT self . headers [ " Content - Type " ] = environ [ " CONTENT _ TYPE " ] NEW_LINE DEDENT if environ . get ( " CONTENT _ LENGTH " ) : NEW_LINE INDENT self . headers [ " Content - Length " ] = environ [ " CONTENT _ LENGTH " ] NEW_LINE DEDENT for key in environ : NEW_LINE INDENT if key . startswith ( " HTTP _ " ) : NEW_LINE INDENT self . headers [ key [ 5 : ] . replace ( " _ " , " - " ) ] = environ [ key ] NEW_LINE DEDENT DEDENT if self . headers . get ( " Content - Length " ) : NEW_LINE INDENT self . body = environ [ " wsgi . input " ] . read ( int ( self . headers [ " Content - Length " ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . body = " " NEW_LINE DEDENT self . protocol = environ [ " wsgi . url _ scheme " ] NEW_LINE self . remote_ip = environ . get ( " REMOTE _ ADDR " , " " ) NEW_LINE if environ . get ( " HTTP _ HOST " ) : NEW_LINE INDENT self . host = environ [ " HTTP _ HOST " ] NEW_LINE DEDENT else : NEW_LINE INDENT self . host = environ [ " SERVER _ NAME " ] NEW_LINE # ▁ Parse ▁ request ▁ body ENDCOM DEDENT self . files = { } NEW_LINE httputil . parse_body_arguments ( self . headers . get ( " Content - Type " , " " ) , self . body , self . body_arguments , self . files ) NEW_LINE for k , v in self . body_arguments . items ( ) : NEW_LINE INDENT self . arguments . setdefault ( k , [ ] ) . extend ( v ) NEW_LINE DEDENT self . _start_time = time . time ( ) NEW_LINE self . _finish_time = None NEW_LINE DEDENT def supports_http_1_1 ( self ) : NEW_LINE INDENT """ Returns ▁ True ▁ if ▁ this ▁ request ▁ supports ▁ HTTP / 1.1 ▁ semantics """ NEW_LINE return self . version == " HTTP / 1.1" NEW_LINE DEDENT @ property NEW_LINE def cookies ( self ) : NEW_LINE INDENT """ A ▁ dictionary ▁ of ▁ Cookie . Morsel ▁ objects . """ NEW_LINE if not hasattr ( self , " _ cookies " ) : NEW_LINE INDENT self . _cookies = Cookie . SimpleCookie ( ) NEW_LINE if " Cookie " in self . headers : NEW_LINE INDENT try : NEW_LINE INDENT self . _cookies . load ( native_str ( self . headers [ " Cookie " ] ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT self . _cookies = None NEW_LINE DEDENT DEDENT DEDENT return self . _cookies NEW_LINE DEDENT def full_url ( self ) : NEW_LINE INDENT """ Reconstructs ▁ the ▁ full ▁ URL ▁ for ▁ this ▁ request . """ NEW_LINE return self . protocol + " : / / " + self . host + self . uri NEW_LINE DEDENT def request_time ( self ) : NEW_LINE INDENT """ Returns ▁ the ▁ amount ▁ of ▁ time ▁ it ▁ took ▁ for ▁ this ▁ request ▁ to ▁ execute . """ NEW_LINE if self . _finish_time is None : NEW_LINE INDENT return time . time ( ) - self . _start_time NEW_LINE DEDENT else : NEW_LINE INDENT return self . _finish_time - self . _start_time NEW_LINE DEDENT DEDENT DEDENT class WSGIContainer ( object ) : NEW_LINE INDENT r """ Makes ▁ a ▁ WSGI - compatible ▁ function ▁ runnable ▁ on ▁ Tornado ' s ▁ HTTP ▁ server . STRNEWLINE STRNEWLINE ▁ Wrap ▁ a ▁ WSGI ▁ function ▁ in ▁ a ▁ ` WSGIContainer ` ▁ and ▁ pass ▁ it ▁ to ▁ ` . HTTPServer ` ▁ to STRNEWLINE ▁ run ▁ it . ▁ For ▁ example : : STRNEWLINE STRNEWLINE ▁ def ▁ simple _ app ( environ , ▁ start _ response ) : STRNEWLINE ▁ status ▁ = ▁ " 200 ▁ OK " STRNEWLINE ▁ response _ headers ▁ = ▁ [ ( " Content - type " , ▁ " text / plain " ) ] STRNEWLINE ▁ start _ response ( status , ▁ response _ headers ) STRNEWLINE ▁ return ▁ [ " Hello ▁ world ! \n " ] STRNEWLINE STRNEWLINE ▁ container ▁ = ▁ tornado . wsgi . WSGIContainer ( simple _ app ) STRNEWLINE ▁ http _ server ▁ = ▁ tornado . httpserver . HTTPServer ( container ) STRNEWLINE ▁ http _ server . listen ( 8888 ) STRNEWLINE ▁ tornado . ioloop . IOLoop . instance ( ) . start ( ) STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ is ▁ intended ▁ to ▁ let ▁ other ▁ frameworks ▁ ( Django , ▁ web . py , ▁ etc ) STRNEWLINE ▁ run ▁ on ▁ the ▁ Tornado ▁ HTTP ▁ server ▁ and ▁ I / O ▁ loop . STRNEWLINE STRNEWLINE ▁ The ▁ ` tornado . web . FallbackHandler ` ▁ class ▁ is ▁ often ▁ useful ▁ for ▁ mixing STRNEWLINE ▁ Tornado ▁ and ▁ WSGI ▁ apps ▁ in ▁ the ▁ same ▁ server . ▁ See STRNEWLINE ▁ https : / / github . com / bdarnell / django - tornado - demo ▁ for ▁ a ▁ complete ▁ example . STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , wsgi_application ) : NEW_LINE INDENT self . wsgi_application = wsgi_application NEW_LINE DEDENT def __call__ ( self , request ) : NEW_LINE INDENT data = { } NEW_LINE response = [ ] NEW_LINE def start_response ( status , response_headers , exc_info = None ) : NEW_LINE INDENT data [ " status " ] = status NEW_LINE data [ " headers " ] = response_headers NEW_LINE return response . append NEW_LINE DEDENT app_response = self . wsgi_application ( WSGIContainer . environ ( request ) , start_response ) NEW_LINE try : NEW_LINE INDENT response . extend ( app_response ) NEW_LINE body = b " " . join ( response ) NEW_LINE DEDENT finally : NEW_LINE INDENT if hasattr ( app_response , " close " ) : NEW_LINE INDENT app_response . close ( ) NEW_LINE DEDENT DEDENT if not data : NEW_LINE INDENT raise Exception ( " WSGI ▁ app ▁ did ▁ not ▁ call ▁ start _ response " ) NEW_LINE DEDENT status_code = int ( data [ " status " ] . split ( ) [ 0 ] ) NEW_LINE headers = data [ " headers " ] NEW_LINE header_set = set ( k . lower ( ) for ( k , v ) in headers ) NEW_LINE body = escape . utf8 ( body ) NEW_LINE if status_code != 304 : NEW_LINE INDENT if " content - length " not in header_set : NEW_LINE INDENT headers . append ( ( " Content - Length " , str ( len ( body ) ) ) ) NEW_LINE DEDENT if " content - type " not in header_set : NEW_LINE INDENT headers . append ( ( " Content - Type " , " text / html ; ▁ charset = UTF - 8" ) ) NEW_LINE DEDENT DEDENT if " server " not in header_set : NEW_LINE INDENT headers . append ( ( " Server " , " TornadoServer / % s " % tornado . version ) ) NEW_LINE DEDENT parts = [ escape . utf8 ( " HTTP / 1.1 ▁ " + data [ " status " ] + " \n " ) ] NEW_LINE for key , value in headers : NEW_LINE INDENT parts . append ( escape . utf8 ( key ) + b " : ▁ " + escape . utf8 ( value ) + b " \n " ) NEW_LINE DEDENT parts . append ( b " \n " ) NEW_LINE parts . append ( body ) NEW_LINE request . write ( b " " . join ( parts ) ) NEW_LINE request . finish ( ) NEW_LINE self . _log ( status_code , request ) NEW_LINE DEDENT @ staticmethod NEW_LINE def environ ( request ) : NEW_LINE INDENT """ Converts ▁ a ▁ ` tornado . httpserver . HTTPRequest ` ▁ to ▁ a ▁ WSGI ▁ environment . STRNEWLINE ▁ """ NEW_LINE hostport = request . host . split ( " : " ) NEW_LINE if len ( hostport ) == 2 : NEW_LINE INDENT host = hostport [ 0 ] NEW_LINE port = int ( hostport [ 1 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT host = request . host NEW_LINE port = 443 if request . protocol == " https " else 80 NEW_LINE DEDENT environ = { " REQUEST _ METHOD " : request . method , " SCRIPT _ NAME " : " " , " PATH _ INFO " : to_wsgi_str ( escape . url_unescape ( request . path , encoding = None , plus = False ) ) , " QUERY _ STRING " : request . query , " REMOTE _ ADDR " : request . remote_ip , " SERVER _ NAME " : host , " SERVER _ PORT " : str ( port ) , " SERVER _ PROTOCOL " : request . version , " wsgi . version " : ( 1 , 0 ) , " wsgi . url _ scheme " : request . protocol , " wsgi . input " : BytesIO ( escape . utf8 ( request . body ) ) , " wsgi . errors " : sys . stderr , " wsgi . multithread " : False , " wsgi . multiprocess " : True , " wsgi . run _ once " : False , } NEW_LINE if " Content - Type " in request . headers : NEW_LINE INDENT environ [ " CONTENT _ TYPE " ] = request . headers . pop ( " Content - Type " ) NEW_LINE DEDENT if " Content - Length " in request . headers : NEW_LINE INDENT environ [ " CONTENT _ LENGTH " ] = request . headers . pop ( " Content - Length " ) NEW_LINE DEDENT for key , value in request . headers . items ( ) : NEW_LINE INDENT environ [ " HTTP _ " + key . replace ( " - " , " _ " ) . upper ( ) ] = value NEW_LINE DEDENT return environ NEW_LINE DEDENT def _log ( self , status_code , request ) : NEW_LINE INDENT if status_code < 400 : NEW_LINE INDENT log_method = access_log . info NEW_LINE DEDENT elif status_code < 500 : NEW_LINE INDENT log_method = access_log . warning NEW_LINE DEDENT else : NEW_LINE INDENT log_method = access_log . error NEW_LINE DEDENT request_time = 1000.0 * request . request_time ( ) NEW_LINE summary = request . method + " ▁ " + request . uri + " ▁ ( " + request . remote_ip + " ) " NEW_LINE log_method ( " % d ▁ % s ▁ % .2fms " , status_code , summary , request_time ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Affix/CouchPotatoServer/tree/master/couchpotato/core/media/_base/providers/torrent/sceneaccess.py"> import traceback NEW_LINE from bs4 import BeautifulSoup NEW_LINE from couchpotato . core . helpers . encoding import toUnicode NEW_LINE from couchpotato . core . helpers . variable import tryInt NEW_LINE from couchpotato . core . logger import CPLog NEW_LINE from couchpotato . core . media . _base . providers . torrent . base import TorrentProvider NEW_LINE log = CPLog ( __name__ ) NEW_LINE class Base ( TorrentProvider ) : NEW_LINE INDENT urls = { ' test ' : ' https : / / www . sceneaccess . eu / ' , ' login ' : ' https : / / www . sceneaccess . eu / login ' , ' login _ check ' : ' https : / / www . sceneaccess . eu / inbox ' , ' detail ' : ' https : / / www . sceneaccess . eu / details ? id = % s ' , ' search ' : ' https : / / www . sceneaccess . eu / browse ? c % d = % d ' , ' archive ' : ' https : / / www . sceneaccess . eu / archive ? & c % d = % d ' , ' download ' : ' https : / / www . sceneaccess . eu / % s ' , } NEW_LINE http_time_between_calls = 1 # ▁ Seconds ENDCOM NEW_LINE def _searchOnTitle ( self , title , media , quality , results ) : NEW_LINE INDENT url = self . buildUrl ( title , media , quality ) NEW_LINE data = self . getHTMLData ( url ) NEW_LINE if data : NEW_LINE INDENT html = BeautifulSoup ( data ) NEW_LINE try : NEW_LINE INDENT resultsTable = html . find ( ' table ' , attrs = { ' id ' : ' torrents - table ' } ) NEW_LINE if resultsTable is None : NEW_LINE INDENT return NEW_LINE DEDENT entries = resultsTable . find_all ( ' tr ' , attrs = { ' class ' : ' tt _ row ' } ) NEW_LINE for result in entries : NEW_LINE INDENT link = result . find ( ' td ' , attrs = { ' class ' : ' ttr _ name ' } ) . find ( ' a ' ) NEW_LINE url = result . find ( ' td ' , attrs = { ' class ' : ' td _ dl ' } ) . find ( ' a ' ) NEW_LINE leechers = result . find ( ' td ' , attrs = { ' class ' : ' ttr _ leechers ' } ) . find ( ' a ' ) NEW_LINE torrent_id = link [ ' href ' ] . replace ( ' details ? id = ' , ' ' ) NEW_LINE results . append ( { ' id ' : torrent_id , ' name ' : link [ ' title ' ] , ' url ' : self . urls [ ' download ' ] % url [ ' href ' ] , ' detail _ url ' : self . urls [ ' detail ' ] % torrent_id , ' size ' : self . parseSize ( result . find ( ' td ' , attrs = { ' class ' : ' ttr _ size ' } ) . contents [ 0 ] ) , ' seeders ' : tryInt ( result . find ( ' td ' , attrs = { ' class ' : ' ttr _ seeders ' } ) . find ( ' a ' ) . string ) , ' leechers ' : tryInt ( leechers . string ) if leechers else 0 , ' get _ more _ info ' : self . getMoreInfo , } ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT log . error ( ' Failed ▁ getting ▁ results ▁ from ▁ % s : ▁ % s ' , ( self . getName ( ) , traceback . format_exc ( ) ) ) NEW_LINE DEDENT DEDENT DEDENT def getMoreInfo ( self , item ) : NEW_LINE INDENT full_description = self . getCache ( ' sceneaccess . % s ' % item [ ' id ' ] , item [ ' detail _ url ' ] , cache_timeout = 25920000 ) NEW_LINE html = BeautifulSoup ( full_description ) NEW_LINE nfo_pre = html . find ( ' div ' , attrs = { ' id ' : ' details _ table ' } ) NEW_LINE description = toUnicode ( nfo_pre . text ) if nfo_pre else ' ' NEW_LINE item [ ' description ' ] = description NEW_LINE return item NEW_LINE # ▁ Login ENDCOM DEDENT def getLoginParams ( self ) : NEW_LINE INDENT return { ' username ' : self . conf ( ' username ' ) , ' password ' : self . conf ( ' password ' ) , ' submit ' : ' come ▁ on ▁ in ' , } NEW_LINE DEDENT def loginSuccess ( self , output ) : NEW_LINE INDENT return ' / inbox ' in output . lower ( ) NEW_LINE DEDENT loginCheckSuccess = loginSuccess NEW_LINE DEDENT config = [ { ' name ' : ' sceneaccess ' , ' groups ' : [ { ' tab ' : ' searcher ' , ' list ' : ' torrent _ providers ' , ' name ' : ' SceneAccess ' , ' description ' : ' < a ▁ href = " https : / / sceneaccess . eu / " > SceneAccess < / a > ' , ' wizard ' : True , ' icon ' : ' iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAABnRSTlMAAAAAAABupgeRAAACT0lEQVR4AYVQS0sbURidO3OTmajJ5FElTTOkPmZ01GhHrIq0aoWAj1Vc + A / cuRMXbl24V9SlCGqrLhVFCrooEhCp2BAx0mobTY2kaR7qmOm87EXL1EWxh29xL + c7nPMdgGHYO5bF / gdbefnr6WlbWRnxluMwAB4Z0uEgXa7nwaDL7 + / RNPzxbYvb / XJ0FBYVfd / ayh0fQ4qCGEHcm0KLRZUk7Pb2YRJPRwcsKMidnKD3t9VVT3s7BDh + z5FOZ3Vfn3h + Hltfx00mRRSRWFcUmmVNhYVqPn8dj3va2oh + txvcQRVF9ebm1fi4k + dRFbosY5rm4Hk7xxULQnJnx93S4g0EIEEQRoDLo6PrWEw8Pc0eHLwYGopMTDirqlJ7eyhYYGHhfgfHCcKYksZGVB / NcXI2mw6HhZERqrjYTNPHi4tFPh8aJIYIhgPlcCRDoZLW1s75 + Z / 7 + 59nZ / OJhLWigqAoKZX6Mjf3dXkZ3pydGYLc4aEoCCkInzQ1fRobS2xuvllaonkedfArnY5OTdGVldBkOADgqq2Nr6z8CIWaJietDHOhKB + HhwFKC6Gnq4ukKJvP9zcSbjYDXbeVlkKzuZBhnnV3e3t6UOmaJO0ODibW1hB1GYkg8R / gup7Z3TVZLJ5AILW9LcZiVpYtYBhw16O3t7cauckyeF9Tgz0ATpL2 + nopmWycmbnY2LiKRjFk6 / d7 + / vRJfl4HGzV1T0UIM43MGBvaIBWK / YvwM5w + IMgGH8tkyEgvIpE7M3Nt6qqZrNyOq1kMmouh455Ggz + BhKY4GEc2CfwAAAAAElFTkSuQmCC ' , ' options ' : [ { ' name ' : ' enabled ' , ' type ' : ' enabler ' , ' default ' : False , } , { ' name ' : ' username ' , ' default ' : ' ' , } , { ' name ' : ' password ' , ' default ' : ' ' , ' type ' : ' password ' , } , { ' name ' : ' seed _ ratio ' , ' label ' : ' Seed ▁ ratio ' , ' type ' : ' float ' , ' default ' : 1 , ' description ' : ' Will ▁ not ▁ be ▁ ( re ) moved ▁ until ▁ this ▁ seed ▁ ratio ▁ is ▁ met . ' , } , { ' name ' : ' seed _ time ' , ' label ' : ' Seed ▁ time ' , ' type ' : ' int ' , ' default ' : 40 , ' description ' : ' Will ▁ not ▁ be ▁ ( re ) moved ▁ until ▁ this ▁ seed ▁ time ▁ ( in ▁ hours ) ▁ is ▁ met . ' , } , { ' name ' : ' extra _ score ' , ' advanced ' : True , ' label ' : ' Extra ▁ Score ' , ' type ' : ' int ' , ' default ' : 20 , ' description ' : ' Starting ▁ score ▁ for ▁ each ▁ release ▁ found ▁ via ▁ this ▁ provider . ' , } ] , } , ] , } ] NEW_LINE </DOCUMENT>
<DOCUMENT_ID="carragom/modoboa/tree/master/modoboa/admin/models/domain_alias.py"> """ Models ▁ related ▁ to ▁ domain ▁ aliases ▁ management . """ NEW_LINE from django . db import models NEW_LINE from django . utils . encoding import python_2_unicode_compatible , smart_text NEW_LINE from django . utils . translation import ugettext as _ , ugettext_lazy NEW_LINE from django . contrib . contenttypes . fields import GenericRelation NEW_LINE from reversion import revisions as reversion NEW_LINE from modoboa . core import models as core_models NEW_LINE from modoboa . core import signals as core_signals NEW_LINE from modoboa . lib . exceptions import BadRequest , Conflict NEW_LINE from . base import AdminObject NEW_LINE from . domain import Domain NEW_LINE class DomainAliasManager ( models . Manager ) : NEW_LINE INDENT def get_for_admin ( self , admin ) : NEW_LINE INDENT """ Return ▁ the ▁ domain ▁ aliases ▁ belonging ▁ to ▁ this ▁ admin . STRNEWLINE STRNEWLINE ▁ The ▁ result ▁ is ▁ a ▁ ` ` QuerySet ` ` ▁ object , ▁ so ▁ this ▁ function ▁ can ▁ be ▁ used STRNEWLINE ▁ to ▁ fill ▁ ` ` ModelChoiceField ` ` ▁ objects . STRNEWLINE ▁ """ NEW_LINE if admin . is_superuser : NEW_LINE INDENT return self . get_queryset ( ) NEW_LINE DEDENT return self . get_queryset ( ) . filter ( owners__user = admin ) NEW_LINE DEDENT DEDENT @ python_2_unicode_compatible NEW_LINE class DomainAlias ( AdminObject ) : NEW_LINE INDENT """ Domain ▁ aliases . """ NEW_LINE name = models . CharField ( ugettext_lazy ( " name " ) , max_length = 100 , unique = True , help_text = ugettext_lazy ( " The ▁ alias ▁ name " ) ) NEW_LINE target = models . ForeignKey ( Domain , verbose_name = ugettext_lazy ( ' target ' ) , help_text = ugettext_lazy ( " The ▁ domain ▁ this ▁ alias ▁ points ▁ to " ) ) NEW_LINE enabled = models . BooleanField ( ugettext_lazy ( ' enabled ' ) , help_text = ugettext_lazy ( " Check ▁ to ▁ activate ▁ this ▁ alias " ) , default = True ) NEW_LINE owners = GenericRelation ( core_models . ObjectAccess ) NEW_LINE objects = DomainAliasManager ( ) NEW_LINE class Meta : NEW_LINE INDENT permissions = ( ( " view _ domaliases " , " View ▁ domain ▁ aliases " ) , ) NEW_LINE app_label = " admin " NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return smart_text ( self . name ) NEW_LINE DEDENT def from_csv ( self , user , row ) : NEW_LINE INDENT """ Create ▁ a ▁ domain ▁ alias ▁ from ▁ a ▁ CSV ▁ row STRNEWLINE STRNEWLINE ▁ Expected ▁ format : ▁ [ " domainalias " , ▁ domain ▁ alias ▁ name , ▁ targeted ▁ domain , ▁ enabled ] STRNEWLINE STRNEWLINE ▁ : param ▁ user : ▁ a ▁ ` ` User ` ` ▁ object STRNEWLINE ▁ : param ▁ row : ▁ a ▁ list ▁ containing ▁ the ▁ alias ▁ definition STRNEWLINE ▁ """ NEW_LINE if len ( row ) < 4 : NEW_LINE INDENT raise BadRequest ( _ ( " Invalid ▁ line " ) ) NEW_LINE DEDENT self . name = row [ 1 ] . strip ( ) NEW_LINE for model in [ DomainAlias , Domain ] : NEW_LINE INDENT if model . objects . filter ( name = self . name ) . exists ( ) : NEW_LINE INDENT raise Conflict NEW_LINE DEDENT DEDENT domname = row [ 2 ] . strip ( ) NEW_LINE try : NEW_LINE INDENT self . target = Domain . objects . get ( name = domname ) NEW_LINE DEDENT except Domain . DoesNotExist : NEW_LINE INDENT raise BadRequest ( _ ( " Unknown ▁ domain ▁ % s " ) % domname ) NEW_LINE DEDENT core_signals . can_create_object . send ( sender = " import " , context = self . target , object_type = " domain _ aliases " ) NEW_LINE self . enabled = row [ 3 ] . strip ( ) in [ " True " , "1" , " yes " , " y " ] NEW_LINE self . save ( creator = user ) NEW_LINE DEDENT def to_csv ( self , csvwriter ) : NEW_LINE INDENT """ Export ▁ a ▁ domain ▁ alias ▁ using ▁ CSV ▁ format STRNEWLINE STRNEWLINE ▁ : param ▁ csvwriter : ▁ a ▁ ` ` csv . writer ` ` ▁ object STRNEWLINE ▁ """ NEW_LINE csvwriter . writerow ( [ " domainalias " , self . name , self . target . name , self . enabled ] ) NEW_LINE DEDENT DEDENT reversion . register ( DomainAlias ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="doublebits/osf.io/tree/master/admin_tests/factories.py"> import factory NEW_LINE from admin . common_auth . models import MyUser NEW_LINE class UserFactory ( factory . Factory ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT model = MyUser NEW_LINE DEDENT id = 123 NEW_LINE email = ' cello @ email . org ' NEW_LINE first_name = ' Yo - yo ' NEW_LINE last_name = ' Ma ' NEW_LINE osf_id = ' abc12' NEW_LINE @ classmethod NEW_LINE def is_in_group ( cls , value ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="40223205/w16b_test-/tree/master/static/Brython3.1.1-20150328-091302/Lib/_socket.py"> """ Implementation ▁ module ▁ for ▁ socket ▁ operations . STRNEWLINE STRNEWLINE See ▁ the ▁ socket ▁ module ▁ for ▁ documentation . """ NEW_LINE AF_APPLETALK = 16 NEW_LINE AF_DECnet = 12 NEW_LINE AF_INET = 2 NEW_LINE AF_INET6 = 23 NEW_LINE AF_IPX = 6 NEW_LINE AF_IRDA = 26 NEW_LINE AF_SNA = 11 NEW_LINE AF_UNSPEC = 0 NEW_LINE AI_ADDRCONFIG = 1024 NEW_LINE AI_ALL = 256 NEW_LINE AI_CANONNAME = 2 NEW_LINE AI_NUMERICHOST = 4 NEW_LINE AI_NUMERICSERV = 8 NEW_LINE AI_PASSIVE = 1 NEW_LINE AI_V4MAPPED = 2048 NEW_LINE CAPI = ' < capsule ▁ object ▁ " _ socket . CAPI " ▁ at ▁ 0x00BC4F38 > ' NEW_LINE EAI_AGAIN = 11002 NEW_LINE EAI_BADFLAGS = 10022 NEW_LINE EAI_FAIL = 11003 NEW_LINE EAI_FAMILY = 10047 NEW_LINE EAI_MEMORY = 8 NEW_LINE EAI_NODATA = 11001 NEW_LINE EAI_NONAME = 11001 NEW_LINE EAI_SERVICE = 10109 NEW_LINE EAI_SOCKTYPE = 10044 NEW_LINE INADDR_ALLHOSTS_GROUP = - 536870911 NEW_LINE INADDR_ANY = 0 NEW_LINE INADDR_BROADCAST = - 1 NEW_LINE INADDR_LOOPBACK = 2130706433 NEW_LINE INADDR_MAX_LOCAL_GROUP = - 536870657 NEW_LINE INADDR_NONE = - 1 NEW_LINE INADDR_UNSPEC_GROUP = - 536870912 NEW_LINE IPPORT_RESERVED = 1024 NEW_LINE IPPORT_USERRESERVED = 5000 NEW_LINE IPPROTO_ICMP = 1 NEW_LINE IPPROTO_IP = 0 NEW_LINE IPPROTO_RAW = 255 NEW_LINE IPPROTO_TCP = 6 NEW_LINE IPPROTO_UDP = 17 NEW_LINE IPV6_CHECKSUM = 26 NEW_LINE IPV6_DONTFRAG = 14 NEW_LINE IPV6_HOPLIMIT = 21 NEW_LINE IPV6_HOPOPTS = 1 NEW_LINE IPV6_JOIN_GROUP = 12 NEW_LINE IPV6_LEAVE_GROUP = 13 NEW_LINE IPV6_MULTICAST_HOPS = 10 NEW_LINE IPV6_MULTICAST_IF = 9 NEW_LINE IPV6_MULTICAST_LOOP = 11 NEW_LINE IPV6_PKTINFO = 19 NEW_LINE IPV6_RECVRTHDR = 38 NEW_LINE IPV6_RECVTCLASS = 40 NEW_LINE IPV6_RTHDR = 32 NEW_LINE IPV6_TCLASS = 39 NEW_LINE IPV6_UNICAST_HOPS = 4 NEW_LINE IPV6_V6ONLY = 27 NEW_LINE IP_ADD_MEMBERSHIP = 12 NEW_LINE IP_DROP_MEMBERSHIP = 13 NEW_LINE IP_HDRINCL = 2 NEW_LINE IP_MULTICAST_IF = 9 NEW_LINE IP_MULTICAST_LOOP = 11 NEW_LINE IP_MULTICAST_TTL = 10 NEW_LINE IP_OPTIONS = 1 NEW_LINE IP_RECVDSTADDR = 25 NEW_LINE IP_TOS = 3 NEW_LINE IP_TTL = 4 NEW_LINE MSG_BCAST = 1024 NEW_LINE MSG_CTRUNC = 512 NEW_LINE MSG_DONTROUTE = 4 NEW_LINE MSG_MCAST = 2048 NEW_LINE MSG_OOB = 1 NEW_LINE MSG_PEEK = 2 NEW_LINE MSG_TRUNC = 256 NEW_LINE NI_DGRAM = 16 NEW_LINE NI_MAXHOST = 1025 NEW_LINE NI_MAXSERV = 32 NEW_LINE NI_NAMEREQD = 4 NEW_LINE NI_NOFQDN = 1 NEW_LINE NI_NUMERICHOST = 2 NEW_LINE NI_NUMERICSERV = 8 NEW_LINE RCVALL_MAX = 3 NEW_LINE RCVALL_OFF = 0 NEW_LINE RCVALL_ON = 1 NEW_LINE RCVALL_SOCKETLEVELONLY = 2 NEW_LINE SHUT_RD = 0 NEW_LINE SHUT_RDWR = 2 NEW_LINE SHUT_WR = 1 NEW_LINE SIO_KEEPALIVE_VALS = 2550136836 NEW_LINE SIO_RCVALL = 2550136833 NEW_LINE SOCK_DGRAM = 2 NEW_LINE SOCK_RAW = 3 NEW_LINE SOCK_RDM = 4 NEW_LINE SOCK_SEQPACKET = 5 NEW_LINE SOCK_STREAM = 1 NEW_LINE SOL_IP = 0 NEW_LINE SOL_SOCKET = 65535 NEW_LINE SOL_TCP = 6 NEW_LINE SOL_UDP = 17 NEW_LINE SOMAXCONN = 2147483647 NEW_LINE SO_ACCEPTCONN = 2 NEW_LINE SO_BROADCAST = 32 NEW_LINE SO_DEBUG = 1 NEW_LINE SO_DONTROUTE = 16 NEW_LINE SO_ERROR = 4103 NEW_LINE SO_EXCLUSIVEADDRUSE = - 5 NEW_LINE SO_KEEPALIVE = 8 NEW_LINE SO_LINGER = 128 NEW_LINE SO_OOBINLINE = 256 NEW_LINE SO_RCVBUF = 4098 NEW_LINE SO_RCVLOWAT = 4100 NEW_LINE SO_RCVTIMEO = 4102 NEW_LINE SO_REUSEADDR = 4 NEW_LINE SO_SNDBUF = 4097 NEW_LINE SO_SNDLOWAT = 4099 NEW_LINE SO_SNDTIMEO = 4101 NEW_LINE SO_TYPE = 4104 NEW_LINE SO_USELOOPBACK = 64 NEW_LINE class SocketType : NEW_LINE INDENT pass NEW_LINE DEDENT TCP_MAXSEG = 4 NEW_LINE TCP_NODELAY = 1 NEW_LINE __loader__ = ' < _ frozen _ importlib . ExtensionFileLoader ▁ object ▁ at ▁ 0x00CA2D90 > ' NEW_LINE def dup ( * args , ** kw ) : NEW_LINE INDENT """ dup ( integer ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Duplicate ▁ an ▁ integer ▁ socket ▁ file ▁ descriptor . ▁ This ▁ is ▁ like ▁ os . dup ( ) , ▁ but ▁ for STRNEWLINE ▁ sockets ; ▁ on ▁ some ▁ platforms ▁ os . dup ( ) ▁ won ' t ▁ work ▁ for ▁ socket ▁ file ▁ descriptors . """ NEW_LINE pass NEW_LINE DEDENT class error : NEW_LINE INDENT pass NEW_LINE DEDENT class gaierror : NEW_LINE INDENT pass NEW_LINE DEDENT def getaddrinfo ( * args , ** kw ) : NEW_LINE INDENT """ getaddrinfo ( host , ▁ port ▁ [ , ▁ family , ▁ socktype , ▁ proto , ▁ flags ] ) ▁ - > ▁ list ▁ of ▁ ( family , ▁ socktype , ▁ proto , ▁ canonname , ▁ sockaddr ) STRNEWLINE ▁ STRNEWLINE ▁ Resolve ▁ host ▁ and ▁ port ▁ into ▁ addrinfo ▁ struct . """ NEW_LINE pass NEW_LINE DEDENT def getdefaulttimeout ( * args , ** kw ) : NEW_LINE INDENT """ getdefaulttimeout ( ) ▁ - > ▁ timeout ▁ STRNEWLINE ▁ Returns ▁ the ▁ default ▁ timeout ▁ in ▁ seconds ▁ ( float ) ▁ for ▁ new ▁ socket ▁ objects . STRNEWLINE ▁ A ▁ value ▁ of ▁ None ▁ indicates ▁ that ▁ new ▁ socket ▁ objects ▁ have ▁ no ▁ timeout . STRNEWLINE ▁ When ▁ the ▁ socket ▁ module ▁ is ▁ first ▁ imported , ▁ the ▁ default ▁ is ▁ None . """ NEW_LINE pass NEW_LINE DEDENT def gethostbyaddr ( * args , ** kw ) : NEW_LINE INDENT """ gethostbyaddr ( host ) ▁ - > ▁ ( name , ▁ aliaslist , ▁ addresslist ) ▁ STRNEWLINE ▁ Return ▁ the ▁ true ▁ host ▁ name , ▁ a ▁ list ▁ of ▁ aliases , ▁ and ▁ a ▁ list ▁ of ▁ IP ▁ addresses , STRNEWLINE ▁ for ▁ a ▁ host . ▁ The ▁ host ▁ argument ▁ is ▁ a ▁ string ▁ giving ▁ a ▁ host ▁ name ▁ or ▁ IP ▁ number . """ NEW_LINE pass NEW_LINE DEDENT def gethostbyname ( * args , ** kw ) : NEW_LINE INDENT """ gethostbyname ( host ) ▁ - > ▁ address ▁ STRNEWLINE ▁ Return ▁ the ▁ IP ▁ address ▁ ( a ▁ string ▁ of ▁ the ▁ form ▁ ' 255.255.255.255 ' ) ▁ for ▁ a ▁ host . """ NEW_LINE pass NEW_LINE DEDENT def gethostbyname_ex ( * args , ** kw ) : NEW_LINE INDENT """ gethostbyname _ ex ( host ) ▁ - > ▁ ( name , ▁ aliaslist , ▁ addresslist ) ▁ STRNEWLINE ▁ Return ▁ the ▁ true ▁ host ▁ name , ▁ a ▁ list ▁ of ▁ aliases , ▁ and ▁ a ▁ list ▁ of ▁ IP ▁ addresses , STRNEWLINE ▁ for ▁ a ▁ host . ▁ The ▁ host ▁ argument ▁ is ▁ a ▁ string ▁ giving ▁ a ▁ host ▁ name ▁ or ▁ IP ▁ number . """ NEW_LINE pass NEW_LINE DEDENT def gethostname ( * args , ** kw ) : NEW_LINE INDENT """ gethostname ( ) ▁ - > ▁ string ▁ STRNEWLINE ▁ Return ▁ the ▁ current ▁ host ▁ name . """ NEW_LINE pass NEW_LINE DEDENT def getnameinfo ( * args , ** kw ) : NEW_LINE INDENT """ getnameinfo ( sockaddr , ▁ flags ) ▁ - - > ▁ ( host , ▁ port ) ▁ STRNEWLINE ▁ Get ▁ host ▁ and ▁ port ▁ for ▁ a ▁ sockaddr . """ NEW_LINE pass NEW_LINE DEDENT def getprotobyname ( * args , ** kw ) : NEW_LINE INDENT """ getprotobyname ( name ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Return ▁ the ▁ protocol ▁ number ▁ for ▁ the ▁ named ▁ protocol . ▁ ( Rarely ▁ used . ) """ NEW_LINE pass NEW_LINE DEDENT def getservbyname ( * args , ** kw ) : NEW_LINE INDENT """ getservbyname ( servicename [ , ▁ protocolname ] ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Return ▁ a ▁ port ▁ number ▁ from ▁ a ▁ service ▁ name ▁ and ▁ protocol ▁ name . STRNEWLINE ▁ The ▁ optional ▁ protocol ▁ name , ▁ if ▁ given , ▁ should ▁ be ▁ ' tcp ' ▁ or ▁ ' udp ' , STRNEWLINE ▁ otherwise ▁ any ▁ protocol ▁ will ▁ match . """ NEW_LINE pass NEW_LINE DEDENT def getservbyport ( * args , ** kw ) : NEW_LINE INDENT """ getservbyport ( port [ , ▁ protocolname ] ) ▁ - > ▁ string ▁ STRNEWLINE ▁ Return ▁ the ▁ service ▁ name ▁ from ▁ a ▁ port ▁ number ▁ and ▁ protocol ▁ name . STRNEWLINE ▁ The ▁ optional ▁ protocol ▁ name , ▁ if ▁ given , ▁ should ▁ be ▁ ' tcp ' ▁ or ▁ ' udp ' , STRNEWLINE ▁ otherwise ▁ any ▁ protocol ▁ will ▁ match . """ NEW_LINE pass NEW_LINE DEDENT has_ipv6 = True NEW_LINE class herror : NEW_LINE INDENT pass NEW_LINE DEDENT def htonl ( * args , ** kw ) : NEW_LINE INDENT """ htonl ( integer ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Convert ▁ a ▁ 32 - bit ▁ integer ▁ from ▁ host ▁ to ▁ network ▁ byte ▁ order . """ NEW_LINE pass NEW_LINE DEDENT def htons ( * args , ** kw ) : NEW_LINE INDENT """ htons ( integer ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Convert ▁ a ▁ 16 - bit ▁ integer ▁ from ▁ host ▁ to ▁ network ▁ byte ▁ order . """ NEW_LINE pass NEW_LINE DEDENT def inet_aton ( * args , ** kw ) : NEW_LINE INDENT """ inet _ aton ( string ) ▁ - > ▁ bytes ▁ giving ▁ packed ▁ 32 - bit ▁ IP ▁ representation ▁ STRNEWLINE ▁ Convert ▁ an ▁ IP ▁ address ▁ in ▁ string ▁ format ▁ ( 123.45.67.89 ) ▁ to ▁ the ▁ 32 - bit ▁ packed STRNEWLINE ▁ binary ▁ format ▁ used ▁ in ▁ low - level ▁ network ▁ functions . """ NEW_LINE pass NEW_LINE DEDENT def inet_ntoa ( * args , ** kw ) : NEW_LINE INDENT """ inet _ ntoa ( packed _ ip ) ▁ - > ▁ ip _ address _ string ▁ STRNEWLINE ▁ Convert ▁ an ▁ IP ▁ address ▁ from ▁ 32 - bit ▁ packed ▁ binary ▁ format ▁ to ▁ string ▁ format """ NEW_LINE pass NEW_LINE DEDENT def ntohl ( * args , ** kw ) : NEW_LINE INDENT """ ntohl ( integer ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Convert ▁ a ▁ 32 - bit ▁ integer ▁ from ▁ network ▁ to ▁ host ▁ byte ▁ order . """ NEW_LINE pass NEW_LINE DEDENT def ntohs ( * args , ** kw ) : NEW_LINE INDENT """ ntohs ( integer ) ▁ - > ▁ integer ▁ STRNEWLINE ▁ Convert ▁ a ▁ 16 - bit ▁ integer ▁ from ▁ network ▁ to ▁ host ▁ byte ▁ order . """ NEW_LINE pass NEW_LINE DEDENT def setdefaulttimeout ( * args , ** kw ) : NEW_LINE INDENT """ setdefaulttimeout ( timeout ) ▁ STRNEWLINE ▁ Set ▁ the ▁ default ▁ timeout ▁ in ▁ seconds ▁ ( float ) ▁ for ▁ new ▁ socket ▁ objects . STRNEWLINE ▁ A ▁ value ▁ of ▁ None ▁ indicates ▁ that ▁ new ▁ socket ▁ objects ▁ have ▁ no ▁ timeout . STRNEWLINE ▁ When ▁ the ▁ socket ▁ module ▁ is ▁ first ▁ imported , ▁ the ▁ default ▁ is ▁ None . """ NEW_LINE pass NEW_LINE DEDENT class socket : NEW_LINE INDENT def __init__ ( self , * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def bind ( self , * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def close ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class timeout : NEW_LINE INDENT pass NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="glaubitz/fs-uae-debian/tree/master/launcher/launcher/game_paths.py"> import os NEW_LINE import fsui NEW_LINE from fsbc . paths import Paths NEW_LINE from fsgs . FSGSDirectories import FSGSDirectories NEW_LINE from . launcher_config import LauncherConfig NEW_LINE from . launcher_settings import LauncherSettings NEW_LINE from . ui . Constants import Constants NEW_LINE class GamePaths ( object ) : NEW_LINE INDENT @ staticmethod NEW_LINE def current ( ) : NEW_LINE INDENT model = LauncherConfig . get ( " amiga _ model " ) NEW_LINE if model . startswith ( " CD32" ) : NEW_LINE INDENT platform = " CD32" NEW_LINE DEDENT elif model == " CDTV " : NEW_LINE INDENT platform = " CDTV " NEW_LINE DEDENT else : NEW_LINE INDENT platform = " Amiga " NEW_LINE DEDENT name = LauncherSettings . get ( " config _ name " ) NEW_LINE uuid = LauncherConfig . get ( " x _ game _ uuid " ) NEW_LINE return GamePaths ( name , platform , uuid ) NEW_LINE DEDENT def __init__ ( self , name , platform , uuid ) : NEW_LINE INDENT self . uuid = uuid NEW_LINE self . config_name = name NEW_LINE if " ( " in name : NEW_LINE INDENT parts = name . split ( " ( " , 1 ) NEW_LINE self . name , self . variant = parts NEW_LINE self . name = self . name . strip ( ) NEW_LINE self . variant = self . variant . strip ( ) NEW_LINE if self . variant . endswith ( " ) " ) : NEW_LINE INDENT self . variant = self . variant [ : - 1 ] NEW_LINE DEDENT self . variant = self . variant . replace ( " ) ▁ ( " , " , ▁ " ) NEW_LINE self . variant = self . variant . replace ( " ) ( " , " , ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . name = name NEW_LINE self . variant = " " NEW_LINE DEDENT self . platform = platform NEW_LINE DEDENT def get_name ( self ) : NEW_LINE INDENT return self . name NEW_LINE DEDENT def get_variant ( self ) : NEW_LINE INDENT return self . variant NEW_LINE DEDENT @ staticmethod NEW_LINE def get_override_path ( name ) : NEW_LINE INDENT path = LauncherConfig . get ( name ) NEW_LINE if not path : NEW_LINE INDENT return " " NEW_LINE DEDENT path = Paths . expand_path ( path ) NEW_LINE return path NEW_LINE DEDENT def get_screenshot_path ( self , number ) : NEW_LINE INDENT if number == 0 : NEW_LINE INDENT sha1 = LauncherConfig . get ( " title _ sha1" ) NEW_LINE DEDENT else : NEW_LINE INDENT sha1 = LauncherConfig . get ( " screen { 0 } _ sha1" . format ( number ) ) NEW_LINE DEDENT if sha1 : NEW_LINE INDENT return " sha1 : " + sha1 NEW_LINE DEDENT if number == 0 : NEW_LINE INDENT path = self . get_override_path ( " title _ image " ) NEW_LINE DEDENT else : NEW_LINE INDENT path = self . get_override_path ( " screen { 0 } _ image " . format ( number ) ) NEW_LINE DEDENT if path and os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT if self . uuid : NEW_LINE INDENT if number == 0 : NEW_LINE INDENT name = " title . png " NEW_LINE DEDENT else : NEW_LINE INDENT name = " screen { 0 } . png " . format ( number ) NEW_LINE DEDENT paths = FSGSDirectories . get_images_dirs ( ) NEW_LINE for dir_ in paths : NEW_LINE INDENT p = os . path . join ( dir_ , self . platform , " Images " , self . uuid [ : 2 ] , self . uuid , name ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT p = os . path . join ( dir_ , self . platform , " Thumbnails " , self . uuid [ : 2 ] , self . uuid , name ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT DEDENT DEDENT letter = self . get_letter ( self . name ) NEW_LINE if not letter : NEW_LINE INDENT return None NEW_LINE DEDENT name = self . name NEW_LINE if number == 0 : NEW_LINE INDENT override_dir = LauncherConfig . get ( " titles _ dir " ) NEW_LINE if override_dir : NEW_LINE INDENT paths = [ Paths . expand_path ( override_dir ) ] NEW_LINE DEDENT else : NEW_LINE INDENT paths = FSGSDirectories . get_titles_dirs ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT override_dir = LauncherConfig . get ( " screenshots _ dir " ) NEW_LINE if override_dir : NEW_LINE INDENT paths = [ Paths . expand_path ( override_dir ) ] NEW_LINE DEDENT else : NEW_LINE INDENT paths = FSGSDirectories . get_screenshots_dirs ( ) NEW_LINE DEDENT DEDENT if number >= 2 : NEW_LINE INDENT name = " { 0 } _ {1 } " . format ( name , number ) NEW_LINE DEDENT for dir_ in paths : NEW_LINE INDENT path = os . path . join ( dir_ , letter , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , letter , name + " . gif " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , letter , name + " . gif " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def load_screenshot ( self , number ) : NEW_LINE INDENT path = self . get_screenshot_path ( number ) NEW_LINE if path : NEW_LINE INDENT return fsui . Image ( path ) NEW_LINE DEDENT DEDENT def load_screenshot_preview ( self , number ) : NEW_LINE INDENT image = self . load_screenshot ( number ) NEW_LINE if image is None : NEW_LINE INDENT return image NEW_LINE DEDENT if image . size == Constants . SCREEN_SIZE : NEW_LINE INDENT return image NEW_LINE DEDENT if image . size [ 0 ] < 400 : NEW_LINE INDENT image . resize ( ( image . size [ 0 ] * 2 , image . size [ 1 ] * 2 ) , fsui . Image . NEAREST ) NEW_LINE DEDENT image . resize ( Constants . SCREEN_SIZE ) NEW_LINE return image NEW_LINE DEDENT def get_cover_path ( self ) : NEW_LINE INDENT sha1 = LauncherConfig . get ( " front _ sha1" ) NEW_LINE if sha1 : NEW_LINE INDENT return " sha1 : " + sha1 NEW_LINE DEDENT path = self . get_override_path ( " cover _ image " ) NEW_LINE if path and os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT if self . uuid : NEW_LINE INDENT paths = FSGSDirectories . get_images_dirs ( ) NEW_LINE for dir_ in paths : NEW_LINE INDENT p = os . path . join ( dir_ , self . platform , " Images " , self . uuid [ : 2 ] , self . uuid , " front . png " ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT p = os . path . join ( dir_ , self . platform , " Thumbnails " , self . uuid [ : 2 ] , self . uuid , " front . png " ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT DEDENT DEDENT letter = self . get_letter ( self . name ) NEW_LINE if not letter : NEW_LINE INDENT return None NEW_LINE DEDENT name = self . name NEW_LINE override_dir = LauncherConfig . get ( " covers _ dir " ) NEW_LINE if override_dir : NEW_LINE INDENT paths = [ Paths . expand_path ( override_dir ) ] NEW_LINE DEDENT else : NEW_LINE INDENT paths = FSGSDirectories . get_covers_dirs ( ) NEW_LINE DEDENT for dir_ in paths : NEW_LINE INDENT path = os . path . join ( dir_ , letter , name + " . jpg " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , letter , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , name + " . jpg " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def load_cover ( self ) : NEW_LINE INDENT path = self . get_cover_path ( ) NEW_LINE print ( path ) NEW_LINE if path : NEW_LINE INDENT return fsui . Image ( path ) NEW_LINE DEDENT DEDENT def load_cover_preview ( self ) : NEW_LINE INDENT image = self . load_cover ( ) NEW_LINE if image is None : NEW_LINE INDENT return image NEW_LINE DEDENT image . resize ( Constants . COVER_SIZE ) NEW_LINE return image NEW_LINE DEDENT def get_theme_path ( self ) : NEW_LINE INDENT letter = self . get_letter ( self . name ) NEW_LINE if not letter : NEW_LINE INDENT return None NEW_LINE DEDENT paths = FSGSDirectories . get_themes_dirs ( ) NEW_LINE for dir_ in paths : NEW_LINE INDENT path = os . path . join ( dir_ , letter , self . name ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def _get_state_dir ( self ) : NEW_LINE INDENT config_name = self . config_name NEW_LINE if not config_name : NEW_LINE INDENT config_name = " Default " NEW_LINE # ▁ use ▁ a ▁ temporary ▁ state ▁ dir , ▁ for ▁ now , ▁ to ▁ avoid ▁ problems ▁ with ENDCOM # ▁ floppy ▁ overlays ▁ etc ▁ interfering ▁ with ▁ net ▁ play ENDCOM DEDENT from . netplay . netplay import Netplay NEW_LINE if Netplay . current ( ) : NEW_LINE # ▁ it ▁ is ▁ possible ▁ to ▁ manually ▁ specify ▁ the ▁ state ▁ dir ENDCOM INDENT config_name = LauncherConfig . get ( " _ _ netplay _ state _ dir _ name " ) NEW_LINE if not config_name : NEW_LINE # ▁ this ▁ is ▁ the ▁ default ▁ behavior , ▁ create ▁ a ▁ clean ▁ state ENDCOM # ▁ dir ▁ for ▁ the ▁ net ▁ play ▁ session ENDCOM INDENT netplay_game = LauncherConfig . get ( " _ _ netplay _ game " ) NEW_LINE if netplay_game : NEW_LINE INDENT config_name = " Net ▁ Play ▁ ( {0 } ) " . format ( netplay_game ) NEW_LINE DEDENT DEDENT DEDENT letter = self . get_letter ( config_name ) NEW_LINE if not letter : NEW_LINE INDENT config_name = " Default " NEW_LINE letter = self . get_letter ( config_name ) NEW_LINE # ▁ we ▁ use ▁ an ▁ existing ▁ state ▁ dir ▁ in ▁ a ▁ " letter " ▁ dir ▁ if ▁ it ▁ exists ENDCOM # ▁ ( legacy ▁ support ) . ENDCOM DEDENT path = os . path . join ( FSGSDirectories . get_save_states_dir ( ) , letter , config_name ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE # ▁ if ▁ not , ▁ we ▁ use ▁ a ▁ direct ▁ sub - folder ▁ of ▁ save ▁ states ▁ dir ENDCOM DEDENT path = os . path . join ( FSGSDirectories . get_save_states_dir ( ) , config_name ) NEW_LINE return path NEW_LINE DEDENT def get_state_dir ( self ) : NEW_LINE INDENT state_dir = self . _get_state_dir ( ) NEW_LINE if not os . path . exists ( state_dir ) : NEW_LINE INDENT os . makedirs ( state_dir ) NEW_LINE DEDENT return state_dir NEW_LINE DEDENT @ staticmethod NEW_LINE def get_letter ( name ) : NEW_LINE INDENT letter_name = name . upper ( ) NEW_LINE if letter_name . startswith ( " THE ▁ " ) : NEW_LINE INDENT letter_name = letter_name [ 4 : ] NEW_LINE DEDENT if letter_name . startswith ( " A ▁ " ) : NEW_LINE INDENT letter_name = letter_name [ 2 : ] NEW_LINE DEDENT for i in range ( len ( letter_name ) ) : NEW_LINE INDENT letter = letter_name [ i ] NEW_LINE if letter in "01234567890" : NEW_LINE INDENT letter = "0" NEW_LINE break NEW_LINE DEDENT if letter in " ABCDEFGHIJKLMNOPQRSTUVWXYZ " : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT return letter NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="bollu/sandhi/tree/master/modules/gr36/grc/gui/Connection.py"> """ STRNEWLINE Copyright ▁ 2007 , ▁ 2008 , ▁ 2009 ▁ Free ▁ Software ▁ Foundation , ▁ Inc . STRNEWLINE This ▁ file ▁ is ▁ part ▁ of ▁ GNU ▁ Radio STRNEWLINE STRNEWLINE GNU ▁ Radio ▁ Companion ▁ is ▁ free ▁ software ; ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or STRNEWLINE modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License STRNEWLINE as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation ; ▁ either ▁ version ▁ 2 STRNEWLINE of ▁ the ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . STRNEWLINE STRNEWLINE GNU ▁ Radio ▁ Companion ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , STRNEWLINE but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of STRNEWLINE MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the STRNEWLINE GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . STRNEWLINE STRNEWLINE You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License STRNEWLINE along ▁ with ▁ this ▁ program ; ▁ if ▁ not , ▁ write ▁ to ▁ the ▁ Free ▁ Software STRNEWLINE Foundation , ▁ Inc . , ▁ 51 ▁ Franklin ▁ Street , ▁ Fifth ▁ Floor , ▁ Boston , ▁ MA ▁ 02110-1301 , ▁ USA STRNEWLINE """ NEW_LINE import Utils NEW_LINE from Element import Element NEW_LINE import Colors NEW_LINE from Constants import CONNECTOR_ARROW_BASE , CONNECTOR_ARROW_HEIGHT NEW_LINE class Connection ( Element ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL A ▁ graphical ▁ connection ▁ for ▁ ports . STRNEWLINE TABSYMBOL The ▁ connection ▁ has ▁ 2 ▁ parts , ▁ the ▁ arrow ▁ and ▁ the ▁ wire . STRNEWLINE TABSYMBOL The ▁ coloring ▁ of ▁ the ▁ arrow ▁ and ▁ wire ▁ exposes ▁ the ▁ status ▁ of ▁ 3 ▁ states : STRNEWLINE TABSYMBOL TABSYMBOL enabled / disabled , ▁ valid / invalid , ▁ highlighted / non - highlighted . STRNEWLINE TABSYMBOL The ▁ wire ▁ coloring ▁ exposes ▁ the ▁ enabled ▁ and ▁ highlighted ▁ states . STRNEWLINE TABSYMBOL The ▁ arrow ▁ coloring ▁ exposes ▁ the ▁ enabled ▁ and ▁ valid ▁ states . STRNEWLINE TABSYMBOL """ NEW_LINE def __init__ ( self ) : Element . __init__ ( self ) NEW_LINE def get_coordinate ( self ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Get ▁ the ▁ 0,0 ▁ coordinate . STRNEWLINE TABSYMBOL TABSYMBOL Coordinates ▁ are ▁ irrelevant ▁ in ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ return ▁ 0 , ▁ 0 STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE return ( 0 , 0 ) NEW_LINE DEDENT def get_rotation ( self ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Get ▁ the ▁ 0 ▁ degree ▁ rotation . STRNEWLINE TABSYMBOL TABSYMBOL Rotations ▁ are ▁ irrelevant ▁ in ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ return ▁ 0 STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE return 0 NEW_LINE DEDENT def create_shapes ( self ) : NEW_LINE INDENT """ Precalculate ▁ relative ▁ coordinates . """ NEW_LINE Element . create_shapes ( self ) NEW_LINE self . _sink_rot = None NEW_LINE self . _source_rot = None NEW_LINE self . _sink_coor = None NEW_LINE self . _source_coor = None NEW_LINE # get ▁ the ▁ source ▁ coordinate ENDCOM connector_length = self . get_source ( ) . get_connector_length ( ) NEW_LINE self . x1 , self . y1 = Utils . get_rotated_coordinate ( ( connector_length , 0 ) , self . get_source ( ) . get_rotation ( ) ) NEW_LINE # get ▁ the ▁ sink ▁ coordinate ENDCOM connector_length = self . get_sink ( ) . get_connector_length ( ) + CONNECTOR_ARROW_HEIGHT NEW_LINE self . x2 , self . y2 = Utils . get_rotated_coordinate ( ( - connector_length , 0 ) , self . get_sink ( ) . get_rotation ( ) ) NEW_LINE # build ▁ the ▁ arrow ENDCOM self . arrow = [ ( 0 , 0 ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , - CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , ] NEW_LINE self . _update_after_move ( ) NEW_LINE if not self . get_enabled ( ) : self . _arrow_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE elif not self . is_valid ( ) : self . _arrow_color = Colors . CONNECTION_ERROR_COLOR NEW_LINE else : self . _arrow_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE DEDENT def _update_after_move ( self ) : NEW_LINE INDENT """ Calculate ▁ coordinates . """ NEW_LINE self . clear ( ) # FIXME ▁ do ▁ i ▁ want ▁ this ▁ here ? ENDCOM NEW_LINE # source ▁ connector ENDCOM source = self . get_source ( ) NEW_LINE X , Y = source . get_connector_coordinate ( ) NEW_LINE x1 , y1 = self . x1 + X , self . y1 + Y NEW_LINE self . add_line ( ( x1 , y1 ) , ( X , Y ) ) NEW_LINE # sink ▁ connector ENDCOM sink = self . get_sink ( ) NEW_LINE X , Y = sink . get_connector_coordinate ( ) NEW_LINE x2 , y2 = self . x2 + X , self . y2 + Y NEW_LINE self . add_line ( ( x2 , y2 ) , ( X , Y ) ) NEW_LINE # adjust ▁ arrow ENDCOM self . _arrow = [ ( x + X , y + Y ) for x , y in self . arrow ] NEW_LINE # add ▁ the ▁ horizontal ▁ and ▁ vertical ▁ lines ▁ in ▁ this ▁ connection ENDCOM if abs ( source . get_connector_direction ( ) - sink . get_connector_direction ( ) ) == 180 : NEW_LINE # 2 ▁ possible ▁ point ▁ sets ▁ to ▁ create ▁ a ▁ 3 - line ▁ connector ENDCOM INDENT mid_x , mid_y = ( x1 + x2 ) / 2.0 , ( y1 + y2 ) / 2.0 NEW_LINE points = [ ( ( mid_x , y1 ) , ( mid_x , y2 ) ) , ( ( x1 , mid_y ) , ( x2 , mid_y ) ) ] NEW_LINE # source ▁ connector ▁ - > ▁ points [ 0 ] [ 0 ] ▁ should ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ▁ ( if ▁ possible ) ENDCOM if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] [ 0 ] ) != source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] [ 0 ] ▁ - > ▁ sink ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ sink ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] [ 0 ] ▁ - > ▁ source ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # create ▁ 3 - line ▁ connector ENDCOM p1 , p2 = map ( int , points [ 0 ] [ 0 ] ) , map ( int , points [ 0 ] [ 1 ] ) NEW_LINE self . add_line ( ( x1 , y1 ) , p1 ) NEW_LINE self . add_line ( p1 , p2 ) NEW_LINE self . add_line ( ( x2 , y2 ) , p2 ) NEW_LINE DEDENT else : NEW_LINE # 2 ▁ possible ▁ points ▁ to ▁ create ▁ a ▁ right - angled ▁ connector ENDCOM INDENT points = [ ( x1 , y2 ) , ( x2 , y1 ) ] NEW_LINE # source ▁ connector ▁ - > ▁ points [ 0 ] ▁ should ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ▁ ( if ▁ possible ) ENDCOM if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] ) != source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] ▁ - > ▁ sink ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ sink ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] ▁ - > ▁ source ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # create ▁ right - angled ▁ connector ENDCOM self . add_line ( ( x1 , y1 ) , points [ 0 ] ) NEW_LINE self . add_line ( ( x2 , y2 ) , points [ 0 ] ) NEW_LINE DEDENT DEDENT def draw ( self , gc , window ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Draw ▁ the ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ param ▁ gc ▁ the ▁ graphics ▁ context STRNEWLINE TABSYMBOL TABSYMBOL @ param ▁ window ▁ the ▁ gtk ▁ window ▁ to ▁ draw ▁ on STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE sink = self . get_sink ( ) NEW_LINE source = self . get_source ( ) NEW_LINE # check ▁ for ▁ changes ENDCOM if self . _sink_rot != sink . get_rotation ( ) or self . _source_rot != source . get_rotation ( ) : self . create_shapes ( ) NEW_LINE elif self . _sink_coor != sink . get_coordinate ( ) or self . _source_coor != source . get_coordinate ( ) : self . _update_after_move ( ) NEW_LINE # cache ▁ values ENDCOM self . _sink_rot = sink . get_rotation ( ) NEW_LINE self . _source_rot = source . get_rotation ( ) NEW_LINE self . _sink_coor = sink . get_coordinate ( ) NEW_LINE self . _source_coor = source . get_coordinate ( ) NEW_LINE # draw ENDCOM if self . is_highlighted ( ) : border_color = Colors . HIGHLIGHT_COLOR NEW_LINE elif self . get_enabled ( ) : border_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE else : border_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE Element . draw ( self , gc , window , bg_color = None , border_color = border_color ) NEW_LINE # draw ▁ arrow ▁ on ▁ sink ▁ port ENDCOM gc . set_foreground ( self . _arrow_color ) NEW_LINE window . draw_polygon ( gc , True , self . _arrow ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="txemi/ansible/tree/master/test/units/parsing/yaml/test_dumper.py"> # ▁ coding : ▁ utf - 8 ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible ENDCOM # ▁ Ansible ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ Ansible . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM # ▁ Make ▁ coding ▁ more ▁ python3 - ish ENDCOM from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE import io NEW_LINE import yaml NEW_LINE try : NEW_LINE INDENT from _yaml import ParserError NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from yaml . parser import ParserError NEW_LINE DEDENT from ansible . parsing . yaml import dumper NEW_LINE from ansible . parsing . yaml . loader import AnsibleLoader NEW_LINE from ansible . compat . tests import unittest NEW_LINE from ansible . parsing . yaml import objects NEW_LINE from ansible . parsing import vault NEW_LINE from units . mock . yaml_helper import YamlTestUtils NEW_LINE class TestAnsibleDumper ( unittest . TestCase , YamlTestUtils ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . vault_password = " hunter42" NEW_LINE self . good_vault = vault . VaultLib ( self . vault_password ) NEW_LINE self . vault = self . good_vault NEW_LINE self . stream = self . _build_stream ( ) NEW_LINE self . dumper = dumper . AnsibleDumper NEW_LINE DEDENT def _build_stream ( self , yaml_text = None ) : NEW_LINE INDENT text = yaml_text or u ' ' NEW_LINE stream = io . StringIO ( text ) NEW_LINE return stream NEW_LINE DEDENT def _loader ( self , stream ) : NEW_LINE INDENT return AnsibleLoader ( stream , vault_password = self . vault_password ) NEW_LINE DEDENT def test ( self ) : NEW_LINE INDENT plaintext = ' This ▁ is ▁ a ▁ string ▁ we ▁ are ▁ going ▁ to ▁ encrypt . ' NEW_LINE avu = objects . AnsibleVaultEncryptedUnicode . from_plaintext ( plaintext , vault = self . vault ) NEW_LINE yaml_out = self . _dump_string ( avu , dumper = self . dumper ) NEW_LINE stream = self . _build_stream ( yaml_out ) NEW_LINE loader = self . _loader ( stream ) NEW_LINE data_from_yaml = loader . get_single_data ( ) NEW_LINE self . assertEquals ( plaintext , data_from_yaml . data ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="andybab/Impala/tree/master/tests/util/hdfs_util.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2012 ▁ Cloudera , ▁ Inc . ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ENDCOM # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ENDCOM # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM # ▁ Hdfs ▁ access ▁ utilities ENDCOM from xml . etree . ElementTree import parse NEW_LINE from pywebhdfs . webhdfs import PyWebHdfsClient , errors , _raise_pywebhdfs_exception NEW_LINE import getpass NEW_LINE import types NEW_LINE import requests , httplib NEW_LINE class PyWebHdfsClientWithChmod ( PyWebHdfsClient ) : NEW_LINE INDENT def chmod ( self , path , permission ) : NEW_LINE INDENT """ Set ▁ the ▁ permission ▁ of ▁ ' path ' ▁ to ▁ ' permission ' ▁ ( specified ▁ as ▁ an ▁ octal ▁ string , ▁ e . g . STRNEWLINE ▁ ' 775 ' """ NEW_LINE uri = self . _create_uri ( path , " SETPERMISSION " , permission = permission ) NEW_LINE response = requests . put ( uri , allow_redirects = True ) NEW_LINE if not response . status_code == httplib . OK : NEW_LINE INDENT _raise_pywebhdfs_exception ( response . status_code , response . text ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT class HdfsConfig ( object ) : NEW_LINE INDENT """ Reads ▁ an ▁ XML ▁ configuration ▁ file ▁ ( produced ▁ by ▁ a ▁ mini - cluster ) ▁ into ▁ a ▁ dictionary STRNEWLINE ▁ accessible ▁ via ▁ get ( ) """ NEW_LINE def __init__ ( self , filename ) : NEW_LINE INDENT self . conf = { } NEW_LINE tree = parse ( filename ) NEW_LINE for property in tree . getroot ( ) . getiterator ( ' property ' ) : NEW_LINE INDENT self . conf [ property . find ( ' name ' ) . text ] = property . find ( ' value ' ) . text NEW_LINE DEDENT DEDENT def get ( self , key ) : NEW_LINE INDENT return self . conf . get ( key ) NEW_LINE DEDENT DEDENT def get_hdfs_client_from_conf ( conf ) : NEW_LINE INDENT """ Returns ▁ a ▁ new ▁ HTTP ▁ client ▁ for ▁ an ▁ HDFS ▁ cluster ▁ using ▁ an ▁ HdfsConfig ▁ object """ NEW_LINE hostport = conf . get ( ' dfs . namenode . http - address ' ) NEW_LINE if hostport is None : NEW_LINE INDENT raise Exception ( " dfs . namenode . http - address ▁ not ▁ found ▁ in ▁ config " ) NEW_LINE DEDENT host , port = hostport . split ( " : " ) NEW_LINE return get_hdfs_client ( host = host , port = port ) NEW_LINE DEDENT def __pyweb_hdfs_client_exists ( self , path ) : NEW_LINE INDENT """ The ▁ PyWebHdfsClient ▁ doesn ' t ▁ provide ▁ an ▁ API ▁ to ▁ cleanly ▁ detect ▁ if ▁ a ▁ file ▁ or ▁ directory STRNEWLINE ▁ exists . ▁ This ▁ method ▁ is ▁ bound ▁ to ▁ each ▁ client ▁ that ▁ is ▁ created ▁ so ▁ tests ▁ can ▁ simply ▁ call STRNEWLINE ▁ hdfs _ client . exists ( ' path ' ) ▁ and ▁ get ▁ back ▁ a ▁ bool . STRNEWLINE ▁ """ NEW_LINE try : NEW_LINE INDENT self . get_file_dir_status ( path ) NEW_LINE DEDENT except errors . FileNotFound : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT def get_hdfs_client ( host , port , user_name = getpass . getuser ( ) ) : NEW_LINE INDENT """ Returns ▁ a ▁ new ▁ HTTP ▁ client ▁ for ▁ an ▁ HDFS ▁ cluster ▁ using ▁ an ▁ explict ▁ host : port ▁ pair """ NEW_LINE hdfs_client = PyWebHdfsClientWithChmod ( host = host , port = port , user_name = user_name ) NEW_LINE # ▁ Bind ▁ our ▁ " exists " ▁ method ▁ to ▁ hdfs _ client . exists ENDCOM hdfs_client . exists = types . MethodType ( __pyweb_hdfs_client_exists , hdfs_client ) NEW_LINE return hdfs_client NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="jasonseminara/OpenSourceFinal/tree/master/myvenv/lib/python3.5/site-packages/django/template/smartif.py"> """ STRNEWLINE Parser ▁ and ▁ utilities ▁ for ▁ the ▁ smart ▁ ' if ' ▁ tag STRNEWLINE """ NEW_LINE import warnings NEW_LINE from django . utils . deprecation import RemovedInDjango110Warning NEW_LINE # ▁ Using ▁ a ▁ simple ▁ top ▁ down ▁ parser , ▁ as ▁ described ▁ here : ENDCOM # ▁ http : / / effbot . org / zone / simple - top - down - parsing . htm . ENDCOM # ▁ ' led ' ▁ = ▁ left ▁ denotation ENDCOM # ▁ ' nud ' ▁ = ▁ null ▁ denotation ENDCOM # ▁ ' bp ' ▁ = ▁ binding ▁ power ▁ ( left ▁ = ▁ lbp , ▁ right ▁ = ▁ rbp ) ENDCOM class TokenBase ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ Base ▁ class ▁ for ▁ operators ▁ and ▁ literals , ▁ mainly ▁ for ▁ debugging ▁ and ▁ for ▁ throwing STRNEWLINE ▁ syntax ▁ errors . STRNEWLINE ▁ """ NEW_LINE id = None # ▁ node / token ▁ type ▁ name ENDCOM NEW_LINE value = None # ▁ used ▁ by ▁ literals ENDCOM NEW_LINE first = second = None # ▁ used ▁ by ▁ tree ▁ nodes ENDCOM NEW_LINE def nud ( self , parser ) : NEW_LINE # ▁ Null ▁ denotation ▁ - ▁ called ▁ in ▁ prefix ▁ context ENDCOM INDENT raise parser . error_class ( " Not ▁ expecting ▁ ' % s ' ▁ in ▁ this ▁ position ▁ in ▁ if ▁ tag . " % self . id ) NEW_LINE DEDENT def led ( self , left , parser ) : NEW_LINE # ▁ Left ▁ denotation ▁ - ▁ called ▁ in ▁ infix ▁ context ENDCOM INDENT raise parser . error_class ( " Not ▁ expecting ▁ ' % s ' ▁ as ▁ infix ▁ operator ▁ in ▁ if ▁ tag . " % self . id ) NEW_LINE DEDENT def display ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ what ▁ to ▁ display ▁ in ▁ error ▁ messages ▁ for ▁ this ▁ node STRNEWLINE ▁ """ NEW_LINE return self . id NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT out = [ str ( x ) for x in [ self . id , self . first , self . second ] if x is not None ] NEW_LINE return " ( " + " ▁ " . join ( out ) + " ) " NEW_LINE DEDENT DEDENT def infix ( bp , func ) : NEW_LINE INDENT """ STRNEWLINE ▁ Creates ▁ an ▁ infix ▁ operator , ▁ given ▁ a ▁ binding ▁ power ▁ and ▁ a ▁ function ▁ that STRNEWLINE ▁ evaluates ▁ the ▁ node STRNEWLINE ▁ """ NEW_LINE class Operator ( TokenBase ) : NEW_LINE INDENT lbp = bp NEW_LINE def led ( self , left , parser ) : NEW_LINE INDENT self . first = left NEW_LINE self . second = parser . expression ( bp ) NEW_LINE return self NEW_LINE DEDENT def eval ( self , context ) : NEW_LINE INDENT try : NEW_LINE INDENT return func ( context , self . first , self . second ) NEW_LINE DEDENT except Exception : NEW_LINE # ▁ Templates ▁ shouldn ' t ▁ throw ▁ exceptions ▁ when ▁ rendering . ▁ We ▁ are ENDCOM # ▁ most ▁ likely ▁ to ▁ get ▁ exceptions ▁ for ▁ things ▁ like ▁ { % ▁ if ▁ foo ▁ in ▁ bar ENDCOM # ▁ % } ▁ where ▁ ' bar ' ▁ does ▁ not ▁ support ▁ ' in ' , ▁ so ▁ default ▁ to ▁ False ENDCOM INDENT return False NEW_LINE DEDENT DEDENT DEDENT return Operator NEW_LINE DEDENT def prefix ( bp , func ) : NEW_LINE INDENT """ STRNEWLINE ▁ Creates ▁ a ▁ prefix ▁ operator , ▁ given ▁ a ▁ binding ▁ power ▁ and ▁ a ▁ function ▁ that STRNEWLINE ▁ evaluates ▁ the ▁ node . STRNEWLINE ▁ """ NEW_LINE class Operator ( TokenBase ) : NEW_LINE INDENT lbp = bp NEW_LINE def nud ( self , parser ) : NEW_LINE INDENT self . first = parser . expression ( bp ) NEW_LINE self . second = None NEW_LINE return self NEW_LINE DEDENT def eval ( self , context ) : NEW_LINE INDENT try : NEW_LINE INDENT return func ( context , self . first ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT DEDENT return Operator NEW_LINE # ▁ Operator ▁ precedence ▁ follows ▁ Python . ENDCOM # ▁ NB ▁ - ▁ we ▁ can ▁ get ▁ slightly ▁ more ▁ accurate ▁ syntax ▁ error ▁ messages ▁ by ▁ not ▁ using ▁ the ENDCOM # ▁ same ▁ object ▁ for ▁ ' = = ' ▁ and ▁ ' = ' . ENDCOM # ▁ We ▁ defer ▁ variable ▁ evaluation ▁ to ▁ the ▁ lambda ▁ to ▁ ensure ▁ that ▁ terms ▁ are ENDCOM # ▁ lazily ▁ evaluated ▁ using ▁ Python ' s ▁ boolean ▁ parsing ▁ logic . ENDCOM DEDENT OPERATORS = { ' or ' : infix ( 6 , lambda context , x , y : x . eval ( context ) or y . eval ( context ) ) , ' and ' : infix ( 7 , lambda context , x , y : x . eval ( context ) and y . eval ( context ) ) , ' not ' : prefix ( 8 , lambda context , x : not x . eval ( context ) ) , ' in ' : infix ( 9 , lambda context , x , y : x . eval ( context ) in y . eval ( context ) ) , ' not ▁ in ' : infix ( 9 , lambda context , x , y : x . eval ( context ) not in y . eval ( context ) ) , # ▁ This ▁ should ▁ be ▁ removed ▁ in ▁ Django ▁ 1.10 : ENDCOM ' = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) == y . eval ( context ) ) , ' = = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) == y . eval ( context ) ) , ' ! = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) != y . eval ( context ) ) , ' > ' : infix ( 10 , lambda context , x , y : x . eval ( context ) > y . eval ( context ) ) , ' > = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) >= y . eval ( context ) ) , ' < ' : infix ( 10 , lambda context , x , y : x . eval ( context ) < y . eval ( context ) ) , ' < = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) <= y . eval ( context ) ) , } NEW_LINE # ▁ Assign ▁ ' id ' ▁ to ▁ each : ENDCOM for key , op in OPERATORS . items ( ) : NEW_LINE INDENT op . id = key NEW_LINE DEDENT class Literal ( TokenBase ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ basic ▁ self - resolvable ▁ object ▁ similar ▁ to ▁ a ▁ Django ▁ template ▁ variable . STRNEWLINE ▁ """ NEW_LINE # ▁ IfParser ▁ uses ▁ Literal ▁ in ▁ create _ var , ▁ but ▁ TemplateIfParser ▁ overrides ENDCOM # ▁ create _ var ▁ so ▁ that ▁ a ▁ proper ▁ implementation ▁ that ▁ actually ▁ resolves ENDCOM # ▁ variables , ▁ filters ▁ etc ▁ is ▁ used . ENDCOM id = " literal " NEW_LINE lbp = 0 NEW_LINE def __init__ ( self , value ) : NEW_LINE INDENT self . value = value NEW_LINE DEDENT def display ( self ) : NEW_LINE INDENT return repr ( self . value ) NEW_LINE DEDENT def nud ( self , parser ) : NEW_LINE INDENT return self NEW_LINE DEDENT def eval ( self , context ) : NEW_LINE INDENT return self . value NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return " ( % s ▁ % r ) " % ( self . id , self . value ) NEW_LINE DEDENT DEDENT class EndToken ( TokenBase ) : NEW_LINE INDENT lbp = 0 NEW_LINE def nud ( self , parser ) : NEW_LINE INDENT raise parser . error_class ( " Unexpected ▁ end ▁ of ▁ expression ▁ in ▁ if ▁ tag . " ) NEW_LINE DEDENT DEDENT EndToken = EndToken ( ) NEW_LINE class IfParser ( object ) : NEW_LINE INDENT error_class = ValueError NEW_LINE def __init__ ( self , tokens ) : NEW_LINE # ▁ pre - pass ▁ necessary ▁ to ▁ turn ▁ ' not ' , ' in ' ▁ into ▁ single ▁ token ENDCOM INDENT l = len ( tokens ) NEW_LINE mapped_tokens = [ ] NEW_LINE i = 0 NEW_LINE while i < l : NEW_LINE INDENT token = tokens [ i ] NEW_LINE if token == " not " and i + 1 < l and tokens [ i + 1 ] == " in " : NEW_LINE INDENT token = " not ▁ in " NEW_LINE i += 1 # ▁ skip ▁ ' in ' ENDCOM NEW_LINE DEDENT mapped_tokens . append ( self . translate_token ( token ) ) NEW_LINE i += 1 NEW_LINE DEDENT self . tokens = mapped_tokens NEW_LINE self . pos = 0 NEW_LINE self . current_token = self . next_token ( ) NEW_LINE DEDENT def translate_token ( self , token ) : NEW_LINE INDENT try : NEW_LINE INDENT op = OPERATORS [ token ] NEW_LINE DEDENT except ( KeyError , TypeError ) : NEW_LINE INDENT return self . create_var ( token ) NEW_LINE DEDENT else : NEW_LINE INDENT if token == ' = ' : NEW_LINE INDENT warnings . warn ( " Operator ▁ ' = ' ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ removed ▁ in ▁ Django ▁ 1.10 . ▁ Use ▁ ' = = ' ▁ instead . " , RemovedInDjango110Warning , stacklevel = 2 ) NEW_LINE DEDENT return op ( ) NEW_LINE DEDENT DEDENT def next_token ( self ) : NEW_LINE INDENT if self . pos >= len ( self . tokens ) : NEW_LINE INDENT return EndToken NEW_LINE DEDENT else : NEW_LINE INDENT retval = self . tokens [ self . pos ] NEW_LINE self . pos += 1 NEW_LINE return retval NEW_LINE DEDENT DEDENT def parse ( self ) : NEW_LINE INDENT retval = self . expression ( ) NEW_LINE # ▁ Check ▁ that ▁ we ▁ have ▁ exhausted ▁ all ▁ the ▁ tokens ENDCOM if self . current_token is not EndToken : NEW_LINE INDENT raise self . error_class ( " Unused ▁ ' % s ' ▁ at ▁ end ▁ of ▁ if ▁ expression . " % self . current_token . display ( ) ) NEW_LINE DEDENT return retval NEW_LINE DEDENT def expression ( self , rbp = 0 ) : NEW_LINE INDENT t = self . current_token NEW_LINE self . current_token = self . next_token ( ) NEW_LINE left = t . nud ( self ) NEW_LINE while rbp < self . current_token . lbp : NEW_LINE INDENT t = self . current_token NEW_LINE self . current_token = self . next_token ( ) NEW_LINE left = t . led ( left , self ) NEW_LINE DEDENT return left NEW_LINE DEDENT def create_var ( self , value ) : NEW_LINE INDENT return Literal ( value ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="sbstp/streamlink/tree/master/src/streamlink/plugins/alieztv.py"> import re NEW_LINE from os . path import splitext NEW_LINE from streamlink . compat import urlparse , unquote NEW_LINE from streamlink . plugin import Plugin NEW_LINE from streamlink . plugin . api import http , validate NEW_LINE from streamlink . stream import HTTPStream , RTMPStream NEW_LINE _url_re = re . compile ( """ STRNEWLINE ▁ ▁ ▁ ▁ http ( s ) ? : / / ( \w + \ . ) ? aliez . tv STRNEWLINE ▁ ▁ ▁ ▁ ( ? : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ / live / [ ^ / ] + STRNEWLINE ▁ ▁ ▁ ▁ ) ? STRNEWLINE ▁ ▁ ▁ ▁ ( ? : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ / video / \d + / [ ^ / ] + STRNEWLINE ▁ ▁ ▁ ▁ ) ? STRNEWLINE """ , re . VERBOSE ) NEW_LINE _file_re = re . compile ( " \ " ? file\ " ? : \s + [ ' \ " ] ( [ ^ ' \ " ] + ) [ ' \ " ] " ) NEW_LINE _swf_url_re = re . compile ( " swfobject . embedSWF\ ( \ " ( [ ^ \ " ] + ) \ " , " ) NEW_LINE _schema = validate . Schema ( validate . union ( { " urls " : validate . all ( validate . transform ( _file_re . findall ) , validate . map ( unquote ) , [ validate . url ( ) ] ) , " swf " : validate . all ( validate . transform ( _swf_url_re . search ) , validate . any ( None , validate . all ( validate . get ( 1 ) , validate . url ( scheme = " http " , path = validate . endswith ( " swf " ) ) ) ) ) } ) ) NEW_LINE class Aliez ( Plugin ) : NEW_LINE INDENT @ classmethod NEW_LINE def can_handle_url ( self , url ) : NEW_LINE INDENT return _url_re . match ( url ) NEW_LINE DEDENT def _get_streams ( self ) : NEW_LINE INDENT res = http . get ( self . url , schema = _schema ) NEW_LINE streams = { } NEW_LINE for url in res [ " urls " ] : NEW_LINE INDENT parsed = urlparse ( url ) NEW_LINE if parsed . scheme . startswith ( " rtmp " ) : NEW_LINE INDENT params = { " rtmp " : url , " pageUrl " : self . url , " live " : True } NEW_LINE if res [ " swf " ] : NEW_LINE INDENT params [ " swfVfy " ] = res [ " swf " ] NEW_LINE DEDENT stream = RTMPStream ( self . session , params ) NEW_LINE streams [ " live " ] = stream NEW_LINE DEDENT elif parsed . scheme . startswith ( " http " ) : NEW_LINE INDENT name = splitext ( parsed . path ) [ 1 ] [ 1 : ] NEW_LINE stream = HTTPStream ( self . session , url ) NEW_LINE streams [ name ] = stream NEW_LINE DEDENT DEDENT return streams NEW_LINE DEDENT DEDENT __plugin__ = Aliez NEW_LINE </DOCUMENT>
<DOCUMENT_ID="thomasgilgenast/gilgistatus-nonrel/tree/master/django/db/backends/creation.py"> import sys NEW_LINE import time NEW_LINE from django . conf import settings NEW_LINE from django . utils . datastructures import DictWrapper NEW_LINE # ▁ The ▁ prefix ▁ to ▁ put ▁ on ▁ the ▁ default ▁ database ▁ name ▁ when ▁ creating ENDCOM # ▁ the ▁ test ▁ database . ENDCOM TEST_DATABASE_PREFIX = ' test _ ' NEW_LINE class BaseDatabaseCreation ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ class ▁ encapsulates ▁ all ▁ backend - specific ▁ differences ▁ that ▁ pertain ▁ to STRNEWLINE ▁ database ▁ * creation * , ▁ such ▁ as ▁ the ▁ column ▁ types ▁ to ▁ use ▁ for ▁ particular ▁ Django STRNEWLINE ▁ Fields , ▁ the ▁ SQL ▁ used ▁ to ▁ create ▁ and ▁ destroy ▁ tables , ▁ and ▁ the ▁ creation ▁ and STRNEWLINE ▁ destruction ▁ of ▁ test ▁ databases . STRNEWLINE ▁ """ NEW_LINE data_types = { } NEW_LINE def __init__ ( self , connection ) : NEW_LINE INDENT self . connection = connection NEW_LINE DEDENT def _digest ( self , * args ) : NEW_LINE INDENT """ STRNEWLINE ▁ Generates ▁ a ▁ 32 - bit ▁ digest ▁ of ▁ a ▁ set ▁ of ▁ arguments ▁ that ▁ can ▁ be ▁ used ▁ to STRNEWLINE ▁ shorten ▁ identifying ▁ names . STRNEWLINE ▁ """ NEW_LINE return ' % x ' % ( abs ( hash ( args ) ) % 4294967296 L ) # ▁ 2 * * 32 ENDCOM NEW_LINE DEDENT def db_type ( self , field ) : NEW_LINE INDENT return self . _db_type ( field , field . get_internal_type ( ) ) NEW_LINE DEDENT def related_db_type ( self , field ) : NEW_LINE INDENT return self . _db_type ( field , field . get_related_internal_type ( ) ) NEW_LINE DEDENT def _db_type ( self , field , internal_type ) : NEW_LINE INDENT data = DictWrapper ( field . __dict__ , self . connection . ops . quote_name , " qn _ " ) NEW_LINE try : NEW_LINE INDENT return self . connection . creation . data_types [ internal_type ] % data NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT def sql_create_model ( self , model , style , known_models = set ( ) ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ the ▁ SQL ▁ required ▁ to ▁ create ▁ a ▁ single ▁ model , ▁ as ▁ a ▁ tuple ▁ of : STRNEWLINE ▁ ( list _ of _ sql , ▁ pending _ references _ dict ) STRNEWLINE ▁ """ NEW_LINE opts = model . _meta NEW_LINE if not opts . managed or opts . proxy : NEW_LINE INDENT return [ ] , { } NEW_LINE DEDENT final_output = [ ] NEW_LINE table_output = [ ] NEW_LINE pending_references = { } NEW_LINE qn = self . connection . ops . quote_name NEW_LINE for f in opts . local_fields : NEW_LINE INDENT col_type = f . db_type ( connection = self . connection ) NEW_LINE tablespace = f . db_tablespace or opts . db_tablespace NEW_LINE if col_type is None : NEW_LINE # ▁ Skip ▁ ManyToManyFields , ▁ because ▁ they ' re ▁ not ▁ represented ▁ as ENDCOM # ▁ database ▁ columns ▁ in ▁ this ▁ table . ENDCOM INDENT continue NEW_LINE # ▁ Make ▁ the ▁ definition ▁ ( e . g . ▁ ' foo ▁ VARCHAR ( 30 ) ' ) ▁ for ▁ this ▁ field . ENDCOM DEDENT field_output = [ style . SQL_FIELD ( qn ( f . column ) ) , style . SQL_COLTYPE ( col_type ) ] NEW_LINE if not f . null : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' NOT ▁ NULL ' ) ) NEW_LINE DEDENT if f . primary_key : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' PRIMARY ▁ KEY ' ) ) NEW_LINE DEDENT elif f . unique : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' UNIQUE ' ) ) NEW_LINE DEDENT if tablespace and f . unique : NEW_LINE # ▁ We ▁ must ▁ specify ▁ the ▁ index ▁ tablespace ▁ inline , ▁ because ▁ we ENDCOM # ▁ won ' t ▁ be ▁ generating ▁ a ▁ CREATE ▁ INDEX ▁ statement ▁ for ▁ this ▁ field . ENDCOM INDENT field_output . append ( self . connection . ops . tablespace_sql ( tablespace , inline = True ) ) NEW_LINE DEDENT if f . rel : NEW_LINE INDENT ref_output , pending = self . sql_for_inline_foreign_key_references ( f , known_models , style ) NEW_LINE if pending : NEW_LINE INDENT pr = pending_references . setdefault ( f . rel . to , [ ] ) . append ( ( model , f ) ) NEW_LINE DEDENT else : NEW_LINE INDENT field_output . extend ( ref_output ) NEW_LINE DEDENT DEDENT table_output . append ( ' ▁ ' . join ( field_output ) ) NEW_LINE DEDENT for field_constraints in opts . unique_together : NEW_LINE INDENT table_output . append ( style . SQL_KEYWORD ( ' UNIQUE ' ) + ' ▁ ( % s ) ' % " , ▁ " . join ( [ style . SQL_FIELD ( qn ( opts . get_field ( f ) . column ) ) for f in field_constraints ] ) ) NEW_LINE DEDENT full_statement = [ style . SQL_KEYWORD ( ' CREATE ▁ TABLE ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( opts . db_table ) ) + ' ▁ ( ' ] NEW_LINE for i , line in enumerate ( table_output ) : # ▁ Combine ▁ and ▁ add ▁ commas . ENDCOM NEW_LINE INDENT full_statement . append ( ' ▁ ▁ ▁ ▁ % s % s ' % ( line , i < len ( table_output ) - 1 and ' , ' or ' ' ) ) NEW_LINE DEDENT full_statement . append ( ' ) ' ) NEW_LINE if opts . db_tablespace : NEW_LINE INDENT full_statement . append ( self . connection . ops . tablespace_sql ( opts . db_tablespace ) ) NEW_LINE DEDENT full_statement . append ( ' ; ' ) NEW_LINE final_output . append ( ' \n ' . join ( full_statement ) ) NEW_LINE if opts . has_auto_field : NEW_LINE # ▁ Add ▁ any ▁ extra ▁ SQL ▁ needed ▁ to ▁ support ▁ auto - incrementing ▁ primary ▁ keys . ENDCOM INDENT auto_column = opts . auto_field . db_column or opts . auto_field . name NEW_LINE autoinc_sql = self . connection . ops . autoinc_sql ( opts . db_table , auto_column ) NEW_LINE if autoinc_sql : NEW_LINE INDENT for stmt in autoinc_sql : NEW_LINE INDENT final_output . append ( stmt ) NEW_LINE DEDENT DEDENT DEDENT return final_output , pending_references NEW_LINE DEDENT def sql_for_inline_foreign_key_references ( self , field , known_models , style ) : NEW_LINE INDENT " Return ▁ the ▁ SQL ▁ snippet ▁ defining ▁ the ▁ foreign ▁ key ▁ reference ▁ for ▁ a ▁ field " NEW_LINE qn = self . connection . ops . quote_name NEW_LINE if field . rel . to in known_models : NEW_LINE INDENT output = [ style . SQL_KEYWORD ( ' REFERENCES ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( field . rel . to . _meta . db_table ) ) + ' ▁ ( ' + style . SQL_FIELD ( qn ( field . rel . to . _meta . get_field ( field . rel . field_name ) . column ) ) + ' ) ' + self . connection . ops . deferrable_sql ( ) ] NEW_LINE pending = False NEW_LINE DEDENT else : NEW_LINE # ▁ We ▁ haven ' t ▁ yet ▁ created ▁ the ▁ table ▁ to ▁ which ▁ this ▁ field ENDCOM # ▁ is ▁ related , ▁ so ▁ save ▁ it ▁ for ▁ later . ENDCOM INDENT output = [ ] NEW_LINE pending = True NEW_LINE DEDENT return output , pending NEW_LINE DEDENT def sql_for_pending_references ( self , model , style , pending_references ) : NEW_LINE INDENT " Returns ▁ any ▁ ALTER ▁ TABLE ▁ statements ▁ to ▁ add ▁ constraints ▁ after ▁ the ▁ fact . " NEW_LINE from django . db . backends . util import truncate_name NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT qn = self . connection . ops . quote_name NEW_LINE final_output = [ ] NEW_LINE opts = model . _meta NEW_LINE if model in pending_references : NEW_LINE INDENT for rel_class , f in pending_references [ model ] : NEW_LINE INDENT rel_opts = rel_class . _meta NEW_LINE r_table = rel_opts . db_table NEW_LINE r_col = f . column NEW_LINE table = opts . db_table NEW_LINE col = opts . get_field ( f . rel . field_name ) . column NEW_LINE # ▁ For ▁ MySQL , ▁ r _ name ▁ must ▁ be ▁ unique ▁ in ▁ the ▁ first ▁ 64 ▁ characters . ENDCOM # ▁ So ▁ we ▁ are ▁ careful ▁ with ▁ character ▁ usage ▁ here . ENDCOM r_name = ' % s _ refs _ % s _ % s ' % ( r_col , col , self . _digest ( r_table , table ) ) NEW_LINE final_output . append ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) + ' ▁ % s ▁ ADD ▁ CONSTRAINT ▁ % s ▁ FOREIGN ▁ KEY ▁ ( % s ) ▁ REFERENCES ▁ % s ▁ ( % s ) % s ; ' % ( qn ( r_table ) , qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) , qn ( r_col ) , qn ( table ) , qn ( col ) , self . connection . ops . deferrable_sql ( ) ) ) NEW_LINE DEDENT del pending_references [ model ] NEW_LINE DEDENT return final_output NEW_LINE DEDENT def sql_for_many_to_many ( self , model , style ) : NEW_LINE INDENT " Return ▁ the ▁ CREATE ▁ TABLE ▁ statments ▁ for ▁ all ▁ the ▁ many - to - many ▁ tables ▁ defined ▁ on ▁ a ▁ model " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE output = [ ] NEW_LINE for f in model . _meta . local_many_to_many : NEW_LINE INDENT if model . _meta . managed or f . rel . to . _meta . managed : NEW_LINE INDENT output . extend ( self . sql_for_many_to_many_field ( model , f , style ) ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def sql_for_many_to_many_field ( self , model , f , style ) : NEW_LINE INDENT " Return ▁ the ▁ CREATE ▁ TABLE ▁ statements ▁ for ▁ a ▁ single ▁ m2m ▁ field " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE from django . db import models NEW_LINE from django . db . backends . util import truncate_name NEW_LINE output = [ ] NEW_LINE if f . auto_created : NEW_LINE INDENT opts = model . _meta NEW_LINE qn = self . connection . ops . quote_name NEW_LINE tablespace = f . db_tablespace or opts . db_tablespace NEW_LINE if tablespace : NEW_LINE INDENT sql = self . connection . ops . tablespace_sql ( tablespace , inline = True ) NEW_LINE if sql : NEW_LINE INDENT tablespace_sql = ' ▁ ' + sql NEW_LINE DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT table_output = [ style . SQL_KEYWORD ( ' CREATE ▁ TABLE ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( f . m2m_db_table ( ) ) ) + ' ▁ ( ' ] NEW_LINE table_output . append ( ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s % s , ' % ( style . SQL_FIELD ( qn ( ' id ' ) ) , style . SQL_COLTYPE ( models . AutoField ( primary_key = True ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ PRIMARY ▁ KEY ' ) , tablespace_sql ) ) NEW_LINE deferred = [ ] NEW_LINE inline_output , deferred = self . sql_for_inline_many_to_many_references ( model , f , style ) NEW_LINE table_output . extend ( inline_output ) NEW_LINE table_output . append ( ' ▁ ▁ ▁ ▁ % s ▁ ( % s , ▁ % s ) % s ' % ( style . SQL_KEYWORD ( ' UNIQUE ' ) , style . SQL_FIELD ( qn ( f . m2m_column_name ( ) ) ) , style . SQL_FIELD ( qn ( f . m2m_reverse_name ( ) ) ) , tablespace_sql ) ) NEW_LINE table_output . append ( ' ) ' ) NEW_LINE if opts . db_tablespace : NEW_LINE # ▁ f . db _ tablespace ▁ is ▁ only ▁ for ▁ indices , ▁ so ▁ ignore ▁ its ▁ value ▁ here . ENDCOM INDENT table_output . append ( self . connection . ops . tablespace_sql ( opts . db_tablespace ) ) NEW_LINE DEDENT table_output . append ( ' ; ' ) NEW_LINE output . append ( ' \n ' . join ( table_output ) ) NEW_LINE for r_table , r_col , table , col in deferred : NEW_LINE INDENT r_name = ' % s _ refs _ % s _ % s ' % ( r_col , col , self . _digest ( r_table , table ) ) NEW_LINE output . append ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) + ' ▁ % s ▁ ADD ▁ CONSTRAINT ▁ % s ▁ FOREIGN ▁ KEY ▁ ( % s ) ▁ REFERENCES ▁ % s ▁ ( % s ) % s ; ' % ( qn ( r_table ) , qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) , qn ( r_col ) , qn ( table ) , qn ( col ) , self . connection . ops . deferrable_sql ( ) ) ) NEW_LINE # ▁ Add ▁ any ▁ extra ▁ SQL ▁ needed ▁ to ▁ support ▁ auto - incrementing ▁ PKs ENDCOM DEDENT autoinc_sql = self . connection . ops . autoinc_sql ( f . m2m_db_table ( ) , ' id ' ) NEW_LINE if autoinc_sql : NEW_LINE INDENT for stmt in autoinc_sql : NEW_LINE INDENT output . append ( stmt ) NEW_LINE DEDENT DEDENT DEDENT return output NEW_LINE DEDENT def sql_for_inline_many_to_many_references ( self , model , field , style ) : NEW_LINE INDENT " Create ▁ the ▁ references ▁ to ▁ other ▁ tables ▁ required ▁ by ▁ a ▁ many - to - many ▁ table " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE from django . db import models NEW_LINE opts = model . _meta NEW_LINE qn = self . connection . ops . quote_name NEW_LINE table_output = [ ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s ▁ % s ▁ ( % s ) % s , ' % ( style . SQL_FIELD ( qn ( field . m2m_column_name ( ) ) ) , style . SQL_COLTYPE ( models . ForeignKey ( model ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ REFERENCES ' ) , style . SQL_TABLE ( qn ( opts . db_table ) ) , style . SQL_FIELD ( qn ( opts . pk . column ) ) , self . connection . ops . deferrable_sql ( ) ) , ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s ▁ % s ▁ ( % s ) % s , ' % ( style . SQL_FIELD ( qn ( field . m2m_reverse_name ( ) ) ) , style . SQL_COLTYPE ( models . ForeignKey ( field . rel . to ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ REFERENCES ' ) , style . SQL_TABLE ( qn ( field . rel . to . _meta . db_table ) ) , style . SQL_FIELD ( qn ( field . rel . to . _meta . pk . column ) ) , self . connection . ops . deferrable_sql ( ) ) ] NEW_LINE deferred = [ ] NEW_LINE return table_output , deferred NEW_LINE DEDENT def sql_indexes_for_model ( self , model , style ) : NEW_LINE INDENT " Returns ▁ the ▁ CREATE ▁ INDEX ▁ SQL ▁ statements ▁ for ▁ a ▁ single ▁ model " NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT output = [ ] NEW_LINE for f in model . _meta . local_fields : NEW_LINE INDENT output . extend ( self . sql_indexes_for_field ( model , f , style ) ) NEW_LINE DEDENT return output NEW_LINE DEDENT def sql_indexes_for_field ( self , model , f , style ) : NEW_LINE INDENT " Return ▁ the ▁ CREATE ▁ INDEX ▁ SQL ▁ statements ▁ for ▁ a ▁ single ▁ model ▁ field " NEW_LINE from django . db . backends . util import truncate_name NEW_LINE if f . db_index and not f . unique : NEW_LINE INDENT qn = self . connection . ops . quote_name NEW_LINE tablespace = f . db_tablespace or model . _meta . db_tablespace NEW_LINE if tablespace : NEW_LINE INDENT sql = self . connection . ops . tablespace_sql ( tablespace ) NEW_LINE if sql : NEW_LINE INDENT tablespace_sql = ' ▁ ' + sql NEW_LINE DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT i_name = ' % s _ % s ' % ( model . _meta . db_table , self . _digest ( f . column ) ) NEW_LINE output = [ style . SQL_KEYWORD ( ' CREATE ▁ INDEX ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( truncate_name ( i_name , self . connection . ops . max_name_length ( ) ) ) ) + ' ▁ ' + style . SQL_KEYWORD ( ' ON ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( model . _meta . db_table ) ) + ' ▁ ' + " ( % s ) " % style . SQL_FIELD ( qn ( f . column ) ) + " % s ; " % tablespace_sql ] NEW_LINE DEDENT else : NEW_LINE INDENT output = [ ] NEW_LINE DEDENT return output NEW_LINE DEDENT def sql_destroy_model ( self , model , references_to_delete , style ) : NEW_LINE INDENT " Return ▁ the ▁ DROP ▁ TABLE ▁ and ▁ restraint ▁ dropping ▁ statements ▁ for ▁ a ▁ single ▁ model " NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE # ▁ Drop ▁ the ▁ table ▁ now ENDCOM DEDENT qn = self . connection . ops . quote_name NEW_LINE output = [ ' % s ▁ % s ; ' % ( style . SQL_KEYWORD ( ' DROP ▁ TABLE ' ) , style . SQL_TABLE ( qn ( model . _meta . db_table ) ) ) ] NEW_LINE if model in references_to_delete : NEW_LINE INDENT output . extend ( self . sql_remove_table_constraints ( model , references_to_delete , style ) ) NEW_LINE DEDENT if model . _meta . has_auto_field : NEW_LINE INDENT ds = self . connection . ops . drop_sequence_sql ( model . _meta . db_table ) NEW_LINE if ds : NEW_LINE INDENT output . append ( ds ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def sql_remove_table_constraints ( self , model , references_to_delete , style ) : NEW_LINE INDENT from django . db . backends . util import truncate_name NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT output = [ ] NEW_LINE qn = self . connection . ops . quote_name NEW_LINE for rel_class , f in references_to_delete [ model ] : NEW_LINE INDENT table = rel_class . _meta . db_table NEW_LINE col = f . column NEW_LINE r_table = model . _meta . db_table NEW_LINE r_col = model . _meta . get_field ( f . rel . field_name ) . column NEW_LINE r_name = ' % s _ refs _ % s _ % s ' % ( col , r_col , self . _digest ( table , r_table ) ) NEW_LINE output . append ( ' % s ▁ % s ▁ % s ▁ % s ; ' % ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) , style . SQL_TABLE ( qn ( table ) ) , style . SQL_KEYWORD ( self . connection . ops . drop_foreignkey_sql ( ) ) , style . SQL_FIELD ( qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) ) ) ) NEW_LINE DEDENT del references_to_delete [ model ] NEW_LINE return output NEW_LINE DEDENT def sql_destroy_many_to_many ( self , model , f , style ) : NEW_LINE INDENT " Returns ▁ the ▁ DROP ▁ TABLE ▁ statements ▁ for ▁ a ▁ single ▁ m2m ▁ field " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE qn = self . connection . ops . quote_name NEW_LINE output = [ ] NEW_LINE if f . auto_created : NEW_LINE INDENT output . append ( " % s ▁ % s ; " % ( style . SQL_KEYWORD ( ' DROP ▁ TABLE ' ) , style . SQL_TABLE ( qn ( f . m2m_db_table ( ) ) ) ) ) NEW_LINE ds = self . connection . ops . drop_sequence_sql ( " % s _ % s " % ( model . _meta . db_table , f . column ) ) NEW_LINE if ds : NEW_LINE INDENT output . append ( ds ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def create_test_db ( self , verbosity = 1 , autoclobber = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Creates ▁ a ▁ test ▁ database , ▁ prompting ▁ the ▁ user ▁ for ▁ confirmation ▁ if ▁ the STRNEWLINE ▁ database ▁ already ▁ exists . ▁ Returns ▁ the ▁ name ▁ of ▁ the ▁ test ▁ database ▁ created . STRNEWLINE ▁ """ NEW_LINE # ▁ Don ' t ▁ import ▁ django . core . management ▁ if ▁ it ▁ isn ' t ▁ needed . ENDCOM from django . core . management import call_command NEW_LINE test_database_name = self . _get_test_db_name ( ) NEW_LINE if verbosity >= 1 : NEW_LINE INDENT test_db_repr = ' ' NEW_LINE if verbosity >= 2 : NEW_LINE INDENT test_db_repr = " ▁ ( ' % s ' ) " % test_database_name NEW_LINE DEDENT print " Creating ▁ test ▁ database ▁ for ▁ alias ▁ ' % s ' % s . . . " % ( self . connection . alias , test_db_repr ) NEW_LINE DEDENT self . _create_test_db ( verbosity , autoclobber ) NEW_LINE self . connection . close ( ) NEW_LINE self . connection . settings_dict [ " NAME " ] = test_database_name NEW_LINE # ▁ Confirm ▁ the ▁ feature ▁ set ▁ of ▁ the ▁ test ▁ database ENDCOM self . connection . features . confirm ( ) NEW_LINE # ▁ Report ▁ syncdb ▁ messages ▁ at ▁ one ▁ level ▁ lower ▁ than ▁ that ▁ requested . ENDCOM # ▁ This ▁ ensures ▁ we ▁ don ' t ▁ get ▁ flooded ▁ with ▁ messages ▁ during ▁ testing ENDCOM # ▁ ( unless ▁ you ▁ really ▁ ask ▁ to ▁ be ▁ flooded ) ENDCOM call_command ( ' syncdb ' , verbosity = max ( verbosity - 1 , 0 ) , interactive = False , database = self . connection . alias , load_initial_data = False ) NEW_LINE # ▁ We ▁ need ▁ to ▁ then ▁ do ▁ a ▁ flush ▁ to ▁ ensure ▁ that ▁ any ▁ data ▁ installed ▁ by ENDCOM # ▁ custom ▁ SQL ▁ has ▁ been ▁ removed . ▁ The ▁ only ▁ test ▁ data ▁ should ▁ come ▁ from ENDCOM # ▁ test ▁ fixtures , ▁ or ▁ autogenerated ▁ from ▁ post _ syncdb ▁ triggers . ENDCOM # ▁ This ▁ has ▁ the ▁ side ▁ effect ▁ of ▁ loading ▁ initial ▁ data ▁ ( which ▁ was ENDCOM # ▁ intentionally ▁ skipped ▁ in ▁ the ▁ syncdb ) . ENDCOM call_command ( ' flush ' , verbosity = max ( verbosity - 1 , 0 ) , interactive = False , database = self . connection . alias ) NEW_LINE from django . core . cache import get_cache NEW_LINE from django . core . cache . backends . db import BaseDatabaseCache NEW_LINE for cache_alias in settings . CACHES : NEW_LINE INDENT cache = get_cache ( cache_alias ) NEW_LINE if isinstance ( cache , BaseDatabaseCache ) : NEW_LINE INDENT from django . db import router NEW_LINE if router . allow_syncdb ( self . connection . alias , cache . cache_model_class ) : NEW_LINE INDENT call_command ( ' createcachetable ' , cache . _table , database = self . connection . alias ) NEW_LINE # ▁ Get ▁ a ▁ cursor ▁ ( even ▁ though ▁ we ▁ don ' t ▁ need ▁ one ▁ yet ) . ▁ This ▁ has ENDCOM # ▁ the ▁ side ▁ effect ▁ of ▁ initializing ▁ the ▁ test ▁ database . ENDCOM DEDENT DEDENT DEDENT cursor = self . connection . cursor ( ) NEW_LINE return test_database_name NEW_LINE DEDENT def _get_test_db_name ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Internal ▁ implementation ▁ - ▁ returns ▁ the ▁ name ▁ of ▁ the ▁ test ▁ DB ▁ that ▁ will ▁ be STRNEWLINE ▁ created . ▁ Only ▁ useful ▁ when ▁ called ▁ from ▁ create _ test _ db ( ) ▁ and STRNEWLINE ▁ _ create _ test _ db ( ) ▁ and ▁ when ▁ no ▁ external ▁ munging ▁ is ▁ done ▁ with ▁ the ▁ ' NAME ' STRNEWLINE ▁ or ▁ ' TEST _ NAME ' ▁ settings . STRNEWLINE ▁ """ NEW_LINE if self . connection . settings_dict [ ' TEST _ NAME ' ] : NEW_LINE INDENT return self . connection . settings_dict [ ' TEST _ NAME ' ] NEW_LINE DEDENT return TEST_DATABASE_PREFIX + self . connection . settings_dict [ ' NAME ' ] NEW_LINE DEDENT def _create_test_db ( self , verbosity , autoclobber ) : NEW_LINE INDENT " Internal ▁ implementation ▁ - ▁ creates ▁ the ▁ test ▁ db ▁ tables . " NEW_LINE suffix = self . sql_table_creation_suffix ( ) NEW_LINE test_database_name = self . _get_test_db_name ( ) NEW_LINE qn = self . connection . ops . quote_name NEW_LINE # ▁ Create ▁ the ▁ test ▁ database ▁ and ▁ connect ▁ to ▁ it . ▁ We ▁ need ▁ to ▁ autocommit ENDCOM # ▁ if ▁ the ▁ database ▁ supports ▁ it ▁ because ▁ PostgreSQL ▁ doesn ' t ▁ allow ENDCOM # ▁ CREATE / DROP ▁ DATABASE ▁ statements ▁ within ▁ transactions . ENDCOM cursor = self . connection . cursor ( ) NEW_LINE self . set_autocommit ( ) NEW_LINE try : NEW_LINE INDENT cursor . execute ( " CREATE ▁ DATABASE ▁ % s ▁ % s " % ( qn ( test_database_name ) , suffix ) ) NEW_LINE DEDENT except Exception , e : NEW_LINE INDENT sys . stderr . write ( " Got ▁ an ▁ error ▁ creating ▁ the ▁ test ▁ database : ▁ % s \n " % e ) NEW_LINE if not autoclobber : NEW_LINE INDENT confirm = raw_input ( " Type ▁ ' yes ' ▁ if ▁ you ▁ would ▁ like ▁ to ▁ try ▁ deleting ▁ the ▁ test ▁ database ▁ ' % s ' , ▁ or ▁ ' no ' ▁ to ▁ cancel : ▁ " % test_database_name ) NEW_LINE DEDENT if autoclobber or confirm == ' yes ' : NEW_LINE INDENT try : NEW_LINE INDENT if verbosity >= 1 : NEW_LINE INDENT print " Destroying ▁ old ▁ test ▁ database ▁ ' % s ' . . . " % self . connection . alias NEW_LINE DEDENT cursor . execute ( " DROP ▁ DATABASE ▁ % s " % qn ( test_database_name ) ) NEW_LINE cursor . execute ( " CREATE ▁ DATABASE ▁ % s ▁ % s " % ( qn ( test_database_name ) , suffix ) ) NEW_LINE DEDENT except Exception , e : NEW_LINE INDENT sys . stderr . write ( " Got ▁ an ▁ error ▁ recreating ▁ the ▁ test ▁ database : ▁ % s \n " % e ) NEW_LINE sys . exit ( 2 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " Tests ▁ cancelled . " NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT DEDENT return test_database_name NEW_LINE DEDENT def destroy_test_db ( self , old_database_name , verbosity = 1 ) : NEW_LINE INDENT """ STRNEWLINE ▁ Destroy ▁ a ▁ test ▁ database , ▁ prompting ▁ the ▁ user ▁ for ▁ confirmation ▁ if ▁ the STRNEWLINE ▁ database ▁ already ▁ exists . ▁ Returns ▁ the ▁ name ▁ of ▁ the ▁ test ▁ database ▁ created . STRNEWLINE ▁ """ NEW_LINE self . connection . close ( ) NEW_LINE test_database_name = self . connection . settings_dict [ ' NAME ' ] NEW_LINE if verbosity >= 1 : NEW_LINE INDENT test_db_repr = ' ' NEW_LINE if verbosity >= 2 : NEW_LINE INDENT test_db_repr = " ▁ ( ' % s ' ) " % test_database_name NEW_LINE DEDENT print " Destroying ▁ test ▁ database ▁ for ▁ alias ▁ ' % s ' % s . . . " % ( self . connection . alias , test_db_repr ) NEW_LINE DEDENT self . connection . settings_dict [ ' NAME ' ] = old_database_name NEW_LINE self . _destroy_test_db ( test_database_name , verbosity ) NEW_LINE DEDENT def _destroy_test_db ( self , test_database_name , verbosity ) : NEW_LINE INDENT " Internal ▁ implementation ▁ - ▁ remove ▁ the ▁ test ▁ db ▁ tables . " NEW_LINE # ▁ Remove ▁ the ▁ test ▁ database ▁ to ▁ clean ▁ up ▁ after ENDCOM # ▁ ourselves . ▁ Connect ▁ to ▁ the ▁ previous ▁ database ▁ ( not ▁ the ▁ test ▁ database ) ENDCOM # ▁ to ▁ do ▁ so , ▁ because ▁ it ' s ▁ not ▁ allowed ▁ to ▁ delete ▁ a ▁ database ▁ while ▁ being ENDCOM # ▁ connected ▁ to ▁ it . ENDCOM cursor = self . connection . cursor ( ) NEW_LINE self . set_autocommit ( ) NEW_LINE time . sleep ( 1 ) # ▁ To ▁ avoid ▁ " database ▁ is ▁ being ▁ accessed ▁ by ▁ other ▁ users " ▁ errors . ENDCOM NEW_LINE cursor . execute ( " DROP ▁ DATABASE ▁ % s " % self . connection . ops . quote_name ( test_database_name ) ) NEW_LINE self . connection . close ( ) NEW_LINE DEDENT def set_autocommit ( self ) : NEW_LINE INDENT " Make ▁ sure ▁ a ▁ connection ▁ is ▁ in ▁ autocommit ▁ mode . " NEW_LINE if hasattr ( self . connection . connection , " autocommit " ) : NEW_LINE INDENT if callable ( self . connection . connection . autocommit ) : NEW_LINE INDENT self . connection . connection . autocommit ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . connection . connection . autocommit = True NEW_LINE DEDENT DEDENT elif hasattr ( self . connection . connection , " set _ isolation _ level " ) : NEW_LINE INDENT self . connection . connection . set_isolation_level ( 0 ) NEW_LINE DEDENT DEDENT def sql_table_creation_suffix ( self ) : NEW_LINE INDENT " SQL ▁ to ▁ append ▁ to ▁ the ▁ end ▁ of ▁ the ▁ test ▁ table ▁ creation ▁ statements " NEW_LINE return ' ' NEW_LINE DEDENT def test_db_signature ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ a ▁ tuple ▁ with ▁ elements ▁ of ▁ self . connection . settings _ dict ▁ ( a STRNEWLINE ▁ DATABASES ▁ setting ▁ value ) ▁ that ▁ uniquely ▁ identify ▁ a ▁ database STRNEWLINE ▁ accordingly ▁ to ▁ the ▁ RDBMS ▁ particularities . STRNEWLINE ▁ """ NEW_LINE settings_dict = self . connection . settings_dict NEW_LINE return ( settings_dict [ ' HOST ' ] , settings_dict [ ' PORT ' ] , settings_dict [ ' ENGINE ' ] , settings_dict [ ' NAME ' ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="PaulWay/insights-core/tree/master/insights/parsers/tests/test_foreman_log.py"> from insights . tests import context_wrap NEW_LINE from insights . parsers . foreman_log import SatelliteLog , ProductionLog NEW_LINE from insights . parsers . foreman_log import CandlepinLog , ProxyLog NEW_LINE PRODUCTION_LOG = """ STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 1783ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 172.9ms ) STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : V2 : : RepositoriesController # sync _ complete ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " call _ report " = > " [ FILTERED ] " , ▁ " event _ type " = > " repo . sync . finish " , ▁ " payload " = > { " importer _ id " = > " yum _ importer " , ▁ " exception " = > nil , ▁ " repo _ id " = > " 1 - Gulfstream _ Aerospace _ Corp _ - Red _ Hat _ Enterprise _ Linux _ Server - Red _ Hat _ Satellite _ Tools _ 6_1 _ for _ RHEL _ 6 _ Server _ RPMs _ i386 " , ▁ " traceback " = > nil , ▁ " started " = > " 2015-11-13T08:30:00Z " , ▁ " _ ns " = > " repo _ sync _ results " , ▁ " completed " = > " 2015-11-13T08:30:06Z " , ▁ " importer _ type _ id " = > " yum _ importer " , ▁ " error _ message " = > nil , ▁ " summary " = > { " content " = > { " state " = > " FINISHED " } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " state " = > " FINISHED " } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " added _ count " = > 0 , ▁ " result " = > " success " , ▁ " updated _ count " = > 3 , ▁ " details " = > { " content " = > { " size _ total " = > 0 , ▁ " items _ left " = > 0 , ▁ " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " size _ left " = > 0 , ▁ " details " = > { " rpm _ total " = > 0 , ▁ " rpm _ done " = > 0 , ▁ " drpm _ total " = > 0 , ▁ " drpm _ done " = > 0 } , ▁ " error _ details " = > [ ] } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " error _ details " = > [ ] , ▁ " items _ left " = > 0 } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " id " = > " 56459f8ef301a213bbfd87bb " , ▁ " removed _ count " = > 0 } , ▁ " token " = > " oQumn3XsKrdRkijuvpCNhKF2PDWZt6az " , ▁ " api _ version " = > " v2 " , ▁ " repository " = > { } } STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ Red ▁ Hat ▁ Satellite ▁ Tools ▁ 6.1 ▁ for ▁ RHEL ▁ 6 ▁ Server ▁ RPMs ▁ i386 , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:30:09 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 1995ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 81.5ms ) STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : V2 : : RepositoriesController # sync _ complete ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " call _ report " = > " [ FILTERED ] " , ▁ " event _ type " = > " repo . sync . finish " , ▁ " payload " = > { " importer _ id " = > " yum _ importer " , ▁ " exception " = > nil , ▁ " repo _ id " = > " 1 - Gulfstream _ Aerospace _ Corp _ - Red _ Hat _ Enterprise _ Linux _ Server - Red _ Hat _ Satellite _ Tools _ 6_1 _ for _ RHEL _ 5 _ Server _ RPMs _ i386 " , ▁ " traceback " = > nil , ▁ " started " = > " 2015-11-13T08:30:05Z " , ▁ " _ ns " = > " repo _ sync _ results " , ▁ " completed " = > " 2015-11-13T08:30:10Z " , ▁ " importer _ type _ id " = > " yum _ importer " , ▁ " error _ message " = > nil , ▁ " summary " = > { " content " = > { " state " = > " FINISHED " } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " state " = > " FINISHED " } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " added _ count " = > 0 , ▁ " result " = > " success " , ▁ " updated _ count " = > 3 , ▁ " details " = > { " content " = > { " size _ total " = > 0 , ▁ " items _ left " = > 0 , ▁ " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " size _ left " = > 0 , ▁ " details " = > { " rpm _ total " = > 0 , ▁ " rpm _ done " = > 0 , ▁ " drpm _ total " = > 0 , ▁ " drpm _ done " = > 0 } , ▁ " error _ details " = > [ ] } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " error _ details " = > [ ] , ▁ " items _ left " = > 0 } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " id " = > " 56459f92f301a2137cd6b802 " , ▁ " removed _ count " = > 0 } , ▁ " token " = > " oQumn3XsKrdRkijuvpCNhKF2PDWZt6az " , ▁ " api _ version " = > " v2 " , ▁ " repository " = > { } } STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ Red ▁ Hat ▁ Satellite ▁ Tools ▁ 6.1 ▁ for ▁ RHEL ▁ 5 ▁ Server ▁ RPMs ▁ i386 , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 818ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 77.2ms ) STRNEWLINE 2015-11-13 ▁ 03:30:17 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:26 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ RHN ▁ Tools ▁ for ▁ Red ▁ Hat ▁ Enterprise ▁ Linux ▁ 5 ▁ Server ▁ RPMs ▁ x86_64 ▁ 5Server , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:50:46 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 2583ms ▁ ( Views : ▁ 2.7ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 06:58:25 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 06:58:25 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 249ms ▁ ( Views : ▁ 3.1ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 84ms ▁ ( Views : ▁ 3.1ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " facts " = > " [ FILTERED ] " , ▁ " name " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " certname " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " apiv " = > " v2 " , ▁ : host = > { " name " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " certname " = > " infrhnpl002 . gac . gulfaero . com " } } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Import ▁ facts ▁ for ▁ ' infrhnpl002 . gac . gulfaero . com ' ▁ completed . ▁ Added : ▁ 0 , ▁ Updated : ▁ 6 , ▁ Deleted ▁ 0 ▁ facts STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 201 ▁ Created ▁ in ▁ 251ms ▁ ( Views : ▁ 179.3ms ▁ | ▁ ActiveRecord : ▁ 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Processing ▁ by ▁ HostsController # externalNodes ▁ as ▁ YML STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " name " = > " infrhnpl002 . gac . gulfaero . com " } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Rendered ▁ text ▁ template ▁ ( 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 48ms ▁ ( Views : ▁ 0.5ms ▁ | ▁ ActiveRecord : ▁ 6.6ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Processing ▁ by ▁ Api : : V2 : : ReportsController # create ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " report " = > " [ FILTERED ] " , ▁ " apiv " = > " v2 " } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Rendered ▁ text ▁ template ▁ ( 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ processing ▁ report ▁ for ▁ infrhnpl002 . gac . gulfaero . com STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Imported ▁ report ▁ for ▁ infrhnpl002 . gac . gulfaero . com ▁ in ▁ 0.02 ▁ seconds STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 201 ▁ Created ▁ in ▁ 28ms ▁ ( Views : ▁ 1.2ms ▁ | ▁ ActiveRecord : ▁ 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:30:17 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 110ms ▁ ( Views : ▁ 2.7ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 07:30:33 ▁ [ I ] ▁ 2015-11-13 ▁ 07:30:33 ▁ - 0500 : ▁ Expired ▁ 48 ▁ Reports STRNEWLINE 2015-11-13 ▁ 07:30:33 ▁ [ I ] ▁ Client ▁ disconnected . STRNEWLINE 2015-11-13 ▁ 09:41:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 93ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 80ms ▁ ( Views : ▁ 3.6ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 09:43:58 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 09:43:58 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 09:43:59 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 80ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE """ . strip ( ) NEW_LINE SATELLITE_OUT = """ STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ cert ] / require : ▁ requires ▁ Class [ Certs : : Pulp _ client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ cert ] / require : ▁ requires ▁ Exec [ foreman - rake - db : seed ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ key ] / require : ▁ requires ▁ Class [ Certs : : Pulp _ client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ key ] / require : ▁ requires ▁ Exec [ foreman - rake - db : seed ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / before : ▁ requires ▁ Class [ Foreman : : Database ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / before : ▁ requires ▁ Exec [ foreman - rake - db : migrate ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / notify : ▁ subscribes ▁ to ▁ Service [ foreman - tasks ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / notify : ▁ subscribes ▁ to ▁ Class [ Foreman : : Service ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / Foreman : : Config : : Passenger : : Fragment [ katello ] / require : ▁ requires ▁ Class [ Foreman : : Config : : Passenger ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / notify : ▁ subscribes ▁ to ▁ Class [ Certs : : Candlepin ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Cert [ kam1opapp999 . connex . bclc . com - qpid - broker ] / notify : ▁ subscribes ▁ to ▁ Pubkey [ / etc / pki / katello / certs / kam1opapp999 . connex . bclc . com - qpid - broker . crt ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Pubkey [ / etc / pki / katello / certs / kam1opapp999 . connex . bclc . com - qpid - broker . crt ] / notify : ▁ subscribes ▁ to ▁ Privkey [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Privkey [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb ] / notify : ▁ subscribes ▁ to ▁ Exec [ generate - nss - password ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ generate - nss - password ] / before : ▁ requires ▁ File [ / etc / pki / katello / nssdb / nss _ db _ password - file ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / nss _ db _ password - file ] / notify : ▁ subscribes ▁ to ▁ Exec [ create - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ ca ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ amqp - client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ ca ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / cert8 . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / key3 . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / secmod . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / cert8 . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / key3 . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / secmod . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ broker ] / notify : ▁ subscribes ▁ to ▁ Exec [ generate - pfx - for - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ generate - pfx - for - nss - db ] / notify : ▁ subscribes ▁ to ▁ Exec [ add - private - key - to - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ add - private - key - to - nss - db ] / notify : ▁ subscribes ▁ to ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Cert [ java - client ] / notify : ▁ subscribes ▁ to ▁ Pubkey [ / etc / pki / katello / certs / java - client . crt ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / pki / katello / keystore _ password - file ] / notify : ▁ subscribes ▁ to ▁ Exec [ candlepin - generate - ssl - keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ candlepin - generate - ssl - keystore ] / notify : ▁ subscribes ▁ to ▁ File [ / usr / share / tomcat / conf / keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / usr / share / tomcat / conf / keystore ] / notify : ▁ subscribes ▁ to ▁ Service [ tomcat ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Pubkey [ / etc / pki / katello / certs / java - client . crt ] / notify : ▁ subscribes ▁ to ▁ Privkey [ / etc / pki / katello / private / java - client . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Privkey [ / etc / pki / katello / private / java - client . key ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ amqp - client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / subscribe : ▁ subscribes ▁ to ▁ Exec [ create - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / notify : ▁ subscribes ▁ to ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / candlepin / certs / amqp ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / candlepin / certs / amqp ] / notify : ▁ subscribes ▁ to ▁ Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] / require : ▁ requires ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] / notify : ▁ subscribes ▁ to ▁ Exec [ import ▁ CA ▁ into ▁ Candlepin ▁ truststore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ import ▁ CA ▁ into ▁ Candlepin ▁ truststore ] / notify : ▁ subscribes ▁ to ▁ Exec [ import ▁ client ▁ certificate ▁ into ▁ Candlepin ▁ keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ import ▁ client ▁ certificate ▁ into ▁ Candlepin ▁ keystore ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / candlepin / certs / amqp / candlepin . jks ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / candlepin / certs / amqp / candlepin . jks ] / notify : ▁ subscribes ▁ to ▁ Service [ tomcat ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin / notify : ▁ subscribes ▁ to ▁ Class [ Qpid ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Install / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Config ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Config / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Database ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Database / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Service ] STRNEWLINE """ . strip ( ) NEW_LINE CANDLEPIN_LOG = """ STRNEWLINE 2016-09-09 ▁ 13:45:52,650 ▁ [ req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b STRNEWLINE 2016-09-09 ▁ 13:45:52,784 ▁ [ req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc , ▁ org = ING _ Luxembourg _ SA ] ▁ INFO ▁ ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 134 STRNEWLINE 2016-09-09 ▁ 13:45:52,947 ▁ [ req = 909ca4c5 - f24e - 4212-8f23 - cc754d06ac57 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b / content _ overrides STRNEWLINE 2016-09-09 ▁ 13:45:52,976 ▁ [ req = 909ca4c5 - f24e - 4212-8f23 - cc754d06ac57 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 29 STRNEWLINE 2016-09-09 ▁ 13:45:53,072 ▁ [ req = 49becd26-5dfe - 4d2f - 8667-470519230d88 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b / release STRNEWLINE 2016-09-09 ▁ 13:45:53,115 ▁ [ req = 49becd26-5dfe - 4d2f - 8667-470519230d88 , ▁ org = ING _ Luxembourg _ SA ] ▁ INFO ▁ ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 43 STRNEWLINE """ . strip ( ) NEW_LINE PROXY_LOG = """ STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:28 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL _ 6_5 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 6.1205 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:38 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL _ 7_6 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 4.4754 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:49 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL6_8 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 4.5776 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:57:34 ▁ - 0400 ] ▁ " GET ▁ / tftp / serverName ▁ HTTP / 1.1 " ▁ 200 ▁ 38 ▁ 0.0014 STRNEWLINE E , ▁ [ 2016-05-31T09:57:34.884636 ▁ # 4494 ] ▁ ERROR ▁ - - ▁ : ▁ Record ▁ 172.16.100.0/172.16.100.17 ▁ not ▁ found ▁ ] STRNEWLINE """ . strip ( ) NEW_LINE def test_production_log ( ) : NEW_LINE INDENT fm_log = ProductionLog ( context_wrap ( PRODUCTION_LOG ) ) NEW_LINE assert 2 == len ( fm_log . get ( " Rendered ▁ text ▁ template " ) ) NEW_LINE assert " Expired ▁ 48 ▁ Reports " in fm_log NEW_LINE assert fm_log . get ( " Completed ▁ 200 ▁ OK ▁ in ▁ 93" ) [ 0 ] == "2015-11-13 ▁ 09:41:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 93ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) " NEW_LINE DEDENT def test_proxy_log ( ) : NEW_LINE INDENT px_log = ProxyLog ( context_wrap ( PROXY_LOG ) ) NEW_LINE assert " ERROR ▁ - - ▁ " in px_log NEW_LINE assert len ( px_log . get ( " KT _ Encore _ Library _ RHEL " ) ) == 3 NEW_LINE DEDENT def test_candlepin_log ( ) : NEW_LINE INDENT cp_log = CandlepinLog ( context_wrap ( CANDLEPIN_LOG ) ) NEW_LINE assert " req = 49becd26-5dfe - 4d2f - 8667-470519230d88" in cp_log NEW_LINE assert len ( cp_log . get ( " req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc " ) ) == 2 NEW_LINE DEDENT def test_satellite_log ( ) : NEW_LINE INDENT sat_log = SatelliteLog ( context_wrap ( SATELLITE_OUT ) ) NEW_LINE assert " subscribes ▁ to ▁ Class [ Qpid ] " in sat_log NEW_LINE assert len ( sat_log . get ( " notify : ▁ subscribes ▁ to ▁ Class [ " ) ) == 7 NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="adobe/chromium/tree/master/third_party/closure_linter/closure_linter/error_fixer.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Copyright ▁ 2007 ▁ The ▁ Closure ▁ Linter ▁ Authors . ▁ All ▁ Rights ▁ Reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ENDCOM # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ENDCOM # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS - IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM """ Main ▁ class ▁ responsible ▁ for ▁ automatically ▁ fixing ▁ simple ▁ style ▁ violations . """ NEW_LINE __author__ = ' robbyw @ google . com ▁ ( Robert ▁ Walker ) ' NEW_LINE import re NEW_LINE import gflags as flags NEW_LINE from closure_linter import errors NEW_LINE from closure_linter import javascriptstatetracker NEW_LINE from closure_linter import javascripttokens NEW_LINE from closure_linter import requireprovidesorter NEW_LINE from closure_linter import tokenutil NEW_LINE from closure_linter . common import errorhandler NEW_LINE # ▁ Shorthand ENDCOM Token = javascripttokens . JavaScriptToken NEW_LINE Type = javascripttokens . JavaScriptTokenType NEW_LINE END_OF_FLAG_TYPE = re . compile ( r ' ( } ? \s * ) $ ' ) NEW_LINE # ▁ Regex ▁ to ▁ represent ▁ common ▁ mistake ▁ inverting ▁ author ▁ name ▁ and ▁ email ▁ as ENDCOM # ▁ @ author ▁ User ▁ Name ▁ ( user @ company ) ENDCOM INVERTED_AUTHOR_SPEC = re . compile ( r ' ( ? P < leading _ whitespace > \s * ) ' ' ( ? P < name > [ ^ ( ] + ) ' ' ( ? P < whitespace _ after _ name > \s + ) ' ' ( ? P < email > [ ^ \s ] + @ [ ^ ) \s ] + ) ' ' ( ? P < trailing _ characters > . * ) ' ) FLAGS = flags . FLAGS NEW_LINE flags . DEFINE_boolean ( ' disable _ indentation _ fixing ' , False , ' Whether ▁ to ▁ disable ▁ automatic ▁ fixing ▁ of ▁ indentation . ' ) NEW_LINE class ErrorFixer ( errorhandler . ErrorHandler ) : NEW_LINE INDENT """ Object ▁ that ▁ fixes ▁ simple ▁ style ▁ errors . """ NEW_LINE def __init__ ( self , external_file = None ) : NEW_LINE INDENT """ Initialize ▁ the ▁ error ▁ fixer . STRNEWLINE STRNEWLINE ▁ Args : STRNEWLINE ▁ external _ file : ▁ If ▁ included , ▁ all ▁ output ▁ will ▁ be ▁ directed ▁ to ▁ this ▁ file STRNEWLINE ▁ instead ▁ of ▁ overwriting ▁ the ▁ files ▁ the ▁ errors ▁ are ▁ found ▁ in . STRNEWLINE ▁ """ NEW_LINE errorhandler . ErrorHandler . __init__ ( self ) NEW_LINE self . _file_name = None NEW_LINE self . _file_token = None NEW_LINE self . _external_file = external_file NEW_LINE DEDENT def HandleFile ( self , filename , first_token ) : NEW_LINE INDENT """ Notifies ▁ this ▁ ErrorPrinter ▁ that ▁ subsequent ▁ errors ▁ are ▁ in ▁ filename . STRNEWLINE STRNEWLINE ▁ Args : STRNEWLINE ▁ filename : ▁ The ▁ name ▁ of ▁ the ▁ file ▁ about ▁ to ▁ be ▁ checked . STRNEWLINE ▁ first _ token : ▁ The ▁ first ▁ token ▁ in ▁ the ▁ file . STRNEWLINE ▁ """ NEW_LINE self . _file_name = filename NEW_LINE self . _file_token = first_token NEW_LINE self . _file_fix_count = 0 NEW_LINE self . _file_changed_lines = set ( ) NEW_LINE DEDENT def _AddFix ( self , tokens ) : NEW_LINE INDENT """ Adds ▁ the ▁ fix ▁ to ▁ the ▁ internal ▁ count . STRNEWLINE STRNEWLINE ▁ Args : STRNEWLINE ▁ tokens : ▁ The ▁ token ▁ or ▁ sequence ▁ of ▁ tokens ▁ changed ▁ to ▁ fix ▁ an ▁ error . STRNEWLINE ▁ """ NEW_LINE self . _file_fix_count += 1 NEW_LINE if hasattr ( tokens , ' line _ number ' ) : NEW_LINE INDENT self . _file_changed_lines . add ( tokens . line_number ) NEW_LINE DEDENT else : NEW_LINE INDENT for token in tokens : NEW_LINE INDENT self . _file_changed_lines . add ( token . line_number ) NEW_LINE DEDENT DEDENT DEDENT def HandleError ( self , error ) : NEW_LINE INDENT """ Attempts ▁ to ▁ fix ▁ the ▁ error . STRNEWLINE STRNEWLINE ▁ Args : STRNEWLINE ▁ error : ▁ The ▁ error ▁ object STRNEWLINE ▁ """ NEW_LINE code = error . code NEW_LINE token = error . token NEW_LINE if code == errors . JSDOC_PREFER_QUESTION_TO_PIPE_NULL : NEW_LINE INDENT iterator = token . attached_object . type_start_token NEW_LINE if iterator . type == Type . DOC_START_BRACE or iterator . string . isspace ( ) : NEW_LINE INDENT iterator = iterator . next NEW_LINE DEDENT leading_space = len ( iterator . string ) - len ( iterator . string . lstrip ( ) ) NEW_LINE iterator . string = ' % s ? % s ' % ( ' ▁ ' * leading_space , iterator . string . lstrip ( ) ) NEW_LINE # ▁ Cover ▁ the ▁ no ▁ outer ▁ brace ▁ case ▁ where ▁ the ▁ end ▁ token ▁ is ▁ part ▁ of ▁ the ▁ type . ENDCOM while iterator and iterator != token . attached_object . type_end_token . next : NEW_LINE INDENT iterator . string = iterator . string . replace ( ' null | ' , ' ' ) . replace ( ' | null ' , ' ' ) NEW_LINE iterator = iterator . next NEW_LINE # ▁ Create ▁ a ▁ new ▁ flag ▁ object ▁ with ▁ updated ▁ type ▁ info . ENDCOM DEDENT token . attached_object = javascriptstatetracker . JsDocFlag ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . JSDOC_MISSING_OPTIONAL_TYPE : NEW_LINE INDENT iterator = token . attached_object . type_end_token NEW_LINE if iterator . type == Type . DOC_END_BRACE or iterator . string . isspace ( ) : NEW_LINE INDENT iterator = iterator . previous NEW_LINE DEDENT ending_space = len ( iterator . string ) - len ( iterator . string . rstrip ( ) ) NEW_LINE iterator . string = ' % s = % s ' % ( iterator . string . rstrip ( ) , ' ▁ ' * ending_space ) NEW_LINE # ▁ Create ▁ a ▁ new ▁ flag ▁ object ▁ with ▁ updated ▁ type ▁ info . ENDCOM token . attached_object = javascriptstatetracker . JsDocFlag ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code in ( errors . MISSING_SEMICOLON_AFTER_FUNCTION , errors . MISSING_SEMICOLON ) : NEW_LINE INDENT semicolon_token = Token ( ' ; ' , Type . SEMICOLON , token . line , token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( semicolon_token , token ) NEW_LINE token . metadata . is_implied_semicolon = False NEW_LINE semicolon_token . metadata . is_implied_semicolon = False NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code in ( errors . ILLEGAL_SEMICOLON_AFTER_FUNCTION , errors . REDUNDANT_SEMICOLON , errors . COMMA_AT_END_OF_LITERAL ) : NEW_LINE INDENT tokenutil . DeleteToken ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . INVALID_JSDOC_TAG : NEW_LINE INDENT if token . string == ' @ returns ' : NEW_LINE INDENT token . string = ' @ return ' NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . FILE_MISSING_NEWLINE : NEW_LINE # ▁ This ▁ error ▁ is ▁ fixed ▁ implicitly ▁ by ▁ the ▁ way ▁ we ▁ restore ▁ the ▁ file ENDCOM INDENT self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . MISSING_SPACE : NEW_LINE INDENT if error . position : NEW_LINE INDENT if error . position . IsAtBeginning ( ) : NEW_LINE INDENT tokenutil . InsertSpaceTokenAfter ( token . previous ) NEW_LINE DEDENT elif error . position . IsAtEnd ( token . string ) : NEW_LINE INDENT tokenutil . InsertSpaceTokenAfter ( token ) NEW_LINE DEDENT else : NEW_LINE INDENT token . string = error . position . Set ( token . string , ' ▁ ' ) NEW_LINE DEDENT self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . EXTRA_SPACE : NEW_LINE INDENT if error . position : NEW_LINE INDENT token . string = error . position . Set ( token . string , ' ' ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . JSDOC_TAG_DESCRIPTION_ENDS_WITH_INVALID_CHARACTER : NEW_LINE INDENT token . string = error . position . Set ( token . string , ' . ' ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . MISSING_LINE : NEW_LINE INDENT if error . position . IsAtBeginning ( ) : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( token . previous ) NEW_LINE DEDENT else : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( token ) NEW_LINE DEDENT self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . EXTRA_LINE : NEW_LINE INDENT tokenutil . DeleteToken ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . WRONG_BLANK_LINE_COUNT : NEW_LINE INDENT if not token . previous : NEW_LINE # ▁ TODO ( user ) : ▁ Add ▁ an ▁ insertBefore ▁ method ▁ to ▁ tokenutil . ENDCOM INDENT return NEW_LINE DEDENT num_lines = error . fix_data NEW_LINE should_delete = False NEW_LINE if num_lines < 0 : NEW_LINE INDENT num_lines *= - 1 NEW_LINE should_delete = True NEW_LINE DEDENT for i in xrange ( 1 , num_lines + 1 ) : NEW_LINE INDENT if should_delete : NEW_LINE # ▁ TODO ( user ) : ▁ DeleteToken ▁ should ▁ update ▁ line ▁ numbers . ENDCOM INDENT tokenutil . DeleteToken ( token . previous ) NEW_LINE DEDENT else : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( token . previous ) NEW_LINE DEDENT self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . UNNECESSARY_DOUBLE_QUOTED_STRING : NEW_LINE INDENT end_quote = tokenutil . Search ( token , Type . DOUBLE_QUOTE_STRING_END ) NEW_LINE if end_quote : NEW_LINE INDENT single_quote_start = Token ( " ' " , Type . SINGLE_QUOTE_STRING_START , token . line , token . line_number ) NEW_LINE single_quote_end = Token ( " ' " , Type . SINGLE_QUOTE_STRING_START , end_quote . line , token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( single_quote_start , token ) NEW_LINE tokenutil . InsertTokenAfter ( single_quote_end , end_quote ) NEW_LINE tokenutil . DeleteToken ( token ) NEW_LINE tokenutil . DeleteToken ( end_quote ) NEW_LINE self . _AddFix ( [ token , end_quote ] ) NEW_LINE DEDENT DEDENT elif code == errors . MISSING_BRACES_AROUND_TYPE : NEW_LINE INDENT fixed_tokens = [ ] NEW_LINE start_token = token . attached_object . type_start_token NEW_LINE if start_token . type != Type . DOC_START_BRACE : NEW_LINE INDENT leading_space = ( len ( start_token . string ) - len ( start_token . string . lstrip ( ) ) ) NEW_LINE if leading_space : NEW_LINE INDENT start_token = tokenutil . SplitToken ( start_token , leading_space ) NEW_LINE # ▁ Fix ▁ case ▁ where ▁ start ▁ and ▁ end ▁ token ▁ were ▁ the ▁ same . ENDCOM if token . attached_object . type_end_token == start_token . previous : NEW_LINE INDENT token . attached_object . type_end_token = start_token NEW_LINE DEDENT DEDENT new_token = Token ( ' { ' , Type . DOC_START_BRACE , start_token . line , start_token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( new_token , start_token . previous ) NEW_LINE token . attached_object . type_start_token = new_token NEW_LINE fixed_tokens . append ( new_token ) NEW_LINE DEDENT end_token = token . attached_object . type_end_token NEW_LINE if end_token . type != Type . DOC_END_BRACE : NEW_LINE # ▁ If ▁ the ▁ start ▁ token ▁ was ▁ a ▁ brace , ▁ the ▁ end ▁ token ▁ will ▁ be ▁ a ENDCOM # ▁ FLAG _ ENDING _ TYPE ▁ token , ▁ if ▁ there ▁ wasn ' t ▁ a ▁ starting ▁ brace ▁ then ENDCOM # ▁ the ▁ end ▁ token ▁ is ▁ the ▁ last ▁ token ▁ of ▁ the ▁ actual ▁ type . ENDCOM INDENT last_type = end_token NEW_LINE if not fixed_tokens : NEW_LINE INDENT last_type = end_token . previous NEW_LINE DEDENT while last_type . string . isspace ( ) : NEW_LINE INDENT last_type = last_type . previous NEW_LINE # ▁ If ▁ there ▁ was ▁ no ▁ starting ▁ brace ▁ then ▁ a ▁ lone ▁ end ▁ brace ▁ wouldn ' t ▁ have ENDCOM # ▁ been ▁ type ▁ end ▁ token . ▁ Now ▁ that ▁ we ' ve ▁ added ▁ any ▁ missing ▁ start ▁ brace , ENDCOM # ▁ see ▁ if ▁ the ▁ last ▁ effective ▁ type ▁ token ▁ was ▁ an ▁ end ▁ brace . ENDCOM DEDENT if last_type . type != Type . DOC_END_BRACE : NEW_LINE INDENT trailing_space = ( len ( last_type . string ) - len ( last_type . string . rstrip ( ) ) ) NEW_LINE if trailing_space : NEW_LINE INDENT tokenutil . SplitToken ( last_type , len ( last_type . string ) - trailing_space ) NEW_LINE DEDENT new_token = Token ( ' } ' , Type . DOC_END_BRACE , last_type . line , last_type . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( new_token , last_type ) NEW_LINE token . attached_object . type_end_token = new_token NEW_LINE fixed_tokens . append ( new_token ) NEW_LINE DEDENT DEDENT self . _AddFix ( fixed_tokens ) NEW_LINE DEDENT elif code == errors . GOOG_REQUIRES_NOT_ALPHABETIZED : NEW_LINE INDENT require_start_token = error . fix_data NEW_LINE sorter = requireprovidesorter . RequireProvideSorter ( ) NEW_LINE sorter . FixRequires ( require_start_token ) NEW_LINE self . _AddFix ( require_start_token ) NEW_LINE DEDENT elif code == errors . GOOG_PROVIDES_NOT_ALPHABETIZED : NEW_LINE INDENT provide_start_token = error . fix_data NEW_LINE sorter = requireprovidesorter . RequireProvideSorter ( ) NEW_LINE sorter . FixProvides ( provide_start_token ) NEW_LINE self . _AddFix ( provide_start_token ) NEW_LINE DEDENT elif code == errors . UNNECESSARY_BRACES_AROUND_INHERIT_DOC : NEW_LINE INDENT if token . previous . string == ' { ' and token . next . string == ' } ' : NEW_LINE INDENT tokenutil . DeleteToken ( token . previous ) NEW_LINE tokenutil . DeleteToken ( token . next ) NEW_LINE self . _AddFix ( [ token ] ) NEW_LINE DEDENT DEDENT elif code == errors . INVALID_AUTHOR_TAG_DESCRIPTION : NEW_LINE INDENT match = INVERTED_AUTHOR_SPEC . match ( token . string ) NEW_LINE if match : NEW_LINE INDENT token . string = ' % s % s % s ( % s ) % s ' % ( match . group ( ' leading _ whitespace ' ) , match . group ( ' email ' ) , match . group ( ' whitespace _ after _ name ' ) , match . group ( ' name ' ) , match . group ( ' trailing _ characters ' ) ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif ( code == errors . WRONG_INDENTATION and not FLAGS . disable_indentation_fixing ) : NEW_LINE INDENT token = tokenutil . GetFirstTokenInSameLine ( token ) NEW_LINE actual = error . position . start NEW_LINE expected = error . position . length NEW_LINE if token . type in ( Type . WHITESPACE , Type . PARAMETERS ) and actual != 0 : NEW_LINE INDENT token . string = token . string . lstrip ( ) + ( ' ▁ ' * expected ) NEW_LINE self . _AddFix ( [ token ] ) NEW_LINE DEDENT else : NEW_LINE # ▁ We ▁ need ▁ to ▁ add ▁ indentation . ENDCOM INDENT new_token = Token ( ' ▁ ' * expected , Type . WHITESPACE , token . line , token . line_number ) NEW_LINE # ▁ Note ▁ that ▁ we ' ll ▁ never ▁ need ▁ to ▁ add ▁ indentation ▁ at ▁ the ▁ first ▁ line , ENDCOM # ▁ since ▁ it ▁ will ▁ always ▁ not ▁ be ▁ indented . ▁ Therefore ▁ it ' s ▁ safe ▁ to ▁ assume ENDCOM # ▁ token . previous ▁ exists . ENDCOM tokenutil . InsertTokenAfter ( new_token , token . previous ) NEW_LINE self . _AddFix ( [ token ] ) NEW_LINE DEDENT DEDENT elif code in [ errors . MALFORMED_END_OF_SCOPE_COMMENT , errors . MISSING_END_OF_SCOPE_COMMENT ] : NEW_LINE # ▁ Only ▁ fix ▁ cases ▁ where ▁ } ) ; ▁ is ▁ found ▁ with ▁ no ▁ trailing ▁ content ▁ on ▁ the ▁ line ENDCOM # ▁ other ▁ than ▁ a ▁ comment . ▁ Value ▁ of ▁ ' token ' ▁ is ▁ set ▁ to ▁ } ▁ for ▁ this ▁ error . ENDCOM INDENT if ( token . type == Type . END_BLOCK and token . next . type == Type . END_PAREN and token . next . next . type == Type . SEMICOLON ) : NEW_LINE INDENT current_token = token . next . next . next NEW_LINE removed_tokens = [ ] NEW_LINE while current_token and current_token . line_number == token . line_number : NEW_LINE INDENT if current_token . IsAnyType ( Type . WHITESPACE , Type . START_SINGLE_LINE_COMMENT , Type . COMMENT ) : NEW_LINE INDENT removed_tokens . append ( current_token ) NEW_LINE current_token = current_token . next NEW_LINE DEDENT else : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT if removed_tokens : NEW_LINE INDENT tokenutil . DeleteTokens ( removed_tokens [ 0 ] , len ( removed_tokens ) ) NEW_LINE DEDENT whitespace_token = Token ( ' ▁ ▁ ' , Type . WHITESPACE , token . line , token . line_number ) NEW_LINE start_comment_token = Token ( ' / / ' , Type . START_SINGLE_LINE_COMMENT , token . line , token . line_number ) NEW_LINE comment_token = Token ( ' ▁ goog . scope ' , Type . COMMENT , token . line , token . line_number ) NEW_LINE insertion_tokens = [ whitespace_token , start_comment_token , comment_token ] NEW_LINE tokenutil . InsertTokensAfter ( insertion_tokens , token . next . next ) NEW_LINE self . _AddFix ( removed_tokens + insertion_tokens ) NEW_LINE DEDENT DEDENT elif code in [ errors . EXTRA_GOOG_PROVIDE , errors . EXTRA_GOOG_REQUIRE ] : NEW_LINE INDENT tokens_in_line = tokenutil . GetAllTokensInSameLine ( token ) NEW_LINE tokenutil . DeleteTokens ( tokens_in_line [ 0 ] , len ( tokens_in_line ) ) NEW_LINE self . _AddFix ( tokens_in_line ) NEW_LINE DEDENT elif code in [ errors . MISSING_GOOG_PROVIDE , errors . MISSING_GOOG_REQUIRE ] : NEW_LINE INDENT is_provide = code == errors . MISSING_GOOG_PROVIDE NEW_LINE is_require = code == errors . MISSING_GOOG_REQUIRE NEW_LINE missing_namespaces = error . fix_data [ 0 ] NEW_LINE need_blank_line = error . fix_data [ 1 ] NEW_LINE if need_blank_line is None : NEW_LINE # ▁ TODO ( user ) : ▁ This ▁ happens ▁ when ▁ there ▁ are ▁ no ▁ existing ENDCOM # ▁ goog . provide ▁ or ▁ goog . require ▁ statements ▁ to ▁ position ▁ new ▁ statements ENDCOM # ▁ relative ▁ to . ▁ Consider ▁ handling ▁ this ▁ case ▁ with ▁ a ▁ heuristic . ENDCOM INDENT return NEW_LINE DEDENT insert_location = token . previous NEW_LINE # ▁ If ▁ inserting ▁ a ▁ missing ▁ require ▁ with ▁ no ▁ existing ▁ requires , ▁ insert ▁ a ENDCOM # ▁ blank ▁ line ▁ first . ENDCOM if need_blank_line and is_require : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( insert_location ) NEW_LINE insert_location = insert_location . next NEW_LINE DEDENT for missing_namespace in missing_namespaces : NEW_LINE INDENT new_tokens = self . _GetNewRequireOrProvideTokens ( is_provide , missing_namespace , insert_location . line_number + 1 ) NEW_LINE tokenutil . InsertLineAfter ( insert_location , new_tokens ) NEW_LINE insert_location = new_tokens [ - 1 ] NEW_LINE self . _AddFix ( new_tokens ) NEW_LINE # ▁ If ▁ inserting ▁ a ▁ missing ▁ provide ▁ with ▁ no ▁ existing ▁ provides , ▁ insert ▁ a ENDCOM # ▁ blank ▁ line ▁ after . ENDCOM DEDENT if need_blank_line and is_provide : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( insert_location ) NEW_LINE DEDENT DEDENT DEDENT def _GetNewRequireOrProvideTokens ( self , is_provide , namespace , line_number ) : NEW_LINE INDENT """ Returns ▁ a ▁ list ▁ of ▁ tokens ▁ to ▁ create ▁ a ▁ goog . require / provide ▁ statement . STRNEWLINE STRNEWLINE ▁ Args : STRNEWLINE ▁ is _ provide : ▁ True ▁ if ▁ getting ▁ tokens ▁ for ▁ a ▁ provide , ▁ False ▁ for ▁ require . STRNEWLINE ▁ namespace : ▁ The ▁ required ▁ or ▁ provided ▁ namespaces ▁ to ▁ get ▁ tokens ▁ for . STRNEWLINE ▁ line _ number : ▁ The ▁ line ▁ number ▁ the ▁ new ▁ require ▁ or ▁ provide ▁ statement ▁ will ▁ be STRNEWLINE ▁ on . STRNEWLINE STRNEWLINE ▁ Returns : STRNEWLINE ▁ Tokens ▁ to ▁ create ▁ a ▁ new ▁ goog . require ▁ or ▁ goog . provide ▁ statement . STRNEWLINE ▁ """ NEW_LINE string = ' goog . require ' NEW_LINE if is_provide : NEW_LINE INDENT string = ' goog . provide ' NEW_LINE DEDENT line_text = string + ' ( \ ' ' + namespace + ' \ ' ) ; \n ' NEW_LINE return [ Token ( string , Type . IDENTIFIER , line_text , line_number ) , Token ( ' ( ' , Type . START_PAREN , line_text , line_number ) , Token ( ' \ ' ' , Type . SINGLE_QUOTE_STRING_START , line_text , line_number ) , Token ( namespace , Type . STRING_TEXT , line_text , line_number ) , Token ( ' \ ' ' , Type . SINGLE_QUOTE_STRING_END , line_text , line_number ) , Token ( ' ) ' , Type . END_PAREN , line_text , line_number ) , Token ( ' ; ' , Type . SEMICOLON , line_text , line_number ) ] NEW_LINE DEDENT def FinishFile ( self ) : NEW_LINE INDENT """ Called ▁ when ▁ the ▁ current ▁ file ▁ has ▁ finished ▁ style ▁ checking . STRNEWLINE STRNEWLINE ▁ Used ▁ to ▁ go ▁ back ▁ and ▁ fix ▁ any ▁ errors ▁ in ▁ the ▁ file . STRNEWLINE ▁ """ NEW_LINE if self . _file_fix_count : NEW_LINE INDENT f = self . _external_file NEW_LINE if not f : NEW_LINE INDENT print ' Fixed ▁ % d ▁ errors ▁ in ▁ % s ' % ( self . _file_fix_count , self . _file_name ) NEW_LINE f = open ( self . _file_name , ' w ' ) NEW_LINE DEDENT token = self . _file_token NEW_LINE char_count = 0 NEW_LINE while token : NEW_LINE INDENT f . write ( token . string ) NEW_LINE char_count += len ( token . string ) NEW_LINE if token . IsLastInLine ( ) : NEW_LINE INDENT f . write ( ' \n ' ) NEW_LINE if char_count > 80 and token . line_number in self . _file_changed_lines : NEW_LINE INDENT print ' WARNING : ▁ Line ▁ % d ▁ of ▁ % s ▁ is ▁ now ▁ longer ▁ than ▁ 80 ▁ characters . ' % ( token . line_number , self . _file_name ) NEW_LINE DEDENT char_count = 0 NEW_LINE DEDENT token = token . next NEW_LINE DEDENT if not self . _external_file : NEW_LINE # ▁ Close ▁ the ▁ file ▁ if ▁ we ▁ created ▁ it ENDCOM INDENT f . close ( ) NEW_LINE DEDENT DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="petecummings/django-cms/tree/master/cms/south_migrations/0015_modified_by_added.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE try : NEW_LINE INDENT from django . contrib . auth import get_user_model NEW_LINE DEDENT except ImportError : # ▁ django ▁ < ▁ 1.5 ENDCOM NEW_LINE INDENT from django . contrib . auth . models import User NEW_LINE DEDENT else : NEW_LINE INDENT User = get_user_model ( ) NEW_LINE DEDENT user_orm_label = ' % s . % s ' % ( User . _meta . app_label , User . _meta . object_name ) NEW_LINE user_model_label = ' % s . % s ' % ( User . _meta . app_label , User . _meta . model_name ) NEW_LINE user_ptr_name = ' % s _ ptr ' % User . _meta . object_name . lower ( ) NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE # ▁ Dummy ▁ migration ENDCOM INDENT pass NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE # ▁ Dummy ▁ migration ENDCOM INDENT pass NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , user_model_label : { ' Meta ' : { ' object _ name ' : User . __name__ , ' db _ table ' : " ' % s ' " % User . _meta . db_table } , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) } , ' cms . cmsplugin ' : { ' Meta ' : { ' object _ name ' : ' CMSPlugin ' } , ' changed _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' blank ' : ' True ' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '15' , ' db _ index ' : ' True ' } ) , ' level ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' lft ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' parent ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . CMSPlugin ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' placeholder ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Placeholder ' ] " , ' null ' : ' True ' } ) , ' plugin _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' position ' : ( ' django . db . models . fields . PositiveSmallIntegerField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' rght ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' tree _ id ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' cms . globalpagepermission ' : { ' Meta ' : { ' object _ name ' : ' GlobalPagePermission ' } , ' can _ add ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change _ advanced _ settings ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ change _ permissions ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ delete ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ moderate ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ move _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ publish ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ recover _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ view ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' group ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' sites ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' symmetrical ' : ' False ' , ' to ' : " orm [ ' sites . Site ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' cms . page ' : { ' Meta ' : { ' ordering ' : " ( ' site ' , ▁ ' tree _ id ' , ▁ ' lft ' ) " , ' object _ name ' : ' Page ' } , ' changed _ by ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '70' } ) , ' changed _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' blank ' : ' True ' } ) , ' created _ by ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '70' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' in _ navigation ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' , ' db _ index ' : ' True ' } ) , ' level ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' lft ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' limit _ visibility _ in _ menu ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : ' None ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' login _ required ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderator _ state ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' , ' blank ' : ' True ' } ) , ' navigation _ extenders ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '80' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' parent ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' blank ' : ' True ' , ' related _ name ' : " ' children ' " , ' null ' : ' True ' , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' placeholders ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' cms . Placeholder ' ] " , ' symmetrical ' : ' False ' } ) , ' publication _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' publication _ end _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' published ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' publisher _ is _ draft ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' , ' db _ index ' : ' True ' } ) , ' publisher _ public ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' publisher _ draft ' " , ' unique ' : ' True ' , ' null ' : ' True ' , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' publisher _ state ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' , ' db _ index ' : ' True ' } ) , ' reverse _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '40' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' rght ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' site ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' sites . Site ' ] " } ) , ' soft _ root ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' , ' db _ index ' : ' True ' } ) , ' template ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' tree _ id ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' cms . pagemoderator ' : { ' Meta ' : { ' object _ name ' : ' PageModerator ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' moderate _ children ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderate _ descendants ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderate _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) } , ' cms . pagemoderatorstate ' : { ' Meta ' : { ' ordering ' : " ( ' page ' , ▁ ' action ' , ▁ ' - created ' ) " , ' object _ name ' : ' PageModeratorState ' } , ' action ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' message ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' default ' : " ' ' " , ' max _ length ' : '1000' , ' blank ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' } ) } , ' cms . pagepermission ' : { ' Meta ' : { ' object _ name ' : ' PagePermission ' } , ' can _ add ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change _ advanced _ settings ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ change _ permissions ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ delete ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ moderate ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ move _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ publish ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ view ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' grant _ on ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '5' } ) , ' group ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' cms . pageuser ' : { ' Meta ' : { ' object _ name ' : ' PageUser ' , ' _ ormbases ' : [ user_orm_label ] } , ' created _ by ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' created _ users ' " , ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) , ' user _ ptr ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' unique ' : ' True ' , ' primary _ key ' : ' True ' } ) } , ' cms . pageusergroup ' : { ' Meta ' : { ' object _ name ' : ' PageUserGroup ' , ' _ ormbases ' : [ ' auth . Group ' ] } , ' created _ by ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' created _ usergroups ' " , ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) , ' group _ ptr ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' unique ' : ' True ' , ' primary _ key ' : ' True ' } ) } , ' cms . placeholder ' : { ' Meta ' : { ' object _ name ' : ' Placeholder ' } , ' default _ width ' : ( ' django . db . models . fields . PositiveSmallIntegerField ' , [ ] , { ' null ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' slot ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) } , ' cms . title ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' language ' , ▁ ' page ' ) , ) " , ' object _ name ' : ' Title ' } , ' application _ urls ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '200' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' has _ url _ overwrite ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '15' , ' db _ index ' : ' True ' } ) , ' menu _ title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta _ description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta _ keywords ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' title _ set ' " , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' page _ title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' path ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' redirect ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' slug ' : ( ' django . db . models . fields . SlugField ' , [ ] , { ' max _ length ' : '255' } ) , ' title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' sites . site ' : { ' Meta ' : { ' ordering ' : " ( ' domain ' , ) " , ' object _ name ' : ' Site ' , ' db _ table ' : " ' django _ site ' " } , ' domain ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } } NEW_LINE complete_apps = [ ' cms ' ] NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="xianjunzhengbackup/Cloud-Native-Python/tree/master/env/lib/python3.6/site-packages/pip/_vendor/progress/__init__.py"> # ▁ Copyright ▁ ( c ) ▁ 2012 ▁ Giorgos ▁ Verigakis ▁ < verigak @ gmail . com > ENDCOM # ▁ Permission ▁ to ▁ use , ▁ copy , ▁ modify , ▁ and ▁ distribute ▁ this ▁ software ▁ for ▁ any ENDCOM # ▁ purpose ▁ with ▁ or ▁ without ▁ fee ▁ is ▁ hereby ▁ granted , ▁ provided ▁ that ▁ the ▁ above ENDCOM # ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ appear ▁ in ▁ all ▁ copies . ENDCOM # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ " AS ▁ IS " ▁ AND ▁ THE ▁ AUTHOR ▁ DISCLAIMS ▁ ALL ▁ WARRANTIES ENDCOM # ▁ WITH ▁ REGARD ▁ TO ▁ THIS ▁ SOFTWARE ▁ INCLUDING ▁ ALL ▁ IMPLIED ▁ WARRANTIES ▁ OF ENDCOM # ▁ MERCHANTABILITY ▁ AND ▁ FITNESS . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ AUTHOR ▁ BE ▁ LIABLE ▁ FOR ENDCOM # ▁ ANY ▁ SPECIAL , ▁ DIRECT , ▁ INDIRECT , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ OR ▁ ANY ▁ DAMAGES ENDCOM # ▁ WHATSOEVER ▁ RESULTING ▁ FROM ▁ LOSS ▁ OF ▁ USE , ▁ DATA ▁ OR ▁ PROFITS , ▁ WHETHER ▁ IN ▁ AN ENDCOM # ▁ ACTION ▁ OF ▁ CONTRACT , ▁ NEGLIGENCE ▁ OR ▁ OTHER ▁ TORTIOUS ▁ ACTION , ▁ ARISING ▁ OUT ▁ OF ENDCOM # ▁ OR ▁ IN ▁ CONNECTION ▁ WITH ▁ THE ▁ USE ▁ OR ▁ PERFORMANCE ▁ OF ▁ THIS ▁ SOFTWARE . ENDCOM from __future__ import division NEW_LINE from collections import deque NEW_LINE from datetime import timedelta NEW_LINE from math import ceil NEW_LINE from sys import stderr NEW_LINE from time import time NEW_LINE __version__ = '1.2' NEW_LINE class Infinite ( object ) : NEW_LINE INDENT file = stderr NEW_LINE sma_window = 10 NEW_LINE def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT self . index = 0 NEW_LINE self . start_ts = time ( ) NEW_LINE self . _ts = self . start_ts NEW_LINE self . _dt = deque ( maxlen = self . sma_window ) NEW_LINE for key , val in kwargs . items ( ) : NEW_LINE INDENT setattr ( self , key , val ) NEW_LINE DEDENT DEDENT def __getitem__ ( self , key ) : NEW_LINE INDENT if key . startswith ( ' _ ' ) : NEW_LINE INDENT return None NEW_LINE DEDENT return getattr ( self , key , None ) NEW_LINE DEDENT @ property NEW_LINE def avg ( self ) : NEW_LINE INDENT return sum ( self . _dt ) / len ( self . _dt ) if self . _dt else 0 NEW_LINE DEDENT @ property NEW_LINE def elapsed ( self ) : NEW_LINE INDENT return int ( time ( ) - self . start_ts ) NEW_LINE DEDENT @ property NEW_LINE def elapsed_td ( self ) : NEW_LINE INDENT return timedelta ( seconds = self . elapsed ) NEW_LINE DEDENT def update ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def start ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def finish ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def next ( self , n = 1 ) : NEW_LINE INDENT if n > 0 : NEW_LINE INDENT now = time ( ) NEW_LINE dt = ( now - self . _ts ) / n NEW_LINE self . _dt . append ( dt ) NEW_LINE self . _ts = now NEW_LINE DEDENT self . index = self . index + n NEW_LINE self . update ( ) NEW_LINE DEDENT def iter ( self , it ) : NEW_LINE INDENT for x in it : NEW_LINE INDENT yield x NEW_LINE self . next ( ) NEW_LINE DEDENT self . finish ( ) NEW_LINE DEDENT DEDENT class Progress ( Infinite ) : NEW_LINE INDENT def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT super ( Progress , self ) . __init__ ( * args , ** kwargs ) NEW_LINE self . max = kwargs . get ( ' max ' , 100 ) NEW_LINE DEDENT @ property NEW_LINE def eta ( self ) : NEW_LINE INDENT return int ( ceil ( self . avg * self . remaining ) ) NEW_LINE DEDENT @ property NEW_LINE def eta_td ( self ) : NEW_LINE INDENT return timedelta ( seconds = self . eta ) NEW_LINE DEDENT @ property NEW_LINE def percent ( self ) : NEW_LINE INDENT return self . progress * 100 NEW_LINE DEDENT @ property NEW_LINE def progress ( self ) : NEW_LINE INDENT return min ( 1 , self . index / self . max ) NEW_LINE DEDENT @ property NEW_LINE def remaining ( self ) : NEW_LINE INDENT return max ( self . max - self . index , 0 ) NEW_LINE DEDENT def start ( self ) : NEW_LINE INDENT self . update ( ) NEW_LINE DEDENT def goto ( self , index ) : NEW_LINE INDENT incr = index - self . index NEW_LINE self . next ( incr ) NEW_LINE DEDENT def iter ( self , it ) : NEW_LINE INDENT try : NEW_LINE INDENT self . max = len ( it ) NEW_LINE DEDENT except TypeError : NEW_LINE INDENT pass NEW_LINE DEDENT for x in it : NEW_LINE INDENT yield x NEW_LINE self . next ( ) NEW_LINE DEDENT self . finish ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="yatinkumbhare/openstack-nova/tree/master/nova/db/sqlalchemy/migrate_repo/versions/284_placeholder.py"> # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM # ▁ This ▁ is ▁ a ▁ placeholder ▁ for ▁ Kilo ▁ backports . ENDCOM # ▁ Do ▁ not ▁ use ▁ this ▁ number ▁ for ▁ new ▁ Liberty ▁ work . ▁ New ▁ work ▁ starts ▁ after ENDCOM # ▁ all ▁ the ▁ placeholders . ENDCOM # ▁ See ▁ this ▁ for ▁ more ▁ information : ENDCOM # ▁ http : / / lists . openstack . org / pipermail / openstack - dev / 2013 - March / 006827 . html ENDCOM def upgrade ( migrate_engine ) : NEW_LINE INDENT pass NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="rjschwei/azure-sdk-for-python/tree/master/azure-mgmt-logic/azure/mgmt/logic/models/generate_upgraded_definition_parameters.py"> # ▁ coding = utf - 8 ENDCOM # ▁ Copyright ▁ ( c ) ▁ Microsoft ▁ Corporation . ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ MIT ▁ License . ▁ See ▁ License . txt ▁ in ▁ the ▁ project ▁ root ▁ for ENDCOM # ▁ license ▁ information . ENDCOM # ▁ Code ▁ generated ▁ by ▁ Microsoft ▁ ( R ) ▁ AutoRest ▁ Code ▁ Generator . ENDCOM # ▁ Changes ▁ may ▁ cause ▁ incorrect ▁ behavior ▁ and ▁ will ▁ be ▁ lost ▁ if ▁ the ▁ code ▁ is ENDCOM # ▁ regenerated . ENDCOM from msrest . serialization import Model NEW_LINE class GenerateUpgradedDefinitionParameters ( Model ) : NEW_LINE INDENT """ GenerateUpgradedDefinitionParameters . STRNEWLINE STRNEWLINE ▁ : param ▁ target _ schema _ version : ▁ The ▁ target ▁ schema ▁ version . STRNEWLINE ▁ : type ▁ target _ schema _ version : ▁ str STRNEWLINE ▁ """ NEW_LINE _attribute_map = { ' target _ schema _ version ' : { ' key ' : ' targetSchemaVersion ' , ' type ' : ' str ' } , } NEW_LINE def __init__ ( self , target_schema_version = None ) : NEW_LINE INDENT self . target_schema_version = target_schema_version NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="mluo613/osf.io/tree/master/scripts/update_comments.py"> """ STRNEWLINE Update ▁ User . comments _ viewed _ timestamp ▁ field . STRNEWLINE """ NEW_LINE import logging NEW_LINE import sys NEW_LINE from modularodm import Q NEW_LINE from framework . auth . core import User NEW_LINE from framework . transactions . context import TokuTransaction NEW_LINE from website . models import Comment NEW_LINE from website . app import init_app NEW_LINE from scripts import utils as script_utils NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE def main ( ) : NEW_LINE INDENT update_comments_viewed_timestamp ( ) NEW_LINE DEDENT def update_comments_viewed_timestamp ( ) : NEW_LINE INDENT users = User . find ( Q ( ' comments _ viewed _ timestamp ' , ' ne ' , None ) & Q ( ' comments _ viewed _ timestamp ' , ' ne ' , { } ) ) NEW_LINE for user in users : NEW_LINE INDENT if user . comments_viewed_timestamp : NEW_LINE INDENT timestamps = { } NEW_LINE for node_id in user . comments_viewed_timestamp : NEW_LINE INDENT node_timestamps = user . comments_viewed_timestamp [ node_id ] NEW_LINE # ▁ node ▁ timestamp ENDCOM if node_timestamps . get ( ' node ' , None ) : NEW_LINE INDENT timestamps [ node_id ] = node_timestamps [ ' node ' ] NEW_LINE # ▁ file ▁ timestamps ENDCOM DEDENT file_timestamps = node_timestamps . get ( ' files ' , None ) NEW_LINE if file_timestamps : NEW_LINE INDENT for file_id in file_timestamps : NEW_LINE INDENT timestamps [ file_id ] = file_timestamps [ file_id ] NEW_LINE DEDENT DEDENT DEDENT user . comments_viewed_timestamp = timestamps NEW_LINE user . save ( ) NEW_LINE logger . info ( ' Migrated ▁ timestamp ▁ for ▁ user ▁ { 0 } ' . format ( user . _id ) ) NEW_LINE DEDENT DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT dry = ' - - dry ' in sys . argv NEW_LINE if not dry : NEW_LINE INDENT script_utils . add_file_logger ( logger , __file__ ) NEW_LINE DEDENT init_app ( routes = False , set_backends = True ) NEW_LINE with TokuTransaction ( ) : NEW_LINE INDENT main ( ) NEW_LINE if dry : NEW_LINE INDENT raise Exception ( ' Dry ▁ Run ▁ - - ▁ Aborting ▁ Transaction ' ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="chouseknecht/ansible/tree/master/lib/ansible/module_utils/network/eos/argspec/facts/facts.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2019 ▁ Red ▁ Hat ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM """ STRNEWLINE The ▁ arg ▁ spec ▁ for ▁ the ▁ eos ▁ facts ▁ module . STRNEWLINE """ NEW_LINE from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE class FactsArgs ( object ) : NEW_LINE INDENT """ ▁ The ▁ arg ▁ spec ▁ for ▁ the ▁ eos ▁ facts ▁ module STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT argument_spec = { ' gather _ subset ' : dict ( default = [ ' ! config ' ] , type = ' list ' ) , ' gather _ network _ resources ' : dict ( type = ' list ' ) , } NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="kcompher/BuildingMachineLearningSystemsWithPython/tree/master/ch03/rel_post_01.py"> # ▁ This ▁ code ▁ is ▁ supporting ▁ material ▁ for ▁ the ▁ book ENDCOM # ▁ Building ▁ Machine ▁ Learning ▁ Systems ▁ with ▁ Python ENDCOM # ▁ by ▁ Willi ▁ Richert ▁ and ▁ Luis ▁ Pedro ▁ Coelho ENDCOM # ▁ published ▁ by ▁ PACKT ▁ Publishing ENDCOM # ▁ It ▁ is ▁ made ▁ available ▁ under ▁ the ▁ MIT ▁ License ENDCOM import os NEW_LINE import sys NEW_LINE import scipy as sp NEW_LINE from sklearn . feature_extraction . text import CountVectorizer NEW_LINE DIR = r " . . / data / toy " NEW_LINE posts = [ open ( os . path . join ( DIR , f ) ) . read ( ) for f in os . listdir ( DIR ) ] NEW_LINE new_post = " imaging ▁ databases " NEW_LINE import nltk . stem NEW_LINE english_stemmer = nltk . stem . SnowballStemmer ( ' english ' ) NEW_LINE class StemmedCountVectorizer ( CountVectorizer ) : NEW_LINE INDENT def build_analyzer ( self ) : NEW_LINE INDENT analyzer = super ( StemmedCountVectorizer , self ) . build_analyzer ( ) NEW_LINE return lambda doc : ( english_stemmer . stem ( w ) for w in analyzer ( doc ) ) NEW_LINE # ▁ vectorizer ▁ = ▁ CountVectorizer ( min _ df = 1 , ▁ stop _ words = ' english ' , ENDCOM # ▁ preprocessor = stemmer ) ENDCOM DEDENT DEDENT vectorizer = StemmedCountVectorizer ( min_df = 1 , stop_words = ' english ' ) NEW_LINE from sklearn . feature_extraction . text import TfidfVectorizer NEW_LINE class StemmedTfidfVectorizer ( TfidfVectorizer ) : NEW_LINE INDENT def build_analyzer ( self ) : NEW_LINE INDENT analyzer = super ( StemmedTfidfVectorizer , self ) . build_analyzer ( ) NEW_LINE return lambda doc : ( english_stemmer . stem ( w ) for w in analyzer ( doc ) ) NEW_LINE DEDENT DEDENT vectorizer = StemmedTfidfVectorizer ( min_df = 1 , stop_words = ' english ' , charset_error = ' ignore ' ) NEW_LINE print ( vectorizer ) NEW_LINE X_train = vectorizer . fit_transform ( posts ) NEW_LINE num_samples , num_features = X_train . shape NEW_LINE print ( " # samples : ▁ % d , ▁ # features : ▁ % d " % ( num_samples , num_features ) ) NEW_LINE new_post_vec = vectorizer . transform ( [ new_post ] ) NEW_LINE print ( new_post_vec , type ( new_post_vec ) ) NEW_LINE print ( new_post_vec . toarray ( ) ) NEW_LINE print ( vectorizer . get_feature_names ( ) ) NEW_LINE def dist_raw ( v1 , v2 ) : NEW_LINE INDENT delta = v1 - v2 NEW_LINE return sp . linalg . norm ( delta . toarray ( ) ) NEW_LINE DEDENT def dist_norm ( v1 , v2 ) : NEW_LINE INDENT v1_normalized = v1 / sp . linalg . norm ( v1 . toarray ( ) ) NEW_LINE v2_normalized = v2 / sp . linalg . norm ( v2 . toarray ( ) ) NEW_LINE delta = v1_normalized - v2_normalized NEW_LINE return sp . linalg . norm ( delta . toarray ( ) ) NEW_LINE DEDENT dist = dist_norm NEW_LINE best_dist = sys . maxsize NEW_LINE best_i = None NEW_LINE for i in range ( 0 , num_samples ) : NEW_LINE INDENT post = posts [ i ] NEW_LINE if post == new_post : NEW_LINE INDENT continue NEW_LINE DEDENT post_vec = X_train . getrow ( i ) NEW_LINE d = dist ( post_vec , new_post_vec ) NEW_LINE print ( " = = = ▁ Post ▁ % i ▁ with ▁ dist = % .2f : ▁ % s " % ( i , d , post ) ) NEW_LINE if d < best_dist : NEW_LINE INDENT best_dist = d NEW_LINE best_i = i NEW_LINE DEDENT DEDENT print ( " Best ▁ post ▁ is ▁ % i ▁ with ▁ dist = % .2f " % ( best_i , best_dist ) ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="haad/ansible/tree/master/lib/ansible/modules/cloud/lxd/lxd_profile.py"> # ! / usr / bin / python ENDCOM # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ ( c ) ▁ 2016 , ▁ Hiroaki ▁ Nakamura ▁ < hnakamur @ gmail . com > ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM from __future__ import absolute_import , division , print_function NEW_LINE __metaclass__ = type NEW_LINE ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = ''' STRNEWLINE - - - STRNEWLINE module : ▁ lxd _ profile STRNEWLINE short _ description : ▁ Manage ▁ LXD ▁ profiles STRNEWLINE version _ added : ▁ " 2.2 " STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ Management ▁ of ▁ LXD ▁ profiles STRNEWLINE author : ▁ " Hiroaki ▁ Nakamura ▁ ( @ hnakamur ) " STRNEWLINE options : STRNEWLINE ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Description ▁ of ▁ the ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ " 2.5 " STRNEWLINE ▁ ▁ ▁ ▁ config : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' The ▁ config ▁ for ▁ the ▁ container ▁ ( e . g . ▁ { " limits . memory " : ▁ " 4GB " } ) . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # patch - 3 ) ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ the ▁ profile ▁ already ▁ exists ▁ and ▁ its ▁ " config " ▁ value ▁ in ▁ metadata STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ obtained ▁ from STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ GET ▁ / 1.0 / profiles / < name > STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # get - 19 ) STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ are ▁ different , ▁ they ▁ this ▁ module ▁ tries ▁ to ▁ apply ▁ the ▁ configurations . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Not ▁ all ▁ config ▁ values ▁ are ▁ supported ▁ to ▁ apply ▁ the ▁ existing ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ Maybe ▁ you ▁ need ▁ to ▁ delete ▁ and ▁ recreate ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ devices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' The ▁ devices ▁ for ▁ the ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ( e . g . ▁ { " rootfs " : ▁ { " path " : ▁ " / dev / kvm " , ▁ " type " : ▁ " unix - char " } ) . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # patch - 3 ) ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ new _ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ new ▁ name ▁ of ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ this ▁ parameter ▁ is ▁ specified ▁ a ▁ profile ▁ will ▁ be ▁ renamed ▁ to ▁ this ▁ name . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # post - 11 ) STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ absent STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Define ▁ the ▁ state ▁ of ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ url : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ unix ▁ domain ▁ socket ▁ path ▁ or ▁ the ▁ https ▁ URL ▁ for ▁ the ▁ LXD ▁ server . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ unix : / var / lib / lxd / unix . socket STRNEWLINE ▁ ▁ ▁ ▁ key _ file : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ client ▁ certificate ▁ key ▁ file ▁ path . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' " { } / . config / lxc / client . key " ▁ . format ( os . environ [ " HOME " ] ) ' STRNEWLINE ▁ ▁ ▁ ▁ cert _ file : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ client ▁ certificate ▁ file ▁ path . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' " { } / . config / lxc / client . crt " ▁ . format ( os . environ [ " HOME " ] ) ' STRNEWLINE ▁ ▁ ▁ ▁ trust _ password : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ client ▁ trusted ▁ password . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ You ▁ need ▁ to ▁ set ▁ this ▁ password ▁ on ▁ the ▁ LXD ▁ server ▁ before STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ running ▁ this ▁ module ▁ using ▁ the ▁ following ▁ command . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ lxc ▁ config ▁ set ▁ core . trust _ password ▁ < some ▁ random ▁ password > STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / www . stgraber . org / 2016/04/18 / lxd - api - direct - interaction / ) STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ trust _ password ▁ is ▁ set , ▁ this ▁ module ▁ send ▁ a ▁ request ▁ for STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ authentication ▁ before ▁ sending ▁ any ▁ requests . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE notes : STRNEWLINE ▁ ▁ - ▁ Profiles ▁ must ▁ have ▁ a ▁ unique ▁ name . ▁ If ▁ you ▁ attempt ▁ to ▁ create ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ with ▁ a ▁ name ▁ that ▁ already ▁ existed ▁ in ▁ the ▁ users ▁ namespace ▁ the ▁ module ▁ will STRNEWLINE ▁ ▁ ▁ ▁ simply ▁ return ▁ as ▁ " unchanged " . STRNEWLINE ''' NEW_LINE EXAMPLES = ''' STRNEWLINE # ▁ An ▁ example ▁ for ▁ creating ▁ a ▁ profile STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ name : ▁ Create ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ config : ▁ { } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : ▁ my ▁ macvlan ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ devices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ eth0 : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ nictype : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ parent : ▁ br0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ nic STRNEWLINE STRNEWLINE # ▁ An ▁ example ▁ for ▁ creating ▁ a ▁ profile ▁ via ▁ http ▁ connection STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ - ▁ name : ▁ create ▁ macvlan ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ url : ▁ https : / / 127.0.0.1:8443 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ # ▁ These ▁ cert _ file ▁ and ▁ key _ file ▁ values ▁ are ▁ equal ▁ to ▁ the ▁ default ▁ values . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ # cert _ file : ▁ " { { ▁ lookup ( ' env ' , ▁ ' HOME ' ) ▁ } } / . config / lxc / client . crt " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ # key _ file : ▁ " { { ▁ lookup ( ' env ' , ▁ ' HOME ' ) ▁ } } / . config / lxc / client . key " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ trust _ password : ▁ mypassword STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ config : ▁ { } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ description : ▁ my ▁ macvlan ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ devices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ eth0 : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ nictype : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ parent : ▁ br0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ nic STRNEWLINE STRNEWLINE # ▁ An ▁ example ▁ for ▁ deleting ▁ a ▁ profile STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ name : ▁ Delete ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE STRNEWLINE # ▁ An ▁ example ▁ for ▁ renaming ▁ a ▁ profile STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ name : ▁ Rename ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ new _ name : ▁ macvlan2 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ''' NEW_LINE RETURN = ''' STRNEWLINE old _ state : STRNEWLINE ▁ ▁ description : ▁ The ▁ old ▁ state ▁ of ▁ the ▁ profile STRNEWLINE ▁ ▁ returned : ▁ success STRNEWLINE ▁ ▁ type : ▁ string STRNEWLINE ▁ ▁ sample : ▁ " absent " STRNEWLINE logs : STRNEWLINE ▁ ▁ description : ▁ The ▁ logs ▁ of ▁ requests ▁ and ▁ responses . STRNEWLINE ▁ ▁ returned : ▁ when ▁ ansible - playbook ▁ is ▁ invoked ▁ with ▁ - vvvv . STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE ▁ ▁ sample : ▁ " ( too ▁ long ▁ to ▁ be ▁ placed ▁ here ) " STRNEWLINE actions : STRNEWLINE ▁ ▁ description : ▁ List ▁ of ▁ actions ▁ performed ▁ for ▁ the ▁ profile . STRNEWLINE ▁ ▁ returned : ▁ success STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE ▁ ▁ sample : ▁ ' [ " create " ] ' STRNEWLINE ''' NEW_LINE import os NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . lxd import LXDClient , LXDClientException NEW_LINE # ▁ PROFILE _ STATES ▁ is ▁ a ▁ list ▁ for ▁ states ▁ supported ENDCOM PROFILES_STATES = [ ' present ' , ' absent ' ] NEW_LINE # ▁ CONFIG _ PARAMS ▁ is ▁ a ▁ list ▁ of ▁ config ▁ attribute ▁ names . ENDCOM CONFIG_PARAMS = [ ' config ' , ' description ' , ' devices ' ] NEW_LINE class LXDProfileManagement ( object ) : NEW_LINE INDENT def __init__ ( self , module ) : NEW_LINE INDENT """ Management ▁ of ▁ LXC ▁ containers ▁ via ▁ Ansible . STRNEWLINE STRNEWLINE ▁ : param ▁ module : ▁ Processed ▁ Ansible ▁ Module . STRNEWLINE ▁ : type ▁ module : ▁ ` ` object ` ` STRNEWLINE ▁ """ NEW_LINE self . module = module NEW_LINE self . name = self . module . params [ ' name ' ] NEW_LINE self . _build_config ( ) NEW_LINE self . state = self . module . params [ ' state ' ] NEW_LINE self . new_name = self . module . params . get ( ' new _ name ' , None ) NEW_LINE self . url = self . module . params [ ' url ' ] NEW_LINE self . key_file = self . module . params . get ( ' key _ file ' , None ) NEW_LINE self . cert_file = self . module . params . get ( ' cert _ file ' , None ) NEW_LINE self . debug = self . module . _verbosity >= 4 NEW_LINE try : NEW_LINE INDENT self . client = LXDClient ( self . url , key_file = self . key_file , cert_file = self . cert_file , debug = self . debug ) NEW_LINE DEDENT except LXDClientException as e : NEW_LINE INDENT self . module . fail_json ( msg = e . msg ) NEW_LINE DEDENT self . trust_password = self . module . params . get ( ' trust _ password ' , None ) NEW_LINE self . actions = [ ] NEW_LINE DEDENT def _build_config ( self ) : NEW_LINE INDENT self . config = { } NEW_LINE for attr in CONFIG_PARAMS : NEW_LINE INDENT param_val = self . module . params . get ( attr , None ) NEW_LINE if param_val is not None : NEW_LINE INDENT self . config [ attr ] = param_val NEW_LINE DEDENT DEDENT DEDENT def _get_profile_json ( self ) : NEW_LINE INDENT return self . client . do ( ' GET ' , ' / 1.0 / profiles / {0 } ' . format ( self . name ) , ok_error_codes = [ 404 ] ) NEW_LINE DEDENT @ staticmethod NEW_LINE def _profile_json_to_module_state ( resp_json ) : NEW_LINE INDENT if resp_json [ ' type ' ] == ' error ' : NEW_LINE INDENT return ' absent ' NEW_LINE DEDENT return ' present ' NEW_LINE DEDENT def _update_profile ( self ) : NEW_LINE INDENT if self . state == ' present ' : NEW_LINE INDENT if self . old_state == ' absent ' : NEW_LINE INDENT if self . new_name is None : NEW_LINE INDENT self . _create_profile ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = ' new _ name ▁ must ▁ not ▁ be ▁ set ▁ when ▁ the ▁ profile ▁ does ▁ not ▁ exist ▁ and ▁ the ▁ specified ▁ state ▁ is ▁ present ' , changed = False ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if self . new_name is not None and self . new_name != self . name : NEW_LINE INDENT self . _rename_profile ( ) NEW_LINE DEDENT if self . _needs_to_apply_profile_configs ( ) : NEW_LINE INDENT self . _apply_profile_configs ( ) NEW_LINE DEDENT DEDENT DEDENT elif self . state == ' absent ' : NEW_LINE INDENT if self . old_state == ' present ' : NEW_LINE INDENT if self . new_name is None : NEW_LINE INDENT self . _delete_profile ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = ' new _ name ▁ must ▁ not ▁ be ▁ set ▁ when ▁ the ▁ profile ▁ exists ▁ and ▁ the ▁ specified ▁ state ▁ is ▁ absent ' , changed = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def _create_profile ( self ) : NEW_LINE INDENT config = self . config . copy ( ) NEW_LINE config [ ' name ' ] = self . name NEW_LINE self . client . do ( ' POST ' , ' / 1.0 / profiles ' , config ) NEW_LINE self . actions . append ( ' create ' ) NEW_LINE DEDENT def _rename_profile ( self ) : NEW_LINE INDENT config = { ' name ' : self . new_name } NEW_LINE self . client . do ( ' POST ' , ' / 1.0 / profiles / { } ' . format ( self . name ) , config ) NEW_LINE self . actions . append ( ' rename ' ) NEW_LINE self . name = self . new_name NEW_LINE DEDENT def _needs_to_change_profile_config ( self , key ) : NEW_LINE INDENT if key not in self . config : NEW_LINE INDENT return False NEW_LINE DEDENT old_configs = self . old_profile_json [ ' metadata ' ] . get ( key , None ) NEW_LINE return self . config [ key ] != old_configs NEW_LINE DEDENT def _needs_to_apply_profile_configs ( self ) : NEW_LINE INDENT return ( self . _needs_to_change_profile_config ( ' config ' ) or self . _needs_to_change_profile_config ( ' description ' ) or self . _needs_to_change_profile_config ( ' devices ' ) ) NEW_LINE DEDENT def _apply_profile_configs ( self ) : NEW_LINE INDENT config = self . old_profile_json . copy ( ) NEW_LINE for k , v in self . config . items ( ) : NEW_LINE INDENT config [ k ] = v NEW_LINE DEDENT self . client . do ( ' PUT ' , ' / 1.0 / profiles / { } ' . format ( self . name ) , config ) NEW_LINE self . actions . append ( ' apply _ profile _ configs ' ) NEW_LINE DEDENT def _delete_profile ( self ) : NEW_LINE INDENT self . client . do ( ' DELETE ' , ' / 1.0 / profiles / { } ' . format ( self . name ) ) NEW_LINE self . actions . append ( ' delete ' ) NEW_LINE DEDENT def run ( self ) : NEW_LINE INDENT """ Run ▁ the ▁ main ▁ method . """ NEW_LINE try : NEW_LINE INDENT if self . trust_password is not None : NEW_LINE INDENT self . client . authenticate ( self . trust_password ) NEW_LINE DEDENT self . old_profile_json = self . _get_profile_json ( ) NEW_LINE self . old_state = self . _profile_json_to_module_state ( self . old_profile_json ) NEW_LINE self . _update_profile ( ) NEW_LINE state_changed = len ( self . actions ) > 0 NEW_LINE result_json = { ' changed ' : state_changed , ' old _ state ' : self . old_state , ' actions ' : self . actions } NEW_LINE if self . client . debug : NEW_LINE INDENT result_json [ ' logs ' ] = self . client . logs NEW_LINE DEDENT self . module . exit_json ( ** result_json ) NEW_LINE DEDENT except LXDClientException as e : NEW_LINE INDENT state_changed = len ( self . actions ) > 0 NEW_LINE fail_params = { ' msg ' : e . msg , ' changed ' : state_changed , ' actions ' : self . actions } NEW_LINE if self . client . debug : NEW_LINE INDENT fail_params [ ' logs ' ] = e . kwargs [ ' logs ' ] NEW_LINE DEDENT self . module . fail_json ( ** fail_params ) NEW_LINE DEDENT DEDENT DEDENT def main ( ) : NEW_LINE INDENT """ Ansible ▁ Main ▁ module . """ NEW_LINE module = AnsibleModule ( argument_spec = dict ( name = dict ( type = ' str ' , required = True ) , new_name = dict ( type = ' str ' , ) , config = dict ( type = ' dict ' , ) , description = dict ( type = ' str ' , ) , devices = dict ( type = ' dict ' , ) , state = dict ( choices = PROFILES_STATES , default = ' present ' ) , url = dict ( type = ' str ' , default = ' unix : / var / lib / lxd / unix . socket ' ) , key_file = dict ( type = ' str ' , default = ' { } / . config / lxc / client . key ' . format ( os . environ [ ' HOME ' ] ) ) , cert_file = dict ( type = ' str ' , default = ' { } / . config / lxc / client . crt ' . format ( os . environ [ ' HOME ' ] ) ) , trust_password = dict ( type = ' str ' , no_log = True ) ) , supports_check_mode = False , ) NEW_LINE lxd_manage = LXDProfileManagement ( module = module ) NEW_LINE lxd_manage . run ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="arifgursel/pyglet/tree/master/pyglet/gl/lib.py"> # ▁ pyglet ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2006-2008 ▁ Alex ▁ Holkner ENDCOM # ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ ENDCOM # ▁ are ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ▁ copyright ▁ ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ▁ in ENDCOM # ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ENDCOM # ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ pyglet ▁ nor ▁ the ▁ names ▁ of ▁ its ENDCOM # ▁ contributors ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ENDCOM # ▁ derived ▁ from ▁ this ▁ software ▁ without ▁ specific ▁ prior ▁ written ENDCOM # ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ENDCOM # ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ENDCOM # ▁ COPYRIGHT ▁ OWNER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ENDCOM # ▁ INCIDENTAL , ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ENDCOM # ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ENDCOM # ▁ LOSS ▁ OF ▁ USE , ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ HOWEVER ENDCOM # ▁ CAUSED ▁ AND ▁ ON ▁ ANY ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ STRICT ENDCOM # ▁ LIABILITY , ▁ OR ▁ TORT ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ▁ ARISING ▁ IN ENDCOM # ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ENDCOM # ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM __docformat__ = ' restructuredtext ' NEW_LINE __version__ = ' $ Id $ ' NEW_LINE import ctypes NEW_LINE import pyglet NEW_LINE __all__ = [ ' link _ GL ' , ' link _ GLU ' , ' link _ AGL ' , ' link _ GLX ' , ' link _ WGL ' ] NEW_LINE _debug_gl = pyglet . options [ ' debug _ gl ' ] NEW_LINE _debug_gl_trace = pyglet . options [ ' debug _ gl _ trace ' ] NEW_LINE _debug_gl_trace_args = pyglet . options [ ' debug _ gl _ trace _ args ' ] NEW_LINE class MissingFunctionException ( Exception ) : NEW_LINE INDENT def __init__ ( self , name , requires = None , suggestions = None ) : NEW_LINE INDENT msg = ' % s ▁ is ▁ not ▁ exported ▁ by ▁ the ▁ available ▁ OpenGL ▁ driver . ' % name NEW_LINE if requires : NEW_LINE INDENT msg += ' ▁ ▁ % s ▁ is ▁ required ▁ for ▁ this ▁ functionality . ' % requires NEW_LINE DEDENT if suggestions : NEW_LINE INDENT msg += ' ▁ ▁ Consider ▁ alternative ( s ) ▁ % s . ' % ' , ▁ ' . join ( suggestions ) NEW_LINE DEDENT Exception . __init__ ( self , msg ) NEW_LINE DEDENT DEDENT def missing_function ( name , requires = None , suggestions = None ) : NEW_LINE INDENT def MissingFunction ( * args , ** kwargs ) : NEW_LINE INDENT raise MissingFunctionException ( name , requires , suggestions ) NEW_LINE DEDENT return MissingFunction NEW_LINE DEDENT _int_types = ( ctypes . c_int16 , ctypes . c_int32 ) NEW_LINE if hasattr ( ctypes , ' c _ int64' ) : NEW_LINE # ▁ Some ▁ builds ▁ of ▁ ctypes ▁ apparently ▁ do ▁ not ▁ have ▁ c _ int64 ENDCOM # ▁ defined ; ▁ it ' s ▁ a ▁ pretty ▁ good ▁ bet ▁ that ▁ these ▁ builds ▁ do ▁ not ENDCOM # ▁ have ▁ 64 - bit ▁ pointers . ENDCOM INDENT _int_types += ( ctypes . c_int64 , ) NEW_LINE DEDENT for t in _int_types : NEW_LINE INDENT if ctypes . sizeof ( t ) == ctypes . sizeof ( ctypes . c_size_t ) : NEW_LINE INDENT c_ptrdiff_t = t NEW_LINE DEDENT DEDENT class c_void ( ctypes . Structure ) : NEW_LINE # ▁ c _ void _ p ▁ is ▁ a ▁ buggy ▁ return ▁ type , ▁ converting ▁ to ▁ int , ▁ so ENDCOM # ▁ POINTER ( None ) ▁ = = ▁ c _ void _ p ▁ is ▁ actually ▁ written ▁ as ENDCOM # ▁ POINTER ( c _ void ) , ▁ so ▁ it ▁ can ▁ be ▁ treated ▁ as ▁ a ▁ real ▁ pointer . ENDCOM INDENT _fields_ = [ ( ' dummy ' , ctypes . c_int ) ] NEW_LINE DEDENT class GLException ( Exception ) : NEW_LINE INDENT pass NEW_LINE DEDENT def errcheck ( result , func , arguments ) : NEW_LINE INDENT if _debug_gl_trace : NEW_LINE INDENT try : NEW_LINE INDENT name = func . __name__ NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT name = repr ( func ) NEW_LINE DEDENT if _debug_gl_trace_args : NEW_LINE INDENT trace_args = ' , ▁ ' . join ( [ repr ( arg ) [ : 20 ] for arg in arguments ] ) NEW_LINE print ' % s ( % s ) ' % ( name , trace_args ) NEW_LINE DEDENT else : NEW_LINE INDENT print name NEW_LINE DEDENT DEDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT if not context . _gl_begin : NEW_LINE INDENT error = gl . glGetError ( ) NEW_LINE if error : NEW_LINE INDENT msg = ctypes . cast ( gl . gluErrorString ( error ) , ctypes . c_char_p ) . value NEW_LINE raise GLException ( msg ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def errcheck_glbegin ( result , func , arguments ) : NEW_LINE INDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT context . _gl_begin = True NEW_LINE return result NEW_LINE DEDENT def errcheck_glend ( result , func , arguments ) : NEW_LINE INDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT context . _gl_begin = False NEW_LINE return errcheck ( result , func , arguments ) NEW_LINE DEDENT def decorate_function ( func , name ) : NEW_LINE INDENT if _debug_gl : NEW_LINE INDENT if name == ' glBegin ' : NEW_LINE INDENT func . errcheck = errcheck_glbegin NEW_LINE DEDENT elif name == ' glEnd ' : NEW_LINE INDENT func . errcheck = errcheck_glend NEW_LINE DEDENT elif name not in ( ' glGetError ' , ' gluErrorString ' ) and name [ : 3 ] not in ( ' glX ' , ' agl ' , ' wgl ' ) : NEW_LINE INDENT func . errcheck = errcheck NEW_LINE DEDENT DEDENT DEDENT link_AGL = None NEW_LINE link_GLX = None NEW_LINE link_WGL = None NEW_LINE if pyglet . compat_platform in ( ' win32' , ' cygwin ' ) : NEW_LINE INDENT from pyglet . gl . lib_wgl import link_GL , link_GLU , link_WGL NEW_LINE DEDENT elif pyglet . compat_platform == ' darwin ' : NEW_LINE INDENT from pyglet . gl . lib_agl import link_GL , link_GLU , link_AGL NEW_LINE DEDENT else : NEW_LINE INDENT from pyglet . gl . lib_glx import link_GL , link_GLU , link_GLX NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="sparkslabs/kamaelia/tree/master/Sketches/CL/Topology/src/RelationTopology/Util/RelationAttributeParsing.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2010 ▁ British ▁ Broadcasting ▁ Corporation ▁ and ▁ Kamaelia ▁ Contributors ( 1 ) ENDCOM # ▁ ( 1 ) ▁ Kamaelia ▁ Contributors ▁ are ▁ listed ▁ in ▁ the ▁ AUTHORS ▁ file ▁ and ▁ at ENDCOM # ▁ http : / / www . kamaelia . org / AUTHORS ▁ - ▁ please ▁ extend ▁ this ▁ file , ENDCOM # ▁ not ▁ this ▁ notice . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ENDCOM # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ENDCOM # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM """ \ STRNEWLINE = = = = = STRNEWLINE Parse ▁ entities , ▁ attributes ▁ and ▁ relations ▁ definition ▁ received STRNEWLINE = = = = = STRNEWLINE STRNEWLINE Parse ▁ entities ▁ and ▁ relations ▁ definition ▁ received , ▁ one ▁ line ▁ one ▁ time . STRNEWLINE STRNEWLINE 1 . ▁ Definition ▁ format STRNEWLINE 1 . ) ▁ Empty ▁ line ▁ ( including ▁ any ▁ number ▁ of ▁ white ▁ spaces ) STRNEWLINE 2 . ) ▁ Line ▁ starting ▁ with ▁ # ▁ to ▁ comment STRNEWLINE 3 . ) ▁ Entity ▁ definition STRNEWLINE Example : STRNEWLINE - - - - - STRNEWLINE person ▁ mum STRNEWLINE person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80 STRNEWLINE person ▁ son ▁ gender = " male " , photo = " . . / Files / son . gif , width = 60 , height = 60 " STRNEWLINE person ▁ daughter ▁ radius = 100 STRNEWLINE 4 . ) ▁ Relation ▁ definition STRNEWLINE Example : ▁ STRNEWLINE - - - - - STRNEWLINE childof ( mum , ▁ son ) STRNEWLINE STRNEWLINE 2 . ▁ NOTE : STRNEWLINE 1 . ) ▁ Any ▁ number ▁ of ▁ spaces ▁ can ▁ exist ▁ before , ▁ after ▁ and ▁ between ▁ the ▁ above ▁ line STRNEWLINE Example : STRNEWLINE - - - - - STRNEWLINE ▁ person ▁ mum ▁ STRNEWLINE ▁ childof ▁ ( ▁ mum ▁ , ▁ son ▁ ) ▁ STRNEWLINE 2 . ) ▁ Parse ▁ one ▁ line ▁ one ▁ time ▁ and ▁ then ▁ send ▁ out STRNEWLINE 3 . ) ▁ Entity ▁ definition ▁ needs ▁ to ▁ come ▁ before ▁ relation ▁ definition ▁ STRNEWLINE if ▁ the ▁ relations ▁ definition ▁ uses ▁ the ▁ entity STRNEWLINE 4 . ) ▁ When ▁ encountering ▁ repeated ▁ entity , ▁ it ▁ will ▁ update ▁ its ▁ attributes ▁ rather ▁ than STRNEWLINE create ▁ a ▁ new ▁ one . ▁ STRNEWLINE """ NEW_LINE def parseEntity ( entityLine ) : NEW_LINE INDENT """ ▁ parse ▁ entity ▁ line ▁ """ NEW_LINE result = entityLine . split ( ) NEW_LINE # entity _ ID ▁ = ▁ result [ 0 ] + ' _ ' + result [ 1 ] ENDCOM entity_name = result [ 1 ] NEW_LINE # particle ▁ = ▁ ' - ' ENDCOM particle = ' GenericParticle ' NEW_LINE if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE # attributes ▁ = ▁ attributes . lower ( ) ENDCOM attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes + ' , type = ' + result [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' type = ' + result [ 0 ] NEW_LINE DEDENT return " ADD ▁ NODE ▁ % s ▁ % s ▁ auto ▁ % s ▁ % s " % ( entity_name , entity_name , particle , attributes ) NEW_LINE DEDENT def parseUpdatedEntity ( entityLine ) : NEW_LINE INDENT """ ▁ parse ▁ entity ▁ line ▁ """ NEW_LINE result = entityLine . split ( ) NEW_LINE # entity _ ID ▁ = ▁ result [ 0 ] + ' _ ' + result [ 1 ] ENDCOM entity_name = result [ 1 ] NEW_LINE # particle ▁ = ▁ ' - ' ENDCOM # particle ▁ = ▁ ' GenericParticle ' ENDCOM if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE # attributes ▁ = ▁ attributes . lower ( ) ENDCOM attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes . replace ( ' name ' , ' label ' ) NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' label = ' + entity_name NEW_LINE DEDENT return " UPDATE ▁ NODE ▁ % s ▁ % s " % ( entity_name , attributes ) NEW_LINE DEDENT def parseRelation ( relationLine ) : NEW_LINE INDENT """ ▁ parse ▁ relation ▁ line ▁ """ NEW_LINE result = relationLine . split ( ' ( ' ) NEW_LINE relation = result [ 0 ] . strip ( ) NEW_LINE entities_str = result [ 1 ] . rstrip ( ' ) ' ) NEW_LINE entities_list = entities_str . split ( ' , ' ) NEW_LINE src = entities_list [ 0 ] . strip ( ) NEW_LINE dst = entities_list [ 1 ] . strip ( ) NEW_LINE return " ADD ▁ LINK ▁ % s ▁ % s ▁ % s " % ( src , dst , relation ) NEW_LINE DEDENT import re NEW_LINE import Axon NEW_LINE from Axon . Ipc import producerFinished , shutdownMicroprocess NEW_LINE class RelationAttributeParser ( Axon . Component . component ) : NEW_LINE INDENT """ \ STRNEWLINE = = = = = STRNEWLINE A ▁ component ▁ to ▁ parse ▁ entities , ▁ attributes ▁ and ▁ relations ▁ definition STRNEWLINE = = = = = STRNEWLINE """ NEW_LINE def shutdown ( self ) : NEW_LINE INDENT """ ▁ shutdown ▁ method : ▁ define ▁ when ▁ to ▁ shun ▁ down """ NEW_LINE while self . dataReady ( " control " ) : NEW_LINE INDENT data = self . recv ( " control " ) NEW_LINE if isinstance ( data , producerFinished ) or isinstance ( data , shutdownMicroprocess ) : NEW_LINE INDENT self . shutdown_mess = data NEW_LINE return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def main ( self ) : NEW_LINE INDENT """ ▁ main ▁ method : ▁ do ▁ stuff ▁ """ NEW_LINE previousNodes = [ ] NEW_LINE # ▁ Put ▁ all ▁ codes ▁ within ▁ the ▁ loop , ▁ so ▁ that ▁ others ▁ can ▁ be ▁ run ▁ even ▁ it ▁ doesn ' t ▁ shut ▁ down ENDCOM while not self . shutdown ( ) : NEW_LINE INDENT X = [ ] NEW_LINE links = [ ] NEW_LINE nodes = [ ] NEW_LINE updatedNodes = [ ] NEW_LINE while not self . anyReady ( ) : NEW_LINE INDENT self . pause ( ) NEW_LINE yield 1 NEW_LINE DEDENT while self . dataReady ( " inbox " ) : NEW_LINE INDENT L = self . recv ( " inbox " ) NEW_LINE if L . strip ( ) == " " : continue # ▁ empty ▁ line ENDCOM NEW_LINE if L . lstrip ( ) [ 0 ] == " # " : continue # ▁ comment ENDCOM NEW_LINE X . append ( L . strip ( ) ) NEW_LINE # yield ▁ 1 ENDCOM DEDENT for item in X : NEW_LINE INDENT if re . match ( ' ( . + ) \ ( ( . + ) , ( . + ) \ ) ' , item ) : # ▁ relation ENDCOM NEW_LINE INDENT command = parseRelation ( item ) NEW_LINE links . append ( command ) NEW_LINE DEDENT else : NEW_LINE INDENT isRepeated = False NEW_LINE for node in previousNodes : NEW_LINE INDENT if item . split ( ) [ 1 ] == node . split ( ) [ 2 ] : NEW_LINE INDENT isRepeated = True NEW_LINE DEDENT DEDENT if not isRepeated : # ▁ new ▁ entity ENDCOM NEW_LINE INDENT command = parseEntity ( item ) NEW_LINE nodes . append ( command ) NEW_LINE previousNodes . append ( command ) NEW_LINE DEDENT else : # ▁ old ▁ entity ENDCOM NEW_LINE INDENT command = parseUpdatedEntity ( item ) NEW_LINE updatedNodes . append ( command ) NEW_LINE # yield ▁ 1 ENDCOM DEDENT DEDENT DEDENT for node in nodes : NEW_LINE INDENT self . send ( node , " outbox " ) NEW_LINE DEDENT for updatedNode in updatedNodes : NEW_LINE INDENT self . send ( updatedNode , " outbox " ) NEW_LINE DEDENT for link in links : NEW_LINE INDENT self . send ( link , " outbox " ) NEW_LINE DEDENT yield 1 NEW_LINE DEDENT self . send ( self . shutdown_mess , " signal " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT from Kamaelia . Util . DataSource import DataSource NEW_LINE from Kamaelia . Visualisation . PhysicsGraph . lines_to_tokenlists import lines_to_tokenlists NEW_LINE from Kamaelia . Util . Console import ConsoleReader , ConsoleEchoer NEW_LINE from GenericTopologyViewer import GenericTopologyViewer NEW_LINE from Kamaelia . Chassis . Graphline import Graphline NEW_LINE # ▁ Data ▁ can ▁ be ▁ from ▁ both ▁ DataSource ▁ and ▁ console ▁ inputs ENDCOM Graphline ( CONSOLEREADER = ConsoleReader ( ) , DATASOURCE = DataSource ( [ " ▁ ▁ person ▁ ▁ mum ▁ ▁ ▁ gender = female , photo = . . / Files / mum . jpg , width = 80 , height = 80 ▁ " , ' ▁ ▁ ' , """ ▁ ▁ ▁ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """ , ' person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80' , ' ▁ ▁ person ▁ ▁ son ▁ ▁ ▁ gender = male , photo = . . / Files / son . gif , width = 60 , height = 60' , ' person ▁ son ▁ photo = . . / Files / son1 . gif ' , ' person ▁ daughter ▁ radius = 20' , ' person ▁ daughter ▁ radius = 100' , ' ▁ childof ▁ ▁ ( ▁ ▁ mum ▁ ▁ , ▁ son ▁ ▁ ) ▁ ' , ' childof ( mum , ▁ daughter ) ' , ' childof ( dad , ▁ son ) ' , ' childof ( dad , ▁ daughter ) ' ] ) , PARSER = RelationAttributeParser ( ) , TOKENS = lines_to_tokenlists ( ) , VIEWER = GenericTopologyViewer ( ) , CONSOLEECHOER = ConsoleEchoer ( ) , linkages = { ( " CONSOLEREADER " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " DATASOURCE " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " PARSER " , " outbox " ) : ( " TOKENS " , " inbox " ) , ( " TOKENS " , " outbox " ) : ( " VIEWER " , " inbox " ) , ( " VIEWER " , " outbox " ) : ( " CONSOLEECHOER " , " inbox " ) , } ) . run ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="fabian4/trove/tree/master/trove/guestagent/datastore/experimental/redis/manager.py"> # ▁ Copyright ▁ ( c ) ▁ 2013 ▁ Rackspace ENDCOM # ▁ All ▁ Rights ▁ Reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM from oslo_log import log as logging NEW_LINE from oslo_service import periodic_task NEW_LINE from trove . common import cfg NEW_LINE from trove . common import exception NEW_LINE from trove . common . i18n import _ NEW_LINE from trove . common import instance as rd_instance NEW_LINE from trove . common import utils NEW_LINE from trove . guestagent import backup NEW_LINE from trove . guestagent . common import operating_system NEW_LINE from trove . guestagent . datastore . experimental . redis import service NEW_LINE from trove . guestagent import dbaas NEW_LINE from trove . guestagent . strategies . replication import get_replication_strategy NEW_LINE from trove . guestagent import volume NEW_LINE LOG = logging . getLogger ( __name__ ) NEW_LINE CONF = cfg . CONF NEW_LINE MANAGER = CONF . datastore_manager or ' redis ' NEW_LINE REPLICATION_STRATEGY = CONF . get ( MANAGER ) . replication_strategy NEW_LINE REPLICATION_NAMESPACE = CONF . get ( MANAGER ) . replication_namespace NEW_LINE REPLICATION_STRATEGY_CLASS = get_replication_strategy ( REPLICATION_STRATEGY , REPLICATION_NAMESPACE ) NEW_LINE class Manager ( periodic_task . PeriodicTasks ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ is ▁ the ▁ Redis ▁ manager ▁ class . ▁ It ▁ is ▁ dynamically ▁ loaded STRNEWLINE ▁ based ▁ off ▁ of ▁ the ▁ service _ type ▁ of ▁ the ▁ trove ▁ instance STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT super ( Manager , self ) . __init__ ( CONF ) NEW_LINE self . _app = service . RedisApp ( ) NEW_LINE DEDENT @ periodic_task . periodic_task NEW_LINE def update_status ( self , context ) : NEW_LINE INDENT """ STRNEWLINE ▁ Updates ▁ the ▁ redis ▁ trove ▁ instance . ▁ It ▁ is ▁ decorated ▁ with STRNEWLINE ▁ perodic ▁ task ▁ so ▁ it ▁ is ▁ automatically ▁ called ▁ every ▁ 3 ▁ ticks . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Update ▁ status ▁ called . " ) NEW_LINE self . _app . status . update ( ) NEW_LINE DEDENT def rpc_ping ( self , context ) : NEW_LINE INDENT LOG . debug ( " Responding ▁ to ▁ RPC ▁ ping . " ) NEW_LINE return True NEW_LINE DEDENT def change_passwords ( self , context , users ) : NEW_LINE INDENT """ STRNEWLINE ▁ Changes ▁ the ▁ redis ▁ instance ▁ password , STRNEWLINE ▁ it ▁ is ▁ currently ▁ not ▁ not ▁ implemented . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Change ▁ passwords ▁ called . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' change _ passwords ' , datastore = MANAGER ) NEW_LINE DEDENT def reset_configuration ( self , context , configuration ) : NEW_LINE INDENT """ STRNEWLINE ▁ Resets ▁ to ▁ the ▁ default ▁ configuration , STRNEWLINE ▁ currently ▁ this ▁ does ▁ nothing . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Reset ▁ configuration ▁ called . " ) NEW_LINE self . _app . reset_configuration ( configuration ) NEW_LINE DEDENT def _perform_restore ( self , backup_info , context , restore_location , app ) : NEW_LINE INDENT """ Perform ▁ a ▁ restore ▁ on ▁ this ▁ instance . """ NEW_LINE LOG . info ( _ ( " Restoring ▁ database ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE try : NEW_LINE INDENT backup . restore ( context , backup_info , restore_location ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ performing ▁ restore ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT LOG . info ( _ ( " Restored ▁ database ▁ successfully . " ) ) NEW_LINE DEDENT def prepare ( self , context , packages , databases , memory_mb , users , device_path = None , mount_point = None , backup_info = None , config_contents = None , root_password = None , overrides = None , cluster_config = None , snapshot = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ is ▁ called ▁ when ▁ the ▁ trove ▁ instance ▁ first ▁ comes ▁ online . STRNEWLINE ▁ It ▁ is ▁ the ▁ first ▁ rpc ▁ message ▁ passed ▁ from ▁ the ▁ task ▁ manager . STRNEWLINE ▁ prepare ▁ handles ▁ all ▁ the ▁ base ▁ configuration ▁ of ▁ the ▁ redis ▁ instance . STRNEWLINE ▁ """ NEW_LINE try : NEW_LINE INDENT self . _app . status . begin_install ( ) NEW_LINE if device_path : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE # ▁ unmount ▁ if ▁ device ▁ is ▁ already ▁ mounted ENDCOM device . unmount_device ( device_path ) NEW_LINE device . format ( ) NEW_LINE device . mount ( mount_point ) NEW_LINE operating_system . chown ( mount_point , ' redis ' , ' redis ' , as_root = True ) NEW_LINE LOG . debug ( ' Mounted ▁ the ▁ volume . ' ) NEW_LINE DEDENT self . _app . install_if_needed ( packages ) NEW_LINE LOG . info ( _ ( ' Writing ▁ redis ▁ configuration . ' ) ) NEW_LINE if cluster_config : NEW_LINE INDENT config_contents = ( config_contents + " \n " + " cluster - enabled ▁ yes \n " + " cluster - config - file ▁ cluster . conf \n " ) NEW_LINE DEDENT self . _app . configuration_manager . save_configuration ( config_contents ) NEW_LINE self . _app . apply_initial_guestagent_configuration ( ) NEW_LINE if backup_info : NEW_LINE INDENT persistence_dir = self . _app . get_working_dir ( ) NEW_LINE self . _perform_restore ( backup_info , context , persistence_dir , self . _app ) NEW_LINE DEDENT if snapshot : NEW_LINE INDENT self . attach_replica ( context , snapshot , snapshot [ ' config ' ] ) NEW_LINE DEDENT self . _app . restart ( ) NEW_LINE if cluster_config : NEW_LINE INDENT self . _app . status . set_status ( rd_instance . ServiceStatuses . BUILD_PENDING ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT LOG . info ( _ ( ' Redis ▁ instance ▁ has ▁ been ▁ setup ▁ and ▁ configured . ' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ setting ▁ up ▁ Redis ▁ instance . " ) ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def restart ( self , context ) : NEW_LINE INDENT """ STRNEWLINE ▁ Restart ▁ this ▁ redis ▁ instance . STRNEWLINE ▁ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ guest ▁ agent STRNEWLINE ▁ gets ▁ a ▁ restart ▁ message ▁ from ▁ the ▁ taskmanager . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Restart ▁ called . " ) NEW_LINE self . _app . restart ( ) NEW_LINE DEDENT def start_db_with_conf_changes ( self , context , config_contents ) : NEW_LINE INDENT """ STRNEWLINE ▁ Start ▁ this ▁ redis ▁ instance ▁ with ▁ new ▁ conf ▁ changes . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Start ▁ DB ▁ with ▁ conf ▁ changes ▁ called . " ) NEW_LINE self . _app . start_db_with_conf_changes ( config_contents ) NEW_LINE DEDENT def stop_db ( self , context , do_not_start_on_reboot = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Stop ▁ this ▁ redis ▁ instance . STRNEWLINE ▁ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ guest ▁ agent STRNEWLINE ▁ gets ▁ a ▁ stop ▁ message ▁ from ▁ the ▁ taskmanager . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Stop ▁ DB ▁ called . " ) NEW_LINE self . _app . stop_db ( do_not_start_on_reboot = do_not_start_on_reboot ) NEW_LINE DEDENT def get_filesystem_stats ( self , context , fs_path ) : NEW_LINE INDENT """ Gets ▁ the ▁ filesystem ▁ stats ▁ for ▁ the ▁ path ▁ given . """ NEW_LINE LOG . debug ( " Get ▁ Filesystem ▁ Stats . " ) NEW_LINE mount_point = CONF . get ( ' mysql ' if not MANAGER else MANAGER ) . mount_point NEW_LINE return dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE DEDENT def create_backup ( self , context , backup_info ) : NEW_LINE INDENT """ Create ▁ a ▁ backup ▁ of ▁ the ▁ database . """ NEW_LINE LOG . debug ( " Creating ▁ backup . " ) NEW_LINE backup . backup ( context , backup_info ) NEW_LINE DEDENT def mount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . mount ( mount_point , write_to_fstab = False ) NEW_LINE LOG . debug ( " Mounted ▁ the ▁ device ▁ % s ▁ at ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def unmount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . unmount ( mount_point ) NEW_LINE LOG . debug ( " Unmounted ▁ the ▁ device ▁ % s ▁ from ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def resize_fs ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . resize_fs ( mount_point ) NEW_LINE LOG . debug ( " Resized ▁ the ▁ filesystem ▁ at ▁ % s . " % mount_point ) NEW_LINE DEDENT def update_overrides ( self , context , overrides , remove = False ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ overrides . " ) NEW_LINE if remove : NEW_LINE INDENT self . _app . remove_overrides ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . update_overrides ( context , overrides , remove ) NEW_LINE DEDENT DEDENT def apply_overrides ( self , context , overrides ) : NEW_LINE INDENT LOG . debug ( " Applying ▁ overrides . " ) NEW_LINE self . _app . apply_overrides ( self . _app . admin , overrides ) NEW_LINE DEDENT def update_attributes ( self , context , username , hostname , user_attrs ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ attributes . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' update _ attributes ' , datastore = MANAGER ) NEW_LINE DEDENT def create_database ( self , context , databases ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def create_user ( self , context , users ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_database ( self , context , database ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_user ( self , context , user ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def get_user ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' get _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def grant_access ( self , context , username , hostname , databases ) : NEW_LINE INDENT LOG . debug ( " Granting ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' grant _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def revoke_access ( self , context , username , hostname , database ) : NEW_LINE INDENT LOG . debug ( " Revoking ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' revoke _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_access ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_databases ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ databases . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ databases ' , datastore = MANAGER ) NEW_LINE DEDENT def list_users ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ users . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ users ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root ( self , context ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root_with_password ( self , context , root_password = None ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root ▁ with ▁ password . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root _ with _ password ' , datastore = MANAGER ) NEW_LINE DEDENT def is_root_enabled ( self , context ) : NEW_LINE INDENT LOG . debug ( " Checking ▁ if ▁ root ▁ is ▁ enabled . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' is _ root _ enabled ' , datastore = MANAGER ) NEW_LINE DEDENT def backup_required_for_replication ( self , context ) : NEW_LINE INDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE return replication . backup_required_for_replication ( ) NEW_LINE DEDENT def get_replication_snapshot ( self , context , snapshot_info , replica_source_config = None ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replication ▁ snapshot . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE snapshot_id , log_position = ( replication . snapshot_for_replication ( context , self . _app , None , snapshot_info ) ) NEW_LINE mount_point = CONF . get ( MANAGER ) . mount_point NEW_LINE volume_stats = dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE replication_snapshot = { ' dataset ' : { ' datastore _ manager ' : MANAGER , ' dataset _ size ' : volume_stats . get ( ' used ' , 0.0 ) , ' volume _ size ' : volume_stats . get ( ' total ' , 0.0 ) , ' snapshot _ id ' : snapshot_id } , ' replication _ strategy ' : REPLICATION_STRATEGY , ' master ' : replication . get_master_ref ( self . _app , snapshot_info ) , ' log _ position ' : log_position } NEW_LINE return replication_snapshot NEW_LINE DEDENT def enable_as_master ( self , context , replica_source_config ) : NEW_LINE INDENT LOG . debug ( " Calling ▁ enable _ as _ master . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE DEDENT def detach_replica ( self , context , for_failover = False ) : NEW_LINE INDENT LOG . debug ( " Detaching ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . detach_slave ( self . _app , for_failover ) NEW_LINE return replica_info NEW_LINE DEDENT def get_replica_context ( self , context ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replica ▁ context . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . get_replica_context ( self . _app ) NEW_LINE return replica_info NEW_LINE DEDENT def _validate_slave_for_replication ( self , context , replica_info ) : NEW_LINE INDENT if ( replica_info [ ' replication _ strategy ' ] != REPLICATION_STRATEGY ) : NEW_LINE INDENT raise exception . IncompatibleReplicationStrategy ( replica_info . update ( { ' guest _ strategy ' : REPLICATION_STRATEGY } ) ) NEW_LINE DEDENT DEDENT def attach_replica ( self , context , replica_info , slave_config ) : NEW_LINE INDENT LOG . debug ( " Attaching ▁ replica . " ) NEW_LINE try : NEW_LINE INDENT if ' replication _ strategy ' in replica_info : NEW_LINE INDENT self . _validate_slave_for_replication ( context , replica_info ) NEW_LINE DEDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_slave ( self . _app , replica_info , slave_config ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( " Error ▁ enabling ▁ replication . " ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def make_read_only ( self , context , read_only ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ make _ read _ only ( % s ) " % read_only ) NEW_LINE self . _app . make_read_only ( read_only ) NEW_LINE DEDENT def _get_repl_info ( self ) : NEW_LINE INDENT return self . _app . admin . get_info ( ' replication ' ) NEW_LINE DEDENT def _get_master_host ( self ) : NEW_LINE INDENT slave_info = self . _get_repl_info ( ) NEW_LINE return slave_info and slave_info [ ' master _ host ' ] or None NEW_LINE DEDENT def _get_repl_offset ( self ) : NEW_LINE INDENT repl_info = self . _get_repl_info ( ) NEW_LINE LOG . debug ( " Got ▁ repl ▁ info : ▁ % s " % repl_info ) NEW_LINE offset_key = ' % s _ repl _ offset ' % repl_info [ ' role ' ] NEW_LINE offset = repl_info [ offset_key ] NEW_LINE LOG . debug ( " Found ▁ offset ▁ % s ▁ for ▁ key ▁ % s . " % ( offset , offset_key ) ) NEW_LINE return int ( offset ) NEW_LINE DEDENT def get_last_txn ( self , context ) : NEW_LINE INDENT master_host = self . _get_master_host ( ) NEW_LINE repl_offset = self . _get_repl_offset ( ) NEW_LINE return master_host , repl_offset NEW_LINE DEDENT def get_latest_txn_id ( self , context ) : NEW_LINE INDENT LOG . info ( _ ( " Retrieving ▁ latest ▁ repl ▁ offset . " ) ) NEW_LINE return self . _get_repl_offset ( ) NEW_LINE DEDENT def wait_for_txn ( self , context , txn ) : NEW_LINE INDENT LOG . info ( _ ( " Waiting ▁ on ▁ repl ▁ offset ▁ ' % s ' . " ) % txn ) NEW_LINE def _wait_for_txn ( ) : NEW_LINE INDENT current_offset = self . _get_repl_offset ( ) NEW_LINE LOG . debug ( " Current ▁ offset : ▁ % s . " % current_offset ) NEW_LINE return current_offset >= txn NEW_LINE DEDENT try : NEW_LINE INDENT utils . poll_until ( _wait_for_txn , time_out = 120 ) NEW_LINE DEDENT except exception . PollTimeOut : NEW_LINE INDENT raise RuntimeError ( _ ( " Timeout ▁ occurred ▁ waiting ▁ for ▁ Redis ▁ repl ▁ " " offset ▁ to ▁ change ▁ to ▁ ' % s ' . " ) % txn ) NEW_LINE DEDENT DEDENT def cleanup_source_on_replica_detach ( self , context , replica_info ) : NEW_LINE INDENT LOG . debug ( " Cleaning ▁ up ▁ the ▁ source ▁ on ▁ the ▁ detach ▁ of ▁ a ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . cleanup_source_on_replica_detach ( self . _app , replica_info ) NEW_LINE DEDENT def demote_replication_master ( self , context ) : NEW_LINE INDENT LOG . debug ( " Demoting ▁ replica ▁ source . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . demote_master ( self . _app ) NEW_LINE DEDENT def cluster_meet ( self , context , ip , port ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ meet ▁ to ▁ join ▁ node ▁ to ▁ cluster . " ) NEW_LINE self . _app . cluster_meet ( ip , port ) NEW_LINE DEDENT def get_node_ip ( self , context ) : NEW_LINE INDENT LOG . debug ( " Retrieving ▁ cluster ▁ node ▁ ip ▁ address . " ) NEW_LINE return self . _app . get_node_ip ( ) NEW_LINE DEDENT def get_node_id_for_removal ( self , context ) : NEW_LINE INDENT LOG . debug ( " Validating ▁ removal ▁ of ▁ node ▁ from ▁ cluster . " ) NEW_LINE return self . _app . get_node_id_for_removal ( ) NEW_LINE DEDENT def remove_nodes ( self , context , node_ids ) : NEW_LINE INDENT LOG . debug ( " Removing ▁ nodes ▁ from ▁ cluster . " ) NEW_LINE self . _app . remove_nodes ( node_ids ) NEW_LINE DEDENT def cluster_addslots ( self , context , first_slot , last_slot ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ addslots ▁ to ▁ assign ▁ hash ▁ slots ▁ % s - % s . " , first_slot , last_slot ) NEW_LINE self . _app . cluster_addslots ( first_slot , last_slot ) NEW_LINE DEDENT def cluster_complete ( self , context ) : NEW_LINE INDENT LOG . debug ( " Cluster ▁ creation ▁ complete , ▁ starting ▁ status ▁ checks . " ) NEW_LINE self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Hernanarce/pelisalacarta/tree/master/python/version-mediaserver/platformcode/platformtools.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ pelisalacarta ▁ 4 ENDCOM # ▁ Copyright ▁ 2015 ▁ tvalacarta @ gmail . com ENDCOM # ▁ http : / / blog . tvalacarta . info / plugin - xbmc / pelisalacarta / ENDCOM # ▁ Distributed ▁ under ▁ the ▁ terms ▁ of ▁ GNU ▁ General ▁ Public ▁ License ▁ v3 ▁ ( GPLv3 ) ENDCOM # ▁ http : / / www . gnu . org / licenses / gpl - 3.0 . html ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ pelisalacarta ▁ 4 . ENDCOM # ▁ pelisalacarta ▁ 4 ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ pelisalacarta ▁ 4 ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ pelisalacarta ▁ 4 . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM # ▁ platformtools ENDCOM # ▁ Herramientas ▁ responsables ▁ de ▁ adaptar ▁ los ▁ diferentes ▁ ENDCOM # ▁ cuadros ▁ de ▁ dialogo ▁ a ▁ una ▁ plataforma ▁ en ▁ concreto , ENDCOM # ▁ en ▁ este ▁ caso ▁ Mediserver . ENDCOM # ▁ version ▁ 1.3 ENDCOM import os NEW_LINE import sys NEW_LINE from core import config NEW_LINE from core import logger NEW_LINE import threading NEW_LINE controllers = { } NEW_LINE def dialog_ok ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_ok ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_notification ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_notification ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_yesno ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_yesno ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_select ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_select ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress_bg ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress_bg ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_input ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_input ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_numeric ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_numeric ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_refresh ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_refresh ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_update ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_update ( * args , ** kwargs ) NEW_LINE DEDENT def render_items ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . render_items ( * args , ** kwargs ) NEW_LINE DEDENT def is_playing ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . is_playing ( * args , ** kwargs ) NEW_LINE DEDENT def play_video ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . play_video ( * args , ** kwargs ) NEW_LINE DEDENT def open_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . open_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_channel_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_channel_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_video_info ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_video_info ( * args , ** kwargs ) NEW_LINE DEDENT def show_recaptcha ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_recaptcha ( * args , ** kwargs ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="apollo13/ansible/tree/master/lib/ansible/modules/cloud/amazon/elasticache.py"> # ! / usr / bin / python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2017 ▁ Ansible ▁ Project ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = """ STRNEWLINE - - - STRNEWLINE module : ▁ elasticache STRNEWLINE short _ description : ▁ Manage ▁ cache ▁ clusters ▁ in ▁ Amazon ▁ Elasticache . STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ Manage ▁ cache ▁ clusters ▁ in ▁ Amazon ▁ Elasticache . STRNEWLINE ▁ ▁ - ▁ Returns ▁ information ▁ about ▁ the ▁ specified ▁ cache ▁ cluster . STRNEWLINE version _ added : ▁ " 1.4 " STRNEWLINE requirements : ▁ [ ▁ boto3 ▁ ] STRNEWLINE author : ▁ " Jim ▁ Dalton ▁ ( @ jsdalton ) " STRNEWLINE options : STRNEWLINE ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ C ( absent ) ▁ or ▁ C ( present ) ▁ are ▁ idempotent ▁ actions ▁ that ▁ will ▁ create ▁ or ▁ destroy ▁ a ▁ cache ▁ cluster ▁ as ▁ needed . ▁ C ( rebooted ) ▁ will ▁ reboot ▁ the ▁ cluster , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ resulting ▁ in ▁ a ▁ momentary ▁ outage . STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' present ' , ▁ ' absent ' , ▁ ' rebooted ' ] STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ cache ▁ cluster ▁ identifier STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ engine : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ cache ▁ engine ▁ to ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ memcached STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' redis ' , ▁ ' memcached ' ] STRNEWLINE ▁ ▁ cache _ engine _ version : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ version ▁ number ▁ of ▁ the ▁ cache ▁ engine STRNEWLINE ▁ ▁ node _ type : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ compute ▁ and ▁ memory ▁ capacity ▁ of ▁ the ▁ nodes ▁ in ▁ the ▁ cache ▁ cluster STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ cache . m1 . small STRNEWLINE ▁ ▁ num _ nodes : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ initial ▁ number ▁ of ▁ cache ▁ nodes ▁ that ▁ the ▁ cache ▁ cluster ▁ will ▁ have . ▁ Required ▁ when ▁ state = present . STRNEWLINE ▁ ▁ cache _ port : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ port ▁ number ▁ on ▁ which ▁ each ▁ of ▁ the ▁ cache ▁ nodes ▁ will ▁ accept ▁ connections STRNEWLINE ▁ ▁ cache _ parameter _ group : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ name ▁ of ▁ the ▁ cache ▁ parameter ▁ group ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ If ▁ this ▁ argument ▁ is ▁ omitted , ▁ the ▁ default ▁ cache ▁ parameter ▁ group STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ for ▁ the ▁ specified ▁ engine ▁ will ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 2.0 " STRNEWLINE ▁ ▁ ▁ ▁ aliases : ▁ [ ▁ ' parameter _ group ' ▁ ] STRNEWLINE ▁ ▁ cache _ subnet _ group : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ subnet ▁ group ▁ name ▁ to ▁ associate ▁ with . ▁ Only ▁ use ▁ if ▁ inside ▁ a ▁ vpc . ▁ Required ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 2.0 " STRNEWLINE ▁ ▁ security _ group _ ids : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ list ▁ of ▁ vpc ▁ security ▁ group ▁ names ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ Only ▁ use ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 1.6 " STRNEWLINE ▁ ▁ cache _ security _ groups : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ list ▁ of ▁ cache ▁ security ▁ group ▁ names ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ Must ▁ be ▁ an ▁ empty ▁ list ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ zone : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ EC2 ▁ Availability ▁ Zone ▁ in ▁ which ▁ the ▁ cache ▁ cluster ▁ will ▁ be ▁ created STRNEWLINE ▁ ▁ wait : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Wait ▁ for ▁ cache ▁ cluster ▁ result ▁ before ▁ returning STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' yes ' STRNEWLINE ▁ ▁ hard _ modify : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Whether ▁ to ▁ destroy ▁ and ▁ recreate ▁ an ▁ existing ▁ cache ▁ cluster ▁ if ▁ necessary ▁ in ▁ order ▁ to ▁ modify ▁ its ▁ state STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE extends _ documentation _ fragment : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ aws STRNEWLINE ▁ ▁ ▁ ▁ - ▁ ec2 STRNEWLINE """ NEW_LINE EXAMPLES = """ STRNEWLINE # ▁ Note : ▁ None ▁ of ▁ these ▁ examples ▁ set ▁ aws _ access _ key , ▁ aws _ secret _ key , ▁ or ▁ region . STRNEWLINE # ▁ It ▁ is ▁ assumed ▁ that ▁ their ▁ matching ▁ environment ▁ variables ▁ are ▁ set . STRNEWLINE STRNEWLINE # ▁ Basic ▁ example STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ engine : ▁ memcached STRNEWLINE ▁ ▁ ▁ ▁ cache _ engine _ version : ▁ 1.4.14 STRNEWLINE ▁ ▁ ▁ ▁ node _ type : ▁ cache . m1 . small STRNEWLINE ▁ ▁ ▁ ▁ num _ nodes : ▁ 1 STRNEWLINE ▁ ▁ ▁ ▁ cache _ port : ▁ 11211 STRNEWLINE ▁ ▁ ▁ ▁ cache _ security _ groups : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ default STRNEWLINE ▁ ▁ ▁ ▁ zone : ▁ us - east - 1d STRNEWLINE STRNEWLINE STRNEWLINE # ▁ Ensure ▁ cache ▁ cluster ▁ is ▁ gone STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE STRNEWLINE # ▁ Reboot ▁ cache ▁ cluster STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ rebooted STRNEWLINE STRNEWLINE """ NEW_LINE from time import sleep NEW_LINE from traceback import format_exc NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . ec2 import ec2_argument_spec , get_aws_connection_info , boto3_conn , HAS_BOTO3 , camel_dict_to_snake_dict NEW_LINE try : NEW_LINE INDENT import boto3 NEW_LINE import botocore NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass # ▁ will ▁ be ▁ detected ▁ by ▁ imported ▁ HAS _ BOTO3 ENDCOM NEW_LINE DEDENT class ElastiCacheManager ( object ) : NEW_LINE INDENT """ Handles ▁ elasticache ▁ creation ▁ and ▁ destruction """ NEW_LINE EXIST_STATUSES = [ ' available ' , ' creating ' , ' rebooting ' , ' modifying ' ] NEW_LINE def __init__ ( self , module , name , engine , cache_engine_version , node_type , num_nodes , cache_port , cache_parameter_group , cache_subnet_group , cache_security_groups , security_group_ids , zone , wait , hard_modify , region , ** aws_connect_kwargs ) : NEW_LINE INDENT self . module = module NEW_LINE self . name = name NEW_LINE self . engine = engine . lower ( ) NEW_LINE self . cache_engine_version = cache_engine_version NEW_LINE self . node_type = node_type NEW_LINE self . num_nodes = num_nodes NEW_LINE self . cache_port = cache_port NEW_LINE self . cache_parameter_group = cache_parameter_group NEW_LINE self . cache_subnet_group = cache_subnet_group NEW_LINE self . cache_security_groups = cache_security_groups NEW_LINE self . security_group_ids = security_group_ids NEW_LINE self . zone = zone NEW_LINE self . wait = wait NEW_LINE self . hard_modify = hard_modify NEW_LINE self . region = region NEW_LINE self . aws_connect_kwargs = aws_connect_kwargs NEW_LINE self . changed = False NEW_LINE self . data = None NEW_LINE self . status = ' gone ' NEW_LINE self . conn = self . _get_elasticache_connection ( ) NEW_LINE self . _refresh_data ( ) NEW_LINE DEDENT def ensure_present ( self ) : NEW_LINE INDENT """ Ensure ▁ cache ▁ cluster ▁ exists ▁ or ▁ create ▁ it ▁ if ▁ not """ NEW_LINE if self . exists ( ) : NEW_LINE INDENT self . sync ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . create ( ) NEW_LINE DEDENT DEDENT def ensure_absent ( self ) : NEW_LINE INDENT """ Ensure ▁ cache ▁ cluster ▁ is ▁ gone ▁ or ▁ delete ▁ it ▁ if ▁ not """ NEW_LINE self . delete ( ) NEW_LINE DEDENT def ensure_rebooted ( self ) : NEW_LINE INDENT """ Ensure ▁ cache ▁ cluster ▁ is ▁ gone ▁ or ▁ delete ▁ it ▁ if ▁ not """ NEW_LINE self . reboot ( ) NEW_LINE DEDENT def exists ( self ) : NEW_LINE INDENT """ Check ▁ if ▁ cache ▁ cluster ▁ exists """ NEW_LINE return self . status in self . EXIST_STATUSES NEW_LINE DEDENT def create ( self ) : NEW_LINE INDENT """ Create ▁ an ▁ ElastiCache ▁ cluster """ NEW_LINE if self . status == ' available ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT return NEW_LINE DEDENT if self . status == ' deleting ' : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ deleting . ▁ Cannot ▁ create . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT DEDENT kwargs = dict ( CacheClusterId = self . name , NumCacheNodes = self . num_nodes , CacheNodeType = self . node_type , Engine = self . engine , EngineVersion = self . cache_engine_version , CacheSecurityGroupNames = self . cache_security_groups , SecurityGroupIds = self . security_group_ids , CacheParameterGroupName = self . cache_parameter_group , CacheSubnetGroupName = self . cache_subnet_group ) NEW_LINE if self . cache_port is not None : NEW_LINE INDENT kwargs [ ' Port ' ] = self . cache_port NEW_LINE DEDENT if self . zone is not None : NEW_LINE INDENT kwargs [ ' PreferredAvailabilityZone ' ] = self . zone NEW_LINE DEDENT try : NEW_LINE INDENT self . conn . create_cache_cluster ( ** kwargs ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT return True NEW_LINE DEDENT def delete ( self ) : NEW_LINE INDENT """ Destroy ▁ an ▁ ElastiCache ▁ cluster """ NEW_LINE if self . status == ' gone ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status == ' deleting ' : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ % s . ▁ Cannot ▁ delete . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT response = self . conn . delete_cache_cluster ( CacheClusterId = self . name ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT cache_cluster_data = response [ ' CacheCluster ' ] NEW_LINE self . _refresh_data ( cache_cluster_data ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT DEDENT def sync ( self ) : NEW_LINE INDENT """ Sync ▁ settings ▁ to ▁ cluster ▁ if ▁ required """ NEW_LINE if not self . exists ( ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ % s . ▁ Cannot ▁ sync . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE # ▁ Cluster ▁ can ▁ only ▁ be ▁ synced ▁ if ▁ available . ▁ If ▁ we ▁ can ' t ▁ wait ENDCOM # ▁ for ▁ this , ▁ then ▁ just ▁ be ▁ done . ENDCOM INDENT return NEW_LINE DEDENT DEDENT if self . _requires_destroy_and_create ( ) : NEW_LINE INDENT if not self . hard_modify : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ destructive ▁ modification . ▁ ' hard _ modify ' ▁ must ▁ be ▁ set ▁ to ▁ true ▁ to ▁ proceed . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT if not self . wait : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ destructive ▁ modification . ▁ ' wait ' ▁ must ▁ be ▁ set ▁ to ▁ true . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT self . delete ( ) NEW_LINE self . create ( ) NEW_LINE return NEW_LINE DEDENT if self . _requires_modification ( ) : NEW_LINE INDENT self . modify ( ) NEW_LINE DEDENT DEDENT def modify ( self ) : NEW_LINE INDENT """ Modify ▁ the ▁ cache ▁ cluster . ▁ Note ▁ it ' s ▁ only ▁ possible ▁ to ▁ modify ▁ a ▁ few ▁ select ▁ options . """ NEW_LINE nodes_to_remove = self . _get_nodes_to_remove ( ) NEW_LINE try : NEW_LINE INDENT self . conn . modify_cache_cluster ( CacheClusterId = self . name , NumCacheNodes = self . num_nodes , CacheNodeIdsToRemove = nodes_to_remove , CacheSecurityGroupNames = self . cache_security_groups , CacheParameterGroupName = self . cache_parameter_group , SecurityGroupIds = self . security_group_ids , ApplyImmediately = True , EngineVersion = self . cache_engine_version ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT DEDENT def reboot ( self ) : NEW_LINE INDENT """ Reboot ▁ the ▁ cache ▁ cluster """ NEW_LINE if not self . exists ( ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ % s . ▁ Cannot ▁ reboot . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT if self . status == ' rebooting ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ % s . ▁ Cannot ▁ reboot . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE # ▁ Collect ▁ ALL ▁ nodes ▁ for ▁ reboot ENDCOM DEDENT DEDENT cache_node_ids = [ cn [ ' CacheNodeId ' ] for cn in self . data [ ' CacheNodes ' ] ] NEW_LINE try : NEW_LINE INDENT self . conn . reboot_cache_cluster ( CacheClusterId = self . name , CacheNodeIdsToReboot = cache_node_ids ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT DEDENT def get_info ( self ) : NEW_LINE INDENT """ Return ▁ basic ▁ info ▁ about ▁ the ▁ cache ▁ cluster """ NEW_LINE info = { ' name ' : self . name , ' status ' : self . status } NEW_LINE if self . data : NEW_LINE INDENT info [ ' data ' ] = self . data NEW_LINE DEDENT return info NEW_LINE DEDENT def _wait_for_status ( self , awaited_status ) : NEW_LINE INDENT """ Wait ▁ for ▁ status ▁ to ▁ change ▁ from ▁ present ▁ status ▁ to ▁ awaited _ status """ NEW_LINE status_map = { ' creating ' : ' available ' , ' rebooting ' : ' available ' , ' modifying ' : ' available ' , ' deleting ' : ' gone ' } NEW_LINE if self . status == awaited_status : NEW_LINE # ▁ No ▁ need ▁ to ▁ wait , ▁ we ' re ▁ already ▁ done ENDCOM INDENT return NEW_LINE DEDENT if status_map [ self . status ] != awaited_status : NEW_LINE INDENT msg = " Invalid ▁ awaited ▁ status . ▁ ' % s ' ▁ cannot ▁ transition ▁ to ▁ ' % s ' " NEW_LINE self . module . fail_json ( msg = msg % ( self . status , awaited_status ) ) NEW_LINE DEDENT if awaited_status not in set ( status_map . values ( ) ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ not ▁ a ▁ valid ▁ awaited ▁ status . " NEW_LINE self . module . fail_json ( msg = msg % awaited_status ) NEW_LINE DEDENT while True : NEW_LINE INDENT sleep ( 1 ) NEW_LINE self . _refresh_data ( ) NEW_LINE if self . status == awaited_status : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT DEDENT def _requires_modification ( self ) : NEW_LINE INDENT """ Check ▁ if ▁ cluster ▁ requires ▁ ( nondestructive ) ▁ modification """ NEW_LINE # ▁ Check ▁ modifiable ▁ data ▁ attributes ENDCOM modifiable_data = { ' NumCacheNodes ' : self . num_nodes , ' EngineVersion ' : self . cache_engine_version } NEW_LINE for key , value in modifiable_data . items ( ) : NEW_LINE INDENT if value is not None and value and self . data [ key ] != value : NEW_LINE INDENT return True NEW_LINE # ▁ Check ▁ cache ▁ security ▁ groups ENDCOM DEDENT DEDENT cache_security_groups = [ ] NEW_LINE for sg in self . data [ ' CacheSecurityGroups ' ] : NEW_LINE INDENT cache_security_groups . append ( sg [ ' CacheSecurityGroupName ' ] ) NEW_LINE DEDENT if set ( cache_security_groups ) != set ( self . cache_security_groups ) : NEW_LINE INDENT return True NEW_LINE # ▁ check ▁ vpc ▁ security ▁ groups ENDCOM DEDENT if self . security_group_ids : NEW_LINE INDENT vpc_security_groups = [ ] NEW_LINE security_groups = self . data [ ' SecurityGroups ' ] or [ ] NEW_LINE for sg in security_groups : NEW_LINE INDENT vpc_security_groups . append ( sg [ ' SecurityGroupId ' ] ) NEW_LINE DEDENT if set ( vpc_security_groups ) != set ( self . security_group_ids ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def _requires_destroy_and_create ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Check ▁ whether ▁ a ▁ destroy ▁ and ▁ create ▁ is ▁ required ▁ to ▁ synchronize ▁ cluster . STRNEWLINE ▁ """ NEW_LINE unmodifiable_data = { ' node _ type ' : self . data [ ' CacheNodeType ' ] , ' engine ' : self . data [ ' Engine ' ] , ' cache _ port ' : self . _get_port ( ) } NEW_LINE # ▁ Only ▁ check ▁ for ▁ modifications ▁ if ▁ zone ▁ is ▁ specified ENDCOM if self . zone is not None : NEW_LINE INDENT unmodifiable_data [ ' zone ' ] = self . data [ ' PreferredAvailabilityZone ' ] NEW_LINE DEDENT for key , value in unmodifiable_data . items ( ) : NEW_LINE INDENT if getattr ( self , key ) is not None and getattr ( self , key ) != value : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def _get_elasticache_connection ( self ) : NEW_LINE INDENT """ Get ▁ an ▁ elasticache ▁ connection """ NEW_LINE region , ec2_url , aws_connect_params = get_aws_connection_info ( self . module , boto3 = True ) NEW_LINE if region : NEW_LINE INDENT return boto3_conn ( self . module , conn_type = ' client ' , resource = ' elasticache ' , region = region , endpoint = ec2_url , ** aws_connect_params ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = " region ▁ must ▁ be ▁ specified " ) NEW_LINE DEDENT DEDENT def _get_port ( self ) : NEW_LINE INDENT """ Get ▁ the ▁ port . ▁ Where ▁ this ▁ information ▁ is ▁ retrieved ▁ from ▁ is ▁ engine ▁ dependent . """ NEW_LINE if self . data [ ' Engine ' ] == ' memcached ' : NEW_LINE INDENT return self . data [ ' ConfigurationEndpoint ' ] [ ' Port ' ] NEW_LINE DEDENT elif self . data [ ' Engine ' ] == ' redis ' : NEW_LINE # ▁ Redis ▁ only ▁ supports ▁ a ▁ single ▁ node ▁ ( presently ) ▁ so ▁ just ▁ use ENDCOM # ▁ the ▁ first ▁ and ▁ only ENDCOM INDENT return self . data [ ' CacheNodes ' ] [ 0 ] [ ' Endpoint ' ] [ ' Port ' ] NEW_LINE DEDENT DEDENT def _refresh_data ( self , cache_cluster_data = None ) : NEW_LINE INDENT """ Refresh ▁ data ▁ about ▁ this ▁ cache ▁ cluster """ NEW_LINE if cache_cluster_data is None : NEW_LINE INDENT try : NEW_LINE INDENT response = self . conn . describe_cache_clusters ( CacheClusterId = self . name , ShowCacheNodeInfo = True ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT if e . response [ ' Error ' ] [ ' Code ' ] == ' CacheClusterNotFound ' : NEW_LINE INDENT self . data = None NEW_LINE self . status = ' gone ' NEW_LINE return NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT DEDENT cache_cluster_data = response [ ' CacheClusters ' ] [ 0 ] NEW_LINE DEDENT self . data = cache_cluster_data NEW_LINE self . status = self . data [ ' CacheClusterStatus ' ] NEW_LINE # ▁ The ▁ documentation ▁ for ▁ elasticache ▁ lies ▁ - - ▁ status ▁ on ▁ rebooting ▁ is ▁ set ENDCOM # ▁ to ▁ ' rebooting ▁ cache ▁ cluster ▁ nodes ' ▁ instead ▁ of ▁ ' rebooting ' . ▁ Fix ▁ it ENDCOM # ▁ here ▁ to ▁ make ▁ status ▁ checks ▁ etc . ▁ more ▁ sane . ENDCOM if self . status == ' rebooting ▁ cache ▁ cluster ▁ nodes ' : NEW_LINE INDENT self . status = ' rebooting ' NEW_LINE DEDENT DEDENT def _get_nodes_to_remove ( self ) : NEW_LINE INDENT """ If ▁ there ▁ are ▁ nodes ▁ to ▁ remove , ▁ it ▁ figures ▁ out ▁ which ▁ need ▁ to ▁ be ▁ removed """ NEW_LINE num_nodes_to_remove = self . data [ ' NumCacheNodes ' ] - self . num_nodes NEW_LINE if num_nodes_to_remove <= 0 : NEW_LINE INDENT return [ ] NEW_LINE DEDENT if not self . hard_modify : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ removal ▁ of ▁ cache ▁ nodes . ▁ ' hard _ modify ' ▁ must ▁ be ▁ set ▁ to ▁ true ▁ to ▁ proceed . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT cache_node_ids = [ cn [ ' CacheNodeId ' ] for cn in self . data [ ' CacheNodes ' ] ] NEW_LINE return cache_node_ids [ - num_nodes_to_remove : ] NEW_LINE DEDENT DEDENT def main ( ) : NEW_LINE INDENT """ ▁ elasticache ▁ ansible ▁ module ▁ """ NEW_LINE argument_spec = ec2_argument_spec ( ) NEW_LINE argument_spec . update ( dict ( state = dict ( required = True , choices = [ ' present ' , ' absent ' , ' rebooted ' ] ) , name = dict ( required = True ) , engine = dict ( default = ' memcached ' ) , cache_engine_version = dict ( default = " " ) , node_type = dict ( default = ' cache . t2 . small ' ) , num_nodes = dict ( default = 1 , type = ' int ' ) , # ▁ alias ▁ for ▁ compat ▁ with ▁ the ▁ original ▁ PR ▁ 1950 ENDCOM cache_parameter_group = dict ( default = " " , aliases = [ ' parameter _ group ' ] ) , cache_port = dict ( type = ' int ' ) , cache_subnet_group = dict ( default = " " ) , cache_security_groups = dict ( default = [ ] , type = ' list ' ) , security_group_ids = dict ( default = [ ] , type = ' list ' ) , zone = dict ( ) , wait = dict ( default = True , type = ' bool ' ) , hard_modify = dict ( type = ' bool ' ) ) ) NEW_LINE module = AnsibleModule ( argument_spec = argument_spec , ) NEW_LINE if not HAS_BOTO3 : NEW_LINE INDENT module . fail_json ( msg = ' boto3 ▁ required ▁ for ▁ this ▁ module ' ) NEW_LINE DEDENT region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module ) NEW_LINE name = module . params [ ' name ' ] NEW_LINE state = module . params [ ' state ' ] NEW_LINE engine = module . params [ ' engine ' ] NEW_LINE cache_engine_version = module . params [ ' cache _ engine _ version ' ] NEW_LINE node_type = module . params [ ' node _ type ' ] NEW_LINE num_nodes = module . params [ ' num _ nodes ' ] NEW_LINE cache_port = module . params [ ' cache _ port ' ] NEW_LINE cache_subnet_group = module . params [ ' cache _ subnet _ group ' ] NEW_LINE cache_security_groups = module . params [ ' cache _ security _ groups ' ] NEW_LINE security_group_ids = module . params [ ' security _ group _ ids ' ] NEW_LINE zone = module . params [ ' zone ' ] NEW_LINE wait = module . params [ ' wait ' ] NEW_LINE hard_modify = module . params [ ' hard _ modify ' ] NEW_LINE cache_parameter_group = module . params [ ' cache _ parameter _ group ' ] NEW_LINE if cache_subnet_group and cache_security_groups : NEW_LINE INDENT module . fail_json ( msg = " Can ' t ▁ specify ▁ both ▁ cache _ subnet _ group ▁ and ▁ cache _ security _ groups " ) NEW_LINE DEDENT if state == ' present ' and not num_nodes : NEW_LINE INDENT module . fail_json ( msg = " ' num _ nodes ' ▁ is ▁ a ▁ required ▁ parameter . ▁ Please ▁ specify ▁ num _ nodes ▁ > ▁ 0" ) NEW_LINE DEDENT elasticache_manager = ElastiCacheManager ( module , name , engine , cache_engine_version , node_type , num_nodes , cache_port , cache_parameter_group , cache_subnet_group , cache_security_groups , security_group_ids , zone , wait , hard_modify , region , ** aws_connect_kwargs ) NEW_LINE if state == ' present ' : NEW_LINE INDENT elasticache_manager . ensure_present ( ) NEW_LINE DEDENT elif state == ' absent ' : NEW_LINE INDENT elasticache_manager . ensure_absent ( ) NEW_LINE DEDENT elif state == ' rebooted ' : NEW_LINE INDENT elasticache_manager . ensure_rebooted ( ) NEW_LINE DEDENT facts_result = dict ( changed = elasticache_manager . changed , elasticache = elasticache_manager . get_info ( ) ) NEW_LINE module . exit_json ( ** facts_result ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="agabrown/PyGaia/tree/master/pygaia/utils.py"> __all__ = [ ' enum ' , ' degreesToRadians ' , ' radiansToDegrees ' ] NEW_LINE import numpy as np NEW_LINE from pygaia . astrometry . constants import auKmYearPerSec NEW_LINE def enum ( typename , field_names ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ a ▁ new ▁ enumeration ▁ type . STRNEWLINE ▁ STRNEWLINE ▁ Code ▁ is ▁ copyright ▁ ( c ) ▁ Gabriel ▁ Genellina , ▁ 2010 , ▁ MIT ▁ License . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ typename ▁ - ▁ Name ▁ of ▁ the ▁ enumerated ▁ type STRNEWLINE ▁ field _ names ▁ - ▁ Names ▁ of ▁ the ▁ fields ▁ of ▁ the ▁ enumerated ▁ type STRNEWLINE ▁ """ NEW_LINE if isinstance ( field_names , str ) : NEW_LINE INDENT field_names = field_names . replace ( ' , ' , ' ▁ ' ) . split ( ) NEW_LINE DEDENT d = dict ( ( reversed ( nv ) for nv in enumerate ( field_names ) ) , __slots__ = ( ) ) NEW_LINE return type ( typename , ( object , ) , d ) ( ) NEW_LINE DEDENT def degreesToRadians ( angle ) : NEW_LINE INDENT """ STRNEWLINE ▁ Convert ▁ from ▁ degrees ▁ to ▁ radians . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ angle ▁ - ▁ angle ▁ in ▁ degrees STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ Angle ▁ in ▁ radians . STRNEWLINE ▁ """ NEW_LINE return angle / 180.0 * np . pi NEW_LINE DEDENT def radiansToDegrees ( angle ) : NEW_LINE INDENT """ STRNEWLINE ▁ Convert ▁ from ▁ radians ▁ to ▁ degrees . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ angle ▁ - ▁ angle ▁ in ▁ radians . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ STRNEWLINE ▁ Angle ▁ in ▁ degrees . STRNEWLINE ▁ """ NEW_LINE return angle / np . pi * 180.0 NEW_LINE DEDENT def construct_covariance_matrix ( cvec , parallax , radial_velocity , radial_velocity_error ) : NEW_LINE INDENT """ STRNEWLINE ▁ Take ▁ the ▁ astrometric ▁ parameter ▁ standard ▁ uncertainties ▁ and ▁ the ▁ uncertainty ▁ correlations ▁ as ▁ quoted ▁ in STRNEWLINE ▁ the ▁ Gaia ▁ catalogue ▁ and ▁ construct ▁ the ▁ covariance ▁ matrix . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ cvec ▁ : ▁ array _ like STRNEWLINE ▁ Array ▁ of ▁ shape ▁ ( 15 , ) ▁ ( 1 ▁ source ) ▁ or ▁ ( n , 15 ) ▁ ( n ▁ sources ) ▁ for ▁ the ▁ astrometric ▁ parameter ▁ standard STRNEWLINE ▁ uncertainties ▁ and ▁ their ▁ correlations , ▁ as ▁ listed ▁ in ▁ the ▁ Gaia ▁ catalogue ▁ [ ra _ error , ▁ dec _ error , STRNEWLINE ▁ parallax _ error , ▁ pmra _ error , ▁ pmdec _ error , ▁ ra _ dec _ corr , ▁ ra _ parallax _ corr , ▁ ra _ pmra _ corr , STRNEWLINE ▁ ra _ pmdec _ corr , ▁ dec _ parallax _ corr , ▁ dec _ pmra _ corr , ▁ dec _ pmdec _ corr , ▁ parallax _ pmra _ corr , STRNEWLINE ▁ parallax _ pmdec _ corr , ▁ pmra _ pmdec _ corr ] . ▁ Units ▁ are ▁ ( mas ^ 2 , ▁ mas ^ 2 / yr , ▁ mas ^ 2 / yr ^ 2 ) . STRNEWLINE ▁ STRNEWLINE ▁ parallax ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ parallax ▁ ( mas ) . STRNEWLINE ▁ STRNEWLINE ▁ radial _ velocity ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ radial ▁ velocity ▁ ( km / s , ▁ does ▁ not ▁ have ▁ to ▁ be ▁ from ▁ Gaia ▁ RVS ! ) . ▁ If ▁ the ▁ radial ▁ velocity ▁ is ▁ not STRNEWLINE ▁ known ▁ it ▁ can ▁ be ▁ set ▁ to ▁ zero . STRNEWLINE STRNEWLINE ▁ radial _ velocity _ error ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ radial ▁ velocity ▁ uncertainty ▁ ( km / s ) . ▁ If ▁ the ▁ radial ▁ velocity ▁ is ▁ not ▁ know ▁ this ▁ can ▁ be ▁ set ▁ to STRNEWLINE ▁ the ▁ radial ▁ velocity ▁ dispersion ▁ for ▁ the ▁ population ▁ the ▁ source ▁ was ▁ drawn ▁ from . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ Covariance ▁ matrix ▁ as ▁ a ▁ 6x6 ▁ array . STRNEWLINE ▁ """ NEW_LINE if np . ndim ( cvec ) == 1 : NEW_LINE INDENT cmat = np . zeros ( ( 1 , 6 , 6 ) ) NEW_LINE nsources = 1 NEW_LINE cv = np . atleast_2d ( cvec ) NEW_LINE DEDENT else : NEW_LINE INDENT nsources = cvec . shape [ 0 ] NEW_LINE cmat = np . zeros ( ( nsources , 6 , 6 ) ) NEW_LINE cv = cvec NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 0 : 5 ] = cv [ k , 0 : 5 ] ** 2 NEW_LINE DEDENT iu = np . triu_indices ( 5 , k = 1 ) NEW_LINE for k in range ( 10 ) : NEW_LINE INDENT i = iu [ 0 ] [ k ] NEW_LINE j = iu [ 1 ] [ k ] NEW_LINE cmat [ : , i , j ] = cv [ : , i ] * cv [ : , j ] * cv [ : , k + 5 ] NEW_LINE cmat [ : , j , i ] = cmat [ : , i , j ] NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 5 ] = cmat [ k , 0 : 5 , 2 ] * np . atleast_1d ( radial_velocity ) [ k ] / auKmYearPerSec NEW_LINE DEDENT cmat [ : , 5 , 0 : 5 ] = cmat [ : , 0 : 5 , 5 ] NEW_LINE cmat [ : , 5 , 5 ] = cmat [ : , 2 , 2 ] * ( radial_velocity ** 2 + radial_velocity_error ** 2 ) / auKmYearPerSec ** 2 + ( parallax * radial_velocity_error / auKmYearPerSec ) ** 2 NEW_LINE return np . squeeze ( cmat ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="ftomassetti/intellij-community/tree/master/python/lib/Lib/site-packages/django/contrib/gis/geos/tests/test_geos.py"> import ctypes , random , unittest , sys NEW_LINE from django . contrib . gis . geos import * NEW_LINE from django . contrib . gis . geos . base import gdal , numpy , GEOSBase NEW_LINE from django . contrib . gis . geos . libgeos import GEOS_PREPARE NEW_LINE from django . contrib . gis . geometry . test_data import TestDataMixin NEW_LINE class GEOSTest ( unittest . TestCase , TestDataMixin ) : NEW_LINE INDENT @ property NEW_LINE def null_srid ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ the ▁ proper ▁ null ▁ SRID ▁ depending ▁ on ▁ the ▁ GEOS ▁ version . STRNEWLINE ▁ See ▁ the ▁ comments ▁ in ▁ ` test15 _ srid ` ▁ for ▁ more ▁ details . STRNEWLINE ▁ """ NEW_LINE info = geos_version_info ( ) NEW_LINE if info [ ' version ' ] == '3.0.0' and info [ ' release _ candidate ' ] : NEW_LINE INDENT return - 1 NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT def test00_base ( self ) : NEW_LINE INDENT " Tests ▁ out ▁ the ▁ GEOSBase ▁ class . " NEW_LINE # ▁ Testing ▁ out ▁ GEOSBase ▁ class , ▁ which ▁ provides ▁ a ▁ ` ptr ` ▁ property ENDCOM # ▁ that ▁ abstracts ▁ out ▁ access ▁ to ▁ underlying ▁ C ▁ pointers . ENDCOM class FakeGeom1 ( GEOSBase ) : NEW_LINE INDENT pass NEW_LINE # ▁ This ▁ one ▁ only ▁ accepts ▁ pointers ▁ to ▁ floats ENDCOM DEDENT c_float_p = ctypes . POINTER ( ctypes . c_float ) NEW_LINE class FakeGeom2 ( GEOSBase ) : NEW_LINE INDENT ptr_type = c_float_p NEW_LINE # ▁ Default ▁ ptr _ type ▁ is ▁ ` c _ void _ p ` . ENDCOM DEDENT fg1 = FakeGeom1 ( ) NEW_LINE # ▁ Default ▁ ptr _ type ▁ is ▁ C ▁ float ▁ pointer ENDCOM fg2 = FakeGeom2 ( ) NEW_LINE # ▁ These ▁ assignments ▁ are ▁ OK ▁ - - ▁ None ▁ is ▁ allowed ▁ because ENDCOM # ▁ it ' s ▁ equivalent ▁ to ▁ the ▁ NULL ▁ pointer . ENDCOM fg1 . ptr = ctypes . c_void_p ( ) NEW_LINE fg1 . ptr = None NEW_LINE fg2 . ptr = c_float_p ( ctypes . c_float ( 5.23 ) ) NEW_LINE fg2 . ptr = None NEW_LINE # ▁ Because ▁ pointers ▁ have ▁ been ▁ set ▁ to ▁ NULL , ▁ an ▁ exception ▁ should ▁ be ENDCOM # ▁ raised ▁ when ▁ we ▁ try ▁ to ▁ access ▁ it . ▁ Raising ▁ an ▁ exception ▁ is ENDCOM # ▁ preferrable ▁ to ▁ a ▁ segmentation ▁ fault ▁ that ▁ commonly ▁ occurs ▁ when ENDCOM # ▁ a ▁ C ▁ method ▁ is ▁ given ▁ a ▁ NULL ▁ memory ▁ reference . ENDCOM for fg in ( fg1 , fg2 ) : NEW_LINE # ▁ Equivalent ▁ to ▁ ` fg . ptr ` ENDCOM INDENT self . assertRaises ( GEOSException , fg . _get_ptr ) NEW_LINE # ▁ Anything ▁ that ▁ is ▁ either ▁ not ▁ None ▁ or ▁ the ▁ acceptable ▁ pointer ▁ type ▁ will ENDCOM # ▁ result ▁ in ▁ a ▁ TypeError ▁ when ▁ trying ▁ to ▁ assign ▁ it ▁ to ▁ the ▁ ` ptr ` ▁ property . ENDCOM # ▁ Thus , ▁ memmory ▁ addresses ▁ ( integers ) ▁ and ▁ pointers ▁ of ▁ the ▁ incorrect ▁ type ENDCOM # ▁ ( in ▁ ` bad _ ptrs ` ) ▁ will ▁ not ▁ be ▁ allowed . ENDCOM DEDENT bad_ptrs = ( 5 , ctypes . c_char_p ( ' foobar ' ) ) NEW_LINE for bad_ptr in bad_ptrs : NEW_LINE # ▁ Equivalent ▁ to ▁ ` fg . ptr ▁ = ▁ bad _ ptr ` ENDCOM INDENT self . assertRaises ( TypeError , fg1 . _set_ptr , bad_ptr ) NEW_LINE self . assertRaises ( TypeError , fg2 . _set_ptr , bad_ptr ) NEW_LINE DEDENT DEDENT def test01a_wkt ( self ) : NEW_LINE INDENT " Testing ▁ WKT ▁ output . " NEW_LINE for g in self . geometries . wkt_out : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( g . ewkt , geom . wkt ) NEW_LINE DEDENT DEDENT def test01b_hex ( self ) : NEW_LINE INDENT " Testing ▁ HEX ▁ output . " NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( g . hex , geom . hex ) NEW_LINE DEDENT DEDENT def test01b_hexewkb ( self ) : NEW_LINE INDENT " Testing ▁ ( HEX ) EWKB ▁ output . " NEW_LINE from binascii import a2b_hex NEW_LINE # ▁ For ▁ testing ▁ HEX ( EWKB ) . ENDCOM ogc_hex = '01010000000000000000000000000000000000F03F ' NEW_LINE # ▁ ` SELECT ▁ ST _ AsHEXEWKB ( ST _ GeomFromText ( ' POINT ( 0 ▁ 1 ) ' , ▁ 4326 ) ) ; ` ENDCOM hexewkb_2d = '0101000020E61000000000000000000000000000000000F03F ' NEW_LINE # ▁ ` SELECT ▁ ST _ AsHEXEWKB ( ST _ GeomFromEWKT ( ' SRID = 4326 ; POINT ( 0 ▁ 1 ▁ 2 ) ' ) ) ; ` ENDCOM hexewkb_3d = '01010000A0E61000000000000000000000000000000000F03F0000000000000040' NEW_LINE pnt_2d = Point ( 0 , 1 , srid = 4326 ) NEW_LINE pnt_3d = Point ( 0 , 1 , 2 , srid = 4326 ) NEW_LINE # ▁ OGC - compliant ▁ HEX ▁ will ▁ not ▁ have ▁ SRID ▁ nor ▁ Z ▁ value . ENDCOM self . assertEqual ( ogc_hex , pnt_2d . hex ) NEW_LINE self . assertEqual ( ogc_hex , pnt_3d . hex ) NEW_LINE # ▁ HEXEWKB ▁ should ▁ be ▁ appropriate ▁ for ▁ its ▁ dimension ▁ - - ▁ have ▁ to ▁ use ▁ an ENDCOM # ▁ a ▁ WKBWriter ▁ w / dimension ▁ set ▁ accordingly , ▁ else ▁ GEOS ▁ will ▁ insert ENDCOM # ▁ garbage ▁ into ▁ 3D ▁ coordinate ▁ if ▁ there ▁ is ▁ none . ▁ Also , ▁ GEOS ▁ has ▁ a ENDCOM # ▁ a ▁ bug ▁ in ▁ versions ▁ prior ▁ to ▁ 3.1 ▁ that ▁ puts ▁ the ▁ X ▁ coordinate ▁ in ENDCOM # ▁ place ▁ of ▁ Z ; ▁ an ▁ exception ▁ should ▁ be ▁ raised ▁ on ▁ those ▁ versions . ENDCOM self . assertEqual ( hexewkb_2d , pnt_2d . hexewkb ) NEW_LINE if GEOS_PREPARE : NEW_LINE INDENT self . assertEqual ( hexewkb_3d , pnt_3d . hexewkb ) NEW_LINE self . assertEqual ( True , GEOSGeometry ( hexewkb_3d ) . hasz ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT hexewkb = pnt_3d . hexewkb NEW_LINE DEDENT except GEOSException : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Should ▁ have ▁ raised ▁ GEOSException . ' ) NEW_LINE # ▁ Same ▁ for ▁ EWKB . ENDCOM DEDENT DEDENT self . assertEqual ( buffer ( a2b_hex ( hexewkb_2d ) ) , pnt_2d . ewkb ) NEW_LINE if GEOS_PREPARE : NEW_LINE INDENT self . assertEqual ( buffer ( a2b_hex ( hexewkb_3d ) ) , pnt_3d . ewkb ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT ewkb = pnt_3d . ewkb NEW_LINE DEDENT except GEOSException : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Should ▁ have ▁ raised ▁ GEOSException ' ) NEW_LINE # ▁ Redundant ▁ sanity ▁ check . ENDCOM DEDENT DEDENT self . assertEqual ( 4326 , GEOSGeometry ( hexewkb_2d ) . srid ) NEW_LINE DEDENT def test01c_kml ( self ) : NEW_LINE INDENT " Testing ▁ KML ▁ output . " NEW_LINE for tg in self . geometries . wkt_out : NEW_LINE INDENT geom = fromstr ( tg . wkt ) NEW_LINE kml = getattr ( tg , ' kml ' , False ) NEW_LINE if kml : self . assertEqual ( kml , geom . kml ) NEW_LINE DEDENT DEDENT def test01d_errors ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ Error ▁ handlers . " NEW_LINE # ▁ string - based ENDCOM print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ ERROR ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE for err in self . geometries . errors : NEW_LINE INDENT try : NEW_LINE INDENT g = fromstr ( err . wkt ) NEW_LINE DEDENT except ( GEOSException , ValueError ) : NEW_LINE INDENT pass NEW_LINE # ▁ Bad ▁ WKB ENDCOM DEDENT DEDENT self . assertRaises ( GEOSException , GEOSGeometry , buffer ( '0' ) ) NEW_LINE print " \n END ▁ - ▁ expecting ▁ GEOS _ ERROR ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE class NotAGeometry ( object ) : NEW_LINE INDENT pass NEW_LINE # ▁ Some ▁ other ▁ object ENDCOM DEDENT self . assertRaises ( TypeError , GEOSGeometry , NotAGeometry ( ) ) NEW_LINE # ▁ None ENDCOM self . assertRaises ( TypeError , GEOSGeometry , None ) NEW_LINE DEDENT def test01e_wkb ( self ) : NEW_LINE INDENT " Testing ▁ WKB ▁ output . " NEW_LINE from binascii import b2a_hex NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE wkb = geom . wkb NEW_LINE self . assertEqual ( b2a_hex ( wkb ) . upper ( ) , g . hex ) NEW_LINE DEDENT DEDENT def test01f_create_hex ( self ) : NEW_LINE INDENT " Testing ▁ creation ▁ from ▁ HEX . " NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom_h = GEOSGeometry ( g . hex ) NEW_LINE # ▁ we ▁ need ▁ to ▁ do ▁ this ▁ so ▁ decimal ▁ places ▁ get ▁ normalised ENDCOM geom_t = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( geom_t . wkt , geom_h . wkt ) NEW_LINE DEDENT DEDENT def test01g_create_wkb ( self ) : NEW_LINE INDENT " Testing ▁ creation ▁ from ▁ WKB . " NEW_LINE from binascii import a2b_hex NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT wkb = buffer ( a2b_hex ( g . hex ) ) NEW_LINE geom_h = GEOSGeometry ( wkb ) NEW_LINE # ▁ we ▁ need ▁ to ▁ do ▁ this ▁ so ▁ decimal ▁ places ▁ get ▁ normalised ENDCOM geom_t = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( geom_t . wkt , geom_h . wkt ) NEW_LINE DEDENT DEDENT def test01h_ewkt ( self ) : NEW_LINE INDENT " Testing ▁ EWKT . " NEW_LINE srid = 32140 NEW_LINE for p in self . geometries . polygons : NEW_LINE INDENT ewkt = ' SRID = % d ; % s ' % ( srid , p . wkt ) NEW_LINE poly = fromstr ( ewkt ) NEW_LINE self . assertEqual ( srid , poly . srid ) NEW_LINE self . assertEqual ( srid , poly . shell . srid ) NEW_LINE self . assertEqual ( srid , fromstr ( poly . ewkt ) . srid ) # ▁ Checking ▁ export ENDCOM NEW_LINE DEDENT DEDENT def test01i_json ( self ) : NEW_LINE INDENT " Testing ▁ GeoJSON ▁ input / output ▁ ( via ▁ GDAL ) . " NEW_LINE if not gdal or not gdal . GEOJSON : return NEW_LINE for g in self . geometries . json_geoms : NEW_LINE INDENT geom = GEOSGeometry ( g . wkt ) NEW_LINE if not hasattr ( g , ' not _ equal ' ) : NEW_LINE INDENT self . assertEqual ( g . json , geom . json ) NEW_LINE self . assertEqual ( g . json , geom . geojson ) NEW_LINE DEDENT self . assertEqual ( GEOSGeometry ( g . wkt ) , GEOSGeometry ( geom . json ) ) NEW_LINE DEDENT DEDENT def test01k_fromfile ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ fromfile ( ) ▁ factory . " NEW_LINE from StringIO import StringIO NEW_LINE ref_pnt = GEOSGeometry ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE wkt_f = StringIO ( ) NEW_LINE wkt_f . write ( ref_pnt . wkt ) NEW_LINE wkb_f = StringIO ( ) NEW_LINE wkb_f . write ( str ( ref_pnt . wkb ) ) NEW_LINE # ▁ Other ▁ tests ▁ use ▁ ` fromfile ( ) ` ▁ on ▁ string ▁ filenames ▁ so ▁ those ENDCOM # ▁ aren ' t ▁ tested ▁ here . ENDCOM for fh in ( wkt_f , wkb_f ) : NEW_LINE INDENT fh . seek ( 0 ) NEW_LINE pnt = fromfile ( fh ) NEW_LINE self . assertEqual ( ref_pnt , pnt ) NEW_LINE DEDENT DEDENT def test01k_eq ( self ) : NEW_LINE INDENT " Testing ▁ equivalence . " NEW_LINE p = fromstr ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE self . assertEqual ( p , p . wkt ) NEW_LINE self . assertNotEqual ( p , ' foo ' ) NEW_LINE ls = fromstr ( ' LINESTRING ( 0 ▁ 0 , ▁ 1 ▁ 1 , ▁ 5 ▁ 5 ) ' ) NEW_LINE self . assertEqual ( ls , ls . wkt ) NEW_LINE self . assertNotEqual ( p , ' bar ' ) NEW_LINE # ▁ Error ▁ shouldn ' t ▁ be ▁ raise ▁ on ▁ equivalence ▁ testing ▁ with ENDCOM # ▁ an ▁ invalid ▁ type . ENDCOM for g in ( p , ls ) : NEW_LINE INDENT self . assertNotEqual ( g , None ) NEW_LINE self . assertNotEqual ( g , { ' foo ' : ' bar ' } ) NEW_LINE self . assertNotEqual ( g , False ) NEW_LINE DEDENT DEDENT def test02a_points ( self ) : NEW_LINE INDENT " Testing ▁ Point ▁ objects . " NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for p in self . geometries . points : NEW_LINE # ▁ Creating ▁ the ▁ point ▁ from ▁ the ▁ WKT ENDCOM INDENT pnt = fromstr ( p . wkt ) NEW_LINE self . assertEqual ( pnt . geom_type , ' Point ' ) NEW_LINE self . assertEqual ( pnt . geom_typeid , 0 ) NEW_LINE self . assertEqual ( p . x , pnt . x ) NEW_LINE self . assertEqual ( p . y , pnt . y ) NEW_LINE self . assertEqual ( True , pnt == fromstr ( p . wkt ) ) NEW_LINE self . assertEqual ( False , pnt == prev ) NEW_LINE # ▁ Making ▁ sure ▁ that ▁ the ▁ point ' s ▁ X , ▁ Y ▁ components ▁ are ▁ what ▁ we ▁ expect ENDCOM self . assertAlmostEqual ( p . x , pnt . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( p . y , pnt . tuple [ 1 ] , 9 ) NEW_LINE # ▁ Testing ▁ the ▁ third ▁ dimension , ▁ and ▁ getting ▁ the ▁ tuple ▁ arguments ENDCOM if hasattr ( p , ' z ' ) : NEW_LINE INDENT self . assertEqual ( True , pnt . hasz ) NEW_LINE self . assertEqual ( p . z , pnt . z ) NEW_LINE self . assertEqual ( p . z , pnt . tuple [ 2 ] , 9 ) NEW_LINE tup_args = ( p . x , p . y , p . z ) NEW_LINE set_tup1 = ( 2.71 , 3.14 , 5.23 ) NEW_LINE set_tup2 = ( 5.23 , 2.71 , 3.14 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( False , pnt . hasz ) NEW_LINE self . assertEqual ( None , pnt . z ) NEW_LINE tup_args = ( p . x , p . y ) NEW_LINE set_tup1 = ( 2.71 , 3.14 ) NEW_LINE set_tup2 = ( 3.14 , 2.71 ) NEW_LINE # ▁ Centroid ▁ operation ▁ on ▁ point ▁ should ▁ be ▁ point ▁ itself ENDCOM DEDENT self . assertEqual ( p . centroid , pnt . centroid . tuple ) NEW_LINE # ▁ Now ▁ testing ▁ the ▁ different ▁ constructors ENDCOM pnt2 = Point ( tup_args ) # ▁ e . g . , ▁ Point ( (1 , ▁ 2 ) ) ENDCOM NEW_LINE pnt3 = Point ( * tup_args ) # ▁ e . g . , ▁ Point ( 1 , ▁ 2 ) ENDCOM NEW_LINE self . assertEqual ( True , pnt == pnt2 ) NEW_LINE self . assertEqual ( True , pnt == pnt3 ) NEW_LINE # ▁ Now ▁ testing ▁ setting ▁ the ▁ x ▁ and ▁ y ENDCOM pnt . y = 3.14 NEW_LINE pnt . x = 2.71 NEW_LINE self . assertEqual ( 3.14 , pnt . y ) NEW_LINE self . assertEqual ( 2.71 , pnt . x ) NEW_LINE # ▁ Setting ▁ via ▁ the ▁ tuple / coords ▁ property ENDCOM pnt . tuple = set_tup1 NEW_LINE self . assertEqual ( set_tup1 , pnt . tuple ) NEW_LINE pnt . coords = set_tup2 NEW_LINE self . assertEqual ( set_tup2 , pnt . coords ) NEW_LINE prev = pnt # ▁ setting ▁ the ▁ previous ▁ geometry ENDCOM NEW_LINE DEDENT DEDENT def test02b_multipoints ( self ) : NEW_LINE INDENT " Testing ▁ MultiPoint ▁ objects . " NEW_LINE for mp in self . geometries . multipoints : NEW_LINE INDENT mpnt = fromstr ( mp . wkt ) NEW_LINE self . assertEqual ( mpnt . geom_type , ' MultiPoint ' ) NEW_LINE self . assertEqual ( mpnt . geom_typeid , 4 ) NEW_LINE self . assertAlmostEqual ( mp . centroid [ 0 ] , mpnt . centroid . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( mp . centroid [ 1 ] , mpnt . centroid . tuple [ 1 ] , 9 ) NEW_LINE self . assertRaises ( GEOSIndexError , mpnt . __getitem__ , len ( mpnt ) ) NEW_LINE self . assertEqual ( mp . centroid , mpnt . centroid . tuple ) NEW_LINE self . assertEqual ( mp . coords , tuple ( m . tuple for m in mpnt ) ) NEW_LINE for p in mpnt : NEW_LINE INDENT self . assertEqual ( p . geom_type , ' Point ' ) NEW_LINE self . assertEqual ( p . geom_typeid , 0 ) NEW_LINE self . assertEqual ( p . empty , False ) NEW_LINE self . assertEqual ( p . valid , True ) NEW_LINE DEDENT DEDENT DEDENT def test03a_linestring ( self ) : NEW_LINE INDENT " Testing ▁ LineString ▁ objects . " NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for l in self . geometries . linestrings : NEW_LINE INDENT ls = fromstr ( l . wkt ) NEW_LINE self . assertEqual ( ls . geom_type , ' LineString ' ) NEW_LINE self . assertEqual ( ls . geom_typeid , 1 ) NEW_LINE self . assertEqual ( ls . empty , False ) NEW_LINE self . assertEqual ( ls . ring , False ) NEW_LINE if hasattr ( l , ' centroid ' ) : NEW_LINE INDENT self . assertEqual ( l . centroid , ls . centroid . tuple ) NEW_LINE DEDENT if hasattr ( l , ' tup ' ) : NEW_LINE INDENT self . assertEqual ( l . tup , ls . tuple ) NEW_LINE DEDENT self . assertEqual ( True , ls == fromstr ( l . wkt ) ) NEW_LINE self . assertEqual ( False , ls == prev ) NEW_LINE self . assertRaises ( GEOSIndexError , ls . __getitem__ , len ( ls ) ) NEW_LINE prev = ls NEW_LINE # ▁ Creating ▁ a ▁ LineString ▁ from ▁ a ▁ tuple , ▁ list , ▁ and ▁ numpy ▁ array ENDCOM self . assertEqual ( ls , LineString ( ls . tuple ) ) # ▁ tuple ENDCOM NEW_LINE self . assertEqual ( ls , LineString ( * ls . tuple ) ) # ▁ as ▁ individual ▁ arguments ENDCOM NEW_LINE self . assertEqual ( ls , LineString ( [ list ( tup ) for tup in ls . tuple ] ) ) # ▁ as ▁ list ENDCOM NEW_LINE self . assertEqual ( ls . wkt , LineString ( * tuple ( Point ( tup ) for tup in ls . tuple ) ) . wkt ) # ▁ Point ▁ individual ▁ arguments ENDCOM NEW_LINE if numpy : self . assertEqual ( ls , LineString ( numpy . array ( ls . tuple ) ) ) # ▁ as ▁ numpy ▁ array ENDCOM NEW_LINE DEDENT DEDENT def test03b_multilinestring ( self ) : NEW_LINE INDENT " Testing ▁ MultiLineString ▁ objects . " NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for l in self . geometries . multilinestrings : NEW_LINE INDENT ml = fromstr ( l . wkt ) NEW_LINE self . assertEqual ( ml . geom_type , ' MultiLineString ' ) NEW_LINE self . assertEqual ( ml . geom_typeid , 5 ) NEW_LINE self . assertAlmostEqual ( l . centroid [ 0 ] , ml . centroid . x , 9 ) NEW_LINE self . assertAlmostEqual ( l . centroid [ 1 ] , ml . centroid . y , 9 ) NEW_LINE self . assertEqual ( True , ml == fromstr ( l . wkt ) ) NEW_LINE self . assertEqual ( False , ml == prev ) NEW_LINE prev = ml NEW_LINE for ls in ml : NEW_LINE INDENT self . assertEqual ( ls . geom_type , ' LineString ' ) NEW_LINE self . assertEqual ( ls . geom_typeid , 1 ) NEW_LINE self . assertEqual ( ls . empty , False ) NEW_LINE DEDENT self . assertRaises ( GEOSIndexError , ml . __getitem__ , len ( ml ) ) NEW_LINE self . assertEqual ( ml . wkt , MultiLineString ( * tuple ( s . clone ( ) for s in ml ) ) . wkt ) NEW_LINE self . assertEqual ( ml , MultiLineString ( * tuple ( LineString ( s . tuple ) for s in ml ) ) ) NEW_LINE DEDENT DEDENT def test04_linearring ( self ) : NEW_LINE INDENT " Testing ▁ LinearRing ▁ objects . " NEW_LINE for rr in self . geometries . linearrings : NEW_LINE INDENT lr = fromstr ( rr . wkt ) NEW_LINE self . assertEqual ( lr . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( lr . geom_typeid , 2 ) NEW_LINE self . assertEqual ( rr . n_p , len ( lr ) ) NEW_LINE self . assertEqual ( True , lr . valid ) NEW_LINE self . assertEqual ( False , lr . empty ) NEW_LINE # ▁ Creating ▁ a ▁ LinearRing ▁ from ▁ a ▁ tuple , ▁ list , ▁ and ▁ numpy ▁ array ENDCOM self . assertEqual ( lr , LinearRing ( lr . tuple ) ) NEW_LINE self . assertEqual ( lr , LinearRing ( * lr . tuple ) ) NEW_LINE self . assertEqual ( lr , LinearRing ( [ list ( tup ) for tup in lr . tuple ] ) ) NEW_LINE if numpy : self . assertEqual ( lr , LinearRing ( numpy . array ( lr . tuple ) ) ) NEW_LINE DEDENT DEDENT def test05a_polygons ( self ) : NEW_LINE INDENT " Testing ▁ Polygon ▁ objects . " NEW_LINE # ▁ Testing ▁ ` from _ bbox ` ▁ class ▁ method ENDCOM bbox = ( - 180 , - 90 , 180 , 90 ) NEW_LINE p = Polygon . from_bbox ( bbox ) NEW_LINE self . assertEqual ( bbox , p . extent ) NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for p in self . geometries . polygons : NEW_LINE # ▁ Creating ▁ the ▁ Polygon , ▁ testing ▁ its ▁ properties . ENDCOM INDENT poly = fromstr ( p . wkt ) NEW_LINE self . assertEqual ( poly . geom_type , ' Polygon ' ) NEW_LINE self . assertEqual ( poly . geom_typeid , 3 ) NEW_LINE self . assertEqual ( poly . empty , False ) NEW_LINE self . assertEqual ( poly . ring , False ) NEW_LINE self . assertEqual ( p . n_i , poly . num_interior_rings ) NEW_LINE self . assertEqual ( p . n_i + 1 , len ( poly ) ) # ▁ Testing ▁ _ _ len _ _ ENDCOM NEW_LINE self . assertEqual ( p . n_p , poly . num_points ) NEW_LINE # ▁ Area ▁ & ▁ Centroid ENDCOM self . assertAlmostEqual ( p . area , poly . area , 9 ) NEW_LINE self . assertAlmostEqual ( p . centroid [ 0 ] , poly . centroid . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( p . centroid [ 1 ] , poly . centroid . tuple [ 1 ] , 9 ) NEW_LINE # ▁ Testing ▁ the ▁ geometry ▁ equivalence ENDCOM self . assertEqual ( True , poly == fromstr ( p . wkt ) ) NEW_LINE self . assertEqual ( False , poly == prev ) # ▁ Should ▁ not ▁ be ▁ equal ▁ to ▁ previous ▁ geometry ENDCOM NEW_LINE self . assertEqual ( True , poly != prev ) NEW_LINE # ▁ Testing ▁ the ▁ exterior ▁ ring ENDCOM ring = poly . exterior_ring NEW_LINE self . assertEqual ( ring . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( ring . geom_typeid , 2 ) NEW_LINE if p . ext_ring_cs : NEW_LINE INDENT self . assertEqual ( p . ext_ring_cs , ring . tuple ) NEW_LINE self . assertEqual ( p . ext_ring_cs , poly [ 0 ] . tuple ) # ▁ Testing ▁ _ _ getitem _ _ ENDCOM NEW_LINE # ▁ Testing ▁ _ _ getitem _ _ ▁ and ▁ _ _ setitem _ _ ▁ on ▁ invalid ▁ indices ENDCOM DEDENT self . assertRaises ( GEOSIndexError , poly . __getitem__ , len ( poly ) ) NEW_LINE self . assertRaises ( GEOSIndexError , poly . __setitem__ , len ( poly ) , False ) NEW_LINE self . assertRaises ( GEOSIndexError , poly . __getitem__ , - 1 * len ( poly ) - 1 ) NEW_LINE # ▁ Testing ▁ _ _ iter _ _ ENDCOM for r in poly : NEW_LINE INDENT self . assertEqual ( r . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( r . geom_typeid , 2 ) NEW_LINE # ▁ Testing ▁ polygon ▁ construction . ENDCOM DEDENT self . assertRaises ( TypeError , Polygon . __init__ , 0 , [ 1 , 2 , 3 ] ) NEW_LINE self . assertRaises ( TypeError , Polygon . __init__ , ' foo ' ) NEW_LINE # ▁ Polygon ( shell , ▁ ( hole1 , ▁ . . . ▁ holeN ) ) ENDCOM rings = tuple ( r for r in poly ) NEW_LINE self . assertEqual ( poly , Polygon ( rings [ 0 ] , rings [ 1 : ] ) ) NEW_LINE # ▁ Polygon ( shell _ tuple , ▁ hole _ tuple1 , ▁ . . . ▁ , ▁ hole _ tupleN ) ENDCOM ring_tuples = tuple ( r . tuple for r in poly ) NEW_LINE self . assertEqual ( poly , Polygon ( * ring_tuples ) ) NEW_LINE # ▁ Constructing ▁ with ▁ tuples ▁ of ▁ LinearRings . ENDCOM self . assertEqual ( poly . wkt , Polygon ( * tuple ( r for r in poly ) ) . wkt ) NEW_LINE self . assertEqual ( poly . wkt , Polygon ( * tuple ( LinearRing ( r . tuple ) for r in poly ) ) . wkt ) NEW_LINE DEDENT DEDENT def test05b_multipolygons ( self ) : NEW_LINE INDENT " Testing ▁ MultiPolygon ▁ objects . " NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE prev = fromstr ( ' POINT ▁ ( 0 ▁ 0 ) ' ) NEW_LINE for mp in self . geometries . multipolygons : NEW_LINE INDENT mpoly = fromstr ( mp . wkt ) NEW_LINE self . assertEqual ( mpoly . geom_type , ' MultiPolygon ' ) NEW_LINE self . assertEqual ( mpoly . geom_typeid , 6 ) NEW_LINE self . assertEqual ( mp . valid , mpoly . valid ) NEW_LINE if mp . valid : NEW_LINE INDENT self . assertEqual ( mp . num_geom , mpoly . num_geom ) NEW_LINE self . assertEqual ( mp . n_p , mpoly . num_coords ) NEW_LINE self . assertEqual ( mp . num_geom , len ( mpoly ) ) NEW_LINE self . assertRaises ( GEOSIndexError , mpoly . __getitem__ , len ( mpoly ) ) NEW_LINE for p in mpoly : NEW_LINE INDENT self . assertEqual ( p . geom_type , ' Polygon ' ) NEW_LINE self . assertEqual ( p . geom_typeid , 3 ) NEW_LINE self . assertEqual ( p . valid , True ) NEW_LINE DEDENT self . assertEqual ( mpoly . wkt , MultiPolygon ( * tuple ( poly . clone ( ) for poly in mpoly ) ) . wkt ) NEW_LINE DEDENT DEDENT print " \n END ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE DEDENT def test06a_memory_hijinks ( self ) : NEW_LINE INDENT " Testing ▁ Geometry ▁ _ _ del _ _ ( ) ▁ on ▁ rings ▁ and ▁ polygons . " NEW_LINE # # # # ▁ Memory ▁ issues ▁ with ▁ rings ▁ and ▁ polygons ENDCOM # ▁ These ▁ tests ▁ are ▁ needed ▁ to ▁ ensure ▁ sanity ▁ with ▁ writable ▁ geometries . ENDCOM # ▁ Getting ▁ a ▁ polygon ▁ with ▁ interior ▁ rings , ▁ and ▁ pulling ▁ out ▁ the ▁ interior ▁ rings ENDCOM poly = fromstr ( self . geometries . polygons [ 1 ] . wkt ) NEW_LINE ring1 = poly [ 0 ] NEW_LINE ring2 = poly [ 1 ] NEW_LINE # ▁ These ▁ deletes ▁ should ▁ be ▁ ' harmless ' ▁ since ▁ they ▁ are ▁ done ▁ on ▁ child ▁ geometries ENDCOM del ring1 NEW_LINE del ring2 NEW_LINE ring1 = poly [ 0 ] NEW_LINE ring2 = poly [ 1 ] NEW_LINE # ▁ Deleting ▁ the ▁ polygon ENDCOM del poly NEW_LINE # ▁ Access ▁ to ▁ these ▁ rings ▁ is ▁ OK ▁ since ▁ they ▁ are ▁ clones . ENDCOM s1 , s2 = str ( ring1 ) , str ( ring2 ) NEW_LINE DEDENT def test08_coord_seq ( self ) : NEW_LINE INDENT " Testing ▁ Coordinate ▁ Sequence ▁ objects . " NEW_LINE for p in self . geometries . polygons : NEW_LINE INDENT if p . ext_ring_cs : NEW_LINE # ▁ Constructing ▁ the ▁ polygon ▁ and ▁ getting ▁ the ▁ coordinate ▁ sequence ENDCOM INDENT poly = fromstr ( p . wkt ) NEW_LINE cs = poly . exterior_ring . coord_seq NEW_LINE self . assertEqual ( p . ext_ring_cs , cs . tuple ) # ▁ done ▁ in ▁ the ▁ Polygon ▁ test ▁ too . ENDCOM NEW_LINE self . assertEqual ( len ( p . ext_ring_cs ) , len ( cs ) ) # ▁ Making ▁ sure ▁ _ _ len _ _ ▁ works ENDCOM NEW_LINE # ▁ Checks ▁ _ _ getitem _ _ ▁ and ▁ _ _ setitem _ _ ENDCOM for i in xrange ( len ( p . ext_ring_cs ) ) : NEW_LINE INDENT c1 = p . ext_ring_cs [ i ] # ▁ Expected ▁ value ENDCOM NEW_LINE c2 = cs [ i ] # ▁ Value ▁ from ▁ coordseq ENDCOM NEW_LINE self . assertEqual ( c1 , c2 ) NEW_LINE # ▁ Constructing ▁ the ▁ test ▁ value ▁ to ▁ set ▁ the ▁ coordinate ▁ sequence ▁ with ENDCOM if len ( c1 ) == 2 : tset = ( 5 , 23 ) NEW_LINE else : tset = ( 5 , 23 , 8 ) NEW_LINE cs [ i ] = tset NEW_LINE # ▁ Making ▁ sure ▁ every ▁ set ▁ point ▁ matches ▁ what ▁ we ▁ expect ENDCOM for j in range ( len ( tset ) ) : NEW_LINE INDENT cs [ i ] = tset NEW_LINE self . assertEqual ( tset [ j ] , cs [ i ] [ j ] ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def test09_relate_pattern ( self ) : NEW_LINE INDENT " Testing ▁ relate ( ) ▁ and ▁ relate _ pattern ( ) . " NEW_LINE g = fromstr ( ' POINT ▁ ( 0 ▁ 0 ) ' ) NEW_LINE self . assertRaises ( GEOSException , g . relate_pattern , 0 , ' invalid ▁ pattern , ▁ yo ' ) NEW_LINE for rg in self . geometries . relate_geoms : NEW_LINE INDENT a = fromstr ( rg . wkt_a ) NEW_LINE b = fromstr ( rg . wkt_b ) NEW_LINE self . assertEqual ( rg . result , a . relate_pattern ( b , rg . pattern ) ) NEW_LINE self . assertEqual ( rg . pattern , a . relate ( b ) ) NEW_LINE DEDENT DEDENT def test10_intersection ( self ) : NEW_LINE INDENT " Testing ▁ intersects ( ) ▁ and ▁ intersection ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE i1 = fromstr ( self . geometries . intersect_geoms [ i ] . wkt ) NEW_LINE self . assertEqual ( True , a . intersects ( b ) ) NEW_LINE i2 = a . intersection ( b ) NEW_LINE self . assertEqual ( i1 , i2 ) NEW_LINE self . assertEqual ( i1 , a & b ) # ▁ _ _ and _ _ ▁ is ▁ intersection ▁ operator ENDCOM NEW_LINE a &= b # ▁ testing ▁ _ _ iand _ _ ENDCOM NEW_LINE self . assertEqual ( i1 , a ) NEW_LINE DEDENT DEDENT def test11_union ( self ) : NEW_LINE INDENT " Testing ▁ union ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE u1 = fromstr ( self . geometries . union_geoms [ i ] . wkt ) NEW_LINE u2 = a . union ( b ) NEW_LINE self . assertEqual ( u1 , u2 ) NEW_LINE self . assertEqual ( u1 , a | b ) # ▁ _ _ or _ _ ▁ is ▁ union ▁ operator ENDCOM NEW_LINE a |= b # ▁ testing ▁ _ _ ior _ _ ENDCOM NEW_LINE self . assertEqual ( u1 , a ) NEW_LINE DEDENT DEDENT def test12_difference ( self ) : NEW_LINE INDENT " Testing ▁ difference ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE d1 = fromstr ( self . geometries . diff_geoms [ i ] . wkt ) NEW_LINE d2 = a . difference ( b ) NEW_LINE self . assertEqual ( d1 , d2 ) NEW_LINE self . assertEqual ( d1 , a - b ) # ▁ _ _ sub _ _ ▁ is ▁ difference ▁ operator ENDCOM NEW_LINE a -= b # ▁ testing ▁ _ _ isub _ _ ENDCOM NEW_LINE self . assertEqual ( d1 , a ) NEW_LINE DEDENT DEDENT def test13_symdifference ( self ) : NEW_LINE INDENT " Testing ▁ sym _ difference ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE d1 = fromstr ( self . geometries . sdiff_geoms [ i ] . wkt ) NEW_LINE d2 = a . sym_difference ( b ) NEW_LINE self . assertEqual ( d1 , d2 ) NEW_LINE self . assertEqual ( d1 , a ^ b ) # ▁ _ _ xor _ _ ▁ is ▁ symmetric ▁ difference ▁ operator ENDCOM NEW_LINE a ^= b # ▁ testing ▁ _ _ ixor _ _ ENDCOM NEW_LINE self . assertEqual ( d1 , a ) NEW_LINE DEDENT DEDENT def test14_buffer ( self ) : NEW_LINE INDENT " Testing ▁ buffer ( ) . " NEW_LINE for bg in self . geometries . buffer_geoms : NEW_LINE INDENT g = fromstr ( bg . wkt ) NEW_LINE # ▁ The ▁ buffer ▁ we ▁ expect ENDCOM exp_buf = fromstr ( bg . buffer_wkt ) NEW_LINE quadsegs = bg . quadsegs NEW_LINE width = bg . width NEW_LINE # ▁ Can ' t ▁ use ▁ a ▁ floating - point ▁ for ▁ the ▁ number ▁ of ▁ quadsegs . ENDCOM self . assertRaises ( ctypes . ArgumentError , g . buffer , width , float ( quadsegs ) ) NEW_LINE # ▁ Constructing ▁ our ▁ buffer ENDCOM buf = g . buffer ( width , quadsegs ) NEW_LINE self . assertEqual ( exp_buf . num_coords , buf . num_coords ) NEW_LINE self . assertEqual ( len ( exp_buf ) , len ( buf ) ) NEW_LINE # ▁ Now ▁ assuring ▁ that ▁ each ▁ point ▁ in ▁ the ▁ buffer ▁ is ▁ almost ▁ equal ENDCOM for j in xrange ( len ( exp_buf ) ) : NEW_LINE INDENT exp_ring = exp_buf [ j ] NEW_LINE buf_ring = buf [ j ] NEW_LINE self . assertEqual ( len ( exp_ring ) , len ( buf_ring ) ) NEW_LINE for k in xrange ( len ( exp_ring ) ) : NEW_LINE # ▁ Asserting ▁ the ▁ X , ▁ Y ▁ of ▁ each ▁ point ▁ are ▁ almost ▁ equal ▁ ( due ▁ to ▁ floating ▁ point ▁ imprecision ) ENDCOM INDENT self . assertAlmostEqual ( exp_ring [ k ] [ 0 ] , buf_ring [ k ] [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( exp_ring [ k ] [ 1 ] , buf_ring [ k ] [ 1 ] , 9 ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def test15_srid ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ SRID ▁ property ▁ and ▁ keyword . " NEW_LINE # ▁ Testing ▁ SRID ▁ keyword ▁ on ▁ Point ENDCOM pnt = Point ( 5 , 23 , srid = 4326 ) NEW_LINE self . assertEqual ( 4326 , pnt . srid ) NEW_LINE pnt . srid = 3084 NEW_LINE self . assertEqual ( 3084 , pnt . srid ) NEW_LINE self . assertRaises ( ctypes . ArgumentError , pnt . set_srid , '4326' ) NEW_LINE # ▁ Testing ▁ SRID ▁ keyword ▁ on ▁ fromstr ( ) , ▁ and ▁ on ▁ Polygon ▁ rings . ENDCOM poly = fromstr ( self . geometries . polygons [ 1 ] . wkt , srid = 4269 ) NEW_LINE self . assertEqual ( 4269 , poly . srid ) NEW_LINE for ring in poly : self . assertEqual ( 4269 , ring . srid ) NEW_LINE poly . srid = 4326 NEW_LINE self . assertEqual ( 4326 , poly . shell . srid ) NEW_LINE # ▁ Testing ▁ SRID ▁ keyword ▁ on ▁ GeometryCollection ENDCOM gc = GeometryCollection ( Point ( 5 , 23 ) , LineString ( ( 0 , 0 ) , ( 1.5 , 1.5 ) , ( 3 , 3 ) ) , srid = 32021 ) NEW_LINE self . assertEqual ( 32021 , gc . srid ) NEW_LINE for i in range ( len ( gc ) ) : self . assertEqual ( 32021 , gc [ i ] . srid ) NEW_LINE # ▁ GEOS ▁ may ▁ get ▁ the ▁ SRID ▁ from ▁ HEXEWKB ENDCOM # ▁ ' POINT ( 5 ▁ 23 ) ' ▁ at ▁ SRID = 4326 ▁ in ▁ hex ▁ form ▁ - - ▁ obtained ▁ from ▁ PostGIS ENDCOM # ▁ using ▁ ` SELECT ▁ GeomFromText ( ' POINT ▁ ( 5 ▁ 23 ) ' , ▁ 4326 ) ; ` . ENDCOM hex = '0101000020E610000000000000000014400000000000003740' NEW_LINE p1 = fromstr ( hex ) NEW_LINE self . assertEqual ( 4326 , p1 . srid ) NEW_LINE # ▁ In ▁ GEOS ▁ 3.0.0rc1-4 ▁ when ▁ the ▁ EWKB ▁ and / or ▁ HEXEWKB ▁ is ▁ exported , ENDCOM # ▁ the ▁ SRID ▁ information ▁ is ▁ lost ▁ and ▁ set ▁ to ▁ - 1 ▁ - - ▁ this ▁ is ▁ not ▁ a ENDCOM # ▁ problem ▁ on ▁ the ▁ 3.0.0 ▁ version ▁ ( another ▁ reason ▁ to ▁ upgrade ) . ENDCOM exp_srid = self . null_srid NEW_LINE p2 = fromstr ( p1 . hex ) NEW_LINE self . assertEqual ( exp_srid , p2 . srid ) NEW_LINE p3 = fromstr ( p1 . hex , srid = - 1 ) # ▁ - 1 ▁ is ▁ intended . ENDCOM NEW_LINE self . assertEqual ( - 1 , p3 . srid ) NEW_LINE DEDENT def test16_mutable_geometries ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ mutability ▁ of ▁ Polygons ▁ and ▁ Geometry ▁ Collections . " NEW_LINE # # # ▁ Testing ▁ the ▁ mutability ▁ of ▁ Polygons ▁ # # # ENDCOM for p in self . geometries . polygons : NEW_LINE INDENT poly = fromstr ( p . wkt ) NEW_LINE # ▁ Should ▁ only ▁ be ▁ able ▁ to ▁ use ▁ _ _ setitem _ _ ▁ with ▁ LinearRing ▁ geometries . ENDCOM self . assertRaises ( TypeError , poly . __setitem__ , 0 , LineString ( ( 1 , 1 ) , ( 2 , 2 ) ) ) NEW_LINE # ▁ Constructing ▁ the ▁ new ▁ shell ▁ by ▁ adding ▁ 500 ▁ to ▁ every ▁ point ▁ in ▁ the ▁ old ▁ shell . ENDCOM shell_tup = poly . shell . tuple NEW_LINE new_coords = [ ] NEW_LINE for point in shell_tup : new_coords . append ( ( point [ 0 ] + 500. , point [ 1 ] + 500. ) ) NEW_LINE new_shell = LinearRing ( * tuple ( new_coords ) ) NEW_LINE # ▁ Assigning ▁ polygon ' s ▁ exterior ▁ ring ▁ w / the ▁ new ▁ shell ENDCOM poly . exterior_ring = new_shell NEW_LINE s = str ( new_shell ) # ▁ new ▁ shell ▁ is ▁ still ▁ accessible ENDCOM NEW_LINE self . assertEqual ( poly . exterior_ring , new_shell ) NEW_LINE self . assertEqual ( poly [ 0 ] , new_shell ) NEW_LINE # # # ▁ Testing ▁ the ▁ mutability ▁ of ▁ Geometry ▁ Collections ENDCOM DEDENT for tg in self . geometries . multipoints : NEW_LINE INDENT mp = fromstr ( tg . wkt ) NEW_LINE for i in range ( len ( mp ) ) : NEW_LINE # ▁ Creating ▁ a ▁ random ▁ point . ENDCOM INDENT pnt = mp [ i ] NEW_LINE new = Point ( random . randint ( 1 , 100 ) , random . randint ( 1 , 100 ) ) NEW_LINE # ▁ Testing ▁ the ▁ assignment ENDCOM mp [ i ] = new NEW_LINE s = str ( new ) # ▁ what ▁ was ▁ used ▁ for ▁ the ▁ assignment ▁ is ▁ still ▁ accessible ENDCOM NEW_LINE self . assertEqual ( mp [ i ] , new ) NEW_LINE self . assertEqual ( mp [ i ] . wkt , new . wkt ) NEW_LINE self . assertNotEqual ( pnt , mp [ i ] ) NEW_LINE # ▁ MultiPolygons ▁ involve ▁ much ▁ more ▁ memory ▁ management ▁ because ▁ each ENDCOM # ▁ Polygon ▁ w / in ▁ the ▁ collection ▁ has ▁ its ▁ own ▁ rings . ENDCOM DEDENT DEDENT for tg in self . geometries . multipolygons : NEW_LINE INDENT mpoly = fromstr ( tg . wkt ) NEW_LINE for i in xrange ( len ( mpoly ) ) : NEW_LINE INDENT poly = mpoly [ i ] NEW_LINE old_poly = mpoly [ i ] NEW_LINE # ▁ Offsetting ▁ the ▁ each ▁ ring ▁ in ▁ the ▁ polygon ▁ by ▁ 500 . ENDCOM for j in xrange ( len ( poly ) ) : NEW_LINE INDENT r = poly [ j ] NEW_LINE for k in xrange ( len ( r ) ) : r [ k ] = ( r [ k ] [ 0 ] + 500. , r [ k ] [ 1 ] + 500. ) NEW_LINE poly [ j ] = r NEW_LINE DEDENT self . assertNotEqual ( mpoly [ i ] , poly ) NEW_LINE # ▁ Testing ▁ the ▁ assignment ENDCOM mpoly [ i ] = poly NEW_LINE s = str ( poly ) # ▁ Still ▁ accessible ENDCOM NEW_LINE self . assertEqual ( mpoly [ i ] , poly ) NEW_LINE self . assertNotEqual ( mpoly [ i ] , old_poly ) NEW_LINE # ▁ Extreme ▁ ( ! ! ) ▁ _ _ setitem _ _ ▁ - - ▁ no ▁ longer ▁ works , ▁ have ▁ to ▁ detect ENDCOM # ▁ in ▁ the ▁ first ▁ object ▁ that ▁ _ _ setitem _ _ ▁ is ▁ called ▁ in ▁ the ▁ subsequent ENDCOM # ▁ objects ▁ - - ▁ maybe ▁ mpoly [ 0 , ▁ 0 , ▁ 0 ] ▁ = ▁ ( 3.14 , ▁ 2.71 ) ? ENDCOM # mpoly [ 0 ] [ 0 ] [ 0 ] ▁ = ▁ ( 3.14 , ▁ 2.71 ) ENDCOM # self . assertEqual ( (3.14 , ▁ 2.71 ) , ▁ mpoly [ 0 ] [ 0 ] [ 0 ] ) ENDCOM # ▁ Doing ▁ it ▁ more ▁ slowly . . ENDCOM # self . assertEqual ( (3.14 , ▁ 2.71 ) , ▁ mpoly [ 0 ] . shell [ 0 ] ) ENDCOM # del ▁ mpoly ENDCOM DEDENT DEDENT DEDENT def test17_threed ( self ) : NEW_LINE INDENT " Testing ▁ three - dimensional ▁ geometries . " NEW_LINE # ▁ Testing ▁ a ▁ 3D ▁ Point ENDCOM pnt = Point ( 2 , 3 , 8 ) NEW_LINE self . assertEqual ( ( 2. , 3. , 8. ) , pnt . coords ) NEW_LINE self . assertRaises ( TypeError , pnt . set_coords , ( 1. , 2. ) ) NEW_LINE pnt . coords = ( 1. , 2. , 3. ) NEW_LINE self . assertEqual ( ( 1. , 2. , 3. ) , pnt . coords ) NEW_LINE # ▁ Testing ▁ a ▁ 3D ▁ LineString ENDCOM ls = LineString ( ( 2. , 3. , 8. ) , ( 50. , 250. , - 117. ) ) NEW_LINE self . assertEqual ( ( ( 2. , 3. , 8. ) , ( 50. , 250. , - 117. ) ) , ls . tuple ) NEW_LINE self . assertRaises ( TypeError , ls . __setitem__ , 0 , ( 1. , 2. ) ) NEW_LINE ls [ 0 ] = ( 1. , 2. , 3. ) NEW_LINE self . assertEqual ( ( 1. , 2. , 3. ) , ls [ 0 ] ) NEW_LINE DEDENT def test18_distance ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ distance ( ) ▁ function . " NEW_LINE # ▁ Distance ▁ to ▁ self ▁ should ▁ be ▁ 0 . ENDCOM pnt = Point ( 0 , 0 ) NEW_LINE self . assertEqual ( 0.0 , pnt . distance ( Point ( 0 , 0 ) ) ) NEW_LINE # ▁ Distance ▁ should ▁ be ▁ 1 ENDCOM self . assertEqual ( 1.0 , pnt . distance ( Point ( 0 , 1 ) ) ) NEW_LINE # ▁ Distance ▁ should ▁ be ▁ ~ ▁ sqrt ( 2 ) ENDCOM self . assertAlmostEqual ( 1.41421356237 , pnt . distance ( Point ( 1 , 1 ) ) , 11 ) NEW_LINE # ▁ Distances ▁ are ▁ from ▁ the ▁ closest ▁ vertex ▁ in ▁ each ▁ geometry ▁ - - ENDCOM # ▁ should ▁ be ▁ 3 ▁ ( distance ▁ from ▁ ( 2 , ▁ 2 ) ▁ to ▁ ( 5 , ▁ 2 ) ) . ENDCOM ls1 = LineString ( ( 0 , 0 ) , ( 1 , 1 ) , ( 2 , 2 ) ) NEW_LINE ls2 = LineString ( ( 5 , 2 ) , ( 6 , 1 ) , ( 7 , 0 ) ) NEW_LINE self . assertEqual ( 3 , ls1 . distance ( ls2 ) ) NEW_LINE DEDENT def test19_length ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ length ▁ property . " NEW_LINE # ▁ Points ▁ have ▁ 0 ▁ length . ENDCOM pnt = Point ( 0 , 0 ) NEW_LINE self . assertEqual ( 0.0 , pnt . length ) NEW_LINE # ▁ Should ▁ be ▁ ~ ▁ sqrt ( 2 ) ENDCOM ls = LineString ( ( 0 , 0 ) , ( 1 , 1 ) ) NEW_LINE self . assertAlmostEqual ( 1.41421356237 , ls . length , 11 ) NEW_LINE # ▁ Should ▁ be ▁ circumfrence ▁ of ▁ Polygon ENDCOM poly = Polygon ( LinearRing ( ( 0 , 0 ) , ( 0 , 1 ) , ( 1 , 1 ) , ( 1 , 0 ) , ( 0 , 0 ) ) ) NEW_LINE self . assertEqual ( 4.0 , poly . length ) NEW_LINE # ▁ Should ▁ be ▁ sum ▁ of ▁ each ▁ element ' s ▁ length ▁ in ▁ collection . ENDCOM mpoly = MultiPolygon ( poly . clone ( ) , poly ) NEW_LINE self . assertEqual ( 8.0 , mpoly . length ) NEW_LINE DEDENT def test20a_emptyCollections ( self ) : NEW_LINE INDENT " Testing ▁ empty ▁ geometries ▁ and ▁ collections . " NEW_LINE gc1 = GeometryCollection ( [ ] ) NEW_LINE gc2 = fromstr ( ' GEOMETRYCOLLECTION ▁ EMPTY ' ) NEW_LINE pnt = fromstr ( ' POINT ▁ EMPTY ' ) NEW_LINE ls = fromstr ( ' LINESTRING ▁ EMPTY ' ) NEW_LINE poly = fromstr ( ' POLYGON ▁ EMPTY ' ) NEW_LINE mls = fromstr ( ' MULTILINESTRING ▁ EMPTY ' ) NEW_LINE mpoly1 = fromstr ( ' MULTIPOLYGON ▁ EMPTY ' ) NEW_LINE mpoly2 = MultiPolygon ( ( ) ) NEW_LINE for g in [ gc1 , gc2 , pnt , ls , poly , mls , mpoly1 , mpoly2 ] : NEW_LINE INDENT self . assertEqual ( True , g . empty ) NEW_LINE # ▁ Testing ▁ len ( ) ▁ and ▁ num _ geom . ENDCOM if isinstance ( g , Polygon ) : NEW_LINE INDENT self . assertEqual ( 1 , len ( g ) ) # ▁ Has ▁ one ▁ empty ▁ linear ▁ ring ENDCOM NEW_LINE self . assertEqual ( 1 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g [ 0 ] ) ) NEW_LINE DEDENT elif isinstance ( g , ( Point , LineString ) ) : NEW_LINE INDENT self . assertEqual ( 1 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( 0 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g ) ) NEW_LINE # ▁ Testing ▁ _ _ getitem _ _ ▁ ( doesn ' t ▁ work ▁ on ▁ Point ▁ or ▁ Polygon ) ENDCOM DEDENT if isinstance ( g , Point ) : NEW_LINE INDENT self . assertRaises ( GEOSIndexError , g . get_x ) NEW_LINE DEDENT elif isinstance ( g , Polygon ) : NEW_LINE INDENT lr = g . shell NEW_LINE self . assertEqual ( ' LINEARRING ▁ EMPTY ' , lr . wkt ) NEW_LINE self . assertEqual ( 0 , len ( lr ) ) NEW_LINE self . assertEqual ( True , lr . empty ) NEW_LINE self . assertRaises ( GEOSIndexError , lr . __getitem__ , 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertRaises ( GEOSIndexError , g . __getitem__ , 0 ) NEW_LINE DEDENT DEDENT DEDENT def test20b_collections_of_collections ( self ) : NEW_LINE INDENT " Testing ▁ GeometryCollection ▁ handling ▁ of ▁ other ▁ collections . " NEW_LINE # ▁ Creating ▁ a ▁ GeometryCollection ▁ WKT ▁ string ▁ composed ▁ of ▁ other ENDCOM # ▁ collections ▁ and ▁ polygons . ENDCOM coll = [ mp . wkt for mp in self . geometries . multipolygons if mp . valid ] NEW_LINE coll . extend ( [ mls . wkt for mls in self . geometries . multilinestrings ] ) NEW_LINE coll . extend ( [ p . wkt for p in self . geometries . polygons ] ) NEW_LINE coll . extend ( [ mp . wkt for mp in self . geometries . multipoints ] ) NEW_LINE gc_wkt = ' GEOMETRYCOLLECTION ( % s ) ' % ' , ' . join ( coll ) NEW_LINE # ▁ Should ▁ construct ▁ ok ▁ from ▁ WKT ENDCOM gc1 = GEOSGeometry ( gc_wkt ) NEW_LINE # ▁ Should ▁ also ▁ construct ▁ ok ▁ from ▁ individual ▁ geometry ▁ arguments . ENDCOM gc2 = GeometryCollection ( * tuple ( g for g in gc1 ) ) NEW_LINE # ▁ And , ▁ they ▁ should ▁ be ▁ equal . ENDCOM self . assertEqual ( gc1 , gc2 ) NEW_LINE DEDENT def test21_test_gdal ( self ) : NEW_LINE INDENT " Testing ▁ ` ogr ` ▁ and ▁ ` srs ` ▁ properties . " NEW_LINE if not gdal . HAS_GDAL : return NEW_LINE g1 = fromstr ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE self . assertEqual ( True , isinstance ( g1 . ogr , gdal . OGRGeometry ) ) NEW_LINE self . assertEqual ( g1 . srs , None ) NEW_LINE g2 = fromstr ( ' LINESTRING ( 0 ▁ 0 , ▁ 5 ▁ 5 , ▁ 23 ▁ 23 ) ' , srid = 4326 ) NEW_LINE self . assertEqual ( True , isinstance ( g2 . ogr , gdal . OGRGeometry ) ) NEW_LINE self . assertEqual ( True , isinstance ( g2 . srs , gdal . SpatialReference ) ) NEW_LINE self . assertEqual ( g2 . hex , g2 . ogr . hex ) NEW_LINE self . assertEqual ( ' WGS ▁ 84' , g2 . srs . name ) NEW_LINE DEDENT def test22_copy ( self ) : NEW_LINE INDENT " Testing ▁ use ▁ with ▁ the ▁ Python ▁ ` copy ` ▁ module . " NEW_LINE import django . utils . copycompat as copy NEW_LINE poly = GEOSGeometry ( ' POLYGON ( (0 ▁ 0 , ▁ 0 ▁ 23 , ▁ 23 ▁ 23 , ▁ 23 ▁ 0 , ▁ 0 ▁ 0 ) , ▁ ( 5 ▁ 5 , ▁ 5 ▁ 10 , ▁ 10 ▁ 10 , ▁ 10 ▁ 5 , ▁ 5 ▁ 5 ) ) ' ) NEW_LINE cpy1 = copy . copy ( poly ) NEW_LINE cpy2 = copy . deepcopy ( poly ) NEW_LINE self . assertNotEqual ( poly . _ptr , cpy1 . _ptr ) NEW_LINE self . assertNotEqual ( poly . _ptr , cpy2 . _ptr ) NEW_LINE DEDENT def test23_transform ( self ) : NEW_LINE INDENT " Testing ▁ ` transform ` ▁ method . " NEW_LINE if not gdal . HAS_GDAL : return NEW_LINE orig = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE trans = GEOSGeometry ( ' POINT ▁ ( 992385.4472045 ▁ 481455.4944650 ) ' , 2774 ) NEW_LINE # ▁ Using ▁ a ▁ srid , ▁ a ▁ SpatialReference ▁ object , ▁ and ▁ a ▁ CoordTransform ▁ object ENDCOM # ▁ for ▁ transformations . ENDCOM t1 , t2 , t3 = orig . clone ( ) , orig . clone ( ) , orig . clone ( ) NEW_LINE t1 . transform ( trans . srid ) NEW_LINE t2 . transform ( gdal . SpatialReference ( ' EPSG : 2774' ) ) NEW_LINE ct = gdal . CoordTransform ( gdal . SpatialReference ( ' WGS84' ) , gdal . SpatialReference ( 2774 ) ) NEW_LINE t3 . transform ( ct ) NEW_LINE # ▁ Testing ▁ use ▁ of ▁ the ▁ ` clone ` ▁ keyword . ENDCOM k1 = orig . clone ( ) NEW_LINE k2 = k1 . transform ( trans . srid , clone = True ) NEW_LINE self . assertEqual ( k1 , orig ) NEW_LINE self . assertNotEqual ( k1 , k2 ) NEW_LINE prec = 3 NEW_LINE for p in ( t1 , t2 , t3 , k2 ) : NEW_LINE INDENT self . assertAlmostEqual ( trans . x , p . x , prec ) NEW_LINE self . assertAlmostEqual ( trans . y , p . y , prec ) NEW_LINE DEDENT DEDENT def test23_transform_noop ( self ) : NEW_LINE INDENT """ ▁ Testing ▁ ` transform ` ▁ method ▁ ( SRID ▁ match ) ▁ """ NEW_LINE # ▁ transform ( ) ▁ should ▁ no - op ▁ if ▁ source ▁ & ▁ dest ▁ SRIDs ▁ match , ENDCOM # ▁ regardless ▁ of ▁ whether ▁ GDAL ▁ is ▁ available . ENDCOM if gdal . HAS_GDAL : NEW_LINE INDENT g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE gt = g . tuple NEW_LINE g . transform ( 4326 ) NEW_LINE self . assertEqual ( g . tuple , gt ) NEW_LINE self . assertEqual ( g . srid , 4326 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE g1 = g . transform ( 4326 , clone = True ) NEW_LINE self . assertEqual ( g1 . tuple , g . tuple ) NEW_LINE self . assertEqual ( g1 . srid , 4326 ) NEW_LINE self . assert_ ( g1 is not g , " Clone ▁ didn ' t ▁ happen " ) NEW_LINE DEDENT old_has_gdal = gdal . HAS_GDAL NEW_LINE try : NEW_LINE INDENT gdal . HAS_GDAL = False NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE gt = g . tuple NEW_LINE g . transform ( 4326 ) NEW_LINE self . assertEqual ( g . tuple , gt ) NEW_LINE self . assertEqual ( g . srid , 4326 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE g1 = g . transform ( 4326 , clone = True ) NEW_LINE self . assertEqual ( g1 . tuple , g . tuple ) NEW_LINE self . assertEqual ( g1 . srid , 4326 ) NEW_LINE self . assert_ ( g1 is not g , " Clone ▁ didn ' t ▁ happen " ) NEW_LINE DEDENT finally : NEW_LINE INDENT gdal . HAS_GDAL = old_has_gdal NEW_LINE DEDENT DEDENT def test23_transform_nosrid ( self ) : NEW_LINE INDENT """ ▁ Testing ▁ ` transform ` ▁ method ▁ ( no ▁ SRID ) ▁ """ NEW_LINE # ▁ raise ▁ a ▁ warning ▁ if ▁ SRID ▁ < 0 / None ENDCOM import warnings NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ Warnings ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE # ▁ test ▁ for ▁ do - nothing ▁ behaviour . ENDCOM try : NEW_LINE # ▁ Keeping ▁ line - noise ▁ down ▁ by ▁ only ▁ printing ▁ the ▁ relevant ENDCOM # ▁ warnings ▁ once . ENDCOM INDENT warnings . simplefilter ( ' once ' , UserWarning ) NEW_LINE warnings . simplefilter ( ' once ' , FutureWarning ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE g . transform ( 2774 ) NEW_LINE self . assertEqual ( g . tuple , ( - 104.609 , 38.255 ) ) NEW_LINE self . assertEqual ( g . srid , None ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE g1 = g . transform ( 2774 , clone = True ) NEW_LINE self . assert_ ( g1 is None ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE g . transform ( 2774 ) NEW_LINE self . assertEqual ( g . tuple , ( - 104.609 , 38.255 ) ) NEW_LINE self . assertEqual ( g . srid , - 1 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE g1 = g . transform ( 2774 , clone = True ) NEW_LINE self . assert_ ( g1 is None ) NEW_LINE DEDENT finally : NEW_LINE INDENT warnings . simplefilter ( ' default ' , UserWarning ) NEW_LINE warnings . simplefilter ( ' default ' , FutureWarning ) NEW_LINE DEDENT print " \n END ▁ - ▁ expecting ▁ Warnings ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE # ▁ test ▁ warning ▁ is ▁ raised ENDCOM try : NEW_LINE INDENT warnings . simplefilter ( ' error ' , FutureWarning ) NEW_LINE warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 , clone = True ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 , clone = True ) NEW_LINE DEDENT finally : NEW_LINE INDENT warnings . simplefilter ( ' default ' , FutureWarning ) NEW_LINE warnings . simplefilter ( ' default ' , UserWarning ) NEW_LINE DEDENT DEDENT def test23_transform_nogdal ( self ) : NEW_LINE INDENT """ ▁ Testing ▁ ` transform ` ▁ method ▁ ( GDAL ▁ not ▁ available ) ▁ """ NEW_LINE old_has_gdal = gdal . HAS_GDAL NEW_LINE try : NEW_LINE INDENT gdal . HAS_GDAL = False NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE self . assertRaises ( GEOSException , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE self . assertRaises ( GEOSException , g . transform , 2774 , clone = True ) NEW_LINE DEDENT finally : NEW_LINE INDENT gdal . HAS_GDAL = old_has_gdal NEW_LINE DEDENT DEDENT def test24_extent ( self ) : NEW_LINE INDENT " Testing ▁ ` extent ` ▁ method . " NEW_LINE # ▁ The ▁ xmin , ▁ ymin , ▁ xmax , ▁ ymax ▁ of ▁ the ▁ MultiPoint ▁ should ▁ be ▁ returned . ENDCOM mp = MultiPoint ( Point ( 5 , 23 ) , Point ( 0 , 0 ) , Point ( 10 , 50 ) ) NEW_LINE self . assertEqual ( ( 0.0 , 0.0 , 10.0 , 50.0 ) , mp . extent ) NEW_LINE pnt = Point ( 5.23 , 17.8 ) NEW_LINE # ▁ Extent ▁ of ▁ points ▁ is ▁ just ▁ the ▁ point ▁ itself ▁ repeated . ENDCOM self . assertEqual ( ( 5.23 , 17.8 , 5.23 , 17.8 ) , pnt . extent ) NEW_LINE # ▁ Testing ▁ on ▁ the ▁ ' real ▁ world ' ▁ Polygon . ENDCOM poly = fromstr ( self . geometries . polygons [ 3 ] . wkt ) NEW_LINE ring = poly . shell NEW_LINE x , y = ring . x , ring . y NEW_LINE xmin , ymin = min ( x ) , min ( y ) NEW_LINE xmax , ymax = max ( x ) , max ( y ) NEW_LINE self . assertEqual ( ( xmin , ymin , xmax , ymax ) , poly . extent ) NEW_LINE DEDENT def test25_pickle ( self ) : NEW_LINE INDENT " Testing ▁ pickling ▁ and ▁ unpickling ▁ support . " NEW_LINE # ▁ Using ▁ both ▁ pickle ▁ and ▁ cPickle ▁ - - ▁ just ▁ ' cause . ENDCOM import pickle , cPickle NEW_LINE # ▁ Creating ▁ a ▁ list ▁ of ▁ test ▁ geometries ▁ for ▁ pickling , ENDCOM # ▁ and ▁ setting ▁ the ▁ SRID ▁ on ▁ some ▁ of ▁ them . ENDCOM def get_geoms ( lst , srid = None ) : NEW_LINE INDENT return [ GEOSGeometry ( tg . wkt , srid ) for tg in lst ] NEW_LINE DEDENT tgeoms = get_geoms ( self . geometries . points ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . multilinestrings , 4326 ) ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . polygons , 3084 ) ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . multipolygons , 900913 ) ) NEW_LINE # ▁ The ▁ SRID ▁ won ' t ▁ be ▁ exported ▁ in ▁ GEOS ▁ 3.0 ▁ release ▁ candidates . ENDCOM no_srid = self . null_srid == - 1 NEW_LINE for geom in tgeoms : NEW_LINE INDENT s1 , s2 = cPickle . dumps ( geom ) , pickle . dumps ( geom ) NEW_LINE g1 , g2 = cPickle . loads ( s1 ) , pickle . loads ( s2 ) NEW_LINE for tmpg in ( g1 , g2 ) : NEW_LINE INDENT self . assertEqual ( geom , tmpg ) NEW_LINE if not no_srid : self . assertEqual ( geom . srid , tmpg . srid ) NEW_LINE DEDENT DEDENT DEDENT def test26_prepared ( self ) : NEW_LINE INDENT " Testing ▁ PreparedGeometry ▁ support . " NEW_LINE if not GEOS_PREPARE : return NEW_LINE # ▁ Creating ▁ a ▁ simple ▁ multipolygon ▁ and ▁ getting ▁ a ▁ prepared ▁ version . ENDCOM mpoly = GEOSGeometry ( ' MULTIPOLYGON ( ( ( 0 ▁ 0,0 ▁ 5,5 ▁ 5,5 ▁ 0,0 ▁ 0 ) ) , ( (5 ▁ 5,5 ▁ 10,10 ▁ 10,10 ▁ 5,5 ▁ 5 ) ) ) ' ) NEW_LINE prep = mpoly . prepared NEW_LINE # ▁ A ▁ set ▁ of ▁ test ▁ points . ENDCOM pnts = [ Point ( 5 , 5 ) , Point ( 7.5 , 7.5 ) , Point ( 2.5 , 7.5 ) ] NEW_LINE covers = [ True , True , False ] # ▁ No ▁ ` covers ` ▁ op ▁ for ▁ regular ▁ GEOS ▁ geoms . ENDCOM NEW_LINE for pnt , c in zip ( pnts , covers ) : NEW_LINE # ▁ Results ▁ should ▁ be ▁ the ▁ same ▁ ( but ▁ faster ) ENDCOM INDENT self . assertEqual ( mpoly . contains ( pnt ) , prep . contains ( pnt ) ) NEW_LINE self . assertEqual ( mpoly . intersects ( pnt ) , prep . intersects ( pnt ) ) NEW_LINE self . assertEqual ( c , prep . covers ( pnt ) ) NEW_LINE DEDENT DEDENT def test26_line_merge ( self ) : NEW_LINE INDENT " Testing ▁ line ▁ merge ▁ support " NEW_LINE ref_geoms = ( fromstr ( ' LINESTRING ( 1 ▁ 1 , ▁ 1 ▁ 1 , ▁ 3 ▁ 3 ) ' ) , fromstr ( ' MULTILINESTRING ( (1 ▁ 1 , ▁ 3 ▁ 3 ) , ▁ ( 3 ▁ 3 , ▁ 4 ▁ 2 ) ) ' ) , ) NEW_LINE ref_merged = ( fromstr ( ' LINESTRING ( 1 ▁ 1 , ▁ 3 ▁ 3 ) ' ) , fromstr ( ' LINESTRING ▁ ( 1 ▁ 1 , ▁ 3 ▁ 3 , ▁ 4 ▁ 2 ) ' ) , ) NEW_LINE for geom , merged in zip ( ref_geoms , ref_merged ) : NEW_LINE INDENT self . assertEqual ( merged , geom . merged ) NEW_LINE DEDENT DEDENT def test27_valid_reason ( self ) : NEW_LINE INDENT " Testing ▁ IsValidReason ▁ support " NEW_LINE # ▁ Skipping ▁ tests ▁ if ▁ GEOS ▁ < ▁ v3.1 . ENDCOM if not GEOS_PREPARE : return NEW_LINE g = GEOSGeometry ( " POINT ( 0 ▁ 0 ) " ) NEW_LINE self . assert_ ( g . valid ) NEW_LINE self . assert_ ( isinstance ( g . valid_reason , basestring ) ) NEW_LINE self . assertEqual ( g . valid_reason , " Valid ▁ Geometry " ) NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE g = GEOSGeometry ( " LINESTRING ( 0 ▁ 0 , ▁ 0 ▁ 0 ) " ) NEW_LINE self . assert_ ( not g . valid ) NEW_LINE self . assert_ ( isinstance ( g . valid_reason , basestring ) ) NEW_LINE self . assert_ ( g . valid_reason . startswith ( " Too ▁ few ▁ points ▁ in ▁ geometry ▁ component " ) ) NEW_LINE print " \n END ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE DEDENT DEDENT def suite ( ) : NEW_LINE INDENT s = unittest . TestSuite ( ) NEW_LINE s . addTest ( unittest . makeSuite ( GEOSTest ) ) NEW_LINE return s NEW_LINE DEDENT def run ( verbosity = 2 ) : NEW_LINE INDENT unittest . TextTestRunner ( verbosity = verbosity ) . run ( suite ( ) ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="dvliman/jaikuengine/tree/master/.google_appengine/lib/django-1.5/django/contrib/comments/views/moderation.py"> from __future__ import absolute_import NEW_LINE from django import template NEW_LINE from django . conf import settings NEW_LINE from django . contrib import comments NEW_LINE from django . contrib . auth . decorators import login_required , permission_required NEW_LINE from django . contrib . comments import signals NEW_LINE from django . contrib . comments . views . utils import next_redirect , confirmation_view NEW_LINE from django . shortcuts import get_object_or_404 , render_to_response NEW_LINE from django . views . decorators . csrf import csrf_protect NEW_LINE @ csrf_protect NEW_LINE @ login_required NEW_LINE def flag ( request , comment_id , next = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Flags ▁ a ▁ comment . ▁ Confirmation ▁ on ▁ GET , ▁ action ▁ on ▁ POST . STRNEWLINE STRNEWLINE ▁ Templates : ▁ : template : ` comments / flag . html ` , STRNEWLINE ▁ Context : STRNEWLINE ▁ comment STRNEWLINE ▁ the ▁ flagged ▁ ` comments . comment ` ▁ object STRNEWLINE ▁ """ NEW_LINE comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE # ▁ Flag ▁ on ▁ POST ENDCOM if request . method == ' POST ' : NEW_LINE INDENT perform_flag ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - flag - done ' , c = comment . pk ) NEW_LINE # ▁ Render ▁ a ▁ form ▁ on ▁ GET ENDCOM DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / flag . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT @ csrf_protect NEW_LINE @ permission_required ( " comments . can _ moderate " ) NEW_LINE def delete ( request , comment_id , next = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Deletes ▁ a ▁ comment . ▁ Confirmation ▁ on ▁ GET , ▁ action ▁ on ▁ POST . ▁ Requires ▁ the ▁ " can STRNEWLINE ▁ moderate ▁ comments " ▁ permission . STRNEWLINE STRNEWLINE ▁ Templates : ▁ : template : ` comments / delete . html ` , STRNEWLINE ▁ Context : STRNEWLINE ▁ comment STRNEWLINE ▁ the ▁ flagged ▁ ` comments . comment ` ▁ object STRNEWLINE ▁ """ NEW_LINE comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE # ▁ Delete ▁ on ▁ POST ENDCOM if request . method == ' POST ' : NEW_LINE # ▁ Flag ▁ the ▁ comment ▁ as ▁ deleted ▁ instead ▁ of ▁ actually ▁ deleting ▁ it . ENDCOM INDENT perform_delete ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - delete - done ' , c = comment . pk ) NEW_LINE # ▁ Render ▁ a ▁ form ▁ on ▁ GET ENDCOM DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / delete . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT @ csrf_protect NEW_LINE @ permission_required ( " comments . can _ moderate " ) NEW_LINE def approve ( request , comment_id , next = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Approve ▁ a ▁ comment ▁ ( that ▁ is , ▁ mark ▁ it ▁ as ▁ public ▁ and ▁ non - removed ) . ▁ Confirmation STRNEWLINE ▁ on ▁ GET , ▁ action ▁ on ▁ POST . ▁ Requires ▁ the ▁ " can ▁ moderate ▁ comments " ▁ permission . STRNEWLINE STRNEWLINE ▁ Templates : ▁ : template : ` comments / approve . html ` , STRNEWLINE ▁ Context : STRNEWLINE ▁ comment STRNEWLINE ▁ the ▁ ` comments . comment ` ▁ object ▁ for ▁ approval STRNEWLINE ▁ """ NEW_LINE comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE # ▁ Delete ▁ on ▁ POST ENDCOM if request . method == ' POST ' : NEW_LINE # ▁ Flag ▁ the ▁ comment ▁ as ▁ approved . ENDCOM INDENT perform_approve ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - approve - done ' , c = comment . pk ) NEW_LINE # ▁ Render ▁ a ▁ form ▁ on ▁ GET ENDCOM DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / approve . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE # ▁ The ▁ following ▁ functions ▁ actually ▁ perform ▁ the ▁ various ▁ flag / aprove / delete ENDCOM # ▁ actions . ▁ They ' ve ▁ been ▁ broken ▁ out ▁ into ▁ separate ▁ functions ▁ to ▁ that ▁ they ENDCOM # ▁ may ▁ be ▁ called ▁ from ▁ admin ▁ actions . ENDCOM DEDENT DEDENT def perform_flag ( request , comment ) : NEW_LINE INDENT """ STRNEWLINE ▁ Actually ▁ perform ▁ the ▁ flagging ▁ of ▁ a ▁ comment ▁ from ▁ a ▁ request . STRNEWLINE ▁ """ NEW_LINE flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . SUGGEST_REMOVAL ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT def perform_delete ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . MODERATOR_DELETION ) NEW_LINE comment . is_removed = True NEW_LINE comment . save ( ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT def perform_approve ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . MODERATOR_APPROVAL , ) NEW_LINE comment . is_removed = False NEW_LINE comment . is_public = True NEW_LINE comment . save ( ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE # ▁ Confirmation ▁ views . ENDCOM DEDENT flag_done = confirmation_view ( template = " comments / flagged . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ flagged " ▁ success ▁ page . ' ) NEW_LINE delete_done = confirmation_view ( template = " comments / deleted . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ deleted " ▁ success ▁ page . ' ) NEW_LINE approve_done = confirmation_view ( template = " comments / approved . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ approved " ▁ success ▁ page . ' ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="tacaswell/datamuxer/tree/master/datamuxer.py"> # ▁ Copyright ▁ ( c ) ▁ 2014 , ▁ Brookhaven ▁ Science ▁ Associates , ▁ Brookhaven ▁ # ENDCOM # ▁ National ▁ Laboratory . ▁ All ▁ rights ▁ reserved . ▁ # ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ▁ # ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ # ENDCOM # ▁ are ▁ met : ▁ # ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ▁ # ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ▁ # ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ▁ copyright ▁ # ENDCOM # ▁ notice ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ▁ in ▁ # ENDCOM # ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ▁ # ENDCOM # ▁ distribution . ▁ # ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ the ▁ Brookhaven ▁ Science ▁ Associates , ▁ Brookhaven ▁ # ENDCOM # ▁ National ▁ Laboratory ▁ nor ▁ the ▁ names ▁ of ▁ its ▁ contributors ▁ may ▁ be ▁ used ▁ # ENDCOM # ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ▁ this ▁ software ▁ without ▁ # ENDCOM # ▁ specific ▁ prior ▁ written ▁ permission . ▁ # ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ▁ # ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ▁ # ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ # ENDCOM # ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ # ENDCOM # ▁ COPYRIGHT ▁ HOLDER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ # ENDCOM # ▁ INDIRECT , ▁ INCIDENTAL , ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ # ENDCOM # ▁ ( INCLUDING , ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ # ENDCOM # ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ # ENDCOM # ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ # ENDCOM # ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OTHERWISE ) ▁ ARISING ▁ # ENDCOM # ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ▁ # ENDCOM # ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ▁ # ENDCOM from __future__ import ( absolute_import , division , print_function , unicode_literals ) NEW_LINE import six NEW_LINE from collections import namedtuple , deque NEW_LINE import logging NEW_LINE import pandas as pd NEW_LINE import tzlocal NEW_LINE import numpy as np NEW_LINE from scipy . interpolate import interp1d NEW_LINE import pandas . core . groupby # ▁ to ▁ get ▁ custom ▁ exception ENDCOM NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE __all__ = [ ' DataMuxer ' , ' dataframe _ to _ dict ' ] NEW_LINE TZ = str ( tzlocal . get_localzone ( ) ) NEW_LINE class BinningError ( Exception ) : NEW_LINE INDENT """ STRNEWLINE ▁ An ▁ exception ▁ to ▁ raise ▁ if ▁ there ▁ are ▁ insufficient ▁ sampling ▁ rules ▁ to STRNEWLINE ▁ upsampling ▁ or ▁ downsample ▁ a ▁ data ▁ column ▁ into ▁ specified ▁ bins . STRNEWLINE ▁ """ NEW_LINE pass NEW_LINE DEDENT class BadDownsamplerError ( Exception ) : NEW_LINE INDENT """ STRNEWLINE ▁ An ▁ exception ▁ to ▁ raise ▁ if ▁ a ▁ downsampler ▁ produces ▁ unexpected ▁ output . STRNEWLINE ▁ """ NEW_LINE pass NEW_LINE DEDENT class ColSpec ( namedtuple ( ' ColSpec ' , [ ' name ' , ' ndim ' , ' shape ' , ' upsample ' , ' downsample ' ] ) ) : NEW_LINE INDENT """ STRNEWLINE ▁ Named - tuple ▁ sub - class ▁ to ▁ validate ▁ the ▁ column ▁ specifications ▁ for ▁ the STRNEWLINE ▁ DataMuxer STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ name ▁ : ▁ hashable STRNEWLINE ▁ ndim ▁ : ▁ uint STRNEWLINE ▁ Dimensionality ▁ of ▁ the ▁ data ▁ stored ▁ in ▁ the ▁ column STRNEWLINE ▁ shape ▁ : ▁ tuple ▁ or ▁ None STRNEWLINE ▁ like ▁ ndarray . shape , ▁ where ▁ 0 ▁ or ▁ None ▁ are ▁ scalar STRNEWLINE ▁ upsample ▁ : ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , ▁ ' cubic ' , ▁ ' ffill ' , ▁ ' bfill ' } STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ The ▁ names ▁ refer ▁ to ▁ kinds ▁ of ▁ scipy . interpolator . ▁ See ▁ documentation STRNEWLINE ▁ link ▁ below . STRNEWLINE ▁ downsample ▁ : ▁ None ▁ or ▁ a ▁ function STRNEWLINE ▁ None ▁ if ▁ the ▁ data ▁ cannot ▁ be ▁ downsampled ▁ ( reduced ) . ▁ Otherwise , STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE # ▁ These ▁ reflect ▁ the ▁ ' method ' ▁ argument ▁ of ▁ pandas . DataFrame . fillna ENDCOM upsampling_methods = { ' None ' , ' linear ' , ' nearest ' , ' zero ' , ' slinear ' , ' quadratic ' , ' cubic ' , ' ffill ' , ' bfill ' } NEW_LINE downsampling_methods = { ' None ' , ' last ' , ' first ' , ' median ' , ' mean ' , ' sum ' , ' min ' , ' max ' } NEW_LINE _downsample_mapping = { ' last ' : lambda x : x [ - 1 ] , ' first ' : lambda x : x [ 0 ] , # ▁ new ▁ in ▁ np ▁ 1.9 ENDCOM ' median ' : lambda x : np . median ( x , 0 ) , ' mean ' : lambda x : np . mean ( x , 0 ) , ' sum ' : lambda x : np . sum ( x , 0 ) , ' min ' : lambda x : np . min ( x , 0 ) , ' max ' : lambda x : np . max ( x , 0 ) } NEW_LINE __slots__ = ( ) NEW_LINE def __new__ ( cls , name , ndim , shape , upsample , downsample ) : NEW_LINE # ▁ Validations ENDCOM INDENT upsample = _validate_upsample ( upsample ) NEW_LINE downsample = _validate_downsample ( downsample ) NEW_LINE if int ( ndim ) < 0 : NEW_LINE INDENT raise ValueError ( " ndim ▁ must ▁ be ▁ positive ▁ not ▁ { } " . format ( ndim ) ) NEW_LINE DEDENT if shape is not None : NEW_LINE INDENT shape = tuple ( shape ) NEW_LINE DEDENT return super ( ColSpec , cls ) . __new__ ( cls , name , int ( ndim ) , shape , upsample , downsample ) NEW_LINE DEDENT DEDENT def _validate_upsample ( input ) : NEW_LINE # ▁ TODO ▁ The ▁ upsampling ▁ method ▁ could ▁ be ▁ any ▁ callable . ENDCOM INDENT if input is None or input == ' None ' : NEW_LINE INDENT return ' None ' NEW_LINE DEDENT if not ( input in ColSpec . upsampling_methods ) : NEW_LINE INDENT raise ValueError ( " { } ▁ is ▁ not ▁ a ▁ valid ▁ upsampling ▁ method . ▁ It ▁ " " must ▁ be ▁ one ▁ of ▁ { } " . format ( input , ColSpec . upsampling_methods ) ) NEW_LINE DEDENT return input . lower ( ) NEW_LINE DEDENT def _validate_downsample ( input ) : NEW_LINE # ▁ TODO ▁ The ▁ downsampling ▁ methods ▁ could ▁ have ▁ string ▁ aliases ▁ like ▁ ' mean ' . ENDCOM INDENT if ( input is not None ) and ( not ( callable ( input ) or input in ColSpec . downsampling_methods ) ) : NEW_LINE INDENT raise ValueError ( " The ▁ downsampling ▁ method ▁ must ▁ be ▁ a ▁ callable , ▁ None , ▁ " " or ▁ one ▁ of ▁ { } . " . format ( ColSpec . downsampling_methods ) ) NEW_LINE DEDENT if input is None : NEW_LINE INDENT return ' None ' NEW_LINE DEDENT return input NEW_LINE DEDENT class DataMuxer ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ class ▁ provides ▁ a ▁ wrapper ▁ layer ▁ of ▁ signals ▁ and ▁ slots STRNEWLINE ▁ around ▁ a ▁ pandas ▁ DataFrame ▁ to ▁ make ▁ plugging ▁ stuff ▁ in ▁ for ▁ live STRNEWLINE ▁ view ▁ easier . STRNEWLINE STRNEWLINE ▁ The ▁ data ▁ collection / event ▁ model ▁ being ▁ used ▁ is ▁ all ▁ measurements STRNEWLINE ▁ ( that ▁ is ▁ values ▁ that ▁ come ▁ off ▁ of ▁ the ▁ hardware ) ▁ are ▁ time ▁ stamped STRNEWLINE ▁ to ▁ ring ▁ time . STRNEWLINE STRNEWLINE ▁ The ▁ language ▁ being ▁ used ▁ through ▁ out ▁ is ▁ that ▁ of ▁ pandas ▁ data ▁ frames . STRNEWLINE STRNEWLINE ▁ The ▁ data ▁ model ▁ is ▁ that ▁ of ▁ a ▁ sparse ▁ table ▁ keyed ▁ on ▁ time ▁ stamps ▁ which STRNEWLINE ▁ is ▁ ' densified ' ▁ on ▁ demand ▁ by ▁ propagating ▁ measurements ▁ forwards . ▁ Not STRNEWLINE ▁ all ▁ measurements ▁ ( ex ▁ images ) ▁ can ▁ be ▁ filled . ▁ This ▁ behavior ▁ is ▁ controlled STRNEWLINE ▁ by ▁ the ▁ ` col _ info ` ▁ tuple . STRNEWLINE STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ object ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE class Planner ( object ) : NEW_LINE INDENT def __init__ ( self , dm ) : NEW_LINE INDENT self . dm = dm NEW_LINE DEDENT def determine_upsample ( self , interpolation = None , use_cols = None ) : NEW_LINE INDENT " Resolve ▁ ( and ▁ if ▁ necessary ▁ validate ) ▁ upsampling ▁ rules . " NEW_LINE if interpolation is None : NEW_LINE INDENT interpolation = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_upsample ( interpolation . get ( name , col_info . upsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE if ( rule is not None ) and ( col_info . ndim > 0 ) : NEW_LINE INDENT raise NotImplementedError ( " Only ▁ scalar ▁ data ▁ can ▁ be ▁ upsampled . ▁ " " The ▁ { 0 } - dimensional ▁ source ▁ { 1 } ▁ was ▁ given ▁ the ▁ " " upsampling ▁ rule ▁ { 2 } . " . format ( col_info . ndim , name , rule ) ) NEW_LINE DEDENT rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT def determine_downsample ( self , agg = None , use_cols = None ) : NEW_LINE INDENT " Resolve ▁ ( and ▁ if ▁ necessary ▁ validate ) ▁ sampling ▁ rules . " NEW_LINE if agg is None : NEW_LINE INDENT agg = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_downsample ( agg . get ( name , col_info . downsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ Explain ▁ operation ▁ of ▁ DataMuxer . bin _ by _ edges STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ edges ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ two - element ▁ items ▁ like ▁ [ ( t1 , ▁ t2 ) , ▁ ( t3 , ▁ t4 ) , ▁ . . . ] STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be STRNEWLINE ▁ evaluated . ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' , ▁ ' ffill ' , ▁ ' bfill ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever STRNEWLINE ▁ dimension ) ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by STRNEWLINE ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ table ▁ giving ▁ upsample ▁ and ▁ downsample ▁ rules ▁ for ▁ each ▁ data ▁ column STRNEWLINE ▁ and ▁ indicating ▁ whether ▁ those ▁ rules ▁ are ▁ applicable STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE # ▁ TODO ▁ Cache ▁ the ▁ grouping ▁ for ▁ reuse ▁ by ▁ resample . ENDCOM grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ Explain ▁ operation ▁ of ▁ DataMuxer . bin _ on . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever STRNEWLINE ▁ dimension ) ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by STRNEWLINE ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ table ▁ giving ▁ upsample ▁ and ▁ downsample ▁ rules ▁ for ▁ each ▁ data ▁ column STRNEWLINE ▁ and ▁ indicating ▁ whether ▁ those ▁ rules ▁ are ▁ applicable STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE centers , bin_edges = self . dm . _bin_on ( source_name ) NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( centers , bin_edges ) NEW_LINE # ▁ TODO ▁ Cache ▁ the ▁ grouping ▁ for ▁ reuse ▁ by ▁ resample . ENDCOM grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT DEDENT default_upsample = None NEW_LINE default_downsample = None NEW_LINE def __init__ ( self ) : NEW_LINE INDENT self . sources = { } NEW_LINE self . col_info = { } NEW_LINE self . col_info [ ' time ' ] = ColSpec ( ' time ' , 0 , [ ] , ' linear ' , ' mean ' ) NEW_LINE self . _data = deque ( ) NEW_LINE self . _time = deque ( ) NEW_LINE self . _timestamps = deque ( ) NEW_LINE self . _timestamps_as_data = set ( ) NEW_LINE self . _known_events = set ( ) NEW_LINE self . _known_descriptors = set ( ) NEW_LINE self . _stale = True NEW_LINE self . plan = self . Planner ( self ) NEW_LINE self . convert_times = True NEW_LINE self . _reference_time = None NEW_LINE DEDENT @ property NEW_LINE def reference_time ( self ) : NEW_LINE INDENT return self . _reference_time NEW_LINE DEDENT @ reference_time . setter NEW_LINE def reference_time ( self , val ) : NEW_LINE INDENT self . _reference_time = pd . Timestamp ( val , unit = ' s ' ) NEW_LINE DEDENT @ property NEW_LINE def columns ( self ) : NEW_LINE INDENT " The ▁ columns ▁ of ▁ DataFrames ▁ returned ▁ by ▁ methods ▁ that ▁ return ▁ DataFrames . " NEW_LINE return set ( self . sources ) | self . _time_columns NEW_LINE DEDENT @ property NEW_LINE def _time_columns ( self ) : NEW_LINE INDENT ts_names = [ name + ' _ timestamp ' for name in self . _timestamps_as_data ] NEW_LINE return { ' time ' } | set ( ts_names ) NEW_LINE DEDENT @ classmethod NEW_LINE def from_events ( cls , events , verbose = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ a ▁ DataMuxer ▁ from ▁ a ▁ list ▁ of ▁ Events . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ objects ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE instance = cls ( ) NEW_LINE instance . append_events ( events , verbose ) NEW_LINE return instance NEW_LINE DEDENT def append_events ( self , events , verbose = False ) : NEW_LINE INDENT """ Add ▁ a ▁ list ▁ of ▁ events ▁ to ▁ the ▁ DataMuxer . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ objects ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE for idx , event in enumerate ( events ) : NEW_LINE INDENT if verbose and idx % 25 == 0 : NEW_LINE INDENT print ( ' loading ▁ event ▁ % s ' % idx ) , NEW_LINE DEDENT self . append_event ( event ) NEW_LINE DEDENT DEDENT def append_event ( self , event ) : NEW_LINE INDENT """ Add ▁ an ▁ event ▁ to ▁ the ▁ DataMuxer . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ event ▁ : ▁ Event STRNEWLINE ▁ Event ▁ Document ▁ or ▁ any ▁ object ▁ with ▁ the ▁ expected ▁ attributes STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ is _ new ▁ : ▁ bool STRNEWLINE ▁ True ▁ if ▁ event ▁ was ▁ added , ▁ False ▁ is ▁ it ▁ has ▁ already ▁ been ▁ added STRNEWLINE ▁ """ NEW_LINE if event . uid in self . _known_events : NEW_LINE INDENT return False NEW_LINE DEDENT self . _known_events . add ( event . uid ) NEW_LINE self . _stale = True NEW_LINE if event . descriptor . uid not in self . _known_descriptors : NEW_LINE INDENT self . _process_new_descriptor ( event . descriptor ) NEW_LINE # ▁ Both ▁ scalar ▁ and ▁ nonscalar ▁ data ▁ will ▁ get ▁ stored ▁ in ▁ the ▁ DataFrame . ENDCOM # ▁ This ▁ may ▁ be ▁ optimized ▁ later , ▁ but ▁ it ▁ might ▁ not ▁ actually ▁ help ▁ much . ENDCOM DEDENT self . _data . append ( { name : data for name , data in six . iteritems ( event . data ) } ) NEW_LINE self . _timestamps . append ( { name : ts for name , ts in six . iteritems ( event . timestamps ) } ) NEW_LINE self . _time . append ( event . time ) NEW_LINE return True NEW_LINE DEDENT def _process_new_descriptor ( self , descriptor ) : NEW_LINE INDENT " Build ▁ a ▁ ColSpec ▁ and ▁ update ▁ state . " NEW_LINE for name , description in six . iteritems ( descriptor . data_keys ) : NEW_LINE # ▁ If ▁ we ▁ already ▁ have ▁ this ▁ source ▁ name , ▁ the ▁ unique ▁ source ENDCOM # ▁ identifiers ▁ must ▁ match . ▁ Ambiguous ▁ names ▁ are ▁ not ▁ allowed . ENDCOM INDENT if name in self . sources : NEW_LINE INDENT if self . sources [ name ] != description [ ' source ' ] : NEW_LINE INDENT raise ValueError ( " In ▁ a ▁ previously ▁ loaded ▁ descriptor , ▁ " " ' {0 } ' ▁ refers ▁ to ▁ { 1 } ▁ but ▁ in ▁ Event ▁ " " Descriptor ▁ { 2 } ▁ it ▁ refers ▁ to ▁ { 3 } . " . format ( name , self . sources [ name ] , descriptor . uid , description [ ' source ' ] ) ) NEW_LINE DEDENT if name == ' time ' : NEW_LINE # ▁ We ▁ can ▁ argue ▁ later ▁ about ▁ how ▁ best ▁ to ▁ handle ▁ this ▁ corner ENDCOM # ▁ case , ▁ but ▁ anything ▁ is ▁ better ▁ than ▁ silently ▁ mislabeling ENDCOM # ▁ data . ENDCOM INDENT raise ValueError ( " The ▁ name ▁ ' time ' ▁ is ▁ reserved ▁ and ▁ cannot ▁ " " be ▁ used ▁ as ▁ an ▁ alias . " ) NEW_LINE # ▁ If ▁ it ▁ is ▁ a ▁ new ▁ name , ▁ determine ▁ a ▁ ColSpec . ENDCOM DEDENT DEDENT else : NEW_LINE INDENT self . sources [ name ] = description [ ' source ' ] NEW_LINE if ' external ' in description and ' shape ' in description : NEW_LINE INDENT shape = description [ ' shape ' ] NEW_LINE ndim = len ( shape ) NEW_LINE DEDENT else : NEW_LINE # ▁ External ▁ data ▁ can ▁ be ▁ scalar . ▁ Nonscalar ▁ data ▁ must ENDCOM # ▁ have ▁ a ▁ specified ▁ shape . ▁ Thus , ▁ if ▁ no ▁ shape ▁ is ▁ given , ENDCOM # ▁ assume ▁ scalar . ENDCOM INDENT shape = None NEW_LINE ndim = 0 NEW_LINE DEDENT upsample = self . default_upsample NEW_LINE if ndim > 0 : NEW_LINE INDENT upsample = None NEW_LINE DEDENT col_info = ColSpec ( name , ndim , shape , upsample , self . default_downsample ) # ▁ defaults ENDCOM NEW_LINE # ▁ TODO ▁ Look ▁ up ▁ source - specific ▁ default ▁ in ▁ a ▁ config ▁ file ENDCOM # ▁ or ▁ some ▁ other ▁ source ▁ of ▁ reference ▁ data . ENDCOM self . col_info [ name ] = col_info NEW_LINE DEDENT DEDENT self . _known_descriptors . add ( descriptor . uid ) NEW_LINE DEDENT @ property NEW_LINE def _dataframe ( self ) : NEW_LINE INDENT " See ▁ also ▁ to _ sparse _ dataframe , ▁ the ▁ public ▁ version ▁ of ▁ this . " NEW_LINE # ▁ Rebuild ▁ the ▁ DataFrame ▁ if ▁ more ▁ data ▁ has ▁ been ▁ added . ENDCOM if self . _stale : NEW_LINE INDENT df = pd . DataFrame ( list ( self . _data ) ) NEW_LINE df [ ' time ' ] = list ( self . _time ) NEW_LINE if self . _timestamps_as_data : NEW_LINE # ▁ Only ▁ build ▁ this ▁ if ▁ we ▁ need ▁ it . ENDCOM # ▁ TODO : ▁ We ▁ shouldn ' t ▁ have ▁ to ▁ build ENDCOM # ▁ the ▁ whole ▁ thing , ▁ but ▁ there ▁ is ▁ already ▁ a ▁ lot ▁ of ▁ trickiness ENDCOM # ▁ here ▁ so ▁ we ' ll ▁ worry ▁ about ▁ optimization ▁ later . ENDCOM INDENT timestamps = pd . DataFrame ( list ( self . _timestamps ) ) NEW_LINE DEDENT for source_name in self . _timestamps_as_data : NEW_LINE INDENT col_name = _timestamp_col_name ( source_name ) NEW_LINE df [ col_name ] = timestamps [ source_name ] NEW_LINE logger . debug ( " Including ▁ % s ▁ timestamps ▁ as ▁ data " , source_name ) NEW_LINE DEDENT self . _df = df . sort ( ' time ' ) . reset_index ( drop = True ) NEW_LINE self . _stale = False NEW_LINE DEDENT return self . _df NEW_LINE DEDENT def to_sparse_dataframe ( self , include_all_timestamps = False ) : NEW_LINE INDENT """ Obtain ▁ all ▁ measurements ▁ in ▁ a ▁ DataFrame , ▁ one ▁ row ▁ per ▁ Event ▁ time . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ include _ all _ timestamps ▁ : ▁ bool STRNEWLINE ▁ The ▁ result ▁ will ▁ always ▁ contain ▁ a ▁ ' time ' ▁ column ▁ but , ▁ by ▁ default , STRNEWLINE ▁ not ▁ timestamps ▁ for ▁ individual ▁ data ▁ sources ▁ like ▁ ' motor _ timestamp ' . STRNEWLINE ▁ Set ▁ this ▁ to ▁ True ▁ to ▁ export ▁ timestamp ▁ columns ▁ for ▁ each ▁ data ▁ column STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ """ NEW_LINE if include_all_timestamps : NEW_LINE INDENT raise NotImplementedError ( " TODO " ) NEW_LINE DEDENT result = self . _dataframe . copy ( ) NEW_LINE for col_name in self . _time_columns : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT return result NEW_LINE DEDENT def _maybe_convert_times ( self , data ) : NEW_LINE INDENT if self . convert_times : NEW_LINE INDENT t = pd . to_datetime ( data , unit = ' s ' , utc = True ) . dt . tz_localize ( TZ ) NEW_LINE if self . reference_time is None : NEW_LINE INDENT return t NEW_LINE DEDENT else : NEW_LINE INDENT return t - self . reference_time NEW_LINE DEDENT DEDENT return data # ▁ no - op ENDCOM NEW_LINE DEDENT def include_timestamp_data ( self , source_name ) : NEW_LINE INDENT """ Add ▁ the ▁ exact ▁ timing ▁ of ▁ a ▁ data ▁ source ▁ as ▁ a ▁ data ▁ column . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ one ▁ of ▁ the ▁ source ▁ names ▁ in ▁ DataMuxer . sources STRNEWLINE ▁ """ NEW_LINE # ▁ self . _ timestamps _ as _ data ▁ is ▁ a ▁ set ▁ of ▁ sources ▁ who ▁ timestamps ENDCOM # ▁ should ▁ be ▁ treated ▁ as ▁ data ▁ in ▁ the ▁ _ dataframe ▁ method ▁ above . ENDCOM self . _timestamps_as_data . add ( source_name ) NEW_LINE name = _timestamp_col_name ( source_name ) NEW_LINE self . col_info [ name ] = ColSpec ( name , 0 , None , None , np . mean ) NEW_LINE self . _stale = True NEW_LINE DEDENT def remove_timestamp_data ( self , source_name ) : NEW_LINE INDENT """ Remove ▁ the ▁ exact ▁ timing ▁ of ▁ a ▁ data ▁ source ▁ from ▁ the ▁ data ▁ columns . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ one ▁ of ▁ the ▁ source ▁ names ▁ in ▁ DataMuxer . sources STRNEWLINE ▁ """ NEW_LINE self . _timestamps_as_data . remove ( source_name ) NEW_LINE # ▁ Do ▁ not ▁ force ▁ a ▁ rebuilt ▁ ( i . e . , ▁ self . _ stale ) . ▁ Just ▁ remove ▁ it ▁ here . ENDCOM del self . _df [ _timestamp_col_name ( source_name ) ] NEW_LINE DEDENT def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ to ▁ align ▁ with ▁ the ▁ data ▁ from ▁ a ▁ particular ▁ source . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE centers , bin_edges = self . _bin_on ( source_name ) NEW_LINE return self . bin_by_edges ( bin_edges , bin_anchors = centers , interpolation = interpolation , agg = agg , use_cols = use_cols ) NEW_LINE DEDENT def _bin_on ( self , source_name ) : NEW_LINE INDENT " Compute ▁ bin ▁ edges ▁ spaced ▁ around ▁ centers ▁ defined ▁ by ▁ source _ name ▁ points . " NEW_LINE col = self . _dataframe [ source_name ] NEW_LINE centers = self . _dataframe [ ' time ' ] . reindex_like ( col . dropna ( ) ) . values NEW_LINE # ▁ [ 2 , ▁ 4 , ▁ 6 ] ▁ - > ▁ [ - inf , ▁ 3 , ▁ 5 , ▁ inf ] ENDCOM bin_edges = np . mean ( [ centers [ 1 : ] , centers [ : - 1 ] ] , 0 ) NEW_LINE # ▁ [ - inf , ▁ 3 , ▁ 5 , ▁ inf ] ▁ - > ▁ [ ( - inf , ▁ 3 ) , ▁ ( 3 , ▁ 5 ) , ▁ ( 5 , ▁ inf ) ] ENDCOM bin_edges = [ - np . inf ] + list ( np . repeat ( bin_edges , 2 ) ) + [ np . inf ] NEW_LINE bin_edges = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE return centers , bin_edges NEW_LINE DEDENT def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ into ▁ bins ▁ with ▁ the ▁ specified ▁ edges . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ edges ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ two - element ▁ items ▁ like ▁ [ ( t1 , ▁ t2 ) , ▁ ( t3 , ▁ t4 ) , ▁ . . . ] STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be ▁ evaluated . STRNEWLINE ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE bin_anchors , binning = self . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE return self . resample ( bin_anchors , binning , interpolation , agg , use_cols = use_cols ) NEW_LINE DEDENT def _bin_by_edges ( self , bin_anchors , bin_edges ) : NEW_LINE INDENT " Compute ▁ bin ▁ assignment ▁ and , ▁ if ▁ needed , ▁ bin _ anchors . " NEW_LINE time = self . _dataframe [ ' time ' ] . values NEW_LINE # ▁ Get ▁ edges ▁ into ▁ 1D ▁ array [ L , ▁ R , ▁ L , ▁ R , ▁ . . . ] ENDCOM edges_as_pairs = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE all_edges = np . ravel ( edges_as_pairs ) NEW_LINE if not np . all ( np . diff ( all_edges ) >= 0 ) : NEW_LINE INDENT raise ValueError ( " Illegal ▁ binning : ▁ the ▁ left ▁ edge ▁ must ▁ be ▁ less ▁ " " than ▁ the ▁ right ▁ edge . " ) NEW_LINE # ▁ Sort ▁ out ▁ where ▁ the ▁ array ▁ each ▁ time ▁ would ▁ be ▁ inserted . ENDCOM DEDENT binning = np . searchsorted ( all_edges , time ) . astype ( float ) NEW_LINE # ▁ Times ▁ that ▁ would ▁ get ▁ inserted ▁ at ▁ even ▁ positions ▁ are ▁ between ▁ bins . ENDCOM # ▁ Mark ▁ them ENDCOM binning [ binning % 2 == 0 ] = np . nan NEW_LINE binning //= 2 # ▁ Make ▁ bin ▁ number ▁ sequential , ▁ not ▁ odds ▁ only . ENDCOM NEW_LINE if bin_anchors is None : NEW_LINE INDENT bin_anchors = np . mean ( edges_as_pairs , axis = 1 ) # ▁ bin ▁ centers ENDCOM NEW_LINE DEDENT else : NEW_LINE INDENT if len ( bin_anchors ) != len ( bin_edges ) : NEW_LINE INDENT raise ValueError ( " There ▁ are ▁ { 0 } ▁ bin _ anchors ▁ but ▁ { 1 } ▁ pairs ▁ of ▁ " " bin _ edges . ▁ These ▁ must ▁ match . " . format ( len ( bin_anchors ) , len ( bin_edges ) ) ) NEW_LINE DEDENT DEDENT return bin_anchors , binning NEW_LINE DEDENT def resample ( self , bin_anchors , binning , interpolation = None , agg = None , verify_integrity = True , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ into ▁ bins ▁ with ▁ the ▁ specified ▁ edges . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be ▁ evaluated . STRNEWLINE ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ Bin ▁ assignment . ▁ Example : ▁ [ 1 , ▁ 1 , ▁ 2 , ▁ 2 , ▁ 3 , ▁ 3 ] ▁ puts ▁ six ▁ data ▁ points STRNEWLINE ▁ into ▁ three ▁ bins ▁ with ▁ two ▁ points ▁ each . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ verify _ integrity ▁ : ▁ bool , ▁ optional STRNEWLINE ▁ For ▁ a ▁ cost ▁ in ▁ performance , ▁ verify ▁ that ▁ the ▁ downsampling ▁ function STRNEWLINE ▁ produces ▁ data ▁ of ▁ the ▁ expected ▁ shape . ▁ True ▁ by ▁ default . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE if use_cols is None : NEW_LINE INDENT use_cols = self . columns NEW_LINE DEDENT plan = self . Planner ( self ) NEW_LINE upsampling_rules = plan . determine_upsample ( interpolation , use_cols ) NEW_LINE downsampling_rules = plan . determine_downsample ( agg , use_cols ) NEW_LINE grouped = self . _dataframe . groupby ( binning ) NEW_LINE first_point = grouped . first ( ) NEW_LINE counts = grouped . count ( ) NEW_LINE resampling_requirements = _is_resampling_applicable ( counts ) NEW_LINE index = np . arange ( len ( bin_anchors ) ) NEW_LINE result = { } # ▁ dict ▁ of ▁ DataFrames , ▁ to ▁ become ▁ one ▁ MultiIndexed ▁ DataFrame ENDCOM NEW_LINE for name in use_cols : NEW_LINE INDENT upsample = upsampling_rules [ name ] NEW_LINE downsample = downsampling_rules [ name ] NEW_LINE upsampling_possible = resampling_requirements [ ' upsampling _ possible ' ] [ name ] NEW_LINE downsampling_needed = resampling_requirements [ ' downsampling _ needed ' ] [ name ] NEW_LINE result [ name ] = pd . DataFrame ( index = index ) NEW_LINE # ▁ Put ▁ the ▁ first ▁ ( maybe ▁ only ) ▁ value ▁ into ▁ a ▁ Series . ENDCOM # ▁ We ▁ will ▁ overwrite ▁ as ▁ needed ▁ below . ENDCOM result [ name ] [ ' val ' ] = pd . Series ( data = first_point [ name ] ) NEW_LINE # ▁ Short - circuit ▁ if ▁ we ▁ are ▁ done . ENDCOM if not ( upsampling_possible or downsampling_needed ) : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ exactly ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE DEDENT result [ name ] [ ' count ' ] = counts [ name ] NEW_LINE # ▁ If ▁ any ▁ bin ▁ has ▁ no ▁ data , ▁ use ▁ the ▁ upsampling ▁ rule ▁ to ▁ interpolate ENDCOM # ▁ at ▁ the ▁ center ▁ of ▁ the ▁ empty ▁ bins . ▁ If ▁ there ▁ is ▁ no ▁ rule , ▁ simply ENDCOM # ▁ leave ▁ some ▁ bins ▁ empty . ▁ Do ▁ not ▁ raise ▁ an ▁ error . ENDCOM if upsampling_possible and ( upsample is not None ) : NEW_LINE INDENT if upsample in ( ' ffill ' , ' bfill ' ) : NEW_LINE INDENT result [ name ] [ ' val ' ] . fillna ( method = upsample , inplace = True ) NEW_LINE DEDENT else : NEW_LINE INDENT dense_col = self . _dataframe [ name ] . dropna ( ) NEW_LINE y = dense_col . values NEW_LINE x = self . _dataframe [ ' time ' ] . reindex_like ( dense_col ) . values NEW_LINE interpolator = interp1d ( x , y , kind = upsample ) NEW_LINE # ▁ Outside ▁ the ▁ limits ▁ of ▁ the ▁ data , ▁ the ▁ interpolator ▁ will ENDCOM # ▁ fail . ▁ Leave ▁ any ▁ such ▁ entires ▁ empty . ENDCOM is_safe = ( ( bin_anchors > np . min ( x ) ) & ( bin_anchors < np . max ( x ) ) ) NEW_LINE safe_times = bin_anchors [ is_safe ] NEW_LINE safe_bins = index [ is_safe ] NEW_LINE interp_points = pd . Series ( interpolator ( safe_times ) , index = safe_bins ) NEW_LINE logger . debug ( " Interpolating ▁ to ▁ fill ▁ % d ▁ of ▁ % d ▁ " " empty ▁ bins ▁ in ▁ % s " , len ( safe_bins ) , ( counts [ name ] == 0 ) . sum ( ) , name ) NEW_LINE result [ name ] [ ' val ' ] . fillna ( interp_points , inplace = True ) NEW_LINE # ▁ Short - circuit ▁ if ▁ we ▁ are ▁ done . ENDCOM DEDENT DEDENT if not downsampling_needed : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ at ▁ most ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE # ▁ Multi - valued ▁ bins ▁ must ▁ be ▁ downsampled ▁ ( reduced ) . ▁ If ▁ there ▁ is ▁ no ENDCOM # ▁ rule ▁ for ▁ downsampling , ▁ we ▁ have ▁ no ▁ recourse : ▁ we ▁ must ▁ raise . ENDCOM DEDENT if ( downsample is None ) : NEW_LINE INDENT raise BinningError ( " The ▁ specified ▁ binning ▁ puts ▁ multiple ▁ " " ' {0 } ' ▁ measurements ▁ in ▁ at ▁ least ▁ one ▁ bin , ▁ " " and ▁ there ▁ is ▁ no ▁ rule ▁ for ▁ downsampling ▁ " " ( i . e . , ▁ reducing ) ▁ it . " . format ( name ) ) NEW_LINE DEDENT if verify_integrity and callable ( downsample ) : NEW_LINE INDENT downsample = _build_verified_downsample ( downsample , self . col_info [ name ] . shape ) NEW_LINE DEDENT g = grouped [ name ] # ▁ for ▁ brevity ENDCOM NEW_LINE if self . col_info [ name ] . ndim == 0 : NEW_LINE INDENT logger . debug ( " The ▁ scalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE # ▁ For ▁ scalars , ▁ pandas ▁ knows ▁ what ▁ to ▁ do . ENDCOM downsampled = g . agg ( downsample ) NEW_LINE std_series = g . std ( ) NEW_LINE max_series = g . max ( ) NEW_LINE min_series = g . min ( ) NEW_LINE DEDENT else : NEW_LINE # ▁ For ▁ nonscalars , ▁ we ▁ are ▁ abusing ▁ groupby ▁ and ▁ must ▁ go ▁ to ▁ a ENDCOM # ▁ a ▁ little ▁ more ▁ trouble ▁ to ▁ guarantee ▁ success . ENDCOM INDENT logger . debug ( " The ▁ nonscalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE if not callable ( downsample ) : NEW_LINE # ▁ Do ▁ this ▁ lookup ▁ here ▁ so ▁ that ▁ strings ▁ can ▁ be ▁ passed ENDCOM # ▁ in ▁ the ▁ call ▁ to ▁ resample . ENDCOM INDENT downsample = ColSpec . _downsample_mapping [ downsample ] NEW_LINE DEDENT downsampled = g . apply ( lambda x : downsample ( np . asarray ( x . dropna ( ) ) ) ) NEW_LINE std_series = g . apply ( lambda x : np . std ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE max_series = g . apply ( lambda x : np . max ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE min_series = g . apply ( lambda x : np . min ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE # ▁ This ▁ ( counts [ name ] ▁ > ▁ 1 ) ▁ is ▁ redundant , ▁ but ▁ there ▁ is ▁ no ▁ clean ▁ way ▁ to ENDCOM # ▁ pass ▁ it ▁ here ▁ without ▁ refactoring . ▁ Not ▁ a ▁ huge ▁ cost . ENDCOM DEDENT result [ name ] [ ' val ' ] . where ( ~ ( counts [ name ] > 1 ) , downsampled , inplace = True ) NEW_LINE result [ name ] [ ' std ' ] = std_series NEW_LINE result [ name ] [ ' max ' ] = max_series NEW_LINE result [ name ] [ ' min ' ] = min_series NEW_LINE DEDENT result = pd . concat ( result , axis = 1 ) # ▁ one ▁ MultiIndexed ▁ DataFrame ENDCOM NEW_LINE result . index . name = ' bin ' NEW_LINE # ▁ Convert ▁ time ▁ timestamp ▁ or ▁ timedelta , ▁ depending ▁ on ▁ the ▁ state ▁ of ENDCOM # ▁ self . convert _ times ▁ and ▁ self . reference _ time . ENDCOM for col_name in self . _time_columns : NEW_LINE INDENT if isinstance ( result [ col_name ] , pd . DataFrame ) : NEW_LINE INDENT subcols = result [ col_name ] . columns NEW_LINE for subcol in subcols & { ' max ' , ' min ' , ' val ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = self . _maybe_convert_times ( result [ ( col_name , subcol ) ] ) NEW_LINE DEDENT for subcol in subcols & { ' std ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = pd . to_timedelta ( result [ ( col_name , subcol ) ] , unit = ' s ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT def __getitem__ ( self , source_name ) : NEW_LINE INDENT if source_name not in list ( self . col_info . keys ( ) ) + [ ' time ' ] : NEW_LINE INDENT raise KeyError ( " No ▁ data ▁ from ▁ a ▁ source ▁ called ▁ ' {0 } ' ▁ has ▁ been ▁ " " added . " . format ( source_name ) ) NEW_LINE # ▁ Unlike ▁ output ▁ from ▁ binning ▁ functions , ▁ this ▁ is ▁ indexed ENDCOM # ▁ on ▁ time . ENDCOM DEDENT result = self . _dataframe [ source_name ] . dropna ( ) NEW_LINE result . index = self . _dataframe [ ' time ' ] . reindex_like ( result ) NEW_LINE return result NEW_LINE DEDENT def __getattr__ ( self , attr ) : NEW_LINE # ▁ Developer ▁ beware : ▁ if ▁ any ▁ properties ▁ raise ▁ an ▁ AttributeError , ENDCOM # ▁ this ▁ will ▁ mask ▁ it . ▁ Comment ▁ this ▁ magic ▁ method ▁ to ▁ debug ▁ properties . ENDCOM INDENT if attr in self . col_info . keys ( ) : NEW_LINE INDENT return self [ attr ] NEW_LINE DEDENT else : NEW_LINE INDENT raise AttributeError ( " DataMuxer ▁ has ▁ no ▁ attribute ▁ { 0 } ▁ and ▁ no ▁ " " data ▁ source ▁ named ▁ ' {0 } ' " . format ( attr ) ) NEW_LINE DEDENT DEDENT @ property NEW_LINE def ncols ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ number ▁ of ▁ columns ▁ that ▁ the ▁ DataMuxer ▁ contains STRNEWLINE ▁ """ NEW_LINE return len ( self . col_info ) NEW_LINE DEDENT @ property NEW_LINE def col_info_by_ndim ( self ) : NEW_LINE INDENT """ Dictionary ▁ mapping ▁ dimensionality ▁ ( ndim ) ▁ onto ▁ a ▁ list ▁ of ▁ ColSpecs """ NEW_LINE result = { } NEW_LINE for name , col_spec in six . iteritems ( self . col_info ) : NEW_LINE INDENT try : NEW_LINE INDENT result [ col_spec . ndim ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT result [ col_spec . ndim ] = [ ] NEW_LINE DEDENT result [ col_spec . ndim ] . append ( col_spec ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def dataframe_to_dict ( df ) : NEW_LINE INDENT """ STRNEWLINE ▁ Turn ▁ a ▁ DataFrame ▁ into ▁ a ▁ dict ▁ of ▁ lists . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ DataFrame STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ index ▁ : ▁ ndarray STRNEWLINE ▁ The ▁ index ▁ of ▁ the ▁ data ▁ frame STRNEWLINE ▁ data ▁ : ▁ dict STRNEWLINE ▁ Dictionary ▁ keyed ▁ on ▁ column ▁ name ▁ of ▁ the ▁ column . ▁ The ▁ value ▁ is STRNEWLINE ▁ one ▁ of ▁ ( ndarray , ▁ list , ▁ pd . Series ) STRNEWLINE ▁ """ NEW_LINE dict_of_lists = { col : df [ col ] . to_list ( ) for col in df . columns } NEW_LINE return df . index . values , dict_of_lists NEW_LINE DEDENT def _build_verified_downsample ( downsample , expected_shape ) : NEW_LINE # ▁ Ensure ▁ two ▁ things : ENDCOM # ▁ 1 . ▁ The ▁ downsampling ▁ function ▁ shouldn ' t ▁ touch ▁ bins ▁ with ▁ only ▁ one ▁ point . ENDCOM # ▁ 2 . ▁ The ▁ result ▁ of ▁ downsample ▁ should ▁ have ▁ the ▁ right ▁ shape . ENDCOM INDENT def _downsample ( data ) : NEW_LINE INDENT if len ( data ) == 1 : NEW_LINE INDENT return data NEW_LINE DEDENT downsampled = downsample ( data ) NEW_LINE if ( expected_shape is None or expected_shape == 0 ) : NEW_LINE INDENT if not np . isscalar ( downsampled ) : NEW_LINE INDENT raise BadDownsamplerError ( " The ▁ ' agg ' ▁ ( downsampling ) ▁ function ▁ " " for ▁ { 0 } ▁ is ▁ expected ▁ to ▁ produce ▁ " " a ▁ scalar ▁ from ▁ the ▁ data ▁ in ▁ each ▁ " " bin . " . format ( downsampled ) ) NEW_LINE DEDENT DEDENT elif downsampled . shape != expected_shape : NEW_LINE INDENT raise BadDownsamplerError ( " An ▁ ' agg ' ▁ ( downsampling ) ▁ function ▁ " " returns ▁ data ▁ shaped ▁ { 0 } ▁ but ▁ the ▁ " " shape ▁ { 1 } ▁ is ▁ expected . " . format ( downsampled . shape , expected_shape ) ) NEW_LINE DEDENT return downsampled NEW_LINE DEDENT return _downsample NEW_LINE DEDENT def _timestamp_col_name ( source_name ) : NEW_LINE INDENT return ' { 0 } _ timestamp ' . format ( source_name ) NEW_LINE DEDENT def _normalize_string_none ( val ) : NEW_LINE INDENT " Replay ▁ passes ▁ ' None ' ▁ to ▁ mean ▁ None . " NEW_LINE try : NEW_LINE INDENT lowercase_val = val . lower ( ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT return val NEW_LINE DEDENT if lowercase_val == ' none ' : NEW_LINE INDENT return None NEW_LINE DEDENT else : NEW_LINE INDENT return val NEW_LINE DEDENT DEDENT def _is_resampling_applicable ( counts ) : NEW_LINE INDENT has_no_points = counts == 0 NEW_LINE has_multiple_points = counts > 1 NEW_LINE upsampling_possible = has_no_points . any ( ) NEW_LINE downsampling_needed = has_multiple_points . any ( ) NEW_LINE result = { } NEW_LINE result [ ' upsampling _ possible ' ] = upsampling_possible . to_dict ( ) NEW_LINE result [ ' downsampling _ needed ' ] = downsampling_needed . to_dict ( ) NEW_LINE return result NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="fernandog/Medusa/tree/master/ext/click/termui.py"> import os NEW_LINE import sys NEW_LINE import struct NEW_LINE from . _compat import raw_input , text_type , string_types , isatty , strip_ansi , get_winterm_size , DEFAULT_COLUMNS , WIN NEW_LINE from . utils import echo NEW_LINE from . exceptions import Abort , UsageError NEW_LINE from . types import convert_type NEW_LINE from . globals import resolve_color_default NEW_LINE # ▁ The ▁ prompt ▁ functions ▁ to ▁ use . ▁ The ▁ doc ▁ tools ▁ currently ▁ override ▁ these ENDCOM # ▁ functions ▁ to ▁ customize ▁ how ▁ they ▁ work . ENDCOM visible_prompt_func = raw_input NEW_LINE _ansi_colors = ( ' black ' , ' red ' , ' green ' , ' yellow ' , ' blue ' , ' magenta ' , ' cyan ' , ' white ' , ' reset ' ) NEW_LINE _ansi_reset_all = ' \033[0m ' NEW_LINE def hidden_prompt_func ( prompt ) : NEW_LINE INDENT import getpass NEW_LINE return getpass . getpass ( prompt ) NEW_LINE DEDENT def _build_prompt ( text , suffix , show_default = False , default = None ) : NEW_LINE INDENT prompt = text NEW_LINE if default is not None and show_default : NEW_LINE INDENT prompt = ' % s ▁ [ % s ] ' % ( prompt , default ) NEW_LINE DEDENT return prompt + suffix NEW_LINE DEDENT def prompt ( text , default = None , hide_input = False , confirmation_prompt = False , type = None , value_proc = None , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT """ Prompts ▁ a ▁ user ▁ for ▁ input . ▁ This ▁ is ▁ a ▁ convenience ▁ function ▁ that ▁ can STRNEWLINE ▁ be ▁ used ▁ to ▁ prompt ▁ a ▁ user ▁ for ▁ input ▁ later . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ user ▁ aborts ▁ the ▁ input ▁ by ▁ sending ▁ a ▁ interrupt ▁ signal , ▁ this STRNEWLINE ▁ function ▁ will ▁ catch ▁ it ▁ and ▁ raise ▁ a ▁ : exc : ` Abort ` ▁ exception . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 6.0 STRNEWLINE ▁ Added ▁ unicode ▁ support ▁ for ▁ cmd . exe ▁ on ▁ Windows . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ show ▁ for ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ default : ▁ the ▁ default ▁ value ▁ to ▁ use ▁ if ▁ no ▁ input ▁ happens . ▁ If ▁ this STRNEWLINE ▁ is ▁ not ▁ given ▁ it ▁ will ▁ prompt ▁ until ▁ it ' s ▁ aborted . STRNEWLINE ▁ : param ▁ hide _ input : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ true ▁ then ▁ the ▁ input ▁ value ▁ will STRNEWLINE ▁ be ▁ hidden . STRNEWLINE ▁ : param ▁ confirmation _ prompt : ▁ asks ▁ for ▁ confirmation ▁ for ▁ the ▁ value . STRNEWLINE ▁ : param ▁ type : ▁ the ▁ type ▁ to ▁ use ▁ to ▁ check ▁ the ▁ value ▁ against . STRNEWLINE ▁ : param ▁ value _ proc : ▁ if ▁ this ▁ parameter ▁ is ▁ provided ▁ it ' s ▁ a ▁ function ▁ that STRNEWLINE ▁ is ▁ invoked ▁ instead ▁ of ▁ the ▁ type ▁ conversion ▁ to STRNEWLINE ▁ convert ▁ a ▁ value . STRNEWLINE ▁ : param ▁ prompt _ suffix : ▁ a ▁ suffix ▁ that ▁ should ▁ be ▁ added ▁ to ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ show _ default : ▁ shows ▁ or ▁ hides ▁ the ▁ default ▁ value ▁ in ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ true ▁ the ▁ file ▁ defaults ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE result = None NEW_LINE def prompt_func ( text ) : NEW_LINE INDENT f = hide_input and hidden_prompt_func or visible_prompt_func NEW_LINE try : NEW_LINE # ▁ Write ▁ the ▁ prompt ▁ separately ▁ so ▁ that ▁ we ▁ get ▁ nice ENDCOM # ▁ coloring ▁ through ▁ colorama ▁ on ▁ Windows ENDCOM INDENT echo ( text , nl = False , err = err ) NEW_LINE return f ( ' ' ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE # ▁ getpass ▁ doesn ' t ▁ print ▁ a ▁ newline ▁ if ▁ the ▁ user ▁ aborts ▁ input ▁ with ▁ ^ C . ENDCOM # ▁ Allegedly ▁ this ▁ behavior ▁ is ▁ inherited ▁ from ▁ getpass ( 3 ) . ENDCOM # ▁ A ▁ doc ▁ bug ▁ has ▁ been ▁ filed ▁ at ▁ https : / / bugs . python . org / issue24711 ENDCOM INDENT if hide_input : NEW_LINE INDENT echo ( None , err = err ) NEW_LINE DEDENT raise Abort ( ) NEW_LINE DEDENT DEDENT if value_proc is None : NEW_LINE INDENT value_proc = convert_type ( type , default ) NEW_LINE DEDENT prompt = _build_prompt ( text , prompt_suffix , show_default , default ) NEW_LINE while 1 : NEW_LINE INDENT while 1 : NEW_LINE INDENT value = prompt_func ( prompt ) NEW_LINE if value : NEW_LINE INDENT break NEW_LINE # ▁ If ▁ a ▁ default ▁ is ▁ set ▁ and ▁ used , ▁ then ▁ the ▁ confirmation ENDCOM # ▁ prompt ▁ is ▁ always ▁ skipped ▁ because ▁ that ' s ▁ the ▁ only ▁ thing ENDCOM # ▁ that ▁ really ▁ makes ▁ sense . ENDCOM DEDENT elif default is not None : NEW_LINE INDENT return default NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT result = value_proc ( value ) NEW_LINE DEDENT except UsageError as e : NEW_LINE INDENT echo ( ' Error : ▁ % s ' % e . message , err = err ) NEW_LINE continue NEW_LINE DEDENT if not confirmation_prompt : NEW_LINE INDENT return result NEW_LINE DEDENT while 1 : NEW_LINE INDENT value2 = prompt_func ( ' Repeat ▁ for ▁ confirmation : ▁ ' ) NEW_LINE if value2 : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT if value == value2 : NEW_LINE INDENT return result NEW_LINE DEDENT echo ( ' Error : ▁ the ▁ two ▁ entered ▁ values ▁ do ▁ not ▁ match ' , err = err ) NEW_LINE DEDENT DEDENT def confirm ( text , default = False , abort = False , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT """ Prompts ▁ for ▁ confirmation ▁ ( yes / no ▁ question ) . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ user ▁ aborts ▁ the ▁ input ▁ by ▁ sending ▁ a ▁ interrupt ▁ signal ▁ this STRNEWLINE ▁ function ▁ will ▁ catch ▁ it ▁ and ▁ raise ▁ a ▁ : exc : ` Abort ` ▁ exception . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ question ▁ to ▁ ask . STRNEWLINE ▁ : param ▁ default : ▁ the ▁ default ▁ for ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ abort : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ ` True ` ▁ a ▁ negative ▁ answer ▁ aborts ▁ the STRNEWLINE ▁ exception ▁ by ▁ raising ▁ : exc : ` Abort ` . STRNEWLINE ▁ : param ▁ prompt _ suffix : ▁ a ▁ suffix ▁ that ▁ should ▁ be ▁ added ▁ to ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ show _ default : ▁ shows ▁ or ▁ hides ▁ the ▁ default ▁ value ▁ in ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ true ▁ the ▁ file ▁ defaults ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE prompt = _build_prompt ( text , prompt_suffix , show_default , default and ' Y / n ' or ' y / N ' ) NEW_LINE while 1 : NEW_LINE INDENT try : NEW_LINE # ▁ Write ▁ the ▁ prompt ▁ separately ▁ so ▁ that ▁ we ▁ get ▁ nice ENDCOM # ▁ coloring ▁ through ▁ colorama ▁ on ▁ Windows ENDCOM INDENT echo ( prompt , nl = False , err = err ) NEW_LINE value = visible_prompt_func ( ' ' ) . lower ( ) . strip ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT if value in ( ' y ' , ' yes ' ) : NEW_LINE INDENT rv = True NEW_LINE DEDENT elif value in ( ' n ' , ' no ' ) : NEW_LINE INDENT rv = False NEW_LINE DEDENT elif value == ' ' : NEW_LINE INDENT rv = default NEW_LINE DEDENT else : NEW_LINE INDENT echo ( ' Error : ▁ invalid ▁ input ' , err = err ) NEW_LINE continue NEW_LINE DEDENT break NEW_LINE DEDENT if abort and not rv : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT return rv NEW_LINE DEDENT def get_terminal_size ( ) : NEW_LINE INDENT """ Returns ▁ the ▁ current ▁ size ▁ of ▁ the ▁ terminal ▁ as ▁ tuple ▁ in ▁ the ▁ form STRNEWLINE ▁ ` ` ( width , ▁ height ) ` ` ▁ in ▁ columns ▁ and ▁ rows . STRNEWLINE ▁ """ NEW_LINE # ▁ If ▁ shutil ▁ has ▁ get _ terminal _ size ( ) ▁ ( Python ▁ 3.3 ▁ and ▁ later ) ▁ use ▁ that ENDCOM if sys . version_info >= ( 3 , 3 ) : NEW_LINE INDENT import shutil NEW_LINE shutil_get_terminal_size = getattr ( shutil , ' get _ terminal _ size ' , None ) NEW_LINE if shutil_get_terminal_size : NEW_LINE INDENT sz = shutil_get_terminal_size ( ) NEW_LINE return sz . columns , sz . lines NEW_LINE DEDENT DEDENT if get_winterm_size is not None : NEW_LINE INDENT return get_winterm_size ( ) NEW_LINE DEDENT def ioctl_gwinsz ( fd ) : NEW_LINE INDENT try : NEW_LINE INDENT import fcntl NEW_LINE import termios NEW_LINE cr = struct . unpack ( ' hh ' , fcntl . ioctl ( fd , termios . TIOCGWINSZ , '1234' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return NEW_LINE DEDENT return cr NEW_LINE DEDENT cr = ioctl_gwinsz ( 0 ) or ioctl_gwinsz ( 1 ) or ioctl_gwinsz ( 2 ) NEW_LINE if not cr : NEW_LINE INDENT try : NEW_LINE INDENT fd = os . open ( os . ctermid ( ) , os . O_RDONLY ) NEW_LINE try : NEW_LINE INDENT cr = ioctl_gwinsz ( fd ) NEW_LINE DEDENT finally : NEW_LINE INDENT os . close ( fd ) NEW_LINE DEDENT DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT if not cr or not cr [ 0 ] or not cr [ 1 ] : NEW_LINE INDENT cr = ( os . environ . get ( ' LINES ' , 25 ) , os . environ . get ( ' COLUMNS ' , DEFAULT_COLUMNS ) ) NEW_LINE DEDENT return int ( cr [ 1 ] ) , int ( cr [ 0 ] ) NEW_LINE DEDENT def echo_via_pager ( text , color = None ) : NEW_LINE INDENT """ This ▁ function ▁ takes ▁ a ▁ text ▁ and ▁ shows ▁ it ▁ via ▁ an ▁ environment ▁ specific STRNEWLINE ▁ pager ▁ on ▁ stdout . STRNEWLINE STRNEWLINE ▁ . . ▁ versionchanged : : ▁ 3.0 STRNEWLINE ▁ Added ▁ the ▁ ` color ` ▁ flag . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ page . STRNEWLINE ▁ : param ▁ color : ▁ controls ▁ if ▁ the ▁ pager ▁ supports ▁ ANSI ▁ colors ▁ or ▁ not . ▁ The STRNEWLINE ▁ default ▁ is ▁ autodetection . STRNEWLINE ▁ """ NEW_LINE color = resolve_color_default ( color ) NEW_LINE if not isinstance ( text , string_types ) : NEW_LINE INDENT text = text_type ( text ) NEW_LINE DEDENT from . _termui_impl import pager NEW_LINE return pager ( text + ' \n ' , color ) NEW_LINE DEDENT def progressbar ( iterable = None , length = None , label = None , show_eta = True , show_percent = None , show_pos = False , item_show_func = None , fill_char = ' # ' , empty_char = ' - ' , bar_template = ' % ( label ) s ▁ ▁ [ % ( bar ) s ] ▁ ▁ % ( info ) s ' , info_sep = ' ▁ ▁ ' , width = 36 , file = None , color = None ) : NEW_LINE INDENT """ This ▁ function ▁ creates ▁ an ▁ iterable ▁ context ▁ manager ▁ that ▁ can ▁ be ▁ used STRNEWLINE ▁ to ▁ iterate ▁ over ▁ something ▁ while ▁ showing ▁ a ▁ progress ▁ bar . ▁ It ▁ will STRNEWLINE ▁ either ▁ iterate ▁ over ▁ the ▁ ` iterable ` ▁ or ▁ ` length ` ▁ items ▁ ( that ▁ are ▁ counted STRNEWLINE ▁ up ) . ▁ While ▁ iteration ▁ happens , ▁ this ▁ function ▁ will ▁ print ▁ a ▁ rendered STRNEWLINE ▁ progress ▁ bar ▁ to ▁ the ▁ given ▁ ` file ` ▁ ( defaults ▁ to ▁ stdout ) ▁ and ▁ will ▁ attempt STRNEWLINE ▁ to ▁ calculate ▁ remaining ▁ time ▁ and ▁ more . ▁ By ▁ default , ▁ this ▁ progress ▁ bar STRNEWLINE ▁ will ▁ not ▁ be ▁ rendered ▁ if ▁ the ▁ file ▁ is ▁ not ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ The ▁ context ▁ manager ▁ creates ▁ the ▁ progress ▁ bar . ▁ When ▁ the ▁ context STRNEWLINE ▁ manager ▁ is ▁ entered ▁ the ▁ progress ▁ bar ▁ is ▁ already ▁ displayed . ▁ With ▁ every STRNEWLINE ▁ iteration ▁ over ▁ the ▁ progress ▁ bar , ▁ the ▁ iterable ▁ passed ▁ to ▁ the ▁ bar ▁ is STRNEWLINE ▁ advanced ▁ and ▁ the ▁ bar ▁ is ▁ updated . ▁ When ▁ the ▁ context ▁ manager ▁ exits , STRNEWLINE ▁ a ▁ newline ▁ is ▁ printed ▁ and ▁ the ▁ progress ▁ bar ▁ is ▁ finalized ▁ on ▁ screen . STRNEWLINE STRNEWLINE ▁ No ▁ printing ▁ must ▁ happen ▁ or ▁ the ▁ progress ▁ bar ▁ will ▁ be ▁ unintentionally STRNEWLINE ▁ destroyed . STRNEWLINE STRNEWLINE ▁ Example ▁ usage : : STRNEWLINE STRNEWLINE ▁ with ▁ progressbar ( items ) ▁ as ▁ bar : STRNEWLINE ▁ for ▁ item ▁ in ▁ bar : STRNEWLINE ▁ do _ something _ with ( item ) STRNEWLINE STRNEWLINE ▁ Alternatively , ▁ if ▁ no ▁ iterable ▁ is ▁ specified , ▁ one ▁ can ▁ manually ▁ update ▁ the STRNEWLINE ▁ progress ▁ bar ▁ through ▁ the ▁ ` update ( ) ` ▁ method ▁ instead ▁ of ▁ directly STRNEWLINE ▁ iterating ▁ over ▁ the ▁ progress ▁ bar . ▁ The ▁ update ▁ method ▁ accepts ▁ the ▁ number STRNEWLINE ▁ of ▁ steps ▁ to ▁ increment ▁ the ▁ bar ▁ with : : STRNEWLINE STRNEWLINE ▁ with ▁ progressbar ( length = chunks . total _ bytes ) ▁ as ▁ bar : STRNEWLINE ▁ for ▁ chunk ▁ in ▁ chunks : STRNEWLINE ▁ process _ chunk ( chunk ) STRNEWLINE ▁ bar . update ( chunks . bytes ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` color ` ▁ parameter . ▁ Added ▁ a ▁ ` update ` ▁ method ▁ to ▁ the STRNEWLINE ▁ progressbar ▁ object . STRNEWLINE STRNEWLINE ▁ : param ▁ iterable : ▁ an ▁ iterable ▁ to ▁ iterate ▁ over . ▁ If ▁ not ▁ provided ▁ the ▁ length STRNEWLINE ▁ is ▁ required . STRNEWLINE ▁ : param ▁ length : ▁ the ▁ number ▁ of ▁ items ▁ to ▁ iterate ▁ over . ▁ By ▁ default ▁ the STRNEWLINE ▁ progressbar ▁ will ▁ attempt ▁ to ▁ ask ▁ the ▁ iterator ▁ about ▁ its STRNEWLINE ▁ length , ▁ which ▁ might ▁ or ▁ might ▁ not ▁ work . ▁ If ▁ an ▁ iterable ▁ is STRNEWLINE ▁ also ▁ provided ▁ this ▁ parameter ▁ can ▁ be ▁ used ▁ to ▁ override ▁ the STRNEWLINE ▁ length . ▁ If ▁ an ▁ iterable ▁ is ▁ not ▁ provided ▁ the ▁ progress ▁ bar STRNEWLINE ▁ will ▁ iterate ▁ over ▁ a ▁ range ▁ of ▁ that ▁ length . STRNEWLINE ▁ : param ▁ label : ▁ the ▁ label ▁ to ▁ show ▁ next ▁ to ▁ the ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ show _ eta : ▁ enables ▁ or ▁ disables ▁ the ▁ estimated ▁ time ▁ display . ▁ This ▁ is STRNEWLINE ▁ automatically ▁ disabled ▁ if ▁ the ▁ length ▁ cannot ▁ be STRNEWLINE ▁ determined . STRNEWLINE ▁ : param ▁ show _ percent : ▁ enables ▁ or ▁ disables ▁ the ▁ percentage ▁ display . ▁ The STRNEWLINE ▁ default ▁ is ▁ ` True ` ▁ if ▁ the ▁ iterable ▁ has ▁ a ▁ length ▁ or STRNEWLINE ▁ ` False ` ▁ if ▁ not . STRNEWLINE ▁ : param ▁ show _ pos : ▁ enables ▁ or ▁ disables ▁ the ▁ absolute ▁ position ▁ display . ▁ The STRNEWLINE ▁ default ▁ is ▁ ` False ` . STRNEWLINE ▁ : param ▁ item _ show _ func : ▁ a ▁ function ▁ called ▁ with ▁ the ▁ current ▁ item ▁ which STRNEWLINE ▁ can ▁ return ▁ a ▁ string ▁ to ▁ show ▁ the ▁ current ▁ item STRNEWLINE ▁ next ▁ to ▁ the ▁ progress ▁ bar . ▁ Note ▁ that ▁ the ▁ current STRNEWLINE ▁ item ▁ can ▁ be ▁ ` None ` ! STRNEWLINE ▁ : param ▁ fill _ char : ▁ the ▁ character ▁ to ▁ use ▁ to ▁ show ▁ the ▁ filled ▁ part ▁ of ▁ the STRNEWLINE ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ empty _ char : ▁ the ▁ character ▁ to ▁ use ▁ to ▁ show ▁ the ▁ non - filled ▁ part ▁ of STRNEWLINE ▁ the ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ bar _ template : ▁ the ▁ format ▁ string ▁ to ▁ use ▁ as ▁ template ▁ for ▁ the ▁ bar . STRNEWLINE ▁ The ▁ parameters ▁ in ▁ it ▁ are ▁ ` ` label ` ` ▁ for ▁ the ▁ label , STRNEWLINE ▁ ` ` bar ` ` ▁ for ▁ the ▁ progress ▁ bar ▁ and ▁ ` ` info ` ` ▁ for ▁ the STRNEWLINE ▁ info ▁ section . STRNEWLINE ▁ : param ▁ info _ sep : ▁ the ▁ separator ▁ between ▁ multiple ▁ info ▁ items ▁ ( eta ▁ etc . ) STRNEWLINE ▁ : param ▁ width : ▁ the ▁ width ▁ of ▁ the ▁ progress ▁ bar ▁ in ▁ characters , ▁ 0 ▁ means ▁ full STRNEWLINE ▁ terminal ▁ width STRNEWLINE ▁ : param ▁ file : ▁ the ▁ file ▁ to ▁ write ▁ to . ▁ If ▁ this ▁ is ▁ not ▁ a ▁ terminal ▁ then STRNEWLINE ▁ only ▁ the ▁ label ▁ is ▁ printed . STRNEWLINE ▁ : param ▁ color : ▁ controls ▁ if ▁ the ▁ terminal ▁ supports ▁ ANSI ▁ colors ▁ or ▁ not . ▁ The STRNEWLINE ▁ default ▁ is ▁ autodetection . ▁ This ▁ is ▁ only ▁ needed ▁ if ▁ ANSI STRNEWLINE ▁ codes ▁ are ▁ included ▁ anywhere ▁ in ▁ the ▁ progress ▁ bar ▁ output STRNEWLINE ▁ which ▁ is ▁ not ▁ the ▁ case ▁ by ▁ default . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import ProgressBar NEW_LINE color = resolve_color_default ( color ) NEW_LINE return ProgressBar ( iterable = iterable , length = length , show_eta = show_eta , show_percent = show_percent , show_pos = show_pos , item_show_func = item_show_func , fill_char = fill_char , empty_char = empty_char , bar_template = bar_template , info_sep = info_sep , file = file , label = label , width = width , color = color ) NEW_LINE DEDENT def clear ( ) : NEW_LINE INDENT """ Clears ▁ the ▁ terminal ▁ screen . ▁ This ▁ will ▁ have ▁ the ▁ effect ▁ of ▁ clearing STRNEWLINE ▁ the ▁ whole ▁ visible ▁ space ▁ of ▁ the ▁ terminal ▁ and ▁ moving ▁ the ▁ cursor ▁ to ▁ the STRNEWLINE ▁ top ▁ left . ▁ This ▁ does ▁ not ▁ do ▁ anything ▁ if ▁ not ▁ connected ▁ to ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE ▁ """ NEW_LINE if not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE # ▁ If ▁ we ' re ▁ on ▁ Windows ▁ and ▁ we ▁ don ' t ▁ have ▁ colorama ▁ available , ▁ then ▁ we ENDCOM # ▁ clear ▁ the ▁ screen ▁ by ▁ shelling ▁ out . ▁ Otherwise ▁ we ▁ can ▁ use ▁ an ▁ escape ENDCOM # ▁ sequence . ENDCOM DEDENT if WIN : NEW_LINE INDENT os . system ( ' cls ' ) NEW_LINE DEDENT else : NEW_LINE INDENT sys . stdout . write ( ' \033[2J\033[1;1H ' ) NEW_LINE DEDENT DEDENT def style ( text , fg = None , bg = None , bold = None , dim = None , underline = None , blink = None , reverse = None , reset = True ) : NEW_LINE INDENT """ Styles ▁ a ▁ text ▁ with ▁ ANSI ▁ styles ▁ and ▁ returns ▁ the ▁ new ▁ string . ▁ By STRNEWLINE ▁ default ▁ the ▁ styling ▁ is ▁ self ▁ contained ▁ which ▁ means ▁ that ▁ at ▁ the ▁ end STRNEWLINE ▁ of ▁ the ▁ string ▁ a ▁ reset ▁ code ▁ is ▁ issued . ▁ This ▁ can ▁ be ▁ prevented ▁ by STRNEWLINE ▁ passing ▁ ` ` reset = False ` ` . STRNEWLINE STRNEWLINE ▁ Examples : : STRNEWLINE STRNEWLINE ▁ click . echo ( click . style ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) ) STRNEWLINE ▁ click . echo ( click . style ( ' ATTENTION ! ' , ▁ blink = True ) ) STRNEWLINE ▁ click . echo ( click . style ( ' Some ▁ things ' , ▁ reverse = True , ▁ fg = ' cyan ' ) ) STRNEWLINE STRNEWLINE ▁ Supported ▁ color ▁ names : STRNEWLINE STRNEWLINE ▁ * ▁ ` ` black ` ` ▁ ( might ▁ be ▁ a ▁ gray ) STRNEWLINE ▁ * ▁ ` ` red ` ` STRNEWLINE ▁ * ▁ ` ` green ` ` STRNEWLINE ▁ * ▁ ` ` yellow ` ` ▁ ( might ▁ be ▁ an ▁ orange ) STRNEWLINE ▁ * ▁ ` ` blue ` ` STRNEWLINE ▁ * ▁ ` ` magenta ` ` STRNEWLINE ▁ * ▁ ` ` cyan ` ` STRNEWLINE ▁ * ▁ ` ` white ` ` ▁ ( might ▁ be ▁ light ▁ gray ) STRNEWLINE ▁ * ▁ ` ` reset ` ` ▁ ( reset ▁ the ▁ color ▁ code ▁ only ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ string ▁ to ▁ style ▁ with ▁ ansi ▁ codes . STRNEWLINE ▁ : param ▁ fg : ▁ if ▁ provided ▁ this ▁ will ▁ become ▁ the ▁ foreground ▁ color . STRNEWLINE ▁ : param ▁ bg : ▁ if ▁ provided ▁ this ▁ will ▁ become ▁ the ▁ background ▁ color . STRNEWLINE ▁ : param ▁ bold : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ bold ▁ mode . STRNEWLINE ▁ : param ▁ dim : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ dim ▁ mode . ▁ This ▁ is STRNEWLINE ▁ badly ▁ supported . STRNEWLINE ▁ : param ▁ underline : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ underline . STRNEWLINE ▁ : param ▁ blink : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ blinking . STRNEWLINE ▁ : param ▁ reverse : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ inverse STRNEWLINE ▁ rendering ▁ ( foreground ▁ becomes ▁ background ▁ and ▁ the STRNEWLINE ▁ other ▁ way ▁ round ) . STRNEWLINE ▁ : param ▁ reset : ▁ by ▁ default ▁ a ▁ reset - all ▁ code ▁ is ▁ added ▁ at ▁ the ▁ end ▁ of ▁ the STRNEWLINE ▁ string ▁ which ▁ means ▁ that ▁ styles ▁ do ▁ not ▁ carry ▁ over . ▁ This STRNEWLINE ▁ can ▁ be ▁ disabled ▁ to ▁ compose ▁ styles . STRNEWLINE ▁ """ NEW_LINE bits = [ ] NEW_LINE if fg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( fg ) + 30 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % fg ) NEW_LINE DEDENT DEDENT if bg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( bg ) + 40 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % bg ) NEW_LINE DEDENT DEDENT if bold is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 1 if bold else 22 ) ) NEW_LINE DEDENT if dim is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 2 if dim else 22 ) ) NEW_LINE DEDENT if underline is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 4 if underline else 24 ) ) NEW_LINE DEDENT if blink is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 5 if blink else 25 ) ) NEW_LINE DEDENT if reverse is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 7 if reverse else 27 ) ) NEW_LINE DEDENT bits . append ( text ) NEW_LINE if reset : NEW_LINE INDENT bits . append ( _ansi_reset_all ) NEW_LINE DEDENT return ' ' . join ( bits ) NEW_LINE DEDENT def unstyle ( text ) : NEW_LINE INDENT """ Removes ▁ ANSI ▁ styling ▁ information ▁ from ▁ a ▁ string . ▁ Usually ▁ it ' s ▁ not STRNEWLINE ▁ necessary ▁ to ▁ use ▁ this ▁ function ▁ as ▁ Click ' s ▁ echo ▁ function ▁ will STRNEWLINE ▁ automatically ▁ remove ▁ styling ▁ if ▁ necessary . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ remove ▁ style ▁ information ▁ from . STRNEWLINE ▁ """ NEW_LINE return strip_ansi ( text ) NEW_LINE DEDENT def secho ( text , file = None , nl = True , err = False , color = None , ** styles ) : NEW_LINE INDENT """ This ▁ function ▁ combines ▁ : func : ` echo ` ▁ and ▁ : func : ` style ` ▁ into ▁ one STRNEWLINE ▁ call . ▁ As ▁ such ▁ the ▁ following ▁ two ▁ calls ▁ are ▁ the ▁ same : : STRNEWLINE STRNEWLINE ▁ click . secho ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) STRNEWLINE ▁ click . echo ( click . style ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) ) STRNEWLINE STRNEWLINE ▁ All ▁ keyword ▁ arguments ▁ are ▁ forwarded ▁ to ▁ the ▁ underlying ▁ functions STRNEWLINE ▁ depending ▁ on ▁ which ▁ one ▁ they ▁ go ▁ with . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE ▁ """ NEW_LINE return echo ( style ( text , ** styles ) , file = file , nl = nl , err = err , color = color ) NEW_LINE DEDENT def edit ( text = None , editor = None , env = None , require_save = True , extension = ' . txt ' , filename = None ) : NEW_LINE INDENT r """ Edits ▁ the ▁ given ▁ text ▁ in ▁ the ▁ defined ▁ editor . ▁ If ▁ an ▁ editor ▁ is ▁ given STRNEWLINE ▁ ( should ▁ be ▁ the ▁ full ▁ path ▁ to ▁ the ▁ executable ▁ but ▁ the ▁ regular ▁ operating STRNEWLINE ▁ system ▁ search ▁ path ▁ is ▁ used ▁ for ▁ finding ▁ the ▁ executable ) ▁ it ▁ overrides STRNEWLINE ▁ the ▁ detected ▁ editor . ▁ Optionally , ▁ some ▁ environment ▁ variables ▁ can ▁ be STRNEWLINE ▁ used . ▁ If ▁ the ▁ editor ▁ is ▁ closed ▁ without ▁ changes , ▁ ` None ` ▁ is ▁ returned . ▁ In STRNEWLINE ▁ case ▁ a ▁ file ▁ is ▁ edited ▁ directly ▁ the ▁ return ▁ value ▁ is ▁ always ▁ ` None ` ▁ and STRNEWLINE ▁ ` require _ save ` ▁ and ▁ ` extension ` ▁ are ▁ ignored . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ editor ▁ cannot ▁ be ▁ opened ▁ a ▁ : exc : ` UsageError ` ▁ is ▁ raised . STRNEWLINE STRNEWLINE ▁ Note ▁ for ▁ Windows : ▁ to ▁ simplify ▁ cross - platform ▁ usage , ▁ the ▁ newlines ▁ are STRNEWLINE ▁ automatically ▁ converted ▁ from ▁ POSIX ▁ to ▁ Windows ▁ and ▁ vice ▁ versa . ▁ As ▁ such , STRNEWLINE ▁ the ▁ message ▁ here ▁ will ▁ have ▁ ` ` \n ` ` ▁ as ▁ newline ▁ markers . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ edit . STRNEWLINE ▁ : param ▁ editor : ▁ optionally ▁ the ▁ editor ▁ to ▁ use . ▁ Defaults ▁ to ▁ automatic STRNEWLINE ▁ detection . STRNEWLINE ▁ : param ▁ env : ▁ environment ▁ variables ▁ to ▁ forward ▁ to ▁ the ▁ editor . STRNEWLINE ▁ : param ▁ require _ save : ▁ if ▁ this ▁ is ▁ true , ▁ then ▁ not ▁ saving ▁ in ▁ the ▁ editor STRNEWLINE ▁ will ▁ make ▁ the ▁ return ▁ value ▁ become ▁ ` None ` . STRNEWLINE ▁ : param ▁ extension : ▁ the ▁ extension ▁ to ▁ tell ▁ the ▁ editor ▁ about . ▁ This ▁ defaults STRNEWLINE ▁ to ▁ ` . txt ` ▁ but ▁ changing ▁ this ▁ might ▁ change ▁ syntax STRNEWLINE ▁ highlighting . STRNEWLINE ▁ : param ▁ filename : ▁ if ▁ provided ▁ it ▁ will ▁ edit ▁ this ▁ file ▁ instead ▁ of ▁ the STRNEWLINE ▁ provided ▁ text ▁ contents . ▁ It ▁ will ▁ not ▁ use ▁ a ▁ temporary STRNEWLINE ▁ file ▁ as ▁ an ▁ indirection ▁ in ▁ that ▁ case . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import Editor NEW_LINE editor = Editor ( editor = editor , env = env , require_save = require_save , extension = extension ) NEW_LINE if filename is None : NEW_LINE INDENT return editor . edit ( text ) NEW_LINE DEDENT editor . edit_file ( filename ) NEW_LINE DEDENT def launch ( url , wait = False , locate = False ) : NEW_LINE INDENT """ This ▁ function ▁ launches ▁ the ▁ given ▁ URL ▁ ( or ▁ filename ) ▁ in ▁ the ▁ default STRNEWLINE ▁ viewer ▁ application ▁ for ▁ this ▁ file ▁ type . ▁ If ▁ this ▁ is ▁ an ▁ executable , ▁ it STRNEWLINE ▁ might ▁ launch ▁ the ▁ executable ▁ in ▁ a ▁ new ▁ session . ▁ The ▁ return ▁ value ▁ is STRNEWLINE ▁ the ▁ exit ▁ code ▁ of ▁ the ▁ launched ▁ application . ▁ Usually , ▁ ` ` 0 ` ` ▁ indicates STRNEWLINE ▁ success . STRNEWLINE STRNEWLINE ▁ Examples : : STRNEWLINE STRNEWLINE ▁ click . launch ( ' http : / / click . pocoo . org / ' ) STRNEWLINE ▁ click . launch ( ' / my / downloaded / file ' , ▁ locate = True ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ url : ▁ URL ▁ or ▁ filename ▁ of ▁ the ▁ thing ▁ to ▁ launch . STRNEWLINE ▁ : param ▁ wait : ▁ waits ▁ for ▁ the ▁ program ▁ to ▁ stop . STRNEWLINE ▁ : param ▁ locate : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ ` True ` ▁ then ▁ instead ▁ of ▁ launching ▁ the STRNEWLINE ▁ application ▁ associated ▁ with ▁ the ▁ URL ▁ it ▁ will ▁ attempt ▁ to STRNEWLINE ▁ launch ▁ a ▁ file ▁ manager ▁ with ▁ the ▁ file ▁ located . ▁ This STRNEWLINE ▁ might ▁ have ▁ weird ▁ effects ▁ if ▁ the ▁ URL ▁ does ▁ not ▁ point ▁ to STRNEWLINE ▁ the ▁ filesystem . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import open_url NEW_LINE return open_url ( url , wait = wait , locate = locate ) NEW_LINE # ▁ If ▁ this ▁ is ▁ provided , ▁ getchar ( ) ▁ calls ▁ into ▁ this ▁ instead . ▁ This ▁ is ▁ used ENDCOM # ▁ for ▁ unittesting ▁ purposes . ENDCOM DEDENT _getchar = None NEW_LINE def getchar ( echo = False ) : NEW_LINE INDENT """ Fetches ▁ a ▁ single ▁ character ▁ from ▁ the ▁ terminal ▁ and ▁ returns ▁ it . ▁ This STRNEWLINE ▁ will ▁ always ▁ return ▁ a ▁ unicode ▁ character ▁ and ▁ under ▁ certain ▁ rare STRNEWLINE ▁ circumstances ▁ this ▁ might ▁ return ▁ more ▁ than ▁ one ▁ character . ▁ The STRNEWLINE ▁ situations ▁ which ▁ more ▁ than ▁ one ▁ character ▁ is ▁ returned ▁ is ▁ when ▁ for STRNEWLINE ▁ whatever ▁ reason ▁ multiple ▁ characters ▁ end ▁ up ▁ in ▁ the ▁ terminal ▁ buffer ▁ or STRNEWLINE ▁ standard ▁ input ▁ was ▁ not ▁ actually ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ Note ▁ that ▁ this ▁ will ▁ always ▁ read ▁ from ▁ the ▁ terminal , ▁ even ▁ if ▁ something STRNEWLINE ▁ is ▁ piped ▁ into ▁ the ▁ standard ▁ input . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ echo : ▁ if ▁ set ▁ to ▁ ` True ` , ▁ the ▁ character ▁ read ▁ will ▁ also ▁ show ▁ up ▁ on STRNEWLINE ▁ the ▁ terminal . ▁ The ▁ default ▁ is ▁ to ▁ not ▁ show ▁ it . STRNEWLINE ▁ """ NEW_LINE f = _getchar NEW_LINE if f is None : NEW_LINE INDENT from . _termui_impl import getchar as f NEW_LINE DEDENT return f ( echo ) NEW_LINE DEDENT def pause ( info = ' Press ▁ any ▁ key ▁ to ▁ continue ▁ . . . ' , err = False ) : NEW_LINE INDENT """ This ▁ command ▁ stops ▁ execution ▁ and ▁ waits ▁ for ▁ the ▁ user ▁ to ▁ press ▁ any STRNEWLINE ▁ key ▁ to ▁ continue . ▁ This ▁ is ▁ similar ▁ to ▁ the ▁ Windows ▁ batch ▁ " pause " STRNEWLINE ▁ command . ▁ If ▁ the ▁ program ▁ is ▁ not ▁ run ▁ through ▁ a ▁ terminal , ▁ this ▁ command STRNEWLINE ▁ will ▁ instead ▁ do ▁ nothing . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ info : ▁ the ▁ info ▁ string ▁ to ▁ print ▁ before ▁ pausing . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ message ▁ goes ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE if not isatty ( sys . stdin ) or not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE DEDENT try : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( info , nl = False , err = err ) NEW_LINE DEDENT try : NEW_LINE INDENT getchar ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT finally : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( err = err ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="andrewburnheimer/ptpop/tree/master/ptpop/Console.py"> # ! / usr / local / bin / python ENDCOM ''' STRNEWLINE Console ▁ Class STRNEWLINE ''' NEW_LINE ''' STRNEWLINE To ▁ Do : STRNEWLINE ▁ - STRNEWLINE ''' NEW_LINE from Listener import Listener NEW_LINE from _version import __version__ NEW_LINE import time NEW_LINE # ▁ Console ENDCOM # ▁ Inheriting ▁ from ▁ ` object ` ▁ ( top - level ▁ class ) ENDCOM class Console ( object ) : NEW_LINE INDENT def __init__ ( self , args = None ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Console ▁ Initialization STRNEWLINE ▁ Input ▁ Attributes : STRNEWLINE ▁ - - - - - STRNEWLINE ▁ self . args ▁ - > ▁ argparse . Namespace : ▁ object ▁ holding ▁ attributes ▁ set STRNEWLINE ▁ on ▁ command - line . STRNEWLINE ▁ ''' NEW_LINE # ▁ Default ▁ Values ENDCOM delay = 3.0 NEW_LINE number = 1 # ▁ XXX ▁ should ▁ be ▁ = ▁ 0 ENDCOM NEW_LINE command = [ ] NEW_LINE interface = ' eth0' NEW_LINE listen = False NEW_LINE host = ' localhost ' NEW_LINE if args : NEW_LINE INDENT delay = float ( args . delay ) if args . delay else delay NEW_LINE number = args . number if ( args . number != None ) else number NEW_LINE command = args . command if args . command else command NEW_LINE interface = args . interface if args . interface else interface NEW_LINE listen = args . listen if args . listen else listen NEW_LINE host = args . host if args . host else host NEW_LINE # ▁ Input ▁ Checks ENDCOM DEDENT if command != [ ] : NEW_LINE INDENT raise NotImplementedError ( ' Issuing ▁ commands ▁ to ▁ hosts ▁ has ▁ ' + ' not ▁ been ▁ implemented ▁ yet ' ) NEW_LINE # ▁ init ▁ . . . ENDCOM DEDENT if listen : NEW_LINE INDENT self . listener = Listener ( interface ) NEW_LINE key = ''' STRNEWLINE remote ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ Dly ▁ St ▁ Dom ▁ Pr1 ▁ ▁ Cl ▁ Acc ▁ ▁ ▁ Var ▁ ▁ Pr2 ▁ ▁ ▁ ▁ ▁ ▁ ▁ Uniq ▁ ▁ ▁ ▁ ▁ ▁ ▁ SyncT ▁ ▁ DlyT ▁ ▁ AnnT STRNEWLINE = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ''' . strip ( ) NEW_LINE while number > 0 : NEW_LINE # ▁ Report ▁ output ▁ directly ▁ to ▁ console ENDCOM INDENT fmt = ' % a ▁ % b ▁ % d ▁ % Y ▁ % H : % M : % S ' NEW_LINE t = time . time ( ) NEW_LINE time_str = time . strftime ( fmt , time . localtime ( t ) ) NEW_LINE time_msecs = int ( ( t - int ( t ) ) * 1000 ) NEW_LINE print time_str + ' . %03d ▁ ' % ( time_msecs ) + time . tzname [ 0 ] NEW_LINE print key NEW_LINE # ▁ output ▁ data ▁ seen ▁ in ▁ since ▁ last ▁ iteration ENDCOM neighbor_stats = self . listener . ptp_neighbors NEW_LINE for neighbor in neighbor_stats : NEW_LINE INDENT print self . listener . ptp_neighbors [ neighbor ] NEW_LINE DEDENT print NEW_LINE number -= 1 NEW_LINE if number <= 0 : NEW_LINE INDENT exit ( 0 ) NEW_LINE # ▁ No ▁ need ▁ to ▁ wait ▁ after ▁ the ▁ last ▁ iteration ENDCOM DEDENT time . sleep ( delay ) NEW_LINE # ▁ Enter ▁ into ▁ the ▁ interactive ▁ environment , ▁ exit ▁ when ▁ q ▁ is ENDCOM # ▁ issued ENDCOM DEDENT DEDENT else : NEW_LINE INDENT for supplied_command in command : NEW_LINE INDENT command = supplied_command . lower ( ) NEW_LINE if command == ' rv ' or command == ' readvar ' : NEW_LINE INDENT None NEW_LINE # ▁ Assuming ▁ to ▁ be ▁ similar ▁ to ▁ NTPQ ENDCOM # ▁ root @ raspberrypi : / home / puppet # ▁ ntpq ▁ - n ▁ - c ▁ rv ▁ - c ▁ peers ENDCOM # associd = 0 ▁ status = 0615 ▁ leap _ none , ▁ sync _ ntp , ▁ 1 ▁ event , ▁ clock _ sync , ENDCOM # version = " ntpd ▁ 4.2.6p5@1.2349 - o ▁ Mon ▁ Nov ▁ 2 ▁ 04:29:47 ▁ UTC ▁ 2015 ▁ ( 1 ) " , ENDCOM # processor = " armv6l " , ▁ system = " Linux / 4.1.17 + " , ▁ leap = 00 , ▁ stratum = 3 , ENDCOM # precision = - 20 , ▁ rootdelay = 2.916 , ▁ rootdisp = 60.561 , ENDCOM # refid = 3.44.174.43 , ENDCOM # reftime = da7f3666.54078831 ▁ Mon , ▁ Feb ▁ 29 ▁ 2016 ▁ 21:28:06.328 , ENDCOM # clock = da7f38cd . 57a72dc6 ▁ Mon , ▁ Feb ▁ 29 ▁ 2016 ▁ 21:38:21.342 , ENDCOM # peer = 7185 , ▁ tc = 8 , ENDCOM # mintc = 3 , ▁ offset = 9.208 , ▁ frequency = - 48.954 , ▁ sys _ jitter = 0.000 , ENDCOM # clk _ jitter = 16.919 , ▁ clk _ wander = 4.216 ENDCOM DEDENT elif command == ' peers ' : NEW_LINE INDENT None NEW_LINE # ▁ Assuming ▁ to ▁ be ▁ similar ▁ to ▁ NTPQ ENDCOM # ▁ remote ▁ refid ▁ st ▁ t ▁ when ▁ poll ▁ reach ▁ delay ▁ offset ▁ jitter ENDCOM # * useclsifl158 . tf ▁ 3.199.96.254 ▁ 2 ▁ u ▁ 14 ▁ 1024 ▁ 377 ▁ 1.582 ▁ 0.186 ▁ 0.919 ENDCOM DEDENT else : NEW_LINE INDENT raise NotImplementedError ( ' Unknown ▁ command , ▁ \ ' ' + command + ' \ ' ' ) NEW_LINE # ▁ _ _ main _ _ . py ▁ is ▁ executed ▁ when ▁ the ▁ package ▁ is ▁ instantiated ENDCOM DEDENT DEDENT DEDENT DEDENT DEDENT import argparse NEW_LINE def main ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( prog = ' ptpop ' , description = ' Gain ▁ ' + ' insight ▁ into ▁ the ▁ operations ▁ of ▁ IEEE ▁ 1588 ▁ Precision ▁ Time ▁ Protocol ▁ ' + ' domains ▁ on ▁ a ▁ network . ▁ Press ▁ the ▁ \ ' q\ ' ▁ key ▁ to ▁ quit . ' ) NEW_LINE command_choices = [ ' readvar ' , ' rv ' , ' peers ' ] NEW_LINE parser . add_argument ( ' host ' , type = str , nargs = ' ? ' , help = ' each ▁ of ▁ the ▁ ' + ' commands ▁ will ▁ be ▁ sent ▁ to ▁ the ▁ PTP ▁ servers ▁ ' + ' running ▁ on ▁ the ▁ host ▁ provided , ▁ localhost ▁ by ▁ ' + ' default . ' ) NEW_LINE parser . add_argument ( ' - c ' , ' - - command ' , type = str , action = ' append ' , help = ' a ▁ command ▁ to ▁ run ▁ on ▁ the ▁ provided ▁ host , ▁ ' + ' i . e . ▁ ' + str ( command_choices ) + ' , ▁ \ ' readvar\ ' ▁ ' + ' by ▁ default . ▁ Multiple ▁ commands ▁ can ▁ be ▁ issued . ' ) NEW_LINE parser . add_argument ( ' - i ' , ' - - interface ' , type = str , help = ' interface ▁ to ▁ issue ▁ commands ▁ on ▁ or ▁ to ▁ ' + ' observe ▁ on ▁ in ▁ listen ▁ mode . ' ) NEW_LINE parser . add_argument ( ' - l ' , ' - - listen ' , action = ' store _ true ' , help = ' don\ ' t ▁ contact ▁ any ▁ PTP ▁ servers , ▁ but ▁ ' + ' report ▁ on ▁ any ▁ services ▁ currently ▁ observed ▁ ' + ' on ▁ the ▁ network , ▁ instead . ' ) NEW_LINE parser . add_argument ( ' - d ' , ' - - delay ' , metavar = ' SECS . TENTHS ' , type = str , help = ' Specifies ▁ the ▁ delay ▁ between ▁ screen ▁ ' + ' updates ▁ when ▁ interactive . ▁ Can ▁ be ▁ changed ▁ while ▁ ' + ' running ▁ using ▁ the ▁ \ ' d\ ' ▁ key . ▁ Negative ▁ ' + ' numbers ▁ are ▁ not ▁ allowed . ▁ Setting ▁ this ▁ value ▁ ' + ' to ▁ 0 ▁ is ▁ the ▁ same ▁ as ▁ issuing ▁ the ▁ \ ' - n ▁ 1\ ' ▁ ' + ' option . ' ) NEW_LINE parser . add_argument ( ' - n ' , ' - - number ' , metavar = ' COUNT ' , type = int , help = ' Specifies ▁ the ▁ maximum ▁ number ▁ of ▁ iterations ▁ ' + ' in ▁ interactive ▁ mode ▁ before ▁ ending . ' ) NEW_LINE parser . add_argument ( ' - v ' , ' - - version ' , action = ' version ' , version = ' % ( prog ) s ▁ ' + __version__ ) NEW_LINE args = parser . parse_args ( ) NEW_LINE try : NEW_LINE INDENT c = Console ( args ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT print type ( e ) . __name__ + " : ▁ " + str ( e . message ) NEW_LINE exit ( - 1 ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="michalkurka/h2o-3/tree/master/h2o-py/tests/testdir_algos/pca/pyunit_pubdev_4961_pca_implementations.py"> from __future__ import print_function NEW_LINE from builtins import str NEW_LINE from builtins import range NEW_LINE import sys NEW_LINE sys . path . insert ( 1 , " . . / . . / . . / " ) NEW_LINE import h2o NEW_LINE from tests import pyunit_utils NEW_LINE from h2o . estimators . pca import H2OPrincipalComponentAnalysisEstimator as H2OPCA NEW_LINE def pca_arrests ( ) : NEW_LINE INDENT print ( " Importing ▁ USArrests . csv ▁ data . . . " ) NEW_LINE arrestsH2O = h2o . upload_file ( pyunit_utils . locate ( " smalldata / pca _ test / USArrests . csv " ) ) NEW_LINE print ( " Testing ▁ to ▁ see ▁ whether ▁ the ▁ trained ▁ PCA ▁ are ▁ essentially ▁ the ▁ same ▁ using ▁ different ▁ implementation . . . " ) NEW_LINE eigenvector_standard = None NEW_LINE for impl in [ " MTJ _ EVD _ DENSEMATRIX " , " MTJ _ EVD _ SYMMMATRIX " , " MTJ _ SVD _ DENSEMATRIX " , " JAMA " ] : NEW_LINE INDENT print ( " Run ▁ PCA ▁ with ▁ implementation : ▁ " + impl ) NEW_LINE model = H2OPCA ( k = 4 , pca_impl = impl , seed = 1234 ) NEW_LINE model . train ( x = list ( range ( 4 ) ) , training_frame = arrestsH2O ) NEW_LINE eigenvectors = model . _model_json [ " output " ] [ " eigenvectors " ] NEW_LINE if eigenvector_standard is not None : NEW_LINE # ▁ Compare ▁ to ▁ see ▁ if ▁ they ▁ are ▁ fundamentally ▁ the ▁ same ENDCOM INDENT pyunit_utils . assert_H2OTwoDimTable_equal ( eigenvector_standard , eigenvectors , model . _model_json [ " output " ] [ " names " ] , tolerance = 1e-6 , check_sign = True , check_all = False ) NEW_LINE DEDENT else : NEW_LINE INDENT eigenvector_standard = eigenvectors NEW_LINE DEDENT DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT pyunit_utils . standalone_test ( pca_arrests ) NEW_LINE DEDENT else : NEW_LINE INDENT pca_arrests ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="tianweizhang/nova/tree/master/nova/cmd/network.py"> # ▁ Copyright ▁ 2010 ▁ United ▁ States ▁ Government ▁ as ▁ represented ▁ by ▁ the ENDCOM # ▁ Administrator ▁ of ▁ the ▁ National ▁ Aeronautics ▁ and ▁ Space ▁ Administration . ENDCOM # ▁ All ▁ Rights ▁ Reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM """ Starter ▁ script ▁ for ▁ Nova ▁ Network . """ NEW_LINE import sys NEW_LINE import traceback NEW_LINE from oslo . config import cfg NEW_LINE from nova . conductor import rpcapi as conductor_rpcapi NEW_LINE from nova import config NEW_LINE import nova . db . api NEW_LINE from nova import exception NEW_LINE from nova . i18n import _ NEW_LINE from nova import objects NEW_LINE from nova . objects import base as objects_base NEW_LINE from nova . openstack . common import log as logging NEW_LINE from nova . openstack . common . report import guru_meditation_report as gmr NEW_LINE from nova import service NEW_LINE from nova import utils NEW_LINE from nova import version NEW_LINE CONF = cfg . CONF NEW_LINE CONF . import_opt ( ' network _ topic ' , ' nova . network . rpcapi ' ) NEW_LINE CONF . import_opt ( ' use _ local ' , ' nova . conductor . api ' , group = ' conductor ' ) NEW_LINE def block_db_access ( ) : NEW_LINE INDENT class NoDB ( object ) : NEW_LINE INDENT def __getattr__ ( self , attr ) : NEW_LINE INDENT return self NEW_LINE DEDENT def __call__ ( self , * args , ** kwargs ) : NEW_LINE INDENT stacktrace = " " . join ( traceback . format_stack ( ) ) NEW_LINE LOG = logging . getLogger ( ' nova . network ' ) NEW_LINE LOG . error ( _ ( ' No ▁ db ▁ access ▁ allowed ▁ in ▁ nova - network : ▁ % s ' ) , stacktrace ) NEW_LINE raise exception . DBNotAllowed ( ' nova - network ' ) NEW_LINE DEDENT DEDENT nova . db . api . IMPL = NoDB ( ) NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT config . parse_args ( sys . argv ) NEW_LINE logging . setup ( " nova " ) NEW_LINE utils . monkey_patch ( ) NEW_LINE objects . register_all ( ) NEW_LINE gmr . TextGuruMeditation . setup_autorun ( version ) NEW_LINE if not CONF . conductor . use_local : NEW_LINE INDENT block_db_access ( ) NEW_LINE objects_base . NovaObject . indirection_api = conductor_rpcapi . ConductorAPI ( ) NEW_LINE DEDENT server = service . Service . create ( binary = ' nova - network ' , topic = CONF . network_topic , db_allowed = CONF . conductor . use_local ) NEW_LINE service . serve ( server ) NEW_LINE service . wait ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="roandelyf/iTerm2/tree/master/tests/esctest/tests/el.py"> from esc import NUL , blank NEW_LINE import escargs NEW_LINE import esccmd NEW_LINE import escio NEW_LINE from esctypes import Point , Rect NEW_LINE from escutil import AssertEQ , AssertScreenCharsInRectEqual , GetCursorPosition , knownBug NEW_LINE class ELTests ( object ) : NEW_LINE INDENT def prepare ( self ) : NEW_LINE INDENT """ Initializes ▁ the ▁ screen ▁ to ▁ abcdefghij ▁ on ▁ the ▁ first ▁ line ▁ with ▁ the ▁ cursor STRNEWLINE ▁ on ▁ the ▁ ' e ' . """ NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE escio . Write ( " abcdefghij " ) NEW_LINE esccmd . CUP ( Point ( 5 , 1 ) ) NEW_LINE DEDENT def test_EL_Default ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ " abcd " + 6 * NUL ] ) NEW_LINE DEDENT def test_EL_0 ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( 0 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ " abcd " + 6 * NUL ] ) NEW_LINE DEDENT def test_EL_1 ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ to ▁ left ▁ of ▁ cursor . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( 1 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 5 * blank ( ) + " fghij " ] ) NEW_LINE DEDENT def test_EL_2 ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ whole ▁ line . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) NEW_LINE DEDENT def test_EL_IgnoresScrollRegion ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ whole ▁ line . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . DECSET ( esccmd . DECLRMM ) NEW_LINE esccmd . DECSLRM ( 2 , 4 ) NEW_LINE esccmd . CUP ( Point ( 5 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE esccmd . DECRESET ( esccmd . DECLRMM ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) NEW_LINE DEDENT def test_EL_doesNotRespectDECProtection ( self ) : NEW_LINE INDENT """ EL ▁ respects ▁ DECSCA . """ NEW_LINE escio . Write ( " a " ) NEW_LINE escio . Write ( " b " ) NEW_LINE esccmd . DECSCA ( 1 ) NEW_LINE escio . Write ( " c " ) NEW_LINE esccmd . DECSCA ( 0 ) NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 3 , 1 ) , [ NUL * 3 ] ) NEW_LINE DEDENT @ knownBug ( terminal = " iTerm2" , reason = " Protection ▁ not ▁ implemented . " ) NEW_LINE def test_EL_respectsISOProtection ( self ) : NEW_LINE INDENT """ EL ▁ respects ▁ SPA / EPA . """ NEW_LINE escio . Write ( " a " ) NEW_LINE escio . Write ( " b " ) NEW_LINE esccmd . SPA ( ) NEW_LINE escio . Write ( " c " ) NEW_LINE esccmd . EPA ( ) NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 3 , 1 ) , [ blank ( ) * 2 + " c " ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="moijes12/oh-mainline/tree/master/vendor/packages/sphinx/tests/test_intersphinx.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM """ STRNEWLINE ▁ test _ intersphinx STRNEWLINE ▁ ~ ~ ~ ~ ~ STRNEWLINE STRNEWLINE ▁ Test ▁ the ▁ intersphinx ▁ extension . STRNEWLINE STRNEWLINE ▁ : copyright : ▁ Copyright ▁ 2007-2013 ▁ by ▁ the ▁ Sphinx ▁ team , ▁ see ▁ AUTHORS . STRNEWLINE ▁ : license : ▁ BSD , ▁ see ▁ LICENSE ▁ for ▁ details . STRNEWLINE """ NEW_LINE import zlib NEW_LINE import posixpath NEW_LINE try : NEW_LINE INDENT from io import BytesIO NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from cStringIO import StringIO as BytesIO NEW_LINE DEDENT from docutils import nodes NEW_LINE from sphinx import addnodes NEW_LINE from sphinx . ext . intersphinx import read_inventory_v1 , read_inventory_v2 , load_mappings , missing_reference NEW_LINE from util import with_app , with_tempdir , write_file NEW_LINE inventory_v1 = ''' \ STRNEWLINE # ▁ Sphinx ▁ inventory ▁ version ▁ 1 STRNEWLINE # ▁ Project : ▁ foo STRNEWLINE # ▁ Version : ▁ 1.0 STRNEWLINE module ▁ mod ▁ foo . html STRNEWLINE module . cls ▁ class ▁ foo . html STRNEWLINE ''' . encode ( ' utf - 8' ) NEW_LINE inventory_v2 = ''' \ STRNEWLINE # ▁ Sphinx ▁ inventory ▁ version ▁ 2 STRNEWLINE # ▁ Project : ▁ foo STRNEWLINE # ▁ Version : ▁ 2.0 STRNEWLINE # ▁ The ▁ remainder ▁ of ▁ this ▁ file ▁ is ▁ compressed ▁ with ▁ zlib . STRNEWLINE ''' . encode ( ' utf - 8' ) + zlib . compress ( ''' \ STRNEWLINE module1 ▁ py : module ▁ 0 ▁ foo . html # module - module1 ▁ Long ▁ Module ▁ desc STRNEWLINE module2 ▁ py : module ▁ 0 ▁ foo . html # module - $ ▁ - STRNEWLINE module1 . func ▁ py : function ▁ 1 ▁ sub / foo . html # $ ▁ - STRNEWLINE CFunc ▁ c : function ▁ 2 ▁ cfunc . html # CFunc ▁ - STRNEWLINE a ▁ term ▁ std : term ▁ - 1 ▁ glossary . html # term - a - term ▁ - STRNEWLINE ''' . encode ( ' utf - 8' ) ) NEW_LINE def test_read_inventory_v1 ( ) : NEW_LINE INDENT f = BytesIO ( inventory_v1 ) NEW_LINE f . readline ( ) NEW_LINE invdata = read_inventory_v1 ( f , ' / util ' , posixpath . join ) NEW_LINE assert invdata [ ' py : module ' ] [ ' module ' ] == ( ' foo ' , '1.0' , ' / util / foo . html # module - module ' , ' - ' ) NEW_LINE assert invdata [ ' py : class ' ] [ ' module . cls ' ] == ( ' foo ' , '1.0' , ' / util / foo . html # module . cls ' , ' - ' ) NEW_LINE DEDENT def test_read_inventory_v2 ( ) : NEW_LINE INDENT f = BytesIO ( inventory_v2 ) NEW_LINE f . readline ( ) NEW_LINE invdata1 = read_inventory_v2 ( f , ' / util ' , posixpath . join ) NEW_LINE # ▁ try ▁ again ▁ with ▁ a ▁ small ▁ buffer ▁ size ▁ to ▁ test ▁ the ▁ chunking ▁ algorithm ENDCOM f = BytesIO ( inventory_v2 ) NEW_LINE f . readline ( ) NEW_LINE invdata2 = read_inventory_v2 ( f , ' / util ' , posixpath . join , bufsize = 5 ) NEW_LINE assert invdata1 == invdata2 NEW_LINE assert len ( invdata1 [ ' py : module ' ] ) == 2 NEW_LINE assert invdata1 [ ' py : module ' ] [ ' module1' ] == ( ' foo ' , '2.0' , ' / util / foo . html # module - module1' , ' Long ▁ Module ▁ desc ' ) NEW_LINE assert invdata1 [ ' py : module ' ] [ ' module2' ] == ( ' foo ' , '2.0' , ' / util / foo . html # module - module2' , ' - ' ) NEW_LINE assert invdata1 [ ' py : function ' ] [ ' module1 . func ' ] [ 2 ] == ' / util / sub / foo . html # module1 . func ' NEW_LINE assert invdata1 [ ' c : function ' ] [ ' CFunc ' ] [ 2 ] == ' / util / cfunc . html # CFunc ' NEW_LINE assert invdata1 [ ' std : term ' ] [ ' a ▁ term ' ] [ 2 ] == ' / util / glossary . html # term - a - term ' NEW_LINE DEDENT @ with_app ( confoverrides = { ' extensions ' : ' sphinx . ext . intersphinx ' } ) NEW_LINE @ with_tempdir NEW_LINE def test_missing_reference ( tempdir , app ) : NEW_LINE INDENT inv_file = tempdir / ' inventory ' NEW_LINE write_file ( inv_file , inventory_v2 ) NEW_LINE app . config . intersphinx_mapping = { ' http : / / docs . python . org / ' : inv_file , ' py3k ' : ( ' http : / / docs . python . org / py3k / ' , inv_file ) , } NEW_LINE app . config . intersphinx_cache_limit = 0 NEW_LINE # ▁ load ▁ the ▁ inventory ▁ and ▁ check ▁ if ▁ it ' s ▁ done ▁ correctly ENDCOM load_mappings ( app ) NEW_LINE inv = app . env . intersphinx_inventory NEW_LINE assert inv [ ' py : module ' ] [ ' module2' ] == ( ' foo ' , '2.0' , ' http : / / docs . python . org / foo . html # module - module2' , ' - ' ) NEW_LINE # ▁ create ▁ fake ▁ nodes ▁ and ▁ check ▁ referencing ENDCOM def fake_node ( domain , type , target , content , ** attrs ) : NEW_LINE INDENT contnode = nodes . emphasis ( content , content ) NEW_LINE node = addnodes . pending_xref ( ' ' ) NEW_LINE node [ ' reftarget ' ] = target NEW_LINE node [ ' reftype ' ] = type NEW_LINE node [ ' refdomain ' ] = domain NEW_LINE node . attributes . update ( attrs ) NEW_LINE node += contnode NEW_LINE return node , contnode NEW_LINE DEDENT def reference_check ( * args , ** kwds ) : NEW_LINE INDENT node , contnode = fake_node ( * args , ** kwds ) NEW_LINE return missing_reference ( app , app . env , node , contnode ) NEW_LINE # ▁ check ▁ resolution ▁ when ▁ a ▁ target ▁ is ▁ found ENDCOM DEDENT rn = reference_check ( ' py ' , ' func ' , ' module1 . func ' , ' foo ' ) NEW_LINE assert isinstance ( rn , nodes . reference ) NEW_LINE assert rn [ ' refuri ' ] == ' http : / / docs . python . org / sub / foo . html # module1 . func ' NEW_LINE assert rn [ ' reftitle ' ] == ' ( in ▁ foo ▁ v2.0 ) ' NEW_LINE assert rn [ 0 ] . astext ( ) == ' foo ' NEW_LINE # ▁ create ▁ unresolvable ▁ nodes ▁ and ▁ check ▁ None ▁ return ▁ value ENDCOM assert reference_check ( ' py ' , ' foo ' , ' module1 . func ' , ' foo ' ) is None NEW_LINE assert reference_check ( ' py ' , ' func ' , ' foo ' , ' foo ' ) is None NEW_LINE assert reference_check ( ' py ' , ' func ' , ' foo ' , ' foo ' ) is None NEW_LINE # ▁ check ▁ handling ▁ of ▁ prefixes ENDCOM # ▁ prefix ▁ given , ▁ target ▁ found : ▁ prefix ▁ is ▁ stripped ENDCOM rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' py3k : module2' ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' module2' NEW_LINE # ▁ prefix ▁ given , ▁ but ▁ not ▁ in ▁ title : ▁ nothing ▁ stripped ENDCOM rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' module2' ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' module2' NEW_LINE # ▁ prefix ▁ given , ▁ but ▁ explicit : ▁ nothing ▁ stripped ENDCOM rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' py3k : module2' , refexplicit = True ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' py3k : module2' NEW_LINE # ▁ prefix ▁ given , ▁ target ▁ not ▁ found ▁ and ▁ nonexplicit ▁ title : ▁ prefix ▁ is ▁ stripped ENDCOM node , contnode = fake_node ( ' py ' , ' mod ' , ' py3k : unknown ' , ' py3k : unknown ' , refexplicit = False ) NEW_LINE rn = missing_reference ( app , app . env , node , contnode ) NEW_LINE assert rn is None NEW_LINE assert contnode [ 0 ] . astext ( ) == ' unknown ' NEW_LINE # ▁ prefix ▁ given , ▁ target ▁ not ▁ found ▁ and ▁ explicit ▁ title : ▁ nothing ▁ is ▁ changed ENDCOM node , contnode = fake_node ( ' py ' , ' mod ' , ' py3k : unknown ' , ' py3k : unknown ' , refexplicit = True ) NEW_LINE rn = missing_reference ( app , app . env , node , contnode ) NEW_LINE assert rn is None NEW_LINE assert contnode [ 0 ] . astext ( ) == ' py3k : unknown ' NEW_LINE DEDENT @ with_app ( confoverrides = { ' extensions ' : ' sphinx . ext . intersphinx ' } ) NEW_LINE @ with_tempdir NEW_LINE def test_load_mappings_warnings ( tempdir , app ) : NEW_LINE INDENT """ STRNEWLINE ▁ load _ mappings ▁ issues ▁ a ▁ warning ▁ if ▁ new - style ▁ mapping STRNEWLINE ▁ identifiers ▁ are ▁ not ▁ alphanumeric STRNEWLINE ▁ """ NEW_LINE inv_file = tempdir / ' inventory ' NEW_LINE write_file ( inv_file , inventory_v2 ) NEW_LINE app . config . intersphinx_mapping = { ' http : / / docs . python . org / ' : inv_file , ' py3k ' : ( ' http : / / docs . python . org / py3k / ' , inv_file ) , ' repoze . workflow ' : ( ' http : / / docs . repoze . org / workflow / ' , inv_file ) , ' django - taggit ' : ( ' http : / / django - taggit . readthedocs . org / en / latest / ' , inv_file ) } NEW_LINE app . config . intersphinx_cache_limit = 0 NEW_LINE # ▁ load ▁ the ▁ inventory ▁ and ▁ check ▁ if ▁ it ' s ▁ done ▁ correctly ENDCOM load_mappings ( app ) NEW_LINE assert len ( app . _warning . content ) == 2 NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="giorgiop/scipy/tree/master/scipy/interpolate/tests/test_fitpack2.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Created ▁ by ▁ Pearu ▁ Peterson , ▁ June ▁ 2003 ENDCOM from __future__ import division , print_function , absolute_import NEW_LINE import warnings NEW_LINE import numpy as np NEW_LINE from numpy . testing import ( assert_equal , assert_almost_equal , assert_array_equal , assert_array_almost_equal , assert_allclose , assert_raises , TestCase , run_module_suite ) NEW_LINE from numpy import array , diff , linspace , meshgrid , ones , pi , shape NEW_LINE from scipy . interpolate . fitpack import bisplrep , bisplev NEW_LINE from scipy . interpolate . fitpack2 import ( UnivariateSpline , LSQUnivariateSpline , InterpolatedUnivariateSpline , LSQBivariateSpline , SmoothBivariateSpline , RectBivariateSpline , LSQSphereBivariateSpline , SmoothSphereBivariateSpline , RectSphereBivariateSpline ) NEW_LINE class TestUnivariateSpline ( TestCase ) : NEW_LINE INDENT def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 3 , 3 , 3 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , [ 1 , 3 ] ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 3 , 3 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] ) , [ 3 , 3 , 3 ] ) NEW_LINE DEDENT def test_preserve_shape ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 0 , 2 , 4 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE arg = 2 NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg ) ) ) NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg , nu = 1 ) ) ) NEW_LINE arg = [ 1.5 , 2 , 2.5 ] NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg ) ) ) NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg , nu = 1 ) ) ) NEW_LINE DEDENT def test_linear_1d ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 0 , 2 , 4 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , [ 1 , 3 ] ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 0 , 4 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] ) , [ 0 , 1 , 2 ] ) NEW_LINE DEDENT def test_subclassing ( self ) : NEW_LINE # ▁ See ▁ # 731 ENDCOM INDENT class ZeroSpline ( UnivariateSpline ) : NEW_LINE INDENT def __call__ ( self , x ) : NEW_LINE INDENT return 0 * array ( x ) NEW_LINE DEDENT DEDENT sp = ZeroSpline ( [ 1 , 2 , 3 , 4 , 5 ] , [ 3 , 2 , 3 , 2 , 3 ] , k = 2 ) NEW_LINE assert_array_equal ( sp ( [ 1.5 , 2.5 ] ) , [ 0. , 0. ] ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE # ▁ Test ▁ whether ▁ empty ▁ input ▁ returns ▁ an ▁ empty ▁ output . ▁ Ticket ▁ 1014 ENDCOM INDENT x = [ 1 , 3 , 5 , 7 , 9 ] NEW_LINE y = [ 0 , 4 , 9 , 12 , 21 ] NEW_LINE spl = UnivariateSpline ( x , y , k = 3 ) NEW_LINE assert_array_equal ( spl ( [ ] ) , array ( [ ] ) ) NEW_LINE DEDENT def test_resize_regression ( self ) : NEW_LINE INDENT """ Regression ▁ test ▁ for ▁ # 1375 . """ NEW_LINE x = [ - 1. , - 0.65016502 , - 0.58856235 , - 0.26903553 , - 0.17370892 , - 0.10011001 , 0. , 0.10011001 , 0.17370892 , 0.26903553 , 0.58856235 , 0.65016502 , 1. ] NEW_LINE y = [ 1. , 0.62928599 , 0.5797223 , 0.39965815 , 0.36322694 , 0.3508061 , 0.35214793 , 0.3508061 , 0.36322694 , 0.39965815 , 0.5797223 , 0.62928599 , 1. ] NEW_LINE w = [ 1.00000000e+12 , 6.88875973e+02 , 4.89314737e+02 , 4.26864807e+02 , 6.07746770e+02 , 4.51341444e+02 , 3.17480210e+02 , 4.51341444e+02 , 6.07746770e+02 , 4.26864807e+02 , 4.89314737e+02 , 6.88875973e+02 , 1.00000000e+12 ] NEW_LINE spl = UnivariateSpline ( x = x , y = y , w = w , s = None ) NEW_LINE desired = array ( [ 0.35100374 , 0.51715855 , 0.87789547 , 0.98719344 ] ) NEW_LINE assert_allclose ( spl ( [ 0.1 , 0.5 , 0.9 , 0.99 ] ) , desired , atol = 5e-4 ) NEW_LINE DEDENT def test_out_of_range_regression ( self ) : NEW_LINE # ▁ Test ▁ different ▁ extrapolation ▁ modes . ▁ See ▁ ticket ▁ 3557 ENDCOM INDENT x = np . arange ( 5 , dtype = float ) NEW_LINE y = x ** 3 NEW_LINE xp = linspace ( - 8 , 13 , 100 ) NEW_LINE xp_zeros = xp . copy ( ) NEW_LINE xp_zeros [ np . logical_or ( xp_zeros < 0. , xp_zeros > 4. ) ] = 0 NEW_LINE xp_clip = xp . copy ( ) NEW_LINE xp_clip [ xp_clip < x [ 0 ] ] = x [ 0 ] NEW_LINE xp_clip [ xp_clip > x [ - 1 ] ] = x [ - 1 ] NEW_LINE for cls in [ UnivariateSpline , InterpolatedUnivariateSpline ] : NEW_LINE INDENT spl = cls ( x = x , y = y ) NEW_LINE for ext in [ 0 , ' extrapolate ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp ** 3 , atol = 1e-16 ) NEW_LINE DEDENT for ext in [ 1 , ' zeros ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE DEDENT for ext in [ 2 , ' raise ' ] : NEW_LINE INDENT assert_raises ( ValueError , spl , xp , ** dict ( ext = ext ) ) NEW_LINE DEDENT for ext in [ 3 , ' const ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE # ▁ also ▁ test ▁ LSQUnivariateSpline ▁ [ which ▁ needs ▁ explicit ▁ knots ] ENDCOM DEDENT DEDENT t = spl . get_knots ( ) [ 3 : 4 ] # ▁ interior ▁ knots ▁ w / ▁ default ▁ k = 3 ENDCOM NEW_LINE spl = LSQUnivariateSpline ( x , y , t ) NEW_LINE assert_allclose ( spl ( xp , ext = 0 ) , xp ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( spl ( xp , ext = 1 ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE assert_raises ( ValueError , spl , xp , ** dict ( ext = 2 ) ) NEW_LINE assert_allclose ( spl ( xp , ext = 3 ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE # ▁ also ▁ make ▁ sure ▁ that ▁ unknown ▁ values ▁ for ▁ ` ext ` ▁ are ▁ caught ▁ early ENDCOM for ext in [ - 1 , ' unknown ' ] : NEW_LINE INDENT spl = UnivariateSpline ( x , y ) NEW_LINE assert_raises ( ValueError , spl , xp , ** dict ( ext = ext ) ) NEW_LINE assert_raises ( ValueError , UnivariateSpline , ** dict ( x = x , y = y , ext = ext ) ) NEW_LINE DEDENT DEDENT def test_lsq_fpchec ( self ) : NEW_LINE INDENT xs = np . arange ( 100 ) * 1. NEW_LINE ys = np . arange ( 100 ) * 1. NEW_LINE knots = np . linspace ( 0 , 99 , 10 ) NEW_LINE bbox = ( - 1 , 101 ) NEW_LINE assert_raises ( ValueError , LSQUnivariateSpline , xs , ys , knots , bbox = bbox ) NEW_LINE DEDENT def test_derivative_and_antiderivative ( self ) : NEW_LINE # ▁ Thin ▁ wrappers ▁ to ▁ splder / splantider , ▁ so ▁ light ▁ smoke ▁ test ▁ only . ENDCOM INDENT x = np . linspace ( 0 , 1 , 70 ) ** 3 NEW_LINE y = np . cos ( x ) NEW_LINE spl = UnivariateSpline ( x , y , s = 0 ) NEW_LINE spl2 = spl . antiderivative ( 2 ) . derivative ( 2 ) NEW_LINE assert_allclose ( spl ( 0.3 ) , spl2 ( 0.3 ) ) NEW_LINE spl2 = spl . antiderivative ( 1 ) NEW_LINE assert_allclose ( spl2 ( 0.6 ) - spl2 ( 0.2 ) , spl . integral ( 0.2 , 0.6 ) ) NEW_LINE DEDENT def test_nan ( self ) : NEW_LINE # ▁ bail ▁ out ▁ early ▁ if ▁ the ▁ input ▁ data ▁ contains ▁ nans ENDCOM INDENT x = np . arange ( 10 , dtype = float ) NEW_LINE y = x ** 3 NEW_LINE for z in [ np . nan , np . inf , - np . inf ] : NEW_LINE INDENT y [ - 1 ] = z NEW_LINE assert_raises ( ValueError , UnivariateSpline , ** dict ( x = x , y = y , check_finite = True ) ) NEW_LINE DEDENT DEDENT DEDENT class TestLSQBivariateSpline ( TestCase ) : NEW_LINE # ▁ NOTE : ▁ The ▁ systems ▁ in ▁ this ▁ test ▁ class ▁ are ▁ rank - deficient ENDCOM INDENT def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : # ▁ coefficients ▁ of ▁ the ▁ . . . ENDCOM NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT assert_almost_equal ( lut ( 2 , 2 ) , 3. ) NEW_LINE DEDENT def test_bilinearity ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( ) : NEW_LINE # ▁ This ▁ seems ▁ to ▁ fail ▁ ( ier = 1 , ▁ see ▁ ticket ▁ 1642 ) . ENDCOM INDENT warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT tx , ty = lut . get_knots ( ) NEW_LINE for xa , xb in zip ( tx [ : - 1 ] , tx [ 1 : ] ) : NEW_LINE INDENT for ya , yb in zip ( ty [ : - 1 ] , ty [ 1 : ] ) : NEW_LINE INDENT for t in [ 0.1 , 0.5 , 0.9 ] : NEW_LINE INDENT for s in [ 0.3 , 0.4 , 0.7 ] : NEW_LINE INDENT xp = xa * ( 1 - t ) + xb * t NEW_LINE yp = ya * ( 1 - s ) + yb * s NEW_LINE zp = ( + lut ( xa , ya ) * ( 1 - t ) * ( 1 - s ) + lut ( xb , ya ) * t * ( 1 - s ) + lut ( xa , yb ) * ( 1 - t ) * s + lut ( xb , yb ) * t * s ) NEW_LINE assert_almost_equal ( lut ( xp , yp ) , zp ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def test_integral ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 8 , 8 , 8 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = array ( [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] ) NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : # ▁ coefficients ▁ of ▁ the ▁ . . . ENDCOM NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT tx , ty = lut . get_knots ( ) NEW_LINE tz = lut ( tx , ty ) NEW_LINE trpz = .25 * ( diff ( tx ) [ : , None ] * diff ( ty ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE # ▁ Test ▁ whether ▁ empty ▁ inputs ▁ returns ▁ an ▁ empty ▁ output . ▁ Ticket ▁ 1014 ENDCOM INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : # ▁ coefficients ▁ of ▁ the ▁ . . . ENDCOM NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT assert_array_equal ( lut ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_equal ( lut ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT DEDENT class TestSmoothBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , ( [ 1 , 1 , 3 , 3 ] , [ 1 , 1 , 3 , 3 ] ) ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 3 , 3 , 3 , 3 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 3 , 3 ] , [ 3 , 3 ] , [ 3 , 3 ] ] ) NEW_LINE DEDENT def test_linear_1d ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 0 , 0 , 0 , 2 , 2 , 2 , 4 , 4 , 4 ] NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , ( [ 1 , 1 , 3 , 3 ] , [ 1 , 1 , 3 , 3 ] ) ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 0 , 0 , 4 , 4 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 0 , 0 ] , [ 1 , 1 ] , [ 2 , 2 ] ] ) NEW_LINE DEDENT def test_integral ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 4 , 4 , 4 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = array ( [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] ) NEW_LINE with warnings . catch_warnings ( ) : NEW_LINE # ▁ This ▁ seems ▁ to ▁ fail ▁ ( ier = 1 , ▁ see ▁ ticket ▁ 1642 ) . ENDCOM INDENT warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 , s = 0 ) NEW_LINE DEDENT tx = [ 1 , 2 , 4 ] NEW_LINE ty = [ 1 , 2 , 3 ] NEW_LINE tz = lut ( tx , ty ) NEW_LINE trpz = .25 * ( diff ( tx ) [ : , None ] * diff ( ty ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz ) NEW_LINE lut2 = SmoothBivariateSpline ( x , y , z , kx = 2 , ky = 2 , s = 0 ) NEW_LINE assert_almost_equal ( lut2 . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz , decimal = 0 ) # ▁ the ▁ quadratures ▁ give ▁ 23.75 ▁ and ▁ 23.85 ENDCOM NEW_LINE tz = lut ( tx [ : - 1 ] , ty [ : - 1 ] ) NEW_LINE trpz = .25 * ( diff ( tx [ : - 1 ] ) [ : , None ] * diff ( ty [ : - 1 ] ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 2 ] , ty [ 0 ] , ty [ - 2 ] ) , trpz ) NEW_LINE DEDENT def test_rerun_lwrk2_too_small ( self ) : NEW_LINE # ▁ in ▁ this ▁ setting , ▁ lwrk2 ▁ is ▁ too ▁ small ▁ in ▁ the ▁ default ▁ run . ▁ Here ▁ we ENDCOM # ▁ check ▁ for ▁ equality ▁ with ▁ the ▁ bisplrep / bisplev ▁ output ▁ because ▁ there , ENDCOM # ▁ an ▁ automatic ▁ re - run ▁ of ▁ the ▁ spline ▁ representation ▁ is ▁ done ▁ if ▁ ier > 10 . ENDCOM INDENT x = np . linspace ( - 2 , 2 , 80 ) NEW_LINE y = np . linspace ( - 2 , 2 , 80 ) NEW_LINE z = x + y NEW_LINE xi = np . linspace ( - 1 , 1 , 100 ) NEW_LINE yi = np . linspace ( - 2 , 2 , 100 ) NEW_LINE tck = bisplrep ( x , y , z ) NEW_LINE res1 = bisplev ( xi , yi , tck ) NEW_LINE interp_ = SmoothBivariateSpline ( x , y , z ) NEW_LINE res2 = interp_ ( xi , yi ) NEW_LINE assert_almost_equal ( res1 , res2 ) NEW_LINE DEDENT DEDENT class TestLSQSphereBivariateSpline ( TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE # ▁ define ▁ the ▁ input ▁ data ▁ and ▁ coordinates ENDCOM INDENT ntheta , nphi = 70 , 90 NEW_LINE theta = linspace ( 0.5 / ( ntheta - 1 ) , 1 - 0.5 / ( ntheta - 1 ) , ntheta ) * pi NEW_LINE phi = linspace ( 0.5 / ( nphi - 1 ) , 1 - 0.5 / ( nphi - 1 ) , nphi ) * 2. * pi NEW_LINE data = ones ( ( theta . shape [ 0 ] , phi . shape [ 0 ] ) ) NEW_LINE # ▁ define ▁ knots ▁ and ▁ extract ▁ data ▁ values ▁ at ▁ the ▁ knots ENDCOM knotst = theta [ : : 5 ] NEW_LINE knotsp = phi [ : : 5 ] NEW_LINE knotdata = data [ : : 5 , : : 5 ] NEW_LINE # ▁ calculate ▁ spline ▁ coefficients ENDCOM lats , lons = meshgrid ( theta , phi ) NEW_LINE lut_lsq = LSQSphereBivariateSpline ( lats . ravel ( ) , lons . ravel ( ) , data . T . ravel ( ) , knotst , knotsp ) NEW_LINE self . lut_lsq = lut_lsq NEW_LINE self . data = knotdata NEW_LINE self . new_lons , self . new_lats = knotsp , knotst NEW_LINE DEDENT def test_linear_constant ( self ) : NEW_LINE INDENT assert_almost_equal ( self . lut_lsq . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( self . lut_lsq ( self . new_lats , self . new_lons ) , self . data ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE INDENT assert_array_almost_equal ( self . lut_lsq ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_almost_equal ( self . lut_lsq ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT DEDENT class TestSmoothSphereBivariateSpline ( TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT theta = array ( [ .25 * pi , .25 * pi , .25 * pi , .5 * pi , .5 * pi , .5 * pi , .75 * pi , .75 * pi , .75 * pi ] ) NEW_LINE phi = array ( [ .5 * pi , pi , 1.5 * pi , .5 * pi , pi , 1.5 * pi , .5 * pi , pi , 1.5 * pi ] ) NEW_LINE r = array ( [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] ) NEW_LINE self . lut = SmoothSphereBivariateSpline ( theta , phi , r , s = 1E10 ) NEW_LINE DEDENT def test_linear_constant ( self ) : NEW_LINE INDENT assert_almost_equal ( self . lut . get_residual ( ) , 0. ) NEW_LINE assert_array_almost_equal ( self . lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 3 , 3 ] , [ 3 , 3 ] , [ 3 , 3 ] ] ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE INDENT assert_array_almost_equal ( self . lut ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_almost_equal ( self . lut ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT DEDENT class TestRectBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_defaults ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y ) , z ) NEW_LINE DEDENT def test_evaluate ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE xi = [ 1 , 2.3 , 5.3 , 0.5 , 3.3 , 1.2 , 3 ] NEW_LINE yi = [ 1 , 3.3 , 1.2 , 4.0 , 5.0 , 1.0 , 3 ] NEW_LINE zi = lut . ev ( xi , yi ) NEW_LINE zi2 = array ( [ lut ( xp , yp ) [ 0 , 0 ] for xp , yp in zip ( xi , yi ) ] ) NEW_LINE assert_almost_equal ( zi , zi2 ) NEW_LINE DEDENT def test_derivatives_grid ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE dx = array ( [ [ 0 , 0 , - 20 , 0 , 0 ] , [ 0 , 0 , 13 , 0 , 0 ] , [ 0 , 0 , 4 , 0 , 0 ] , [ 0 , 0 , - 11 , 0 , 0 ] , [ 0 , 0 , 4 , 0 , 0 ] ] ) / 6. NEW_LINE dy = array ( [ [ 4 , - 1 , 0 , 1 , - 4 ] , [ 4 , - 1 , 0 , 1 , - 4 ] , [ 0 , 1.5 , 0 , - 1.5 , 0 ] , [ 2 , .25 , 0 , - .25 , - 2 ] , [ 4 , - 1 , 0 , 1 , - 4 ] ] ) NEW_LINE dxdy = array ( [ [ 40 , - 25 , 0 , 25 , - 40 ] , [ - 26 , 16.25 , 0 , - 16.25 , 26 ] , [ - 8 , 5 , 0 , - 5 , 8 ] , [ 22 , - 13.75 , 0 , 13.75 , - 22 ] , [ - 8 , 5 , 0 , - 5 , 8 ] ] ) / 6. NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 ) , dx ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dy = 1 ) , dy ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , dy = 1 ) , dxdy ) NEW_LINE DEDENT def test_derivatives ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE dx = array ( [ 0 , 0 , 2. / 3 , 0 , 0 ] ) NEW_LINE dy = array ( [ 4 , - 1 , 0 , - .25 , - 4 ] ) NEW_LINE dxdy = array ( [ 160 , 65 , 0 , 55 , 32 ] ) / 24. NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , grid = False ) , dx ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dy = 1 , grid = False ) , dy ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , dy = 1 , grid = False ) , dxdy ) NEW_LINE DEDENT def test_broadcast ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_allclose ( lut ( x , y ) , lut ( x [ : , None ] , y [ None , : ] , grid = False ) ) NEW_LINE DEDENT DEDENT class TestRectSphereBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_defaults ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y ) , z ) NEW_LINE DEDENT def test_evaluate ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE yi = [ 0.2 , 1 , 2.3 , 2.35 , 3.0 , 3.99 , 5.25 ] NEW_LINE xi = [ 1.5 , 0.4 , 1.1 , 0.45 , 0.2345 , 1. , 0.0001 ] NEW_LINE zi = lut . ev ( xi , yi ) NEW_LINE zi2 = array ( [ lut ( xp , yp ) [ 0 , 0 ] for xp , yp in zip ( xi , yi ) ] ) NEW_LINE assert_almost_equal ( zi , zi2 ) NEW_LINE DEDENT def test_derivatives_grid ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE y = linspace ( 0.02 , 2 * pi - 0.02 , 7 ) NEW_LINE x = linspace ( 0.02 , pi - 0.02 , 7 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 ) , _numdiff_2d ( lut , x , y , dx = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dphi = 1 ) , _numdiff_2d ( lut , x , y , dy = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , dphi = 1 ) , _numdiff_2d ( lut , x , y , dx = 1 , dy = 1 , eps = 1e-6 ) , rtol = 1e-3 , atol = 1e-3 ) NEW_LINE DEDENT def test_derivatives ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE y = linspace ( 0.02 , 2 * pi - 0.02 , 7 ) NEW_LINE x = linspace ( 0.02 , pi - 0.02 , 7 ) NEW_LINE assert_equal ( lut ( x , y , dtheta = 1 , grid = False ) . shape , x . shape ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dx = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dphi = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dy = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , dphi = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dx = 1 , dy = 1 , eps = 1e-6 ) , rtol = 1e-3 , atol = 1e-3 ) NEW_LINE DEDENT DEDENT def _numdiff_2d ( func , x , y , dx = 0 , dy = 0 , eps = 1e-8 ) : NEW_LINE INDENT if dx == 0 and dy == 0 : NEW_LINE INDENT return func ( x , y ) NEW_LINE DEDENT elif dx == 1 and dy == 0 : NEW_LINE INDENT return ( func ( x + eps , y ) - func ( x - eps , y ) ) / ( 2 * eps ) NEW_LINE DEDENT elif dx == 0 and dy == 1 : NEW_LINE INDENT return ( func ( x , y + eps ) - func ( x , y - eps ) ) / ( 2 * eps ) NEW_LINE DEDENT elif dx == 1 and dy == 1 : NEW_LINE INDENT return ( func ( x + eps , y + eps ) - func ( x - eps , y + eps ) - func ( x + eps , y - eps ) + func ( x - eps , y - eps ) ) / ( 2 * eps ) ** 2 NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " invalid ▁ derivative ▁ order " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT run_module_suite ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="chenlian2015/skia_from_google/tree/master/tools/skp/page_sets/skia_youtube_desktop.py"> # ▁ Copyright ▁ 2014 ▁ The ▁ Chromium ▁ Authors . ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Use ▁ of ▁ this ▁ source ▁ code ▁ is ▁ governed ▁ by ▁ a ▁ BSD - style ▁ license ▁ that ▁ can ▁ be ENDCOM # ▁ found ▁ in ▁ the ▁ LICENSE ▁ file . ENDCOM # ▁ pylint : ▁ disable = W0401 , W0614 ENDCOM from telemetry . page import page as page_module NEW_LINE from telemetry . page import page_set as page_set_module NEW_LINE class SkiaBuildbotDesktopPage ( page_module . Page ) : NEW_LINE INDENT def __init__ ( self , url , page_set ) : NEW_LINE INDENT super ( SkiaBuildbotDesktopPage , self ) . __init__ ( url = url , page_set = page_set , credentials_path = ' data / credentials . json ' ) NEW_LINE self . user_agent_type = ' desktop ' NEW_LINE self . archive_data_file = ' data / skia _ youtube _ desktop . json ' NEW_LINE DEDENT def RunNavigateSteps ( self , action_runner ) : NEW_LINE INDENT action_runner . NavigateToPage ( self ) NEW_LINE action_runner . Wait ( 25 ) NEW_LINE DEDENT DEDENT class SkiaYoutubeDesktopPageSet ( page_set_module . PageSet ) : NEW_LINE INDENT """ ▁ Pages ▁ designed ▁ to ▁ represent ▁ the ▁ median , ▁ not ▁ highly ▁ optimized ▁ web ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT super ( SkiaYoutubeDesktopPageSet , self ) . __init__ ( user_agent_type = ' desktop ' , archive_data_file = ' data / skia _ youtube _ desktop . json ' ) NEW_LINE urls_list = [ # ▁ Why : ▁ # 3 ▁ ( Alexa ▁ global ) ENDCOM ' http : / / www . youtube . com / watch ? v = PC57z - oDPLs ' , ] NEW_LINE for url in urls_list : NEW_LINE INDENT self . AddPage ( SkiaBuildbotDesktopPage ( url , self ) ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="brandonivey/django-marimo/tree/master/marimo/templatetags/writecapture.py"> import json NEW_LINE import random NEW_LINE from django import template NEW_LINE import logging NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE register = template . Library ( ) NEW_LINE def jsescape ( string ) : NEW_LINE INDENT """ ▁ escaping ▁ so ▁ that ▁ javascript ▁ can ▁ be ▁ safely ▁ put ▁ into ▁ json ▁ dicts STRNEWLINE ▁ for ▁ some ▁ reason ▁ json ▁ newline ▁ escaping ▁ isn ' t ▁ enough ? ? STRNEWLINE ▁ """ NEW_LINE return string . replace ( ' < script ' , ' $ BEGINSCRIPT ' ) . replace ( ' < / script > ' , ' $ ENDSCRIPT ' ) . replace ( ' \n ' , ' $ NEWLINE ' ) . replace ( ' ' , ' ' ) NEW_LINE DEDENT @ register . tag ( name = ' writecapture ' ) NEW_LINE def write_capture ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture ▁ [ filter ] ▁ [ " prototype " ] ▁ [ " widget _ id " ] ▁ % } STRNEWLINE ▁ < script ▁ src = " evil . js " > STRNEWLINE ▁ document . write ( ' this ▁ is ▁ evil ' ) STRNEWLINE ▁ < script > STRNEWLINE ▁ { % ▁ endwritecapture ▁ % } STRNEWLINE STRNEWLINE ▁ Wraps ▁ the ▁ enclosed ▁ HTML ▁ inside ▁ of ▁ a ▁ marimo ▁ writecapture ▁ widget . STRNEWLINE STRNEWLINE ▁ The ▁ ` ` filter ` ` ▁ argument ▁ is ▁ a ▁ boolean ▁ ( default ▁ False ) ▁ that ▁ turns ▁ on ▁ a STRNEWLINE ▁ writecapture ▁ feature ▁ called ▁ writeOnGetElementById . ▁ This ▁ fixes ▁ some STRNEWLINE ▁ extra - bad ▁ scripts . STRNEWLINE STRNEWLINE ▁ The ▁ ` ` prototype ` ` ▁ argument ▁ defaults ▁ to ▁ ' writecapture . ' ▁ You ▁ will ▁ only STRNEWLINE ▁ need ▁ to ▁ use ▁ this ▁ if ▁ you ▁ have ▁ subclassed ▁ marimo ' s ▁ built - in ▁ writecapture STRNEWLINE ▁ widget ▁ and ▁ want ▁ to ▁ use ▁ that ▁ instead . STRNEWLINE STRNEWLINE ▁ The ▁ ` ` widget _ id ` ` ▁ argument ▁ defaults ▁ to ▁ a ▁ ' writecapture _ < randomnumber > . ' STRNEWLINE ▁ Use ▁ this ▁ only ▁ if ▁ you ▁ need ▁ to ▁ specify ▁ an ▁ alternate ▁ element ▁ id ▁ in ▁ the ▁ DOM STRNEWLINE ▁ to ▁ write ▁ to ▁ ( otherwise ▁ one ▁ will ▁ be ▁ created ▁ for ▁ you ▁ at ▁ the ▁ site ▁ of ▁ the STRNEWLINE ▁ { % writecapture % } ▁ invocation ) . . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE # ▁ TODO ▁ should ▁ work ▁ with ▁ marimo ▁ fast ▁ and ▁ widget _ id ▁ should ▁ be ▁ resolved ▁ maybe ENDCOM tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 4 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture ▁ block ▁ takes ▁ at ▁ most ▁ 3 ▁ arguments " ) NEW_LINE DEDENT nodelist = parser . parse ( ( ' endwritecapture ' , ) ) NEW_LINE parser . delete_first_token ( ) NEW_LINE if len ( tokens ) > 1 : NEW_LINE INDENT script_filter = tokens [ 1 ] NEW_LINE if script_filter == ' False ' : NEW_LINE INDENT script_filter = False NEW_LINE DEDENT elif script_filter == ' True ' : NEW_LINE INDENT script_filter = True NEW_LINE DEDENT else : NEW_LINE INDENT script_filter = template . Variable ( script_filter ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT script_filter = False NEW_LINE DEDENT return WriteCaptureNode ( nodelist , script_filter , * tokens [ 2 : ] ) NEW_LINE DEDENT class WriteCaptureNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , nodelist , script_filter = False , prototype = ' writecapture _ widget ' , widget_id = None ) : NEW_LINE INDENT self . nodelist = nodelist NEW_LINE self . script_filter = script_filter NEW_LINE self . prototype = prototype NEW_LINE self . widget_id = widget_id NEW_LINE if not self . widget_id : NEW_LINE INDENT self . widget_id = ' writecapture ' + str ( random . randint ( 0 , 99999999 ) ) NEW_LINE DEDENT DEDENT def render ( self , context ) : NEW_LINE INDENT eviloutput = jsescape ( self . nodelist . render ( context ) ) NEW_LINE if isinstance ( self . script_filter , template . Variable ) : NEW_LINE INDENT self . script_filter = bool ( self . script_filter . resolve ( context ) ) NEW_LINE # ▁ Set ▁ this ▁ flag ▁ in ▁ your ▁ template ▁ tag ▁ for ▁ advanced ▁ write ▁ capture ▁ widget ▁ sanitation . ENDCOM # ▁ Source : ▁ https : / / github . com / iamnoah / writeCapture / wiki / Usage ENDCOM DEDENT global_compatibility_mode = context . get ( ' wc _ compatibility _ mode ' , None ) NEW_LINE if global_compatibility_mode is None : NEW_LINE INDENT wc_compatibility_mode = self . script_filter NEW_LINE DEDENT else : NEW_LINE INDENT wc_compatibility_mode = global_compatibility_mode NEW_LINE DEDENT widget_dict = dict ( widget_prototype = self . prototype , id = self . widget_id , html = eviloutput , wc_compatibility_mode = wc_compatibility_mode , ) NEW_LINE output = """ < div ▁ id = " { widget _ id } " > < / div > STRNEWLINE < script ▁ type = " text / javascript " > STRNEWLINE ▁ ▁ ▁ ▁ marimo . emit ( ' { widget _ id } _ ready ' ) ; STRNEWLINE ▁ ▁ ▁ ▁ marimo . add _ widget ( { widget _ json } ) ; STRNEWLINE < / script > """ NEW_LINE output = output . format ( widget_id = self . widget_id , widget_json = json . dumps ( widget_dict ) , ) NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture _ delay ▁ [ event _ name ] ▁ % } STRNEWLINE ▁ """ NEW_LINE tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE # ▁ this ▁ should ▁ only ▁ be ▁ used ▁ once ▁ per ▁ page ▁ if ▁ it ' s ▁ uses ▁ a ▁ second ▁ time ENDCOM # ▁ overwrite ▁ but ▁ log ▁ an ▁ error ENDCOM DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture _ delay ▁ [ event _ name ] ▁ % } STRNEWLINE ▁ """ NEW_LINE tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE # ▁ this ▁ should ▁ only ▁ be ▁ used ▁ once ▁ per ▁ page ▁ if ▁ it ' s ▁ uses ▁ a ▁ second ▁ time ENDCOM # ▁ overwrite ▁ but ▁ log ▁ an ▁ error ENDCOM DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture _ delay ▁ [ event _ name ] ▁ % } STRNEWLINE ▁ """ NEW_LINE tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE # ▁ this ▁ should ▁ only ▁ be ▁ used ▁ once ▁ per ▁ page ▁ if ▁ it ' s ▁ uses ▁ a ▁ second ▁ time ENDCOM # ▁ overwrite ▁ but ▁ log ▁ an ▁ error ENDCOM DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="FHannes/intellij-community/tree/master/python/testData/intentions/returnTypeInPy3Annotation2_after.py"> def my_func ( p1 = 1 ) -> object : NEW_LINE INDENT return p1 NEW_LINE DEDENT d = my_func ( 1 ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="xadahiya/django/tree/master/django/contrib/admin/actions.py"> """ STRNEWLINE Built - in , ▁ globally - available ▁ admin ▁ actions . STRNEWLINE """ NEW_LINE from django . contrib import messages NEW_LINE from django . contrib . admin import helpers NEW_LINE from django . contrib . admin . utils import get_deleted_objects , model_ngettext NEW_LINE from django . core . exceptions import PermissionDenied NEW_LINE from django . db import router NEW_LINE from django . template . response import TemplateResponse NEW_LINE from django . utils . encoding import force_text NEW_LINE from django . utils . translation import ugettext as _ , ugettext_lazy NEW_LINE def delete_selected ( modeladmin , request , queryset ) : NEW_LINE INDENT """ STRNEWLINE ▁ Default ▁ action ▁ which ▁ deletes ▁ the ▁ selected ▁ objects . STRNEWLINE STRNEWLINE ▁ This ▁ action ▁ first ▁ displays ▁ a ▁ confirmation ▁ page ▁ whichs ▁ shows ▁ all ▁ the STRNEWLINE ▁ deleteable ▁ objects , ▁ or , ▁ if ▁ the ▁ user ▁ has ▁ no ▁ permission ▁ one ▁ of ▁ the ▁ related STRNEWLINE ▁ childs ▁ ( foreignkeys ) , ▁ a ▁ " permission ▁ denied " ▁ message . STRNEWLINE STRNEWLINE ▁ Next , ▁ it ▁ deletes ▁ all ▁ selected ▁ objects ▁ and ▁ redirects ▁ back ▁ to ▁ the ▁ change ▁ list . STRNEWLINE ▁ """ NEW_LINE opts = modeladmin . model . _meta NEW_LINE app_label = opts . app_label NEW_LINE # ▁ Check ▁ that ▁ the ▁ user ▁ has ▁ delete ▁ permission ▁ for ▁ the ▁ actual ▁ model ENDCOM if not modeladmin . has_delete_permission ( request ) : NEW_LINE INDENT raise PermissionDenied NEW_LINE DEDENT using = router . db_for_write ( modeladmin . model ) NEW_LINE # ▁ Populate ▁ deletable _ objects , ▁ a ▁ data ▁ structure ▁ of ▁ all ▁ related ▁ objects ▁ that ENDCOM # ▁ will ▁ also ▁ be ▁ deleted . ENDCOM deletable_objects , model_count , perms_needed , protected = get_deleted_objects ( queryset , opts , request . user , modeladmin . admin_site , using ) NEW_LINE # ▁ The ▁ user ▁ has ▁ already ▁ confirmed ▁ the ▁ deletion . ENDCOM # ▁ Do ▁ the ▁ deletion ▁ and ▁ return ▁ a ▁ None ▁ to ▁ display ▁ the ▁ change ▁ list ▁ view ▁ again . ENDCOM if request . POST . get ( ' post ' ) : NEW_LINE INDENT if perms_needed : NEW_LINE INDENT raise PermissionDenied NEW_LINE DEDENT n = queryset . count ( ) NEW_LINE if n : NEW_LINE INDENT for obj in queryset : NEW_LINE INDENT obj_display = force_text ( obj ) NEW_LINE modeladmin . log_deletion ( request , obj , obj_display ) NEW_LINE DEDENT queryset . delete ( ) NEW_LINE modeladmin . message_user ( request , _ ( " Successfully ▁ deleted ▁ % ( count ) d ▁ % ( items ) s . " ) % { " count " : n , " items " : model_ngettext ( modeladmin . opts , n ) } , messages . SUCCESS ) NEW_LINE # ▁ Return ▁ None ▁ to ▁ display ▁ the ▁ change ▁ list ▁ page ▁ again . ENDCOM DEDENT return None NEW_LINE DEDENT if len ( queryset ) == 1 : NEW_LINE INDENT objects_name = force_text ( opts . verbose_name ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_name = force_text ( opts . verbose_name_plural ) NEW_LINE DEDENT if perms_needed or protected : NEW_LINE INDENT title = _ ( " Cannot ▁ delete ▁ % ( name ) s " ) % { " name " : objects_name } NEW_LINE DEDENT else : NEW_LINE INDENT title = _ ( " Are ▁ you ▁ sure ? " ) NEW_LINE DEDENT context = dict ( modeladmin . admin_site . each_context ( request ) , title = title , objects_name = objects_name , deletable_objects = [ deletable_objects ] , model_count = dict ( model_count ) . items ( ) , queryset = queryset , perms_lacking = perms_needed , protected = protected , opts = opts , action_checkbox_name = helpers . ACTION_CHECKBOX_NAME , ) NEW_LINE request . current_app = modeladmin . admin_site . name NEW_LINE # ▁ Display ▁ the ▁ confirmation ▁ page ENDCOM return TemplateResponse ( request , modeladmin . delete_selected_confirmation_template or [ " admin / % s / % s / delete _ selected _ confirmation . html " % ( app_label , opts . model_name ) , " admin / % s / delete _ selected _ confirmation . html " % app_label , " admin / delete _ selected _ confirmation . html " ] , context ) NEW_LINE DEDENT delete_selected . short_description = ugettext_lazy ( " Delete ▁ selected ▁ % ( verbose _ name _ plural ) s " ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="andyzsf/edx/tree/master/common/djangoapps/student/migrations/0020_add_test_center_user.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE # ▁ Adding ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . create_table ( ' student _ testcenteruser ' , ( ( ' id ' , self . gf ( ' django . db . models . fields . AutoField ' ) ( primary_key = True ) ) , ( ' user ' , self . gf ( ' django . db . models . fields . related . ForeignKey ' ) ( default = None , to = orm [ ' auth . User ' ] , unique = True ) ) , ( ' created _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now_add = True , db_index = True , blank = True ) ) , ( ' updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now = True , db_index = True , blank = True ) ) , ( ' user _ updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( db_index = True ) ) , ( ' candidate _ id ' , self . gf ( ' django . db . models . fields . IntegerField ' ) ( null = True , db_index = True ) ) , ( ' client _ candidate _ id ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' first _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , db_index = True ) ) , ( ' last _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' middle _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , blank = True ) ) , ( ' suffix ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 255 , blank = True ) ) , ( ' salutation ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ( ' address _ 1' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 ) ) , ( ' address _ 2' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' address _ 3' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' city ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 32 , db_index = True ) ) , ( ' state ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 20 , blank = True ) ) , ( ' postal _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 16 , blank = True ) ) , ( ' country ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' phone ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 ) ) , ( ' extension ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 8 , blank = True ) ) , ( ' phone _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' fax ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 , blank = True ) ) , ( ' fax _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , blank = True ) ) , ( ' company _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ) ) NEW_LINE db . send_create_signal ( ' student ' , [ ' TestCenterUser ' ] ) NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE # ▁ Deleting ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . delete_table ( ' student _ testcenteruser ' ) NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , ' auth . user ' : { ' Meta ' : { ' object _ name ' : ' User ' } , ' about ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' avatar _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' n ' " , ' max _ length ' : '1' } ) , ' bronze ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' consecutive _ days _ visit _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' country ' : ( ' django _ countries . fields . CountryField ' , [ ] , { ' max _ length ' : '2' , ' blank ' : ' True ' } ) , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' date _ of _ birth ' : ( ' django . db . models . fields . DateField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' display _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' email _ isvalid ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' email _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' null ' : ' True ' } ) , ' email _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' gold ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' gravatar ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' ignored _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' interesting _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' last _ seen ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' new _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' questions _ per _ page ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '10' } ) , ' real _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' reputation ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' default ' : '1' } ) , ' seen _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' show _ country ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' silver ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' status ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' w ' " , ' max _ length ' : '2' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) , ' website ' : ( ' django . db . models . fields . URLField ' , [ ] , { ' max _ length ' : '200' , ' blank ' : ' True ' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' student . courseenrollment ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' user ' , ▁ ' course _ id ' ) , ) " , ' object _ name ' : ' CourseEnrollment ' } , ' course _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " } ) } , ' student . pendingemailchange ' : { ' Meta ' : { ' object _ name ' : ' PendingEmailChange ' } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ email ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . pendingnamechange ' : { ' Meta ' : { ' object _ name ' : ' PendingNameChange ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' rationale ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '1024' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . registration ' : { ' Meta ' : { ' object _ name ' : ' Registration ' , ' db _ table ' : " ' auth _ registration ' " } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . testcenteruser ' : { ' Meta ' : { ' object _ name ' : ' TestCenterUser ' } , ' address _ 1' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' } ) , ' address _ 2' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' address _ 3' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' candidate _ id ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' null ' : ' True ' , ' db _ index ' : ' True ' } ) , ' city ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' client _ candidate _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' company _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' country ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' created _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' extension ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '8' , ' blank ' : ' True ' } ) , ' fax ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' , ' blank ' : ' True ' } ) , ' fax _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' middle _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' phone ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' } ) , ' phone _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' postal _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '16' , ' blank ' : ' True ' } ) , ' salutation ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' state ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '20' , ' blank ' : ' True ' } ) , ' suffix ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' default ' : ' None ' , ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) , ' user _ updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' student . userprofile ' : { ' Meta ' : { ' object _ name ' : ' UserProfile ' , ' db _ table ' : " ' auth _ userprofile ' " } , ' courseware ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' course . xml ' " , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' gender ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' goals ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' level _ of _ education ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' mailing _ address ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' profile ' " , ' unique ' : ' True ' , ' to ' : " orm [ ' auth . User ' ] " } ) , ' year _ of _ birth ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' student . usertestgroup ' : { ' Meta ' : { ' object _ name ' : ' UserTestGroup ' } , ' description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' users ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' db _ index ' : ' True ' , ' symmetrical ' : ' False ' } ) } } NEW_LINE complete_apps = [ ' student ' ] NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="ffantast/magnum/tree/master/magnum/tests/unit/objects/test_objects.py"> # ▁ Copyright ▁ 2015 ▁ IBM ▁ Corp . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM import datetime NEW_LINE import gettext NEW_LINE import iso8601 NEW_LINE import netaddr NEW_LINE from oslo_utils import timeutils NEW_LINE from oslo_versionedobjects import fields NEW_LINE from magnum . common import context as magnum_context NEW_LINE from magnum . common import exception NEW_LINE from magnum . objects import base NEW_LINE from magnum . objects import utils NEW_LINE from magnum . tests import base as test_base NEW_LINE gettext . install ( ' magnum ' ) NEW_LINE @ base . MagnumObjectRegistry . register NEW_LINE class MyObj ( base . MagnumObject ) : NEW_LINE INDENT VERSION = '1.0' NEW_LINE fields = { ' foo ' : fields . IntegerField ( ) , ' bar ' : fields . StringField ( ) , ' missing ' : fields . StringField ( ) , } NEW_LINE def obj_load_attr ( self , attrname ) : NEW_LINE INDENT setattr ( self , attrname , ' loaded ! ' ) NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def query ( cls , context ) : NEW_LINE INDENT obj = cls ( context ) NEW_LINE obj . foo = 1 NEW_LINE obj . bar = ' bar ' NEW_LINE obj . obj_reset_changes ( ) NEW_LINE return obj NEW_LINE DEDENT @ base . remotable NEW_LINE def marco ( self , context ) : NEW_LINE INDENT return ' polo ' NEW_LINE DEDENT @ base . remotable NEW_LINE def update_test ( self , context ) : NEW_LINE INDENT if context . project_id == ' alternate ' : NEW_LINE INDENT self . bar = ' alternate - context ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bar = ' updated ' NEW_LINE DEDENT DEDENT @ base . remotable NEW_LINE def save ( self , context ) : NEW_LINE INDENT self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def refresh ( self , context ) : NEW_LINE INDENT self . foo = 321 NEW_LINE self . bar = ' refreshed ' NEW_LINE self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def modify_save_modify ( self , context ) : NEW_LINE INDENT self . bar = ' meow ' NEW_LINE self . save ( ) NEW_LINE self . foo = 42 NEW_LINE DEDENT DEDENT class MyObj2 ( object ) : NEW_LINE INDENT @ classmethod NEW_LINE def obj_name ( cls ) : NEW_LINE INDENT return ' MyObj ' NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def get ( cls , * args , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class TestSubclassedObject ( MyObj ) : NEW_LINE INDENT fields = { ' new _ field ' : fields . StringField ( ) } NEW_LINE DEDENT class TestUtils ( test_base . TestCase ) : NEW_LINE INDENT def test_datetime_or_none ( self ) : NEW_LINE INDENT naive_dt = datetime . datetime . now ( ) NEW_LINE dt = timeutils . parse_isotime ( timeutils . isotime ( naive_dt ) ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , dt ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , naive_dt . replace ( tzinfo = iso8601 . iso8601 . Utc ( ) , microsecond = 0 ) ) NEW_LINE self . assertIsNone ( utils . datetime_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_none , ' foo ' ) NEW_LINE DEDENT def test_datetime_or_str_or_none ( self ) : NEW_LINE INDENT dts = timeutils . isotime ( ) NEW_LINE dt = timeutils . parse_isotime ( dts ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dt ) , dt ) NEW_LINE self . assertIsNone ( utils . datetime_or_str_or_none ( None ) ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dts ) , dt ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_str_or_none , ' foo ' ) NEW_LINE DEDENT def test_int_or_none ( self ) : NEW_LINE INDENT self . assertEqual ( utils . int_or_none ( 1 ) , 1 ) NEW_LINE self . assertEqual ( utils . int_or_none ( '1' ) , 1 ) NEW_LINE self . assertIsNone ( utils . int_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . int_or_none , ' foo ' ) NEW_LINE DEDENT def test_str_or_none ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT pass NEW_LINE DEDENT self . assertEqual ( utils . str_or_none ( ' foo ' ) , ' foo ' ) NEW_LINE self . assertEqual ( utils . str_or_none ( 1 ) , '1' ) NEW_LINE self . assertIsNone ( utils . str_or_none ( None ) ) NEW_LINE DEDENT def test_ip_or_none ( self ) : NEW_LINE INDENT ip4 = netaddr . IPAddress ( '1.2.3.4' , 4 ) NEW_LINE ip6 = netaddr . IPAddress ( '1 : : 2' , 6 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 4 ) ( '1.2.3.4' ) , ip4 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 6 ) ( '1 : : 2' ) , ip6 ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 4 ) ( None ) ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 6 ) ( None ) ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 4 ) , ' foo ' ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 6 ) , ' foo ' ) NEW_LINE DEDENT def test_dt_serializer ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT foo = utils . dt_serializer ( ' bar ' ) NEW_LINE DEDENT obj = Obj ( ) NEW_LINE obj . bar = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( '1955-11-05T00:00:00Z ' , obj . foo ( ) ) NEW_LINE obj . bar = None NEW_LINE self . assertIsNone ( obj . foo ( ) ) NEW_LINE obj . bar = ' foo ' NEW_LINE self . assertRaises ( AttributeError , obj . foo ) NEW_LINE DEDENT def test_dt_deserializer ( self ) : NEW_LINE INDENT dt = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( utils . dt_deserializer ( None , timeutils . isotime ( dt ) ) , dt ) NEW_LINE self . assertIsNone ( utils . dt_deserializer ( None , None ) ) NEW_LINE self . assertRaises ( ValueError , utils . dt_deserializer , None , ' foo ' ) NEW_LINE DEDENT DEDENT class _TestObject ( object ) : NEW_LINE INDENT def test_hydration_type_error ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : ' a ' } } NEW_LINE self . assertRaises ( ValueError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_hydration ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_hydration_bad_ns ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' foo ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE self . assertRaises ( exception . UnsupportedObjectError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_dehydration ( self ) : NEW_LINE INDENT expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_get_updates ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_object_property ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_object_property_type_error ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE def fail ( ) : NEW_LINE INDENT obj . foo = ' a ' NEW_LINE DEDENT self . assertRaises ( ValueError , fail ) NEW_LINE DEDENT def test_load ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE DEDENT def test_load_in_base ( self ) : NEW_LINE INDENT class Foo ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foobar ' : fields . IntegerField ( ) } NEW_LINE DEDENT obj = Foo ( self . context ) NEW_LINE # ▁ NOTE ( danms ) : ▁ Can ' t ▁ use ▁ assertRaisesRegexp ( ) ▁ because ▁ of ▁ py26 ENDCOM raised = False NEW_LINE try : NEW_LINE INDENT obj . foobar NEW_LINE DEDENT except NotImplementedError as ex : NEW_LINE INDENT raised = True NEW_LINE DEDENT self . assertTrue ( raised ) NEW_LINE self . assertTrue ( ' foobar ' in str ( ex ) ) NEW_LINE DEDENT def test_loaded_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' bar ' ] , ' magnum _ object . data ' : { ' foo ' : 1 , ' bar ' : ' loaded ! ' } } NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_changes_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE primitive = obj . obj_to_primitive ( ) NEW_LINE self . assertTrue ( ' magnum _ object . changes ' in primitive ) NEW_LINE obj2 = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj2 . obj_what_changed ( ) ) NEW_LINE obj2 . obj_reset_changes ( ) NEW_LINE self . assertEqual ( set ( ) , obj2 . obj_what_changed ( ) ) NEW_LINE DEDENT def test_unknown_objtype ( self ) : NEW_LINE INDENT self . assertRaises ( exception . UnsupportedObjectError , base . MagnumObject . obj_class_from_name , ' foo ' , '1.0' ) NEW_LINE DEDENT def test_with_alternate_context ( self ) : NEW_LINE INDENT context1 = magnum_context . RequestContext ( ' foo ' , ' foo ' ) NEW_LINE context2 = magnum_context . RequestContext ( ' bar ' , project_id = ' alternate ' ) NEW_LINE obj = MyObj . query ( context1 ) NEW_LINE obj . update_test ( context2 ) NEW_LINE self . assertEqual ( ' alternate - context ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_orphaned_object ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . _context = None NEW_LINE self . assertRaises ( exception . OrphanedObjectError , obj . update_test ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_1 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . update_test ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_2 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . save ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_3 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . refresh ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 321 , obj . foo ) NEW_LINE self . assertEqual ( ' refreshed ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_4 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . bar = ' something ' NEW_LINE self . assertEqual ( set ( [ ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . modify_save_modify ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 42 , obj . foo ) NEW_LINE self . assertEqual ( ' meow ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_static_result ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( ' bar ' , obj . bar ) NEW_LINE result = obj . marco ( ) NEW_LINE self . assertEqual ( ' polo ' , result ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_updates ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE obj . update_test ( ) NEW_LINE self . assertEqual ( ' updated ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_base_attributes ( self ) : NEW_LINE INDENT dt = datetime . datetime ( 1955 , 11 , 5 ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . created_at = dt NEW_LINE obj . updated_at = dt NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' created _ at ' , ' updated _ at ' ] , ' magnum _ object . data ' : { ' created _ at ' : timeutils . isotime ( dt ) , ' updated _ at ' : timeutils . isotime ( dt ) } } NEW_LINE actual = obj . obj_to_primitive ( ) NEW_LINE # ▁ magnum _ object . changes ▁ is ▁ built ▁ from ▁ a ▁ set ▁ and ▁ order ▁ is ▁ undefined ENDCOM self . assertEqual ( sorted ( expected [ ' magnum _ object . changes ' ] ) , sorted ( actual [ ' magnum _ object . changes ' ] ) ) NEW_LINE del expected [ ' magnum _ object . changes ' ] , actual [ ' magnum _ object . changes ' ] NEW_LINE self . assertEqual ( expected , actual ) NEW_LINE DEDENT def test_contains ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertFalse ( ' foo ' in obj ) NEW_LINE obj . foo = 1 NEW_LINE self . assertTrue ( ' foo ' in obj ) NEW_LINE self . assertFalse ( ' does _ not _ exist ' in obj ) NEW_LINE DEDENT def test_obj_attr_is_set ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertTrue ( obj . obj_attr_is_set ( ' foo ' ) ) NEW_LINE self . assertFalse ( obj . obj_attr_is_set ( ' bar ' ) ) NEW_LINE self . assertRaises ( AttributeError , obj . obj_attr_is_set , ' bang ' ) NEW_LINE DEDENT def test_get ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE # ▁ Foo ▁ has ▁ value , ▁ should ▁ not ▁ get ▁ the ▁ default ENDCOM self . assertEqual ( obj . get ( ' foo ' , 2 ) , 1 ) NEW_LINE # ▁ Foo ▁ has ▁ value , ▁ should ▁ return ▁ the ▁ value ▁ without ▁ error ENDCOM self . assertEqual ( obj . get ( ' foo ' ) , 1 ) NEW_LINE # ▁ Bar ▁ is ▁ not ▁ loaded , ▁ so ▁ we ▁ should ▁ get ▁ the ▁ default ENDCOM self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' not - loaded ' ) NEW_LINE # ▁ Bar ▁ without ▁ a ▁ default ▁ should ▁ lazy - load ENDCOM self . assertEqual ( obj . get ( ' bar ' ) , ' loaded ! ' ) NEW_LINE # ▁ Bar ▁ now ▁ has ▁ a ▁ default , ▁ but ▁ loaded ▁ value ▁ should ▁ be ▁ returned ENDCOM self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' loaded ! ' ) NEW_LINE # ▁ Invalid ▁ attribute ▁ should ▁ raise ▁ AttributeError ENDCOM self . assertRaises ( AttributeError , obj . get , ' nothing ' ) NEW_LINE # ▁ . . . even ▁ with ▁ a ▁ default ENDCOM self . assertRaises ( AttributeError , obj . get , ' nothing ' , 3 ) NEW_LINE DEDENT def test_object_inheritance ( self ) : NEW_LINE INDENT base_fields = list ( base . MagnumObject . fields . keys ( ) ) NEW_LINE myobj_fields = [ ' foo ' , ' bar ' , ' missing ' ] + base_fields NEW_LINE myobj3_fields = [ ' new _ field ' ] NEW_LINE self . assertTrue ( issubclass ( TestSubclassedObject , MyObj ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) , len ( MyObj . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) , set ( MyObj . fields . keys ( ) ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) + len ( myobj3_fields ) , len ( TestSubclassedObject . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) | set ( myobj3_fields ) , set ( TestSubclassedObject . fields . keys ( ) ) ) NEW_LINE DEDENT def test_get_changes ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_obj_fields ( self ) : NEW_LINE INDENT class TestObj ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foo ' : fields . IntegerField ( ) } NEW_LINE obj_extra_fields = [ ' bar ' ] NEW_LINE @ property NEW_LINE def bar ( self ) : NEW_LINE INDENT return ' this ▁ is ▁ bar ' NEW_LINE DEDENT DEDENT obj = TestObj ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' created _ at ' , ' updated _ at ' , ' foo ' , ' bar ' ] ) , set ( obj . obj_fields ) ) NEW_LINE DEDENT def test_obj_constructor ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 123 , bar = ' abc ' ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertEqual ( ' abc ' , obj . bar ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE DEDENT DEDENT class TestObjectSerializer ( test_base . TestCase ) : NEW_LINE INDENT def test_object_serialization ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE primitive = ser . serialize_entity ( self . context , obj ) NEW_LINE self . assertTrue ( ' magnum _ object . name ' in primitive ) NEW_LINE obj2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertIsInstance ( obj2 , MyObj ) NEW_LINE self . assertEqual ( self . context , obj2 . _context ) NEW_LINE DEDENT def test_object_serialization_iterables ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE for iterable in ( list , tuple , set ) : NEW_LINE INDENT thing = iterable ( [ obj ] ) NEW_LINE primitive = ser . serialize_entity ( self . context , thing ) NEW_LINE self . assertEqual ( 1 , len ( primitive ) ) NEW_LINE for item in primitive : NEW_LINE INDENT self . assertFalse ( isinstance ( item , base . MagnumObject ) ) NEW_LINE DEDENT thing2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertEqual ( 1 , len ( thing2 ) ) NEW_LINE for item in thing2 : NEW_LINE INDENT self . assertIsInstance ( item , MyObj ) NEW_LINE DEDENT DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="tangyiyong/odoo/tree/master/addons/mrp/wizard/stock_move.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ OpenERP , ▁ Open ▁ Source ▁ Management ▁ Solution ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2004-2010 ▁ Tiny ▁ SPRL ▁ ( < http : / / tiny . be > ) . ENDCOM # ▁ This ▁ program ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ as ENDCOM # ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ENDCOM # ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ this ▁ program . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM from openerp . osv import fields , osv NEW_LINE from openerp . tools import float_compare NEW_LINE from openerp . tools . translate import _ NEW_LINE import openerp . addons . decimal_precision as dp NEW_LINE class stock_move_consume ( osv . osv_memory ) : NEW_LINE INDENT _name = " stock . move . consume " NEW_LINE _description = " Consume ▁ Products " NEW_LINE _columns = { ' product _ id ' : fields . many2one ( ' product . product ' , ' Product ' , required = True , select = True ) , ' product _ qty ' : fields . float ( ' Quantity ' , digits_compute = dp . get_precision ( ' Product ▁ Unit ▁ of ▁ Measure ' ) , required = True ) , ' product _ uom ' : fields . many2one ( ' product . uom ' , ' Product ▁ Unit ▁ of ▁ Measure ' , required = True ) , ' location _ id ' : fields . many2one ( ' stock . location ' , ' Location ' , required = True ) , ' restrict _ lot _ id ' : fields . many2one ( ' stock . production . lot ' , ' Lot ' ) , } NEW_LINE # TOFIX : ▁ product _ uom ▁ should ▁ not ▁ have ▁ different ▁ category ▁ of ▁ default ▁ UOM ▁ of ▁ product . ▁ Qty ▁ should ▁ be ▁ convert ▁ into ▁ UOM ▁ of ▁ original ▁ move ▁ line ▁ before ▁ going ▁ in ▁ consume ▁ and ▁ scrap ENDCOM def default_get ( self , cr , uid , fields , context = None ) : NEW_LINE INDENT if context is None : NEW_LINE INDENT context = { } NEW_LINE DEDENT res = super ( stock_move_consume , self ) . default_get ( cr , uid , fields , context = context ) NEW_LINE move = self . pool . get ( ' stock . move ' ) . browse ( cr , uid , context [ ' active _ id ' ] , context = context ) NEW_LINE if ' product _ id ' in fields : NEW_LINE INDENT res . update ( { ' product _ id ' : move . product_id . id } ) NEW_LINE DEDENT if ' product _ uom ' in fields : NEW_LINE INDENT res . update ( { ' product _ uom ' : move . product_uom . id } ) NEW_LINE DEDENT if ' product _ qty ' in fields : NEW_LINE INDENT res . update ( { ' product _ qty ' : move . product_uom_qty } ) NEW_LINE DEDENT if ' location _ id ' in fields : NEW_LINE INDENT res . update ( { ' location _ id ' : move . location_id . id } ) NEW_LINE DEDENT return res NEW_LINE DEDENT def do_move_consume ( self , cr , uid , ids , context = None ) : NEW_LINE INDENT if context is None : NEW_LINE INDENT context = { } NEW_LINE DEDENT move_obj = self . pool . get ( ' stock . move ' ) NEW_LINE uom_obj = self . pool . get ( ' product . uom ' ) NEW_LINE production_obj = self . pool . get ( ' mrp . production ' ) NEW_LINE move_ids = context [ ' active _ ids ' ] NEW_LINE move = move_obj . browse ( cr , uid , move_ids [ 0 ] , context = context ) NEW_LINE production_id = move . raw_material_production_id . id NEW_LINE production = production_obj . browse ( cr , uid , production_id , context = context ) NEW_LINE precision = self . pool [ ' decimal . precision ' ] . precision_get ( cr , uid , ' Product ▁ Unit ▁ of ▁ Measure ' ) NEW_LINE for data in self . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT qty = uom_obj . _compute_qty ( cr , uid , data [ ' product _ uom ' ] . id , data . product_qty , data . product_id . uom_id . id ) NEW_LINE remaining_qty = move . product_qty - qty NEW_LINE # check ▁ for ▁ product ▁ quantity ▁ is ▁ less ▁ than ▁ previously ▁ planned ENDCOM if float_compare ( remaining_qty , 0 , precision_digits = precision ) >= 0 : NEW_LINE INDENT move_obj . action_consume ( cr , uid , move_ids , qty , data . location_id . id , restrict_lot_id = data . restrict_lot_id . id , context = context ) NEW_LINE DEDENT else : NEW_LINE INDENT consumed_qty = min ( move . product_qty , qty ) NEW_LINE new_moves = move_obj . action_consume ( cr , uid , move_ids , consumed_qty , data . location_id . id , restrict_lot_id = data . restrict_lot_id . id , context = context ) NEW_LINE # consumed ▁ more ▁ in ▁ wizard ▁ than ▁ previously ▁ planned ENDCOM extra_more_qty = qty - consumed_qty NEW_LINE # create ▁ new ▁ line ▁ for ▁ a ▁ remaining ▁ qty ▁ of ▁ the ▁ product ENDCOM extra_move_id = production_obj . _make_consume_line_from_data ( cr , uid , production , data . product_id , data . product_id . uom_id . id , extra_more_qty , False , 0 , context = context ) NEW_LINE move_obj . write ( cr , uid , [ extra_move_id ] , { ' restrict _ lot _ id ' : data . restrict_lot_id . id } , context = context ) NEW_LINE move_obj . action_done ( cr , uid , [ extra_move_id ] , context = context ) NEW_LINE DEDENT DEDENT return { ' type ' : ' ir . actions . act _ window _ close ' } NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="itsjeyd/edx-platform/tree/master/cms/djangoapps/contentstore/tests/test_import_draft_order.py"> """ STRNEWLINE Tests ▁ Draft ▁ import ▁ order . STRNEWLINE """ NEW_LINE from xmodule . modulestore . xml_importer import import_course_from_xml NEW_LINE from xmodule . modulestore . tests . django_utils import ModuleStoreTestCase NEW_LINE from xmodule . modulestore . django import modulestore NEW_LINE from django . conf import settings NEW_LINE TEST_DATA_DIR = settings . COMMON_TEST_DATA_ROOT NEW_LINE # ▁ This ▁ test ▁ is ▁ in ▁ the ▁ CMS ▁ module ▁ because ▁ the ▁ test ▁ configuration ▁ to ▁ use ▁ a ▁ draft ENDCOM # ▁ modulestore ▁ is ▁ dependent ▁ on ▁ django . ENDCOM class DraftReorderTestCase ( ModuleStoreTestCase ) : NEW_LINE INDENT def test_order ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Verify ▁ that ▁ drafts ▁ are ▁ imported ▁ in ▁ the ▁ correct ▁ order . STRNEWLINE ▁ """ NEW_LINE store = modulestore ( ) NEW_LINE course_items = import_course_from_xml ( store , self . user . id , TEST_DATA_DIR , [ ' import _ draft _ order ' ] , create_if_not_present = True ) NEW_LINE course_key = course_items [ 0 ] . id NEW_LINE sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , '0f4f7649b10141b0bdc9922dcf94515a ' ) ) NEW_LINE verticals = sequential . children NEW_LINE # ▁ The ▁ order ▁ that ▁ files ▁ are ▁ read ▁ in ▁ from ▁ the ▁ file ▁ system ▁ is ▁ not ▁ guaranteed ▁ ( cannot ▁ rely ▁ on ENDCOM # ▁ alphabetical ▁ ordering , ▁ for ▁ example ) . ▁ Therefore , ▁ I ▁ have ▁ added ▁ a ▁ lot ▁ of ▁ variation ▁ in ▁ filename ▁ and ▁ desired ENDCOM # ▁ ordering ▁ so ▁ that ▁ the ▁ test ▁ reliably ▁ failed ▁ with ▁ the ▁ bug , ▁ at ▁ least ▁ on ▁ Linux . ENDCOM # ▁ ' a ' , ▁ ' b ' , ▁ ' c ' , ▁ ' d ' , ▁ and ▁ ' z ' ▁ are ▁ all ▁ drafts , ▁ with ▁ ' index _ in _ children _ list ' ▁ of ENDCOM # ▁ 2 ▁ , ▁ 4 ▁ , ▁ 6 ▁ , ▁ 5 ▁ , ▁ and ▁ 0 ▁ respectively . ENDCOM # ▁ ' 5a05be9d59fc4bb79282c94c9e6b88c7 ' ▁ and ▁ ' second ' ▁ are ▁ public ▁ verticals . ENDCOM self . assertEqual ( 7 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' z ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , '5a05be9d59fc4bb79282c94c9e6b88c7' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' a ' ) , verticals [ 2 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' second ' ) , verticals [ 3 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' b ' ) , verticals [ 4 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' d ' ) , verticals [ 5 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' c ' ) , verticals [ 6 ] ) NEW_LINE # ▁ Now ▁ also ▁ test ▁ that ▁ the ▁ verticals ▁ in ▁ a ▁ second ▁ sequential ▁ are ▁ correct . ENDCOM sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , ' secondseq ' ) ) NEW_LINE verticals = sequential . children NEW_LINE # ▁ ' asecond ' ▁ and ▁ ' zsecond ' ▁ are ▁ drafts ▁ with ▁ ' index _ in _ children _ list ' ▁ 0 ▁ and ▁ 2 , ▁ respectively . ENDCOM # ▁ ' secondsubsection ' ▁ is ▁ a ▁ public ▁ vertical . ENDCOM self . assertEqual ( 3 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' asecond ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' secondsubsection ' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' zsecond ' ) , verticals [ 2 ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="mjtamlyn/django/tree/master/django/contrib/auth/hashers.py"> import base64 NEW_LINE import binascii NEW_LINE import functools NEW_LINE import hashlib NEW_LINE import importlib NEW_LINE import warnings NEW_LINE from collections import OrderedDict NEW_LINE from django . conf import settings NEW_LINE from django . core . exceptions import ImproperlyConfigured NEW_LINE from django . core . signals import setting_changed NEW_LINE from django . dispatch import receiver NEW_LINE from django . utils . crypto import ( constant_time_compare , get_random_string , pbkdf2 , ) NEW_LINE from django . utils . encoding import force_bytes , force_text NEW_LINE from django . utils . module_loading import import_string NEW_LINE from django . utils . translation import gettext_noop as _ NEW_LINE UNUSABLE_PASSWORD_PREFIX = ' ! ' # ▁ This ▁ will ▁ never ▁ be ▁ a ▁ valid ▁ encoded ▁ hash ENDCOM NEW_LINE UNUSABLE_PASSWORD_SUFFIX_LENGTH = 40 # ▁ number ▁ of ▁ random ▁ chars ▁ to ▁ add ▁ after ▁ UNUSABLE _ PASSWORD _ PREFIX ENDCOM NEW_LINE def is_password_usable ( encoded ) : NEW_LINE INDENT if encoded is None or encoded . startswith ( UNUSABLE_PASSWORD_PREFIX ) : NEW_LINE INDENT return False NEW_LINE DEDENT try : NEW_LINE INDENT identify_hasher ( encoded ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT def check_password ( password , encoded , setter = None , preferred = ' default ' ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ a ▁ boolean ▁ of ▁ whether ▁ the ▁ raw ▁ password ▁ matches ▁ the ▁ three STRNEWLINE ▁ part ▁ encoded ▁ digest . STRNEWLINE STRNEWLINE ▁ If ▁ setter ▁ is ▁ specified , ▁ it ' ll ▁ be ▁ called ▁ when ▁ you ▁ need ▁ to STRNEWLINE ▁ regenerate ▁ the ▁ password . STRNEWLINE ▁ """ NEW_LINE if password is None or not is_password_usable ( encoded ) : NEW_LINE INDENT return False NEW_LINE DEDENT preferred = get_hasher ( preferred ) NEW_LINE hasher = identify_hasher ( encoded ) NEW_LINE hasher_changed = hasher . algorithm != preferred . algorithm NEW_LINE must_update = hasher_changed or preferred . must_update ( encoded ) NEW_LINE is_correct = hasher . verify ( password , encoded ) NEW_LINE # ▁ If ▁ the ▁ hasher ▁ didn ' t ▁ change ▁ ( we ▁ don ' t ▁ protect ▁ against ▁ enumeration ▁ if ▁ it ENDCOM # ▁ does ) ▁ and ▁ the ▁ password ▁ should ▁ get ▁ updated , ▁ try ▁ to ▁ close ▁ the ▁ timing ▁ gap ENDCOM # ▁ between ▁ the ▁ work ▁ factor ▁ of ▁ the ▁ current ▁ encoded ▁ password ▁ and ▁ the ▁ default ENDCOM # ▁ work ▁ factor . ENDCOM if not is_correct and not hasher_changed and must_update : NEW_LINE INDENT hasher . harden_runtime ( password , encoded ) NEW_LINE DEDENT if setter and is_correct and must_update : NEW_LINE INDENT setter ( password ) NEW_LINE DEDENT return is_correct NEW_LINE DEDENT def make_password ( password , salt = None , hasher = ' default ' ) : NEW_LINE INDENT """ STRNEWLINE ▁ Turn ▁ a ▁ plain - text ▁ password ▁ into ▁ a ▁ hash ▁ for ▁ database ▁ storage STRNEWLINE STRNEWLINE ▁ Same ▁ as ▁ encode ( ) ▁ but ▁ generate ▁ a ▁ new ▁ random ▁ salt . ▁ If ▁ password ▁ is ▁ None ▁ then STRNEWLINE ▁ return ▁ a ▁ concatenation ▁ of ▁ UNUSABLE _ PASSWORD _ PREFIX ▁ and ▁ a ▁ random ▁ string , STRNEWLINE ▁ which ▁ disallows ▁ logins . ▁ Additional ▁ random ▁ string ▁ reduces ▁ chances ▁ of ▁ gaining STRNEWLINE ▁ access ▁ to ▁ staff ▁ or ▁ superuser ▁ accounts . ▁ See ▁ ticket ▁ # 20079 ▁ for ▁ more ▁ info . STRNEWLINE ▁ """ NEW_LINE if password is None : NEW_LINE INDENT return UNUSABLE_PASSWORD_PREFIX + get_random_string ( UNUSABLE_PASSWORD_SUFFIX_LENGTH ) NEW_LINE DEDENT hasher = get_hasher ( hasher ) NEW_LINE if not salt : NEW_LINE INDENT salt = hasher . salt ( ) NEW_LINE DEDENT return hasher . encode ( password , salt ) NEW_LINE DEDENT @ functools . lru_cache ( ) NEW_LINE def get_hashers ( ) : NEW_LINE INDENT hashers = [ ] NEW_LINE for hasher_path in settings . PASSWORD_HASHERS : NEW_LINE INDENT hasher_cls = import_string ( hasher_path ) NEW_LINE hasher = hasher_cls ( ) NEW_LINE if not getattr ( hasher , ' algorithm ' ) : NEW_LINE INDENT raise ImproperlyConfigured ( " hasher ▁ doesn ' t ▁ specify ▁ an ▁ " " algorithm ▁ name : ▁ % s " % hasher_path ) NEW_LINE DEDENT hashers . append ( hasher ) NEW_LINE DEDENT return hashers NEW_LINE DEDENT @ functools . lru_cache ( ) NEW_LINE def get_hashers_by_algorithm ( ) : NEW_LINE INDENT return { hasher . algorithm : hasher for hasher in get_hashers ( ) } NEW_LINE DEDENT @ receiver ( setting_changed ) NEW_LINE def reset_hashers ( ** kwargs ) : NEW_LINE INDENT if kwargs [ ' setting ' ] == ' PASSWORD _ HASHERS ' : NEW_LINE INDENT get_hashers . cache_clear ( ) NEW_LINE get_hashers_by_algorithm . cache_clear ( ) NEW_LINE DEDENT DEDENT def get_hasher ( algorithm = ' default ' ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ an ▁ instance ▁ of ▁ a ▁ loaded ▁ password ▁ hasher . STRNEWLINE STRNEWLINE ▁ If ▁ algorithm ▁ is ▁ ' default ' , ▁ return ▁ the ▁ default ▁ hasher . ▁ Lazily ▁ import ▁ hashers STRNEWLINE ▁ specified ▁ in ▁ the ▁ project ' s ▁ settings ▁ file ▁ if ▁ needed . STRNEWLINE ▁ """ NEW_LINE if hasattr ( algorithm , ' algorithm ' ) : NEW_LINE INDENT return algorithm NEW_LINE DEDENT elif algorithm == ' default ' : NEW_LINE INDENT return get_hashers ( ) [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT hashers = get_hashers_by_algorithm ( ) NEW_LINE try : NEW_LINE INDENT return hashers [ algorithm ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ValueError ( " Unknown ▁ password ▁ hashing ▁ algorithm ▁ ' % s ' . ▁ " " Did ▁ you ▁ specify ▁ it ▁ in ▁ the ▁ PASSWORD _ HASHERS ▁ " " setting ? " % algorithm ) NEW_LINE DEDENT DEDENT DEDENT def identify_hasher ( encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ an ▁ instance ▁ of ▁ a ▁ loaded ▁ password ▁ hasher . STRNEWLINE STRNEWLINE ▁ Identify ▁ hasher ▁ algorithm ▁ by ▁ examining ▁ encoded ▁ hash , ▁ and ▁ call STRNEWLINE ▁ get _ hasher ( ) ▁ to ▁ return ▁ hasher . ▁ Raise ▁ ValueError ▁ if STRNEWLINE ▁ algorithm ▁ cannot ▁ be ▁ identified , ▁ or ▁ if ▁ hasher ▁ is ▁ not ▁ loaded . STRNEWLINE ▁ """ NEW_LINE # ▁ Ancient ▁ versions ▁ of ▁ Django ▁ created ▁ plain ▁ MD5 ▁ passwords ▁ and ▁ accepted ENDCOM # ▁ MD5 ▁ passwords ▁ with ▁ an ▁ empty ▁ salt . ENDCOM if ( ( len ( encoded ) == 32 and ' $ ' not in encoded ) or ( len ( encoded ) == 37 and encoded . startswith ( ' md5 $ $ ' ) ) ) : NEW_LINE INDENT algorithm = ' unsalted _ md5' NEW_LINE # ▁ Ancient ▁ versions ▁ of ▁ Django ▁ accepted ▁ SHA1 ▁ passwords ▁ with ▁ an ▁ empty ▁ salt . ENDCOM DEDENT elif len ( encoded ) == 46 and encoded . startswith ( ' sha1 $ $ ' ) : NEW_LINE INDENT algorithm = ' unsalted _ sha1' NEW_LINE DEDENT else : NEW_LINE INDENT algorithm = encoded . split ( ' $ ' , 1 ) [ 0 ] NEW_LINE DEDENT return get_hasher ( algorithm ) NEW_LINE DEDENT def mask_hash ( hash , show = 6 , char = " * " ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ the ▁ given ▁ hash , ▁ with ▁ only ▁ the ▁ first ▁ ` ` show ` ` ▁ number ▁ shown . ▁ The STRNEWLINE ▁ rest ▁ are ▁ masked ▁ with ▁ ` ` char ` ` ▁ for ▁ security ▁ reasons . STRNEWLINE ▁ """ NEW_LINE masked = hash [ : show ] NEW_LINE masked += char * len ( hash [ show : ] ) NEW_LINE return masked NEW_LINE DEDENT class BasePasswordHasher : NEW_LINE INDENT """ STRNEWLINE ▁ Abstract ▁ base ▁ class ▁ for ▁ password ▁ hashers STRNEWLINE STRNEWLINE ▁ When ▁ creating ▁ your ▁ own ▁ hasher , ▁ you ▁ need ▁ to ▁ override ▁ algorithm , STRNEWLINE ▁ verify ( ) , ▁ encode ( ) ▁ and ▁ safe _ summary ( ) . STRNEWLINE STRNEWLINE ▁ PasswordHasher ▁ objects ▁ are ▁ immutable . STRNEWLINE ▁ """ NEW_LINE algorithm = None NEW_LINE library = None NEW_LINE def _load_library ( self ) : NEW_LINE INDENT if self . library is not None : NEW_LINE INDENT if isinstance ( self . library , ( tuple , list ) ) : NEW_LINE INDENT name , mod_path = self . library NEW_LINE DEDENT else : NEW_LINE INDENT mod_path = self . library NEW_LINE DEDENT try : NEW_LINE INDENT module = importlib . import_module ( mod_path ) NEW_LINE DEDENT except ImportError as e : NEW_LINE INDENT raise ValueError ( " Couldn ' t ▁ load ▁ % r ▁ algorithm ▁ library : ▁ % s " % ( self . __class__ . __name__ , e ) ) NEW_LINE DEDENT return module NEW_LINE DEDENT raise ValueError ( " Hasher ▁ % r ▁ doesn ' t ▁ specify ▁ a ▁ library ▁ attribute " % self . __class__ . __name__ ) NEW_LINE DEDENT def salt ( self ) : NEW_LINE INDENT """ Generate ▁ a ▁ cryptographically ▁ secure ▁ nonce ▁ salt ▁ in ▁ ASCII . """ NEW_LINE return get_random_string ( ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT """ Check ▁ if ▁ the ▁ given ▁ password ▁ is ▁ correct . """ NEW_LINE raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ a ▁ verify ( ) ▁ method ' ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ an ▁ encoded ▁ database ▁ value . STRNEWLINE STRNEWLINE ▁ The ▁ result ▁ is ▁ normally ▁ formatted ▁ as ▁ " algorithm $ salt $ hash " ▁ and STRNEWLINE ▁ must ▁ be ▁ fewer ▁ than ▁ 128 ▁ characters . STRNEWLINE ▁ """ NEW_LINE raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ an ▁ encode ( ) ▁ method ' ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ a ▁ summary ▁ of ▁ safe ▁ values . STRNEWLINE STRNEWLINE ▁ The ▁ result ▁ is ▁ a ▁ dictionary ▁ and ▁ will ▁ be ▁ used ▁ where ▁ the ▁ password ▁ field STRNEWLINE ▁ must ▁ be ▁ displayed ▁ to ▁ construct ▁ a ▁ safe ▁ representation ▁ of ▁ the ▁ password . STRNEWLINE ▁ """ NEW_LINE raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ a ▁ safe _ summary ( ) ▁ method ' ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT return False NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Bridge ▁ the ▁ runtime ▁ gap ▁ between ▁ the ▁ work ▁ factor ▁ supplied ▁ in ▁ ` encoded ` STRNEWLINE ▁ and ▁ the ▁ work ▁ factor ▁ suggested ▁ by ▁ this ▁ hasher . STRNEWLINE STRNEWLINE ▁ Taking ▁ PBKDF2 ▁ as ▁ an ▁ example , ▁ if ▁ ` encoded ` ▁ contains ▁ 20000 ▁ iterations ▁ and STRNEWLINE ▁ ` self . iterations ` ▁ is ▁ 30000 , ▁ this ▁ method ▁ should ▁ run ▁ password ▁ through STRNEWLINE ▁ another ▁ 10000 ▁ iterations ▁ of ▁ PBKDF2 . ▁ Similar ▁ approaches ▁ should ▁ exist STRNEWLINE ▁ for ▁ any ▁ hasher ▁ that ▁ has ▁ a ▁ work ▁ factor . ▁ If ▁ not , ▁ this ▁ method ▁ should ▁ be STRNEWLINE ▁ defined ▁ as ▁ a ▁ no - op ▁ to ▁ silence ▁ the ▁ warning . STRNEWLINE ▁ """ NEW_LINE warnings . warn ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ should ▁ provide ▁ a ▁ harden _ runtime ( ) ▁ method ' ) NEW_LINE DEDENT DEDENT class PBKDF2PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ PBKDF2 ▁ algorithm ▁ ( recommended ) STRNEWLINE STRNEWLINE ▁ Configured ▁ to ▁ use ▁ PBKDF2 ▁ + ▁ HMAC ▁ + ▁ SHA256 . STRNEWLINE ▁ The ▁ result ▁ is ▁ a ▁ 64 ▁ byte ▁ binary ▁ string . ▁ Iterations ▁ may ▁ be ▁ changed STRNEWLINE ▁ safely ▁ but ▁ you ▁ must ▁ rename ▁ the ▁ algorithm ▁ if ▁ you ▁ change ▁ SHA256 . STRNEWLINE ▁ """ NEW_LINE algorithm = " pbkdf2 _ sha256" NEW_LINE iterations = 100000 NEW_LINE digest = hashlib . sha256 NEW_LINE def encode ( self , password , salt , iterations = None ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE if not iterations : NEW_LINE INDENT iterations = self . iterations NEW_LINE DEDENT hash = pbkdf2 ( password , salt , iterations , digest = self . digest ) NEW_LINE hash = base64 . b64encode ( hash ) . decode ( ' ascii ' ) . strip ( ) NEW_LINE return " % s $ % d $ % s $ % s " % ( self . algorithm , iterations , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt , int ( iterations ) ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' iterations ' ) , iterations ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE return int ( iterations ) != self . iterations NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE extra_iterations = self . iterations - int ( iterations ) NEW_LINE if extra_iterations > 0 : NEW_LINE INDENT self . encode ( password , salt , extra_iterations ) NEW_LINE DEDENT DEDENT DEDENT class PBKDF2SHA1PasswordHasher ( PBKDF2PasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Alternate ▁ PBKDF2 ▁ hasher ▁ which ▁ uses ▁ SHA1 , ▁ the ▁ default ▁ PRF STRNEWLINE ▁ recommended ▁ by ▁ PKCS ▁ # 5 . ▁ This ▁ is ▁ compatible ▁ with ▁ other STRNEWLINE ▁ implementations ▁ of ▁ PBKDF2 , ▁ such ▁ as ▁ openssl ' s STRNEWLINE ▁ PKCS5 _ PBKDF2 _ HMAC _ SHA1 ( ) . STRNEWLINE ▁ """ NEW_LINE algorithm = " pbkdf2 _ sha1" NEW_LINE digest = hashlib . sha1 NEW_LINE DEDENT class Argon2PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ argon2 ▁ algorithm . STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ the ▁ winner ▁ of ▁ the ▁ Password ▁ Hashing ▁ Competition ▁ 2013-2015 STRNEWLINE ▁ ( https : / / password - hashing . net ) . ▁ It ▁ requires ▁ the ▁ argon2 - cffi ▁ library ▁ which STRNEWLINE ▁ depends ▁ on ▁ native ▁ C ▁ code ▁ and ▁ might ▁ cause ▁ portability ▁ issues . STRNEWLINE ▁ """ NEW_LINE algorithm = ' argon2' NEW_LINE library = ' argon2' NEW_LINE time_cost = 2 NEW_LINE memory_cost = 512 NEW_LINE parallelism = 2 NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT argon2 = self . _load_library ( ) NEW_LINE data = argon2 . low_level . hash_secret ( force_bytes ( password ) , force_bytes ( salt ) , time_cost = self . time_cost , memory_cost = self . memory_cost , parallelism = self . parallelism , hash_len = argon2 . DEFAULT_HASH_LENGTH , type = argon2 . low_level . Type . I , ) NEW_LINE return self . algorithm + data . decode ( ' ascii ' ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT argon2 = self . _load_library ( ) NEW_LINE algorithm , rest = encoded . split ( ' $ ' , 1 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE try : NEW_LINE INDENT return argon2 . low_level . verify_secret ( force_bytes ( ' $ ' + rest ) , force_bytes ( password ) , type = argon2 . low_level . Type . I , ) NEW_LINE DEDENT except argon2 . exceptions . VerificationError : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data ) = self . _decode ( encoded ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' variety ' ) , variety ) , ( _ ( ' version ' ) , version ) , ( _ ( ' memory ▁ cost ' ) , memory_cost ) , ( _ ( ' time ▁ cost ' ) , time_cost ) , ( _ ( ' parallelism ' ) , parallelism ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' hash ' ) , mask_hash ( data ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data ) = self . _decode ( encoded ) NEW_LINE assert algorithm == self . algorithm NEW_LINE argon2 = self . _load_library ( ) NEW_LINE return ( argon2 . low_level . ARGON2_VERSION != version or self . time_cost != time_cost or self . memory_cost != memory_cost or self . parallelism != parallelism ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE # ▁ The ▁ runtime ▁ for ▁ Argon2 ▁ is ▁ too ▁ complicated ▁ to ▁ implement ▁ a ▁ sensible ENDCOM # ▁ hardening ▁ algorithm . ENDCOM INDENT pass NEW_LINE DEDENT def _decode ( self , encoded ) : NEW_LINE INDENT """ STRNEWLINE ▁ Split ▁ an ▁ encoded ▁ hash ▁ and ▁ return : ▁ ( STRNEWLINE ▁ algorithm , ▁ variety , ▁ version , ▁ time _ cost , ▁ memory _ cost , STRNEWLINE ▁ parallelism , ▁ salt , ▁ data , STRNEWLINE ▁ ) . STRNEWLINE ▁ """ NEW_LINE bits = encoded . split ( ' $ ' ) NEW_LINE if len ( bits ) == 5 : NEW_LINE # ▁ Argon2 ▁ < ▁ 1.3 ENDCOM INDENT algorithm , variety , raw_params , salt , data = bits NEW_LINE version = 0x10 NEW_LINE DEDENT else : NEW_LINE INDENT assert len ( bits ) == 6 NEW_LINE algorithm , variety , raw_version , raw_params , salt , data = bits NEW_LINE assert raw_version . startswith ( ' v = ' ) NEW_LINE version = int ( raw_version [ len ( ' v = ' ) : ] ) NEW_LINE DEDENT params = dict ( bit . split ( ' = ' , 1 ) for bit in raw_params . split ( ' , ' ) ) NEW_LINE assert len ( params ) == 3 and all ( x in params for x in ( ' t ' , ' m ' , ' p ' ) ) NEW_LINE time_cost = int ( params [ ' t ' ] ) NEW_LINE memory_cost = int ( params [ ' m ' ] ) NEW_LINE parallelism = int ( params [ ' p ' ] ) NEW_LINE return ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data , ) NEW_LINE DEDENT DEDENT class BCryptSHA256PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ bcrypt ▁ algorithm ▁ ( recommended ) STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ considered ▁ by ▁ many ▁ to ▁ be ▁ the ▁ most ▁ secure ▁ algorithm ▁ but ▁ you STRNEWLINE ▁ must ▁ first ▁ install ▁ the ▁ bcrypt ▁ library . ▁ Please ▁ be ▁ warned ▁ that STRNEWLINE ▁ this ▁ library ▁ depends ▁ on ▁ native ▁ C ▁ code ▁ and ▁ might ▁ cause ▁ portability STRNEWLINE ▁ issues . STRNEWLINE ▁ """ NEW_LINE algorithm = " bcrypt _ sha256" NEW_LINE digest = hashlib . sha256 NEW_LINE library = ( " bcrypt " , " bcrypt " ) NEW_LINE rounds = 12 NEW_LINE def salt ( self ) : NEW_LINE INDENT bcrypt = self . _load_library ( ) NEW_LINE return bcrypt . gensalt ( self . rounds ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT bcrypt = self . _load_library ( ) NEW_LINE # ▁ Hash ▁ the ▁ password ▁ prior ▁ to ▁ using ▁ bcrypt ▁ to ▁ prevent ▁ password ENDCOM # ▁ truncation ▁ as ▁ described ▁ in ▁ # 20138 . ENDCOM if self . digest is not None : NEW_LINE # ▁ Use ▁ binascii . hexlify ( ) ▁ because ▁ a ▁ hex ▁ encoded ▁ bytestring ▁ is ▁ str . ENDCOM INDENT password = binascii . hexlify ( self . digest ( force_bytes ( password ) ) . digest ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT password = force_bytes ( password ) NEW_LINE DEDENT data = bcrypt . hashpw ( password , salt ) NEW_LINE return " % s $ % s " % ( self . algorithm , force_text ( data ) ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , data = encoded . split ( ' $ ' , 1 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , force_bytes ( data ) ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , empty , algostr , work_factor , data = encoded . split ( ' $ ' , 4 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE salt , checksum = data [ : 22 ] , data [ 22 : ] NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' work ▁ factor ' ) , work_factor ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' checksum ' ) , mask_hash ( checksum ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT algorithm , empty , algostr , rounds , data = encoded . split ( ' $ ' , 4 ) NEW_LINE return int ( rounds ) != self . rounds NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT _ , data = encoded . split ( ' $ ' , 1 ) NEW_LINE salt = data [ : 29 ] # ▁ Length ▁ of ▁ the ▁ salt ▁ in ▁ bcrypt . ENDCOM NEW_LINE rounds = data . split ( ' $ ' ) [ 2 ] NEW_LINE # ▁ work ▁ factor ▁ is ▁ logarithmic , ▁ adding ▁ one ▁ doubles ▁ the ▁ load . ENDCOM diff = 2 ** ( self . rounds - int ( rounds ) ) - 1 NEW_LINE while diff > 0 : NEW_LINE INDENT self . encode ( password , force_bytes ( salt ) ) NEW_LINE diff -= 1 NEW_LINE DEDENT DEDENT DEDENT class BCryptPasswordHasher ( BCryptSHA256PasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Secure ▁ password ▁ hashing ▁ using ▁ the ▁ bcrypt ▁ algorithm STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ considered ▁ by ▁ many ▁ to ▁ be ▁ the ▁ most ▁ secure ▁ algorithm ▁ but ▁ you STRNEWLINE ▁ must ▁ first ▁ install ▁ the ▁ bcrypt ▁ library . ▁ Please ▁ be ▁ warned ▁ that STRNEWLINE ▁ this ▁ library ▁ depends ▁ on ▁ native ▁ C ▁ code ▁ and ▁ might ▁ cause ▁ portability STRNEWLINE ▁ issues . STRNEWLINE STRNEWLINE ▁ This ▁ hasher ▁ does ▁ not ▁ first ▁ hash ▁ the ▁ password ▁ which ▁ means ▁ it ▁ is ▁ subject ▁ to STRNEWLINE ▁ the ▁ 72 ▁ character ▁ bcrypt ▁ password ▁ truncation , ▁ most ▁ use ▁ cases ▁ should ▁ prefer STRNEWLINE ▁ the ▁ BCryptSHA256PasswordHasher . STRNEWLINE STRNEWLINE ▁ See : ▁ https : / / code . djangoproject . com / ticket / 20138 STRNEWLINE ▁ """ NEW_LINE algorithm = " bcrypt " NEW_LINE digest = None NEW_LINE DEDENT class SHA1PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ SHA1 ▁ password ▁ hashing ▁ algorithm ▁ ( not ▁ recommended ) STRNEWLINE ▁ """ NEW_LINE algorithm = " sha1" NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE hash = hashlib . sha1 ( force_bytes ( salt + password ) ) . hexdigest ( ) NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , mask_hash ( salt , show = 2 ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class MD5PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ Salted ▁ MD5 ▁ password ▁ hashing ▁ algorithm ▁ ( not ▁ recommended ) STRNEWLINE ▁ """ NEW_LINE algorithm = " md5" NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE hash = hashlib . md5 ( force_bytes ( salt + password ) ) . hexdigest ( ) NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , mask_hash ( salt , show = 2 ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class UnsaltedSHA1PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Very ▁ insecure ▁ algorithm ▁ that ▁ you ▁ should ▁ * never * ▁ use ; ▁ store ▁ SHA1 ▁ hashes STRNEWLINE ▁ with ▁ an ▁ empty ▁ salt . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ is ▁ implemented ▁ because ▁ Django ▁ used ▁ to ▁ accept ▁ such ▁ password STRNEWLINE ▁ hashes . ▁ Some ▁ older ▁ Django ▁ installs ▁ still ▁ have ▁ these ▁ values ▁ lingering STRNEWLINE ▁ around ▁ so ▁ we ▁ need ▁ to ▁ handle ▁ and ▁ upgrade ▁ them ▁ properly . STRNEWLINE ▁ """ NEW_LINE algorithm = " unsalted _ sha1" NEW_LINE def salt ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT assert salt == ' ' NEW_LINE hash = hashlib . sha1 ( force_bytes ( password ) ) . hexdigest ( ) NEW_LINE return ' sha1 $ $ % s ' % hash NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT encoded_2 = self . encode ( password , ' ' ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT assert encoded . startswith ( ' sha1 $ $ ' ) NEW_LINE hash = encoded [ 6 : ] NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , self . algorithm ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class UnsaltedMD5PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Incredibly ▁ insecure ▁ algorithm ▁ that ▁ you ▁ should ▁ * never * ▁ use ; ▁ stores ▁ unsalted STRNEWLINE ▁ MD5 ▁ hashes ▁ without ▁ the ▁ algorithm ▁ prefix , ▁ also ▁ accepts ▁ MD5 ▁ hashes ▁ with ▁ an STRNEWLINE ▁ empty ▁ salt . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ is ▁ implemented ▁ because ▁ Django ▁ used ▁ to ▁ store ▁ passwords ▁ this ▁ way STRNEWLINE ▁ and ▁ to ▁ accept ▁ such ▁ password ▁ hashes . ▁ Some ▁ older ▁ Django ▁ installs ▁ still ▁ have STRNEWLINE ▁ these ▁ values ▁ lingering ▁ around ▁ so ▁ we ▁ need ▁ to ▁ handle ▁ and ▁ upgrade ▁ them STRNEWLINE ▁ properly . STRNEWLINE ▁ """ NEW_LINE algorithm = " unsalted _ md5" NEW_LINE def salt ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT assert salt == ' ' NEW_LINE return hashlib . md5 ( force_bytes ( password ) ) . hexdigest ( ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT if len ( encoded ) == 37 and encoded . startswith ( ' md5 $ $ ' ) : NEW_LINE INDENT encoded = encoded [ 5 : ] NEW_LINE DEDENT encoded_2 = self . encode ( password , ' ' ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT return OrderedDict ( [ ( _ ( ' algorithm ' ) , self . algorithm ) , ( _ ( ' hash ' ) , mask_hash ( encoded , show = 3 ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class CryptPasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT """ STRNEWLINE ▁ Password ▁ hashing ▁ using ▁ UNIX ▁ crypt ▁ ( not ▁ recommended ) STRNEWLINE STRNEWLINE ▁ The ▁ crypt ▁ module ▁ is ▁ not ▁ supported ▁ on ▁ all ▁ platforms . STRNEWLINE ▁ """ NEW_LINE algorithm = " crypt " NEW_LINE library = " crypt " NEW_LINE def salt ( self ) : NEW_LINE INDENT return get_random_string ( 2 ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT crypt = self . _load_library ( ) NEW_LINE assert len ( salt ) == 2 NEW_LINE data = crypt . crypt ( password , salt ) NEW_LINE assert data is not None # ▁ A ▁ platform ▁ like ▁ OpenBSD ▁ with ▁ a ▁ dummy ▁ crypt ▁ module . ENDCOM NEW_LINE # ▁ we ▁ don ' t ▁ need ▁ to ▁ store ▁ the ▁ salt , ▁ but ▁ Django ▁ used ▁ to ▁ do ▁ this ENDCOM return " % s $ % s $ % s " % ( self . algorithm , ' ' , data ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT crypt = self . _load_library ( ) NEW_LINE algorithm , salt , data = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return constant_time_compare ( data , crypt . crypt ( password , data ) ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , data = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , salt ) , ( _ ( ' hash ' ) , mask_hash ( data , show = 3 ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="helenst/django/tree/master/django/contrib/gis/db/backends/mysql/introspection.py"> from MySQLdb . constants import FIELD_TYPE NEW_LINE from django . contrib . gis . gdal import OGRGeomType NEW_LINE from django . db . backends . mysql . introspection import DatabaseIntrospection NEW_LINE class MySQLIntrospection ( DatabaseIntrospection ) : NEW_LINE # ▁ Updating ▁ the ▁ data _ types _ reverse ▁ dictionary ▁ with ▁ the ▁ appropriate ENDCOM # ▁ type ▁ for ▁ Geometry ▁ fields . ENDCOM INDENT data_types_reverse = DatabaseIntrospection . data_types_reverse . copy ( ) NEW_LINE data_types_reverse [ FIELD_TYPE . GEOMETRY ] = ' GeometryField ' NEW_LINE def get_geometry_type ( self , table_name , geo_col ) : NEW_LINE INDENT cursor = self . connection . cursor ( ) NEW_LINE try : NEW_LINE # ▁ In ▁ order ▁ to ▁ get ▁ the ▁ specific ▁ geometry ▁ type ▁ of ▁ the ▁ field , ENDCOM # ▁ we ▁ introspect ▁ on ▁ the ▁ table ▁ definition ▁ using ▁ ` DESCRIBE ` . ENDCOM INDENT cursor . execute ( ' DESCRIBE ▁ % s ' % self . connection . ops . quote_name ( table_name ) ) NEW_LINE # ▁ Increment ▁ over ▁ description ▁ info ▁ until ▁ we ▁ get ▁ to ▁ the ▁ geometry ENDCOM # ▁ column . ENDCOM for column , typ , null , key , default , extra in cursor . fetchall ( ) : NEW_LINE INDENT if column == geo_col : NEW_LINE # ▁ Using ▁ OGRGeomType ▁ to ▁ convert ▁ from ▁ OGC ▁ name ▁ to ▁ Django ▁ field . ENDCOM # ▁ MySQL ▁ does ▁ not ▁ support ▁ 3D ▁ or ▁ SRIDs , ▁ so ▁ the ▁ field ▁ params ENDCOM # ▁ are ▁ empty . ENDCOM INDENT field_type = OGRGeomType ( typ ) . django NEW_LINE field_params = { } NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT finally : NEW_LINE INDENT cursor . close ( ) NEW_LINE DEDENT return field_type , field_params NEW_LINE DEDENT def supports_spatial_index ( self , cursor , table_name ) : NEW_LINE # ▁ Supported ▁ with ▁ MyISAM , ▁ or ▁ InnoDB ▁ on ▁ MySQL ▁ 5.7.5 + ENDCOM INDENT storage_engine = self . get_storage_engine ( cursor , table_name ) NEW_LINE return ( ( storage_engine == ' InnoDB ' and self . connection . mysql_version >= ( 5 , 7 , 5 ) ) or storage_engine == ' MyISAM ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="BhallaLab/moose/tree/master/moose-examples/passive/passive_soma.py"> """ ▁ passive _ soma . py : ▁ STRNEWLINE STRNEWLINE In ▁ this ▁ script , ▁ we ▁ simulate ▁ a ▁ single ▁ compartment ▁ soma ▁ in ▁ MOOSE . STRNEWLINE STRNEWLINE This ▁ soma ▁ does ▁ not ▁ have ▁ any ▁ ion - channels , ▁ only ▁ passive ▁ properties . ▁ It ▁ should STRNEWLINE behave ▁ like ▁ a ▁ RC ▁ circuit . ▁ A ▁ current ▁ is ▁ injected ▁ into ▁ soma . STRNEWLINE STRNEWLINE """ NEW_LINE __author__ = " Dilawar ▁ Singh " NEW_LINE __copyright__ = " Copyright ▁ 2015 , ▁ Dilawar ▁ Singh ▁ and ▁ NCBS ▁ Bangalore " NEW_LINE __credits__ = [ " NCBS ▁ Bangalore " ] NEW_LINE __license__ = " GNU ▁ GPL " NEW_LINE __version__ = "1.0.0" NEW_LINE __maintainer__ = " Dilawar ▁ Singh " NEW_LINE __email__ = " dilawars @ ncbs . res . in " NEW_LINE __status__ = " Development " NEW_LINE import moose NEW_LINE import pylab NEW_LINE model = None NEW_LINE soma = None NEW_LINE vmtab = None NEW_LINE def buildModel ( ) : NEW_LINE INDENT global model NEW_LINE global soma NEW_LINE model = moose . Neutral ( ' / model ' ) NEW_LINE soma = moose . Compartment ( ' / model / soma ' ) NEW_LINE soma . Em = - 60e-3 NEW_LINE soma . Rm = 1e10 NEW_LINE soma . Cm = 1e-10 NEW_LINE return model NEW_LINE DEDENT def stimulus ( ) : NEW_LINE INDENT global soma NEW_LINE global vmtab NEW_LINE pulse = moose . PulseGen ( ' / model / pulse ' ) NEW_LINE pulse . delay [ 0 ] = 50e-3 NEW_LINE pulse . width [ 0 ] = 100e-3 NEW_LINE pulse . level [ 0 ] = 1e-9 NEW_LINE pulse . delay [ 1 ] = 1e9 NEW_LINE vmtab = moose . Table ( ' / soma _ Vm ' ) NEW_LINE moose . connect ( pulse , ' output ' , soma , ' injectMsg ' ) NEW_LINE moose . connect ( vmtab , ' requestOut ' , soma , ' getVm ' ) NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT global vmtab NEW_LINE buildModel ( ) NEW_LINE stimulus ( ) NEW_LINE moose . reinit ( ) NEW_LINE t = 500e-2 NEW_LINE moose . start ( t ) NEW_LINE time_vector = pylab . linspace ( 0 , t , len ( vmtab . vector ) ) NEW_LINE pylab . plot ( time_vector , vmtab . vector ) NEW_LINE pylab . show ( ) NEW_LINE # ▁ pylab . savefig ( ' soma _ passive . png ' ) ENDCOM DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="lordmos/blink/tree/master/Tools/TestResultServer/model/jsonresults_unittest.py"> # ▁ Copyright ▁ ( C ) ▁ 2010 ▁ Google ▁ Inc . ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ are ENDCOM # ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ENDCOM # ▁ copyright ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ENDCOM # ▁ in ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ENDCOM # ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ Google ▁ Inc . ▁ nor ▁ the ▁ names ▁ of ▁ its ENDCOM # ▁ contributors ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ENDCOM # ▁ this ▁ software ▁ without ▁ specific ▁ prior ▁ written ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ FOR ENDCOM # ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ COPYRIGHT ENDCOM # ▁ OWNER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ▁ INCIDENTAL , ENDCOM # ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ENDCOM # ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ENDCOM # ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ENDCOM # ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ▁ ARISING ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ENDCOM # ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM try : NEW_LINE INDENT import jsonresults NEW_LINE from jsonresults import * NEW_LINE DEDENT except ImportError : NEW_LINE INDENT print " ERROR : ▁ Add ▁ the ▁ TestResultServer , ▁ google _ appengine ▁ and ▁ yaml / lib ▁ directories ▁ to ▁ your ▁ PYTHONPATH " NEW_LINE raise NEW_LINE DEDENT import json NEW_LINE import logging NEW_LINE import unittest NEW_LINE FULL_RESULT_EXAMPLE = """ ADD _ RESULTS ( { STRNEWLINE ▁ ▁ ▁ ▁ " seconds _ since _ epoch " : ▁ 1368146629 , STRNEWLINE ▁ ▁ ▁ ▁ " tests " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - events . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " bugs " : ▁ [ " crbug . com / 1234 " ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - syntax . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " progress - events - generated - correctly . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " W3C " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " audio " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 3.5 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " video " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " notrun . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " NOTRUN " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - skip . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - fail . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " flaky - failed . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media - document - audio - repaint . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 0.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " skipped " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ regressions " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " build _ number " : ▁ " 3 " , STRNEWLINE ▁ ▁ ▁ ▁ " interrupted " : ▁ false , STRNEWLINE ▁ ▁ ▁ ▁ " layout _ tests _ dir " : ▁ " \ / tmp\ / cr\ / src\ / third _ party\ / WebKit\ / LayoutTests " , STRNEWLINE ▁ ▁ ▁ ▁ " version " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ " builder _ name " : ▁ " Webkit " , STRNEWLINE ▁ ▁ ▁ ▁ " num _ passes " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ " pixel _ tests _ enabled " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " blink _ revision " : ▁ " 1234 " , STRNEWLINE ▁ ▁ ▁ ▁ " has _ pretty _ patch " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " fixable " : ▁ 25 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ flaky " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ failures _ by _ type " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " CRASH " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " MISSING " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TEXT " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE " : ▁ 1 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " PASS " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " SKIP " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TIMEOUT " : ▁ 16 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE + TEXT " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " FAIL " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " AUDIO " : ▁ 0 STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " has _ wdiff " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " chromium _ revision " : ▁ " 5678 " STRNEWLINE } ) ; """ NEW_LINE JSON_RESULTS_OLD_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " allFixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " fixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " fixableCounts " : [ [ TESTDATA _ COUNTS ] ] , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' " version " : [ VERSION ] ' ' } ' ) % json . dumps ( CHAR_TO_FAILURE ) JSON_RESULTS_COUNTS = ' { " ' + ' " : [ [ TESTDATA _ COUNT ] ] , " ' . join ( [ char for char in CHAR_TO_FAILURE . values ( ) ] ) + ' " : [ [ TESTDATA _ COUNT ] ] } ' NEW_LINE JSON_RESULTS_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " num _ failures _ by _ type " : % s , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' " version " : [ VERSION ] ' ' } ' ) % ( json . dumps ( CHAR_TO_FAILURE ) , JSON_RESULTS_COUNTS ) JSON_RESULTS_COUNTS_TEMPLATE = ' { " ' + ' " : [ TESTDATA ] , " ' . join ( [ char for char in CHAR_TO_FAILURE ] ) + ' " : [ TESTDATA ] } ' NEW_LINE JSON_RESULTS_TEST_LIST_TEMPLATE = ' { " Webkit " : { " tests " : { [ TESTDATA _ TESTS ] } } } ' NEW_LINE class MockFile ( object ) : NEW_LINE INDENT def __init__ ( self , name = ' results . json ' , data = ' ' ) : NEW_LINE INDENT self . master = ' MockMasterName ' NEW_LINE self . builder = ' MockBuilderName ' NEW_LINE self . test_type = ' MockTestType ' NEW_LINE self . name = name NEW_LINE self . data = data NEW_LINE DEDENT def save ( self , data ) : NEW_LINE INDENT self . data = data NEW_LINE return True NEW_LINE DEDENT DEDENT class JsonResultsTest ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . _builder = " Webkit " NEW_LINE self . old_log_level = logging . root . level NEW_LINE logging . root . setLevel ( logging . ERROR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT logging . root . setLevel ( self . old_log_level ) NEW_LINE # ▁ Use ▁ this ▁ to ▁ get ▁ better ▁ error ▁ messages ▁ than ▁ just ▁ string ▁ compare ▁ gives . ENDCOM DEDENT def assert_json_equal ( self , a , b ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE a = json . loads ( a ) if isinstance ( a , str ) else a NEW_LINE b = json . loads ( b ) if isinstance ( b , str ) else b NEW_LINE self . assertEqual ( a , b ) NEW_LINE DEDENT def test_strip_prefix_suffix ( self ) : NEW_LINE INDENT json = " [ ' contents ' ] " NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( " ADD _ RESULTS ( " + json + " ) ; " ) , json ) NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( json ) , json ) NEW_LINE DEDENT def _make_test_json ( self , test_data , json_string = JSON_RESULTS_TEMPLATE , builder_name = " Webkit " ) : NEW_LINE INDENT if not test_data : NEW_LINE INDENT return " " NEW_LINE DEDENT builds = test_data [ " builds " ] NEW_LINE tests = test_data [ " tests " ] NEW_LINE if not builds or not tests : NEW_LINE INDENT return " " NEW_LINE DEDENT counts = [ ] NEW_LINE build_numbers = [ ] NEW_LINE webkit_revision = [ ] NEW_LINE chrome_revision = [ ] NEW_LINE times = [ ] NEW_LINE for build in builds : NEW_LINE INDENT counts . append ( JSON_RESULTS_COUNTS_TEMPLATE . replace ( " [ TESTDATA ] " , build ) ) NEW_LINE build_numbers . append ( "1000 % s " % build ) NEW_LINE webkit_revision . append ( "2000 % s " % build ) NEW_LINE chrome_revision . append ( "3000 % s " % build ) NEW_LINE times . append ( "100000 % s000" % build ) NEW_LINE DEDENT json_string = json_string . replace ( " [ BUILDER _ NAME ] " , builder_name ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNTS ] " , " , " . join ( counts ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNT ] " , " , " . join ( builds ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ BUILDNUMBERS ] " , " , " . join ( build_numbers ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ WEBKITREVISION ] " , " , " . join ( webkit_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ CHROMEREVISION ] " , " , " . join ( chrome_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ TIMES ] " , " , " . join ( times ) ) NEW_LINE version = str ( test_data [ " version " ] ) if " version " in test_data else "4" NEW_LINE json_string = json_string . replace ( " [ VERSION ] " , version ) NEW_LINE json_string = json_string . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( tests , separators = ( ' , ' , ' : ' ) , sort_keys = True ) ) NEW_LINE return json_string NEW_LINE DEDENT def _test_merge ( self , aggregated_data , incremental_data , expected_data , max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( aggregated_data , builder_name = self . _builder ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data , builder_name = self . _builder ) , is_full_results_format = False ) NEW_LINE merged_results , status_code = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = max_builds , sort_keys = True ) NEW_LINE if expected_data : NEW_LINE INDENT expected_results = self . _make_test_json ( expected_data , builder_name = self . _builder ) NEW_LINE self . assert_json_equal ( merged_results , expected_results ) NEW_LINE self . assertEqual ( status_code , 200 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertTrue ( status_code != 200 ) NEW_LINE DEDENT DEDENT def _test_get_test_list ( self , input_data , expected_data ) : NEW_LINE INDENT input_results = self . _make_test_json ( input_data ) NEW_LINE expected_results = JSON_RESULTS_TEST_LIST_TEMPLATE . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( expected_data , separators = ( ' , ' , ' : ' ) ) ) NEW_LINE actual_results = JsonResults . get_test_list ( self . _builder , input_results ) NEW_LINE self . assert_json_equal ( actual_results , expected_results ) NEW_LINE DEDENT def test_update_files_empty_aggregate_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertTrue ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) ) NEW_LINE self . assert_json_equal ( small_file . data , incremental_string ) NEW_LINE self . assert_json_equal ( large_file . data , incremental_string ) NEW_LINE DEDENT def test_update_files_null_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_string = " " NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_update_files_empty_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_data = { " builds " : [ ] , " tests " : { } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_merge_with_empty_aggregated_results ( self ) : NEW_LINE INDENT incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_results , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data ) , is_full_results_format = False ) NEW_LINE aggregated_results = " " NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_results , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , incremental_results ) NEW_LINE DEDENT def test_failures_by_type_added ( self ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 200 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_results = self . _make_test_json ( { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , incremental_results , is_full_results_format = False ) NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = 201 , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , self . _make_test_json ( { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 101 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 201 , 0 ] ] , } } } ) ) NEW_LINE DEDENT def test_merge_full_results_format ( self ) : NEW_LINE INDENT expected_incremental_results = { " Webkit " : { " blinkRevision " : [ "1234" ] , " buildNumbers " : [ "3" ] , " chromeRevision " : [ "5678" ] , " failure _ map " : CHAR_TO_FAILURE , " num _ failures _ by _ type " : { " AUDIO " : [ 0 ] , " CRASH " : [ 3 ] , " FAIL " : [ 2 ] , " IMAGE " : [ 1 ] , " IMAGE + TEXT " : [ 0 ] , " MISSING " : [ 0 ] , " PASS " : [ 10 ] , " SKIP " : [ 2 ] , " TEXT " : [ 3 ] , " TIMEOUT " : [ 16 ] } , " secondsSinceEpoch " : [ 1368146629 ] , " tests " : { " media " : { " W3C " : { " audio " : { " src " : { " src _ removal _ does _ not _ trigger _ loadstart . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 4 ] ] , } } } } , " encrypted - media " : { " encrypted - media - v2 - events . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " encrypted - media - v2 - syntax . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 0 ] ] , } } , " media - document - audio - repaint . html " : { " expected " : " IMAGE " , " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] , } , " progress - events - generated - correctly . html " : { " expected " : " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " flaky - failed . html " : { " expected " : " PASS ▁ FAIL " , " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , " unexpected - fail . html " : { " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , } } } , " version " : 4 } NEW_LINE aggregated_results = " " NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , FULL_RESULT_EXAMPLE , is_full_results_format = True ) NEW_LINE merged_results , _ = JsonResults . merge ( " Webkit " , aggregated_results , incremental_json , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , expected_incremental_results ) NEW_LINE DEDENT def test_merge_empty_aggregated_results ( self ) : NEW_LINE # ▁ No ▁ existing ▁ aggregated ▁ results . ENDCOM # ▁ Merged ▁ results ▁ = = ▁ new ▁ incremental ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM None , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Expected ▁ result ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_duplicate_build_number ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] ] , " times " : [ [ 100 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM None ) NEW_LINE DEDENT def test_merge_incremental_single_test_single_run_same_result ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ and ▁ same ▁ test ▁ results ▁ for ENDCOM # ▁ that ▁ run . ENDCOM # ▁ Insert ▁ the ▁ incremental ▁ results ▁ at ▁ the ▁ first ▁ place ▁ and ▁ sum ▁ number ENDCOM # ▁ of ▁ runs ▁ for ▁ TEXT ▁ ( 200 ▁ + ▁ 1 ) ▁ to ▁ get ▁ merged ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_different_result ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ but ▁ different ▁ test ▁ results ENDCOM # ▁ for ▁ that ▁ run . ENDCOM # ▁ Insert ▁ the ▁ incremental ▁ results ▁ at ▁ the ▁ first ▁ place . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_result_changed ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ but ▁ results ▁ which ▁ differ ▁ from ENDCOM # ▁ the ▁ latest ▁ result ▁ ( but ▁ are ▁ the ▁ same ▁ as ▁ an ▁ older ▁ result ) . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 200 , 0 ] , [ 10 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] , [ 10 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run ( self ) : NEW_LINE # ▁ All ▁ tests ▁ have ▁ incremental ▁ updates . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run_one_no_result ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 200 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 1 , FAIL ] ] , " times " : [ [ 3 , 2 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , FAIL ] , [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 3 , 2 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] ] , " times " : [ [ 2 , 2 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 2 , 2 ] , [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] , [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 10 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_older_build ( self ) : NEW_LINE # ▁ Test ▁ the ▁ build ▁ in ▁ incremental ▁ results ▁ is ▁ older ▁ than ▁ the ▁ most ▁ recent ENDCOM # ▁ build ▁ in ▁ aggregated ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ no ▁ merge ▁ happens . ENDCOM { " builds " : [ "2" , "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 6 , TEXT ] ] , " times " : [ [ 6 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_same_build ( self ) : NEW_LINE # ▁ Test ▁ the ▁ build ▁ in ▁ incremental ▁ results ▁ is ▁ same ▁ as ▁ the ▁ build ▁ in ENDCOM # ▁ aggregated ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" , "2" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , TEXT ] ] , " times " : [ [ 2 , 0 ] ] } } } , # ▁ Expected ▁ no ▁ merge ▁ happens . ENDCOM { " builds " : [ "3" , "2" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 7 , TEXT ] ] , " times " : [ [ 7 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_remove_new_test ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 199 , TEXT ] ] , " times " : [ [ 199 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , " notrun . html " : { " results " : [ [ 1 , NOTRUN ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_remove_test ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_updates_expected ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " expected " : " FAIL " , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " FAIL " , " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " expected " : " FAIL " , " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " results " : [ [ 199 , PASS ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "002 . html " : { " expected " : " PASS " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 191 , PASS ] , [ 9 , NO_DATA ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_keep_test_with_all_pass_but_slow_time ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_pruning_slow_tests_for_debug_builders ( self ) : NEW_LINE INDENT self . _builder = " MockBuilder ( dbg ) " NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results ( self ) : NEW_LINE # ▁ Remove ▁ items ▁ from ▁ test ▁ results ▁ and ▁ times ▁ that ▁ exceed ▁ the ▁ max ▁ number ENDCOM # ▁ of ▁ builds ▁ to ▁ track . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results_small ( self ) : NEW_LINE # ▁ Remove ▁ items ▁ from ▁ test ▁ results ▁ and ▁ times ▁ that ▁ exceed ▁ the ▁ max ▁ number ENDCOM # ▁ of ▁ builds ▁ to ▁ track , ▁ using ▁ smaller ▁ threshold . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_prune_extra_results_with_new_result_of_same_type ( self ) : NEW_LINE # ▁ Test ▁ that ▁ merging ▁ in ▁ a ▁ new ▁ result ▁ of ▁ the ▁ same ▁ type ▁ as ▁ the ▁ last ▁ result ENDCOM # ▁ causes ▁ old ▁ results ▁ to ▁ fall ▁ off . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , NO_DATA ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] ] , " times " : [ [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_build_directory_hierarchy ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 25 , TEXT ] ] , " times " : [ [ 25 , 0 ] ] } } } , " foo " : { "001 . html " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } } } , " version " : 4 } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } } , " version " : 4 } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 25 , TEXT ] ] , " times " : [ [ 26 , 0 ] ] } } } , " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 51 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } } } , " version " : 4 } ) NEW_LINE # ▁ FIXME ( aboxhall ) : ▁ Add ▁ some ▁ tests ▁ for ▁ xhtml / svg ▁ test ▁ results . ENDCOM DEDENT def test_get_test_name_list ( self ) : NEW_LINE # ▁ Get ▁ test ▁ name ▁ list ▁ only . ▁ Don ' t ▁ include ▁ non - test - list ▁ data ▁ and ENDCOM # ▁ of ▁ test ▁ result ▁ details . ENDCOM # ▁ FIXME : ▁ This ▁ also ▁ tests ▁ a ▁ temporary ▁ bug ▁ in ▁ the ▁ data ▁ where ▁ directory - level ENDCOM # ▁ results ▁ have ▁ a ▁ results ▁ and ▁ times ▁ values . ▁ Once ▁ that ▁ bug ▁ is ▁ fixed , ENDCOM # ▁ remove ▁ this ▁ test - case ▁ and ▁ assert ▁ we ▁ don ' t ▁ ever ▁ hit ▁ it . ENDCOM INDENT self . _test_get_test_list ( # ▁ Input ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " foo " : { "001 . html " : { } } , "002 . html " : { } } ) NEW_LINE DEDENT def test_gtest ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 3 } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " foo . bar2" : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 4 } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 1 , NO_DATA ] , [ 50 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 10 , FAIL ] ] , " times " : [ [ 10 , 0 ] ] } , } , " version " : 4 } ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT unittest . main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="bert9bert/statsmodels/tree/master/statsmodels/sandbox/nonparametric/kernel_extras.py"> """ STRNEWLINE Multivariate ▁ Conditional ▁ and ▁ Unconditional ▁ Kernel ▁ Density ▁ Estimation STRNEWLINE with ▁ Mixed ▁ Data ▁ Types STRNEWLINE STRNEWLINE References STRNEWLINE - - - - - STRNEWLINE [ 1 ] ▁ Racine , ▁ J . , ▁ Li , ▁ Q . ▁ Nonparametric ▁ econometrics : ▁ theory ▁ and ▁ practice . STRNEWLINE ▁ Princeton ▁ University ▁ Press . ▁ ( 2007 ) STRNEWLINE [ 2 ] ▁ Racine , ▁ Jeff . ▁ " Nonparametric ▁ Econometrics : ▁ A ▁ Primer , " ▁ Foundation STRNEWLINE ▁ and ▁ Trends ▁ in ▁ Econometrics : ▁ Vol ▁ 3 : ▁ No ▁ 1 , ▁ pp1-88 . ▁ ( 2008 ) STRNEWLINE ▁ http : / / dx . doi . org / 10.1561/08000009 STRNEWLINE [ 3 ] ▁ Racine , ▁ J . , ▁ Li , ▁ Q . ▁ " Nonparametric ▁ Estimation ▁ of ▁ Distributions STRNEWLINE ▁ with ▁ Categorical ▁ and ▁ Continuous ▁ Data . " ▁ Working ▁ Paper . ▁ ( 2000 ) STRNEWLINE [ 4 ] ▁ Racine , ▁ J . ▁ Li , ▁ Q . ▁ " Kernel ▁ Estimation ▁ of ▁ Multivariate ▁ Conditional STRNEWLINE ▁ Distributions ▁ Annals ▁ of ▁ Economics ▁ and ▁ Finance ▁ 5 , ▁ 211-235 ▁ ( 2004 ) STRNEWLINE [ 5 ] ▁ Liu , ▁ R . , ▁ Yang , ▁ L . ▁ " Kernel ▁ estimation ▁ of ▁ multivariate STRNEWLINE ▁ cumulative ▁ distribution ▁ function . " STRNEWLINE ▁ Journal ▁ of ▁ Nonparametric ▁ Statistics ▁ ( 2008 ) STRNEWLINE [ 6 ] ▁ Li , ▁ R . , ▁ Ju , ▁ G . ▁ " Nonparametric ▁ Estimation ▁ of ▁ Multivariate ▁ CDF STRNEWLINE ▁ with ▁ Categorical ▁ and ▁ Continuous ▁ Data . " ▁ Working ▁ Paper STRNEWLINE [ 7 ] ▁ Li , ▁ Q . , ▁ Racine , ▁ J . ▁ " Cross - validated ▁ local ▁ linear ▁ nonparametric STRNEWLINE ▁ regression " ▁ Statistica ▁ Sinica ▁ 14(2004 ) , ▁ pp . ▁ 485-512 STRNEWLINE [ 8 ] ▁ Racine , ▁ J . : ▁ " Consistent ▁ Significance ▁ Testing ▁ for ▁ Nonparametric STRNEWLINE ▁ Regression " ▁ Journal ▁ of ▁ Business ▁ & ▁ Economics ▁ Statistics STRNEWLINE [ 9 ] ▁ Racine , ▁ J . , ▁ Hart , ▁ J . , ▁ Li , ▁ Q . , ▁ " Testing ▁ the ▁ Significance ▁ of STRNEWLINE ▁ Categorical ▁ Predictor ▁ Variables ▁ in ▁ Nonparametric ▁ Regression STRNEWLINE ▁ Models " , ▁ 2006 , ▁ Econometric ▁ Reviews ▁ 25 , ▁ 523-544 STRNEWLINE STRNEWLINE """ NEW_LINE # ▁ TODO : ▁ make ▁ default ▁ behavior ▁ efficient = True ▁ above ▁ a ▁ certain ▁ n _ obs ENDCOM from statsmodels . compat . python import range , next NEW_LINE import numpy as np NEW_LINE from scipy import optimize NEW_LINE from scipy . stats . mstats import mquantiles NEW_LINE from statsmodels . nonparametric . api import KDEMultivariate , KernelReg NEW_LINE from statsmodels . nonparametric . _kernel_base import gpke , LeaveOneOut , _get_type_pos , _adjust_shape NEW_LINE __all__ = [ ' SingleIndexModel ' , ' SemiLinear ' , ' TestFForm ' ] NEW_LINE class TestFForm ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ Nonparametric ▁ test ▁ for ▁ functional ▁ form . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ endog : ▁ list STRNEWLINE ▁ Dependent ▁ variable ▁ ( training ▁ set ) STRNEWLINE ▁ exog : ▁ list ▁ of ▁ array _ like ▁ objects STRNEWLINE ▁ The ▁ independent ▁ ( right - hand - side ) ▁ variables STRNEWLINE ▁ bw : ▁ array _ like , ▁ str STRNEWLINE ▁ Bandwidths ▁ for ▁ exog ▁ or ▁ specify ▁ method ▁ for ▁ bandwidth ▁ selection STRNEWLINE ▁ fform : ▁ function STRNEWLINE ▁ The ▁ functional ▁ form ▁ ` ` y ▁ = ▁ g ( b , ▁ x ) ` ` ▁ to ▁ be ▁ tested . ▁ Takes ▁ as ▁ inputs STRNEWLINE ▁ the ▁ RHS ▁ variables ▁ ` exog ` ▁ and ▁ the ▁ coefficients ▁ ` ` b ` ` ▁ ( betas ) STRNEWLINE ▁ and ▁ returns ▁ a ▁ fitted ▁ ` ` y _ hat ` ` . STRNEWLINE ▁ var _ type : ▁ str STRNEWLINE ▁ The ▁ type ▁ of ▁ the ▁ independent ▁ ` exog ` ▁ variables : STRNEWLINE STRNEWLINE ▁ - ▁ c : ▁ continuous STRNEWLINE ▁ - ▁ o : ▁ ordered STRNEWLINE ▁ - ▁ u : ▁ unordered STRNEWLINE STRNEWLINE ▁ estimator : ▁ function STRNEWLINE ▁ Must ▁ return ▁ the ▁ estimated ▁ coefficients ▁ b ▁ ( betas ) . ▁ Takes ▁ as ▁ inputs STRNEWLINE ▁ ` ` ( endog , ▁ exog ) ` ` . ▁ E . g . ▁ least ▁ square ▁ estimator : : STRNEWLINE STRNEWLINE ▁ lambda ▁ ( x , y ) : ▁ np . dot ( np . pinv ( np . dot ( x . T , ▁ x ) ) , ▁ np . dot ( x . T , ▁ y ) ) STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ Racine , ▁ J . : ▁ " Consistent ▁ Significance ▁ Testing ▁ for ▁ Nonparametric STRNEWLINE ▁ Regression " ▁ Journal ▁ of ▁ Business ▁ \ & ▁ Economics ▁ Statistics . STRNEWLINE STRNEWLINE ▁ See ▁ chapter ▁ 12 ▁ in ▁ [ 1 ] ▁ pp . ▁ 355-357 . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , endog , exog , bw , var_type , fform , estimator , nboot = 100 ) : NEW_LINE INDENT self . endog = endog NEW_LINE self . exog = exog NEW_LINE self . var_type = var_type NEW_LINE self . fform = fform NEW_LINE self . estimator = estimator NEW_LINE self . nboot = nboot NEW_LINE self . bw = KDEMultivariate ( exog , bw = bw , var_type = var_type ) . bw NEW_LINE self . sig = self . _compute_sig ( ) NEW_LINE DEDENT def _compute_sig ( self ) : NEW_LINE INDENT Y = self . endog NEW_LINE X = self . exog NEW_LINE b = self . estimator ( Y , X ) NEW_LINE m = self . fform ( X , b ) NEW_LINE n = np . shape ( X ) [ 0 ] NEW_LINE resid = Y - m NEW_LINE resid = resid - np . mean ( resid ) # ▁ center ▁ residuals ENDCOM NEW_LINE self . test_stat = self . _compute_test_stat ( resid ) NEW_LINE sqrt5 = np . sqrt ( 5. ) NEW_LINE fct1 = ( 1 - sqrt5 ) / 2. NEW_LINE fct2 = ( 1 + sqrt5 ) / 2. NEW_LINE u1 = fct1 * resid NEW_LINE u2 = fct2 * resid NEW_LINE r = fct2 / sqrt5 NEW_LINE I_dist = np . empty ( ( self . nboot , 1 ) ) NEW_LINE for j in range ( self . nboot ) : NEW_LINE INDENT u_boot = u2 . copy ( ) NEW_LINE prob = np . random . uniform ( 0 , 1 , size = ( n , ) ) NEW_LINE ind = prob < r NEW_LINE u_boot [ ind ] = u1 [ ind ] NEW_LINE Y_boot = m + u_boot NEW_LINE b_hat = self . estimator ( Y_boot , X ) NEW_LINE m_hat = self . fform ( X , b_hat ) NEW_LINE u_boot_hat = Y_boot - m_hat NEW_LINE I_dist [ j ] = self . _compute_test_stat ( u_boot_hat ) NEW_LINE DEDENT self . boots_results = I_dist NEW_LINE sig = " Not ▁ Significant " NEW_LINE if self . test_stat > mquantiles ( I_dist , 0.9 ) : NEW_LINE INDENT sig = " * " NEW_LINE DEDENT if self . test_stat > mquantiles ( I_dist , 0.95 ) : NEW_LINE INDENT sig = " * * " NEW_LINE DEDENT if self . test_stat > mquantiles ( I_dist , 0.99 ) : NEW_LINE INDENT sig = " * * * " NEW_LINE DEDENT return sig NEW_LINE DEDENT def _compute_test_stat ( self , u ) : NEW_LINE INDENT n = np . shape ( u ) [ 0 ] NEW_LINE XLOO = LeaveOneOut ( self . exog ) NEW_LINE uLOO = LeaveOneOut ( u [ : , None ] ) . __iter__ ( ) NEW_LINE I = 0 NEW_LINE S2 = 0 NEW_LINE for i , X_not_i in enumerate ( XLOO ) : NEW_LINE INDENT u_j = next ( uLOO ) NEW_LINE u_j = np . squeeze ( u_j ) NEW_LINE # ▁ See ▁ Bootstrapping ▁ procedure ▁ on ▁ p . ▁ 357 ▁ in ▁ [ 1 ] ENDCOM K = gpke ( self . bw , data = - X_not_i , data_predict = - self . exog [ i , : ] , var_type = self . var_type , tosum = False ) NEW_LINE f_i = ( u [ i ] * u_j * K ) NEW_LINE assert u_j . shape == K . shape NEW_LINE I += f_i . sum ( ) # ▁ See ▁ eq . ▁ 12.7 ▁ on ▁ p . ▁ 355 ▁ in ▁ [ 1 ] ENDCOM NEW_LINE S2 += ( f_i ** 2 ) . sum ( ) # ▁ See ▁ Theorem ▁ 12.1 ▁ on ▁ p . 356 ▁ in ▁ [ 1 ] ENDCOM NEW_LINE assert np . size ( I ) == 1 NEW_LINE assert np . size ( S2 ) == 1 NEW_LINE DEDENT I *= 1. / ( n * ( n - 1 ) ) NEW_LINE ix_cont = _get_type_pos ( self . var_type ) [ 0 ] NEW_LINE hp = self . bw [ ix_cont ] . prod ( ) NEW_LINE S2 *= 2 * hp / ( n * ( n - 1 ) ) NEW_LINE T = n * I * np . sqrt ( hp / S2 ) NEW_LINE return T NEW_LINE DEDENT DEDENT class SingleIndexModel ( KernelReg ) : NEW_LINE INDENT """ STRNEWLINE ▁ Single ▁ index ▁ semiparametric ▁ model ▁ ` ` y ▁ = ▁ g ( X ▁ * ▁ b ) ▁ + ▁ e ` ` . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ endog : ▁ array _ like STRNEWLINE ▁ The ▁ dependent ▁ variable STRNEWLINE ▁ exog : ▁ array _ like STRNEWLINE ▁ The ▁ independent ▁ variable ( s ) STRNEWLINE ▁ var _ type : ▁ str STRNEWLINE ▁ The ▁ type ▁ of ▁ variables ▁ in ▁ X : STRNEWLINE STRNEWLINE ▁ - ▁ c : ▁ continuous STRNEWLINE ▁ - ▁ o : ▁ ordered STRNEWLINE ▁ - ▁ u : ▁ unordered STRNEWLINE STRNEWLINE ▁ Attributes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ b : ▁ array _ like STRNEWLINE ▁ The ▁ linear ▁ coefficients ▁ b ▁ ( betas ) STRNEWLINE ▁ bw : ▁ array _ like STRNEWLINE ▁ Bandwidths STRNEWLINE STRNEWLINE ▁ Methods STRNEWLINE ▁ - - - - - STRNEWLINE ▁ fit ( ) : ▁ Computes ▁ the ▁ fitted ▁ values ▁ ` ` E [ Y | X ] ▁ = ▁ g ( X ▁ * ▁ b ) ` ` STRNEWLINE ▁ and ▁ the ▁ marginal ▁ effects ▁ ` ` dY / dX ` ` . STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ chapter ▁ on ▁ semiparametric ▁ models ▁ in ▁ [ 1 ] STRNEWLINE STRNEWLINE ▁ Notes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ This ▁ model ▁ resembles ▁ the ▁ binary ▁ choice ▁ models . ▁ The ▁ user ▁ knows STRNEWLINE ▁ that ▁ X ▁ and ▁ b ▁ interact ▁ linearly , ▁ but ▁ ` ` g ( X ▁ * ▁ b ) ` ` ▁ is ▁ unknown . STRNEWLINE ▁ In ▁ the ▁ parametric ▁ binary ▁ choice ▁ models ▁ the ▁ user ▁ usually ▁ assumes STRNEWLINE ▁ some ▁ distribution ▁ of ▁ g ( ) ▁ such ▁ as ▁ normal ▁ or ▁ logistic . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , endog , exog , var_type ) : NEW_LINE INDENT self . var_type = var_type NEW_LINE self . K = len ( var_type ) NEW_LINE self . var_type = self . var_type [ 0 ] NEW_LINE self . endog = _adjust_shape ( endog , 1 ) NEW_LINE self . exog = _adjust_shape ( exog , self . K ) NEW_LINE self . nobs = np . shape ( self . exog ) [ 0 ] NEW_LINE self . data_type = self . var_type NEW_LINE self . func = self . _est_loc_linear NEW_LINE self . b , self . bw = self . _est_b_bw ( ) NEW_LINE DEDENT def _est_b_bw ( self ) : NEW_LINE INDENT params0 = np . random . uniform ( size = ( self . K + 1 , ) ) NEW_LINE b_bw = optimize . fmin ( self . cv_loo , params0 , disp = 0 ) NEW_LINE b = b_bw [ 0 : self . K ] NEW_LINE bw = b_bw [ self . K : ] NEW_LINE bw = self . _set_bw_bounds ( bw ) NEW_LINE return b , bw NEW_LINE DEDENT def cv_loo ( self , params ) : NEW_LINE # ▁ See ▁ p . ▁ 254 ▁ in ▁ Textbook ENDCOM INDENT params = np . asarray ( params ) NEW_LINE b = params [ 0 : self . K ] NEW_LINE bw = params [ self . K : ] NEW_LINE LOO_X = LeaveOneOut ( self . exog ) NEW_LINE LOO_Y = LeaveOneOut ( self . endog ) . __iter__ ( ) NEW_LINE L = 0 NEW_LINE for i , X_not_i in enumerate ( LOO_X ) : NEW_LINE INDENT Y = next ( LOO_Y ) NEW_LINE # print ▁ b . shape , ▁ np . dot ( self . exog [ i : i + 1 , ▁ : ] , ▁ b ) . shape , ▁ bw , ENDCOM G = self . func ( bw , endog = Y , exog = - np . dot ( X_not_i , b ) [ : , None ] , # data _ predict = - b * self . exog [ i , ▁ : ] ) [0 ] ENDCOM data_predict = - np . dot ( self . exog [ i : i + 1 , : ] , b ) ) [ 0 ] NEW_LINE # print ▁ G . shape ENDCOM L += ( self . endog [ i ] - G ) ** 2 NEW_LINE # ▁ Note : ▁ There ▁ might ▁ be ▁ a ▁ way ▁ to ▁ vectorize ▁ this . ▁ See ▁ p . 72 ▁ in ▁ [ 1 ] ENDCOM DEDENT return L / self . nobs NEW_LINE DEDENT def fit ( self , data_predict = None ) : NEW_LINE INDENT if data_predict is None : NEW_LINE INDENT data_predict = self . exog NEW_LINE DEDENT else : NEW_LINE INDENT data_predict = _adjust_shape ( data_predict , self . K ) NEW_LINE DEDENT N_data_predict = np . shape ( data_predict ) [ 0 ] NEW_LINE mean = np . empty ( ( N_data_predict , ) ) NEW_LINE mfx = np . empty ( ( N_data_predict , self . K ) ) NEW_LINE for i in range ( N_data_predict ) : NEW_LINE INDENT mean_mfx = self . func ( self . bw , self . endog , np . dot ( self . exog , self . b ) [ : , None ] , data_predict = np . dot ( data_predict [ i : i + 1 , : ] , self . b ) ) NEW_LINE mean [ i ] = mean_mfx [ 0 ] NEW_LINE mfx_c = np . squeeze ( mean_mfx [ 1 ] ) NEW_LINE mfx [ i , : ] = mfx_c NEW_LINE DEDENT return mean , mfx NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT """ Provide ▁ something ▁ sane ▁ to ▁ print . """ NEW_LINE repr = " Single ▁ Index ▁ Model ▁ \n " NEW_LINE repr += " Number ▁ of ▁ variables : ▁ K ▁ = ▁ " + str ( self . K ) + " \n " NEW_LINE repr += " Number ▁ of ▁ samples : ▁ ▁ ▁ nobs ▁ = ▁ " + str ( self . nobs ) + " \n " NEW_LINE repr += " Variable ▁ types : ▁ ▁ ▁ ▁ ▁ ▁ " + self . var_type + " \n " NEW_LINE repr += " BW ▁ selection ▁ method : ▁ cv _ ls " + " \n " NEW_LINE repr += " Estimator ▁ type : ▁ local ▁ constant " + " \n " NEW_LINE return repr NEW_LINE DEDENT DEDENT class SemiLinear ( KernelReg ) : NEW_LINE INDENT """ STRNEWLINE ▁ Semiparametric ▁ partially ▁ linear ▁ model , ▁ ` ` Y ▁ = ▁ Xb ▁ + ▁ g ( Z ) ▁ + ▁ e ` ` . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ endog : ▁ array _ like STRNEWLINE ▁ The ▁ dependent ▁ variable STRNEWLINE ▁ exog : ▁ array _ like STRNEWLINE ▁ The ▁ linear ▁ component ▁ in ▁ the ▁ regression STRNEWLINE ▁ exog _ nonparametric : ▁ array _ like STRNEWLINE ▁ The ▁ nonparametric ▁ component ▁ in ▁ the ▁ regression STRNEWLINE ▁ var _ type : ▁ str STRNEWLINE ▁ The ▁ type ▁ of ▁ the ▁ variables ▁ in ▁ the ▁ nonparametric ▁ component ; STRNEWLINE STRNEWLINE ▁ - ▁ c : ▁ continuous STRNEWLINE ▁ - ▁ o : ▁ ordered STRNEWLINE ▁ - ▁ u : ▁ unordered STRNEWLINE STRNEWLINE ▁ k _ linear ▁ : ▁ int STRNEWLINE ▁ The ▁ number ▁ of ▁ variables ▁ that ▁ comprise ▁ the ▁ linear ▁ component . STRNEWLINE STRNEWLINE ▁ Attributes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bw : ▁ array _ like STRNEWLINE ▁ Bandwidths ▁ for ▁ the ▁ nonparametric ▁ component ▁ exog _ nonparametric STRNEWLINE ▁ b : ▁ array _ like STRNEWLINE ▁ Coefficients ▁ in ▁ the ▁ linear ▁ component STRNEWLINE ▁ nobs ▁ : ▁ int STRNEWLINE ▁ The ▁ number ▁ of ▁ observations . STRNEWLINE ▁ k _ linear ▁ : ▁ int STRNEWLINE ▁ The ▁ number ▁ of ▁ variables ▁ that ▁ comprise ▁ the ▁ linear ▁ component . STRNEWLINE STRNEWLINE ▁ Methods STRNEWLINE ▁ - - - - - STRNEWLINE ▁ fit ( ) : ▁ Returns ▁ the ▁ fitted ▁ mean ▁ and ▁ marginal ▁ effects ▁ dy / dz STRNEWLINE STRNEWLINE ▁ Notes STRNEWLINE ▁ - - - - - STRNEWLINE ▁ This ▁ model ▁ uses ▁ only ▁ the ▁ local ▁ constant ▁ regression ▁ estimator STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ chapter ▁ on ▁ Semiparametric ▁ Models ▁ in ▁ [ 1 ] STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , endog , exog , exog_nonparametric , var_type , k_linear ) : NEW_LINE INDENT self . endog = _adjust_shape ( endog , 1 ) NEW_LINE self . exog = _adjust_shape ( exog , k_linear ) NEW_LINE self . K = len ( var_type ) NEW_LINE self . exog_nonparametric = _adjust_shape ( exog_nonparametric , self . K ) NEW_LINE self . k_linear = k_linear NEW_LINE self . nobs = np . shape ( self . exog ) [ 0 ] NEW_LINE self . var_type = var_type NEW_LINE self . data_type = self . var_type NEW_LINE self . func = self . _est_loc_linear NEW_LINE self . b , self . bw = self . _est_b_bw ( ) NEW_LINE DEDENT def _est_b_bw ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Computes ▁ the ▁ ( beta ) ▁ coefficients ▁ and ▁ the ▁ bandwidths . STRNEWLINE STRNEWLINE ▁ Minimizes ▁ ` ` cv _ loo ` ` ▁ with ▁ respect ▁ to ▁ ` ` b ` ` ▁ and ▁ ` ` bw ` ` . STRNEWLINE ▁ """ NEW_LINE params0 = np . random . uniform ( size = ( self . k_linear + self . K , ) ) NEW_LINE b_bw = optimize . fmin ( self . cv_loo , params0 , disp = 0 ) NEW_LINE b = b_bw [ 0 : self . k_linear ] NEW_LINE bw = b_bw [ self . k_linear : ] NEW_LINE # bw ▁ = ▁ self . _ set _ bw _ bounds ( np . asarray ( bw ) ) ENDCOM return b , bw NEW_LINE DEDENT def cv_loo ( self , params ) : NEW_LINE INDENT """ STRNEWLINE ▁ Similar ▁ to ▁ the ▁ cross ▁ validation ▁ leave - one - out ▁ estimator . STRNEWLINE STRNEWLINE ▁ Modified ▁ to ▁ reflect ▁ the ▁ linear ▁ components . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ params : ▁ array _ like STRNEWLINE ▁ Vector ▁ consisting ▁ of ▁ the ▁ coefficients ▁ ( b ) ▁ and ▁ the ▁ bandwidths ▁ ( bw ) . STRNEWLINE ▁ The ▁ first ▁ ` ` k _ linear ` ` ▁ elements ▁ are ▁ the ▁ coefficients . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ L : ▁ float STRNEWLINE ▁ The ▁ value ▁ of ▁ the ▁ objective ▁ function STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ See ▁ p . 254 ▁ in ▁ [ 1 ] STRNEWLINE ▁ """ NEW_LINE params = np . asarray ( params ) NEW_LINE b = params [ 0 : self . k_linear ] NEW_LINE bw = params [ self . k_linear : ] NEW_LINE LOO_X = LeaveOneOut ( self . exog ) NEW_LINE LOO_Y = LeaveOneOut ( self . endog ) . __iter__ ( ) NEW_LINE LOO_Z = LeaveOneOut ( self . exog_nonparametric ) . __iter__ ( ) NEW_LINE Xb = np . dot ( self . exog , b ) [ : , None ] NEW_LINE L = 0 NEW_LINE for ii , X_not_i in enumerate ( LOO_X ) : NEW_LINE INDENT Y = next ( LOO_Y ) NEW_LINE Z = next ( LOO_Z ) NEW_LINE Xb_j = np . dot ( X_not_i , b ) [ : , None ] NEW_LINE Yx = Y - Xb_j NEW_LINE G = self . func ( bw , endog = Yx , exog = - Z , data_predict = - self . exog_nonparametric [ ii , : ] ) [ 0 ] NEW_LINE lt = Xb [ ii , : ] # . sum ( ) ▁ # ▁ linear ▁ term ENDCOM NEW_LINE L += ( self . endog [ ii ] - lt - G ) ** 2 NEW_LINE DEDENT return L NEW_LINE DEDENT def fit ( self , exog_predict = None , exog_nonparametric_predict = None ) : NEW_LINE INDENT """ Computes ▁ fitted ▁ values ▁ and ▁ marginal ▁ effects """ NEW_LINE if exog_predict is None : NEW_LINE INDENT exog_predict = self . exog NEW_LINE DEDENT else : NEW_LINE INDENT exog_predict = _adjust_shape ( exog_predict , self . k_linear ) NEW_LINE DEDENT if exog_nonparametric_predict is None : NEW_LINE INDENT exog_nonparametric_predict = self . exog_nonparametric NEW_LINE DEDENT else : NEW_LINE INDENT exog_nonparametric_predict = _adjust_shape ( exog_nonparametric_predict , self . K ) NEW_LINE DEDENT N_data_predict = np . shape ( exog_nonparametric_predict ) [ 0 ] NEW_LINE mean = np . empty ( ( N_data_predict , ) ) NEW_LINE mfx = np . empty ( ( N_data_predict , self . K ) ) NEW_LINE Y = self . endog - np . dot ( exog_predict , self . b ) [ : , None ] NEW_LINE for i in range ( N_data_predict ) : NEW_LINE INDENT mean_mfx = self . func ( self . bw , Y , self . exog_nonparametric , data_predict = exog_nonparametric_predict [ i , : ] ) NEW_LINE mean [ i ] = mean_mfx [ 0 ] NEW_LINE mfx_c = np . squeeze ( mean_mfx [ 1 ] ) NEW_LINE mfx [ i , : ] = mfx_c NEW_LINE DEDENT return mean , mfx NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT """ Provide ▁ something ▁ sane ▁ to ▁ print . """ NEW_LINE repr = " Semiparamatric ▁ Partially ▁ Linear ▁ Model ▁ \n " NEW_LINE repr += " Number ▁ of ▁ variables : ▁ K ▁ = ▁ " + str ( self . K ) + " \n " NEW_LINE repr += " Number ▁ of ▁ samples : ▁ ▁ ▁ N ▁ = ▁ " + str ( self . nobs ) + " \n " NEW_LINE repr += " Variable ▁ types : ▁ ▁ ▁ ▁ ▁ ▁ " + self . var_type + " \n " NEW_LINE repr += " BW ▁ selection ▁ method : ▁ cv _ ls " + " \n " NEW_LINE repr += " Estimator ▁ type : ▁ local ▁ constant " + " \n " NEW_LINE return repr NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="octacoin-project/beta/tree/master/share/qt/extract_strings_qt.py"> # ! / usr / bin / python ENDCOM ''' STRNEWLINE Extract ▁ _ ( " . . . " ) ▁ strings ▁ for ▁ translation ▁ and ▁ convert ▁ to ▁ Qt4 ▁ stringdefs ▁ so ▁ that STRNEWLINE they ▁ can ▁ be ▁ picked ▁ up ▁ by ▁ Qt ▁ linguist . STRNEWLINE ''' NEW_LINE from subprocess import Popen , PIPE NEW_LINE import glob NEW_LINE import operator NEW_LINE import os NEW_LINE import sys NEW_LINE OUT_CPP = " qt / bitcoinstrings . cpp " NEW_LINE EMPTY = [ ' " " ' ] NEW_LINE def parse_po ( text ) : NEW_LINE INDENT """ STRNEWLINE ▁ Parse ▁ ' po ' ▁ format ▁ produced ▁ by ▁ xgettext . STRNEWLINE ▁ Return ▁ a ▁ list ▁ of ▁ ( msgid , msgstr ) ▁ tuples . STRNEWLINE ▁ """ NEW_LINE messages = [ ] NEW_LINE msgid = [ ] NEW_LINE msgstr = [ ] NEW_LINE in_msgid = False NEW_LINE in_msgstr = False NEW_LINE for line in text . split ( ' \n ' ) : NEW_LINE INDENT line = line . rstrip ( ' ' ) NEW_LINE if line . startswith ( ' msgid ▁ ' ) : NEW_LINE INDENT if in_msgstr : NEW_LINE INDENT messages . append ( ( msgid , msgstr ) ) NEW_LINE in_msgstr = False NEW_LINE # ▁ message ▁ start ENDCOM DEDENT in_msgid = True NEW_LINE msgid = [ line [ 6 : ] ] NEW_LINE DEDENT elif line . startswith ( ' msgstr ▁ ' ) : NEW_LINE INDENT in_msgid = False NEW_LINE in_msgstr = True NEW_LINE msgstr = [ line [ 7 : ] ] NEW_LINE DEDENT elif line . startswith ( ' " ' ) : NEW_LINE INDENT if in_msgid : NEW_LINE INDENT msgid . append ( line ) NEW_LINE DEDENT if in_msgstr : NEW_LINE INDENT msgstr . append ( line ) NEW_LINE DEDENT DEDENT DEDENT if in_msgstr : NEW_LINE INDENT messages . append ( ( msgid , msgstr ) ) NEW_LINE DEDENT return messages NEW_LINE DEDENT files = sys . argv [ 1 : ] NEW_LINE # ▁ xgettext ▁ - n ▁ - - keyword = _ ▁ $ FILES ENDCOM XGETTEXT = os . getenv ( ' XGETTEXT ' , ' xgettext ' ) NEW_LINE child = Popen ( [ XGETTEXT , ' - - output = - ' , ' - n ' , ' - - keyword = _ ' ] + files , stdout = PIPE ) NEW_LINE ( out , err ) = child . communicate ( ) NEW_LINE messages = parse_po ( out ) NEW_LINE f = open ( OUT_CPP , ' w ' ) NEW_LINE f . write ( """ STRNEWLINE STRNEWLINE # include ▁ < QtGlobal > STRNEWLINE STRNEWLINE / / ▁ Automatically ▁ generated ▁ by ▁ extract _ strings . py STRNEWLINE # ifdef ▁ _ _ GNUC _ _ STRNEWLINE # define ▁ UNUSED ▁ _ _ attribute _ _ ( ( unused ) ) STRNEWLINE # else STRNEWLINE # define ▁ UNUSED STRNEWLINE # endif STRNEWLINE """ ) NEW_LINE f . write ( ' static ▁ const ▁ char ▁ UNUSED ▁ * bitcoin _ strings [ ] ▁ = ▁ { \n ' ) NEW_LINE messages . sort ( key = operator . itemgetter ( 0 ) ) NEW_LINE for ( msgid , msgstr ) in messages : NEW_LINE INDENT if msgid != EMPTY : NEW_LINE INDENT f . write ( ' QT _ TRANSLATE _ NOOP ( " bitcoin - core " , ▁ % s ) , \n ' % ( ' \n ' . join ( msgid ) ) ) NEW_LINE DEDENT DEDENT f . write ( ' } ; \n ' ) NEW_LINE f . close ( ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="wsmith323/django/tree/master/tests/save_delete_hooks/tests.py"> from __future__ import unicode_literals NEW_LINE from django . test import TestCase NEW_LINE from django . utils import six NEW_LINE from . models import Person NEW_LINE class SaveDeleteHookTests ( TestCase ) : NEW_LINE INDENT def test_basic ( self ) : NEW_LINE INDENT p = Person ( first_name = " John " , last_name = " Smith " ) NEW_LINE self . assertEqual ( p . data , [ ] ) NEW_LINE p . save ( ) NEW_LINE self . assertEqual ( p . data , [ " Before ▁ save " , " After ▁ save " , ] ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) , [ " John ▁ Smith " , ] , six . text_type ) NEW_LINE p . delete ( ) NEW_LINE self . assertEqual ( p . data , [ " Before ▁ save " , " After ▁ save " , " Before ▁ deletion " , " After ▁ deletion " , ] ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) , [ ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="dssg/wikienergy/tree/master/disaggregator/build/pandas/pandas/io/tests/__init__.py"> def setUp ( ) : NEW_LINE INDENT import socket NEW_LINE socket . setdefaulttimeout ( 5 ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="shsingh/ansible/tree/master/lib/ansible/modules/cloud/azure/azure_rm_securitygroup.py"> # ! / usr / bin / python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2016 ▁ Matt ▁ Davis , ▁ < mdavis @ ansible . com > ENDCOM # ▁ Chris ▁ Houseknecht , ▁ < house @ redhat . com > ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM from __future__ import absolute_import , division , print_function NEW_LINE __metaclass__ = type NEW_LINE ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = ''' STRNEWLINE - - - STRNEWLINE module : ▁ azure _ rm _ securitygroup STRNEWLINE version _ added : ▁ " 2.1 " STRNEWLINE short _ description : ▁ Manage ▁ Azure ▁ network ▁ security ▁ groups . STRNEWLINE description : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ Create , ▁ update ▁ or ▁ delete ▁ a ▁ network ▁ security ▁ group . ▁ A ▁ security ▁ group ▁ contains ▁ Access ▁ Control ▁ List ▁ ( ACL ) ▁ rules STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ that ▁ allow ▁ or ▁ deny ▁ network ▁ traffic ▁ to ▁ subnets ▁ or ▁ individual ▁ network ▁ interfaces . ▁ A ▁ security ▁ group ▁ is ▁ created STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ with ▁ a ▁ set ▁ of ▁ default ▁ security ▁ rules ▁ and ▁ an ▁ empty ▁ set ▁ of ▁ security ▁ rules . ▁ Shape ▁ traffic ▁ flow ▁ by ▁ adding STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ rules ▁ to ▁ the ▁ empty ▁ set ▁ of ▁ security ▁ rules . STRNEWLINE STRNEWLINE options : STRNEWLINE ▁ ▁ ▁ ▁ default _ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ set ▁ of ▁ default ▁ rules ▁ automatically ▁ added ▁ to ▁ a ▁ security ▁ group ▁ at ▁ creation . ▁ In ▁ general ▁ default STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ rules ▁ will ▁ not ▁ be ▁ modified . ▁ Modify ▁ rules ▁ to ▁ shape ▁ the ▁ flow ▁ of ▁ traffic ▁ to ▁ or ▁ from ▁ a ▁ subnet ▁ or ▁ NIC . ▁ See STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ rules ▁ below ▁ for ▁ the ▁ makeup ▁ of ▁ a ▁ rule ▁ dict . STRNEWLINE ▁ ▁ ▁ ▁ location : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Valid ▁ azure ▁ location . ▁ Defaults ▁ to ▁ location ▁ of ▁ the ▁ resource ▁ group . STRNEWLINE ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ security ▁ group ▁ to ▁ operate ▁ on . STRNEWLINE ▁ ▁ ▁ ▁ purge _ default _ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Remove ▁ any ▁ existing ▁ rules ▁ not ▁ matching ▁ those ▁ defined ▁ in ▁ the ▁ default _ rules ▁ parameter . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE ▁ ▁ ▁ ▁ purge _ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Remove ▁ any ▁ existing ▁ rules ▁ not ▁ matching ▁ those ▁ defined ▁ in ▁ the ▁ rules ▁ parameters . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE ▁ ▁ ▁ ▁ resource _ group : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ resource ▁ group ▁ the ▁ security ▁ group ▁ belongs ▁ to . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Set ▁ of ▁ rules ▁ shaping ▁ traffic ▁ flow ▁ to ▁ or ▁ from ▁ a ▁ subnet ▁ or ▁ NIC . ▁ Each ▁ rule ▁ is ▁ a ▁ dictionary . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ suboptions : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Unique ▁ name ▁ for ▁ the ▁ rule . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Short ▁ description ▁ of ▁ the ▁ rule ' s ▁ purpose . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : ▁ Accepted ▁ traffic ▁ protocol . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Udp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ port _ range : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Port ▁ or ▁ range ▁ of ▁ ports ▁ from ▁ which ▁ traffic ▁ originates . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Port ▁ or ▁ range ▁ of ▁ ports ▁ to ▁ which ▁ traffic ▁ is ▁ headed . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ CIDR ▁ or ▁ source ▁ IP ▁ range . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Asterisk ▁ C ( * ) ▁ can ▁ also ▁ be ▁ used ▁ to ▁ match ▁ all ▁ source ▁ IPs . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Default ▁ tags ▁ such ▁ as ▁ C ( VirtualNetwork ) , ▁ C ( AzureLoadBalancer ) ▁ and ▁ C ( Internet ) ▁ can ▁ also ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ this ▁ is ▁ an ▁ ingress ▁ rule , ▁ specifies ▁ where ▁ network ▁ traffic ▁ originates ▁ from . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ destination ▁ address ▁ prefix . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ CIDR ▁ or ▁ destination ▁ IP ▁ range . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Asterisk ▁ C ( * ) ▁ can ▁ also ▁ be ▁ used ▁ to ▁ match ▁ all ▁ source ▁ IPs . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Default ▁ tags ▁ such ▁ as ▁ C ( VirtualNetwork ) , ▁ C ( AzureLoadBalancer ) ▁ and ▁ C ( Internet ) ▁ can ▁ also ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Whether ▁ or ▁ not ▁ to ▁ allow ▁ the ▁ traffic ▁ flow . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Deny STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Order ▁ in ▁ which ▁ to ▁ apply ▁ the ▁ rule . ▁ Must ▁ a ▁ unique ▁ integer ▁ between ▁ 100 ▁ and ▁ 4096 ▁ inclusive . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Indicates ▁ the ▁ direction ▁ of ▁ the ▁ traffic ▁ flow . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Outbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Assert ▁ the ▁ state ▁ of ▁ the ▁ security ▁ group . ▁ Set ▁ to ▁ C ( present ) ▁ to ▁ create ▁ or ▁ update ▁ a ▁ security ▁ group . ▁ Set ▁ to STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ C ( absent ) ▁ to ▁ remove ▁ a ▁ security ▁ group . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ absent STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ present STRNEWLINE STRNEWLINE extends _ documentation _ fragment : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ azure STRNEWLINE ▁ ▁ ▁ ▁ - ▁ azure _ tags STRNEWLINE STRNEWLINE author : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Chris ▁ Houseknecht ▁ ( @ chouseknecht ) " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Matt ▁ Davis ▁ ( @ nitzmahone ) " STRNEWLINE STRNEWLINE ''' NEW_LINE EXAMPLES = ''' STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ security ▁ group STRNEWLINE - ▁ azure _ rm _ securitygroup : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ resource _ group : ▁ myResourceGroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ mysecgroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ purge _ rules : ▁ yes STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ DenySSH STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Deny STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 100 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ ' AllowSSH ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.158.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.159.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 101 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ ' AllowMultiplePorts ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.158.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.159.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ 80 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ 443 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 102 STRNEWLINE STRNEWLINE # ▁ Update ▁ rules ▁ on ▁ existing ▁ security ▁ group STRNEWLINE - ▁ azure _ rm _ securitygroup : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ resource _ group : ▁ myResourceGroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ mysecgroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ DenySSH STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22-23 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Deny STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 100 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ AllowSSHFromHome STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : ▁ ' 174.109.158.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22-23 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 102 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ tags : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ testing : ▁ testing STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ delete : ▁ on - exit STRNEWLINE STRNEWLINE # ▁ Delete ▁ security ▁ group STRNEWLINE - ▁ azure _ rm _ securitygroup : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ resource _ group : ▁ myResourceGroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ mysecgroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE ''' NEW_LINE RETURN = ''' STRNEWLINE state : STRNEWLINE ▁ ▁ ▁ ▁ description : ▁ Current ▁ state ▁ of ▁ the ▁ security ▁ group . STRNEWLINE ▁ ▁ ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ dict STRNEWLINE ▁ ▁ ▁ ▁ sample : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " default _ rules " : ▁ [ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ inbound ▁ traffic ▁ from ▁ all ▁ VMs ▁ in ▁ VNET " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowVnetInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowVnetInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65000 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ inbound ▁ traffic ▁ from ▁ azure ▁ load ▁ balancer " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowAzureLoadBalancerInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowAzureLoadBalancerInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65001 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " AzureLoadBalancer " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Deny " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Deny ▁ all ▁ inbound ▁ traffic " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / DenyAllInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " DenyAllInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65500 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ outbound ▁ traffic ▁ from ▁ all ▁ VMs ▁ to ▁ all ▁ VMs ▁ in ▁ VNET " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Outbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowVnetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowVnetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65000 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ outbound ▁ traffic ▁ from ▁ all ▁ VMs ▁ to ▁ Internet " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " Internet " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Outbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowInternetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowInternetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65001 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Deny " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Deny ▁ all ▁ outbound ▁ traffic " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Outbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / DenyAllOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " DenyAllOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65500 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " location " : ▁ " westus " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " mysecgroup " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " network _ interfaces " : ▁ [ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " rules " : ▁ [ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Deny " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ null , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " 22 " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / securityRules / DenySSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " DenySSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 100 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " Tcp " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ null , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " 22 " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / securityRules / AllowSSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowSSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 101 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " Tcp " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " 174.109.158.0/24 " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " subnets " : ▁ [ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " tags " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " delete " : ▁ " on - exit " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " foo " : ▁ " bar " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " testing " : ▁ " testing " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " type " : ▁ " Microsoft . Network / networkSecurityGroups " STRNEWLINE ▁ ▁ ▁ ▁ } STRNEWLINE ''' # ▁ NOQA ENDCOM NEW_LINE try : NEW_LINE INDENT from msrestazure . azure_exceptions import CloudError NEW_LINE from azure . mgmt . network import NetworkManagementClient NEW_LINE DEDENT except ImportError : NEW_LINE # ▁ This ▁ is ▁ handled ▁ in ▁ azure _ rm _ common ENDCOM INDENT pass NEW_LINE DEDENT from ansible . module_utils . azure_rm_common import AzureRMModuleBase NEW_LINE from ansible . module_utils . six import integer_types NEW_LINE from ansible . module_utils . _text import to_native NEW_LINE def validate_rule ( self , rule , rule_type = None ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Apply ▁ defaults ▁ to ▁ a ▁ rule ▁ dictionary ▁ and ▁ check ▁ that ▁ all ▁ values ▁ are ▁ valid . STRNEWLINE STRNEWLINE ▁ : param ▁ rule : ▁ rule ▁ dict STRNEWLINE ▁ : param ▁ rule _ type : ▁ Set ▁ to ▁ ' default ' ▁ if ▁ the ▁ rule ▁ is ▁ part ▁ of ▁ the ▁ default ▁ set ▁ of ▁ rules . STRNEWLINE ▁ : return : ▁ None STRNEWLINE ▁ ''' NEW_LINE priority = rule . get ( ' priority ' , 0 ) NEW_LINE if rule_type != ' default ' and ( priority < 100 or priority > 4096 ) : NEW_LINE INDENT raise Exception ( " Rule ▁ priority ▁ must ▁ be ▁ between ▁ 100 ▁ and ▁ 4096" ) NEW_LINE DEDENT def check_plural ( src , dest ) : NEW_LINE INDENT if isinstance ( rule . get ( src ) , list ) : NEW_LINE INDENT rule [ dest ] = rule [ src ] NEW_LINE rule [ src ] = None NEW_LINE DEDENT DEDENT check_plural ( ' destination _ address _ prefix ' , ' destination _ address _ prefixes ' ) NEW_LINE check_plural ( ' source _ address _ prefix ' , ' source _ address _ prefixes ' ) NEW_LINE check_plural ( ' source _ port _ range ' , ' source _ port _ ranges ' ) NEW_LINE check_plural ( ' destination _ port _ range ' , ' destination _ port _ ranges ' ) NEW_LINE DEDENT def compare_rules_change ( old_list , new_list , purge_list ) : NEW_LINE INDENT old_list = old_list or [ ] NEW_LINE new_list = new_list or [ ] NEW_LINE changed = False NEW_LINE for old_rule in old_list : NEW_LINE INDENT matched = next ( ( x for x in new_list if x [ ' name ' ] == old_rule [ ' name ' ] ) , [ ] ) NEW_LINE if matched : # ▁ if ▁ the ▁ new ▁ one ▁ is ▁ in ▁ the ▁ old ▁ list , ▁ check ▁ whether ▁ it ▁ is ▁ updated ENDCOM NEW_LINE INDENT changed = changed or compare_rules ( old_rule , matched ) NEW_LINE DEDENT elif not purge_list : # ▁ keep ▁ this ▁ rule ENDCOM NEW_LINE INDENT new_list . append ( old_rule ) NEW_LINE DEDENT else : # ▁ one ▁ rule ▁ is ▁ removed ENDCOM NEW_LINE INDENT changed = True NEW_LINE # ▁ Compare ▁ new ▁ list ▁ and ▁ old ▁ list ▁ is ▁ the ▁ same ? ▁ here ▁ only ▁ compare ▁ names ENDCOM DEDENT DEDENT if not changed : NEW_LINE INDENT new_names = [ to_native ( x [ ' name ' ] ) for x in new_list ] NEW_LINE old_names = [ to_native ( x [ ' name ' ] ) for x in old_list ] NEW_LINE changed = ( set ( new_names ) != set ( old_names ) ) NEW_LINE DEDENT return changed , new_list NEW_LINE DEDENT def compare_rules ( old_rule , rule ) : NEW_LINE INDENT changed = False NEW_LINE if old_rule [ ' name ' ] != rule [ ' name ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule . get ( ' description ' , None ) != old_rule [ ' description ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' protocol ' ] != old_rule [ ' protocol ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' source _ port _ range ' ] ) != str ( old_rule [ ' source _ port _ range ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' destination _ port _ range ' ] ) != str ( old_rule [ ' destination _ port _ range ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' access ' ] != old_rule [ ' access ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' priority ' ] != old_rule [ ' priority ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' direction ' ] != old_rule [ ' direction ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' source _ address _ prefix ' ] ) != str ( old_rule [ ' source _ address _ prefix ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' destination _ address _ prefix ' ] ) != str ( old_rule [ ' destination _ address _ prefix ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' source _ address _ prefixes ' ) or [ ] ) != set ( old_rule . get ( ' source _ address _ prefixes ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' destination _ address _ prefixes ' ) or [ ] ) != set ( old_rule . get ( ' destination _ address _ prefixes ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' source _ port _ ranges ' ) or [ ] ) != set ( old_rule . get ( ' source _ port _ ranges ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' destination _ port _ ranges ' ) or [ ] ) != set ( old_rule . get ( ' destination _ port _ ranges ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT return changed NEW_LINE DEDENT def create_rule_instance ( self , rule ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Create ▁ an ▁ instance ▁ of ▁ SecurityRule ▁ from ▁ a ▁ dict . STRNEWLINE STRNEWLINE ▁ : param ▁ rule : ▁ dict STRNEWLINE ▁ : return : ▁ SecurityRule STRNEWLINE ▁ ''' NEW_LINE return self . nsg_models . SecurityRule ( description = rule . get ( ' description ' , None ) , protocol = rule . get ( ' protocol ' , None ) , source_port_range = rule . get ( ' source _ port _ range ' , None ) , destination_port_range = rule . get ( ' destination _ port _ range ' , None ) , source_address_prefix = rule . get ( ' source _ address _ prefix ' , None ) , source_address_prefixes = rule . get ( ' source _ address _ prefixes ' , None ) , destination_address_prefix = rule . get ( ' destination _ address _ prefix ' , None ) , destination_address_prefixes = rule . get ( ' destination _ address _ prefixes ' , None ) , source_port_ranges = rule . get ( ' source _ port _ ranges ' , None ) , destination_port_ranges = rule . get ( ' destination _ port _ ranges ' , None ) , access = rule . get ( ' access ' , None ) , priority = rule . get ( ' priority ' , None ) , direction = rule . get ( ' direction ' , None ) , provisioning_state = rule . get ( ' provisioning _ state ' , None ) , name = rule . get ( ' name ' , None ) , etag = rule . get ( ' etag ' , None ) ) NEW_LINE DEDENT def create_rule_dict_from_obj ( rule ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Create ▁ a ▁ dict ▁ from ▁ an ▁ instance ▁ of ▁ a ▁ SecurityRule . STRNEWLINE STRNEWLINE ▁ : param ▁ rule : ▁ SecurityRule STRNEWLINE ▁ : return : ▁ dict STRNEWLINE ▁ ''' NEW_LINE return dict ( id = rule . id , name = rule . name , description = rule . description , protocol = rule . protocol , source_port_range = rule . source_port_range , destination_port_range = rule . destination_port_range , source_address_prefix = rule . source_address_prefix , destination_address_prefix = rule . destination_address_prefix , source_port_ranges = rule . source_port_ranges , destination_port_ranges = rule . destination_port_ranges , source_address_prefixes = rule . source_address_prefixes , destination_address_prefixes = rule . destination_address_prefixes , access = rule . access , priority = rule . priority , direction = rule . direction , provisioning_state = rule . provisioning_state , etag = rule . etag ) NEW_LINE DEDENT def create_network_security_group_dict ( nsg ) : NEW_LINE INDENT results = dict ( id = nsg . id , name = nsg . name , type = nsg . type , location = nsg . location , tags = nsg . tags , ) NEW_LINE results [ ' rules ' ] = [ ] NEW_LINE if nsg . security_rules : NEW_LINE INDENT for rule in nsg . security_rules : NEW_LINE INDENT results [ ' rules ' ] . append ( create_rule_dict_from_obj ( rule ) ) NEW_LINE DEDENT DEDENT results [ ' default _ rules ' ] = [ ] NEW_LINE if nsg . default_security_rules : NEW_LINE INDENT for rule in nsg . default_security_rules : NEW_LINE INDENT results [ ' default _ rules ' ] . append ( create_rule_dict_from_obj ( rule ) ) NEW_LINE DEDENT DEDENT results [ ' network _ interfaces ' ] = [ ] NEW_LINE if nsg . network_interfaces : NEW_LINE INDENT for interface in nsg . network_interfaces : NEW_LINE INDENT results [ ' network _ interfaces ' ] . append ( interface . id ) NEW_LINE DEDENT DEDENT results [ ' subnets ' ] = [ ] NEW_LINE if nsg . subnets : NEW_LINE INDENT for subnet in nsg . subnets : NEW_LINE INDENT results [ ' subnets ' ] . append ( subnet . id ) NEW_LINE DEDENT DEDENT return results NEW_LINE DEDENT rule_spec = dict ( name = dict ( type = ' str ' , required = True ) , description = dict ( type = ' str ' ) , protocol = dict ( type = ' str ' , choices = [ ' Udp ' , ' Tcp ' , ' * ' ] , default = ' * ' ) , source_port_range = dict ( type = ' raw ' , default = ' * ' ) , destination_port_range = dict ( type = ' raw ' , default = ' * ' ) , source_address_prefix = dict ( type = ' raw ' , default = ' * ' ) , destination_address_prefix = dict ( type = ' raw ' , default = ' * ' ) , access = dict ( type = ' str ' , choices = [ ' Allow ' , ' Deny ' ] , default = ' Allow ' ) , priority = dict ( type = ' int ' , required = True ) , direction = dict ( type = ' str ' , choices = [ ' Inbound ' , ' Outbound ' ] , default = ' Inbound ' ) ) NEW_LINE class AzureRMSecurityGroup ( AzureRMModuleBase ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . module_arg_spec = dict ( default_rules = dict ( type = ' list ' , elements = ' dict ' , options = rule_spec ) , location = dict ( type = ' str ' ) , name = dict ( type = ' str ' , required = True ) , purge_default_rules = dict ( type = ' bool ' , default = False ) , purge_rules = dict ( type = ' bool ' , default = False ) , resource_group = dict ( required = True , type = ' str ' ) , rules = dict ( type = ' list ' , elements = ' dict ' , options = rule_spec ) , state = dict ( type = ' str ' , default = ' present ' , choices = [ ' present ' , ' absent ' ] ) , ) NEW_LINE self . default_rules = None NEW_LINE self . location = None NEW_LINE self . name = None NEW_LINE self . purge_default_rules = None NEW_LINE self . purge_rules = None NEW_LINE self . resource_group = None NEW_LINE self . rules = None NEW_LINE self . state = None NEW_LINE self . tags = None NEW_LINE self . nsg_models = None # ▁ type : ▁ azure . mgmt . network . models ENDCOM NEW_LINE self . results = dict ( changed = False , state = dict ( ) ) NEW_LINE super ( AzureRMSecurityGroup , self ) . __init__ ( self . module_arg_spec , supports_check_mode = True ) NEW_LINE DEDENT def exec_module ( self , ** kwargs ) : NEW_LINE # ▁ tighten ▁ up ▁ poll ▁ interval ▁ for ▁ security ▁ groups ; ▁ default ▁ 30s ▁ is ▁ an ▁ eternity ENDCOM # ▁ this ▁ value ▁ is ▁ still ▁ overridden ▁ by ▁ the ▁ response ▁ Retry - After ▁ header ▁ ( which ▁ is ▁ set ▁ on ▁ the ▁ initial ▁ operation ▁ response ▁ to ▁ 10s ) ENDCOM INDENT self . network_client . config . long_running_operation_timeout = 3 NEW_LINE self . nsg_models = self . network_client . network_security_groups . models NEW_LINE for key in list ( self . module_arg_spec . keys ( ) ) + [ ' tags ' ] : NEW_LINE INDENT setattr ( self , key , kwargs [ key ] ) NEW_LINE DEDENT changed = False NEW_LINE results = dict ( ) NEW_LINE resource_group = self . get_resource_group ( self . resource_group ) NEW_LINE if not self . location : NEW_LINE # ▁ Set ▁ default ▁ location ENDCOM INDENT self . location = resource_group . location NEW_LINE DEDENT if self . rules : NEW_LINE INDENT for rule in self . rules : NEW_LINE INDENT try : NEW_LINE INDENT validate_rule ( self , rule ) NEW_LINE DEDENT except Exception as exc : NEW_LINE INDENT self . fail ( " Error ▁ validating ▁ rule ▁ { 0 } ▁ - ▁ { 1 } " . format ( rule , str ( exc ) ) ) NEW_LINE DEDENT DEDENT DEDENT if self . default_rules : NEW_LINE INDENT for rule in self . default_rules : NEW_LINE INDENT try : NEW_LINE INDENT validate_rule ( self , rule , ' default ' ) NEW_LINE DEDENT except Exception as exc : NEW_LINE INDENT self . fail ( " Error ▁ validating ▁ default ▁ rule ▁ { 0 } ▁ - ▁ { 1 } " . format ( rule , str ( exc ) ) ) NEW_LINE DEDENT DEDENT DEDENT try : NEW_LINE INDENT nsg = self . network_client . network_security_groups . get ( self . resource_group , self . name ) NEW_LINE results = create_network_security_group_dict ( nsg ) NEW_LINE self . log ( " Found ▁ security ▁ group : " ) NEW_LINE self . log ( results , pretty_print = True ) NEW_LINE self . check_provisioning_state ( nsg , self . state ) NEW_LINE if self . state == ' present ' : NEW_LINE INDENT pass NEW_LINE DEDENT elif self . state == ' absent ' : NEW_LINE INDENT self . log ( " CHANGED : ▁ security ▁ group ▁ found ▁ but ▁ state ▁ is ▁ ' absent ' " ) NEW_LINE changed = True NEW_LINE DEDENT DEDENT except CloudError : # ▁ TODO : ▁ actually ▁ check ▁ for ▁ ResourceMissingError ENDCOM NEW_LINE INDENT if self . state == ' present ' : NEW_LINE INDENT self . log ( " CHANGED : ▁ security ▁ group ▁ not ▁ found ▁ and ▁ state ▁ is ▁ ' present ' " ) NEW_LINE changed = True NEW_LINE DEDENT DEDENT if self . state == ' present ' and not changed : NEW_LINE # ▁ update ▁ the ▁ security ▁ group ENDCOM INDENT self . log ( " Update ▁ security ▁ group ▁ { 0 } " . format ( self . name ) ) NEW_LINE update_tags , results [ ' tags ' ] = self . update_tags ( results [ ' tags ' ] ) NEW_LINE if update_tags : NEW_LINE INDENT changed = True NEW_LINE DEDENT rule_changed , new_rule = compare_rules_change ( results [ ' rules ' ] , self . rules , self . purge_rules ) NEW_LINE if rule_changed : NEW_LINE INDENT changed = True NEW_LINE results [ ' rules ' ] = new_rule NEW_LINE DEDENT rule_changed , new_rule = compare_rules_change ( results [ ' default _ rules ' ] , self . default_rules , self . purge_default_rules ) NEW_LINE if rule_changed : NEW_LINE INDENT changed = True NEW_LINE results [ ' default _ rules ' ] = new_rule NEW_LINE DEDENT self . results [ ' changed ' ] = changed NEW_LINE self . results [ ' state ' ] = results NEW_LINE if not self . check_mode and changed : NEW_LINE INDENT self . results [ ' state ' ] = self . create_or_update ( results ) NEW_LINE DEDENT DEDENT elif self . state == ' present ' and changed : NEW_LINE # ▁ create ▁ the ▁ security ▁ group ENDCOM INDENT self . log ( " Create ▁ security ▁ group ▁ { 0 } " . format ( self . name ) ) NEW_LINE if not self . location : NEW_LINE INDENT self . fail ( " Parameter ▁ error : ▁ location ▁ required ▁ when ▁ creating ▁ a ▁ security ▁ group . " ) NEW_LINE DEDENT results [ ' name ' ] = self . name NEW_LINE results [ ' location ' ] = self . location NEW_LINE results [ ' rules ' ] = [ ] NEW_LINE results [ ' default _ rules ' ] = [ ] NEW_LINE results [ ' tags ' ] = { } NEW_LINE if self . rules : NEW_LINE INDENT results [ ' rules ' ] = self . rules NEW_LINE DEDENT if self . default_rules : NEW_LINE INDENT results [ ' default _ rules ' ] = self . default_rules NEW_LINE DEDENT if self . tags : NEW_LINE INDENT results [ ' tags ' ] = self . tags NEW_LINE DEDENT self . results [ ' changed ' ] = changed NEW_LINE self . results [ ' state ' ] = results NEW_LINE if not self . check_mode : NEW_LINE INDENT self . results [ ' state ' ] = self . create_or_update ( results ) NEW_LINE DEDENT DEDENT elif self . state == ' absent ' and changed : NEW_LINE INDENT self . log ( " Delete ▁ security ▁ group ▁ { 0 } " . format ( self . name ) ) NEW_LINE self . results [ ' changed ' ] = changed NEW_LINE self . results [ ' state ' ] = dict ( ) NEW_LINE if not self . check_mode : NEW_LINE INDENT self . delete ( ) NEW_LINE # ▁ the ▁ delete ▁ does ▁ not ▁ actually ▁ return ▁ anything . ▁ if ▁ no ▁ exception , ▁ then ▁ we ' ll ▁ assume ENDCOM # ▁ it ▁ worked . ENDCOM self . results [ ' state ' ] [ ' status ' ] = ' Deleted ' NEW_LINE DEDENT DEDENT return self . results NEW_LINE DEDENT def create_or_update ( self , results ) : NEW_LINE INDENT parameters = self . nsg_models . NetworkSecurityGroup ( ) NEW_LINE if results . get ( ' rules ' ) : NEW_LINE INDENT parameters . security_rules = [ ] NEW_LINE for rule in results . get ( ' rules ' ) : NEW_LINE INDENT parameters . security_rules . append ( create_rule_instance ( self , rule ) ) NEW_LINE DEDENT DEDENT if results . get ( ' default _ rules ' ) : NEW_LINE INDENT parameters . default_security_rules = [ ] NEW_LINE for rule in results . get ( ' default _ rules ' ) : NEW_LINE INDENT parameters . default_security_rules . append ( create_rule_instance ( self , rule ) ) NEW_LINE DEDENT DEDENT parameters . tags = results . get ( ' tags ' ) NEW_LINE parameters . location = results . get ( ' location ' ) NEW_LINE try : NEW_LINE INDENT poller = self . network_client . network_security_groups . create_or_update ( resource_group_name = self . resource_group , network_security_group_name = self . name , parameters = parameters ) NEW_LINE result = self . get_poller_result ( poller ) NEW_LINE DEDENT except CloudError as exc : NEW_LINE INDENT self . fail ( " Error ▁ creating / updating ▁ security ▁ group ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . name , str ( exc ) ) ) NEW_LINE DEDENT return create_network_security_group_dict ( result ) NEW_LINE DEDENT def delete ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT poller = self . network_client . network_security_groups . delete ( resource_group_name = self . resource_group , network_security_group_name = self . name ) NEW_LINE result = self . get_poller_result ( poller ) NEW_LINE DEDENT except CloudError as exc : NEW_LINE INDENT raise Exception ( " Error ▁ deleting ▁ security ▁ group ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . name , str ( exc ) ) ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def main ( ) : NEW_LINE INDENT AzureRMSecurityGroup ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="apocquet/django/tree/master/django/contrib/gis/db/models/sql/conversion.py"> """ STRNEWLINE This ▁ module ▁ holds ▁ simple ▁ classes ▁ to ▁ convert ▁ geospatial ▁ values ▁ from ▁ the STRNEWLINE database . STRNEWLINE """ NEW_LINE from django . contrib . gis . db . models . fields import GeoSelectFormatMixin NEW_LINE from django . contrib . gis . geometry . backend import Geometry NEW_LINE from django . contrib . gis . measure import Area , Distance NEW_LINE class BaseField ( object ) : NEW_LINE INDENT empty_strings_allowed = True NEW_LINE def get_db_converters ( self , connection ) : NEW_LINE INDENT return [ self . from_db_value ] NEW_LINE DEDENT def select_format ( self , compiler , sql , params ) : NEW_LINE INDENT return sql , params NEW_LINE DEDENT DEDENT class AreaField ( BaseField ) : NEW_LINE INDENT " Wrapper ▁ for ▁ Area ▁ values . " NEW_LINE def __init__ ( self , area_att ) : NEW_LINE INDENT self . area_att = area_att NEW_LINE DEDENT def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT if value is not None : NEW_LINE INDENT value = Area ( ** { self . area_att : value } ) NEW_LINE DEDENT return value NEW_LINE DEDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' AreaField ' NEW_LINE DEDENT DEDENT class DistanceField ( BaseField ) : NEW_LINE INDENT " Wrapper ▁ for ▁ Distance ▁ values . " NEW_LINE def __init__ ( self , distance_att ) : NEW_LINE INDENT self . distance_att = distance_att NEW_LINE DEDENT def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT if value is not None : NEW_LINE INDENT value = Distance ( ** { self . distance_att : value } ) NEW_LINE DEDENT return value NEW_LINE DEDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' DistanceField ' NEW_LINE DEDENT DEDENT class GeomField ( GeoSelectFormatMixin , BaseField ) : NEW_LINE INDENT """ STRNEWLINE ▁ Wrapper ▁ for ▁ Geometry ▁ values . ▁ It ▁ is ▁ a ▁ lightweight ▁ alternative ▁ to STRNEWLINE ▁ using ▁ GeometryField ▁ ( which ▁ requires ▁ an ▁ SQL ▁ query ▁ upon ▁ instantiation ) . STRNEWLINE ▁ """ NEW_LINE # ▁ Hacky ▁ marker ▁ for ▁ get _ db _ converters ( ) ENDCOM geom_type = None NEW_LINE def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT if value is not None : NEW_LINE INDENT value = Geometry ( value ) NEW_LINE DEDENT return value NEW_LINE DEDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' GeometryField ' NEW_LINE DEDENT DEDENT class GMLField ( BaseField ) : NEW_LINE INDENT """ STRNEWLINE ▁ Wrapper ▁ for ▁ GML ▁ to ▁ be ▁ used ▁ by ▁ Oracle ▁ to ▁ ensure ▁ Database . LOB ▁ conversion . STRNEWLINE ▁ """ NEW_LINE def get_internal_type ( self ) : NEW_LINE INDENT return ' GMLField ' NEW_LINE DEDENT def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT return value NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="soulxu/libvirt-xuhj/tree/master/src/esx/esx_vi_generator.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ esx _ vi _ generator . py : ▁ generates ▁ most ▁ of ▁ the ▁ SOAP ▁ type ▁ mapping ▁ code ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2010-2011 ▁ Matthias ▁ Bolte ▁ < matthias . bolte @ googlemail . com > ENDCOM # ▁ This ▁ library ▁ is ▁ free ▁ software ; ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ENDCOM # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ENDCOM # ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation ; ▁ either ENDCOM # ▁ version ▁ 2.1 ▁ of ▁ the ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ This ▁ library ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ▁ GNU ENDCOM # ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ENDCOM # ▁ License ▁ along ▁ with ▁ this ▁ library ; ▁ if ▁ not , ▁ write ▁ to ▁ the ▁ Free ▁ Software ENDCOM # ▁ Foundation , ▁ Inc . , ▁ 59 ▁ Temple ▁ Place , ▁ Suite ▁ 330 , ▁ Boston , ▁ MA ▁ 02111-1307 ▁ USA ENDCOM import sys NEW_LINE import os NEW_LINE import os . path NEW_LINE OCCURRENCE__REQUIRED_ITEM = " r " NEW_LINE OCCURRENCE__REQUIRED_LIST = " rl " NEW_LINE OCCURRENCE__OPTIONAL_ITEM = " o " NEW_LINE OCCURRENCE__OPTIONAL_LIST = " ol " NEW_LINE OCCURRENCE__IGNORED = " i " NEW_LINE valid_occurrences = [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_ITEM , OCCURRENCE__OPTIONAL_LIST , OCCURRENCE__IGNORED ] NEW_LINE autobind_names = set ( ) NEW_LINE separator = " / * ▁ " + ( " * ▁ " * 37 ) + " * \n " NEW_LINE def aligned ( left , right , length = 59 ) : NEW_LINE INDENT while len ( left ) < length : NEW_LINE INDENT left += " ▁ " NEW_LINE DEDENT return left + right NEW_LINE DEDENT class Member : NEW_LINE INDENT def __init__ ( self , type , occurrence ) : NEW_LINE INDENT self . type = type NEW_LINE self . occurrence = occurrence NEW_LINE DEDENT def is_enum ( self ) : NEW_LINE INDENT return self . type in predefined_enums or self . type in enums_by_name NEW_LINE DEDENT def is_object ( self ) : NEW_LINE INDENT return self . type in predefined_objects or self . type in objects_by_name NEW_LINE DEDENT def is_type_generated ( self ) : NEW_LINE INDENT return self . type in enums_by_name or self . type in objects_by_name NEW_LINE DEDENT def get_occurrence_comment ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__REQUIRED_ITEM : NEW_LINE INDENT return " / * ▁ required ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__REQUIRED_LIST : NEW_LINE INDENT return " / * ▁ required , ▁ list ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_ITEM : NEW_LINE INDENT return " / * ▁ optional ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT return " / * ▁ optional , ▁ list ▁ * / " NEW_LINE DEDENT raise ValueError ( " unknown ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT DEDENT class Parameter ( Member ) : NEW_LINE INDENT def __init__ ( self , type , name , occurrence ) : NEW_LINE INDENT Member . __init__ ( self , type , occurrence ) NEW_LINE if ' : ' in name and name . startswith ( " _ this " ) : NEW_LINE INDENT self . name , self . autobind_name = name . split ( " : " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . name = name NEW_LINE self . autobind_name = None NEW_LINE DEDENT DEDENT def generate_parameter ( self , is_last = False , is_header = True , offset = 0 ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT raise ValueError ( " invalid ▁ function ▁ parameter ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT elif self . autobind_name is not None : NEW_LINE INDENT return " " NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ " NEW_LINE string += " ▁ " * offset NEW_LINE string += " % s % s " % ( self . get_type_string ( ) , self . name ) NEW_LINE if is_last : NEW_LINE INDENT if is_header : NEW_LINE INDENT string += " ) ; ▁ " NEW_LINE DEDENT else : NEW_LINE INDENT string += " ) , ▁ " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT string += " , ▁ " NEW_LINE DEDENT return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_return ( self , offset = 0 , end_of_line = " ; " ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT raise ValueError ( " invalid ▁ function ▁ parameter ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ " NEW_LINE string += " ▁ " * offset NEW_LINE string += " % s % s ) % s " % ( self . get_type_string ( True ) , self . name , end_of_line ) NEW_LINE return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_require_code ( self ) : NEW_LINE INDENT if self . occurrence in [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ REQUIRE ( % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " " NEW_LINE DEDENT DEDENT def generate_serialize_code ( self ) : NEW_LINE INDENT if self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def get_type_string ( self , as_return_value = False ) : NEW_LINE INDENT string = " " NEW_LINE if self . type == " String " and self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT if as_return_value : NEW_LINE INDENT string += " char ▁ * " NEW_LINE DEDENT else : NEW_LINE INDENT string += " const ▁ char ▁ * " NEW_LINE DEDENT DEDENT elif self . is_enum ( ) : NEW_LINE INDENT string += " esxVI _ % s ▁ " % self . type NEW_LINE DEDENT else : NEW_LINE INDENT string += " esxVI _ % s ▁ * " % self . type NEW_LINE DEDENT if as_return_value : NEW_LINE INDENT string += " * " NEW_LINE DEDENT return string NEW_LINE DEDENT def get_occurrence_short_enum ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__REQUIRED_ITEM : NEW_LINE INDENT return " RequiredItem " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__REQUIRED_LIST : NEW_LINE INDENT return " RequiredList " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_ITEM : NEW_LINE INDENT return " OptionalItem " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT return " OptionalList " NEW_LINE DEDENT raise ValueError ( " unknown ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT DEDENT class Method : NEW_LINE INDENT def __init__ ( self , name , parameters , returns ) : NEW_LINE INDENT self . name = name NEW_LINE self . parameters = [ ] NEW_LINE self . autobind_parameter = None NEW_LINE self . returns = returns NEW_LINE for parameter in parameters : NEW_LINE INDENT if parameter . autobind_name is None : NEW_LINE INDENT self . parameters . append ( parameter ) NEW_LINE DEDENT else : NEW_LINE INDENT self . autobind_parameter = parameter NEW_LINE DEDENT DEDENT DEDENT def generate_header ( self ) : NEW_LINE INDENT header = " int ▁ esxVI _ % s \n " % self . name NEW_LINE header += " ▁ ▁ ▁ ▁ ▁ ▁ ( esxVI _ Context ▁ * ctx " NEW_LINE if len ( self . parameters ) > 0 or self . returns is not None : NEW_LINE INDENT header += " , \n " NEW_LINE for parameter in self . parameters [ : - 1 ] : NEW_LINE INDENT header += parameter . generate_parameter ( ) NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT header += self . parameters [ - 1 ] . generate_parameter ( is_last = True ) NEW_LINE DEDENT else : NEW_LINE INDENT header += self . parameters [ - 1 ] . generate_parameter ( ) NEW_LINE header += self . returns . generate_return ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT header += " ) ; \n " NEW_LINE DEDENT header += " \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = " / * ▁ esxVI _ % s ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ METHOD ( % s , " % self . name NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT autobind_names . add ( self . autobind_parameter . autobind_name ) NEW_LINE source += " ▁ % s , \n " % self . autobind_parameter . autobind_name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ / * ▁ explicit ▁ _ this ▁ * / , \n " NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ( esxVI _ Context ▁ * ctx " NEW_LINE if len ( self . parameters ) > 0 or self . returns is not None : NEW_LINE INDENT source += " , \n " NEW_LINE for parameter in self . parameters [ : - 1 ] : NEW_LINE INDENT source += parameter . generate_parameter ( is_header = False , offset = 9 ) NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT source += self . parameters [ - 1 ] . generate_parameter ( is_last = True , is_header = False , offset = 9 ) NEW_LINE DEDENT else : NEW_LINE INDENT source += self . parameters [ - 1 ] . generate_parameter ( is_header = False , offset = 9 ) NEW_LINE source += self . returns . generate_return ( offset = 9 , end_of_line = " , " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT source += " ) , \n " NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ void , ▁ / * ▁ nothing ▁ * / , ▁ None , \n " NEW_LINE DEDENT elif self . returns . type == " String " : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ String , ▁ Value , ▁ % s , \n " % self . returns . get_occurrence_short_enum ( ) NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s , ▁ / * ▁ nothing ▁ * / , ▁ % s , \n " % ( self . returns . type , self . returns . get_occurrence_short_enum ( ) ) NEW_LINE DEDENT source += " { \n " NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT source += self . autobind_parameter . generate_require_code ( ) NEW_LINE DEDENT for parameter in self . parameters : NEW_LINE INDENT source += parameter . generate_require_code ( ) NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT source += self . autobind_parameter . generate_serialize_code ( ) NEW_LINE DEDENT for parameter in self . parameters : NEW_LINE INDENT source += parameter . generate_serialize_code ( ) NEW_LINE DEDENT source += " } ) \n \n \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class Property ( Member ) : NEW_LINE INDENT def __init__ ( self , type , name , occurrence ) : NEW_LINE INDENT Member . __init__ ( self , type , occurrence ) NEW_LINE self . name = name NEW_LINE DEDENT def generate_struct_member ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ % s % s ; ▁ " % ( self . get_type_string ( ) , self . name ) NEW_LINE return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_free_code ( self ) : NEW_LINE INDENT if self . type == " String " and self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST , OCCURRENCE__IGNORED ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ VIR _ FREE ( item - > % s ) ; \n " % self . name NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " " NEW_LINE DEDENT else : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > % s ) ; \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT DEDENT def generate_validate_code ( self , managed = False ) : NEW_LINE INDENT if managed : NEW_LINE INDENT macro = " ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ MANAGED _ REQUIRE " NEW_LINE DEDENT else : NEW_LINE INDENT macro = " ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ REQUIRE " NEW_LINE DEDENT if self . occurrence in [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ % s ( % s ) \n " % ( macro , self . name ) NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " " NEW_LINE DEDENT DEDENT def generate_deep_copy_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ( * dest ) - > % s ▁ = ▁ src - > % s ; \n " % ( self . name , self . name ) NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_serialize_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_deserialize_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ IGNORE ( % s ) ▁ / * ▁ FIXME ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_lookup_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ FROM _ ANY _ TYPE _ IGNORE ( % s ) ▁ / * ▁ FIXME ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ LIST _ FROM _ ANY _ TYPE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ VALUE _ FROM _ ANY _ TYPE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ FROM _ ANY _ TYPE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def get_type_string ( self ) : NEW_LINE INDENT if self . type == " String " and self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " char ▁ * " NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " esxVI _ % s ▁ " % self . type NEW_LINE DEDENT else : NEW_LINE INDENT return " esxVI _ % s ▁ * " % self . type NEW_LINE DEDENT DEDENT DEDENT class Type : NEW_LINE INDENT def __init__ ( self , kind , name ) : NEW_LINE INDENT self . kind = kind NEW_LINE self . name = name NEW_LINE DEDENT def generate_typedef ( self ) : NEW_LINE INDENT return " typedef ▁ % s ▁ _ esxVI _ % s ▁ esxVI _ % s ; \n " % ( self . kind , self . name , self . name ) NEW_LINE DEDENT def generate_typeenum ( self ) : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ esxVI _ Type _ % s , \n " % self . name NEW_LINE DEDENT def generate_typetostring ( self ) : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ case ▁ esxVI _ Type _ % s : \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ return ▁ \ " % s\ " ; \n \n " % self . name NEW_LINE return string NEW_LINE DEDENT def generate_typefromstring ( self ) : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ else ▁ if ▁ ( STREQ ( type , ▁ \ " % s\ " ) ) ▁ { \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ return ▁ esxVI _ Type _ % s ; \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } \n " NEW_LINE return string NEW_LINE DEDENT DEDENT class Object ( Type ) : NEW_LINE INDENT FEATURE__DYNAMIC_CAST = ( 1 << 1 ) NEW_LINE FEATURE__LIST = ( 1 << 2 ) NEW_LINE FEATURE__DEEP_COPY = ( 1 << 3 ) NEW_LINE FEATURE__ANY_TYPE = ( 1 << 4 ) NEW_LINE FEATURE__SERIALIZE = ( 1 << 5 ) NEW_LINE FEATURE__DESERIALIZE = ( 1 << 6 ) NEW_LINE def __init__ ( self , name , extends , properties , features = 0 , extended_by = None ) : NEW_LINE INDENT Type . __init__ ( self , " struct " , name ) NEW_LINE self . extends = extends NEW_LINE self . features = features NEW_LINE self . properties = properties NEW_LINE self . extended_by = extended_by NEW_LINE self . candidate_for_dynamic_cast = False NEW_LINE if self . extended_by is not None : NEW_LINE INDENT self . extended_by . sort ( ) NEW_LINE DEDENT DEDENT def generate_struct_members ( self , add_banner = False , struct_gap = False ) : NEW_LINE INDENT members = " " NEW_LINE if struct_gap : NEW_LINE INDENT members += " \n " NEW_LINE DEDENT if self . extends is not None : NEW_LINE INDENT members += objects_by_name [ self . extends ] . generate_struct_members ( add_banner = True , struct_gap = False ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT for property in self . properties : NEW_LINE INDENT members += property . generate_struct_member ( ) NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT return members NEW_LINE DEDENT def generate_free_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_free_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_free_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ freed ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_validate_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_validate_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_validate_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ required ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_dynamic_cast_code ( self , is_first = True ) : NEW_LINE INDENT source = " " NEW_LINE if self . extended_by is not None : NEW_LINE INDENT if not is_first : NEW_LINE INDENT source += " \n " NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST _ _ ACCEPT ( % s ) \n " % extended_by NEW_LINE DEDENT for extended_by in self . extended_by : NEW_LINE INDENT source += objects_by_name [ extended_by ] . generate_dynamic_cast_code ( False ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_deep_copy_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_deep_copy_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_deep_copy_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ deep ▁ copied ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_serialize_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_serialize_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT for property in self . properties : NEW_LINE INDENT source += property . generate_serialize_code ( ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_deserialize_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_deserialize_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT for property in self . properties : NEW_LINE INDENT source += property . generate_deserialize_code ( ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = separator NEW_LINE header += " ▁ * ▁ VI ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT header += " ▁ * / \n \n " NEW_LINE # ▁ struct ENDCOM header += " struct ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ next ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT else : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ unused ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ Type ▁ _ type ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += self . generate_struct_members ( struct_gap = True ) NEW_LINE header += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM header += " int ▁ esxVI _ % s _ Alloc ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " void ▁ esxVI _ % s _ Free ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " int ▁ esxVI _ % s _ Validate ( esxVI _ % s ▁ * item ) ; \n " % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__DYNAMIC_CAST : NEW_LINE INDENT if self . extended_by is not None or self . extends is not None : NEW_LINE INDENT header += " esxVI _ % s ▁ * esxVI _ % s _ DynamicCast ( void ▁ * item ) ; \n " % ( self . name , self . name ) NEW_LINE DEDENT else : NEW_LINE INDENT report_error ( " cannot ▁ add ▁ dynamic ▁ cast ▁ support ▁ for ▁ an ▁ untyped ▁ object " ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ AppendToList ( esxVI _ % s ▁ * * list , ▁ esxVI _ % s ▁ * item ) ; \n " % ( self . name , self . name , self . name ) NEW_LINE DEDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ DeepCopy ( esxVI _ % s ▁ * * dst , ▁ esxVI _ % s ▁ * src ) ; \n " % ( self . name , self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ DeepCopyList ( esxVI _ % s ▁ * * dstList , ▁ " " esxVI _ % s ▁ * srcList ) ; \n " ) % ( self . name , self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * * item ) ; \n " ) % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastListFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * * list ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Serialize ( esxVI _ % s ▁ * item , ▁ " " const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ SerializeList ( esxVI _ % s ▁ * list , ▁ " " const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ Deserialize ( xmlNodePtr ▁ node , ▁ esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ DeserializeList ( xmlNodePtr ▁ node , ▁ " " esxVI _ % s ▁ * * list ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = separator NEW_LINE source += " ▁ * ▁ VI ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT source += " ▁ * / \n \n " NEW_LINE # ▁ functions ENDCOM source += " / * ▁ esxVI _ % s _ Alloc ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ALLOC ( % s ) \n \n " % self . name NEW_LINE # ▁ free ENDCOM if self . extended_by is None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ break ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n \n " % self . name NEW_LINE DEDENT DEDENT source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ FREE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ brea ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n \n " % self . name NEW_LINE DEDENT DEDENT source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ validate ENDCOM DEDENT source += " / * ▁ esxVI _ % s _ Validate ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ VALIDATE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_validate_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ dynamic ▁ cast ENDCOM if self . features & Object . FEATURE__DYNAMIC_CAST : NEW_LINE INDENT if self . extended_by is not None or self . extends is not None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DynamicCast ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_dynamic_cast_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT report_error ( " cannot ▁ add ▁ dynamic ▁ cast ▁ support ▁ for ▁ an ▁ untyped ▁ object " ) NEW_LINE # ▁ append ▁ to ▁ list ENDCOM DEDENT DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ AppendToList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ APPEND ( % s ) \n \n " % self . name NEW_LINE # ▁ deep ▁ copy ENDCOM DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopy ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DEEP _ COPY ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_deep_copy_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopyList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DEEP _ COPY ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopy ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ DEEP _ COPY ( % s ) \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ DEEP _ COPY ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_deep_copy_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopyList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DEEP _ COPY ( % s ) \n \n " % self . name NEW_LINE # ▁ cast ▁ from ▁ any ▁ type ENDCOM DEDENT DEDENT DEDENT if self . features & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastFromAnyType ▁ * / \n " % self . name NEW_LINE if self . extended_by is None : NEW_LINE INDENT source += " ESX _ VI _ _ TEMPLATE _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST _ FROM _ ANY _ TYPE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } ) \n \n " NEW_LINE DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastListFromAnyType ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " % self . name NEW_LINE # ▁ serialize ENDCOM DEDENT DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ SERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_serialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ SerializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ SERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ SERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ SERIALIZE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_serialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ SerializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ SERIALIZE ( % s ) \n \n " % self . name NEW_LINE # ▁ deserialize ENDCOM DEDENT DEDENT DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DESERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_deserialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeserializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DESERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ DESERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ DESERIALIZE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_deserialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeserializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DESERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class ManagedObject ( Type ) : NEW_LINE INDENT FEATURE__LIST = ( 1 << 2 ) NEW_LINE def __init__ ( self , name , extends , properties , features = 0 , extended_by = None ) : NEW_LINE INDENT Type . __init__ ( self , " struct " , name ) NEW_LINE self . extends = extends NEW_LINE self . features = features NEW_LINE self . properties = properties NEW_LINE self . extended_by = extended_by NEW_LINE if self . extended_by is not None : NEW_LINE INDENT self . extended_by . sort ( ) NEW_LINE DEDENT DEDENT def generate_struct_members ( self , add_banner = False , struct_gap = False ) : NEW_LINE INDENT members = " " NEW_LINE if struct_gap : NEW_LINE INDENT members += " \n " NEW_LINE DEDENT if self . extends is not None : NEW_LINE INDENT members += managed_objects_by_name [ self . extends ] . generate_struct_members ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT for property in self . properties : NEW_LINE INDENT members += property . generate_struct_member ( ) NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT return members NEW_LINE DEDENT def generate_free_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_free_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_free_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ freed ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_validate_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_validate_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_validate_code ( managed = True ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ required ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_lookup_code1 ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_lookup_code1 ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += " ▁ ▁ ▁ ▁ \ " % s\\0\ " \n " % property . name NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_lookup_code2 ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_lookup_code2 ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_lookup_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_comment ( self ) : NEW_LINE INDENT comment = separator NEW_LINE comment += " ▁ * ▁ VI ▁ Managed ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT comment += " ▁ * / \n \n " NEW_LINE return comment NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = self . generate_comment ( ) NEW_LINE # ▁ struct ENDCOM header += " struct ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ next ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT else : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ unused ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ Type ▁ _ type ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference ▁ * _ reference ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += " \n " NEW_LINE header += self . generate_struct_members ( ) NEW_LINE header += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM header += " int ▁ esxVI _ % s _ Alloc ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " void ▁ esxVI _ % s _ Free ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += ( " int ▁ esxVI _ % s _ Validate ( esxVI _ % s ▁ * item , ▁ " " esxVI _ String ▁ * selectedPropertyNameList ) ; \n " ) % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ AppendToList ( esxVI _ % s ▁ * * list , ▁ esxVI _ % s ▁ * item ) ; \n " % ( self . name , self . name , self . name ) NEW_LINE DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_helper_header ( self ) : NEW_LINE INDENT header = " " NEW_LINE # ▁ functions ENDCOM header += ( " int ▁ esxVI _ Lookup % s ( esxVI _ Context ▁ * ctx , ▁ " " const ▁ char ▁ * name , ▁ " " esxVI _ ManagedObjectReference ▁ * root , ▁ " " esxVI _ String ▁ * selectedPropertyNameList , ▁ " " esxVI _ % s ▁ * * item , ▁ " " esxVI _ Occurrence ▁ occurrence ) ; \n " ) % ( self . name , self . name ) NEW_LINE header += " \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = self . generate_comment ( ) NEW_LINE # ▁ functions ENDCOM source += " / * ▁ esxVI _ % s _ Alloc ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ALLOC ( % s ) \n \n " % self . name NEW_LINE # ▁ free ENDCOM if self . extended_by is None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE if self . features & ManagedObject . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ break ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n " % self . name NEW_LINE DEDENT DEDENT source += " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference _ Free ( & item - > _ reference ) ; \n \n " NEW_LINE source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ FREE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ break ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n " % self . name NEW_LINE DEDENT DEDENT source += " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference _ Free ( & item - > _ reference ) ; \n \n " NEW_LINE source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ validate ENDCOM DEDENT source += " / * ▁ esxVI _ % s _ Validate ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ MANAGED _ VALIDATE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_validate_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ append ▁ to ▁ list ENDCOM if self . features & ManagedObject . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ AppendToList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ APPEND ( % s ) \n \n " % self . name NEW_LINE DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT def generate_helper_source ( self ) : NEW_LINE INDENT source = " " NEW_LINE # ▁ lookup ENDCOM source += " / * ▁ esxVI _ Lookup % s ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LOOKUP ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_lookup_code1 ( ) NEW_LINE source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_lookup_code2 ( ) NEW_LINE source += " } ) \n \n " NEW_LINE source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class Enum ( Type ) : NEW_LINE INDENT FEATURE__ANY_TYPE = ( 1 << 1 ) NEW_LINE FEATURE__SERIALIZE = ( 1 << 2 ) NEW_LINE FEATURE__DESERIALIZE = ( 1 << 3 ) NEW_LINE def __init__ ( self , name , values , features = 0 ) : NEW_LINE INDENT Type . __init__ ( self , " enum " , name ) NEW_LINE self . values = values NEW_LINE self . features = features NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = separator NEW_LINE header += " ▁ * ▁ VI ▁ Enum : ▁ % s \n " % self . name NEW_LINE header += " ▁ * / \n \n " NEW_LINE # ▁ enum ENDCOM header += " enum ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE header += " ▁ ▁ ▁ ▁ esxVI _ % s _ Undefined ▁ = ▁ 0 , \n " % self . name NEW_LINE for value in self . values : NEW_LINE INDENT header += " ▁ ▁ ▁ ▁ esxVI _ % s _ % s , \n " % ( self . name , capitalize_first ( value ) ) NEW_LINE DEDENT header += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM if self . features & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * item ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT if self . features & Enum . FEATURE__SERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Serialize ( esxVI _ % s ▁ item , ▁ const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT if self . features & Enum . FEATURE__DESERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Deserialize ( xmlNodePtr ▁ node , ▁ " " esxVI _ % s ▁ * item ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = separator NEW_LINE source += " ▁ * ▁ VI ▁ Enum : ▁ % s \n " % self . name NEW_LINE source += " ▁ * / \n \n " NEW_LINE source += " static ▁ const ▁ esxVI _ Enumeration ▁ _ esxVI _ % s _ Enumeration ▁ = ▁ { \n " % self . name NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ Type _ % s , ▁ { \n " % self . name NEW_LINE for value in self . values : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { ▁ \ " % s\ " , ▁ esxVI _ % s _ % s ▁ } , \n " % ( value , self . name , capitalize_first ( value ) ) NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { ▁ NULL , ▁ - 1 ▁ } , \n " NEW_LINE source += " ▁ ▁ ▁ ▁ } , \n " NEW_LINE source += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM if self . features & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastFromAnyType ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " % self . name NEW_LINE DEDENT if self . features & Enum . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ SERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT if self . features & Enum . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ DESERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT def report_error ( message ) : NEW_LINE INDENT print " error : ▁ " + message NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT def capitalize_first ( string ) : NEW_LINE INDENT return string [ : 1 ] . upper ( ) + string [ 1 : ] NEW_LINE DEDENT def parse_object ( block ) : NEW_LINE # ▁ expected ▁ format : ▁ [ managed ] ▁ object ▁ < name > ▁ [ extends ▁ < name > ] ENDCOM INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE managed = False NEW_LINE if header_items [ 0 ] == " managed " : NEW_LINE INDENT managed = True NEW_LINE del header_items [ 0 ] NEW_LINE DEDENT if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " object " NEW_LINE name = header_items [ 1 ] NEW_LINE extends = None NEW_LINE if len ( header_items ) > 2 : NEW_LINE INDENT if header_items [ 2 ] != " extends " : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT extends = header_items [ 3 ] NEW_LINE DEDENT DEDENT properties = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE # ▁ expected ▁ format : ▁ < type > ▁ < name > ▁ < occurrence > ENDCOM INDENT items = line [ 1 ] . split ( ) NEW_LINE if len ( items ) != 3 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ property " % line [ 0 ] ) NEW_LINE DEDENT if items [ 2 ] not in valid_occurrences : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ occurrence " % line [ 0 ] ) NEW_LINE DEDENT properties . append ( Property ( type = items [ 0 ] , name = items [ 1 ] , occurrence = items [ 2 ] ) ) NEW_LINE DEDENT if managed : NEW_LINE INDENT return ManagedObject ( name = name , extends = extends , properties = properties ) NEW_LINE DEDENT else : NEW_LINE INDENT return Object ( name = name , extends = extends , properties = properties ) NEW_LINE DEDENT DEDENT def parse_enum ( block ) : NEW_LINE # ▁ expected ▁ format : ▁ enum ▁ < name > ENDCOM INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " enum " NEW_LINE name = header_items [ 1 ] NEW_LINE values = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE # ▁ expected ▁ format : ▁ < value > ENDCOM INDENT values . append ( line [ 1 ] ) NEW_LINE DEDENT return Enum ( name = name , values = values ) NEW_LINE DEDENT def parse_method ( block ) : NEW_LINE # ▁ expected ▁ format : ▁ method ▁ < name > ▁ [ returns ▁ < type > ▁ < occurrence > ] ENDCOM INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " method " NEW_LINE name = header_items [ 1 ] NEW_LINE returns = None NEW_LINE if len ( header_items ) > 2 : NEW_LINE INDENT if header_items [ 2 ] != " returns " : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT returns = Parameter ( type = header_items [ 3 ] , name = " output " , occurrence = header_items [ 4 ] ) NEW_LINE DEDENT DEDENT parameters = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE # ▁ expected ▁ format : ▁ < type > ▁ < name > ▁ < occurrence > ENDCOM INDENT items = line [ 1 ] . split ( ) NEW_LINE if len ( items ) != 3 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ property " % line [ 0 ] ) NEW_LINE DEDENT if items [ 2 ] not in valid_occurrences : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ occurrence " % line [ 0 ] ) NEW_LINE DEDENT parameters . append ( Parameter ( type = items [ 0 ] , name = items [ 1 ] , occurrence = items [ 2 ] ) ) NEW_LINE DEDENT return Method ( name = name , parameters = parameters , returns = returns ) NEW_LINE DEDENT def is_known_type ( type ) : NEW_LINE INDENT return type in predefined_objects or type in predefined_enums or type in objects_by_name or type in managed_objects_by_name or type in enums_by_name NEW_LINE DEDENT def open_and_print ( filename ) : NEW_LINE INDENT if filename . startswith ( " . / " ) : NEW_LINE INDENT print " ▁ ▁ GEN ▁ ▁ ▁ ▁ " + filename [ 2 : ] NEW_LINE DEDENT else : NEW_LINE INDENT print " ▁ ▁ GEN ▁ ▁ ▁ ▁ " + filename NEW_LINE DEDENT return open ( filename , " wb " ) NEW_LINE DEDENT predefined_enums = [ " Boolean " ] NEW_LINE predefined_objects = [ " AnyType " , " Int " , " Long " , " String " , " DateTime " , " MethodFault " , " ManagedObjectReference " ] NEW_LINE additional_enum_features = { " ManagedEntityStatus " : Enum . FEATURE__ANY_TYPE , " TaskInfoState " : Enum . FEATURE__ANY_TYPE , " VirtualMachinePowerState " : Enum . FEATURE__ANY_TYPE } NEW_LINE additional_object_features = { " AutoStartDefaults " : Object . FEATURE__ANY_TYPE , " AutoStartPowerInfo " : Object . FEATURE__ANY_TYPE , " DatastoreHostMount " : Object . FEATURE__DEEP_COPY | Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " DatastoreInfo " : Object . FEATURE__ANY_TYPE | Object . FEATURE__DYNAMIC_CAST , " HostConfigManager " : Object . FEATURE__ANY_TYPE , " HostCpuIdInfo " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " HostDatastoreBrowserSearchResults " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " ManagedObjectReference " : Object . FEATURE__ANY_TYPE , " ObjectContent " : Object . FEATURE__DEEP_COPY , " ResourcePoolResourceUsage " : Object . FEATURE__ANY_TYPE , " ServiceContent " : Object . FEATURE__DESERIALIZE , " SharesInfo " : Object . FEATURE__ANY_TYPE , " TaskInfo " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " UserSession " : Object . FEATURE__ANY_TYPE , " VirtualMachineQuestionInfo " : Object . FEATURE__ANY_TYPE , " VirtualMachineSnapshotTree " : Object . FEATURE__DEEP_COPY | Object . FEATURE__ANY_TYPE , " VmEventArgument " : Object . FEATURE__DESERIALIZE } NEW_LINE removed_object_features = { } NEW_LINE if " srcdir " in os . environ : NEW_LINE INDENT input_filename = os . path . join ( os . environ [ " srcdir " ] , " esx / esx _ vi _ generator . input " ) NEW_LINE output_dirname = os . path . join ( os . environ [ " srcdir " ] , " esx " ) NEW_LINE DEDENT else : NEW_LINE INDENT input_filename = os . path . join ( os . getcwd ( ) , " esx _ vi _ generator . input " ) NEW_LINE output_dirname = os . getcwd ( ) NEW_LINE DEDENT types_typedef = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typedef " ) ) NEW_LINE types_typeenum = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typeenum " ) ) NEW_LINE types_typetostring = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typetostring " ) ) NEW_LINE types_typefromstring = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typefromstring " ) ) NEW_LINE types_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . h " ) ) NEW_LINE types_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . c " ) ) NEW_LINE methods_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . h " ) ) NEW_LINE methods_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . c " ) ) NEW_LINE methods_macro = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . macro " ) ) NEW_LINE helpers_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi . generated . h " ) ) NEW_LINE helpers_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi . generated . c " ) ) NEW_LINE number = 0 NEW_LINE objects_by_name = { } NEW_LINE managed_objects_by_name = { } NEW_LINE enums_by_name = { } NEW_LINE methods_by_name = { } NEW_LINE block = None NEW_LINE # ▁ parse ▁ input ▁ file ENDCOM for line in file ( input_filename , " rb " ) . readlines ( ) : NEW_LINE INDENT number += 1 NEW_LINE if " # " in line : NEW_LINE INDENT line = line [ : line . index ( " # " ) ] NEW_LINE DEDENT line = line . lstrip ( ) . rstrip ( ) NEW_LINE if len ( line ) < 1 : NEW_LINE INDENT continue NEW_LINE DEDENT if line . startswith ( " object " ) or line . startswith ( " managed ▁ object " ) or line . startswith ( " enum " ) or line . startswith ( " method " ) : NEW_LINE INDENT if block is not None : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ nested ▁ block ▁ found " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT block = [ ] NEW_LINE DEDENT DEDENT if block is not None : NEW_LINE INDENT if line == " end " : NEW_LINE INDENT if block [ 0 ] [ 1 ] . startswith ( " object " ) : NEW_LINE INDENT obj = parse_object ( block ) NEW_LINE objects_by_name [ obj . name ] = obj NEW_LINE DEDENT elif block [ 0 ] [ 1 ] . startswith ( " managed ▁ object " ) : NEW_LINE INDENT obj = parse_object ( block ) NEW_LINE managed_objects_by_name [ obj . name ] = obj NEW_LINE DEDENT elif block [ 0 ] [ 1 ] . startswith ( " enum " ) : NEW_LINE INDENT enum = parse_enum ( block ) NEW_LINE enums_by_name [ enum . name ] = enum NEW_LINE DEDENT else : NEW_LINE INDENT method = parse_method ( block ) NEW_LINE methods_by_name [ method . name ] = method NEW_LINE DEDENT block = None NEW_LINE DEDENT else : NEW_LINE INDENT block . append ( ( number , line ) ) NEW_LINE DEDENT DEDENT DEDENT for method in methods_by_name . values ( ) : NEW_LINE # ▁ method ▁ parameter ▁ types ▁ must ▁ be ▁ serializable ENDCOM INDENT for parameter in method . parameters : NEW_LINE INDENT if not parameter . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if parameter . is_enum ( ) : NEW_LINE INDENT enums_by_name [ parameter . type ] . features |= Enum . FEATURE__SERIALIZE NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ parameter . type ] . features |= Object . FEATURE__SERIALIZE NEW_LINE objects_by_name [ parameter . type ] . candidate_for_dynamic_cast = True NEW_LINE # ▁ detect ▁ list ▁ usage ENDCOM DEDENT if parameter . occurrence == OCCURRENCE__REQUIRED_LIST or parameter . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if parameter . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( parameter . type , method . name ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ parameter . type ] . features |= Object . FEATURE__LIST NEW_LINE # ▁ method ▁ return ▁ types ▁ must ▁ be ▁ deserializable ENDCOM DEDENT DEDENT DEDENT if method . returns and method . returns . is_type_generated ( ) : NEW_LINE INDENT if method . returns . is_enum ( ) : NEW_LINE INDENT enums_by_name [ method . returns . type ] . features |= Enum . FEATURE__DESERIALIZE NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ method . returns . type ] . features |= Object . FEATURE__DESERIALIZE NEW_LINE objects_by_name [ method . returns . type ] . candidate_for_dynamic_cast = True NEW_LINE # ▁ detect ▁ list ▁ usage ENDCOM DEDENT if method . returns . occurrence == OCCURRENCE__REQUIRED_LIST or method . returns . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if method . returns . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( method . returns . type , method . name ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ method . returns . type ] . features |= Object . FEATURE__LIST NEW_LINE DEDENT DEDENT DEDENT DEDENT for enum in enums_by_name . values ( ) : NEW_LINE # ▁ apply ▁ additional ▁ features ENDCOM INDENT if enum . name in additional_enum_features : NEW_LINE INDENT enum . features |= additional_enum_features [ enum . name ] NEW_LINE if additional_enum_features [ enum . name ] & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT enum . features |= Enum . FEATURE__DESERIALIZE NEW_LINE DEDENT DEDENT DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence != OCCURRENCE__IGNORED and not is_known_type ( property . type ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ contains ▁ unknown ▁ property ▁ type ▁ ' % s ' " % ( obj . name , property . type ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT if not is_known_type ( obj . extends ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ extends ▁ unknown ▁ object ▁ ' % s ' " % ( obj . name , obj . extends ) ) NEW_LINE DEDENT DEDENT for property in obj . properties : NEW_LINE INDENT if not property . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if property . is_enum ( ) : NEW_LINE INDENT enums_by_name [ property . type ] . candidate_for_dynamic_cast = True NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ property . type ] . candidate_for_dynamic_cast = True NEW_LINE # ▁ detect ▁ list ▁ usage ENDCOM DEDENT if property . occurrence == OCCURRENCE__REQUIRED_LIST or property . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if property . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( property . type , obj . type ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ property . type ] . features |= Object . FEATURE__LIST NEW_LINE # ▁ apply / remove ▁ additional ▁ features ENDCOM DEDENT DEDENT DEDENT if obj . name in additional_object_features : NEW_LINE INDENT obj . features |= additional_object_features [ obj . name ] NEW_LINE if additional_object_features [ obj . name ] & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT obj . features |= Object . FEATURE__DESERIALIZE NEW_LINE DEDENT DEDENT if obj . name in removed_object_features : NEW_LINE INDENT obj . features &= ~ removed_object_features [ obj . name ] NEW_LINE # ▁ detect ▁ extended _ by ▁ relation ENDCOM DEDENT if obj . extends is not None : NEW_LINE INDENT extended_obj = objects_by_name [ obj . extends ] NEW_LINE if extended_obj . extended_by is None : NEW_LINE INDENT extended_obj . extended_by = [ obj . name ] NEW_LINE DEDENT else : NEW_LINE INDENT extended_obj . extended_by . append ( obj . name ) NEW_LINE extended_obj . extended_by . sort ( ) NEW_LINE DEDENT DEDENT DEDENT for obj in objects_by_name . values ( ) : NEW_LINE # ▁ if ▁ an ▁ object ▁ is ▁ a ▁ candidate ▁ ( it ▁ is ▁ used ▁ directly ▁ as ▁ parameter ▁ or ▁ return ENDCOM # ▁ type ▁ or ▁ is ▁ a ▁ member ▁ of ▁ another ▁ object ) ▁ and ▁ it ▁ is ▁ extended ▁ by ▁ another ENDCOM # ▁ object ▁ then ▁ this ▁ type ▁ needs ▁ the ▁ dynamic ▁ cast ▁ feature ENDCOM INDENT if obj . candidate_for_dynamic_cast and obj . extended_by : NEW_LINE INDENT obj . features |= Object . FEATURE__DYNAMIC_CAST NEW_LINE DEDENT DEDENT def propagate_feature ( obj , feature ) : NEW_LINE INDENT global features_have_changed NEW_LINE if not ( obj . features & feature ) : NEW_LINE INDENT return NEW_LINE DEDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence == OCCURRENCE__IGNORED or not property . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if property . is_enum ( ) : NEW_LINE INDENT if feature == Object . FEATURE__SERIALIZE and not ( enums_by_name [ property . type ] . features & Enum . FEATURE__SERIALIZE ) : NEW_LINE INDENT enums_by_name [ property . type ] . features |= Enum . FEATURE__SERIALIZE NEW_LINE features_have_changed = True NEW_LINE DEDENT elif feature == Object . FEATURE__DESERIALIZE and not ( enums_by_name [ property . type ] . features & Enum . FEATURE__DESERIALIZE ) : NEW_LINE INDENT enums_by_name [ property . type ] . features |= Enum . FEATURE__DESERIALIZE NEW_LINE features_have_changed = True NEW_LINE DEDENT DEDENT elif property . is_object ( ) : NEW_LINE INDENT if not ( objects_by_name [ property . type ] . features & feature ) : NEW_LINE INDENT objects_by_name [ property . type ] . features |= feature NEW_LINE features_have_changed = True NEW_LINE DEDENT if obj . name != property . type : NEW_LINE INDENT propagate_feature ( objects_by_name [ property . type ] , feature ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def inherit_features ( obj ) : NEW_LINE INDENT global features_have_changed NEW_LINE if obj . extended_by is not None : NEW_LINE INDENT for extended_by in obj . extended_by : NEW_LINE INDENT previous = objects_by_name [ extended_by ] . features NEW_LINE objects_by_name [ extended_by ] . features |= obj . features NEW_LINE if objects_by_name [ extended_by ] . features != previous : NEW_LINE INDENT features_have_changed = True NEW_LINE DEDENT DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT previous = objects_by_name [ obj . extends ] . features NEW_LINE objects_by_name [ obj . extends ] . features |= obj . features NEW_LINE if objects_by_name [ obj . extends ] . features != previous : NEW_LINE INDENT features_have_changed = True NEW_LINE DEDENT DEDENT if obj . extended_by is not None : NEW_LINE INDENT for extended_by in obj . extended_by : NEW_LINE INDENT inherit_features ( objects_by_name [ extended_by ] ) NEW_LINE # ▁ there ▁ are ▁ two ▁ directions ▁ to ▁ spread ▁ features : ENDCOM # ▁ 1 ) ▁ up ▁ and ▁ down ▁ the ▁ inheritance ▁ chain ENDCOM # ▁ 2 ) ▁ from ▁ object ▁ types ▁ to ▁ their ▁ member ▁ property ▁ types ENDCOM # ▁ spreading ▁ needs ▁ to ▁ be ▁ done ▁ alternating ▁ on ▁ both ▁ directions ▁ because ▁ they ▁ can ENDCOM # ▁ affect ▁ each ▁ other ENDCOM DEDENT DEDENT DEDENT features_have_changed = True NEW_LINE while features_have_changed : NEW_LINE INDENT features_have_changed = False NEW_LINE for obj in objects_by_name . values ( ) : NEW_LINE INDENT propagate_feature ( obj , Object . FEATURE__DEEP_COPY ) NEW_LINE propagate_feature ( obj , Object . FEATURE__SERIALIZE ) NEW_LINE propagate_feature ( obj , Object . FEATURE__DESERIALIZE ) NEW_LINE DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT inherit_features ( obj ) NEW_LINE DEDENT DEDENT for obj in managed_objects_by_name . values ( ) : NEW_LINE INDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence != OCCURRENCE__IGNORED and not is_known_type ( property . type ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ contains ▁ unknown ▁ property ▁ type ▁ ' % s ' " % ( obj . name , property . type ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT if not is_known_type ( obj . extends ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ extends ▁ unknown ▁ object ▁ ' % s ' " % ( obj . name , obj . extends ) ) NEW_LINE # ▁ detect ▁ extended _ by ▁ relation ENDCOM DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT extended_obj = managed_objects_by_name [ obj . extends ] NEW_LINE if extended_obj . extended_by is None : NEW_LINE INDENT extended_obj . extended_by = [ obj . name ] NEW_LINE DEDENT else : NEW_LINE INDENT extended_obj . extended_by . append ( obj . name ) NEW_LINE extended_obj . extended_by . sort ( ) NEW_LINE DEDENT DEDENT DEDENT notice = " / * ▁ Generated ▁ by ▁ esx _ vi _ generator . py ▁ * / \n \n \n \n " NEW_LINE types_typedef . write ( notice ) NEW_LINE types_typeenum . write ( notice ) NEW_LINE types_typetostring . write ( notice ) NEW_LINE types_typefromstring . write ( notice ) NEW_LINE types_header . write ( notice ) NEW_LINE types_source . write ( notice ) NEW_LINE methods_header . write ( notice ) NEW_LINE methods_source . write ( notice ) NEW_LINE methods_macro . write ( notice ) NEW_LINE helpers_header . write ( notice ) NEW_LINE helpers_source . write ( notice ) NEW_LINE # ▁ output ▁ enums ENDCOM types_typedef . write ( separator + " ▁ * ▁ VI ▁ Enums \n " + " ▁ * / \n \n " ) NEW_LINE names = enums_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( enums_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( enums_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( enums_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( enums_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( enums_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( enums_by_name [ name ] . generate_source ( ) ) NEW_LINE # ▁ output ▁ objects ENDCOM DEDENT types_typedef . write ( " \n \n \n " + separator + " ▁ * ▁ VI ▁ Objects \n " + " ▁ * / \n \n " ) NEW_LINE types_typeenum . write ( " \n " ) NEW_LINE types_typetostring . write ( " \n " ) NEW_LINE types_typefromstring . write ( " \n " ) NEW_LINE names = objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( objects_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( objects_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( objects_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( objects_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( objects_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( objects_by_name [ name ] . generate_source ( ) ) NEW_LINE # ▁ output ▁ managed ▁ objects ENDCOM DEDENT types_typedef . write ( " \n \n \n " + separator + " ▁ * ▁ VI ▁ Managed ▁ Objects \n " + " ▁ * / \n \n " ) NEW_LINE types_typeenum . write ( " \n " ) NEW_LINE types_typetostring . write ( " \n " ) NEW_LINE types_typefromstring . write ( " \n " ) NEW_LINE names = managed_objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( managed_objects_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( managed_objects_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( managed_objects_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( managed_objects_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( managed_objects_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( managed_objects_by_name [ name ] . generate_source ( ) ) NEW_LINE # ▁ output ▁ methods ENDCOM DEDENT names = methods_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT methods_header . write ( methods_by_name [ name ] . generate_header ( ) ) NEW_LINE methods_source . write ( methods_by_name [ name ] . generate_source ( ) ) NEW_LINE DEDENT names = list ( autobind_names ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT string = aligned ( " # define ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ THIS _ _ % s ▁ " % name , " \\ \n " , 78 ) NEW_LINE string += " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ THIS _ FROM _ SERVICE ( ManagedObjectReference , ▁ ▁ ▁ ▁ ▁ ▁ \\ \n " NEW_LINE string += aligned ( " " , " % s ) \n \n \n \n " % name , 49 ) NEW_LINE methods_macro . write ( string ) NEW_LINE # ▁ output ▁ helpers ENDCOM DEDENT names = managed_objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT helpers_header . write ( managed_objects_by_name [ name ] . generate_helper_header ( ) ) NEW_LINE helpers_source . write ( managed_objects_by_name [ name ] . generate_helper_source ( ) ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="robertglen/flask/tree/master/tests/test_instance_config.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM """ STRNEWLINE ▁ tests . test _ instance STRNEWLINE ▁ ~ ~ ~ ~ ~ STRNEWLINE STRNEWLINE ▁ : copyright : ▁ ( c ) ▁ 2015 ▁ by ▁ the ▁ Flask ▁ Team , ▁ see ▁ AUTHORS ▁ for ▁ more ▁ details . STRNEWLINE ▁ : license : ▁ BSD , ▁ see ▁ LICENSE ▁ for ▁ more ▁ details . STRNEWLINE """ NEW_LINE import os NEW_LINE import sys NEW_LINE import pytest NEW_LINE import flask NEW_LINE from flask . _compat import PY2 NEW_LINE def test_explicit_instance_paths ( modules_tmpdir ) : NEW_LINE INDENT with pytest . raises ( ValueError ) as excinfo : NEW_LINE INDENT flask . Flask ( __name__ , instance_path = ' instance ' ) NEW_LINE DEDENT assert ' must ▁ be ▁ absolute ' in str ( excinfo . value ) NEW_LINE app = flask . Flask ( __name__ , instance_path = str ( modules_tmpdir ) ) NEW_LINE assert app . instance_path == str ( modules_tmpdir ) NEW_LINE DEDENT def test_main_module_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' main _ app . py ' ) NEW_LINE app . write ( ' import ▁ flask \n \n app ▁ = ▁ flask . Flask ( " _ _ main _ _ " ) ' ) NEW_LINE purge_module ( ' main _ app ' ) NEW_LINE from main_app import app NEW_LINE here = os . path . abspath ( os . getcwd ( ) ) NEW_LINE assert app . instance_path == os . path . join ( here , ' instance ' ) NEW_LINE DEDENT def test_uninstalled_module_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' config _ module _ app . py ' ) . write ( ' import ▁ os \n ' ' import ▁ flask \n ' ' here ▁ = ▁ os . path . abspath ( os . path . dirname ( _ _ file _ _ ) ) \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' config _ module _ app ' ) NEW_LINE from config_module_app import app NEW_LINE assert app . instance_path == str ( modules_tmpdir . join ( ' instance ' ) ) NEW_LINE DEDENT def test_uninstalled_package_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . mkdir ( ' config _ package _ app ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ os \n ' ' import ▁ flask \n ' ' here ▁ = ▁ os . path . abspath ( os . path . dirname ( _ _ file _ _ ) ) \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' config _ package _ app ' ) NEW_LINE from config_package_app import app NEW_LINE assert app . instance_path == str ( modules_tmpdir . join ( ' instance ' ) ) NEW_LINE DEDENT def test_installed_module_paths ( modules_tmpdir , modules_tmpdir_prefix , purge_module , site_packages , limit_loader ) : NEW_LINE INDENT site_packages . join ( ' site _ app . py ' ) . write ( ' import ▁ flask \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' site _ app ' ) NEW_LINE from site_app import app NEW_LINE assert app . instance_path == modules_tmpdir . join ( ' var ' ) . join ( ' site _ app - instance ' ) NEW_LINE DEDENT def test_installed_package_paths ( limit_loader , modules_tmpdir , modules_tmpdir_prefix , purge_module , monkeypatch ) : NEW_LINE INDENT installed_path = modules_tmpdir . mkdir ( ' path ' ) NEW_LINE monkeypatch . syspath_prepend ( installed_path ) NEW_LINE app = installed_path . mkdir ( ' installed _ package ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE purge_module ( ' installed _ package ' ) NEW_LINE from installed_package import app NEW_LINE assert app . instance_path == modules_tmpdir . join ( ' var ' ) . join ( ' installed _ package - instance ' ) NEW_LINE DEDENT def test_prefix_package_paths ( limit_loader , modules_tmpdir , modules_tmpdir_prefix , purge_module , site_packages ) : NEW_LINE INDENT app = site_packages . mkdir ( ' site _ package ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE purge_module ( ' site _ package ' ) NEW_LINE import site_package NEW_LINE assert site_package . app . instance_path == modules_tmpdir . join ( ' var ' ) . join ( ' site _ package - instance ' ) NEW_LINE DEDENT def test_egg_installed_paths ( install_egg , modules_tmpdir , modules_tmpdir_prefix ) : NEW_LINE INDENT modules_tmpdir . mkdir ( ' site _ egg ' ) . join ( ' _ _ init _ _ . py ' ) . write ( ' import ▁ flask \n \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE install_egg ( ' site _ egg ' ) NEW_LINE try : NEW_LINE INDENT import site_egg NEW_LINE assert site_egg . app . instance_path == str ( modules_tmpdir . join ( ' var / ' ) . join ( ' site _ egg - instance ' ) ) NEW_LINE DEDENT finally : NEW_LINE INDENT if ' site _ egg ' in sys . modules : NEW_LINE INDENT del sys . modules [ ' site _ egg ' ] NEW_LINE DEDENT DEDENT DEDENT @ pytest . mark . skipif ( not PY2 , reason = ' This ▁ only ▁ works ▁ under ▁ Python ▁ 2 . ' ) NEW_LINE def test_meta_path_loader_without_is_package ( request , modules_tmpdir ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' unimportable . py ' ) NEW_LINE app . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE class Loader ( object ) : NEW_LINE INDENT def find_module ( self , name , path = None ) : NEW_LINE INDENT return self NEW_LINE DEDENT DEDENT sys . meta_path . append ( Loader ( ) ) NEW_LINE request . addfinalizer ( sys . meta_path . pop ) NEW_LINE with pytest . raises ( AttributeError ) : NEW_LINE INDENT import unimportable NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="dragonpt/Kernel_3.4.67_KK_Wiko_DarkMoon/tree/master/tools/perf/scripts/python/futex-contention.py"> # ▁ futex ▁ contention ENDCOM # ▁ ( c ) ▁ 2010 , ▁ Arnaldo ▁ Carvalho ▁ de ▁ Melo ▁ < acme @ redhat . com > ENDCOM # ▁ Licensed ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ GPL ▁ License ▁ version ▁ 2 ENDCOM # ▁ Translation ▁ of : ENDCOM # ▁ http : / / sourceware . org / systemtap / wiki / WSFutexContention ENDCOM # ▁ to ▁ perf ▁ python ▁ scripting . ENDCOM # ▁ Measures ▁ futex ▁ contention ENDCOM import os , sys NEW_LINE sys . path . append ( os . environ [ ' PERF _ EXEC _ PATH ' ] + ' / scripts / python / Perf - Trace - Util / lib / Perf / Trace ' ) NEW_LINE from Util import * NEW_LINE process_names = { } NEW_LINE thread_thislock = { } NEW_LINE thread_blocktime = { } NEW_LINE lock_waits = { } # ▁ long - lived ▁ stats ▁ on ▁ ( tid , lock ) ▁ blockage ▁ elapsed ▁ time ENDCOM NEW_LINE process_names = { } # ▁ long - lived ▁ pid - to - execname ▁ mapping ENDCOM NEW_LINE def syscalls__sys_enter_futex ( event , ctxt , cpu , s , ns , tid , comm , nr , uaddr , op , val , utime , uaddr2 , val3 ) : NEW_LINE INDENT cmd = op & FUTEX_CMD_MASK NEW_LINE if cmd != FUTEX_WAIT : NEW_LINE INDENT return # ▁ we ▁ don ' t ▁ care ▁ about ▁ originators ▁ of ▁ WAKE ▁ events ENDCOM NEW_LINE DEDENT process_names [ tid ] = comm NEW_LINE thread_thislock [ tid ] = uaddr NEW_LINE thread_blocktime [ tid ] = nsecs ( s , ns ) NEW_LINE DEDENT def syscalls__sys_exit_futex ( event , ctxt , cpu , s , ns , tid , comm , nr , ret ) : NEW_LINE INDENT if thread_blocktime . has_key ( tid ) : NEW_LINE INDENT elapsed = nsecs ( s , ns ) - thread_blocktime [ tid ] NEW_LINE add_stats ( lock_waits , ( tid , thread_thislock [ tid ] ) , elapsed ) NEW_LINE del thread_blocktime [ tid ] NEW_LINE del thread_thislock [ tid ] NEW_LINE DEDENT DEDENT def trace_begin ( ) : NEW_LINE INDENT print " Press ▁ control + C ▁ to ▁ stop ▁ and ▁ show ▁ the ▁ summary " NEW_LINE DEDENT def trace_end ( ) : NEW_LINE INDENT for ( tid , lock ) in lock_waits : NEW_LINE INDENT min , max , avg , count = lock_waits [ tid , lock ] NEW_LINE print " % s [ % d ] ▁ lock ▁ % x ▁ contended ▁ % d ▁ times , ▁ % d ▁ avg ▁ ns " % ( process_names [ tid ] , tid , lock , count , avg ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="travisdesell/csg_boinc/tree/master/test/cgiserver.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ $ Id $ ENDCOM # ▁ cgi / php ▁ web ▁ server ENDCOM import BaseHTTPServer , CGIHTTPServer NEW_LINE import sys , os , urllib , select NEW_LINE import random , time # ▁ XXX ENDCOM NEW_LINE php_path = None NEW_LINE possible_php_paths = [ ' / usr / lib / cgi - bin / php4' , ' PROGRAM _ PATH / fake _ php . py ' ] NEW_LINE def setup_php ( program_path ) : NEW_LINE INDENT global php_path NEW_LINE for p in possible_php_paths : NEW_LINE INDENT p = p . replace ( ' PROGRAM _ PATH ' , program_path ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT php_path = p NEW_LINE return NEW_LINE DEDENT DEDENT raise Exception ( " No ▁ php ▁ binary ▁ found ▁ - ▁ not ▁ even ▁ fake _ php . py ▁ ( program _ path = % s ) ▁ ! " % program_path ) NEW_LINE DEDENT class PHPHTTPRequestHandler ( CGIHTTPServer . CGIHTTPRequestHandler ) : NEW_LINE INDENT def is_cgi ( self ) : NEW_LINE INDENT if os . path . split ( self . path ) [ 1 ] == ' ' : NEW_LINE INDENT index_php = os . path . join ( self . path , ' index . php ' ) NEW_LINE if os . path . exists ( self . translate_path ( index_php ) ) : NEW_LINE INDENT self . path = index_php NEW_LINE DEDENT DEDENT if self . path . find ( ' . php ' ) != - 1 : NEW_LINE INDENT self . cgi_info = os . path . split ( self . path ) NEW_LINE return True NEW_LINE DEDENT for p in self . cgi_directories : NEW_LINE INDENT p = os . path . join ( p , ' ' ) NEW_LINE if self . path . startswith ( p ) : NEW_LINE INDENT self . cgi_info = os . path . split ( self . path ) NEW_LINE return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def run_cgi ( self ) : NEW_LINE INDENT """ Execute ▁ a ▁ CGI ▁ script . """ NEW_LINE dir , rest = self . cgi_info NEW_LINE i = rest . rfind ( ' ? ' ) NEW_LINE if i >= 0 : NEW_LINE INDENT rest , query = rest [ : i ] , rest [ i + 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT query = ' ' NEW_LINE DEDENT i = rest . find ( ' / ' ) NEW_LINE if i >= 0 : NEW_LINE INDENT script , rest = rest [ : i ] , rest [ i : ] NEW_LINE DEDENT else : NEW_LINE INDENT script , rest = rest , ' ' NEW_LINE DEDENT scriptname = dir + ' / ' + script NEW_LINE is_php = script . endswith ( ' . php ' ) NEW_LINE # ▁ print ▁ " # # # # ▁ cgi _ info = % s , dir = % s , rest = % s , script = % s , scriptname = % s , is _ php = % s " % ( self . cgi _ info , dir , rest , script , scriptname , is _ php ) ENDCOM if is_php : NEW_LINE INDENT if not php_path : raise Exception ( ' php _ path ▁ not ▁ set ' ) NEW_LINE scriptfile = php_path NEW_LINE sourcefile = self . translate_path ( scriptname ) NEW_LINE DEDENT else : NEW_LINE INDENT scriptfile = self . translate_path ( scriptname ) NEW_LINE DEDENT if not os . path . exists ( scriptfile ) : NEW_LINE INDENT self . send_error ( 404 , " No ▁ such ▁ CGI ▁ script ▁ ( % s ) " %   ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT if not os . path . isfile ( scriptfile ) : NEW_LINE INDENT self . send_error ( 403 , " CGI ▁ script ▁ is ▁ not ▁ a ▁ plain ▁ file ▁ ( % s ) " %                                                         ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT ispy = self . is_python ( scriptname ) NEW_LINE if not ispy : NEW_LINE INDENT if not ( self . have_fork or self . have_popen2 or self . have_popen3 ) : NEW_LINE INDENT self . send_error ( 403 , " CGI ▁ script ▁ is ▁ not ▁ a ▁ Python ▁ script ▁ ( % s ) " %                                                                 ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT if not self . is_executable ( scriptfile ) : NEW_LINE INDENT self . send_error ( 403 , " CGI ▁ script ▁ is ▁ not ▁ executable ▁ ( % s ) " %                                                                 ` scriptname ` ) NEW_LINE return NEW_LINE # ▁ Reference : ▁ http : / / hoohoo . ncsa . uiuc . edu / cgi / env . html ENDCOM # ▁ XXX ▁ Much ▁ of ▁ the ▁ following ▁ could ▁ be ▁ prepared ▁ ahead ▁ of ▁ time ! ENDCOM DEDENT DEDENT env = { } NEW_LINE env [ ' DOCUMENT _ ROOT ' ] = os . getcwd ( ) NEW_LINE env [ ' SERVER _ SOFTWARE ' ] = self . version_string ( ) NEW_LINE env [ ' SERVER _ NAME ' ] = self . server . server_name NEW_LINE env [ ' GATEWAY _ INTERFACE ' ] = ' CGI / 1.1' NEW_LINE env [ ' SERVER _ PROTOCOL ' ] = self . protocol_version NEW_LINE env [ ' SERVER _ PORT ' ] = str ( self . server . server_port ) NEW_LINE env [ ' REQUEST _ METHOD ' ] = self . command NEW_LINE uqrest = urllib . unquote ( self . cgi_info [ 1 ] ) NEW_LINE env [ ' REQUEST _ URI ' ] = self . path NEW_LINE # ▁ env [ ' PATH _ INFO ' ] ▁ = ▁ uqrest ENDCOM # ▁ env [ ' PATH _ TRANSLATED ' ] ▁ = ▁ self . translate _ path ( uqrest ) ENDCOM env [ ' SCRIPT _ NAME ' ] = scriptname NEW_LINE env [ ' SCRIPT _ FILENAME ' ] = self . translate_path ( scriptname ) NEW_LINE if query : NEW_LINE INDENT env [ ' QUERY _ STRING ' ] = query NEW_LINE DEDENT host = self . address_string ( ) NEW_LINE if host != self . client_address [ 0 ] : NEW_LINE INDENT env [ ' REMOTE _ HOST ' ] = host NEW_LINE DEDENT env [ ' REMOTE _ ADDR ' ] = self . client_address [ 0 ] NEW_LINE env [ ' REDIRECT _ STATUS ' ] = '1' # ▁ for ▁ php ENDCOM NEW_LINE # ▁ XXX ▁ AUTH _ TYPE ENDCOM # ▁ XXX ▁ REMOTE _ USER ENDCOM # ▁ XXX ▁ REMOTE _ IDENT ENDCOM if self . headers . typeheader is None : NEW_LINE INDENT env [ ' CONTENT _ TYPE ' ] = self . headers . type NEW_LINE DEDENT else : NEW_LINE INDENT env [ ' CONTENT _ TYPE ' ] = self . headers . typeheader NEW_LINE DEDENT length = self . headers . getheader ( ' content - length ' ) NEW_LINE if length : NEW_LINE INDENT env [ ' CONTENT _ LENGTH ' ] = length NEW_LINE DEDENT accept = [ ] NEW_LINE for line in self . headers . getallmatchingheaders ( ' accept ' ) : NEW_LINE INDENT if line [ : 1 ] in " \t \n ▁ " : NEW_LINE INDENT accept . append ( line . strip ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT accept = accept + line [ 7 : ] . split ( ' , ' ) NEW_LINE DEDENT DEDENT env [ ' HTTP _ ACCEPT ' ] = ' , ' . join ( accept ) NEW_LINE ua = self . headers . getheader ( ' user - agent ' ) NEW_LINE if ua : NEW_LINE INDENT env [ ' HTTP _ USER _ AGENT ' ] = ua NEW_LINE DEDENT co = filter ( None , self . headers . getheaders ( ' cookie ' ) ) NEW_LINE if co : NEW_LINE INDENT env [ ' HTTP _ COOKIE ' ] = ' , ▁ ' . join ( co ) NEW_LINE # ▁ XXX ▁ Other ▁ HTTP _ * ▁ headers ENDCOM DEDENT if not self . have_fork : NEW_LINE # ▁ Since ▁ we ' re ▁ setting ▁ the ▁ env ▁ in ▁ the ▁ parent , ▁ provide ▁ empty ENDCOM # ▁ values ▁ to ▁ override ▁ previously ▁ set ▁ values ENDCOM INDENT for k in ( ' QUERY _ STRING ' , ' REMOTE _ HOST ' , ' CONTENT _ LENGTH ' , ' HTTP _ USER _ AGENT ' , ' HTTP _ COOKIE ' ) : NEW_LINE INDENT env . setdefault ( k , " " ) NEW_LINE DEDENT DEDENT os . environ . update ( env ) NEW_LINE self . send_response ( 200 , " Script ▁ output ▁ follows " ) NEW_LINE decoded_query = query . replace ( ' + ' , ' ▁ ' ) NEW_LINE if self . have_fork : NEW_LINE # ▁ Unix ▁ - - ▁ fork ▁ as ▁ we ▁ should ENDCOM INDENT if is_php : NEW_LINE INDENT args = [ php_path , sourcefile ] NEW_LINE DEDENT else : NEW_LINE INDENT args = [ script ] NEW_LINE DEDENT if ' = ' not in decoded_query : NEW_LINE INDENT args . append ( decoded_query ) NEW_LINE DEDENT self . wfile . flush ( ) # ▁ Always ▁ flush ▁ before ▁ forking ENDCOM NEW_LINE pid = os . fork ( ) NEW_LINE if pid != 0 : NEW_LINE # ▁ Parent ENDCOM INDENT pid , sts = os . waitpid ( pid , 0 ) NEW_LINE # ▁ throw ▁ away ▁ additional ▁ data ▁ [ see ▁ bug ▁ # 427345 ] ENDCOM while select . select ( [ self . rfile ] , [ ] , [ ] , 0 ) [ 0 ] : NEW_LINE INDENT try : NEW_LINE INDENT if not self . rfile . read ( 1 ) : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT if sts : NEW_LINE INDENT self . log_error ( " CGI ▁ script ▁ exit ▁ status ▁ % # x " , sts ) NEW_LINE DEDENT return NEW_LINE # ▁ Child ENDCOM DEDENT try : NEW_LINE INDENT if 0 : NEW_LINE INDENT time . sleep ( .1 ) NEW_LINE fn = ' / tmp / a % d ' % random . randint ( 1000 , 10000 ) NEW_LINE f = open ( fn , ' w ' ) NEW_LINE s = ' ' NEW_LINE while select . select ( [ self . rfile ] , [ ] , [ ] , 0 ) [ 0 ] : NEW_LINE INDENT try : NEW_LINE INDENT c = self . rfile . read ( 1 ) NEW_LINE if not c : NEW_LINE INDENT break NEW_LINE DEDENT s += c NEW_LINE DEDENT except : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT print ' # # # ▁ input : ' , repr ( s ) NEW_LINE print >> f , s NEW_LINE f . close ( ) NEW_LINE self . rfile = open ( fn , ' r ' ) NEW_LINE DEDENT os . dup2 ( self . rfile . fileno ( ) , 0 ) NEW_LINE os . dup2 ( self . wfile . fileno ( ) , 1 ) NEW_LINE os . chdir ( self . translate_path ( dir ) ) # ▁ KC ENDCOM NEW_LINE os . execve ( scriptfile , args , os . environ ) NEW_LINE DEDENT except : NEW_LINE INDENT self . server . handle_error ( self . request , self . client_address ) NEW_LINE os . _exit ( 127 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise SystemExit ( ' need ▁ fork ( ) ' ) NEW_LINE DEDENT DEDENT DEDENT def serve ( bind = ' localhost ' , port = 8000 , handler = PHPHTTPRequestHandler ) : NEW_LINE INDENT httpd = BaseHTTPServer . HTTPServer ( ( bind , port ) , handler ) NEW_LINE httpd . serve_forever ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT setup_php ( os . path . realpath ( os . path . dirname ( sys . argv [ 0 ] ) ) ) NEW_LINE serve ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="Thhhza/XlsxWriter/tree/master/xlsxwriter/test/comparison/test_chart_column04.py"> # ▁ Tests ▁ for ▁ XlsxWriter . ENDCOM # ▁ Copyright ▁ ( c ) , ▁ 2013-2015 , ▁ John ▁ McNamara , ▁ jmcnamara @ cpan . org ENDCOM from . . excel_comparsion_test import ExcelComparisonTest NEW_LINE from ... workbook import Workbook NEW_LINE class TestCompareXLSXFiles ( ExcelComparisonTest ) : NEW_LINE INDENT """ STRNEWLINE ▁ Test ▁ file ▁ created ▁ by ▁ XlsxWriter ▁ against ▁ a ▁ file ▁ created ▁ by ▁ Excel . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def setUp ( self ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE filename = ' chart _ column04 . xlsx ' NEW_LINE test_dir = ' xlsxwriter / test / comparison / ' NEW_LINE self . got_filename = test_dir + ' _ test _ ' + filename NEW_LINE self . exp_filename = test_dir + ' xlsx _ files / ' + filename NEW_LINE self . ignore_files = [ ] NEW_LINE self . ignore_elements = { ' xl / workbook . xml ' : [ ' < fileVersion ' , ' < calcPr ' ] } NEW_LINE DEDENT def test_create_file ( self ) : NEW_LINE INDENT """ Test ▁ the ▁ creation ▁ of ▁ a ▁ simple ▁ XlsxWriter ▁ file . """ NEW_LINE workbook = Workbook ( self . got_filename ) NEW_LINE worksheet = workbook . add_worksheet ( ) NEW_LINE chart = workbook . add_chart ( { ' type ' : ' column ' } ) NEW_LINE chart . axis_ids = [ 63591936 , 63593856 ] NEW_LINE chart . axis2_ids = [ 63613568 , 63612032 ] NEW_LINE data = [ [ 1 , 2 , 3 , 4 , 5 ] , [ 6 , 8 , 6 , 4 , 2 ] ] NEW_LINE worksheet . write_column ( ' A1' , data [ 0 ] ) NEW_LINE worksheet . write_column ( ' B1' , data [ 1 ] ) NEW_LINE chart . add_series ( { ' values ' : ' = Sheet1 ! $ A $ 1 : $ A $ 5' } ) NEW_LINE chart . add_series ( { ' values ' : ' = Sheet1 ! $ B $ 1 : $ B $ 5' , ' y2 _ axis ' : 1 } ) NEW_LINE worksheet . insert_chart ( ' E9' , chart ) NEW_LINE workbook . close ( ) NEW_LINE self . assertExcelEqual ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="w1ll1am23/home-assistant/tree/master/homeassistant/components/homematicip_cloud/weather.py"> """ Support ▁ for ▁ HomematicIP ▁ Cloud ▁ weather ▁ devices . """ NEW_LINE import logging NEW_LINE from homematicip . aio . device import ( AsyncWeatherSensor , AsyncWeatherSensorPlus , AsyncWeatherSensorPro ) NEW_LINE from homematicip . aio . home import AsyncHome NEW_LINE from homeassistant . components . weather import WeatherEntity NEW_LINE from homeassistant . config_entries import ConfigEntry NEW_LINE from homeassistant . const import TEMP_CELSIUS NEW_LINE from homeassistant . core import HomeAssistant NEW_LINE from . import DOMAIN as HMIPC_DOMAIN , HMIPC_HAPID , HomematicipGenericDevice NEW_LINE _LOGGER = logging . getLogger ( __name__ ) NEW_LINE async def async_setup_platform ( hass , config , async_add_entities , discovery_info = None ) : NEW_LINE INDENT """ Set ▁ up ▁ the ▁ HomematicIP ▁ Cloud ▁ weather ▁ sensor . """ NEW_LINE pass NEW_LINE DEDENT async def async_setup_entry ( hass : HomeAssistant , config_entry : ConfigEntry , async_add_entities ) -> None : NEW_LINE INDENT """ Set ▁ up ▁ the ▁ HomematicIP ▁ weather ▁ sensor ▁ from ▁ a ▁ config ▁ entry . """ NEW_LINE home = hass . data [ HMIPC_DOMAIN ] [ config_entry . data [ HMIPC_HAPID ] ] . home NEW_LINE devices = [ ] NEW_LINE for device in home . devices : NEW_LINE INDENT if isinstance ( device , AsyncWeatherSensorPro ) : NEW_LINE INDENT devices . append ( HomematicipWeatherSensorPro ( home , device ) ) NEW_LINE DEDENT elif isinstance ( device , ( AsyncWeatherSensor , AsyncWeatherSensorPlus ) ) : NEW_LINE INDENT devices . append ( HomematicipWeatherSensor ( home , device ) ) NEW_LINE DEDENT DEDENT if devices : NEW_LINE INDENT async_add_entities ( devices ) NEW_LINE DEDENT DEDENT class HomematicipWeatherSensor ( HomematicipGenericDevice , WeatherEntity ) : NEW_LINE INDENT """ representation ▁ of ▁ a ▁ HomematicIP ▁ Cloud ▁ weather ▁ sensor ▁ plus ▁ & ▁ basic . """ NEW_LINE def __init__ ( self , home : AsyncHome , device ) -> None : NEW_LINE INDENT """ Initialize ▁ the ▁ weather ▁ sensor . """ NEW_LINE super ( ) . __init__ ( home , device ) NEW_LINE DEDENT @ property NEW_LINE def name ( self ) -> str : NEW_LINE INDENT """ Return ▁ the ▁ name ▁ of ▁ the ▁ sensor . """ NEW_LINE return self . _device . label NEW_LINE DEDENT @ property NEW_LINE def temperature ( self ) -> float : NEW_LINE INDENT """ Return ▁ the ▁ platform ▁ temperature . """ NEW_LINE return self . _device . actualTemperature NEW_LINE DEDENT @ property NEW_LINE def temperature_unit ( self ) -> str : NEW_LINE INDENT """ Return ▁ the ▁ unit ▁ of ▁ measurement . """ NEW_LINE return TEMP_CELSIUS NEW_LINE DEDENT @ property NEW_LINE def humidity ( self ) -> int : NEW_LINE INDENT """ Return ▁ the ▁ humidity . """ NEW_LINE return self . _device . humidity NEW_LINE DEDENT @ property NEW_LINE def wind_speed ( self ) -> float : NEW_LINE INDENT """ Return ▁ the ▁ wind ▁ speed . """ NEW_LINE return self . _device . windSpeed NEW_LINE DEDENT @ property NEW_LINE def attribution ( self ) -> str : NEW_LINE INDENT """ Return ▁ the ▁ attribution . """ NEW_LINE return " Powered ▁ by ▁ Homematic ▁ IP " NEW_LINE DEDENT @ property NEW_LINE def condition ( self ) -> str : NEW_LINE INDENT """ Return ▁ the ▁ current ▁ condition . """ NEW_LINE if hasattr ( self . _device , " raining " ) and self . _device . raining : NEW_LINE INDENT return ' rainy ' NEW_LINE DEDENT if self . _device . storm : NEW_LINE INDENT return ' windy ' NEW_LINE DEDENT if self . _device . sunshine : NEW_LINE INDENT return ' sunny ' NEW_LINE DEDENT return ' ' NEW_LINE DEDENT DEDENT class HomematicipWeatherSensorPro ( HomematicipWeatherSensor ) : NEW_LINE INDENT """ representation ▁ of ▁ a ▁ HomematicIP ▁ weather ▁ sensor ▁ pro . """ NEW_LINE @ property NEW_LINE def wind_bearing ( self ) -> float : NEW_LINE INDENT """ Return ▁ the ▁ wind ▁ bearing . """ NEW_LINE return self . _device . windDirection NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="hobson/pyexiv2/tree/master/test/usercomment.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2010 ▁ Olivier ▁ Tilloy ▁ < olivier @ tilloy . net > ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ the ▁ pyexiv2 ▁ distribution . ENDCOM # ▁ pyexiv2 ▁ is ▁ free ▁ software ; ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ENDCOM # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation ; ▁ either ▁ version ▁ 2 ENDCOM # ▁ of ▁ the ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ pyexiv2 ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ pyexiv2 ; ▁ if ▁ not , ▁ write ▁ to ▁ the ▁ Free ▁ Software ENDCOM # ▁ Foundation , ▁ Inc . , ▁ 51 ▁ Franklin ▁ Street , ▁ 5th ▁ Floor , ▁ Boston , ▁ MA ▁ 02110-1301 ▁ USA . ENDCOM # ▁ Author : ▁ Olivier ▁ Tilloy ▁ < olivier @ tilloy . net > ENDCOM from pyexiv2 . metadata import ImageMetadata NEW_LINE import unittest NEW_LINE import testutils NEW_LINE import os NEW_LINE import tempfile NEW_LINE from testutils import EMPTY_JPG_DATA NEW_LINE class TestUserCommentReadWrite ( unittest . TestCase ) : NEW_LINE INDENT checksums = { ' usercomment - ascii . jpg ' : ' ad29ac65fb6f63c8361aaed6cb02f8c7' , ' usercomment - unicode - ii . jpg ' : '13b7cc09129a8677f2cf18634f5abd3c ' , ' usercomment - unicode - mm . jpg ' : '7addfed7823c556ba489cd4ab2037200' , } NEW_LINE def _read_image ( self , filename ) : NEW_LINE INDENT filepath = testutils . get_absolute_file_path ( os . path . join ( ' data ' , filename ) ) NEW_LINE self . assert_ ( testutils . CheckFileSum ( filepath , self . checksums [ filename ] ) ) NEW_LINE m = ImageMetadata ( filepath ) NEW_LINE m . read ( ) NEW_LINE return m NEW_LINE DEDENT def _expected_raw_value ( self , endianness , value ) : NEW_LINE INDENT from pyexiv2 import __exiv2_version__ NEW_LINE if __exiv2_version__ >= '0.20' : NEW_LINE INDENT return value NEW_LINE DEDENT else : NEW_LINE INDENT encodings = { ' ii ' : ' utf - 16le ' , ' mm ' : ' utf - 16be ' } NEW_LINE return value . decode ( ' utf - 8' ) . encode ( encodings [ endianness ] ) NEW_LINE DEDENT DEDENT def test_read_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Ascii " ▁ deja ▁ vu ' ) NEW_LINE self . assertEqual ( tag . value , u ' deja ▁ vu ' ) NEW_LINE DEDENT def test_read_unicode_little_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - ii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' ii ' , ' déjà ▁ vu ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' déjà ▁ vu ' ) NEW_LINE DEDENT def test_read_unicode_big_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - mm . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' mm ' , ' déjà ▁ vu ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' déjà ▁ vu ' ) NEW_LINE DEDENT def test_write_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = ' foo ▁ bar ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Ascii " ▁ foo ▁ bar ' ) NEW_LINE self . assertEqual ( tag . value , u ' foo ▁ bar ' ) NEW_LINE DEDENT def test_write_unicode_over_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u ' déjà ▁ vu ' NEW_LINE self . assertEqual ( tag . raw_value , ' déjà ▁ vu ' ) NEW_LINE self . assertEqual ( tag . value , u ' déjà ▁ vu ' ) NEW_LINE DEDENT def test_write_unicode_little_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - ii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u ' DÉJÀ ▁ VU ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' ii ' , ' DÉJÀ ▁ VU ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' DÉJÀ ▁ VU ' ) NEW_LINE DEDENT def test_write_unicode_big_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - mm . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u ' DÉJÀ ▁ VU ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' mm ' , ' DÉJÀ ▁ VU ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' DÉJÀ ▁ VU ' ) NEW_LINE DEDENT DEDENT class TestUserCommentAdd ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE # ▁ Create ▁ an ▁ empty ▁ image ▁ file ENDCOM INDENT fd , self . pathname = tempfile . mkstemp ( suffix = ' . jpg ' ) NEW_LINE os . write ( fd , EMPTY_JPG_DATA ) NEW_LINE os . close ( fd ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT os . remove ( self . pathname ) NEW_LINE DEDENT def _test_add_comment ( self , value ) : NEW_LINE INDENT metadata = ImageMetadata ( self . pathname ) NEW_LINE metadata . read ( ) NEW_LINE key = ' Exif . Photo . UserComment ' NEW_LINE metadata [ key ] = value NEW_LINE metadata . write ( ) NEW_LINE metadata = ImageMetadata ( self . pathname ) NEW_LINE metadata . read ( ) NEW_LINE self . assert_ ( key in metadata . exif_keys ) NEW_LINE tag = metadata [ key ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . value , value ) NEW_LINE DEDENT def test_add_comment_ascii ( self ) : NEW_LINE INDENT self . _test_add_comment ( ' deja ▁ vu ' ) NEW_LINE DEDENT def test_add_comment_unicode ( self ) : NEW_LINE INDENT self . _test_add_comment ( u ' déjà ▁ vu ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="nischalsheth/contrail-controller/tree/master/src/vnsw/provisioning/contrail_vrouter_provisioning/network.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2013 ▁ Juniper ▁ Networks , ▁ Inc . ▁ All ▁ rights ▁ reserved . ENDCOM import os NEW_LINE import re NEW_LINE import glob NEW_LINE import struct NEW_LINE import socket NEW_LINE import logging NEW_LINE import netifaces NEW_LINE from contrail_vrouter_provisioning import local NEW_LINE log = logging . getLogger ( ' contrail _ vrouter _ provisioning . network ' ) NEW_LINE class ComputeNetworkSetup ( object ) : NEW_LINE INDENT def find_gateway ( self , dev ) : NEW_LINE INDENT gateway = ' ' NEW_LINE cmd = " sudo ▁ netstat ▁ - rn ▁ | ▁ sudo ▁ grep ▁ ^ \ " 0.0.0.0\ " ▁ | ▁ " NEW_LINE cmd += " sudo ▁ head ▁ - n ▁ 1 ▁ | ▁ sudo ▁ grep ▁ % s ▁ | ▁ sudo ▁ awk ▁ ' { ▁ print ▁ $ 2 ▁ } ' " % dev NEW_LINE gateway = local ( cmd , capture = True ) . strip ( ) NEW_LINE return gateway NEW_LINE # ▁ end ▁ find _ gateway ENDCOM DEDENT def get_dns_servers ( self , dev ) : NEW_LINE INDENT cmd = " sudo ▁ grep ▁ \ " ^ nameserver\\ > \ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ▁ ' { print ▁ $ 2 } ' " NEW_LINE dns_list = local ( cmd , capture = True ) NEW_LINE return dns_list . split ( ) NEW_LINE # ▁ end ▁ get _ dns _ servers ENDCOM DEDENT def get_domain_search_list ( self ) : NEW_LINE INDENT domain_list = ' ' NEW_LINE cmd = " sudo ▁ grep ▁ ^ \ " search\ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ' { $ 1 = \ " \ " ; print ▁ $ 0 } ' " NEW_LINE domain_list = local ( cmd , capture = True ) . strip ( ) NEW_LINE if not domain_list : NEW_LINE INDENT cmd = " sudo ▁ grep ▁ ^ \ " domain\ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ' { $ 1 = \ " \ " ; ▁ print ▁ $ 0 } ' " NEW_LINE domain_list = local ( cmd , capture = True ) . strip ( ) NEW_LINE DEDENT return domain_list NEW_LINE DEDENT def get_if_mtu ( self , dev ) : NEW_LINE INDENT cmd = " sudo ▁ ifconfig ▁ % s ▁ | ▁ sudo ▁ grep ▁ mtu ▁ | ▁ sudo ▁ awk ▁ ' { ▁ print ▁ $ NF ▁ } ' " % dev NEW_LINE mtu = local ( cmd , capture = True ) . strip ( ) NEW_LINE if not mtu : NEW_LINE # ▁ for ▁ debian ENDCOM INDENT cmd = r " sudo ▁ ifconfig ▁ % s ▁ | ▁ sudo ▁ grep ▁ MTU ▁ | ▁ " % dev NEW_LINE cmd += r " sudo ▁ sed ▁ ' s / . * MTU . \ ( [0-9 ] \ + \ ) . * / \1 / g ' " NEW_LINE mtu = local ( cmd , capture = True ) . strip ( ) NEW_LINE DEDENT if ( mtu and mtu != '1500' ) : NEW_LINE INDENT return mtu NEW_LINE DEDENT return ' ' NEW_LINE # ▁ end ▁ if _ mtu ENDCOM DEDENT def get_device_by_ip ( self , ip ) : NEW_LINE INDENT for i in netifaces . interfaces ( ) : NEW_LINE INDENT try : NEW_LINE INDENT if i == ' pkt1' : NEW_LINE INDENT continue NEW_LINE DEDENT if netifaces . AF_INET in netifaces . ifaddresses ( i ) : NEW_LINE INDENT interfaces = netifaces . ifaddresses ( i ) [ netifaces . AF_INET ] NEW_LINE for interface in interfaces : NEW_LINE INDENT if ip == interface [ ' addr ' ] : NEW_LINE INDENT if i == ' vhost0' : NEW_LINE INDENT log . info ( " vhost0 ▁ is ▁ already ▁ present ! " ) NEW_LINE DEDENT return i NEW_LINE DEDENT DEDENT DEDENT DEDENT except ValueError : NEW_LINE INDENT log . info ( " Skipping ▁ interface ▁ % s " , i ) NEW_LINE DEDENT DEDENT raise RuntimeError ( ' % s ▁ not ▁ configured , ▁ rerun ▁ w / ▁ - - physical _ interface ' % ip ) NEW_LINE # ▁ end ▁ get _ device _ by _ ip ENDCOM DEDENT def get_device_info ( self , ip ) : NEW_LINE INDENT reprov = False NEW_LINE cfg_file = " / etc / contrail / contrail - vrouter - agent . conf " NEW_LINE try : NEW_LINE INDENT dev = self . get_device_by_ip ( ip ) NEW_LINE if dev == " vhost0" : NEW_LINE INDENT dev = self . get_config ( cfg_file , " VIRTUAL - HOST - INTERFACE " , " physical _ interface " ) NEW_LINE log . info ( " Re - provision . ▁ vhost0 ▁ present " ) NEW_LINE reprov = True NEW_LINE DEDENT else : NEW_LINE INDENT log . info ( " Fresh ▁ Install . ▁ vhost0 ▁ not ▁ present " ) NEW_LINE DEDENT DEDENT except RuntimeError : NEW_LINE INDENT dev = self . get_config ( cfg_file , " VIRTUAL - HOST - INTERFACE " , " physical _ interface " ) NEW_LINE if not dev . succeeded : NEW_LINE INDENT raise NEW_LINE DEDENT log . info ( " vhost0 ▁ not ▁ present , ▁ vrouter ▁ not ▁ running " ) NEW_LINE reprov = True NEW_LINE DEDENT return ( dev . strip ( ) , reprov ) NEW_LINE # ▁ end ▁ get _ device _ info ENDCOM DEDENT def get_secondary_device ( self , primary ) : NEW_LINE INDENT for i in netifaces . interfaces ( ) : NEW_LINE INDENT try : NEW_LINE INDENT if i == ' pkt1' : NEW_LINE INDENT continue NEW_LINE DEDENT if i == primary : NEW_LINE INDENT continue NEW_LINE DEDENT if i == ' vhost0' : NEW_LINE INDENT continue NEW_LINE DEDENT if netifaces . AF_INET not in netifaces . ifaddresses ( i ) : NEW_LINE INDENT return i NEW_LINE DEDENT DEDENT except ValueError : NEW_LINE INDENT log . info ( " Skipping ▁ interface ▁ % s " % i ) NEW_LINE DEDENT DEDENT raise RuntimeError ( ' Secondary ▁ interace ▁ ▁ not ▁ configured , ' , ' rerun ▁ w / ▁ - - physical _ interface ' ) NEW_LINE # ▁ end ▁ get _ secondary _ device ENDCOM DEDENT def get_if_mac ( self , dev ) : NEW_LINE INDENT iface_addr = netifaces . ifaddresses ( dev ) NEW_LINE link_info = iface_addr [ netifaces . AF_LINK ] NEW_LINE mac_addr = link_info [ 0 ] [ ' addr ' ] NEW_LINE return mac_addr NEW_LINE # ▁ end ▁ get _ if _ mac ENDCOM DEDENT @ staticmethod NEW_LINE def is_interface_vlan ( interface ) : NEW_LINE INDENT iface = local ( " sudo ▁ ip ▁ link ▁ show ▁ % s ▁ | ▁ head ▁ - 1" % interface + " | ▁ cut ▁ - f2 ▁ - d ' : ' ▁ | ▁ grep ▁ ' @ ' " , capture = True , warn_only = True ) NEW_LINE if iface . succeeded : NEW_LINE INDENT return True NEW_LINE DEDENT else : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def get_physical_interface_of_vlan ( interface ) : NEW_LINE INDENT iface = local ( " sudo ▁ ip ▁ link ▁ show ▁ % s ▁ | ▁ head ▁ - 1 ▁ | ▁ cut ▁ - f2 ▁ - d ' : ' " % interface + " | ▁ cut ▁ - f2 ▁ - d ' @ ' " , capture = True ) NEW_LINE return iface NEW_LINE DEDENT def _rewrite_ifcfg_file ( self , filename , dev , prsv_cfg ) : NEW_LINE INDENT bond = False NEW_LINE mac = ' ' NEW_LINE temp_dir_name = self . _temp_dir_name NEW_LINE vlan = False NEW_LINE if os . path . isfile ( ' / proc / net / vlan / % s ' % dev ) : NEW_LINE INDENT vlan_info = open ( ' / proc / net / vlan / config ' ) . readlines ( ) NEW_LINE match = re . search ( ' ^ % s . * \ | \s + ( \S + ) $ ' % dev , " \n " . join ( vlan_info ) , flags = re . M | re . I ) NEW_LINE if not match : NEW_LINE INDENT raise RuntimeError ( " Configured ▁ vlan ▁ % s ▁ is ▁ not ▁ found ▁ in " , " / proc / net / vlan / config " % dev ) NEW_LINE DEDENT vlan = True NEW_LINE DEDENT if os . path . isdir ( ' / sys / class / net / % s / bonding ' % dev ) : NEW_LINE INDENT bond = True NEW_LINE # ▁ end ▁ if ▁ os . path . isdir . . . ENDCOM DEDENT mac = netifaces . ifaddresses ( dev ) [ netifaces . AF_LINK ] [ 0 ] [ ' addr ' ] NEW_LINE ifcfg_file = ' / etc / sysconfig / network - scripts / ifcfg - % s ' % dev NEW_LINE if not os . path . isfile ( ifcfg_file ) : NEW_LINE INDENT ifcfg_file = temp_dir_name + ' ifcfg - ' + dev NEW_LINE with open ( ifcfg_file , ' w ' ) as f : NEW_LINE INDENT f . write ( ''' # Contrail ▁ % s STRNEWLINE TYPE = Ethernet STRNEWLINE ONBOOT = yes STRNEWLINE DEVICE = " % s " STRNEWLINE USERCTL = yes STRNEWLINE NM _ CONTROLLED = no STRNEWLINE HWADDR = % s STRNEWLINE ''' % ( dev , dev , mac ) ) NEW_LINE for dcfg in prsv_cfg : NEW_LINE INDENT f . write ( dcfg + ' \n ' ) NEW_LINE DEDENT if vlan : NEW_LINE INDENT f . write ( ' VLAN = yes \n ' ) NEW_LINE DEDENT DEDENT DEDENT fd = open ( ifcfg_file ) NEW_LINE f_lines = fd . readlines ( ) NEW_LINE fd . close ( ) NEW_LINE local ( " sudo ▁ rm ▁ - f ▁ % s " % ifcfg_file ) NEW_LINE new_f_lines = [ ] NEW_LINE remove_items = [ ' IPADDR ' , ' NETMASK ' , ' PREFIX ' , ' GATEWAY ' , ' HWADDR ' , ' DNS1' , ' DNS2' , ' BOOTPROTO ' , ' NM _ CONTROLLED ' , ' # Contrail ' ] NEW_LINE remove_items . append ( ' DEVICE ' ) NEW_LINE new_f_lines . append ( ' # Contrail ▁ % s \n ' % dev ) NEW_LINE new_f_lines . append ( ' DEVICE = % s \n ' % dev ) NEW_LINE for line in f_lines : NEW_LINE INDENT found = False NEW_LINE for text in remove_items : NEW_LINE INDENT if text in line : NEW_LINE INDENT found = True NEW_LINE DEDENT DEDENT if not found : NEW_LINE INDENT new_f_lines . append ( line ) NEW_LINE DEDENT DEDENT new_f_lines . append ( ' NM _ CONTROLLED = no \n ' ) NEW_LINE if bond : NEW_LINE INDENT new_f_lines . append ( ' SUBCHANNELS = 1,2,3 \n ' ) NEW_LINE DEDENT elif not vlan : NEW_LINE INDENT new_f_lines . append ( ' HWADDR = % s \n ' % mac ) NEW_LINE DEDENT fdw = open ( filename , ' w ' ) NEW_LINE fdw . writelines ( new_f_lines ) NEW_LINE fdw . close ( ) NEW_LINE DEDENT def migrate_routes ( self , device ) : NEW_LINE INDENT ''' STRNEWLINE ▁ add ▁ route ▁ entries ▁ in ▁ / proc / net / route STRNEWLINE ▁ ''' NEW_LINE temp_dir_name = self . _temp_dir_name NEW_LINE cfg_file = ' / etc / sysconfig / network - scripts / route - vhost0' NEW_LINE tmp_file = ' % s / route - vhost0' % temp_dir_name NEW_LINE with open ( tmp_file , ' w ' ) as route_cfg_file : NEW_LINE INDENT for route in open ( ' / proc / net / route ' , ' r ' ) . readlines ( ) : NEW_LINE INDENT if route . startswith ( device ) : NEW_LINE INDENT route_fields = route . split ( ) NEW_LINE destination = int ( route_fields [ 1 ] , 16 ) NEW_LINE gateway = int ( route_fields [ 2 ] , 16 ) NEW_LINE flags = int ( route_fields [ 3 ] , 16 ) NEW_LINE mask = int ( route_fields [ 7 ] , 16 ) NEW_LINE if flags & 0x2 : NEW_LINE INDENT if destination != 0 : NEW_LINE INDENT route_cfg_file . write ( socket . inet_ntoa ( struct . pack ( ' I ' , destination ) ) ) NEW_LINE route_cfg_file . write ( ' / ' + str ( bin ( mask ) . count ( '1' ) ) + ' ▁ ' ) NEW_LINE route_cfg_file . write ( ' via ▁ ' ) NEW_LINE route_cfg_file . write ( socket . inet_ntoa ( struct . pack ( ' I ' , gateway ) ) + ' ▁ ' ) NEW_LINE route_cfg_file . write ( ' dev ▁ vhost0' ) NEW_LINE # ▁ end ▁ if ▁ detination . . . ENDCOM # ▁ end ▁ if ▁ flags ▁ & . . . ENDCOM # ▁ end ▁ if ▁ route . startswith . . . ENDCOM # ▁ end ▁ for ▁ route . . . ENDCOM # ▁ end ▁ with ▁ open . . . ENDCOM DEDENT DEDENT DEDENT DEDENT DEDENT local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( tmp_file , cfg_file ) ) NEW_LINE # ▁ delete ▁ the ▁ route - dev ▁ file ENDCOM if os . path . isfile ( ' / etc / sysconfig / network - scripts / route - % s ' % device ) : NEW_LINE INDENT os . unlink ( ' / etc / sysconfig / network - scripts / route - % s ' % device ) NEW_LINE # ▁ end ▁ def ▁ migrate _ routes ENDCOM DEDENT DEDENT def get_cfgfile_for_dev ( self , iface , cfg_files ) : NEW_LINE INDENT if not cfg_files : NEW_LINE INDENT return None NEW_LINE DEDENT mapped_intf_cfgfile = None NEW_LINE for file in cfg_files : NEW_LINE INDENT with open ( file , ' r ' ) as fd : NEW_LINE INDENT contents = fd . read ( ) NEW_LINE regex = ' ( ? : ^ | \n ) \s * iface\s + % s\s + ' % iface NEW_LINE if re . search ( regex , contents ) : NEW_LINE INDENT mapped_intf_cfgfile = file NEW_LINE DEDENT DEDENT DEDENT return mapped_intf_cfgfile NEW_LINE DEDENT def get_sourced_files ( self ) : NEW_LINE INDENT ''' Get ▁ all ▁ sourced ▁ config ▁ files ''' NEW_LINE files = self . get_valid_files ( self . get_source_entries ( ) ) NEW_LINE files += self . get_source_directory_files ( ) NEW_LINE return list ( set ( files ) ) NEW_LINE DEDENT def get_source_directory_files ( self ) : NEW_LINE INDENT ''' Get ▁ source - directory ▁ entry ▁ and ▁ make ▁ list ▁ of ▁ valid ▁ files ''' NEW_LINE regex = ' ( ? : ^ | \n ) \s * source - directory\s + ( \S + ) ' NEW_LINE files = list ( ) NEW_LINE with open ( self . default_cfg_file , ' r ' ) as fd : NEW_LINE INDENT entries = re . findall ( regex , fd . read ( ) ) NEW_LINE DEDENT dirs = [ d for d in self . get_valid_files ( entries ) if os . path . isdir ( d ) ] NEW_LINE for dir in dirs : NEW_LINE INDENT files . extend ( [ os . path . join ( dir , f ) for f in os . listdir ( dir ) if os . path . isfile ( os . path . join ( dir , f ) ) and re . match ( ' ^ [ a - zA - Z0-9 _ - ] + $ ' , f ) ] ) NEW_LINE DEDENT return files NEW_LINE DEDENT def get_source_entries ( self ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Get ▁ entries ▁ matching ▁ source ▁ keyword ▁ from STRNEWLINE ▁ / etc / network / interfaces ▁ file . STRNEWLINE ▁ ''' NEW_LINE regex = ' ( ? : ^ | \n ) \s * source\s + ( \S + ) ' NEW_LINE with open ( self . default_cfg_file , ' r ' ) as fd : NEW_LINE INDENT return re . findall ( regex , fd . read ( ) ) NEW_LINE DEDENT DEDENT def get_valid_files ( self , entries ) : NEW_LINE INDENT ''' Provided ▁ a ▁ list ▁ of ▁ glob ' d ▁ strings , ▁ return ▁ matching ▁ file ▁ names ''' NEW_LINE files = list ( ) NEW_LINE prepend = os . path . join ( os . path . sep , ' etc ' , ' network ' ) + os . path . sep NEW_LINE for entry in entries : NEW_LINE INDENT entry = entry . lstrip ( ' . / ' ) if entry . startswith ( ' . / ' ) else entry NEW_LINE if entry . startswith ( os . path . sep ) : NEW_LINE INDENT entry = entry NEW_LINE DEDENT else : NEW_LINE INDENT entry = prepend + entry NEW_LINE DEDENT files . extend ( glob . glob ( entry ) ) NEW_LINE DEDENT return files NEW_LINE DEDENT def _rewrite_net_interfaces_file ( self , dev , mac , vhost_ip , netmask , gateway_ip , esxi_vm , vmpg_mtu , datapg_mtu ) : NEW_LINE INDENT self . default_cfg_file = ' / etc / network / interfaces ' NEW_LINE cfg_files = self . get_sourced_files ( ) NEW_LINE cfg_files . append ( self . default_cfg_file ) NEW_LINE intf_cfgfile = self . get_cfgfile_for_dev ( ' vhost0' , cfg_files ) NEW_LINE if intf_cfgfile : NEW_LINE INDENT log . info ( " Interface ▁ vhost0 ▁ is ▁ already ▁ present ▁ in " + " / etc / network / interfaces " ) NEW_LINE log . info ( " Skipping ▁ rewrite ▁ of ▁ this ▁ file " ) NEW_LINE return NEW_LINE # ▁ endif ENDCOM DEDENT vlan = False NEW_LINE if os . path . isfile ( ' / proc / net / vlan / % s ' % dev ) : NEW_LINE INDENT vlan_info = open ( ' / proc / net / vlan / config ' ) . readlines ( ) NEW_LINE match = re . search ( ' ^ % s . * \ | \s + ( \S + ) $ ' % dev , " \n " . join ( vlan_info ) , flags = re . M | re . I ) NEW_LINE if not match : NEW_LINE INDENT raise RuntimeError ( ' Configured ▁ vlan ▁ % s ▁ is ▁ not ▁ found ▁ in ' , ' / proc / net / vlan / config ' % dev ) NEW_LINE DEDENT phydev = match . group ( 1 ) NEW_LINE vlan = True NEW_LINE # ▁ Replace ▁ strings ▁ matching ▁ dev ▁ to ▁ vhost0 ▁ in ▁ ifup ▁ and ▁ ifdown ▁ parts ▁ file ENDCOM # ▁ Any ▁ changes ▁ to ▁ the ▁ file / logic ▁ with ▁ static ▁ routes ▁ has ▁ to ▁ be ENDCOM # ▁ reflected ▁ in ▁ setup - vnc - static - routes . py ▁ too ENDCOM DEDENT ifup_parts_file = os . path . join ( os . path . sep , ' etc ' , ' network ' , ' if - up . d ' , ' routes ' ) NEW_LINE ifdown_parts_file = os . path . join ( os . path . sep , ' etc ' , ' network ' , ' if - down . d ' , ' routes ' ) NEW_LINE if ( os . path . isfile ( ifup_parts_file ) and os . path . isfile ( ifdown_parts_file ) ) : NEW_LINE INDENT local ( " sudo ▁ sed ▁ - i ▁ ' s / % s / vhost0 / g ' ▁ % s " % ( dev , ifup_parts_file ) , warn_only = True ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' s / % s / vhost0 / g ' ▁ % s " % ( dev , ifdown_parts_file ) , warn_only = True ) NEW_LINE DEDENT dev_cfgfile = self . get_cfgfile_for_dev ( dev , cfg_files ) NEW_LINE temp_intf_file = ' % s / interfaces ' % self . _temp_dir_name NEW_LINE local ( " sudo ▁ cp ▁ % s ▁ % s " % ( dev_cfgfile , temp_intf_file ) ) NEW_LINE with open ( dev_cfgfile , ' r ' ) as fd : NEW_LINE INDENT cfg_file = fd . read ( ) NEW_LINE DEDENT if not self . _args . non_mgmt_ip : NEW_LINE # ▁ remove ▁ entry ▁ from ▁ auto ▁ < dev > ▁ to ▁ auto ▁ excluding ▁ these ▁ pattern ENDCOM # ▁ then ▁ delete ▁ specifically ▁ auto ▁ < dev > ENDCOM INDENT local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / , / auto / { / auto / ! d } ' ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / d ' ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE # ▁ add ▁ manual ▁ entry ▁ for ▁ dev ENDCOM local ( " sudo ▁ echo ▁ ' auto ▁ % s ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ % s ▁ inet ▁ manual ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE if vlan : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - up ▁ ifconfig ▁ % s ▁ up ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE DEDENT else : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE DEDENT if esxi_vm : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( dev , datapg_mtu , temp_intf_file ) ) NEW_LINE cmd = " sudo ▁ ethtool ▁ - i ▁ % s ▁ | ▁ grep ▁ driver ▁ | ▁ cut ▁ - f ▁ 2 ▁ - d ▁ ' ▁ ' " % dev NEW_LINE device_driver = local ( cmd , capture = True ) NEW_LINE if ( device_driver == " vmxnet3" ) : NEW_LINE INDENT cmd = " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ " NEW_LINE rx_cmd = ( cmd + " % s ▁ rx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE tx_cmd = ( cmd + " % s ▁ tx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( rx_cmd ) NEW_LINE local ( tx_cmd ) NEW_LINE DEDENT DEDENT if vlan : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ vlan - raw - device ▁ % s ' ▁ > > ▁ % s " % ( phydev , temp_intf_file ) ) NEW_LINE DEDENT if ' bond ' in dev . lower ( ) : NEW_LINE INDENT iters = re . finditer ( ' ^ \s * auto\s ' , cfg_file , re . M ) NEW_LINE indices = [ pat_match . start ( ) for pat_match in iters ] NEW_LINE matches = map ( cfg_file . __getslice__ , indices , indices [ 1 : ] + [ len ( cfg_file ) ] ) NEW_LINE for each in matches : NEW_LINE INDENT each = each . strip ( ) NEW_LINE if re . match ( ' ^ auto\s + % s ' % dev , each ) : NEW_LINE INDENT string = ' ' NEW_LINE for lines in each . splitlines ( ) : NEW_LINE INDENT if ' bond - ' in lines : NEW_LINE INDENT string += lines + os . linesep NEW_LINE DEDENT DEDENT local ( " sudo ▁ echo ▁ ' % s ' ▁ > > ▁ % s " % ( string , temp_intf_file ) ) NEW_LINE DEDENT else : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE DEDENT else : NEW_LINE # ▁ remove ▁ ip ▁ address ▁ and ▁ gateway ENDCOM INDENT local ( " sudo ▁ sed ▁ - i ▁ ' / iface ▁ % s ▁ inet ▁ static / , ▁ + 2d ' ▁ % s " % ( dev , temp_intf_file ) , warn_only = True ) NEW_LINE if esxi_vm : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( dev , datapg_mtu , temp_intf_file ) , warn_only = True ) NEW_LINE cmd = " sudo ▁ ethtool ▁ - i ▁ % s ▁ | ▁ " % dev NEW_LINE cmd += " sudo ▁ grep ▁ driver ▁ | ▁ sudo ▁ cut ▁ - f ▁ 2 ▁ - d ▁ ' ▁ ' " NEW_LINE device_driver = local ( cmd , capture = True , warn_only = True ) NEW_LINE if ( device_driver == " vmxnet3" ) : NEW_LINE INDENT cmd = " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ " NEW_LINE rx_cmd = cmd + " % s ▁ rx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) NEW_LINE tx_cmd = cmd + " % s ▁ tx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( rx_cmd , warn_only = True ) NEW_LINE local ( tx_cmd , warn_only = True ) NEW_LINE DEDENT DEDENT if vlan : NEW_LINE INDENT cmd = " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / ▁ a\iface ▁ % s ▁ inet ▁ manual\ \n ▁ ▁ ▁ ▁ " % ( dev , dev ) NEW_LINE cmd += " post - up ▁ ifconfig ▁ % s ▁ up\ \n ▁ ▁ ▁ ▁ " % dev NEW_LINE cmd += " pre - down ▁ ifconfig ▁ % s ▁ down\ ' ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( cmd ) NEW_LINE DEDENT else : NEW_LINE INDENT cmd = " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / ▁ a\iface ▁ % s ▁ inet ▁ manual\ \n ▁ ▁ ▁ ▁ " % ( dev , dev ) NEW_LINE cmd += " pre - up ▁ ifconfig ▁ % s ▁ up\ \n ▁ ▁ ▁ ▁ " % dev NEW_LINE cmd += " post - down ▁ ifconfig ▁ % s ▁ down\ ' ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( cmd ) NEW_LINE DEDENT DEDENT if esxi_vm and vmpg_mtu : NEW_LINE INDENT intf = self . get_secondary_device ( self . dev ) NEW_LINE mac_addr = self . get_if_mac ( intf ) NEW_LINE udev_net_file = ' / etc / udev / rules . d / 70 - persistent - net . rules ' NEW_LINE temp_udev_net_file = ' % s / 70 - persistent - net . rules ' % ( self . _temp_dir_name ) NEW_LINE local ( " sudo ▁ touch ▁ % s " % temp_udev_net_file ) NEW_LINE local ( " sudo ▁ cp ▁ % s ▁ % s " % ( udev_net_file , temp_udev_net_file ) ) NEW_LINE cmd = " sudo ▁ echo ▁ ' SUBSYSTEM = = \ " net\ " , ▁ ACTION = = \ " add\ " , " NEW_LINE cmd += " ▁ DRIVERS = = \ " ? * \ " , " NEW_LINE cmd += " ▁ ATTR { address } = = \ " % s\ " , ▁ ATTR { dev _ id } = = \ " 0x0\ " , ▁ " % mac_addr NEW_LINE cmd += " ATTR { type } = = \ " 1\ " , ▁ KERNEL = = \ " eth * \ " , ▁ NAME = \ " % s\ " ' ▁ > > ▁ % s " % ( intf , temp_udev_net_file ) NEW_LINE local ( cmd ) NEW_LINE local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( temp_udev_net_file , udev_net_file ) ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / , / down / d ' ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' \n auto ▁ % s ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ % s ▁ inet ▁ manual ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( intf , vmpg_mtu , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ % s ▁ lro ▁ off ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE # ▁ populte ▁ vhost0 ▁ as ▁ static ENDCOM DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' auto ▁ vhost0 ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ vhost0 ▁ inet ▁ static ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ % s / if - vhost0 ' ▁ > > ▁ % s " % ( self . contrail_bin_dir , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ netmask ▁ % s ' ▁ > > ▁ % s " % ( netmask , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ network _ name ▁ application ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE if esxi_vm and datapg_mtu : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( datapg_mtu , temp_intf_file ) ) NEW_LINE DEDENT if vhost_ip : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ address ▁ % s ' ▁ > > ▁ % s " % ( vhost_ip , temp_intf_file ) ) NEW_LINE DEDENT if ( not self . _args . non_mgmt_ip ) and gateway_ip : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ gateway ▁ % s ' ▁ > > ▁ % s " % ( gateway_ip , temp_intf_file ) ) NEW_LINE DEDENT domain = self . get_domain_search_list ( ) NEW_LINE if domain : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ dns - search ▁ % s ' ▁ > > ▁ % s " % ( domain , temp_intf_file ) ) NEW_LINE DEDENT dns_list = self . get_dns_servers ( dev ) NEW_LINE if dns_list : NEW_LINE INDENT local ( " sudo ▁ echo ▁ - n ▁ ' ▁ ▁ ▁ ▁ dns - nameservers ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE for dns in dns_list : NEW_LINE INDENT local ( " sudo ▁ echo ▁ - n ▁ ' ▁ % s ' ▁ > > ▁ % s " % ( dns , temp_intf_file ) ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - up ▁ ip ▁ link ▁ set ▁ vhost0 ▁ address ▁ % s ' ▁ > > ▁ % s " % ( mac , temp_intf_file ) ) NEW_LINE # ▁ move ▁ it ▁ to ▁ right ▁ place ENDCOM local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( temp_intf_file , dev_cfgfile ) ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="dentaku65/plugin.video.italyalacarta/tree/master/lib/gdata/tlslite/utils/PyCrypto_RSAKey.py"> """ PyCrypto ▁ RSA ▁ implementation . """ NEW_LINE from cryptomath import * NEW_LINE from RSAKey import * NEW_LINE from Python_RSAKey import Python_RSAKey NEW_LINE if pycryptoLoaded : NEW_LINE INDENT from Crypto . PublicKey import RSA NEW_LINE class PyCrypto_RSAKey ( RSAKey ) : NEW_LINE INDENT def __init__ ( self , n = 0 , e = 0 , d = 0 , p = 0 , q = 0 , dP = 0 , dQ = 0 , qInv = 0 ) : NEW_LINE INDENT if not d : NEW_LINE INDENT self . rsa = RSA . construct ( ( n , e ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . rsa = RSA . construct ( ( n , e , d , p , q ) ) NEW_LINE DEDENT DEDENT def __getattr__ ( self , name ) : NEW_LINE INDENT return getattr ( self . rsa , name ) NEW_LINE DEDENT def hasPrivateKey ( self ) : NEW_LINE INDENT return self . rsa . has_private ( ) NEW_LINE DEDENT def hash ( self ) : NEW_LINE INDENT return Python_RSAKey ( self . n , self . e ) . hash ( ) NEW_LINE DEDENT def _rawPrivateKeyOp ( self , m ) : NEW_LINE INDENT s = numberToString ( m ) NEW_LINE byteLength = numBytes ( self . n ) NEW_LINE if len ( s ) == byteLength : NEW_LINE INDENT pass NEW_LINE DEDENT elif len ( s ) == byteLength - 1 : NEW_LINE INDENT s = ' \0' + s NEW_LINE DEDENT else : NEW_LINE INDENT raise AssertionError ( ) NEW_LINE DEDENT c = stringToNumber ( self . rsa . decrypt ( ( s , ) ) ) NEW_LINE return c NEW_LINE DEDENT def _rawPublicKeyOp ( self , c ) : NEW_LINE INDENT s = numberToString ( c ) NEW_LINE byteLength = numBytes ( self . n ) NEW_LINE if len ( s ) == byteLength : NEW_LINE INDENT pass NEW_LINE DEDENT elif len ( s ) == byteLength - 1 : NEW_LINE INDENT s = ' \0' + s NEW_LINE DEDENT else : NEW_LINE INDENT raise AssertionError ( ) NEW_LINE DEDENT m = stringToNumber ( self . rsa . encrypt ( s , None ) [ 0 ] ) NEW_LINE return m NEW_LINE DEDENT def writeXMLPublicKey ( self , indent = ' ' ) : NEW_LINE INDENT return Python_RSAKey ( self . n , self . e ) . write ( indent ) NEW_LINE DEDENT def generate ( bits ) : NEW_LINE INDENT key = PyCrypto_RSAKey ( ) NEW_LINE def f ( numBytes ) : NEW_LINE INDENT return bytesToString ( getRandomBytes ( numBytes ) ) NEW_LINE DEDENT key . rsa = RSA . generate ( bits , f ) NEW_LINE return key NEW_LINE DEDENT generate = staticmethod ( generate ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="2014cdbg14/2014cdbg14/tree/master/wsgi/static/Brython2.1.0-20140419-113919/Lib/collections/abc.py"> # ▁ Copyright ▁ 2007 ▁ Google , ▁ Inc . ▁ All ▁ Rights ▁ Reserved . ENDCOM # ▁ Licensed ▁ to ▁ PSF ▁ under ▁ a ▁ Contributor ▁ Agreement . ENDCOM """ Abstract ▁ Base ▁ Classes ▁ ( ABCs ) ▁ for ▁ collections , ▁ according ▁ to ▁ PEP ▁ 3119 . STRNEWLINE STRNEWLINE Unit ▁ tests ▁ are ▁ in ▁ test _ collections . STRNEWLINE """ NEW_LINE from abc import ABCMeta , abstractmethod NEW_LINE import sys NEW_LINE __all__ = [ " Hashable " , " Iterable " , " Iterator " , " Sized " , " Container " , " Callable " , " Set " , " MutableSet " , " Mapping " , " MutableMapping " , " MappingView " , " KeysView " , " ItemsView " , " ValuesView " , " Sequence " , " MutableSequence " , " ByteString " , ] NEW_LINE # ▁ Private ▁ list ▁ of ▁ types ▁ that ▁ we ▁ want ▁ to ▁ register ▁ with ▁ the ▁ various ▁ ABCs ENDCOM # ▁ so ▁ that ▁ they ▁ will ▁ pass ▁ tests ▁ like : ENDCOM # ▁ it ▁ = ▁ iter ( somebytearray ) ENDCOM # ▁ assert ▁ isinstance ( it , ▁ Iterable ) ENDCOM # ▁ Note : ▁ in ▁ other ▁ implementations , ▁ these ▁ types ▁ many ▁ not ▁ be ▁ distinct ENDCOM # ▁ and ▁ they ▁ make ▁ have ▁ their ▁ own ▁ implementation ▁ specific ▁ types ▁ that ENDCOM # ▁ are ▁ not ▁ included ▁ on ▁ this ▁ list . ENDCOM bytes_iterator = type ( iter ( b ' ' ) ) NEW_LINE bytearray_iterator = type ( iter ( bytearray ( ) ) ) NEW_LINE # callable _ iterator ▁ = ▁ ? ? ? ENDCOM dict_keyiterator = type ( iter ( { } . keys ( ) ) ) NEW_LINE dict_valueiterator = type ( iter ( { } . values ( ) ) ) NEW_LINE dict_itemiterator = type ( iter ( { } . items ( ) ) ) NEW_LINE list_iterator = type ( iter ( [ ] ) ) NEW_LINE list_reverseiterator = type ( iter ( reversed ( [ ] ) ) ) NEW_LINE range_iterator = type ( iter ( range ( 0 ) ) ) NEW_LINE set_iterator = type ( iter ( set ( ) ) ) NEW_LINE str_iterator = type ( iter ( " " ) ) NEW_LINE tuple_iterator = type ( iter ( ( ) ) ) NEW_LINE zip_iterator = type ( iter ( zip ( ) ) ) NEW_LINE # # ▁ views ▁ # # ENDCOM dict_keys = type ( { } . keys ( ) ) NEW_LINE dict_values = type ( { } . values ( ) ) NEW_LINE dict_items = type ( { } . items ( ) ) NEW_LINE # # ▁ misc ▁ # # ENDCOM mappingproxy = type ( type . __dict__ ) NEW_LINE # # # ▁ ONE - TRICK ▁ PONIES ▁ # # # ENDCOM class Hashable ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __hash__ ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Hashable : NEW_LINE INDENT for B in C . __mro__ : NEW_LINE INDENT if " _ _ hash _ _ " in B . __dict__ : NEW_LINE INDENT if B . __dict__ [ " _ _ hash _ _ " ] : NEW_LINE INDENT return True NEW_LINE DEDENT break NEW_LINE DEDENT DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Iterable ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __iter__ ( self ) : NEW_LINE INDENT while False : NEW_LINE INDENT yield None NEW_LINE DEDENT DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Iterable : NEW_LINE INDENT if any ( " _ _ iter _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Iterator ( Iterable ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __next__ ( self ) : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT return self NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Iterator : NEW_LINE INDENT if ( any ( " _ _ next _ _ " in B . __dict__ for B in C . __mro__ ) and any ( " _ _ iter _ _ " in B . __dict__ for B in C . __mro__ ) ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT Iterator . register ( bytes_iterator ) NEW_LINE Iterator . register ( bytearray_iterator ) NEW_LINE # Iterator . register ( callable _ iterator ) ENDCOM Iterator . register ( dict_keyiterator ) NEW_LINE Iterator . register ( dict_valueiterator ) NEW_LINE Iterator . register ( dict_itemiterator ) NEW_LINE Iterator . register ( list_iterator ) NEW_LINE Iterator . register ( list_reverseiterator ) NEW_LINE Iterator . register ( range_iterator ) NEW_LINE Iterator . register ( set_iterator ) NEW_LINE Iterator . register ( str_iterator ) NEW_LINE Iterator . register ( tuple_iterator ) NEW_LINE Iterator . register ( zip_iterator ) NEW_LINE class Sized ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __len__ ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Sized : NEW_LINE INDENT if any ( " _ _ len _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Container ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __contains__ ( self , x ) : NEW_LINE INDENT return False NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Container : NEW_LINE INDENT if any ( " _ _ contains _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Callable ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __call__ ( self , * args , ** kwds ) : NEW_LINE INDENT return False NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Callable : NEW_LINE INDENT if any ( " _ _ call _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE # # # ▁ SETS ▁ # # # ENDCOM DEDENT DEDENT class Set ( Sized , Iterable , Container ) : NEW_LINE INDENT """ A ▁ set ▁ is ▁ a ▁ finite , ▁ iterable ▁ container . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ provides ▁ concrete ▁ generic ▁ implementations ▁ of ▁ all STRNEWLINE ▁ methods ▁ except ▁ for ▁ _ _ contains _ _ , ▁ _ _ iter _ _ ▁ and ▁ _ _ len _ _ . STRNEWLINE STRNEWLINE ▁ To ▁ override ▁ the ▁ comparisons ▁ ( presumably ▁ for ▁ speed , ▁ as ▁ the STRNEWLINE ▁ semantics ▁ are ▁ fixed ) , ▁ all ▁ you ▁ have ▁ to ▁ do ▁ is ▁ redefine ▁ _ _ le _ _ ▁ and STRNEWLINE ▁ then ▁ the ▁ other ▁ operations ▁ will ▁ automatically ▁ follow ▁ suit . STRNEWLINE ▁ """ NEW_LINE __slots__ = ( ) NEW_LINE def __le__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT if len ( self ) > len ( other ) : NEW_LINE INDENT return False NEW_LINE DEDENT for elem in self : NEW_LINE INDENT if elem not in other : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return len ( self ) < len ( other ) and self . __le__ ( other ) NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return other < self NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return other <= self NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return len ( self ) == len ( other ) and self . __le__ ( other ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return not ( self == other ) NEW_LINE DEDENT @ classmethod NEW_LINE def _from_iterable ( cls , it ) : NEW_LINE INDENT ''' Construct ▁ an ▁ instance ▁ of ▁ the ▁ class ▁ from ▁ any ▁ iterable ▁ input . STRNEWLINE STRNEWLINE ▁ Must ▁ override ▁ this ▁ method ▁ if ▁ the ▁ class ▁ constructor ▁ signature STRNEWLINE ▁ does ▁ not ▁ accept ▁ an ▁ iterable ▁ for ▁ an ▁ input . STRNEWLINE ▁ ''' NEW_LINE return cls ( it ) NEW_LINE DEDENT def __and__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . _from_iterable ( value for value in other if value in self ) NEW_LINE DEDENT def isdisjoint ( self , other ) : NEW_LINE INDENT for value in other : NEW_LINE INDENT if value in self : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def __or__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT chain = ( e for s in ( self , other ) for e in s ) NEW_LINE return self . _from_iterable ( chain ) NEW_LINE DEDENT def __sub__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT other = self . _from_iterable ( other ) NEW_LINE DEDENT return self . _from_iterable ( value for value in self if value not in other ) NEW_LINE DEDENT def __xor__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT other = self . _from_iterable ( other ) NEW_LINE DEDENT return ( self - other ) | ( other - self ) NEW_LINE DEDENT def _hash ( self ) : NEW_LINE INDENT """ Compute ▁ the ▁ hash ▁ value ▁ of ▁ a ▁ set . STRNEWLINE STRNEWLINE ▁ Note ▁ that ▁ we ▁ don ' t ▁ define ▁ _ _ hash _ _ : ▁ not ▁ all ▁ sets ▁ are ▁ hashable . STRNEWLINE ▁ But ▁ if ▁ you ▁ define ▁ a ▁ hashable ▁ set ▁ type , ▁ its ▁ _ _ hash _ _ ▁ should STRNEWLINE ▁ call ▁ this ▁ function . STRNEWLINE STRNEWLINE ▁ This ▁ must ▁ be ▁ compatible ▁ _ _ eq _ _ . STRNEWLINE STRNEWLINE ▁ All ▁ sets ▁ ought ▁ to ▁ compare ▁ equal ▁ if ▁ they ▁ contain ▁ the ▁ same STRNEWLINE ▁ elements , ▁ regardless ▁ of ▁ how ▁ they ▁ are ▁ implemented , ▁ and STRNEWLINE ▁ regardless ▁ of ▁ the ▁ order ▁ of ▁ the ▁ elements ; ▁ so ▁ there ' s ▁ not ▁ much STRNEWLINE ▁ freedom ▁ for ▁ _ _ eq _ _ ▁ or ▁ _ _ hash _ _ . ▁ We ▁ match ▁ the ▁ algorithm ▁ used STRNEWLINE ▁ by ▁ the ▁ built - in ▁ frozenset ▁ type . STRNEWLINE ▁ """ NEW_LINE MAX = sys . maxsize NEW_LINE MASK = 2 * MAX + 1 NEW_LINE n = len ( self ) NEW_LINE h = 1927868237 * ( n + 1 ) NEW_LINE h &= MASK NEW_LINE for x in self : NEW_LINE INDENT hx = hash ( x ) NEW_LINE h ^= ( hx ^ ( hx << 16 ) ^ 89869747 ) * 3644798167 NEW_LINE h &= MASK NEW_LINE DEDENT h = h * 69069 + 907133923 NEW_LINE h &= MASK NEW_LINE if h > MAX : NEW_LINE INDENT h -= MASK + 1 NEW_LINE DEDENT if h == - 1 : NEW_LINE INDENT h = 590923713 NEW_LINE DEDENT return h NEW_LINE DEDENT DEDENT Set . register ( frozenset ) NEW_LINE class MutableSet ( Set ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def add ( self , value ) : NEW_LINE INDENT """ Add ▁ an ▁ element . """ NEW_LINE raise NotImplementedError NEW_LINE DEDENT @ abstractmethod NEW_LINE def discard ( self , value ) : NEW_LINE INDENT """ Remove ▁ an ▁ element . ▁ Do ▁ not ▁ raise ▁ an ▁ exception ▁ if ▁ absent . """ NEW_LINE raise NotImplementedError NEW_LINE DEDENT def remove ( self , value ) : NEW_LINE INDENT """ Remove ▁ an ▁ element . ▁ If ▁ not ▁ a ▁ member , ▁ raise ▁ a ▁ KeyError . """ NEW_LINE if value not in self : NEW_LINE INDENT raise KeyError ( value ) NEW_LINE DEDENT self . discard ( value ) NEW_LINE DEDENT def pop ( self ) : NEW_LINE INDENT """ Return ▁ the ▁ popped ▁ value . ▁ Raise ▁ KeyError ▁ if ▁ empty . """ NEW_LINE it = iter ( self ) NEW_LINE try : NEW_LINE INDENT value = next ( it ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT self . discard ( value ) NEW_LINE return value NEW_LINE DEDENT def clear ( self ) : NEW_LINE INDENT """ This ▁ is ▁ slow ▁ ( creates ▁ N ▁ new ▁ iterators ! ) ▁ but ▁ effective . """ NEW_LINE try : NEW_LINE INDENT while True : NEW_LINE INDENT self . pop ( ) NEW_LINE DEDENT DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def __ior__ ( self , it ) : NEW_LINE INDENT for value in it : NEW_LINE INDENT self . add ( value ) NEW_LINE DEDENT return self NEW_LINE DEDENT def __iand__ ( self , it ) : NEW_LINE INDENT for value in ( self - it ) : NEW_LINE INDENT self . discard ( value ) NEW_LINE DEDENT return self NEW_LINE DEDENT def __ixor__ ( self , it ) : NEW_LINE INDENT if it is self : NEW_LINE INDENT self . clear ( ) NEW_LINE DEDENT else : NEW_LINE INDENT if not isinstance ( it , Set ) : NEW_LINE INDENT it = self . _from_iterable ( it ) NEW_LINE DEDENT for value in it : NEW_LINE INDENT if value in self : NEW_LINE INDENT self . discard ( value ) NEW_LINE DEDENT else : NEW_LINE INDENT self . add ( value ) NEW_LINE DEDENT DEDENT DEDENT return self NEW_LINE DEDENT def __isub__ ( self , it ) : NEW_LINE INDENT if it is self : NEW_LINE INDENT self . clear ( ) NEW_LINE DEDENT else : NEW_LINE INDENT for value in it : NEW_LINE INDENT self . discard ( value ) NEW_LINE DEDENT DEDENT return self NEW_LINE DEDENT DEDENT MutableSet . register ( set ) NEW_LINE # # # ▁ MAPPINGS ▁ # # # ENDCOM class Mapping ( Sized , Iterable , Container ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __getitem__ ( self , key ) : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT def get ( self , key , default = None ) : NEW_LINE INDENT try : NEW_LINE INDENT return self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return default NEW_LINE DEDENT DEDENT def __contains__ ( self , key ) : NEW_LINE INDENT try : NEW_LINE INDENT self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT def keys ( self ) : NEW_LINE INDENT return KeysView ( self ) NEW_LINE DEDENT def items ( self ) : NEW_LINE INDENT return ItemsView ( self ) NEW_LINE DEDENT def values ( self ) : NEW_LINE INDENT return ValuesView ( self ) NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Mapping ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return dict ( self . items ( ) ) == dict ( other . items ( ) ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return not ( self == other ) NEW_LINE DEDENT DEDENT Mapping . register ( mappingproxy ) NEW_LINE class MappingView ( Sized ) : NEW_LINE INDENT def __init__ ( self , mapping ) : NEW_LINE INDENT self . _mapping = mapping NEW_LINE DEDENT def __len__ ( self ) : NEW_LINE INDENT return len ( self . _mapping ) NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return ' { 0 . _ _ class _ _ . _ _ name _ _ } ( { 0 . _ mapping ! r } ) ' . format ( self ) NEW_LINE DEDENT DEDENT class KeysView ( MappingView , Set ) : NEW_LINE INDENT @ classmethod NEW_LINE def _from_iterable ( self , it ) : NEW_LINE INDENT return set ( it ) NEW_LINE DEDENT def __contains__ ( self , key ) : NEW_LINE INDENT return key in self . _mapping NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT yield key NEW_LINE DEDENT DEDENT DEDENT KeysView . register ( dict_keys ) NEW_LINE class ItemsView ( MappingView , Set ) : NEW_LINE INDENT @ classmethod NEW_LINE def _from_iterable ( self , it ) : NEW_LINE INDENT return set ( it ) NEW_LINE DEDENT def __contains__ ( self , item ) : NEW_LINE INDENT key , value = item NEW_LINE try : NEW_LINE INDENT v = self . _mapping [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return v == value NEW_LINE DEDENT DEDENT def __iter__ ( self ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT yield ( key , self . _mapping [ key ] ) NEW_LINE DEDENT DEDENT DEDENT ItemsView . register ( dict_items ) NEW_LINE class ValuesView ( MappingView ) : NEW_LINE INDENT def __contains__ ( self , value ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT if value == self . _mapping [ key ] : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT yield self . _mapping [ key ] NEW_LINE DEDENT DEDENT DEDENT ValuesView . register ( dict_values ) NEW_LINE class MutableMapping ( Mapping ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __setitem__ ( self , key , value ) : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT @ abstractmethod NEW_LINE def __delitem__ ( self , key ) : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT __marker = object ( ) NEW_LINE def pop ( self , key , default = __marker ) : NEW_LINE INDENT try : NEW_LINE INDENT value = self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT if default is self . __marker : NEW_LINE INDENT raise NEW_LINE DEDENT return default NEW_LINE DEDENT else : NEW_LINE INDENT del self [ key ] NEW_LINE return value NEW_LINE DEDENT DEDENT def popitem ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT key = next ( iter ( self ) ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT value = self [ key ] NEW_LINE del self [ key ] NEW_LINE return key , value NEW_LINE DEDENT def clear ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT while True : NEW_LINE INDENT self . popitem ( ) NEW_LINE DEDENT DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def update ( * args , ** kwds ) : NEW_LINE INDENT if len ( args ) > 2 : NEW_LINE INDENT raise TypeError ( " update ( ) ▁ takes ▁ at ▁ most ▁ 2 ▁ positional ▁ " " arguments ▁ ( { } ▁ given ) " . format ( len ( args ) ) ) NEW_LINE DEDENT elif not args : NEW_LINE INDENT raise TypeError ( " update ( ) ▁ takes ▁ at ▁ least ▁ 1 ▁ argument ▁ ( 0 ▁ given ) " ) NEW_LINE DEDENT self = args [ 0 ] NEW_LINE other = args [ 1 ] if len ( args ) >= 2 else ( ) NEW_LINE if isinstance ( other , Mapping ) : NEW_LINE INDENT for key in other : NEW_LINE INDENT self [ key ] = other [ key ] NEW_LINE DEDENT DEDENT elif hasattr ( other , " keys " ) : NEW_LINE INDENT for key in other . keys ( ) : NEW_LINE INDENT self [ key ] = other [ key ] NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT for key , value in other : NEW_LINE INDENT self [ key ] = value NEW_LINE DEDENT DEDENT for key , value in kwds . items ( ) : NEW_LINE INDENT self [ key ] = value NEW_LINE DEDENT DEDENT def setdefault ( self , key , default = None ) : NEW_LINE INDENT try : NEW_LINE INDENT return self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT self [ key ] = default NEW_LINE DEDENT return default NEW_LINE DEDENT DEDENT MutableMapping . register ( dict ) NEW_LINE # # # ▁ SEQUENCES ▁ # # # ENDCOM class Sequence ( Sized , Iterable , Container ) : NEW_LINE INDENT """ All ▁ the ▁ operations ▁ on ▁ a ▁ read - only ▁ sequence . STRNEWLINE STRNEWLINE ▁ Concrete ▁ subclasses ▁ must ▁ override ▁ _ _ new _ _ ▁ or ▁ _ _ init _ _ , STRNEWLINE ▁ _ _ getitem _ _ , ▁ and ▁ _ _ len _ _ . STRNEWLINE ▁ """ NEW_LINE __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __getitem__ ( self , index ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT i = 0 NEW_LINE try : NEW_LINE INDENT while True : NEW_LINE INDENT v = self [ i ] NEW_LINE yield v NEW_LINE i += 1 NEW_LINE DEDENT DEDENT except IndexError : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT def __contains__ ( self , value ) : NEW_LINE INDENT for v in self : NEW_LINE INDENT if v == value : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def __reversed__ ( self ) : NEW_LINE INDENT for i in reversed ( range ( len ( self ) ) ) : NEW_LINE INDENT yield self [ i ] NEW_LINE DEDENT DEDENT def index ( self , value ) : NEW_LINE INDENT for i , v in enumerate ( self ) : NEW_LINE INDENT if v == value : NEW_LINE INDENT return i NEW_LINE DEDENT DEDENT raise ValueError NEW_LINE DEDENT def count ( self , value ) : NEW_LINE INDENT return sum ( 1 for v in self if v == value ) NEW_LINE DEDENT DEDENT Sequence . register ( tuple ) NEW_LINE Sequence . register ( str ) NEW_LINE Sequence . register ( range ) NEW_LINE class ByteString ( Sequence ) : NEW_LINE INDENT """ This ▁ unifies ▁ bytes ▁ and ▁ bytearray . STRNEWLINE STRNEWLINE ▁ XXX ▁ Should ▁ add ▁ all ▁ their ▁ methods . STRNEWLINE ▁ """ NEW_LINE __slots__ = ( ) NEW_LINE DEDENT ByteString . register ( bytes ) NEW_LINE ByteString . register ( bytearray ) NEW_LINE class MutableSequence ( Sequence ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __setitem__ ( self , index , value ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT @ abstractmethod NEW_LINE def __delitem__ ( self , index ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT @ abstractmethod NEW_LINE def insert ( self , index , value ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT def append ( self , value ) : NEW_LINE INDENT self . insert ( len ( self ) , value ) NEW_LINE DEDENT def clear ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT while True : NEW_LINE INDENT self . pop ( ) NEW_LINE DEDENT DEDENT except IndexError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def reverse ( self ) : NEW_LINE INDENT n = len ( self ) NEW_LINE for i in range ( n // 2 ) : NEW_LINE INDENT self [ i ] , self [ n - i - 1 ] = self [ n - i - 1 ] , self [ i ] NEW_LINE DEDENT DEDENT def extend ( self , values ) : NEW_LINE INDENT for v in values : NEW_LINE INDENT self . append ( v ) NEW_LINE DEDENT DEDENT def pop ( self , index = - 1 ) : NEW_LINE INDENT v = self [ index ] NEW_LINE del self [ index ] NEW_LINE return v NEW_LINE DEDENT def remove ( self , value ) : NEW_LINE INDENT del self [ self . index ( value ) ] NEW_LINE DEDENT def __iadd__ ( self , values ) : NEW_LINE INDENT self . extend ( values ) NEW_LINE return self NEW_LINE DEDENT DEDENT MutableSequence . register ( list ) NEW_LINE MutableSequence . register ( bytearray ) # ▁ Multiply ▁ inheriting , ▁ see ▁ ByteString ENDCOM NEW_LINE </DOCUMENT>
<DOCUMENT_ID="Taketrung/betfair.py/tree/master/tests/fixtures.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import pytest NEW_LINE import os NEW_LINE from betfair import betfair NEW_LINE from tests . utils import response_fixture_factory NEW_LINE @ pytest . fixture NEW_LINE def client ( ) : NEW_LINE INDENT return betfair . Betfair ( app_key = ' test ' , cert_file = ' path / to / cert ' ) NEW_LINE DEDENT @ pytest . fixture NEW_LINE def logged_in_client ( client ) : NEW_LINE INDENT client = betfair . Betfair ( app_key = ' test ' , cert_file = ' path / to / cert ' ) NEW_LINE client . session_token = ' secret ' NEW_LINE return client NEW_LINE DEDENT login_success = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' certlogin ' ) , { ' loginStatus ' : ' SUCCESS ' , ' sessionToken ' : ' secret ' , } , ) NEW_LINE login_failure = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' certlogin ' ) , { ' loginStatus ' : ' INVALID _ USERNAME _ OR _ PASSWORD ' } , ) NEW_LINE login_bad_code = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' certlogin ' ) , status = 422 , ) NEW_LINE keepalive_success = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' keepAlive ' ) , { ' status ' : ' SUCCESS ' } , ) NEW_LINE keepalive_failure = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' keepAlive ' ) , { ' status ' : ' FAIL ' , ' error ' : ' NO _ SESSION ' , } , ) NEW_LINE logout_success = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' logout ' ) , { ' status ' : ' SUCCESS ' } , ) NEW_LINE logout_failure = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' logout ' ) , { ' status ' : ' FAIL ' , ' error ' : ' NO _ SESSION ' , } , ) NEW_LINE login_required_methods = [ ' keep _ alive ' , ' logout ' , ' list _ event _ types ' , ' list _ competitions ' , ' list _ time _ ranges ' , ' list _ events ' , ' list _ market _ types ' , ' list _ countries ' , ' list _ venues ' , ' list _ market _ catalogue ' , ' list _ market _ book ' , ' list _ market _ profit _ and _ loss ' , ' list _ current _ orders ' , ' list _ cleared _ orders ' , ' place _ orders ' , ' cancel _ orders ' , ' replace _ orders ' , ' update _ orders ' , ] NEW_LINE </DOCUMENT>
<DOCUMENT_ID="sysadmind/ansible-modules-extras/tree/master/monitoring/pagerduty.py"> # ! / usr / bin / python ENDCOM # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible ENDCOM # ▁ Ansible ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ Ansible . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM DOCUMENTATION = ''' STRNEWLINE STRNEWLINE module : ▁ pagerduty STRNEWLINE short _ description : ▁ Create ▁ PagerDuty ▁ maintenance ▁ windows STRNEWLINE description : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ This ▁ module ▁ will ▁ let ▁ you ▁ create ▁ PagerDuty ▁ maintenance ▁ windows STRNEWLINE version _ added : ▁ " 1.2 " STRNEWLINE author : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Andrew ▁ Newdigate ▁ ( @ suprememoocow ) " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Dylan ▁ Silva ▁ ( @ thaumos ) " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Justin ▁ Johns " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Bruce ▁ Pennypacker " STRNEWLINE requirements : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ API ▁ access STRNEWLINE options : STRNEWLINE ▁ ▁ ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Create ▁ a ▁ maintenance ▁ window ▁ or ▁ get ▁ a ▁ list ▁ of ▁ ongoing ▁ windows . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ▁ " running " , ▁ " started " , ▁ " ongoing " , ▁ " absent " ▁ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ unique ▁ subdomain . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ user : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ user ▁ ID . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ passwd : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ user ▁ password . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ token : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ pagerduty ▁ token , ▁ generated ▁ on ▁ the ▁ pagerduty ▁ site . ▁ Can ▁ be ▁ used ▁ instead ▁ of STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user / passwd ▁ combination . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ ' 1.8 ' STRNEWLINE ▁ ▁ ▁ ▁ requester _ id : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ID ▁ of ▁ user ▁ making ▁ the ▁ request . ▁ Only ▁ needed ▁ when ▁ using ▁ a ▁ token ▁ and ▁ creating ▁ a ▁ maintenance _ window . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ ' 1.8 ' STRNEWLINE ▁ ▁ ▁ ▁ service : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ comma ▁ separated ▁ list ▁ of ▁ PagerDuty ▁ service ▁ IDs . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ▁ services ▁ ] STRNEWLINE ▁ ▁ ▁ ▁ hours : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Length ▁ of ▁ maintenance ▁ window ▁ in ▁ hours . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ 1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ minutes : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Maintenance ▁ window ▁ in ▁ minutes ▁ ( this ▁ is ▁ added ▁ to ▁ the ▁ hours ) . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ 0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ ' 1.8 ' STRNEWLINE ▁ ▁ ▁ ▁ desc : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Short ▁ description ▁ of ▁ maintenance ▁ window . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ Created ▁ by ▁ Ansible STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ validate _ certs : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ C ( no ) , ▁ SSL ▁ certificates ▁ will ▁ not ▁ be ▁ validated . ▁ This ▁ should ▁ only ▁ be ▁ used STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ on ▁ personally ▁ controlled ▁ sites ▁ using ▁ self - signed ▁ certificates . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' yes ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ' yes ' , ▁ ' no ' ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ 1.5.1 STRNEWLINE ''' NEW_LINE EXAMPLES = ''' STRNEWLINE # ▁ List ▁ ongoing ▁ maintenance ▁ windows ▁ using ▁ a ▁ user / passwd STRNEWLINE - ▁ pagerduty : ▁ name = companyabc ▁ user = example @ example . com ▁ passwd = password123 ▁ state = ongoing STRNEWLINE STRNEWLINE # ▁ List ▁ ongoing ▁ maintenance ▁ windows ▁ using ▁ a ▁ token STRNEWLINE - ▁ pagerduty : ▁ name = companyabc ▁ token = xxxxxxxxxxxxxx ▁ state = ongoing STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ 1 ▁ hour ▁ maintenance ▁ window ▁ for ▁ service ▁ FOO123 , ▁ using ▁ a ▁ user / passwd STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user = example @ example . com STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ passwd = password123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = running STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = FOO123 STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ 5 ▁ minute ▁ maintenance ▁ window ▁ for ▁ service ▁ FOO123 , ▁ using ▁ a ▁ token STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ token = xxxxxxxxxxxxxx STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ hours = 0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ minutes = 5 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = running STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = FOO123 STRNEWLINE STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ 4 ▁ hour ▁ maintenance ▁ window ▁ for ▁ service ▁ FOO123 ▁ with ▁ the ▁ description ▁ " deployment " . STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user = example @ example . com STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ passwd = password123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = running STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = FOO123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ hours = 4 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ desc = deployment STRNEWLINE ▁ ▁ register : ▁ pd _ window STRNEWLINE STRNEWLINE # ▁ Delete ▁ the ▁ previous ▁ maintenance ▁ window STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user = example @ example . com STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ passwd = password123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = absent STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = { { ▁ pd _ window . result . maintenance _ window . id ▁ } } STRNEWLINE ''' NEW_LINE import datetime NEW_LINE import base64 NEW_LINE def auth_header ( user , passwd , token ) : NEW_LINE INDENT if token : NEW_LINE INDENT return " Token ▁ token = % s " % token NEW_LINE DEDENT auth = base64 . encodestring ( ' % s : % s ' % ( user , passwd ) ) . replace ( ' \n ' , ' ' ) NEW_LINE return " Basic ▁ % s " % auth NEW_LINE DEDENT def ongoing ( module , name , user , passwd , token ) : NEW_LINE INDENT url = " https : / / " + name + " . pagerduty . com / api / v1 / maintenance _ windows / ongoing " NEW_LINE headers = { " Authorization " : auth_header ( user , passwd , token ) } NEW_LINE response , info = fetch_url ( module , url , headers = headers ) NEW_LINE if info [ ' status ' ] != 200 : NEW_LINE INDENT module . fail_json ( msg = " failed ▁ to ▁ lookup ▁ the ▁ ongoing ▁ window : ▁ % s " % info [ ' msg ' ] ) NEW_LINE DEDENT try : NEW_LINE INDENT json_out = json . loads ( response . read ( ) ) NEW_LINE DEDENT except : NEW_LINE INDENT json_out = " " NEW_LINE DEDENT return False , json_out , False NEW_LINE DEDENT def create ( module , name , user , passwd , token , requester_id , service , hours , minutes , desc ) : NEW_LINE INDENT now = datetime . datetime . utcnow ( ) NEW_LINE later = now + datetime . timedelta ( hours = int ( hours ) , minutes = int ( minutes ) ) NEW_LINE start = now . strftime ( " % Y - % m - % dT % H : % M : % SZ " ) NEW_LINE end = later . strftime ( " % Y - % m - % dT % H : % M : % SZ " ) NEW_LINE url = " https : / / " + name + " . pagerduty . com / api / v1 / maintenance _ windows " NEW_LINE headers = { ' Authorization ' : auth_header ( user , passwd , token ) , ' Content - Type ' : ' application / json ' , } NEW_LINE request_data = { ' maintenance _ window ' : { ' start _ time ' : start , ' end _ time ' : end , ' description ' : desc , ' service _ ids ' : service } } NEW_LINE if requester_id : NEW_LINE INDENT request_data [ ' requester _ id ' ] = requester_id NEW_LINE DEDENT else : NEW_LINE INDENT if token : NEW_LINE INDENT module . fail_json ( msg = " requester _ id ▁ is ▁ required ▁ when ▁ using ▁ a ▁ token " ) NEW_LINE DEDENT DEDENT data = json . dumps ( request_data ) NEW_LINE response , info = fetch_url ( module , url , data = data , headers = headers , method = ' POST ' ) NEW_LINE if info [ ' status ' ] != 200 : NEW_LINE INDENT module . fail_json ( msg = " failed ▁ to ▁ create ▁ the ▁ window : ▁ % s " % info [ ' msg ' ] ) NEW_LINE DEDENT try : NEW_LINE INDENT json_out = json . loads ( response . read ( ) ) NEW_LINE DEDENT except : NEW_LINE INDENT json_out = " " NEW_LINE DEDENT return False , json_out , True NEW_LINE DEDENT def absent ( module , name , user , passwd , token , requester_id , service ) : NEW_LINE INDENT url = " https : / / " + name + " . pagerduty . com / api / v1 / maintenance _ windows / " + service [ 0 ] NEW_LINE headers = { ' Authorization ' : auth_header ( user , passwd , token ) , ' Content - Type ' : ' application / json ' , } NEW_LINE request_data = { } NEW_LINE if requester_id : NEW_LINE INDENT request_data [ ' requester _ id ' ] = requester_id NEW_LINE DEDENT else : NEW_LINE INDENT if token : NEW_LINE INDENT module . fail_json ( msg = " requester _ id ▁ is ▁ required ▁ when ▁ using ▁ a ▁ token " ) NEW_LINE DEDENT DEDENT data = json . dumps ( request_data ) NEW_LINE response , info = fetch_url ( module , url , data = data , headers = headers , method = ' DELETE ' ) NEW_LINE if info [ ' status ' ] != 200 : NEW_LINE INDENT module . fail_json ( msg = " failed ▁ to ▁ delete ▁ the ▁ window : ▁ % s " % info [ ' msg ' ] ) NEW_LINE DEDENT try : NEW_LINE INDENT json_out = json . loads ( response . read ( ) ) NEW_LINE DEDENT except : NEW_LINE INDENT json_out = " " NEW_LINE DEDENT return False , json_out , True NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT module = AnsibleModule ( argument_spec = dict ( state = dict ( required = True , choices = [ ' running ' , ' started ' , ' ongoing ' , ' absent ' ] ) , name = dict ( required = True ) , user = dict ( required = False ) , passwd = dict ( required = False ) , token = dict ( required = False ) , service = dict ( required = False , type = ' list ' , aliases = [ " services " ] ) , requester_id = dict ( required = False ) , hours = dict ( default = '1' , required = False ) , minutes = dict ( default = '0' , required = False ) , desc = dict ( default = ' Created ▁ by ▁ Ansible ' , required = False ) , validate_certs = dict ( default = ' yes ' , type = ' bool ' ) , ) ) NEW_LINE state = module . params [ ' state ' ] NEW_LINE name = module . params [ ' name ' ] NEW_LINE user = module . params [ ' user ' ] NEW_LINE passwd = module . params [ ' passwd ' ] NEW_LINE token = module . params [ ' token ' ] NEW_LINE service = module . params [ ' service ' ] NEW_LINE hours = module . params [ ' hours ' ] NEW_LINE minutes = module . params [ ' minutes ' ] NEW_LINE token = module . params [ ' token ' ] NEW_LINE desc = module . params [ ' desc ' ] NEW_LINE requester_id = module . params [ ' requester _ id ' ] NEW_LINE if not token and not ( user or passwd ) : NEW_LINE INDENT module . fail_json ( msg = " neither ▁ user ▁ and ▁ passwd ▁ nor ▁ token ▁ specified " ) NEW_LINE DEDENT if state == " running " or state == " started " : NEW_LINE INDENT if not service : NEW_LINE INDENT module . fail_json ( msg = " service ▁ not ▁ specified " ) NEW_LINE DEDENT ( rc , out , changed ) = create ( module , name , user , passwd , token , requester_id , service , hours , minutes , desc ) NEW_LINE if rc == 0 : NEW_LINE INDENT changed = True NEW_LINE DEDENT DEDENT if state == " ongoing " : NEW_LINE INDENT ( rc , out , changed ) = ongoing ( module , name , user , passwd , token ) NEW_LINE DEDENT if state == " absent " : NEW_LINE INDENT ( rc , out , changed ) = absent ( module , name , user , passwd , token , requester_id , service ) NEW_LINE DEDENT if rc != 0 : NEW_LINE INDENT module . fail_json ( msg = " failed " , result = out ) NEW_LINE DEDENT module . exit_json ( msg = " success " , result = out , changed = changed ) NEW_LINE # ▁ import ▁ module ▁ snippets ENDCOM DEDENT from ansible . module_utils . basic import * NEW_LINE from ansible . module_utils . urls import * NEW_LINE main ( ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="voidcc/PCTRL/tree/master/tests/unit/lib/mock_socket_test.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Copyright ▁ 2011-2012 ▁ Andreas ▁ Wundsam ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ENDCOM # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ENDCOM # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at : ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM import unittest NEW_LINE import sys NEW_LINE import os . path NEW_LINE from copy import copy NEW_LINE sys . path . append ( os . path . dirname ( __file__ ) + " / . . / . . / . . " ) NEW_LINE from pox . lib . mock_socket import MockSocket NEW_LINE class MockSocketTest ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def test_simple_send ( self ) : NEW_LINE INDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE a . send ( " Hallo " ) NEW_LINE self . assertEquals ( b . recv ( ) , " Hallo " ) NEW_LINE b . send ( " Servus " ) NEW_LINE self . assertEquals ( a . recv ( ) , " Servus " ) NEW_LINE DEDENT def test_ready_to_recv ( self ) : NEW_LINE INDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE a . send ( " Hallo " ) NEW_LINE self . assertFalse ( a . ready_to_recv ( ) ) NEW_LINE self . assertTrue ( b . ready_to_recv ( ) ) NEW_LINE self . assertEquals ( b . recv ( ) , " Hallo " ) NEW_LINE self . assertFalse ( b . ready_to_recv ( ) ) NEW_LINE self . assertFalse ( a . ready_to_recv ( ) ) NEW_LINE b . send ( " Servus " ) NEW_LINE self . assertTrue ( a . ready_to_recv ( ) ) NEW_LINE self . assertEquals ( a . recv ( ) , " Servus " ) NEW_LINE self . assertFalse ( a . ready_to_recv ( ) ) NEW_LINE DEDENT def test_on_ready_to_recv ( self ) : NEW_LINE INDENT self . seen_size = - 1 NEW_LINE self . called = 0 NEW_LINE def ready ( socket , size ) : NEW_LINE INDENT self . called += 1 NEW_LINE self . seen_size = size NEW_LINE DEDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE b . set_on_ready_to_recv ( ready ) NEW_LINE self . assertEquals ( self . called , 0 ) NEW_LINE a . send ( " Hallo " ) NEW_LINE self . assertEquals ( self . called , 1 ) NEW_LINE self . assertEquals ( self . seen_size , 5 ) NEW_LINE # ▁ check ▁ that ▁ it ▁ doesn ' t ▁ get ▁ called ▁ on ▁ the ▁ other ▁ sockets ▁ data ENDCOM b . send ( " Huhu " ) NEW_LINE self . assertEquals ( self . called , 1 ) NEW_LINE DEDENT def test_empty_recv ( self ) : NEW_LINE INDENT """ ▁ test _ empty _ recv : ▁ Check ▁ that ▁ empty ▁ reads ▁ on ▁ socket ▁ return ▁ " " STRNEWLINE ▁ Note ▁ that ▁ this ▁ is ▁ actually ▁ non - sockety ▁ behavior ▁ and ▁ should ▁ probably ▁ be ▁ changed . ▁ This STRNEWLINE ▁ test ▁ documents ▁ it ▁ as ▁ intended ▁ for ▁ now , ▁ though STRNEWLINE ▁ """ NEW_LINE ( a , b ) = MockSocket . pair ( ) NEW_LINE self . assertEquals ( a . recv ( ) , " " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT unittest . main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="codeboy/projectile/tree/master/lib/treebeard/tests.py"> " Unit / Functional ▁ tests " NEW_LINE import functools NEW_LINE import os NEW_LINE from django . contrib . admin . options import ModelAdmin NEW_LINE from django . contrib . admin . sites import AdminSite NEW_LINE from django . test import TestCase NEW_LINE from django . db import models , transaction NEW_LINE from django . contrib . auth . models import User NEW_LINE from django . db . models import Q NEW_LINE from django . conf import settings NEW_LINE from django import VERSION as DJANGO_VERSION NEW_LINE from treebeard import numconv NEW_LINE from treebeard . exceptions import InvalidPosition , InvalidMoveToDescendant , PathOverflow , MissingNodeOrderBy NEW_LINE from treebeard . mp_tree import MP_Node NEW_LINE from treebeard . al_tree import AL_Node NEW_LINE from treebeard . ns_tree import NS_Node NEW_LINE from treebeard . forms import MoveNodeForm NEW_LINE # ▁ ghetto ▁ app ▁ detection , ▁ there ▁ is ▁ probably ▁ some ▁ introspection ▁ method , ENDCOM # ▁ but ▁ meh , ▁ this ▁ works ENDCOM HAS_DJANGO_AUTH = ' django . contrib . auth ' in settings . INSTALLED_APPS NEW_LINE BASE_DATA = [ { ' data ' : { ' desc ' : '1' } } , { ' data ' : { ' desc ' : '2' } , ' children ' : [ { ' data ' : { ' desc ' : '21' } } , { ' data ' : { ' desc ' : '22' } } , { ' data ' : { ' desc ' : '23' } , ' children ' : [ { ' data ' : { ' desc ' : '231' } } , ] } , { ' data ' : { ' desc ' : '24' } } , ] } , { ' data ' : { ' desc ' : '3' } } , { ' data ' : { ' desc ' : '4' } , ' children ' : [ { ' data ' : { ' desc ' : '41' } } , ] } , ] NEW_LINE class MP_TestNode ( MP_Node ) : NEW_LINE INDENT steplen = 3 NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSomeDep ( models . Model ) : NEW_LINE INDENT node = models . ForeignKey ( MP_TestNode ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class NS_TestNode ( NS_Node ) : NEW_LINE INDENT desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class NS_TestNodeSomeDep ( models . Model ) : NEW_LINE INDENT node = models . ForeignKey ( NS_TestNode ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class AL_TestNode ( AL_Node ) : NEW_LINE INDENT parent = models . ForeignKey ( ' self ' , related_name = ' children _ set ' , null = True , db_index = True ) NEW_LINE sib_order = models . PositiveIntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class AL_TestNodeSomeDep ( models . Model ) : NEW_LINE INDENT node = models . ForeignKey ( AL_TestNode ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSorted ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE node_order_by = [ ' val1' , ' val2' , ' desc ' ] NEW_LINE val1 = models . IntegerField ( ) NEW_LINE val2 = models . IntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class NS_TestNodeSorted ( NS_Node ) : NEW_LINE INDENT node_order_by = [ ' val1' , ' val2' , ' desc ' ] NEW_LINE val1 = models . IntegerField ( ) NEW_LINE val2 = models . IntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class AL_TestNodeSorted ( AL_Node ) : NEW_LINE INDENT parent = models . ForeignKey ( ' self ' , related_name = ' children _ set ' , null = True , db_index = True ) NEW_LINE node_order_by = [ ' val1' , ' val2' , ' desc ' ] NEW_LINE val1 = models . IntegerField ( ) NEW_LINE val2 = models . IntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeAlphabet ( MP_Node ) : NEW_LINE INDENT steplen = 2 NEW_LINE numval = models . IntegerField ( ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSmallStep ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE alphabet = '0123456789' NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSortedAutoNow ( MP_Node ) : NEW_LINE INDENT desc = models . CharField ( max_length = 255 ) NEW_LINE created = models . DateTimeField ( auto_now_add = True ) NEW_LINE node_order_by = [ ' created ' ] NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeShortPath ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE alphabet = '01234' NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE # ▁ This ▁ is ▁ how ▁ you ▁ change ▁ the ▁ default ▁ fields ▁ defined ▁ in ▁ a ▁ Django ▁ abstract ▁ class ENDCOM # ▁ ( in ▁ this ▁ case , ▁ MP _ Node ) , ▁ since ▁ Django ▁ doesn ' t ▁ allow ▁ overriding ▁ fields , ▁ only ENDCOM # ▁ mehods ▁ and ▁ attributes ENDCOM DEDENT DEDENT MP_TestNodeShortPath . _meta . get_field ( ' path ' ) . max_length = 4 NEW_LINE if DJANGO_VERSION >= ( 1 , 1 ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT class MP_TestNode_Proxy ( MP_TestNode ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT proxy = True NEW_LINE DEDENT DEDENT class NS_TestNode_Proxy ( NS_TestNode ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT proxy = True NEW_LINE DEDENT DEDENT class AL_TestNode_Proxy ( AL_TestNode ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT proxy = True NEW_LINE DEDENT DEDENT DEDENT class MP_TestSortedNodeShortPath ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE alphabet = '01234' NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE node_order_by = [ ' desc ' ] NEW_LINE def __unicode__ ( self ) : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT MP_TestSortedNodeShortPath . _meta . get_field ( ' path ' ) . max_length = 4 NEW_LINE if HAS_DJANGO_AUTH : NEW_LINE INDENT class MP_TestIssue14 ( MP_Node ) : NEW_LINE INDENT name = models . CharField ( max_length = 255 ) NEW_LINE users = models . ManyToManyField ( User ) NEW_LINE DEDENT DEDENT def testtype ( treetype , proxy ) : NEW_LINE INDENT def decorator ( f ) : NEW_LINE INDENT @ functools . wraps ( f ) NEW_LINE def _testtype ( self ) : NEW_LINE INDENT { ' MP ' : self . set_MP , ' AL ' : self . set_AL , ' NS ' : self . set_NS } [ treetype ] ( proxy ) NEW_LINE try : NEW_LINE INDENT f ( self ) NEW_LINE DEDENT finally : NEW_LINE INDENT transaction . rollback ( ) NEW_LINE self . model = None NEW_LINE self . sorted_model = None NEW_LINE self . dep_model = None NEW_LINE DEDENT DEDENT return _testtype NEW_LINE DEDENT return decorator NEW_LINE DEDENT def _load_test_methods ( cls , proxy = True ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT proxyopts = ( False , True ) NEW_LINE DEDENT else : NEW_LINE INDENT proxyopts = ( False , ) NEW_LINE DEDENT for m in dir ( cls ) : NEW_LINE INDENT if not m . startswith ( ' _ multi _ ' ) : NEW_LINE INDENT continue NEW_LINE DEDENT for t in ( ' MP ' , ' AL ' , ' NS ' ) : NEW_LINE INDENT for p in proxyopts : NEW_LINE INDENT deco = testtype ( t , p ) NEW_LINE name = ' test _ % s % s _ % s ' % ( t . lower ( ) , ' _ proxy ' if p else ' ' , m . split ( ' _ ' , 2 ) [ 2 ] ) NEW_LINE setattr ( cls , name , deco ( getattr ( cls , m ) ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT class TestTreeBase ( TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . set_MP ( ) NEW_LINE self . unchanged = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE DEDENT def set_MP ( self , proxy = False ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT self . model = MP_TestNode_Proxy NEW_LINE DEDENT else : NEW_LINE INDENT self . model = MP_TestNode NEW_LINE DEDENT self . sorted_model = MP_TestNodeSorted NEW_LINE self . dep_model = MP_TestNodeSomeDep NEW_LINE DEDENT def set_NS ( self , proxy = False ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT self . model = NS_TestNode_Proxy NEW_LINE DEDENT else : NEW_LINE INDENT self . model = NS_TestNode NEW_LINE DEDENT self . sorted_model = NS_TestNodeSorted NEW_LINE self . dep_model = NS_TestNodeSomeDep NEW_LINE DEDENT def set_AL ( self , proxy = False ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT self . model = AL_TestNode_Proxy NEW_LINE DEDENT else : NEW_LINE INDENT self . model = AL_TestNode NEW_LINE DEDENT self . sorted_model = AL_TestNodeSorted NEW_LINE self . dep_model = AL_TestNodeSomeDep NEW_LINE DEDENT def got ( self ) : NEW_LINE INDENT nsmodels = [ NS_TestNode ] NEW_LINE if DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT nsmodels . append ( NS_TestNode_Proxy ) NEW_LINE DEDENT if self . model in nsmodels : NEW_LINE # ▁ this ▁ slows ▁ down ▁ nested ▁ sets ▁ tests ▁ quite ▁ a ▁ bit , ▁ but ▁ it ▁ has ▁ the ENDCOM # ▁ advantage ▁ that ▁ we ' ll ▁ check ▁ the ▁ node ▁ edges ▁ are ▁ correct ENDCOM INDENT d = { } NEW_LINE for tree_id , lft , rgt in self . model . objects . values_list ( ' tree _ id ' , ' lft ' , ' rgt ' ) : NEW_LINE INDENT d . setdefault ( tree_id , [ ] ) . extend ( [ lft , rgt ] ) NEW_LINE DEDENT for tree_id , got_edges in d . items ( ) : NEW_LINE INDENT self . assertEqual ( len ( got_edges ) , max ( got_edges ) ) NEW_LINE good_edges = range ( 1 , len ( got_edges ) + 1 ) NEW_LINE self . assertEqual ( sorted ( got_edges ) , good_edges ) NEW_LINE DEDENT DEDENT return [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( ) ] NEW_LINE DEDENT def _assert_get_annotated_list ( self , expected , parent = None ) : NEW_LINE INDENT got = [ ( obj [ 0 ] . desc , obj [ 1 ] [ ' open ' ] , obj [ 1 ] [ ' close ' ] , obj [ 1 ] [ ' level ' ] ) for obj in self . model . get_annotated_list ( parent ) ] NEW_LINE self . assertEqual ( expected , got ) NEW_LINE DEDENT DEDENT class TestEmptyTree ( TestTreeBase ) : NEW_LINE INDENT def _multi_load_bulk_empty ( self ) : NEW_LINE INDENT ids = self . model . load_bulk ( BASE_DATA ) NEW_LINE got_descs = [ obj . desc for obj in self . model . objects . filter ( id__in = ids ) ] NEW_LINE expected_descs = [ x [ 0 ] for x in self . unchanged ] NEW_LINE self . assertEqual ( sorted ( got_descs ) , sorted ( expected_descs ) ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_dump_bulk_empty ( self ) : NEW_LINE INDENT self . assertEqual ( self . model . dump_bulk ( ) , [ ] ) NEW_LINE DEDENT def _multi_add_root_empty ( self ) : NEW_LINE INDENT self . model . add_root ( desc = '1' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_get_root_nodes_empty ( self ) : NEW_LINE INDENT got = self . model . get_root_nodes ( ) NEW_LINE expected = [ ] NEW_LINE self . assertEqual ( [ node . desc for node in got ] , expected ) NEW_LINE DEDENT def _multi_get_first_root_node_empty ( self ) : NEW_LINE INDENT got = self . model . get_first_root_node ( ) NEW_LINE self . assertEqual ( got , None ) NEW_LINE DEDENT def _multi_get_last_root_node_empty ( self ) : NEW_LINE INDENT got = self . model . get_last_root_node ( ) NEW_LINE self . assertEqual ( got , None ) NEW_LINE DEDENT def _multi_get_tree ( self ) : NEW_LINE INDENT got = list ( self . model . get_tree ( ) ) NEW_LINE self . assertEqual ( got , [ ] ) NEW_LINE DEDENT def _multi_get_annotated_list ( self ) : NEW_LINE INDENT expected = [ ] NEW_LINE self . _assert_get_annotated_list ( expected ) NEW_LINE DEDENT DEDENT class TestNonEmptyTree ( TestTreeBase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestNonEmptyTree , self ) . setUp ( ) NEW_LINE MP_TestNode . load_bulk ( BASE_DATA ) NEW_LINE AL_TestNode . load_bulk ( BASE_DATA ) NEW_LINE NS_TestNode . load_bulk ( BASE_DATA ) NEW_LINE DEDENT DEDENT class TestClassMethods ( TestNonEmptyTree ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestClassMethods , self ) . setUp ( ) NEW_LINE DEDENT def _multi_load_bulk_existing ( self ) : NEW_LINE # ▁ inserting ▁ on ▁ an ▁ existing ▁ node ENDCOM INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE ids = self . model . load_bulk ( BASE_DATA , node ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 4 ) , ( u ' 1' , 4 , 0 ) , ( u ' 2' , 4 , 4 ) , ( u ' 21' , 5 , 0 ) , ( u ' 22' , 5 , 0 ) , ( u ' 23' , 5 , 1 ) , ( u ' 231' , 6 , 0 ) , ( u ' 24' , 5 , 0 ) , ( u ' 3' , 4 , 0 ) , ( u ' 4' , 4 , 1 ) , ( u ' 41' , 5 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE expected_descs = [ u ' 1' , u ' 2' , u ' 21' , u ' 22' , u ' 23' , u ' 231' , u ' 24' , u ' 3' , u ' 4' , u ' 41' ] NEW_LINE got_descs = [ obj . desc for obj in self . model . objects . filter ( id__in = ids ) ] NEW_LINE self . assertEqual ( sorted ( got_descs ) , sorted ( expected_descs ) ) NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_get_tree_all ( self ) : NEW_LINE INDENT got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( ) ] NEW_LINE self . assertEqual ( got , self . unchanged ) NEW_LINE DEDENT def _multi_dump_bulk_all ( self ) : NEW_LINE INDENT self . assertEqual ( self . model . dump_bulk ( keep_ids = False ) , BASE_DATA ) NEW_LINE DEDENT def _multi_get_tree_node ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE self . model . load_bulk ( BASE_DATA , node ) NEW_LINE # ▁ the ▁ tree ▁ was ▁ modified ▁ by ▁ load _ bulk , ▁ so ▁ we ▁ reload ▁ our ▁ node ▁ object ENDCOM node = self . model . objects . get ( pk = node . id ) NEW_LINE got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( node ) ] NEW_LINE expected = [ ( u ' 231' , 3 , 4 ) , ( u ' 1' , 4 , 0 ) , ( u ' 2' , 4 , 4 ) , ( u ' 21' , 5 , 0 ) , ( u ' 22' , 5 , 0 ) , ( u ' 23' , 5 , 1 ) , ( u ' 231' , 6 , 0 ) , ( u ' 24' , 5 , 0 ) , ( u ' 3' , 4 , 0 ) , ( u ' 4' , 4 , 1 ) , ( u ' 41' , 5 , 0 ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_get_tree_leaf ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 1' ) NEW_LINE self . assertEqual ( 0 , node . get_children_count ( ) ) NEW_LINE got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( node ) ] NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_get_annotated_list_all ( self ) : NEW_LINE INDENT expected = [ ( u ' 1' , True , [ ] , 0 ) , ( u ' 2' , False , [ ] , 0 ) , ( u ' 21' , True , [ ] , 1 ) , ( u ' 22' , False , [ ] , 1 ) , ( u ' 23' , False , [ ] , 1 ) , ( u ' 231' , True , [ 0 ] , 2 ) , ( u ' 24' , False , [ 0 ] , 1 ) , ( u ' 3' , False , [ ] , 0 ) , ( u ' 4' , False , [ ] , 0 ) , ( u ' 41' , True , [ 0 , 1 ] , 1 ) ] NEW_LINE self . _assert_get_annotated_list ( expected ) NEW_LINE DEDENT def _multi_get_annotated_list_node ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 2' ) NEW_LINE expected = [ ( u ' 2' , True , [ ] , 0 ) , ( u ' 21' , True , [ ] , 1 ) , ( u ' 22' , False , [ ] , 1 ) , ( u ' 23' , False , [ ] , 1 ) , ( u ' 231' , True , [ 0 ] , 2 ) , ( u ' 24' , False , [ 0 , 1 ] , 1 ) ] NEW_LINE self . _assert_get_annotated_list ( expected , node ) NEW_LINE DEDENT def _multi_get_annotated_list_leaf ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 1' ) NEW_LINE expected = [ ( u ' 1' , True , [ 0 ] , 0 ) ] NEW_LINE self . _assert_get_annotated_list ( expected , node ) NEW_LINE DEDENT def _multi_dump_bulk_node ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE self . model . load_bulk ( BASE_DATA , node ) NEW_LINE # ▁ the ▁ tree ▁ was ▁ modified ▁ by ▁ load _ bulk , ▁ so ▁ we ▁ reload ▁ our ▁ node ▁ object ENDCOM node = self . model . objects . get ( pk = node . id ) NEW_LINE got = self . model . dump_bulk ( node , False ) NEW_LINE expected = [ { ' data ' : { ' desc ' : u ' 231' } , ' children ' : BASE_DATA } ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_load_and_dump_bulk_keeping_ids ( self ) : NEW_LINE INDENT exp = self . model . dump_bulk ( keep_ids = True ) NEW_LINE self . model . objects . all ( ) . delete ( ) NEW_LINE self . model . load_bulk ( exp , None , True ) NEW_LINE got = self . model . dump_bulk ( keep_ids = True ) NEW_LINE self . assertEqual ( got , exp ) NEW_LINE # ▁ do ▁ we ▁ really ▁ have ▁ an ▁ unchaged ▁ tree ▁ after ▁ the ▁ dump / delete / load ? ENDCOM got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( ) ] NEW_LINE self . assertEqual ( got , self . unchanged ) NEW_LINE DEDENT def _multi_get_root_nodes ( self ) : NEW_LINE INDENT got = self . model . get_root_nodes ( ) NEW_LINE expected = [ '1' , '2' , '3' , '4' ] NEW_LINE self . assertEqual ( [ node . desc for node in got ] , expected ) NEW_LINE DEDENT def _multi_get_first_root_node ( self ) : NEW_LINE INDENT got = self . model . get_first_root_node ( ) NEW_LINE self . assertEqual ( got . desc , '1' ) NEW_LINE DEDENT def _multi_get_last_root_node ( self ) : NEW_LINE INDENT got = self . model . get_last_root_node ( ) NEW_LINE self . assertEqual ( got . desc , '4' ) NEW_LINE DEDENT def _multi_add_root ( self ) : NEW_LINE INDENT obj = self . model . add_root ( desc = '5' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE self . assertEqual ( self . model . get_last_root_node ( ) . desc , '5' ) NEW_LINE DEDENT DEDENT class TestSimpleNodeMethods ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_is_root ( self ) : NEW_LINE INDENT data = [ ( '2' , True ) , ( '1' , True ) , ( '4' , True ) , ( '21' , False ) , ( '24' , False ) , ( '22' , False ) , ( '231' , False ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . is_root ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_is_leaf ( self ) : NEW_LINE INDENT data = [ ( '2' , False ) , ( '23' , False ) , ( '231' , True ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . is_leaf ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_get_root ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' ) , ( '1' , '1' ) , ( '4' , '4' ) , ( '21' , '2' ) , ( '24' , '2' ) , ( '22' , '2' ) , ( '231' , '2' ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_root ( ) NEW_LINE self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT def _multi_get_parent ( self ) : NEW_LINE INDENT data = [ ( '2' , None ) , ( '1' , None ) , ( '4' , None ) , ( '21' , '2' ) , ( '24' , '2' ) , ( '22' , '2' ) , ( '231' , '23' ) , ] NEW_LINE data = dict ( data ) NEW_LINE objs = { } NEW_LINE for desc , expected in data . items ( ) : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) NEW_LINE parent = node . get_parent ( ) NEW_LINE if expected : NEW_LINE INDENT self . assertEqual ( parent . desc , expected ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( parent , None ) NEW_LINE DEDENT objs [ desc ] = node NEW_LINE # ▁ corrupt ▁ the ▁ objects ' ▁ parent ▁ cache ENDCOM node . _parent_obj = ' CORRUPTED ! ! ! ' NEW_LINE DEDENT for desc , expected in data . items ( ) : NEW_LINE INDENT node = objs [ desc ] NEW_LINE # ▁ asking ▁ get _ parent ▁ to ▁ not ▁ use ▁ the ▁ parent ▁ cache ▁ ( since ▁ we ENDCOM # ▁ corrupted ▁ it ▁ in ▁ the ▁ previous ▁ loop ) ENDCOM parent = node . get_parent ( True ) NEW_LINE if expected : NEW_LINE INDENT self . assertEqual ( parent . desc , expected ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( parent , None ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_children ( self ) : NEW_LINE INDENT data = [ ( '2' , [ '21' , '22' , '23' , '24' ] ) , ( '23' , [ '231' ] ) , ( '231' , [ ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT children = self . model . objects . get ( desc = desc ) . get_children ( ) NEW_LINE self . assertEqual ( [ node . desc for node in children ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_children_count ( self ) : NEW_LINE INDENT data = [ ( '2' , 4 ) , ( '23' , 1 ) , ( '231' , 0 ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . get_children_count ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_get_siblings ( self ) : NEW_LINE INDENT data = [ ( '2' , [ '1' , '2' , '3' , '4' ] ) , ( '21' , [ '21' , '22' , '23' , '24' ] ) , ( '231' , [ '231' ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT siblings = self . model . objects . get ( desc = desc ) . get_siblings ( ) NEW_LINE self . assertEqual ( [ node . desc for node in siblings ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_first_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '1' ) , ( '1' , '1' ) , ( '4' , '1' ) , ( '21' , '21' ) , ( '24' , '21' ) , ( '22' , '21' ) , ( '231' , '231' ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_first_sibling ( ) NEW_LINE self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT def _multi_get_prev_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '1' ) , ( '1' , None ) , ( '4' , '3' ) , ( '21' , None ) , ( '24' , '23' ) , ( '22' , '21' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_prev_sibling ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_next_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '3' ) , ( '1' , '2' ) , ( '4' , None ) , ( '21' , '22' ) , ( '24' , None ) , ( '22' , '23' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_next_sibling ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_last_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '4' ) , ( '1' , '4' ) , ( '4' , '4' ) , ( '21' , '24' ) , ( '24' , '24' ) , ( '22' , '24' ) , ( '231' , '231' ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_last_sibling ( ) NEW_LINE self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT def _multi_get_first_child ( self ) : NEW_LINE INDENT data = [ ( '2' , '21' ) , ( '21' , None ) , ( '23' , '231' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_first_child ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_last_child ( self ) : NEW_LINE INDENT data = [ ( '2' , '24' ) , ( '21' , None ) , ( '23' , '231' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_last_child ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_ancestors ( self ) : NEW_LINE INDENT data = [ ( '2' , [ ] ) , ( '21' , [ '2' ] ) , ( '231' , [ '2' , '23' ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT nodes = self . model . objects . get ( desc = desc ) . get_ancestors ( ) NEW_LINE self . assertEqual ( [ node . desc for node in nodes ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_descendants ( self ) : NEW_LINE INDENT data = [ ( '2' , [ '21' , '22' , '23' , '231' , '24' ] ) , ( '23' , [ '231' ] ) , ( '231' , [ ] ) , ( '1' , [ ] ) , ( '4' , [ '41' ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT nodes = self . model . objects . get ( desc = desc ) . get_descendants ( ) NEW_LINE self . assertEqual ( [ node . desc for node in nodes ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_descendant_count ( self ) : NEW_LINE INDENT data = [ ( '2' , 5 ) , ( '23' , 1 ) , ( '231' , 0 ) , ( '1' , 0 ) , ( '4' , 1 ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . get_descendant_count ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_is_sibling_of ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' , True ) , ( '2' , '1' , True ) , ( '21' , '2' , False ) , ( '231' , '2' , False ) , ( '22' , '23' , True ) , ( '231' , '23' , False ) , ( '231' , '231' , True ) , ] NEW_LINE for desc1 , desc2 , expected in data : NEW_LINE INDENT node1 = self . model . objects . get ( desc = desc1 ) NEW_LINE node2 = self . model . objects . get ( desc = desc2 ) NEW_LINE self . assertEqual ( node1 . is_sibling_of ( node2 ) , expected ) NEW_LINE DEDENT DEDENT def _multi_is_child_of ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' , False ) , ( '2' , '1' , False ) , ( '21' , '2' , True ) , ( '231' , '2' , False ) , ( '231' , '23' , True ) , ( '231' , '231' , False ) , ] NEW_LINE for desc1 , desc2 , expected in data : NEW_LINE INDENT node1 = self . model . objects . get ( desc = desc1 ) NEW_LINE node2 = self . model . objects . get ( desc = desc2 ) NEW_LINE self . assertEqual ( node1 . is_child_of ( node2 ) , expected ) NEW_LINE DEDENT DEDENT def _multi_is_descendant_of ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' , False ) , ( '2' , '1' , False ) , ( '21' , '2' , True ) , ( '231' , '2' , True ) , ( '231' , '23' , True ) , ( '231' , '231' , False ) , ] NEW_LINE for desc1 , desc2 , expected in data : NEW_LINE INDENT node1 = self . model . objects . get ( desc = desc1 ) NEW_LINE node2 = self . model . objects . get ( desc = desc2 ) NEW_LINE self . assertEqual ( node1 . is_descendant_of ( node2 ) , expected ) NEW_LINE DEDENT DEDENT DEDENT class TestAddChild ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_add_child_to_leaf ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . add_child ( desc = '2311' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 1 ) , ( u ' 2311' , 4 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_child_to_node ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 2' ) . add_child ( desc = '25' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 25' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestAddSibling ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_add_sibling_invalid_pos ( self ) : NEW_LINE INDENT method = self . model . objects . get ( desc = u ' 231' ) . add_sibling NEW_LINE self . assertRaises ( InvalidPosition , method , ' invalid _ pos ' ) NEW_LINE DEDENT def _multi_add_sibling_missing_nodeorderby ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 2' ) NEW_LINE method = node_wchildren . add_sibling NEW_LINE self . assertRaises ( MissingNodeOrderBy , method , ' sorted - sibling ' , desc = ' aaa ' ) NEW_LINE DEDENT def _multi_add_sibling_last_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' last - sibling ' , desc = '5' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE self . assertEqual ( node_wchildren . get_last_sibling ( ) . desc , u ' 5' ) NEW_LINE DEDENT def _multi_add_sibling_last ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE obj = node . add_sibling ( ' last - sibling ' , desc = '232' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 3 ) NEW_LINE self . assertEqual ( node . get_last_sibling ( ) . desc , u ' 232' ) NEW_LINE DEDENT def _multi_add_sibling_first_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' first - sibling ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u ' new ' , 1 , 0 ) , ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_first ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 23' ) NEW_LINE obj = node_wchildren . add_sibling ( ' first - sibling ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 2 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' new ' , 2 , 0 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' new ' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 23' ) NEW_LINE obj = node_wchildren . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 2 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' new ' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left_noleft_root ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 1' ) NEW_LINE obj = node . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u ' new ' , 1 , 0 ) , ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left_noleft ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE obj = node . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 3 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 2 ) , ( u ' new ' , 3 , 0 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' new ' , 1 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u ' 23' ) NEW_LINE obj = node_wchildren . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 2 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' new ' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right_noright_root ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 4' ) NEW_LINE obj = node . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) , ( u ' new ' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right_noright ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE obj = node . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 3 ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 2 ) , ( u ' 231' , 3 , 0 ) , ( u ' new ' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestDelete ( TestNonEmptyTree ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestDelete , self ) . setUp ( ) NEW_LINE for node in self . model . objects . all ( ) : NEW_LINE INDENT self . dep_model ( node = node ) . save ( ) NEW_LINE DEDENT DEDENT def _multi_delete_leaf ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . delete ( ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_node ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 23' ) . delete ( ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 3 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 2' ) . delete ( ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_filter_root_nodes ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( '2' , '3' ) ) . delete ( ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_filter_children ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( '2' , '23' , '231' ) ) . delete ( ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_nonexistant_nodes ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( ' ZZZ ' , ' XXX ' ) ) . delete ( ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_delete_same_node_twice ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( '2' , '2' ) ) . delete ( ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_all_root_nodes ( self ) : NEW_LINE INDENT self . model . get_root_nodes ( ) . delete ( ) NEW_LINE count = self . model . objects . count ( ) NEW_LINE self . assertEqual ( count , 0 ) NEW_LINE DEDENT def _multi_delete_all_nodes ( self ) : NEW_LINE INDENT self . model . objects . all ( ) . delete ( ) NEW_LINE count = self . model . objects . count ( ) NEW_LINE self . assertEqual ( count , 0 ) NEW_LINE DEDENT DEDENT class TestMoveErrors ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_invalid_pos ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE self . assertRaises ( InvalidPosition , node . move , node , ' invalid _ pos ' ) NEW_LINE DEDENT def _multi_move_to_descendant ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 2' ) NEW_LINE target = self . model . objects . get ( desc = u ' 231' ) NEW_LINE self . assertRaises ( InvalidMoveToDescendant , node . move , target , ' first - sibling ' ) NEW_LINE DEDENT def _multi_move_missing_nodeorderby ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u ' 231' ) NEW_LINE self . assertRaises ( MissingNodeOrderBy , node . move , node , ' sorted - child ' ) NEW_LINE self . assertRaises ( MissingNodeOrderBy , node . move , node , ' sorted - sibling ' ) NEW_LINE DEDENT DEDENT class TestMoveSortedErrors ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_nonsorted_move_in_sorted ( self ) : NEW_LINE INDENT node = self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE self . assertRaises ( InvalidPosition , node . move , node , ' left ' ) NEW_LINE DEDENT DEDENT class TestMoveLeafRoot ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_leaf_last_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 2' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) , ( u ' 231' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 2' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u ' 231' , 1 , 0 ) , ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_left_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 2' ) , ' left ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 231' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_right_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 2' ) , ' right ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 231' , 1 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_last_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 2' ) , ' last - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 231' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 2' ) , ' first - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 231' , 2 , 0 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMoveLeaf ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_leaf_last_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 22' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 231' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 22' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 231' , 2 , 0 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_left_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 22' ) , ' left ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 231' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_right_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 22' ) , ' right ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 231' , 2 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_left_sibling_itself ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 231' ) , ' left ' ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_move_leaf_last_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 22' ) , ' last - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u ' 231' ) . move ( self . model . objects . get ( desc = u ' 22' ) , ' first - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 23' , 2 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMoveBranchRoot ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_branch_first_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) , ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' left ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' right ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_noleft_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) . get_first_sibling ( ) , ' left ' ) NEW_LINE expected = [ ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) , ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_noright_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) . get_last_sibling ( ) , ' right ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) , ( u ' 4' , 1 , 1 ) , ( u ' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_first_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' first - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' last - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMoveBranch ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_branch_first_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' left ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' right ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_noleft_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) . get_first_sibling ( ) , ' left ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_noright_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) . get_last_sibling ( ) , ' right ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 5 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 1 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 4' , 2 , 1 ) , ( u ' 41' , 3 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_itself_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '4' ) , ' left ' ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_move_branch_first_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' first - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 2 ) , ( u ' 4' , 3 , 1 ) , ( u ' 41' , 4 , 0 ) , ( u ' 231' , 3 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' last - child ' ) NEW_LINE expected = [ ( u ' 1' , 1 , 0 ) , ( u ' 2' , 1 , 4 ) , ( u ' 21' , 2 , 0 ) , ( u ' 22' , 2 , 0 ) , ( u ' 23' , 2 , 2 ) , ( u ' 231' , 3 , 0 ) , ( u ' 4' , 3 , 1 ) , ( u ' 41' , 4 , 0 ) , ( u ' 24' , 2 , 0 ) , ( u ' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestTreeSorted ( TestTreeBase ) : NEW_LINE INDENT def got ( self ) : NEW_LINE INDENT return [ ( o . val1 , o . val2 , o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . sorted_model . get_tree ( ) ] NEW_LINE DEDENT def _multi_add_root_sorted ( self ) : NEW_LINE INDENT self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 1 , val2 = 4 , desc = ' bcd ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 5 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 4 , val2 = 1 , desc = ' fgh ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 2 , desc = ' qwe ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 2 , desc = ' vcx ' ) NEW_LINE expected = [ ( 1 , 4 , u ' bcd ' , 1 , 0 ) , ( 2 , 2 , u ' qwe ' , 1 , 0 ) , ( 2 , 5 , u ' zxy ' , 1 , 0 ) , ( 3 , 2 , u ' vcx ' , 1 , 0 ) , ( 3 , 3 , u ' abc ' , 1 , 0 ) , ( 3 , 3 , u ' abc ' , 1 , 0 ) , ( 3 , 3 , u ' zxy ' , 1 , 0 ) , ( 4 , 1 , u ' fgh ' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_child_root_sorted ( self ) : NEW_LINE INDENT root = self . sorted_model . add_root ( val1 = 0 , val2 = 0 , desc = ' aaa ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE root . add_child ( val1 = 1 , val2 = 4 , desc = ' bcd ' ) NEW_LINE root . add_child ( val1 = 2 , val2 = 5 , desc = ' zxy ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE root . add_child ( val1 = 4 , val2 = 1 , desc = ' fgh ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE root . add_child ( val1 = 2 , val2 = 2 , desc = ' qwe ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 2 , desc = ' vcx ' ) NEW_LINE expected = [ ( 0 , 0 , u ' aaa ' , 1 , 8 ) , ( 1 , 4 , u ' bcd ' , 2 , 0 ) , ( 2 , 2 , u ' qwe ' , 2 , 0 ) , ( 2 , 5 , u ' zxy ' , 2 , 0 ) , ( 3 , 2 , u ' vcx ' , 2 , 0 ) , ( 3 , 3 , u ' abc ' , 2 , 0 ) , ( 3 , 3 , u ' abc ' , 2 , 0 ) , ( 3 , 3 , u ' zxy ' , 2 , 0 ) , ( 4 , 1 , u ' fgh ' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_child_nonroot_sorted ( self ) : NEW_LINE INDENT get_node = lambda node_id : self . sorted_model . objects . get ( pk = node_id ) NEW_LINE root_id = self . sorted_model . add_root ( val1 = 0 , val2 = 0 , desc = ' a ' ) . id NEW_LINE node_id = get_node ( root_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' ac ' ) . id NEW_LINE get_node ( root_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' aa ' ) NEW_LINE get_node ( root_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' av ' ) NEW_LINE get_node ( node_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' aca ' ) NEW_LINE get_node ( node_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' acc ' ) NEW_LINE get_node ( node_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' acb ' ) NEW_LINE expected = [ ( 0 , 0 , u ' a ' , 1 , 3 ) , ( 0 , 0 , u ' aa ' , 2 , 0 ) , ( 0 , 0 , u ' ac ' , 2 , 3 ) , ( 0 , 0 , u ' aca ' , 3 , 0 ) , ( 0 , 0 , u ' acb ' , 3 , 0 ) , ( 0 , 0 , u ' acc ' , 3 , 0 ) , ( 0 , 0 , u ' av ' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_sorted ( self ) : NEW_LINE INDENT self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 1 , val2 = 4 , desc = ' bcd ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 5 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 4 , val2 = 1 , desc = ' fgh ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 2 , desc = ' qwe ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 2 , desc = ' vcx ' ) NEW_LINE root_nodes = self . sorted_model . get_root_nodes ( ) NEW_LINE target = root_nodes [ 0 ] NEW_LINE for node in root_nodes [ 1 : ] : NEW_LINE # ▁ because ▁ raw ▁ queries ▁ don ' t ▁ update ▁ django ▁ objects ENDCOM INDENT node = self . sorted_model . objects . get ( pk = node . id ) NEW_LINE target = self . sorted_model . objects . get ( pk = target . id ) NEW_LINE node . move ( target , ' sorted - child ' ) NEW_LINE DEDENT expected = [ ( 1 , 4 , u ' bcd ' , 1 , 7 ) , ( 2 , 2 , u ' qwe ' , 2 , 0 ) , ( 2 , 5 , u ' zxy ' , 2 , 0 ) , ( 3 , 2 , u ' vcx ' , 2 , 0 ) , ( 3 , 3 , u ' abc ' , 2 , 0 ) , ( 3 , 3 , u ' abc ' , 2 , 0 ) , ( 3 , 3 , u ' zxy ' , 2 , 0 ) , ( 4 , 1 , u ' fgh ' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMP_TreeAlphabet ( TestCase ) : NEW_LINE INDENT def test_alphabet ( self ) : NEW_LINE INDENT if not os . getenv ( ' TREEBEARD _ TEST _ ALPHABET ' , False ) : NEW_LINE # ▁ run ▁ this ▁ test ▁ only ▁ if ▁ the ▁ enviroment ▁ variable ▁ is ▁ set ENDCOM INDENT return NEW_LINE DEDENT basealpha = numconv . BASE85 NEW_LINE got_err = False NEW_LINE last_good = None NEW_LINE for alphabetlen in range ( 35 , len ( basealpha ) + 1 ) : NEW_LINE INDENT alphabet = basealpha [ 0 : alphabetlen ] NEW_LINE expected = [ alphabet [ 0 ] + char for char in alphabet [ 1 : ] ] NEW_LINE expected . extend ( [ alphabet [ 1 ] + char for char in alphabet ] ) NEW_LINE expected . append ( alphabet [ 2 ] + alphabet [ 0 ] ) NEW_LINE # ▁ remove ▁ all ▁ nodes ENDCOM MP_TestNodeAlphabet . objects . all ( ) . delete ( ) NEW_LINE # ▁ change ▁ the ▁ model ' s ▁ alphabet ENDCOM MP_TestNodeAlphabet . alphabet = alphabet NEW_LINE # ▁ insert ▁ root ▁ nodes ENDCOM for pos in range ( len ( alphabet ) * 2 ) : NEW_LINE INDENT try : NEW_LINE INDENT MP_TestNodeAlphabet . add_root ( numval = pos ) NEW_LINE DEDENT except : NEW_LINE INDENT got_err = True NEW_LINE break NEW_LINE DEDENT DEDENT if got_err : NEW_LINE INDENT break NEW_LINE DEDENT got = [ obj . path for obj in MP_TestNodeAlphabet . objects . all ( ) ] NEW_LINE if got != expected : NEW_LINE INDENT got_err = True NEW_LINE DEDENT last_good = alphabet NEW_LINE DEDENT print ' \n The ▁ best ▁ BASE85 ▁ based ▁ alphabet ▁ for ▁ your ▁ setup ▁ is : ▁ % s ' % ( last_good , ) NEW_LINE DEDENT DEDENT class TestHelpers ( TestTreeBase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT for model in ( MP_TestNode , AL_TestNode , NS_TestNode ) : NEW_LINE INDENT model . load_bulk ( BASE_DATA ) NEW_LINE for node in model . get_root_nodes ( ) : NEW_LINE INDENT model . load_bulk ( BASE_DATA , node ) NEW_LINE DEDENT model . add_root ( desc = '5' ) NEW_LINE DEDENT DEDENT def _multi_descendants_group_count_root ( self ) : NEW_LINE INDENT expected = [ ( o . desc , o . get_descendant_count ( ) ) for o in self . model . get_root_nodes ( ) ] NEW_LINE got = [ ( o . desc , o . descendants_count ) for o in self . model . get_descendants_group_count ( ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_descendants_group_count_node ( self ) : NEW_LINE INDENT parent = self . model . get_root_nodes ( ) . get ( desc = '2' ) NEW_LINE expected = [ ( o . desc , o . get_descendant_count ( ) ) for o in parent . get_children ( ) ] NEW_LINE got = [ ( o . desc , o . descendants_count ) for o in self . model . get_descendants_group_count ( parent ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT class TestMP_TreeSortedAutoNow ( TestCase ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ sorting ▁ mechanism ▁ used ▁ by ▁ treebeard ▁ when ▁ adding ▁ a ▁ node ▁ can ▁ fail ▁ if ▁ the STRNEWLINE ▁ ordering ▁ is ▁ using ▁ an ▁ " auto _ now " ▁ field STRNEWLINE ▁ """ NEW_LINE def test_sorted_by_autonow_workaround ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ workaround STRNEWLINE ▁ """ NEW_LINE import datetime NEW_LINE for i in range ( 1 , 5 ) : NEW_LINE INDENT MP_TestNodeSortedAutoNow . add_root ( desc = ' node % d ' % ( i , ) , created = datetime . datetime . now ( ) ) NEW_LINE DEDENT DEDENT def test_sorted_by_autonow_FAIL ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ test ▁ asserts ▁ that ▁ we ▁ have ▁ a ▁ problem . STRNEWLINE ▁ fix ▁ this , ▁ somehow STRNEWLINE ▁ """ NEW_LINE MP_TestNodeSortedAutoNow . add_root ( desc = ' node1' ) NEW_LINE self . assertRaises ( ValueError , MP_TestNodeSortedAutoNow . add_root , desc = ' node2' ) NEW_LINE DEDENT DEDENT class TestMP_TreeStepOverflow ( TestCase ) : NEW_LINE INDENT def test_add_root ( self ) : NEW_LINE INDENT method = MP_TestNodeSmallStep . add_root NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT method ( ) NEW_LINE DEDENT self . assertRaises ( PathOverflow , method ) NEW_LINE DEDENT def test_add_child ( self ) : NEW_LINE INDENT root = MP_TestNodeSmallStep . add_root ( ) NEW_LINE method = root . add_child NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT method ( ) NEW_LINE DEDENT self . assertRaises ( PathOverflow , method ) NEW_LINE DEDENT def test_add_sibling ( self ) : NEW_LINE INDENT root = MP_TestNodeSmallStep . add_root ( ) NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT root . add_child ( ) NEW_LINE DEDENT method = root . get_last_child ( ) . add_sibling NEW_LINE positions = ( ' first - sibling ' , ' left ' , ' right ' , ' last - sibling ' ) NEW_LINE for pos in positions : NEW_LINE INDENT self . assertRaises ( PathOverflow , method , pos ) NEW_LINE DEDENT DEDENT def test_move ( self ) : NEW_LINE INDENT root = MP_TestNodeSmallStep . add_root ( ) NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT root . add_child ( ) NEW_LINE DEDENT newroot = MP_TestNodeSmallStep . add_root ( ) NEW_LINE targets = [ ( root , [ ' first - child ' , ' last - child ' ] ) , ( root . get_first_child ( ) , [ ' first - sibling ' , ' left ' , ' right ' , ' last - sibling ' ] ) ] NEW_LINE for target , positions in targets : NEW_LINE INDENT for pos in positions : NEW_LINE INDENT self . assertRaises ( PathOverflow , newroot . move , target , pos ) NEW_LINE DEDENT DEDENT DEDENT DEDENT class TestMP_TreeShortPath ( TestCase ) : NEW_LINE INDENT """ STRNEWLINE ▁ Here ▁ we ▁ test ▁ a ▁ tree ▁ with ▁ a ▁ very ▁ small ▁ path ▁ field ▁ ( max _ length = 4 ) ▁ and ▁ a STRNEWLINE ▁ steplen ▁ of ▁ 1 STRNEWLINE ▁ """ NEW_LINE def test_short_path ( self ) : NEW_LINE INDENT obj = MP_TestNodeShortPath . add_root ( ) NEW_LINE obj = obj . add_child ( ) . add_child ( ) . add_child ( ) NEW_LINE self . assertRaises ( PathOverflow , obj . add_child ) NEW_LINE DEDENT DEDENT class TestMP_TreeFindProblems ( TestTreeBase ) : NEW_LINE INDENT def test_find_problems ( self ) : NEW_LINE INDENT model = MP_TestNodeAlphabet NEW_LINE model . alphabet = '01234' NEW_LINE model ( path = '01' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '1' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '111' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = ' abcd ' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = ' qa # $ % ! ' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '0201' , depth = 2 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '020201' , depth = 3 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '03' , depth = 1 , numchild = 2 , numval = 0 ) . save ( ) NEW_LINE model ( path = '0301' , depth = 2 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '030102' , depth = 3 , numchild = 10 , numval = 0 ) . save ( ) NEW_LINE model ( path = '04' , depth = 10 , numchild = 1 , numval = 0 ) . save ( ) NEW_LINE model ( path = '0401' , depth = 20 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE evil_chars , bad_steplen , orphans , wrong_depth , wrong_numchild = model . find_problems ( ) NEW_LINE self . assertEqual ( [ ' abcd ' , ' qa # $ % ! ' ] , [ o . path for o in model . objects . filter ( id__in = evil_chars ) ] ) NEW_LINE self . assertEqual ( [ '1' , '111' ] , [ o . path for o in model . objects . filter ( id__in = bad_steplen ) ] ) NEW_LINE self . assertEqual ( [ '0201' , '020201' ] , [ o . path for o in model . objects . filter ( id__in = orphans ) ] ) NEW_LINE self . assertEqual ( [ '03' , '0301' , '030102' ] , [ o . path for o in model . objects . filter ( id__in = wrong_numchild ) ] ) NEW_LINE self . assertEqual ( [ '04' , '0401' ] , [ o . path for o in model . objects . filter ( id__in = wrong_depth ) ] ) NEW_LINE DEDENT DEDENT class TestMP_TreeFix ( TestTreeBase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestMP_TreeFix , self ) . setUp ( ) NEW_LINE self . expected_no_holes = { MP_TestNodeShortPath : [ ( u ' 1' , u ' b ' , 1 , 2 ) , ( u ' 11' , u ' u ' , 2 , 1 ) , ( u ' 111' , u ' i ' , 3 , 1 ) , ( u ' 1111' , u ' e ' , 4 , 0 ) , ( u ' 12' , u ' o ' , 2 , 0 ) , ( u ' 2' , u ' d ' , 1 , 0 ) , ( u ' 3' , u ' g ' , 1 , 0 ) , ( u ' 4' , u ' a ' , 1 , 4 ) , ( u ' 41' , u ' a ' , 2 , 0 ) , ( u ' 42' , u ' a ' , 2 , 0 ) , ( u ' 43' , u ' u ' , 2 , 1 ) , ( u ' 431' , u ' i ' , 3 , 1 ) , ( u ' 4311' , u ' e ' , 4 , 0 ) , ( u ' 44' , u ' o ' , 2 , 0 ) ] , MP_TestSortedNodeShortPath : [ ( u ' 1' , u ' a ' , 1 , 4 ) , ( u ' 11' , u ' a ' , 2 , 0 ) , ( u ' 12' , u ' a ' , 2 , 0 ) , ( u ' 13' , u ' o ' , 2 , 0 ) , ( u ' 14' , u ' u ' , 2 , 1 ) , ( u ' 141' , u ' i ' , 3 , 1 ) , ( u ' 1411' , u ' e ' , 4 , 0 ) , ( u ' 2' , u ' b ' , 1 , 2 ) , ( u ' 21' , u ' o ' , 2 , 0 ) , ( u ' 22' , u ' u ' , 2 , 1 ) , ( u ' 221' , u ' i ' , 3 , 1 ) , ( u ' 2211' , u ' e ' , 4 , 0 ) , ( u ' 3' , u ' d ' , 1 , 0 ) , ( u ' 4' , u ' g ' , 1 , 0 ) ] } NEW_LINE self . expected_with_holes = { MP_TestNodeShortPath : [ ( u ' 1' , u ' b ' , 1 L , 2 L ) , ( u ' 13' , u ' u ' , 2 L , 1 L ) , ( u ' 134' , u ' i ' , 3 L , 1 L ) , ( u ' 1343' , u ' e ' , 4 L , 0 L ) , ( u ' 14' , u ' o ' , 2 L , 0 L ) , ( u ' 2' , u ' d ' , 1 L , 0 L ) , ( u ' 3' , u ' g ' , 1 L , 0 L ) , ( u ' 4' , u ' a ' , 1 L , 4 L ) , ( u ' 41' , u ' a ' , 2 L , 0 L ) , ( u ' 42' , u ' a ' , 2 L , 0 L ) , ( u ' 43' , u ' u ' , 2 L , 1 L ) , ( u ' 434' , u ' i ' , 3 L , 1 L ) , ( u ' 4343' , u ' e ' , 4 L , 0 L ) , ( u ' 44' , u ' o ' , 2 L , 0 L ) ] , MP_TestSortedNodeShortPath : [ ( u ' 1' , u ' b ' , 1 L , 2 L ) , ( u ' 13' , u ' u ' , 2 L , 1 L ) , ( u ' 134' , u ' i ' , 3 L , 1 L ) , ( u ' 1343' , u ' e ' , 4 L , 0 L ) , ( u ' 14' , u ' o ' , 2 L , 0 L ) , ( u ' 2' , u ' d ' , 1 L , 0 L ) , ( u ' 3' , u ' g ' , 1 L , 0 L ) , ( u ' 4' , u ' a ' , 1 L , 4 L ) , ( u ' 41' , u ' a ' , 2 L , 0 L ) , ( u ' 42' , u ' a ' , 2 L , 0 L ) , ( u ' 43' , u ' u ' , 2 L , 1 L ) , ( u ' 434' , u ' i ' , 3 L , 1 L ) , ( u ' 4343' , u ' e ' , 4 L , 0 L ) , ( u ' 44' , u ' o ' , 2 L , 0 L ) ] } NEW_LINE DEDENT def got ( self , model ) : NEW_LINE INDENT return [ ( o . path , o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in model . get_tree ( ) ] NEW_LINE DEDENT def add_broken_test_data ( self , model ) : NEW_LINE INDENT model ( path = '4' , depth = 2 , numchild = 2 , desc = ' a ' ) . save ( ) NEW_LINE model ( path = '13' , depth = 1000 , numchild = 0 , desc = ' u ' ) . save ( ) NEW_LINE model ( path = '14' , depth = 4 , numchild = 500 , desc = ' o ' ) . save ( ) NEW_LINE model ( path = '134' , depth = 321 , numchild = 543 , desc = ' i ' ) . save ( ) NEW_LINE model ( path = '1343' , depth = 321 , numchild = 543 , desc = ' e ' ) . save ( ) NEW_LINE model ( path = '42' , depth = 1 , numchild = 1 , desc = ' a ' ) . save ( ) NEW_LINE model ( path = '43' , depth = 1000 , numchild = 0 , desc = ' u ' ) . save ( ) NEW_LINE model ( path = '44' , depth = 4 , numchild = 500 , desc = ' o ' ) . save ( ) NEW_LINE model ( path = '434' , depth = 321 , numchild = 543 , desc = ' i ' ) . save ( ) NEW_LINE model ( path = '4343' , depth = 321 , numchild = 543 , desc = ' e ' ) . save ( ) NEW_LINE model ( path = '41' , depth = 1 , numchild = 1 , desc = ' a ' ) . save ( ) NEW_LINE model ( path = '3' , depth = 221 , numchild = 322 , desc = ' g ' ) . save ( ) NEW_LINE model ( path = '1' , depth = 10 , numchild = 3 , desc = ' b ' ) . save ( ) NEW_LINE model ( path = '2' , depth = 10 , numchild = 3 , desc = ' d ' ) . save ( ) NEW_LINE DEDENT def test_fix_tree_non_destructive ( self ) : NEW_LINE INDENT for model in ( MP_TestNodeShortPath , MP_TestSortedNodeShortPath ) : NEW_LINE INDENT self . add_broken_test_data ( model ) NEW_LINE model . fix_tree ( destructive = False ) NEW_LINE self . assertEqual ( self . got ( model ) , self . expected_with_holes [ model ] ) NEW_LINE model . find_problems ( ) NEW_LINE DEDENT DEDENT def test_fix_tree_destructive ( self ) : NEW_LINE INDENT for model in ( MP_TestNodeShortPath , MP_TestSortedNodeShortPath ) : NEW_LINE INDENT self . add_broken_test_data ( model ) NEW_LINE model . fix_tree ( destructive = True ) NEW_LINE self . assertEqual ( self . got ( model ) , self . expected_no_holes [ model ] ) NEW_LINE model . find_problems ( ) NEW_LINE DEDENT DEDENT DEDENT class TestIssues ( TestCase ) : NEW_LINE INDENT " test ▁ for ▁ http : / / code . google . com / p / django - treebeard / issues / detail ? id = 14" NEW_LINE def test_many_to_many_django_user_anonymous ( self ) : NEW_LINE INDENT if not HAS_DJANGO_AUTH : # ▁ pragma : ▁ no ▁ cover ENDCOM NEW_LINE INDENT self . fail ( ' this ▁ test ▁ needs ▁ django . contrib . auth ▁ in ▁ INSTALLED _ APPS ' ) NEW_LINE # ▁ Using ▁ AnonymousUser ( ) ▁ in ▁ the ▁ querysets ▁ will ▁ expose ▁ non - treebeard ENDCOM # ▁ related ▁ problems ▁ in ▁ Django ▁ 1.0 ENDCOM # ▁ Postgres : ENDCOM # ▁ ProgrammingError : ▁ can ' t ▁ adapt ENDCOM # ▁ SQLite : ENDCOM # ▁ InterfaceError : ▁ Error ▁ binding ▁ parameter ▁ 4 ▁ - ▁ probably ▁ unsupported ENDCOM # ▁ type . ENDCOM # ▁ MySQL ▁ compared ▁ a ▁ string ▁ to ▁ an ▁ integer ▁ field : ENDCOM # ▁ ` treebeard _ mp _ testissue14 _ users ` . ` user _ id ` ▁ = ▁ ' AnonymousUser ' ENDCOM # ▁ Using ▁ a ▁ None ▁ field ▁ instead ▁ works ▁ ( will ▁ be ▁ translated ▁ to ▁ IS ▁ NULL ) . ENDCOM # ▁ anonuserobj ▁ = ▁ AnonymousUser ( ) ENDCOM DEDENT anonuserobj = None NEW_LINE def qs_check ( qs , expected ) : NEW_LINE INDENT self . assertEqual ( [ o . name for o in qs ] , expected ) NEW_LINE DEDENT user = User . objects . create_user ( ' test _ user ' , ' test @ example . com ' , ' testpasswd ' ) NEW_LINE user . save ( ) NEW_LINE root = MP_TestIssue14 . add_root ( name = " the ▁ root ▁ node " ) NEW_LINE root . add_child ( name = " first " ) NEW_LINE second = root . add_child ( name = " second " ) NEW_LINE qs_check ( root . get_children ( ) , [ ' first ' , ' second ' ] ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) ) , [ ' first ' ] ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( users = user ) ) , [ ] ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' ] ) NEW_LINE user = anonuserobj NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' , ' second ' ] ) NEW_LINE user = User . objects . get ( username = " test _ user " ) NEW_LINE second . users . add ( user ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' , ' second ' ] ) NEW_LINE user = anonuserobj NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' ] ) NEW_LINE DEDENT DEDENT class TestModelAdmin ( ModelAdmin ) : NEW_LINE INDENT form = MoveNodeForm NEW_LINE DEDENT class TestMoveNodeForm ( TestTreeBase ) : NEW_LINE INDENT tpl = ( u ' < tr > < th > < label ▁ for = " id _ _ position " > Position : < / label > < / th > ' ' < td > < select ▁ name = " _ position " ▁ id = " id _ _ position " > \n ' ' < option ▁ value = " first - child " > First ▁ child ▁ of < / option > \n ' ' < option ▁ value = " left " > Before < / option > \n ' ' < option ▁ value = " right " > After < / option > \n ' ' < / select > < / td > < / tr > \n ' ' < tr > < th > < label ▁ for = " id _ _ ref _ node _ id " > Relative ▁ to : < / label > ' ' < / th > < td > < select ▁ name = " _ ref _ node _ id " ▁ id = " id _ _ ref _ node _ id " > \n ' ' < option ▁ value = " 0 " > - - ▁ root ▁ - - < / option > \n ' ) NEW_LINE def _multi_form_html_root_node ( self ) : NEW_LINE INDENT self . model . load_bulk ( BASE_DATA ) NEW_LINE node = self . model . get_tree ( ) [ 0 ] NEW_LINE form = MoveNodeForm ( instance = node ) NEW_LINE rtpl = self . tpl NEW_LINE self . assertEqual ( [ ' _ position ' , ' _ ref _ node _ id ' ] , form . base_fields . keys ( ) ) NEW_LINE for obj in self . model . get_tree ( ) : NEW_LINE INDENT if node != obj or obj . is_descendant_of ( node ) : NEW_LINE INDENT rtpl += ' < option ▁ value = " % d " > % sNode ▁ % d < / option > \n ' % ( obj . id , ' . ▁ . ▁ ' * ( obj . get_depth ( ) - 1 ) , obj . id ) NEW_LINE DEDENT DEDENT rtpl += ' < / select > < / td > < / tr > ' NEW_LINE formstr = unicode ( form ) . replace ( u ' ▁ selected = " selected " ' , u ' ' ) NEW_LINE self . assertEqual ( rtpl , formstr ) NEW_LINE DEDENT def _multi_form_html_leaf_node ( self ) : NEW_LINE INDENT self . model . load_bulk ( BASE_DATA ) NEW_LINE nodes = list ( self . model . get_tree ( ) ) NEW_LINE node = nodes [ - 1 ] NEW_LINE form = MoveNodeForm ( instance = node ) NEW_LINE rtpl = self . tpl NEW_LINE self . assertEqual ( [ ' _ position ' , ' _ ref _ node _ id ' ] , form . base_fields . keys ( ) ) NEW_LINE for obj in self . model . get_tree ( ) : NEW_LINE INDENT if node != obj or obj . is_descendant_of ( node ) : NEW_LINE INDENT rtpl += ' < option ▁ value = " % d " > % sNode ▁ % d < / option > \n ' % ( obj . id , ' . ▁ . ▁ ' * ( obj . get_depth ( ) - 1 ) , obj . id ) NEW_LINE DEDENT DEDENT rtpl += ' < / select > < / td > < / tr > ' NEW_LINE formstr = unicode ( form ) . replace ( u ' ▁ selected = " selected " ' , u ' ' ) NEW_LINE self . assertEqual ( rtpl , formstr ) NEW_LINE DEDENT def _multi_admin_html ( self ) : NEW_LINE INDENT tpl = ( ' < tr > < th > < label ▁ for = " id _ desc " > Desc : < / label > ' ' < / th > < td > < input ▁ id = " id _ desc " ▁ type = " text " ▁ class = " vTextField " ▁ ' ' name = " desc " ▁ maxlength = " 255 " ▁ / > < / td > < / tr > \n ' ' < tr > < th > < label ▁ for = " id _ _ position " > Position : < / label > < / th > ' ' < td > < select ▁ name = " _ position " ▁ id = " id _ _ position " > \n ' ' < option ▁ value = " first - child " > First ▁ child ▁ of < / option > \n ' ' < option ▁ value = " left " > Before < / option > \n ' ' < option ▁ value = " right " > After < / option > \n ' ' < / select > < / td > < / tr > \n ' ' < tr > < th > < label ▁ for = " id _ _ ref _ node _ id " > Relative ▁ to : < / label > ' ' < / th > < td > < select ▁ name = " _ ref _ node _ id " ▁ id = " id _ _ ref _ node _ id " > \n ' ' < option ▁ value = " 0 " > - - ▁ root ▁ - - < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < / select > < / td > < / tr > ' ) NEW_LINE request = None NEW_LINE self . model . load_bulk ( BASE_DATA ) NEW_LINE for node in self . model . objects . all ( ) : NEW_LINE INDENT site = AdminSite ( ) NEW_LINE ma = TestModelAdmin ( self . model , site ) NEW_LINE self . assertEqual ( [ ' desc ' , ' _ position ' , ' _ ref _ node _ id ' ] , ma . get_form ( request ) . base_fields . keys ( ) ) NEW_LINE self . assertEqual ( [ ( None , { ' fields ' : [ ' desc ' , ' _ position ' , ' _ ref _ node _ id ' ] } ) ] , ma . get_fieldsets ( request ) ) NEW_LINE self . assertEqual ( [ ( None , { ' fields ' : [ ' desc ' , ' _ position ' , ' _ ref _ node _ id ' ] } ) ] , ma . get_fieldsets ( request , node ) ) NEW_LINE form = ma . get_form ( request ) ( ) NEW_LINE ids = [ ] NEW_LINE for obj in self . model . get_tree ( ) : NEW_LINE INDENT ids . extend ( [ obj . id ] * 2 ) NEW_LINE DEDENT self . assertEqual ( tpl % tuple ( ids ) , unicode ( form ) ) NEW_LINE DEDENT DEDENT DEDENT _load_test_methods ( TestMoveNodeForm ) NEW_LINE _load_test_methods ( TestEmptyTree ) NEW_LINE _load_test_methods ( TestClassMethods ) NEW_LINE _load_test_methods ( TestSimpleNodeMethods ) NEW_LINE _load_test_methods ( TestAddChild ) NEW_LINE _load_test_methods ( TestAddSibling ) NEW_LINE _load_test_methods ( TestDelete ) NEW_LINE _load_test_methods ( TestMoveErrors ) NEW_LINE _load_test_methods ( TestMoveLeafRoot ) NEW_LINE _load_test_methods ( TestMoveLeaf ) NEW_LINE _load_test_methods ( TestMoveBranchRoot ) NEW_LINE _load_test_methods ( TestMoveBranch ) NEW_LINE _load_test_methods ( TestHelpers ) NEW_LINE # ▁ we ▁ didn ' t ▁ create ▁ extra ▁ sorted - proxy ▁ models ENDCOM _load_test_methods ( TestMoveSortedErrors , proxy = False ) NEW_LINE _load_test_methods ( TestTreeSorted , proxy = False ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="jonathonwalz/ansible/tree/master/test/units/modules/network/f5/test_bigip_iapp_service.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2017 ▁ F5 ▁ Networks ▁ Inc . ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible ENDCOM # ▁ Ansible ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ Ansible . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE import os NEW_LINE import json NEW_LINE import sys NEW_LINE from nose . plugins . skip import SkipTest NEW_LINE if sys . version_info < ( 2 , 7 ) : NEW_LINE INDENT raise SkipTest ( " F5 ▁ Ansible ▁ modules ▁ require ▁ Python ▁ > = ▁ 2.7" ) NEW_LINE DEDENT from ansible . compat . tests import unittest NEW_LINE from ansible . compat . tests . mock import patch , Mock NEW_LINE from ansible . module_utils import basic NEW_LINE from ansible . module_utils . _text import to_bytes NEW_LINE from ansible . module_utils . f5_utils import AnsibleF5Client NEW_LINE try : NEW_LINE INDENT from library . bigip_iapp_service import Parameters NEW_LINE from library . bigip_iapp_service import ModuleManager NEW_LINE from library . bigip_iapp_service import ArgumentSpec NEW_LINE DEDENT except ImportError : NEW_LINE INDENT try : NEW_LINE INDENT from ansible . modules . network . f5 . bigip_iapp_service import Parameters NEW_LINE from ansible . modules . network . f5 . bigip_iapp_service import ModuleManager NEW_LINE from ansible . modules . network . f5 . bigip_iapp_service import ArgumentSpec NEW_LINE DEDENT except ImportError : NEW_LINE INDENT raise SkipTest ( " F5 ▁ Ansible ▁ modules ▁ require ▁ the ▁ f5 - sdk ▁ Python ▁ library " ) NEW_LINE DEDENT DEDENT fixture_path = os . path . join ( os . path . dirname ( __file__ ) , ' fixtures ' ) NEW_LINE fixture_data = { } NEW_LINE def set_module_args ( args ) : NEW_LINE INDENT args = json . dumps ( { ' ANSIBLE _ MODULE _ ARGS ' : args } ) NEW_LINE basic . _ANSIBLE_ARGS = to_bytes ( args ) NEW_LINE DEDENT def load_fixture ( name ) : NEW_LINE INDENT path = os . path . join ( fixture_path , name ) NEW_LINE if path in fixture_data : NEW_LINE INDENT return fixture_data [ path ] NEW_LINE DEDENT with open ( path ) as f : NEW_LINE INDENT data = f . read ( ) NEW_LINE DEDENT try : NEW_LINE INDENT data = json . loads ( data ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT fixture_data [ path ] = data NEW_LINE return data NEW_LINE DEDENT class TestParameters ( unittest . TestCase ) : NEW_LINE INDENT def test_module_parameters_keys ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE # ▁ Assert ▁ the ▁ top - level ▁ keys ENDCOM assert p . name == ' http _ example ' NEW_LINE assert p . partition == ' Common ' NEW_LINE assert p . template == ' / Common / f5 . http ' NEW_LINE DEDENT def test_module_parameters_lists ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' lists ' in p . _values NEW_LINE assert p . lists [ 0 ] [ ' name ' ] == ' irules _ _ irules ' NEW_LINE assert p . lists [ 0 ] [ ' encrypted ' ] == ' no ' NEW_LINE assert len ( p . lists [ 0 ] [ ' value ' ] ) == 1 NEW_LINE assert p . lists [ 0 ] [ ' value ' ] [ 0 ] == ' / Common / lgyft ' NEW_LINE assert p . lists [ 1 ] [ ' name ' ] == ' net _ _ client _ vlan ' NEW_LINE assert p . lists [ 1 ] [ ' encrypted ' ] == ' no ' NEW_LINE assert len ( p . lists [ 1 ] [ ' value ' ] ) == 1 NEW_LINE assert p . lists [ 1 ] [ ' value ' ] [ 0 ] == ' / Common / net2' NEW_LINE DEDENT def test_module_parameters_tables ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' tables ' in p . _values NEW_LINE assert ' columnNames ' in p . tables [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' columnNames ' ] ) == 1 NEW_LINE assert p . tables [ 0 ] [ ' columnNames ' ] [ 0 ] == ' name ' NEW_LINE assert ' name ' in p . tables [ 0 ] NEW_LINE assert p . tables [ 0 ] [ ' name ' ] == ' pool _ _ hosts ' NEW_LINE assert ' rows ' in p . tables [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] ) == 1 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] ) == 1 NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 0 ] == ' demo . example . com ' NEW_LINE assert len ( p . tables [ 1 ] [ ' rows ' ] ) == 2 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert len ( p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] ) == 2 NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 0 ] == '10.1.1.1' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 1 ] == '0' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 1 ] [ ' row ' ] [ 0 ] == '10.1.1.2' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 1 ] [ ' row ' ] [ 1 ] == '0' NEW_LINE DEDENT def test_module_parameters_variables ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' variables ' in p . _values NEW_LINE assert len ( p . variables ) == 34 NEW_LINE # ▁ Assert ▁ one ▁ configuration ▁ value ENDCOM assert ' name ' in p . variables [ 0 ] NEW_LINE assert ' value ' in p . variables [ 0 ] NEW_LINE assert p . variables [ 0 ] [ ' name ' ] == ' afm _ _ dos _ security _ profile ' NEW_LINE assert p . variables [ 0 ] [ ' value ' ] == ' / # do _ not _ use # ' NEW_LINE # ▁ Assert ▁ a ▁ second ▁ configuration ▁ value ENDCOM assert ' name ' in p . variables [ 1 ] NEW_LINE assert ' value ' in p . variables [ 1 ] NEW_LINE assert p . variables [ 1 ] [ ' name ' ] == ' afm _ _ policy ' NEW_LINE assert p . variables [ 1 ] [ ' value ' ] == ' / # do _ not _ use # ' NEW_LINE DEDENT def test_api_parameters_variables ( self ) : NEW_LINE INDENT args = dict ( variables = [ dict ( name = " client _ _ http _ compression " , encrypted = " no " , value = " / # create _ new # " ) ] ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . variables [ 0 ] [ ' name ' ] == ' client _ _ http _ compression ' NEW_LINE DEDENT def test_api_parameters_tables ( self ) : NEW_LINE INDENT args = dict ( tables = [ { " name " : " pool _ _ members " , " columnNames " : [ " addr " , " port " , " connection _ limit " ] , " rows " : [ { " row " : [ "12.12.12.12" , "80" , ] } , { " row " : [ "13.13.13.13" , "443" , 10 ] } ] } ] ) p = Parameters ( args ) NEW_LINE assert p . tables [ 0 ] [ ' name ' ] == ' pool _ _ members ' NEW_LINE assert p . tables [ 0 ] [ ' columnNames ' ] == [ ' addr ' , ' port ' , ' connection _ limit ' ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] ) == 2 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 1 ] NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] == [ '12.12.12.12' , '80' , '0' ] NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 1 ] [ ' row ' ] == [ '13.13.13.13' , '443' , '10' ] NEW_LINE DEDENT def test_module_template_same_partition ( self ) : NEW_LINE INDENT args = dict ( template = ' foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / bar / foo ' NEW_LINE DEDENT def test_module_template_same_partition_full_path ( self ) : NEW_LINE INDENT args = dict ( template = ' / bar / foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / bar / foo ' NEW_LINE DEDENT def test_module_template_different_partition_full_path ( self ) : NEW_LINE INDENT args = dict ( template = ' / Common / foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / Common / foo ' NEW_LINE DEDENT DEDENT @ patch ( ' ansible . module _ utils . f5 _ utils . AnsibleF5Client . _ get _ mgmt _ root ' , return_value = True ) NEW_LINE class TestManager ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . spec = ArgumentSpec ( ) NEW_LINE DEDENT def test_create_service ( self , * args ) : NEW_LINE INDENT parameters = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE set_module_args ( dict ( name = ' foo ' , template = ' f5 . http ' , parameters = parameters , state = ' present ' , password = ' passsword ' , server = ' localhost ' , user = ' admin ' ) ) NEW_LINE client = AnsibleF5Client ( argument_spec = self . spec . argument_spec , supports_check_mode = self . spec . supports_check_mode , f5_product_name = self . spec . f5_product_name ) NEW_LINE mm = ModuleManager ( client ) NEW_LINE # ▁ Override ▁ methods ▁ to ▁ force ▁ specific ▁ logic ▁ in ▁ the ▁ module ▁ to ▁ happen ENDCOM mm . exists = Mock ( return_value = False ) NEW_LINE mm . create_on_device = Mock ( return_value = True ) NEW_LINE results = mm . exec_module ( ) NEW_LINE assert results [ ' changed ' ] is True NEW_LINE DEDENT def test_update_agent_status_traps ( self , * args ) : NEW_LINE INDENT parameters = load_fixture ( ' update _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE set_module_args ( dict ( name = ' foo ' , template = ' f5 . http ' , parameters = parameters , state = ' present ' , password = ' passsword ' , server = ' localhost ' , user = ' admin ' ) ) NEW_LINE # ▁ Configure ▁ the ▁ parameters ▁ that ▁ would ▁ be ▁ returned ▁ by ▁ querying ▁ the ENDCOM # ▁ remote ▁ device ENDCOM parameters = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE current = Parameters ( parameters ) NEW_LINE client = AnsibleF5Client ( argument_spec = self . spec . argument_spec , supports_check_mode = self . spec . supports_check_mode , f5_product_name = self . spec . f5_product_name ) NEW_LINE mm = ModuleManager ( client ) NEW_LINE # ▁ Override ▁ methods ▁ to ▁ force ▁ specific ▁ logic ▁ in ▁ the ▁ module ▁ to ▁ happen ENDCOM mm . exists = Mock ( return_value = True ) NEW_LINE mm . update_on_device = Mock ( return_value = True ) NEW_LINE mm . read_current_from_device = Mock ( return_value = current ) NEW_LINE results = mm . exec_module ( ) NEW_LINE assert results [ ' changed ' ] is True NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="anas-taji/knowledge/tree/master/attachment_edit/models/ir_attachment.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ © ▁ 2015 ▁ Therp ▁ BV ▁ < http : / / therp . nl > ENDCOM # ▁ License ▁ AGPL - 3.0 ▁ or ▁ later ▁ ( http : / / www . gnu . org / licenses / agpl . html ) . ENDCOM # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM from openerp import models , fields , api NEW_LINE class IrAttachment ( models . Model ) : NEW_LINE INDENT _inherit = ' ir . attachment ' NEW_LINE res_reference = fields . Reference ( selection = ' _ selection _ res _ reference ' , string = ' Resource ▁ reference ' , compute = ' _ compute _ res _ reference ' , inverse = ' _ inverse _ res _ reference ' ) NEW_LINE @ api . one NEW_LINE @ api . depends ( ' res _ id ' , ' res _ model ' ) NEW_LINE def _compute_res_reference ( self ) : NEW_LINE INDENT if self . res_model and self . res_id : NEW_LINE INDENT self . res_reference = ' % s , % s ' % ( self . res_model , self . res_id ) NEW_LINE DEDENT DEDENT @ api . one NEW_LINE def _inverse_res_reference ( self ) : NEW_LINE INDENT if self . res_reference : NEW_LINE INDENT self . write ( { ' res _ model ' : self . res_reference . _model . _model , ' res _ id ' : self . res_reference . id , } ) NEW_LINE DEDENT else : NEW_LINE INDENT self . write ( { ' res _ model ' : False , ' res _ id ' : False } ) NEW_LINE DEDENT DEDENT @ api . model NEW_LINE def _selection_res_reference ( self ) : NEW_LINE INDENT return self . env [ ' ir . model ' ] . search ( [ ( ' osv _ memory ' , ' = ' , False ) , ( ' access _ ids . group _ id . users ' , ' = ' , self . env . uid ) ] ) . mapped ( lambda rec : ( rec . model , rec . name ) ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="bdupharm/sqlalchemy/tree/master/lib/sqlalchemy/ext/declarative/api.py"> # ▁ ext / declarative / api . py ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2005-2016 ▁ the ▁ SQLAlchemy ▁ authors ▁ and ▁ contributors ENDCOM # ▁ < see ▁ AUTHORS ▁ file > ENDCOM # ▁ This ▁ module ▁ is ▁ part ▁ of ▁ SQLAlchemy ▁ and ▁ is ▁ released ▁ under ENDCOM # ▁ the ▁ MIT ▁ License : ▁ http : / / www . opensource . org / licenses / mit - license . php ENDCOM """ Public ▁ API ▁ functions ▁ and ▁ helpers ▁ for ▁ declarative . """ NEW_LINE from ... schema import Table , MetaData , Column NEW_LINE from ... orm import synonym as _orm_synonym , comparable_property , interfaces , properties , attributes NEW_LINE from ... orm . util import polymorphic_union NEW_LINE from ... orm . base import _mapper_or_none NEW_LINE from ... util import OrderedDict , hybridmethod , hybridproperty NEW_LINE from ... import util NEW_LINE from ... import exc NEW_LINE import weakref NEW_LINE from . base import _as_declarative , _declarative_constructor , _DeferredMapperConfig , _add_attribute NEW_LINE from . clsregistry import _class_resolver NEW_LINE def instrument_declarative ( cls , registry , metadata ) : NEW_LINE INDENT """ Given ▁ a ▁ class , ▁ configure ▁ the ▁ class ▁ declaratively , STRNEWLINE ▁ using ▁ the ▁ given ▁ registry , ▁ which ▁ can ▁ be ▁ any ▁ dictionary , ▁ and STRNEWLINE ▁ MetaData ▁ object . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if ' _ decl _ class _ registry ' in cls . __dict__ : NEW_LINE INDENT raise exc . InvalidRequestError ( " Class ▁ % r ▁ already ▁ has ▁ been ▁ " " instrumented ▁ declaratively " % cls ) NEW_LINE DEDENT cls . _decl_class_registry = registry NEW_LINE cls . metadata = metadata NEW_LINE _as_declarative ( cls , cls . __name__ , cls . __dict__ ) NEW_LINE DEDENT def has_inherited_table ( cls ) : NEW_LINE INDENT """ Given ▁ a ▁ class , ▁ return ▁ True ▁ if ▁ any ▁ of ▁ the ▁ classes ▁ it ▁ inherits ▁ from ▁ has ▁ a STRNEWLINE ▁ mapped ▁ table , ▁ otherwise ▁ return ▁ False . STRNEWLINE ▁ """ NEW_LINE for class_ in cls . __mro__ [ 1 : ] : NEW_LINE INDENT if getattr ( class_ , ' _ _ table _ _ ' , None ) is not None : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT class DeclarativeMeta ( type ) : NEW_LINE INDENT def __init__ ( cls , classname , bases , dict_ ) : NEW_LINE INDENT if ' _ decl _ class _ registry ' not in cls . __dict__ : NEW_LINE INDENT _as_declarative ( cls , classname , cls . __dict__ ) NEW_LINE DEDENT type . __init__ ( cls , classname , bases , dict_ ) NEW_LINE DEDENT def __setattr__ ( cls , key , value ) : NEW_LINE INDENT _add_attribute ( cls , key , value ) NEW_LINE DEDENT DEDENT def synonym_for ( name , map_column = False ) : NEW_LINE INDENT """ Decorator , ▁ make ▁ a ▁ Python ▁ @ property ▁ a ▁ query ▁ synonym ▁ for ▁ a ▁ column . STRNEWLINE STRNEWLINE ▁ A ▁ decorator ▁ version ▁ of ▁ : func : ` ~ sqlalchemy . orm . synonym ` . ▁ The ▁ function ▁ being STRNEWLINE ▁ decorated ▁ is ▁ the ▁ ' descriptor ' , ▁ otherwise ▁ passes ▁ its ▁ arguments ▁ through ▁ to STRNEWLINE ▁ synonym ( ) : : STRNEWLINE STRNEWLINE ▁ @ synonym _ for ( ' col ' ) STRNEWLINE ▁ @ property STRNEWLINE ▁ def ▁ prop ( self ) : STRNEWLINE ▁ return ▁ ' special ▁ sauce ' STRNEWLINE STRNEWLINE ▁ The ▁ regular ▁ ` ` synonym ( ) ` ` ▁ is ▁ also ▁ usable ▁ directly ▁ in ▁ a ▁ declarative ▁ setting STRNEWLINE ▁ and ▁ may ▁ be ▁ convenient ▁ for ▁ read / write ▁ properties : : STRNEWLINE STRNEWLINE ▁ prop ▁ = ▁ synonym ( ' col ' , ▁ descriptor = property ( _ read _ prop , ▁ _ write _ prop ) ) STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def decorate ( fn ) : NEW_LINE INDENT return _orm_synonym ( name , map_column = map_column , descriptor = fn ) NEW_LINE DEDENT return decorate NEW_LINE DEDENT def comparable_using ( comparator_factory ) : NEW_LINE INDENT """ Decorator , ▁ allow ▁ a ▁ Python ▁ @ property ▁ to ▁ be ▁ used ▁ in ▁ query ▁ criteria . STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ a ▁ decorator ▁ front ▁ end ▁ to STRNEWLINE ▁ : func : ` ~ sqlalchemy . orm . comparable _ property ` ▁ that ▁ passes STRNEWLINE ▁ through ▁ the ▁ comparator _ factory ▁ and ▁ the ▁ function ▁ being ▁ decorated : : STRNEWLINE STRNEWLINE ▁ @ comparable _ using ( MyComparatorType ) STRNEWLINE ▁ @ property STRNEWLINE ▁ def ▁ prop ( self ) : STRNEWLINE ▁ return ▁ ' special ▁ sauce ' STRNEWLINE STRNEWLINE ▁ The ▁ regular ▁ ` ` comparable _ property ( ) ` ` ▁ is ▁ also ▁ usable ▁ directly ▁ in ▁ a STRNEWLINE ▁ declarative ▁ setting ▁ and ▁ may ▁ be ▁ convenient ▁ for ▁ read / write ▁ properties : : STRNEWLINE STRNEWLINE ▁ prop ▁ = ▁ comparable _ property ( MyComparatorType ) STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def decorate ( fn ) : NEW_LINE INDENT return comparable_property ( comparator_factory , fn ) NEW_LINE DEDENT return decorate NEW_LINE DEDENT class declared_attr ( interfaces . _MappedAttribute , property ) : NEW_LINE INDENT """ Mark ▁ a ▁ class - level ▁ method ▁ as ▁ representing ▁ the ▁ definition ▁ of STRNEWLINE ▁ a ▁ mapped ▁ property ▁ or ▁ special ▁ declarative ▁ member ▁ name . STRNEWLINE STRNEWLINE ▁ @ declared _ attr ▁ turns ▁ the ▁ attribute ▁ into ▁ a ▁ scalar - like STRNEWLINE ▁ property ▁ that ▁ can ▁ be ▁ invoked ▁ from ▁ the ▁ uninstantiated ▁ class . STRNEWLINE ▁ Declarative ▁ treats ▁ attributes ▁ specifically ▁ marked ▁ with STRNEWLINE ▁ @ declared _ attr ▁ as ▁ returning ▁ a ▁ construct ▁ that ▁ is ▁ specific STRNEWLINE ▁ to ▁ mapping ▁ or ▁ declarative ▁ table ▁ configuration . ▁ The ▁ name STRNEWLINE ▁ of ▁ the ▁ attribute ▁ is ▁ that ▁ of ▁ what ▁ the ▁ non - dynamic ▁ version STRNEWLINE ▁ of ▁ the ▁ attribute ▁ would ▁ be . STRNEWLINE STRNEWLINE ▁ @ declared _ attr ▁ is ▁ more ▁ often ▁ than ▁ not ▁ applicable ▁ to ▁ mixins , STRNEWLINE ▁ to ▁ define ▁ relationships ▁ that ▁ are ▁ to ▁ be ▁ applied ▁ to ▁ different STRNEWLINE ▁ implementors ▁ of ▁ the ▁ class : : STRNEWLINE STRNEWLINE ▁ class ▁ ProvidesUser ( object ) : STRNEWLINE ▁ " A ▁ mixin ▁ that ▁ adds ▁ a ▁ ' user ' ▁ relationship ▁ to ▁ classes . " STRNEWLINE STRNEWLINE ▁ @ declared _ attr STRNEWLINE ▁ def ▁ user ( self ) : STRNEWLINE ▁ return ▁ relationship ( " User " ) STRNEWLINE STRNEWLINE ▁ It ▁ also ▁ can ▁ be ▁ applied ▁ to ▁ mapped ▁ classes , ▁ such ▁ as ▁ to ▁ provide STRNEWLINE ▁ a ▁ " polymorphic " ▁ scheme ▁ for ▁ inheritance : : STRNEWLINE STRNEWLINE ▁ class ▁ Employee ( Base ) : STRNEWLINE ▁ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE ▁ type ▁ = ▁ Column ( String ( 50 ) , ▁ nullable = False ) STRNEWLINE STRNEWLINE ▁ @ declared _ attr STRNEWLINE ▁ def ▁ _ _ tablename _ _ ( cls ) : STRNEWLINE ▁ return ▁ cls . _ _ name _ _ . lower ( ) STRNEWLINE STRNEWLINE ▁ @ declared _ attr STRNEWLINE ▁ def ▁ _ _ mapper _ args _ _ ( cls ) : STRNEWLINE ▁ if ▁ cls . _ _ name _ _ ▁ = = ▁ ' Employee ' : STRNEWLINE ▁ return ▁ { STRNEWLINE ▁ " polymorphic _ on " : cls . type , STRNEWLINE ▁ " polymorphic _ identity " : " Employee " STRNEWLINE ▁ } STRNEWLINE ▁ else : STRNEWLINE ▁ return ▁ { " polymorphic _ identity " : cls . _ _ name _ _ } STRNEWLINE STRNEWLINE ▁ . . ▁ versionchanged : : ▁ 0.8 ▁ : class : ` . declared _ attr ` ▁ can ▁ be ▁ used ▁ with STRNEWLINE ▁ non - ORM ▁ or ▁ extension ▁ attributes , ▁ such ▁ as ▁ user - defined ▁ attributes STRNEWLINE ▁ or ▁ : func : ` . association _ proxy ` ▁ objects , ▁ which ▁ will ▁ be ▁ assigned STRNEWLINE ▁ to ▁ the ▁ class ▁ at ▁ class ▁ construction ▁ time . STRNEWLINE STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , fget , cascading = False ) : NEW_LINE INDENT super ( declared_attr , self ) . __init__ ( fget ) NEW_LINE self . __doc__ = fget . __doc__ NEW_LINE self . _cascading = cascading NEW_LINE DEDENT def __get__ ( desc , self , cls ) : NEW_LINE INDENT reg = cls . __dict__ . get ( ' _ sa _ declared _ attr _ reg ' , None ) NEW_LINE if reg is None : NEW_LINE INDENT manager = attributes . manager_of_class ( cls ) NEW_LINE if manager is None : NEW_LINE INDENT util . warn ( " Unmanaged ▁ access ▁ of ▁ declarative ▁ attribute ▁ % s ▁ from ▁ " " non - mapped ▁ class ▁ % s " % ( desc . fget . __name__ , cls . __name__ ) ) NEW_LINE DEDENT return desc . fget ( cls ) NEW_LINE DEDENT if reg is None : NEW_LINE INDENT return desc . fget ( cls ) NEW_LINE DEDENT elif desc in reg : NEW_LINE INDENT return reg [ desc ] NEW_LINE DEDENT else : NEW_LINE INDENT reg [ desc ] = obj = desc . fget ( cls ) NEW_LINE return obj NEW_LINE DEDENT DEDENT @ hybridmethod NEW_LINE def _stateful ( cls , ** kw ) : NEW_LINE INDENT return _stateful_declared_attr ( ** kw ) NEW_LINE DEDENT @ hybridproperty NEW_LINE def cascading ( cls ) : NEW_LINE INDENT """ Mark ▁ a ▁ : class : ` . declared _ attr ` ▁ as ▁ cascading . STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ a ▁ special - use ▁ modifier ▁ which ▁ indicates ▁ that ▁ a ▁ column STRNEWLINE ▁ or ▁ MapperProperty - based ▁ declared ▁ attribute ▁ should ▁ be ▁ configured STRNEWLINE ▁ distinctly ▁ per ▁ mapped ▁ subclass , ▁ within ▁ a ▁ mapped - inheritance ▁ scenario . STRNEWLINE STRNEWLINE ▁ Below , ▁ both ▁ MyClass ▁ as ▁ well ▁ as ▁ MySubClass ▁ will ▁ have ▁ a ▁ distinct STRNEWLINE ▁ ` ` id ` ` ▁ Column ▁ object ▁ established : : STRNEWLINE STRNEWLINE ▁ class ▁ HasSomeAttribute ( object ) : STRNEWLINE ▁ @ declared _ attr . cascading STRNEWLINE ▁ def ▁ some _ id ( cls ) : STRNEWLINE ▁ if ▁ has _ inherited _ table ( cls ) : STRNEWLINE ▁ return ▁ Column ( STRNEWLINE ▁ ForeignKey ( ' myclass . id ' ) , ▁ primary _ key = True ) STRNEWLINE ▁ else : STRNEWLINE ▁ return ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE STRNEWLINE ▁ return ▁ Column ( ' id ' , ▁ Integer , ▁ primary _ key = True ) STRNEWLINE STRNEWLINE ▁ class ▁ MyClass ( HasSomeAttribute , ▁ Base ) : STRNEWLINE ▁ " " STRNEWLINE ▁ # ▁ . . . STRNEWLINE STRNEWLINE ▁ class ▁ MySubClass ( MyClass ) : STRNEWLINE ▁ " " STRNEWLINE ▁ # ▁ . . . STRNEWLINE STRNEWLINE ▁ The ▁ behavior ▁ of ▁ the ▁ above ▁ configuration ▁ is ▁ that ▁ ` ` MySubClass ` ` STRNEWLINE ▁ will ▁ refer ▁ to ▁ both ▁ its ▁ own ▁ ` ` id ` ` ▁ column ▁ as ▁ well ▁ as ▁ that ▁ of STRNEWLINE ▁ ` ` MyClass ` ` ▁ underneath ▁ the ▁ attribute ▁ named ▁ ` ` some _ id ` ` . STRNEWLINE STRNEWLINE ▁ . . ▁ seealso : : STRNEWLINE STRNEWLINE ▁ : ref : ` declarative _ inheritance ` STRNEWLINE STRNEWLINE ▁ : ref : ` mixin _ inheritance _ columns ` STRNEWLINE STRNEWLINE STRNEWLINE ▁ """ NEW_LINE return cls . _stateful ( cascading = True ) NEW_LINE DEDENT DEDENT class _stateful_declared_attr ( declared_attr ) : NEW_LINE INDENT def __init__ ( self , ** kw ) : NEW_LINE INDENT self . kw = kw NEW_LINE DEDENT def _stateful ( self , ** kw ) : NEW_LINE INDENT new_kw = self . kw . copy ( ) NEW_LINE new_kw . update ( kw ) NEW_LINE return _stateful_declared_attr ( ** new_kw ) NEW_LINE DEDENT def __call__ ( self , fn ) : NEW_LINE INDENT return declared_attr ( fn , ** self . kw ) NEW_LINE DEDENT DEDENT def declarative_base ( bind = None , metadata = None , mapper = None , cls = object , name = ' Base ' , constructor = _declarative_constructor , class_registry = None , metaclass = DeclarativeMeta ) : NEW_LINE INDENT """ Construct ▁ a ▁ base ▁ class ▁ for ▁ declarative ▁ class ▁ definitions . STRNEWLINE STRNEWLINE ▁ The ▁ new ▁ base ▁ class ▁ will ▁ be ▁ given ▁ a ▁ metaclass ▁ that ▁ produces STRNEWLINE ▁ appropriate ▁ : class : ` ~ sqlalchemy . schema . Table ` ▁ objects ▁ and ▁ makes STRNEWLINE ▁ the ▁ appropriate ▁ : func : ` ~ sqlalchemy . orm . mapper ` ▁ calls ▁ based ▁ on ▁ the STRNEWLINE ▁ information ▁ provided ▁ declaratively ▁ in ▁ the ▁ class ▁ and ▁ any ▁ subclasses STRNEWLINE ▁ of ▁ the ▁ class . STRNEWLINE STRNEWLINE ▁ : param ▁ bind : ▁ An ▁ optional STRNEWLINE ▁ : class : ` ~ sqlalchemy . engine . Connectable ` , ▁ will ▁ be ▁ assigned STRNEWLINE ▁ the ▁ ` ` bind ` ` ▁ attribute ▁ on ▁ the ▁ : class : ` ~ sqlalchemy . schema . MetaData ` STRNEWLINE ▁ instance . STRNEWLINE STRNEWLINE ▁ : param ▁ metadata : STRNEWLINE ▁ An ▁ optional ▁ : class : ` ~ sqlalchemy . schema . MetaData ` ▁ instance . ▁ All STRNEWLINE ▁ : class : ` ~ sqlalchemy . schema . Table ` ▁ objects ▁ implicitly ▁ declared ▁ by STRNEWLINE ▁ subclasses ▁ of ▁ the ▁ base ▁ will ▁ share ▁ this ▁ MetaData . ▁ A ▁ MetaData ▁ instance STRNEWLINE ▁ will ▁ be ▁ created ▁ if ▁ none ▁ is ▁ provided . ▁ The STRNEWLINE ▁ : class : ` ~ sqlalchemy . schema . MetaData ` ▁ instance ▁ will ▁ be ▁ available ▁ via ▁ the STRNEWLINE ▁ ` metadata ` ▁ attribute ▁ of ▁ the ▁ generated ▁ declarative ▁ base ▁ class . STRNEWLINE STRNEWLINE ▁ : param ▁ mapper : STRNEWLINE ▁ An ▁ optional ▁ callable , ▁ defaults ▁ to ▁ : func : ` ~ sqlalchemy . orm . mapper ` . ▁ Will STRNEWLINE ▁ be ▁ used ▁ to ▁ map ▁ subclasses ▁ to ▁ their ▁ Tables . STRNEWLINE STRNEWLINE ▁ : param ▁ cls : STRNEWLINE ▁ Defaults ▁ to ▁ : class : ` object ` . ▁ A ▁ type ▁ to ▁ use ▁ as ▁ the ▁ base ▁ for ▁ the ▁ generated STRNEWLINE ▁ declarative ▁ base ▁ class . ▁ May ▁ be ▁ a ▁ class ▁ or ▁ tuple ▁ of ▁ classes . STRNEWLINE STRNEWLINE ▁ : param ▁ name : STRNEWLINE ▁ Defaults ▁ to ▁ ` ` Base ` ` . ▁ The ▁ display ▁ name ▁ for ▁ the ▁ generated STRNEWLINE ▁ class . ▁ Customizing ▁ this ▁ is ▁ not ▁ required , ▁ but ▁ can ▁ improve ▁ clarity ▁ in STRNEWLINE ▁ tracebacks ▁ and ▁ debugging . STRNEWLINE STRNEWLINE ▁ : param ▁ constructor : STRNEWLINE ▁ Defaults ▁ to STRNEWLINE ▁ : func : ` ~ sqlalchemy . ext . declarative . _ declarative _ constructor ` , ▁ an STRNEWLINE ▁ _ _ init _ _ ▁ implementation ▁ that ▁ assigns ▁ \ * * kwargs ▁ for ▁ declared STRNEWLINE ▁ fields ▁ and ▁ relationships ▁ to ▁ an ▁ instance . ▁ If ▁ ` ` None ` ` ▁ is ▁ supplied , STRNEWLINE ▁ no ▁ _ _ init _ _ ▁ will ▁ be ▁ provided ▁ and ▁ construction ▁ will ▁ fall ▁ back ▁ to STRNEWLINE ▁ cls . _ _ init _ _ ▁ by ▁ way ▁ of ▁ the ▁ normal ▁ Python ▁ semantics . STRNEWLINE STRNEWLINE ▁ : param ▁ class _ registry : ▁ optional ▁ dictionary ▁ that ▁ will ▁ serve ▁ as ▁ the STRNEWLINE ▁ registry ▁ of ▁ class ▁ names - > ▁ mapped ▁ classes ▁ when ▁ string ▁ names STRNEWLINE ▁ are ▁ used ▁ to ▁ identify ▁ classes ▁ inside ▁ of ▁ : func : ` . relationship ` STRNEWLINE ▁ and ▁ others . ▁ Allows ▁ two ▁ or ▁ more ▁ declarative ▁ base ▁ classes STRNEWLINE ▁ to ▁ share ▁ the ▁ same ▁ registry ▁ of ▁ class ▁ names ▁ for ▁ simplified STRNEWLINE ▁ inter - base ▁ relationships . STRNEWLINE STRNEWLINE ▁ : param ▁ metaclass : STRNEWLINE ▁ Defaults ▁ to ▁ : class : ` . DeclarativeMeta ` . ▁ A ▁ metaclass ▁ or ▁ _ _ metaclass _ _ STRNEWLINE ▁ compatible ▁ callable ▁ to ▁ use ▁ as ▁ the ▁ meta ▁ type ▁ of ▁ the ▁ generated STRNEWLINE ▁ declarative ▁ base ▁ class . STRNEWLINE STRNEWLINE ▁ . . ▁ seealso : : STRNEWLINE STRNEWLINE ▁ : func : ` . as _ declarative ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE lcl_metadata = metadata or MetaData ( ) NEW_LINE if bind : NEW_LINE INDENT lcl_metadata . bind = bind NEW_LINE DEDENT if class_registry is None : NEW_LINE INDENT class_registry = weakref . WeakValueDictionary ( ) NEW_LINE DEDENT bases = not isinstance ( cls , tuple ) and ( cls , ) or cls NEW_LINE class_dict = dict ( _decl_class_registry = class_registry , metadata = lcl_metadata ) NEW_LINE if constructor : NEW_LINE INDENT class_dict [ ' _ _ init _ _ ' ] = constructor NEW_LINE DEDENT if mapper : NEW_LINE INDENT class_dict [ ' _ _ mapper _ cls _ _ ' ] = mapper NEW_LINE DEDENT return metaclass ( name , bases , class_dict ) NEW_LINE DEDENT def as_declarative ( ** kw ) : NEW_LINE INDENT """ STRNEWLINE ▁ Class ▁ decorator ▁ for ▁ : func : ` . declarative _ base ` . STRNEWLINE STRNEWLINE ▁ Provides ▁ a ▁ syntactical ▁ shortcut ▁ to ▁ the ▁ ` ` cls ` ` ▁ argument STRNEWLINE ▁ sent ▁ to ▁ : func : ` . declarative _ base ` , ▁ allowing ▁ the ▁ base ▁ class STRNEWLINE ▁ to ▁ be ▁ converted ▁ in - place ▁ to ▁ a ▁ " declarative " ▁ base : : STRNEWLINE STRNEWLINE ▁ from ▁ sqlalchemy . ext . declarative ▁ import ▁ as _ declarative STRNEWLINE STRNEWLINE ▁ @ as _ declarative ( ) STRNEWLINE ▁ class ▁ Base ( object ) : STRNEWLINE ▁ @ declared _ attr STRNEWLINE ▁ def ▁ _ _ tablename _ _ ( cls ) : STRNEWLINE ▁ return ▁ cls . _ _ name _ _ . lower ( ) STRNEWLINE ▁ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE STRNEWLINE ▁ class ▁ MyMappedClass ( Base ) : STRNEWLINE ▁ # ▁ . . . STRNEWLINE STRNEWLINE ▁ All ▁ keyword ▁ arguments ▁ passed ▁ to ▁ : func : ` . as _ declarative ` ▁ are ▁ passed STRNEWLINE ▁ along ▁ to ▁ : func : ` . declarative _ base ` . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 0.8.3 STRNEWLINE STRNEWLINE ▁ . . ▁ seealso : : STRNEWLINE STRNEWLINE ▁ : func : ` . declarative _ base ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def decorate ( cls ) : NEW_LINE INDENT kw [ ' cls ' ] = cls NEW_LINE kw [ ' name ' ] = cls . __name__ NEW_LINE return declarative_base ( ** kw ) NEW_LINE DEDENT return decorate NEW_LINE DEDENT class ConcreteBase ( object ) : NEW_LINE INDENT """ A ▁ helper ▁ class ▁ for ▁ ' concrete ' ▁ declarative ▁ mappings . STRNEWLINE STRNEWLINE ▁ : class : ` . ConcreteBase ` ▁ will ▁ use ▁ the ▁ : func : ` . polymorphic _ union ` STRNEWLINE ▁ function ▁ automatically , ▁ against ▁ all ▁ tables ▁ mapped ▁ as ▁ a ▁ subclass STRNEWLINE ▁ to ▁ this ▁ class . ▁ The ▁ function ▁ is ▁ called ▁ via ▁ the STRNEWLINE ▁ ` ` _ _ declare _ last _ _ ( ) ` ` ▁ function , ▁ which ▁ is ▁ essentially STRNEWLINE ▁ a ▁ hook ▁ for ▁ the ▁ : meth : ` . after _ configured ` ▁ event . STRNEWLINE STRNEWLINE ▁ : class : ` . ConcreteBase ` ▁ produces ▁ a ▁ mapped STRNEWLINE ▁ table ▁ for ▁ the ▁ class ▁ itself . ▁ Compare ▁ to ▁ : class : ` . AbstractConcreteBase ` , STRNEWLINE ▁ which ▁ does ▁ not . STRNEWLINE STRNEWLINE ▁ Example : : STRNEWLINE STRNEWLINE ▁ from ▁ sqlalchemy . ext . declarative ▁ import ▁ ConcreteBase STRNEWLINE STRNEWLINE ▁ class ▁ Employee ( ConcreteBase , ▁ Base ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' employee ' STRNEWLINE ▁ employee _ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE ▁ name ▁ = ▁ Column ( String ( 50 ) ) STRNEWLINE ▁ _ _ mapper _ args _ _ ▁ = ▁ { STRNEWLINE ▁ ' polymorphic _ identity ' : ' employee ' , STRNEWLINE ▁ ' concrete ' : True } STRNEWLINE STRNEWLINE ▁ class ▁ Manager ( Employee ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' manager ' STRNEWLINE ▁ employee _ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE ▁ name ▁ = ▁ Column ( String ( 50 ) ) STRNEWLINE ▁ manager _ data ▁ = ▁ Column ( String ( 40 ) ) STRNEWLINE ▁ _ _ mapper _ args _ _ ▁ = ▁ { STRNEWLINE ▁ ' polymorphic _ identity ' : ' manager ' , STRNEWLINE ▁ ' concrete ' : True } STRNEWLINE STRNEWLINE ▁ . . ▁ seealso : : STRNEWLINE STRNEWLINE ▁ : class : ` . AbstractConcreteBase ` STRNEWLINE STRNEWLINE ▁ : ref : ` concrete _ inheritance ` STRNEWLINE STRNEWLINE ▁ : ref : ` inheritance _ concrete _ helpers ` STRNEWLINE STRNEWLINE STRNEWLINE ▁ """ NEW_LINE @ classmethod NEW_LINE def _create_polymorphic_union ( cls , mappers ) : NEW_LINE INDENT return polymorphic_union ( OrderedDict ( ( mp . polymorphic_identity , mp . local_table ) for mp in mappers ) , ' type ' , ' pjoin ' ) NEW_LINE DEDENT @ classmethod NEW_LINE def __declare_first__ ( cls ) : NEW_LINE INDENT m = cls . __mapper__ NEW_LINE if m . with_polymorphic : NEW_LINE INDENT return NEW_LINE DEDENT mappers = list ( m . self_and_descendants ) NEW_LINE pjoin = cls . _create_polymorphic_union ( mappers ) NEW_LINE m . _set_with_polymorphic ( ( " * " , pjoin ) ) NEW_LINE m . _set_polymorphic_on ( pjoin . c . type ) NEW_LINE DEDENT DEDENT class AbstractConcreteBase ( ConcreteBase ) : NEW_LINE INDENT """ A ▁ helper ▁ class ▁ for ▁ ' concrete ' ▁ declarative ▁ mappings . STRNEWLINE STRNEWLINE ▁ : class : ` . AbstractConcreteBase ` ▁ will ▁ use ▁ the ▁ : func : ` . polymorphic _ union ` STRNEWLINE ▁ function ▁ automatically , ▁ against ▁ all ▁ tables ▁ mapped ▁ as ▁ a ▁ subclass STRNEWLINE ▁ to ▁ this ▁ class . ▁ The ▁ function ▁ is ▁ called ▁ via ▁ the STRNEWLINE ▁ ` ` _ _ declare _ last _ _ ( ) ` ` ▁ function , ▁ which ▁ is ▁ essentially STRNEWLINE ▁ a ▁ hook ▁ for ▁ the ▁ : meth : ` . after _ configured ` ▁ event . STRNEWLINE STRNEWLINE ▁ : class : ` . AbstractConcreteBase ` ▁ does ▁ produce ▁ a ▁ mapped ▁ class STRNEWLINE ▁ for ▁ the ▁ base ▁ class , ▁ however ▁ it ▁ is ▁ not ▁ persisted ▁ to ▁ any ▁ table ; ▁ it STRNEWLINE ▁ is ▁ instead ▁ mapped ▁ directly ▁ to ▁ the ▁ " polymorphic " ▁ selectable ▁ directly STRNEWLINE ▁ and ▁ is ▁ only ▁ used ▁ for ▁ selecting . ▁ Compare ▁ to ▁ : class : ` . ConcreteBase ` , STRNEWLINE ▁ which ▁ does ▁ create ▁ a ▁ persisted ▁ table ▁ for ▁ the ▁ base ▁ class . STRNEWLINE STRNEWLINE ▁ Example : : STRNEWLINE STRNEWLINE ▁ from ▁ sqlalchemy . ext . declarative ▁ import ▁ AbstractConcreteBase STRNEWLINE STRNEWLINE ▁ class ▁ Employee ( AbstractConcreteBase , ▁ Base ) : STRNEWLINE ▁ pass STRNEWLINE STRNEWLINE ▁ class ▁ Manager ( Employee ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' manager ' STRNEWLINE ▁ employee _ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE ▁ name ▁ = ▁ Column ( String ( 50 ) ) STRNEWLINE ▁ manager _ data ▁ = ▁ Column ( String ( 40 ) ) STRNEWLINE STRNEWLINE ▁ _ _ mapper _ args _ _ ▁ = ▁ { STRNEWLINE ▁ ' polymorphic _ identity ' : ' manager ' , STRNEWLINE ▁ ' concrete ' : True } STRNEWLINE STRNEWLINE ▁ The ▁ abstract ▁ base ▁ class ▁ is ▁ handled ▁ by ▁ declarative ▁ in ▁ a ▁ special ▁ way ; STRNEWLINE ▁ at ▁ class ▁ configuration ▁ time , ▁ it ▁ behaves ▁ like ▁ a ▁ declarative ▁ mixin STRNEWLINE ▁ or ▁ an ▁ ` ` _ _ abstract _ _ ` ` ▁ base ▁ class . ▁ Once ▁ classes ▁ are ▁ configured STRNEWLINE ▁ and ▁ mappings ▁ are ▁ produced , ▁ it ▁ then ▁ gets ▁ mapped ▁ itself , ▁ but STRNEWLINE ▁ after ▁ all ▁ of ▁ its ▁ decscendants . ▁ This ▁ is ▁ a ▁ very ▁ unique ▁ system ▁ of ▁ mapping STRNEWLINE ▁ not ▁ found ▁ in ▁ any ▁ other ▁ SQLAlchemy ▁ system . STRNEWLINE STRNEWLINE ▁ Using ▁ this ▁ approach , ▁ we ▁ can ▁ specify ▁ columns ▁ and ▁ properties STRNEWLINE ▁ that ▁ will ▁ take ▁ place ▁ on ▁ mapped ▁ subclasses , ▁ in ▁ the ▁ way ▁ that STRNEWLINE ▁ we ▁ normally ▁ do ▁ as ▁ in ▁ : ref : ` declarative _ mixins ` : : STRNEWLINE STRNEWLINE ▁ class ▁ Company ( Base ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' company ' STRNEWLINE ▁ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE STRNEWLINE ▁ class ▁ Employee ( AbstractConcreteBase , ▁ Base ) : STRNEWLINE ▁ employee _ id ▁ = ▁ Column ( Integer , ▁ primary _ key = True ) STRNEWLINE STRNEWLINE ▁ @ declared _ attr STRNEWLINE ▁ def ▁ company _ id ( cls ) : STRNEWLINE ▁ return ▁ Column ( ForeignKey ( ' company . id ' ) ) STRNEWLINE STRNEWLINE ▁ @ declared _ attr STRNEWLINE ▁ def ▁ company ( cls ) : STRNEWLINE ▁ return ▁ relationship ( " Company " ) STRNEWLINE STRNEWLINE ▁ class ▁ Manager ( Employee ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' manager ' STRNEWLINE STRNEWLINE ▁ name ▁ = ▁ Column ( String ( 50 ) ) STRNEWLINE ▁ manager _ data ▁ = ▁ Column ( String ( 40 ) ) STRNEWLINE STRNEWLINE ▁ _ _ mapper _ args _ _ ▁ = ▁ { STRNEWLINE ▁ ' polymorphic _ identity ' : ' manager ' , STRNEWLINE ▁ ' concrete ' : True } STRNEWLINE STRNEWLINE ▁ When ▁ we ▁ make ▁ use ▁ of ▁ our ▁ mappings ▁ however , ▁ both ▁ ` ` Manager ` ` ▁ and STRNEWLINE ▁ ` ` Employee ` ` ▁ will ▁ have ▁ an ▁ independently ▁ usable ▁ ` ` . company ` ` ▁ attribute : : STRNEWLINE STRNEWLINE ▁ session . query ( Employee ) . filter ( Employee . company . has ( id = 5 ) ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionchanged : : ▁ 1.0.0 ▁ - ▁ The ▁ mechanics ▁ of ▁ : class : ` . AbstractConcreteBase ` STRNEWLINE ▁ have ▁ been ▁ reworked ▁ to ▁ support ▁ relationships ▁ established ▁ directly STRNEWLINE ▁ on ▁ the ▁ abstract ▁ base , ▁ without ▁ any ▁ special ▁ configurational ▁ steps . STRNEWLINE STRNEWLINE ▁ . . ▁ seealso : : STRNEWLINE STRNEWLINE ▁ : class : ` . ConcreteBase ` STRNEWLINE STRNEWLINE ▁ : ref : ` concrete _ inheritance ` STRNEWLINE STRNEWLINE ▁ : ref : ` inheritance _ concrete _ helpers ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE __no_table__ = True NEW_LINE @ classmethod NEW_LINE def __declare_first__ ( cls ) : NEW_LINE INDENT cls . _sa_decl_prepare_nocascade ( ) NEW_LINE DEDENT @ classmethod NEW_LINE def _sa_decl_prepare_nocascade ( cls ) : NEW_LINE INDENT if getattr ( cls , ' _ _ mapper _ _ ' , None ) : NEW_LINE INDENT return NEW_LINE DEDENT to_map = _DeferredMapperConfig . config_for_cls ( cls ) NEW_LINE # ▁ can ' t ▁ rely ▁ on ▁ ' self _ and _ descendants ' ▁ here ENDCOM # ▁ since ▁ technically ▁ an ▁ immediate ▁ subclass ENDCOM # ▁ might ▁ not ▁ be ▁ mapped , ▁ but ▁ a ▁ subclass ENDCOM # ▁ may ▁ be . ENDCOM mappers = [ ] NEW_LINE stack = list ( cls . __subclasses__ ( ) ) NEW_LINE while stack : NEW_LINE INDENT klass = stack . pop ( ) NEW_LINE stack . extend ( klass . __subclasses__ ( ) ) NEW_LINE mn = _mapper_or_none ( klass ) NEW_LINE if mn is not None : NEW_LINE INDENT mappers . append ( mn ) NEW_LINE DEDENT DEDENT pjoin = cls . _create_polymorphic_union ( mappers ) NEW_LINE # ▁ For ▁ columns ▁ that ▁ were ▁ declared ▁ on ▁ the ▁ class , ▁ these ENDCOM # ▁ are ▁ normally ▁ ignored ▁ with ▁ the ▁ " _ _ no _ table _ _ " ▁ mapping , ENDCOM # ▁ unless ▁ they ▁ have ▁ a ▁ different ▁ attribute ▁ key ▁ vs . ▁ col ▁ name ENDCOM # ▁ and ▁ are ▁ in ▁ the ▁ properties ▁ argument . ENDCOM # ▁ In ▁ that ▁ case , ▁ ensure ▁ we ▁ update ▁ the ▁ properties ▁ entry ENDCOM # ▁ to ▁ the ▁ correct ▁ column ▁ from ▁ the ▁ pjoin ▁ target ▁ table . ENDCOM declared_cols = set ( to_map . declared_columns ) NEW_LINE for k , v in list ( to_map . properties . items ( ) ) : NEW_LINE INDENT if v in declared_cols : NEW_LINE INDENT to_map . properties [ k ] = pjoin . c [ v . key ] NEW_LINE DEDENT DEDENT to_map . local_table = pjoin NEW_LINE m_args = to_map . mapper_args_fn or dict NEW_LINE def mapper_args ( ) : NEW_LINE INDENT args = m_args ( ) NEW_LINE args [ ' polymorphic _ on ' ] = pjoin . c . type NEW_LINE return args NEW_LINE DEDENT to_map . mapper_args_fn = mapper_args NEW_LINE m = to_map . map ( ) NEW_LINE for scls in cls . __subclasses__ ( ) : NEW_LINE INDENT sm = _mapper_or_none ( scls ) NEW_LINE if sm and sm . concrete and cls in scls . __bases__ : NEW_LINE INDENT sm . _set_concrete_base ( m ) NEW_LINE DEDENT DEDENT DEDENT DEDENT class DeferredReflection ( object ) : NEW_LINE INDENT """ A ▁ helper ▁ class ▁ for ▁ construction ▁ of ▁ mappings ▁ based ▁ on STRNEWLINE ▁ a ▁ deferred ▁ reflection ▁ step . STRNEWLINE STRNEWLINE ▁ Normally , ▁ declarative ▁ can ▁ be ▁ used ▁ with ▁ reflection ▁ by STRNEWLINE ▁ setting ▁ a ▁ : class : ` . Table ` ▁ object ▁ using ▁ autoload = True STRNEWLINE ▁ as ▁ the ▁ ` ` _ _ table _ _ ` ` ▁ attribute ▁ on ▁ a ▁ declarative ▁ class . STRNEWLINE ▁ The ▁ caveat ▁ is ▁ that ▁ the ▁ : class : ` . Table ` ▁ must ▁ be ▁ fully STRNEWLINE ▁ reflected , ▁ or ▁ at ▁ the ▁ very ▁ least ▁ have ▁ a ▁ primary ▁ key ▁ column , STRNEWLINE ▁ at ▁ the ▁ point ▁ at ▁ which ▁ a ▁ normal ▁ declarative ▁ mapping ▁ is STRNEWLINE ▁ constructed , ▁ meaning ▁ the ▁ : class : ` . Engine ` ▁ must ▁ be ▁ available STRNEWLINE ▁ at ▁ class ▁ declaration ▁ time . STRNEWLINE STRNEWLINE ▁ The ▁ : class : ` . DeferredReflection ` ▁ mixin ▁ moves ▁ the ▁ construction STRNEWLINE ▁ of ▁ mappers ▁ to ▁ be ▁ at ▁ a ▁ later ▁ point , ▁ after ▁ a ▁ specific STRNEWLINE ▁ method ▁ is ▁ called ▁ which ▁ first ▁ reflects ▁ all ▁ : class : ` . Table ` STRNEWLINE ▁ objects ▁ created ▁ so ▁ far . ▁ Classes ▁ can ▁ define ▁ it ▁ as ▁ such : : STRNEWLINE STRNEWLINE ▁ from ▁ sqlalchemy . ext . declarative ▁ import ▁ declarative _ base STRNEWLINE ▁ from ▁ sqlalchemy . ext . declarative ▁ import ▁ DeferredReflection STRNEWLINE ▁ Base ▁ = ▁ declarative _ base ( ) STRNEWLINE STRNEWLINE ▁ class ▁ MyClass ( DeferredReflection , ▁ Base ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' mytable ' STRNEWLINE STRNEWLINE ▁ Above , ▁ ` ` MyClass ` ` ▁ is ▁ not ▁ yet ▁ mapped . ▁ After ▁ a ▁ series ▁ of STRNEWLINE ▁ classes ▁ have ▁ been ▁ defined ▁ in ▁ the ▁ above ▁ fashion , ▁ all ▁ tables STRNEWLINE ▁ can ▁ be ▁ reflected ▁ and ▁ mappings ▁ created ▁ using STRNEWLINE ▁ : meth : ` . prepare ` : : STRNEWLINE STRNEWLINE ▁ engine ▁ = ▁ create _ engine ( " someengine : / / . . . " ) STRNEWLINE ▁ DeferredReflection . prepare ( engine ) STRNEWLINE STRNEWLINE ▁ The ▁ : class : ` . DeferredReflection ` ▁ mixin ▁ can ▁ be ▁ applied ▁ to ▁ individual STRNEWLINE ▁ classes , ▁ used ▁ as ▁ the ▁ base ▁ for ▁ the ▁ declarative ▁ base ▁ itself , STRNEWLINE ▁ or ▁ used ▁ in ▁ a ▁ custom ▁ abstract ▁ class . ▁ Using ▁ an ▁ abstract ▁ base STRNEWLINE ▁ allows ▁ that ▁ only ▁ a ▁ subset ▁ of ▁ classes ▁ to ▁ be ▁ prepared ▁ for ▁ a STRNEWLINE ▁ particular ▁ prepare ▁ step , ▁ which ▁ is ▁ necessary ▁ for ▁ applications STRNEWLINE ▁ that ▁ use ▁ more ▁ than ▁ one ▁ engine . ▁ For ▁ example , ▁ if ▁ an ▁ application STRNEWLINE ▁ has ▁ two ▁ engines , ▁ you ▁ might ▁ use ▁ two ▁ bases , ▁ and ▁ prepare ▁ each STRNEWLINE ▁ separately , ▁ e . g . : : STRNEWLINE STRNEWLINE ▁ class ▁ ReflectedOne ( DeferredReflection , ▁ Base ) : STRNEWLINE ▁ _ _ abstract _ _ ▁ = ▁ True STRNEWLINE STRNEWLINE ▁ class ▁ ReflectedTwo ( DeferredReflection , ▁ Base ) : STRNEWLINE ▁ _ _ abstract _ _ ▁ = ▁ True STRNEWLINE STRNEWLINE ▁ class ▁ MyClass ( ReflectedOne ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' mytable ' STRNEWLINE STRNEWLINE ▁ class ▁ MyOtherClass ( ReflectedOne ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' myothertable ' STRNEWLINE STRNEWLINE ▁ class ▁ YetAnotherClass ( ReflectedTwo ) : STRNEWLINE ▁ _ _ tablename _ _ ▁ = ▁ ' yetanothertable ' STRNEWLINE STRNEWLINE ▁ # ▁ . . . ▁ etc . STRNEWLINE STRNEWLINE ▁ Above , ▁ the ▁ class ▁ hierarchies ▁ for ▁ ` ` ReflectedOne ` ` ▁ and STRNEWLINE ▁ ` ` ReflectedTwo ` ` ▁ can ▁ be ▁ configured ▁ separately : : STRNEWLINE STRNEWLINE ▁ ReflectedOne . prepare ( engine _ one ) STRNEWLINE ▁ ReflectedTwo . prepare ( engine _ two ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 0.8 STRNEWLINE STRNEWLINE ▁ """ NEW_LINE @ classmethod NEW_LINE def prepare ( cls , engine ) : NEW_LINE INDENT """ Reflect ▁ all ▁ : class : ` . Table ` ▁ objects ▁ for ▁ all ▁ current STRNEWLINE ▁ : class : ` . DeferredReflection ` ▁ subclasses """ NEW_LINE to_map = _DeferredMapperConfig . classes_for_base ( cls ) NEW_LINE for thingy in to_map : NEW_LINE INDENT cls . _sa_decl_prepare ( thingy . local_table , engine ) NEW_LINE thingy . map ( ) NEW_LINE mapper = thingy . cls . __mapper__ NEW_LINE metadata = mapper . class_ . metadata NEW_LINE for rel in mapper . _props . values ( ) : NEW_LINE INDENT if isinstance ( rel , properties . RelationshipProperty ) and rel . secondary is not None : NEW_LINE INDENT if isinstance ( rel . secondary , Table ) : NEW_LINE INDENT cls . _reflect_table ( rel . secondary , engine ) NEW_LINE DEDENT elif isinstance ( rel . secondary , _class_resolver ) : NEW_LINE INDENT rel . secondary . _resolvers += ( cls . _sa_deferred_table_resolver ( engine , metadata ) , ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT @ classmethod NEW_LINE def _sa_deferred_table_resolver ( cls , engine , metadata ) : NEW_LINE INDENT def _resolve ( key ) : NEW_LINE INDENT t1 = Table ( key , metadata ) NEW_LINE cls . _reflect_table ( t1 , engine ) NEW_LINE return t1 NEW_LINE DEDENT return _resolve NEW_LINE DEDENT @ classmethod NEW_LINE def _sa_decl_prepare ( cls , local_table , engine ) : NEW_LINE # ▁ autoload ▁ Table , ▁ which ▁ is ▁ already ENDCOM # ▁ present ▁ in ▁ the ▁ metadata . ▁ This ENDCOM # ▁ will ▁ fill ▁ in ▁ db - loaded ▁ columns ENDCOM # ▁ into ▁ the ▁ existing ▁ Table ▁ object . ENDCOM INDENT if local_table is not None : NEW_LINE INDENT cls . _reflect_table ( local_table , engine ) NEW_LINE DEDENT DEDENT @ classmethod NEW_LINE def _reflect_table ( cls , table , engine ) : NEW_LINE INDENT Table ( table . name , table . metadata , extend_existing = True , autoload_replace = False , autoload = True , autoload_with = engine , schema = table . schema ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="xboxfanj/android_kernel_htc_msm8974/tree/master/tools/perf/scripts/python/check-perf-trace.py"> # ▁ perf ▁ script ▁ event ▁ handlers , ▁ generated ▁ by ▁ perf ▁ script ▁ - g ▁ python ENDCOM # ▁ ( c ) ▁ 2010 , ▁ Tom ▁ Zanussi ▁ < tzanussi @ gmail . com > ENDCOM # ▁ Licensed ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ GPL ▁ License ▁ version ▁ 2 ENDCOM # ▁ This ▁ script ▁ tests ▁ basic ▁ functionality ▁ such ▁ as ▁ flag ▁ and ▁ symbol ENDCOM # ▁ strings , ▁ common _ xxx ( ) ▁ calls ▁ back ▁ into ▁ perf , ▁ begin , ▁ end , ▁ unhandled ENDCOM # ▁ events , ▁ etc . ▁ Basically , ▁ if ▁ this ▁ script ▁ runs ▁ successfully ▁ and ENDCOM # ▁ displays ▁ expected ▁ results , ▁ Python ▁ scripting ▁ support ▁ should ▁ be ▁ ok . ENDCOM import os NEW_LINE import sys NEW_LINE sys . path . append ( os . environ [ ' PERF _ EXEC _ PATH ' ] + ' / scripts / python / Perf - Trace - Util / lib / Perf / Trace ' ) NEW_LINE from Core import * NEW_LINE from perf_trace_context import * NEW_LINE unhandled = autodict ( ) NEW_LINE def trace_begin ( ) : NEW_LINE INDENT print " trace _ begin " NEW_LINE pass NEW_LINE DEDENT def trace_end ( ) : NEW_LINE INDENT print_unhandled ( ) NEW_LINE DEDENT def irq__softirq_entry ( event_name , context , common_cpu , common_secs , common_nsecs , common_pid , common_comm , vec ) : NEW_LINE INDENT print_header ( event_name , common_cpu , common_secs , common_nsecs , common_pid , common_comm ) NEW_LINE print_uncommon ( context ) NEW_LINE print " vec = % s \n " % ( symbol_str ( " irq _ _ softirq _ entry " , " vec " , vec ) ) , NEW_LINE DEDENT def kmem__kmalloc ( event_name , context , common_cpu , common_secs , common_nsecs , common_pid , common_comm , call_site , ptr , bytes_req , bytes_alloc , gfp_flags ) : NEW_LINE INDENT print_header ( event_name , common_cpu , common_secs , common_nsecs , common_pid , common_comm ) NEW_LINE print_uncommon ( context ) NEW_LINE print " call _ site = % u , ▁ ptr = % u , ▁ bytes _ req = % u , ▁ " " bytes _ alloc = % u , ▁ gfp _ flags = % s \n " % ( call_site , ptr , bytes_req , bytes_alloc , flag_str ( " kmem _ _ kmalloc " , " gfp _ flags " , gfp_flags ) ) , NEW_LINE DEDENT def trace_unhandled ( event_name , context , event_fields_dict ) : NEW_LINE INDENT try : NEW_LINE INDENT unhandled [ event_name ] += 1 NEW_LINE DEDENT except TypeError : NEW_LINE INDENT unhandled [ event_name ] = 1 NEW_LINE DEDENT DEDENT def print_header ( event_name , cpu , secs , nsecs , pid , comm ) : NEW_LINE INDENT print " % -20s ▁ % 5u ▁ % 05u . %09u ▁ % 8u ▁ % -20s ▁ " % ( event_name , cpu , secs , nsecs , pid , comm ) , NEW_LINE # ▁ print ▁ trace ▁ fields ▁ not ▁ included ▁ in ▁ handler ▁ args ENDCOM DEDENT def print_uncommon ( context ) : NEW_LINE INDENT print " common _ preempt _ count = % d , ▁ common _ flags = % s , ▁ common _ lock _ depth = % d , ▁ " % ( common_pc ( context ) , trace_flag_str ( common_flags ( context ) ) , common_lock_depth ( context ) ) NEW_LINE DEDENT def print_unhandled ( ) : NEW_LINE INDENT keys = unhandled . keys ( ) NEW_LINE if not keys : NEW_LINE INDENT return NEW_LINE DEDENT print " \n unhandled ▁ events : \n \n " , NEW_LINE print " % -40s ▁ ▁ % 10s \n " % ( " event " , " count " ) , NEW_LINE print " % -40s ▁ ▁ % 10s \n " % ( " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - " , " - - - - - - - - - - - " ) , NEW_LINE for event_name in keys : NEW_LINE INDENT print " % -40s ▁ ▁ % 10d \n " % ( event_name , unhandled [ event_name ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Syrcon/servo/tree/master/tests/wpt/web-platform-tests/tools/serve/serve.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import argparse NEW_LINE import json NEW_LINE import os NEW_LINE import signal NEW_LINE import socket NEW_LINE import sys NEW_LINE import threading NEW_LINE import time NEW_LINE import traceback NEW_LINE import urllib2 NEW_LINE import uuid NEW_LINE from collections import defaultdict , OrderedDict NEW_LINE from multiprocessing import Process , Event NEW_LINE from . . import localpaths NEW_LINE import sslutils NEW_LINE from wptserve import server as wptserve , handlers NEW_LINE from wptserve import stash NEW_LINE from wptserve . logger import set_logger NEW_LINE from mod_pywebsocket import standalone as pywebsocket NEW_LINE repo_root = localpaths . repo_root NEW_LINE class WorkersHandler ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . handler = handlers . handler ( self . handle_request ) NEW_LINE DEDENT def __call__ ( self , request , response ) : NEW_LINE INDENT return self . handler ( request , response ) NEW_LINE DEDENT def handle_request ( self , request , response ) : NEW_LINE INDENT worker_path = request . url_parts . path . replace ( " . worker " , " . worker . js " ) NEW_LINE return """ < ! doctype ▁ html > STRNEWLINE < meta ▁ charset = utf - 8 > STRNEWLINE < script ▁ src = " / resources / testharness . js " > < / script > STRNEWLINE < script ▁ src = " / resources / testharnessreport . js " > < / script > STRNEWLINE < div ▁ id = log > < / div > STRNEWLINE < script > STRNEWLINE fetch _ tests _ from _ worker ( new ▁ Worker ( " % s " ) ) ; STRNEWLINE < / script > STRNEWLINE """ % ( worker_path , ) NEW_LINE DEDENT DEDENT rewrites = [ ( " GET " , " / resources / WebIDLParser . js " , " / resources / webidl2 / lib / webidl2 . js " ) ] NEW_LINE subdomains = [ u " www " , u " www1" , u " www2" , u " 天気の良い日 " , u " élève " ] NEW_LINE class RoutesBuilder ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . forbidden_override = [ ( " GET " , " / tools / runner / * " , handlers . file_handler ) , ( " POST " , " / tools / runner / update _ manifest . py " , handlers . python_script_handler ) ] NEW_LINE self . forbidden = [ ( " * " , " / _ certs / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " / tools / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " { spec } / tools / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " / serve . py " , handlers . ErrorHandler ( 404 ) ) ] NEW_LINE self . static = [ ( " GET " , " * . worker " , WorkersHandler ( ) ) ] NEW_LINE self . mountpoint_routes = OrderedDict ( ) NEW_LINE self . add_mount_point ( " / " , None ) NEW_LINE DEDENT def get_routes ( self ) : NEW_LINE INDENT routes = self . forbidden_override + self . forbidden + self . static NEW_LINE # ▁ Using ▁ reversed ▁ here ▁ means ▁ that ▁ mount ▁ points ▁ that ▁ are ▁ added ▁ later ENDCOM # ▁ get ▁ higher ▁ priority . ▁ This ▁ makes ▁ sense ▁ since ▁ / ▁ is ▁ typically ▁ added ENDCOM # ▁ first . ENDCOM for item in reversed ( self . mountpoint_routes . values ( ) ) : NEW_LINE INDENT routes . extend ( item ) NEW_LINE DEDENT return routes NEW_LINE DEDENT def add_static ( self , path , format_args , content_type , route ) : NEW_LINE INDENT handler = handlers . StaticHandler ( path , format_args , content_type ) NEW_LINE self . static . append ( ( b " GET " , str ( route ) , handler ) ) NEW_LINE DEDENT def add_mount_point ( self , url_base , path ) : NEW_LINE INDENT url_base = " / % s / " % url_base . strip ( " / " ) if url_base != " / " else " / " NEW_LINE self . mountpoint_routes [ url_base ] = [ ] NEW_LINE routes = [ ( " GET " , " * . asis " , handlers . AsIsHandler ) , ( " * " , " * . py " , handlers . PythonScriptHandler ) , ( " GET " , " * " , handlers . FileHandler ) ] NEW_LINE for ( method , suffix , handler_cls ) in routes : NEW_LINE INDENT self . mountpoint_routes [ url_base ] . append ( ( method , b " % s % s " % ( str ( url_base ) if url_base != " / " else " " , str ( suffix ) ) , handler_cls ( base_path = path , url_base = url_base ) ) ) NEW_LINE DEDENT DEDENT DEDENT def default_routes ( ) : NEW_LINE INDENT return RoutesBuilder ( ) . get_routes ( ) NEW_LINE DEDENT def setup_logger ( level ) : NEW_LINE INDENT import logging NEW_LINE global logger NEW_LINE logger = logging . getLogger ( " web - platform - tests " ) NEW_LINE logging . basicConfig ( level = getattr ( logging , level . upper ( ) ) ) NEW_LINE set_logger ( logger ) NEW_LINE DEDENT def open_socket ( port ) : NEW_LINE INDENT sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) NEW_LINE if port != 0 : NEW_LINE INDENT sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) NEW_LINE DEDENT sock . bind ( ( '127.0.0.1' , port ) ) NEW_LINE sock . listen ( 5 ) NEW_LINE return sock NEW_LINE DEDENT def get_port ( ) : NEW_LINE INDENT free_socket = open_socket ( 0 ) NEW_LINE port = free_socket . getsockname ( ) [ 1 ] NEW_LINE logger . debug ( " Going ▁ to ▁ use ▁ port ▁ % s " % port ) NEW_LINE free_socket . close ( ) NEW_LINE return port NEW_LINE DEDENT class ServerProc ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . proc = None NEW_LINE self . daemon = None NEW_LINE self . stop = Event ( ) NEW_LINE DEDENT def start ( self , init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT self . proc = Process ( target = self . create_daemon , args = ( init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config ) ) NEW_LINE self . proc . daemon = True NEW_LINE self . proc . start ( ) NEW_LINE DEDENT def create_daemon ( self , init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT try : NEW_LINE INDENT self . daemon = init_func ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE DEDENT except socket . error : NEW_LINE INDENT print >> sys . stderr , " Socket ▁ error ▁ on ▁ port ▁ % s " % port NEW_LINE raise NEW_LINE DEDENT except : NEW_LINE INDENT print >> sys . stderr , traceback . format_exc ( ) NEW_LINE raise NEW_LINE DEDENT if self . daemon : NEW_LINE INDENT try : NEW_LINE INDENT self . daemon . start ( block = False ) NEW_LINE try : NEW_LINE INDENT self . stop . wait ( ) NEW_LINE DEDENT except KeyboardInterrupt : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT print >> sys . stderr , traceback . format_exc ( ) NEW_LINE raise NEW_LINE DEDENT DEDENT DEDENT def wait ( self ) : NEW_LINE INDENT self . stop . set ( ) NEW_LINE self . proc . join ( ) NEW_LINE DEDENT def kill ( self ) : NEW_LINE INDENT self . stop . set ( ) NEW_LINE self . proc . terminate ( ) NEW_LINE self . proc . join ( ) NEW_LINE DEDENT def is_alive ( self ) : NEW_LINE INDENT return self . proc . is_alive ( ) NEW_LINE DEDENT DEDENT def check_subdomains ( host , paths , bind_hostname , ssl_config ) : NEW_LINE INDENT port = get_port ( ) NEW_LINE subdomains = get_subdomains ( host ) NEW_LINE wrapper = ServerProc ( ) NEW_LINE wrapper . start ( start_http_server , host , port , paths , default_routes ( ) , bind_hostname , None , ssl_config ) NEW_LINE connected = False NEW_LINE for i in range ( 10 ) : NEW_LINE INDENT try : NEW_LINE INDENT urllib2 . urlopen ( " http : / / % s : % d / " % ( host , port ) ) NEW_LINE connected = True NEW_LINE break NEW_LINE DEDENT except urllib2 . URLError : NEW_LINE INDENT time . sleep ( 1 ) NEW_LINE DEDENT DEDENT if not connected : NEW_LINE INDENT logger . critical ( " Failed ▁ to ▁ connect ▁ to ▁ test ▁ server ▁ on ▁ http : / / % s : % s ▁ You ▁ may ▁ need ▁ to ▁ edit ▁ / etc / hosts ▁ or ▁ similar " % ( host , port ) ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT for subdomain , ( punycode , host ) in subdomains . iteritems ( ) : NEW_LINE INDENT domain = " % s . % s " % ( punycode , host ) NEW_LINE try : NEW_LINE INDENT urllib2 . urlopen ( " http : / / % s : % d / " % ( domain , port ) ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT logger . critical ( " Failed ▁ probing ▁ domain ▁ % s . ▁ You ▁ may ▁ need ▁ to ▁ edit ▁ / etc / hosts ▁ or ▁ similar . " % domain ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT DEDENT wrapper . wait ( ) NEW_LINE DEDENT def get_subdomains ( host ) : NEW_LINE # This ▁ assumes ▁ that ▁ the ▁ tld ▁ is ▁ ascii - only ▁ or ▁ already ▁ in ▁ punycode ENDCOM INDENT return { subdomain : ( subdomain . encode ( " idna " ) , host ) for subdomain in subdomains } NEW_LINE DEDENT def start_servers ( host , ports , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT servers = defaultdict ( list ) NEW_LINE for scheme , ports in ports . iteritems ( ) : NEW_LINE INDENT assert len ( ports ) == { " http " : 2 } . get ( scheme , 1 ) NEW_LINE for port in ports : NEW_LINE INDENT if port is None : NEW_LINE INDENT continue NEW_LINE DEDENT init_func = { " http " : start_http_server , " https " : start_https_server , " ws " : start_ws_server , " wss " : start_wss_server } [ scheme ] NEW_LINE server_proc = ServerProc ( ) NEW_LINE server_proc . start ( init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE servers [ scheme ] . append ( ( port , server_proc ) ) NEW_LINE DEDENT DEDENT return servers NEW_LINE DEDENT def start_http_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return wptserve . WebTestHttpd ( host = host , port = port , doc_root = paths [ " doc _ root " ] , routes = routes , rewrites = rewrites , bind_hostname = bind_hostname , config = external_config , use_ssl = False , key_file = None , certificate = None , latency = kwargs . get ( " latency " ) ) NEW_LINE DEDENT def start_https_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return wptserve . WebTestHttpd ( host = host , port = port , doc_root = paths [ " doc _ root " ] , routes = routes , rewrites = rewrites , bind_hostname = bind_hostname , config = external_config , use_ssl = True , key_file = ssl_config [ " key _ path " ] , certificate = ssl_config [ " cert _ path " ] , encrypt_after_connect = ssl_config [ " encrypt _ after _ connect " ] , latency = kwargs . get ( " latency " ) ) NEW_LINE DEDENT class WebSocketDaemon ( object ) : NEW_LINE INDENT def __init__ ( self , host , port , doc_root , handlers_root , log_level , bind_hostname , ssl_config ) : NEW_LINE INDENT self . host = host NEW_LINE cmd_args = [ " - p " , port , " - d " , doc_root , " - w " , handlers_root , " - - log - level " , log_level ] NEW_LINE if ssl_config is not None : NEW_LINE # ▁ This ▁ is ▁ usually ▁ done ▁ through ▁ pywebsocket . main , ▁ however ▁ we ' re ENDCOM # ▁ working ▁ around ▁ that ▁ to ▁ get ▁ the ▁ server ▁ instance ▁ and ▁ manually ENDCOM # ▁ setup ▁ the ▁ wss ▁ server . ENDCOM INDENT if pywebsocket . _import_ssl ( ) : NEW_LINE INDENT tls_module = pywebsocket . _TLS_BY_STANDARD_MODULE NEW_LINE DEDENT elif pywebsocket . _import_pyopenssl ( ) : NEW_LINE INDENT tls_module = pywebsocket . _TLS_BY_PYOPENSSL NEW_LINE DEDENT else : NEW_LINE INDENT print " No ▁ SSL ▁ module ▁ available " NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT cmd_args += [ " - - tls " , " - - private - key " , ssl_config [ " key _ path " ] , " - - certificate " , ssl_config [ " cert _ path " ] , " - - tls - module " , tls_module ] NEW_LINE DEDENT if ( bind_hostname ) : NEW_LINE INDENT cmd_args = [ " - H " , host ] + cmd_args NEW_LINE DEDENT opts , args = pywebsocket . _parse_args_and_config ( cmd_args ) NEW_LINE opts . cgi_directories = [ ] NEW_LINE opts . is_executable_method = None NEW_LINE self . server = pywebsocket . WebSocketServer ( opts ) NEW_LINE ports = [ item [ 0 ] . getsockname ( ) [ 1 ] for item in self . server . _sockets ] NEW_LINE assert all ( item == ports [ 0 ] for item in ports ) NEW_LINE self . port = ports [ 0 ] NEW_LINE self . started = False NEW_LINE self . server_thread = None NEW_LINE DEDENT def start ( self , block = False ) : NEW_LINE INDENT self . started = True NEW_LINE if block : NEW_LINE INDENT self . server . serve_forever ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . server_thread = threading . Thread ( target = self . server . serve_forever ) NEW_LINE self . server_thread . setDaemon ( True ) # ▁ don ' t ▁ hang ▁ on ▁ exit ENDCOM NEW_LINE self . server_thread . start ( ) NEW_LINE DEDENT DEDENT def stop ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Stops ▁ the ▁ server . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ server ▁ is ▁ not ▁ running , ▁ this ▁ method ▁ has ▁ no ▁ effect . STRNEWLINE ▁ """ NEW_LINE if self . started : NEW_LINE INDENT try : NEW_LINE INDENT self . server . shutdown ( ) NEW_LINE self . server . server_close ( ) NEW_LINE self . server_thread . join ( ) NEW_LINE self . server_thread = None NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT pass NEW_LINE DEDENT self . started = False NEW_LINE DEDENT self . server = None NEW_LINE DEDENT DEDENT def start_ws_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return WebSocketDaemon ( host , str ( port ) , repo_root , paths [ " ws _ doc _ root " ] , " debug " , bind_hostname , ssl_config = None ) NEW_LINE DEDENT def start_wss_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return WebSocketDaemon ( host , str ( port ) , repo_root , paths [ " ws _ doc _ root " ] , " debug " , bind_hostname , ssl_config ) NEW_LINE DEDENT def get_ports ( config , ssl_environment ) : NEW_LINE INDENT rv = defaultdict ( list ) NEW_LINE for scheme , ports in config [ " ports " ] . iteritems ( ) : NEW_LINE INDENT for i , port in enumerate ( ports ) : NEW_LINE INDENT if scheme in [ " wss " , " https " ] and not ssl_environment . ssl_enabled : NEW_LINE INDENT port = None NEW_LINE DEDENT if port == " auto " : NEW_LINE INDENT port = get_port ( ) NEW_LINE DEDENT else : NEW_LINE INDENT port = port NEW_LINE DEDENT rv [ scheme ] . append ( port ) NEW_LINE DEDENT DEDENT return rv NEW_LINE DEDENT def normalise_config ( config , ports ) : NEW_LINE INDENT host = config [ " external _ host " ] if config [ " external _ host " ] else config [ " host " ] NEW_LINE domains = get_subdomains ( host ) NEW_LINE ports_ = { } NEW_LINE for scheme , ports_used in ports . iteritems ( ) : NEW_LINE INDENT ports_ [ scheme ] = ports_used NEW_LINE DEDENT for key , value in domains . iteritems ( ) : NEW_LINE INDENT domains [ key ] = " . " . join ( value ) NEW_LINE DEDENT domains [ " " ] = host NEW_LINE ports_ = { } NEW_LINE for scheme , ports_used in ports . iteritems ( ) : NEW_LINE INDENT ports_ [ scheme ] = ports_used NEW_LINE DEDENT return { " host " : host , " domains " : domains , " ports " : ports_ } NEW_LINE DEDENT def get_ssl_config ( config , external_domains , ssl_environment ) : NEW_LINE INDENT key_path , cert_path = ssl_environment . host_cert_path ( external_domains ) NEW_LINE return { " key _ path " : key_path , " cert _ path " : cert_path , " encrypt _ after _ connect " : config [ " ssl " ] [ " encrypt _ after _ connect " ] } NEW_LINE DEDENT def start ( config , ssl_environment , routes , ** kwargs ) : NEW_LINE INDENT host = config [ " host " ] NEW_LINE domains = get_subdomains ( host ) NEW_LINE ports = get_ports ( config , ssl_environment ) NEW_LINE bind_hostname = config [ " bind _ hostname " ] NEW_LINE paths = { " doc _ root " : config [ " doc _ root " ] , " ws _ doc _ root " : config [ " ws _ doc _ root " ] } NEW_LINE external_config = normalise_config ( config , ports ) NEW_LINE ssl_config = get_ssl_config ( config , external_config [ " domains " ] . values ( ) , ssl_environment ) NEW_LINE if config [ " check _ subdomains " ] : NEW_LINE INDENT check_subdomains ( host , paths , bind_hostname , ssl_config ) NEW_LINE DEDENT servers = start_servers ( host , ports , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE return external_config , servers NEW_LINE DEDENT def iter_procs ( servers ) : NEW_LINE INDENT for servers in servers . values ( ) : NEW_LINE INDENT for port , server in servers : NEW_LINE INDENT yield server . proc NEW_LINE DEDENT DEDENT DEDENT def value_set ( config , key ) : NEW_LINE INDENT return key in config and config [ key ] is not None NEW_LINE DEDENT def get_value_or_default ( config , key , default = None ) : NEW_LINE INDENT return config [ key ] if value_set ( config , key ) else default NEW_LINE DEDENT def set_computed_defaults ( config ) : NEW_LINE INDENT if not value_set ( config , " doc _ root " ) : NEW_LINE INDENT config [ " doc _ root " ] = repo_root NEW_LINE DEDENT if not value_set ( config , " ws _ doc _ root " ) : NEW_LINE INDENT root = get_value_or_default ( config , " doc _ root " , default = repo_root ) NEW_LINE config [ " ws _ doc _ root " ] = os . path . join ( root , " websockets " , " handlers " ) NEW_LINE DEDENT DEDENT def merge_json ( base_obj , override_obj ) : NEW_LINE INDENT rv = { } NEW_LINE for key , value in base_obj . iteritems ( ) : NEW_LINE INDENT if key not in override_obj : NEW_LINE INDENT rv [ key ] = value NEW_LINE DEDENT else : NEW_LINE INDENT if isinstance ( value , dict ) : NEW_LINE INDENT rv [ key ] = merge_json ( value , override_obj [ key ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rv [ key ] = override_obj [ key ] NEW_LINE DEDENT DEDENT DEDENT return rv NEW_LINE DEDENT def get_ssl_environment ( config ) : NEW_LINE INDENT implementation_type = config [ " ssl " ] [ " type " ] NEW_LINE cls = sslutils . environments [ implementation_type ] NEW_LINE try : NEW_LINE INDENT kwargs = config [ " ssl " ] [ implementation_type ] . copy ( ) NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ValueError ( " % s ▁ is ▁ not ▁ a ▁ vaid ▁ ssl ▁ type . " % implementation_type ) NEW_LINE DEDENT return cls ( logger , ** kwargs ) NEW_LINE DEDENT def load_config ( default_path , override_path = None , ** kwargs ) : NEW_LINE INDENT if os . path . exists ( default_path ) : NEW_LINE INDENT with open ( default_path ) as f : NEW_LINE INDENT base_obj = json . load ( f ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise ValueError ( " Config ▁ path ▁ % s ▁ does ▁ not ▁ exist " % default_path ) NEW_LINE DEDENT if os . path . exists ( override_path ) : NEW_LINE INDENT with open ( override_path ) as f : NEW_LINE INDENT override_obj = json . load ( f ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT override_obj = { } NEW_LINE DEDENT rv = merge_json ( base_obj , override_obj ) NEW_LINE if kwargs . get ( " config _ path " ) : NEW_LINE INDENT other_path = os . path . abspath ( os . path . expanduser ( kwargs . get ( " config _ path " ) ) ) NEW_LINE if os . path . exists ( other_path ) : NEW_LINE INDENT base_obj = rv NEW_LINE with open ( other_path ) as f : NEW_LINE INDENT override_obj = json . load ( f ) NEW_LINE DEDENT rv = merge_json ( base_obj , override_obj ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " Config ▁ path ▁ % s ▁ does ▁ not ▁ exist " % other_path ) NEW_LINE DEDENT DEDENT overriding_path_args = [ ( " doc _ root " , " Document ▁ root " ) , ( " ws _ doc _ root " , " WebSockets ▁ document ▁ root " ) ] NEW_LINE for key , title in overriding_path_args : NEW_LINE INDENT value = kwargs . get ( key ) NEW_LINE if value is None : NEW_LINE INDENT continue NEW_LINE DEDENT value = os . path . abspath ( os . path . expanduser ( value ) ) NEW_LINE if not os . path . exists ( value ) : NEW_LINE INDENT raise ValueError ( " % s ▁ path ▁ % s ▁ does ▁ not ▁ exist " % ( title , value ) ) NEW_LINE DEDENT rv [ key ] = value NEW_LINE DEDENT set_computed_defaults ( rv ) NEW_LINE return rv NEW_LINE DEDENT def get_parser ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( ) NEW_LINE parser . add_argument ( " - - latency " , type = int , help = " Artificial ▁ latency ▁ to ▁ add ▁ before ▁ sending ▁ http ▁ responses , ▁ in ▁ ms " ) NEW_LINE parser . add_argument ( " - - config " , action = " store " , dest = " config _ path " , help = " Path ▁ to ▁ external ▁ config ▁ file " ) NEW_LINE parser . add_argument ( " - - doc _ root " , action = " store " , dest = " doc _ root " , help = " Path ▁ to ▁ document ▁ root . ▁ Overrides ▁ config . " ) NEW_LINE parser . add_argument ( " - - ws _ doc _ root " , action = " store " , dest = " ws _ doc _ root " , help = " Path ▁ to ▁ WebSockets ▁ document ▁ root . ▁ Overrides ▁ config . " ) NEW_LINE return parser NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT kwargs = vars ( get_parser ( ) . parse_args ( ) ) NEW_LINE config = load_config ( " config . default . json " , " config . json " , ** kwargs ) NEW_LINE setup_logger ( config [ " log _ level " ] ) NEW_LINE with stash . StashServer ( ( config [ " host " ] , get_port ( ) ) , authkey = str ( uuid . uuid4 ( ) ) ) : NEW_LINE INDENT with get_ssl_environment ( config ) as ssl_env : NEW_LINE INDENT config_ , servers = start ( config , ssl_env , default_routes ( ) , ** kwargs ) NEW_LINE try : NEW_LINE INDENT while any ( item . is_alive ( ) for item in iter_procs ( servers ) ) : NEW_LINE INDENT for item in iter_procs ( servers ) : NEW_LINE INDENT item . join ( 1 ) NEW_LINE DEDENT DEDENT DEDENT except KeyboardInterrupt : NEW_LINE INDENT logger . info ( " Shutting ▁ down " ) NEW_LINE DEDENT DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="ryfeus/lambda-packs/tree/master/Skimage_numpy/source/PIL/JpegImagePlugin.py"> # ▁ The ▁ Python ▁ Imaging ▁ Library . ENDCOM # ▁ $ Id $ ENDCOM # ▁ JPEG ▁ ( JFIF ) ▁ file ▁ handling ENDCOM # ▁ See ▁ " Digital ▁ Compression ▁ and ▁ Coding ▁ of ▁ Continuous - Tone ▁ Still ▁ Images , ENDCOM # ▁ Part ▁ 1 , ▁ Requirements ▁ and ▁ Guidelines " ▁ ( CCITT ▁ T . 81 ▁ / ▁ ISO ▁ 10918-1 ) ENDCOM # ▁ History : ENDCOM # ▁ 1995-09-09 ▁ fl ▁ Created ENDCOM # ▁ 1995-09-13 ▁ fl ▁ Added ▁ full ▁ parser ENDCOM # ▁ 1996-03-25 ▁ fl ▁ Added ▁ hack ▁ to ▁ use ▁ the ▁ IJG ▁ command ▁ line ▁ utilities ENDCOM # ▁ 1996-05-05 ▁ fl ▁ Workaround ▁ Photoshop ▁ 2.5 ▁ CMYK ▁ polarity ▁ bug ENDCOM # ▁ 1996-05-28 ▁ fl ▁ Added ▁ draft ▁ support , ▁ JFIF ▁ version ▁ ( 0.1 ) ENDCOM # ▁ 1996-12-30 ▁ fl ▁ Added ▁ encoder ▁ options , ▁ added ▁ progression ▁ property ▁ ( 0.2 ) ENDCOM # ▁ 1997-08-27 ▁ fl ▁ Save ▁ mode ▁ 1 ▁ images ▁ as ▁ BW ▁ ( 0.3 ) ENDCOM # ▁ 1998-07-12 ▁ fl ▁ Added ▁ YCbCr ▁ to ▁ draft ▁ and ▁ save ▁ methods ▁ ( 0.4 ) ENDCOM # ▁ 1998-10-19 ▁ fl ▁ Don ' t ▁ hang ▁ on ▁ files ▁ using ▁ 16 - bit ▁ DQT ' s ▁ ( 0.4.1 ) ENDCOM # ▁ 2001-04-16 ▁ fl ▁ Extract ▁ DPI ▁ settings ▁ from ▁ JFIF ▁ files ▁ ( 0.4.2 ) ENDCOM # ▁ 2002-07-01 ▁ fl ▁ Skip ▁ pad ▁ bytes ▁ before ▁ markers ; ▁ identify ▁ Exif ▁ files ▁ ( 0.4.3 ) ENDCOM # ▁ 2003-04-25 ▁ fl ▁ Added ▁ experimental ▁ EXIF ▁ decoder ▁ ( 0.5 ) ENDCOM # ▁ 2003-06-06 ▁ fl ▁ Added ▁ experimental ▁ EXIF ▁ GPSinfo ▁ decoder ENDCOM # ▁ 2003-09-13 ▁ fl ▁ Extract ▁ COM ▁ markers ENDCOM # ▁ 2009-09-06 ▁ fl ▁ Added ▁ icc _ profile ▁ support ▁ ( from ▁ Florian ▁ Hoech ) ENDCOM # ▁ 2009-03-06 ▁ fl ▁ Changed ▁ CMYK ▁ handling ; ▁ always ▁ use ▁ Adobe ▁ polarity ▁ ( 0.6 ) ENDCOM # ▁ 2009-03-08 ▁ fl ▁ Added ▁ subsampling ▁ support ▁ ( from ▁ Justin ▁ Huff ) . ENDCOM # ▁ Copyright ▁ ( c ) ▁ 1997-2003 ▁ by ▁ Secret ▁ Labs ▁ AB . ENDCOM # ▁ Copyright ▁ ( c ) ▁ 1995-1996 ▁ by ▁ Fredrik ▁ Lundh . ENDCOM # ▁ See ▁ the ▁ README ▁ file ▁ for ▁ information ▁ on ▁ usage ▁ and ▁ redistribution . ENDCOM from __future__ import print_function NEW_LINE import array NEW_LINE import struct NEW_LINE import io NEW_LINE import warnings NEW_LINE from struct import unpack_from NEW_LINE from PIL import Image , ImageFile , TiffImagePlugin , _binary NEW_LINE from PIL . JpegPresets import presets NEW_LINE from PIL . _util import isStringType NEW_LINE i8 = _binary . i8 NEW_LINE o8 = _binary . o8 NEW_LINE i16 = _binary . i16be NEW_LINE i32 = _binary . i32be NEW_LINE __version__ = "0.6" NEW_LINE # ▁ Parser ENDCOM def Skip ( self , marker ) : NEW_LINE INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE ImageFile . _safe_read ( self . fp , n ) NEW_LINE DEDENT def APP ( self , marker ) : NEW_LINE # ▁ Application ▁ marker . ▁ Store ▁ these ▁ in ▁ the ▁ APP ▁ dictionary . ENDCOM # ▁ Also ▁ look ▁ for ▁ well - known ▁ application ▁ markers . ENDCOM INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE app = " APP % d " % ( marker & 15 ) NEW_LINE self . app [ app ] = s # ▁ compatibility ENDCOM NEW_LINE self . applist . append ( ( app , s ) ) NEW_LINE if marker == 0xFFE0 and s [ : 4 ] == b " JFIF " : NEW_LINE # ▁ extract ▁ JFIF ▁ information ENDCOM INDENT self . info [ " jfif " ] = version = i16 ( s , 5 ) # ▁ version ENDCOM NEW_LINE self . info [ " jfif _ version " ] = divmod ( version , 256 ) NEW_LINE # ▁ extract ▁ JFIF ▁ properties ENDCOM try : NEW_LINE INDENT jfif_unit = i8 ( s [ 7 ] ) NEW_LINE jfif_density = i16 ( s , 8 ) , i16 ( s , 10 ) NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT if jfif_unit == 1 : NEW_LINE INDENT self . info [ " dpi " ] = jfif_density NEW_LINE DEDENT self . info [ " jfif _ unit " ] = jfif_unit NEW_LINE self . info [ " jfif _ density " ] = jfif_density NEW_LINE DEDENT DEDENT elif marker == 0xFFE1 and s [ : 5 ] == b " Exif\0" : NEW_LINE # ▁ extract ▁ Exif ▁ information ▁ ( incomplete ) ENDCOM INDENT self . info [ " exif " ] = s # ▁ FIXME : ▁ value ▁ will ▁ change ENDCOM NEW_LINE DEDENT elif marker == 0xFFE2 and s [ : 5 ] == b " FPXR\0" : NEW_LINE # ▁ extract ▁ FlashPix ▁ information ▁ ( incomplete ) ENDCOM INDENT self . info [ " flashpix " ] = s # ▁ FIXME : ▁ value ▁ will ▁ change ENDCOM NEW_LINE DEDENT elif marker == 0xFFE2 and s [ : 12 ] == b " ICC _ PROFILE\0" : NEW_LINE # ▁ Since ▁ an ▁ ICC ▁ profile ▁ can ▁ be ▁ larger ▁ than ▁ the ▁ maximum ▁ size ▁ of ENDCOM # ▁ a ▁ JPEG ▁ marker ▁ ( 64K ) , ▁ we ▁ need ▁ provisions ▁ to ▁ split ▁ it ▁ into ENDCOM # ▁ multiple ▁ markers . ▁ The ▁ format ▁ defined ▁ by ▁ the ▁ ICC ▁ specifies ENDCOM # ▁ one ▁ or ▁ more ▁ APP2 ▁ markers ▁ containing ▁ the ▁ following ▁ data : ENDCOM # ▁ Identifying ▁ string ▁ ASCII ▁ " ICC _ PROFILE\0 " ▁ ( 12 ▁ bytes ) ENDCOM # ▁ Marker ▁ sequence ▁ number ▁ 1 , ▁ 2 , ▁ etc ▁ ( 1 ▁ byte ) ENDCOM # ▁ Number ▁ of ▁ markers ▁ Total ▁ of ▁ APP2 ' s ▁ used ▁ ( 1 ▁ byte ) ENDCOM # ▁ Profile ▁ data ▁ ( remainder ▁ of ▁ APP2 ▁ data ) ENDCOM # ▁ Decoders ▁ should ▁ use ▁ the ▁ marker ▁ sequence ▁ numbers ▁ to ENDCOM # ▁ reassemble ▁ the ▁ profile , ▁ rather ▁ than ▁ assuming ▁ that ▁ the ▁ APP2 ENDCOM # ▁ markers ▁ appear ▁ in ▁ the ▁ correct ▁ sequence . ENDCOM INDENT self . icclist . append ( s ) NEW_LINE DEDENT elif marker == 0xFFEE and s [ : 5 ] == b " Adobe " : NEW_LINE INDENT self . info [ " adobe " ] = i16 ( s , 5 ) NEW_LINE # ▁ extract ▁ Adobe ▁ custom ▁ properties ENDCOM try : NEW_LINE INDENT adobe_transform = i8 ( s [ 1 ] ) NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . info [ " adobe _ transform " ] = adobe_transform NEW_LINE DEDENT DEDENT elif marker == 0xFFE2 and s [ : 4 ] == b " MPF\0" : NEW_LINE # ▁ extract ▁ MPO ▁ information ENDCOM INDENT self . info [ " mp " ] = s [ 4 : ] NEW_LINE # ▁ offset ▁ is ▁ current ▁ location ▁ minus ▁ buffer ▁ size ENDCOM # ▁ plus ▁ constant ▁ header ▁ size ENDCOM self . info [ " mpoffset " ] = self . fp . tell ( ) - n + 4 NEW_LINE DEDENT DEDENT def COM ( self , marker ) : NEW_LINE # ▁ Comment ▁ marker . ▁ Store ▁ these ▁ in ▁ the ▁ APP ▁ dictionary . ENDCOM INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE self . app [ " COM " ] = s # ▁ compatibility ENDCOM NEW_LINE self . applist . append ( ( " COM " , s ) ) NEW_LINE DEDENT def SOF ( self , marker ) : NEW_LINE # ▁ Start ▁ of ▁ frame ▁ marker . ▁ Defines ▁ the ▁ size ▁ and ▁ mode ▁ of ▁ the ENDCOM # ▁ image . ▁ JPEG ▁ is ▁ colour ▁ blind , ▁ so ▁ we ▁ use ▁ some ▁ simple ENDCOM # ▁ heuristics ▁ to ▁ map ▁ the ▁ number ▁ of ▁ layers ▁ to ▁ an ▁ appropriate ENDCOM # ▁ mode . ▁ Note ▁ that ▁ this ▁ could ▁ be ▁ made ▁ a ▁ bit ▁ brighter , ▁ by ENDCOM # ▁ looking ▁ for ▁ JFIF ▁ and ▁ Adobe ▁ APP ▁ markers . ENDCOM INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE self . size = i16 ( s [ 3 : ] ) , i16 ( s [ 1 : ] ) NEW_LINE self . bits = i8 ( s [ 0 ] ) NEW_LINE if self . bits != 8 : NEW_LINE INDENT raise SyntaxError ( " cannot ▁ handle ▁ % d - bit ▁ layers " % self . bits ) NEW_LINE DEDENT self . layers = i8 ( s [ 5 ] ) NEW_LINE if self . layers == 1 : NEW_LINE INDENT self . mode = " L " NEW_LINE DEDENT elif self . layers == 3 : NEW_LINE INDENT self . mode = " RGB " NEW_LINE DEDENT elif self . layers == 4 : NEW_LINE INDENT self . mode = " CMYK " NEW_LINE DEDENT else : NEW_LINE INDENT raise SyntaxError ( " cannot ▁ handle ▁ % d - layer ▁ images " % self . layers ) NEW_LINE DEDENT if marker in [ 0xFFC2 , 0xFFC6 , 0xFFCA , 0xFFCE ] : NEW_LINE INDENT self . info [ " progressive " ] = self . info [ " progression " ] = 1 NEW_LINE DEDENT if self . icclist : NEW_LINE # ▁ fixup ▁ icc ▁ profile ENDCOM INDENT self . icclist . sort ( ) # ▁ sort ▁ by ▁ sequence ▁ number ENDCOM NEW_LINE if i8 ( self . icclist [ 0 ] [ 13 ] ) == len ( self . icclist ) : NEW_LINE INDENT profile = [ ] NEW_LINE for p in self . icclist : NEW_LINE INDENT profile . append ( p [ 14 : ] ) NEW_LINE DEDENT icc_profile = b " " . join ( profile ) NEW_LINE DEDENT else : NEW_LINE INDENT icc_profile = None # ▁ wrong ▁ number ▁ of ▁ fragments ENDCOM NEW_LINE DEDENT self . info [ " icc _ profile " ] = icc_profile NEW_LINE self . icclist = None NEW_LINE DEDENT for i in range ( 6 , len ( s ) , 3 ) : NEW_LINE INDENT t = s [ i : i + 3 ] NEW_LINE # ▁ 4 - tuples : ▁ id , ▁ vsamp , ▁ hsamp , ▁ qtable ENDCOM self . layer . append ( ( t [ 0 ] , i8 ( t [ 1 ] ) // 16 , i8 ( t [ 1 ] ) & 15 , i8 ( t [ 2 ] ) ) ) NEW_LINE DEDENT DEDENT def DQT ( self , marker ) : NEW_LINE # ▁ Define ▁ quantization ▁ table . ▁ Support ▁ baseline ▁ 8 - bit ▁ tables ENDCOM # ▁ only . ▁ Note ▁ that ▁ there ▁ might ▁ be ▁ more ▁ than ▁ one ▁ table ▁ in ENDCOM # ▁ each ▁ marker . ENDCOM # ▁ FIXME : ▁ The ▁ quantization ▁ tables ▁ can ▁ be ▁ used ▁ to ▁ estimate ▁ the ENDCOM # ▁ compression ▁ quality . ENDCOM INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE while len ( s ) : NEW_LINE INDENT if len ( s ) < 65 : NEW_LINE INDENT raise SyntaxError ( " bad ▁ quantization ▁ table ▁ marker " ) NEW_LINE DEDENT v = i8 ( s [ 0 ] ) NEW_LINE if v // 16 == 0 : NEW_LINE INDENT self . quantization [ v & 15 ] = array . array ( " B " , s [ 1 : 65 ] ) NEW_LINE s = s [ 65 : ] NEW_LINE DEDENT else : NEW_LINE INDENT return # ▁ FIXME : ▁ add ▁ code ▁ to ▁ read ▁ 16 - bit ▁ tables ! ENDCOM NEW_LINE # ▁ raise ▁ SyntaxError , ▁ " bad ▁ quantization ▁ table ▁ element ▁ size " ENDCOM # ▁ JPEG ▁ marker ▁ table ENDCOM DEDENT DEDENT DEDENT MARKER = { 0xFFC0 : ( " SOF0" , " Baseline ▁ DCT " , SOF ) , 0xFFC1 : ( " SOF1" , " Extended ▁ Sequential ▁ DCT " , SOF ) , 0xFFC2 : ( " SOF2" , " Progressive ▁ DCT " , SOF ) , 0xFFC3 : ( " SOF3" , " Spatial ▁ lossless " , SOF ) , 0xFFC4 : ( " DHT " , " Define ▁ Huffman ▁ table " , Skip ) , 0xFFC5 : ( " SOF5" , " Differential ▁ sequential ▁ DCT " , SOF ) , 0xFFC6 : ( " SOF6" , " Differential ▁ progressive ▁ DCT " , SOF ) , 0xFFC7 : ( " SOF7" , " Differential ▁ spatial " , SOF ) , 0xFFC8 : ( " JPG " , " Extension " , None ) , 0xFFC9 : ( " SOF9" , " Extended ▁ sequential ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCA : ( " SOF10" , " Progressive ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCB : ( " SOF11" , " Spatial ▁ lossless ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCC : ( " DAC " , " Define ▁ arithmetic ▁ coding ▁ conditioning " , Skip ) , 0xFFCD : ( " SOF13" , " Differential ▁ sequential ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCE : ( " SOF14" , " Differential ▁ progressive ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCF : ( " SOF15" , " Differential ▁ spatial ▁ ( AC ) " , SOF ) , 0xFFD0 : ( " RST0" , " Restart ▁ 0" , None ) , 0xFFD1 : ( " RST1" , " Restart ▁ 1" , None ) , 0xFFD2 : ( " RST2" , " Restart ▁ 2" , None ) , 0xFFD3 : ( " RST3" , " Restart ▁ 3" , None ) , 0xFFD4 : ( " RST4" , " Restart ▁ 4" , None ) , 0xFFD5 : ( " RST5" , " Restart ▁ 5" , None ) , 0xFFD6 : ( " RST6" , " Restart ▁ 6" , None ) , 0xFFD7 : ( " RST7" , " Restart ▁ 7" , None ) , 0xFFD8 : ( " SOI " , " Start ▁ of ▁ image " , None ) , 0xFFD9 : ( " EOI " , " End ▁ of ▁ image " , None ) , 0xFFDA : ( " SOS " , " Start ▁ of ▁ scan " , Skip ) , 0xFFDB : ( " DQT " , " Define ▁ quantization ▁ table " , DQT ) , 0xFFDC : ( " DNL " , " Define ▁ number ▁ of ▁ lines " , Skip ) , 0xFFDD : ( " DRI " , " Define ▁ restart ▁ interval " , Skip ) , 0xFFDE : ( " DHP " , " Define ▁ hierarchical ▁ progression " , SOF ) , 0xFFDF : ( " EXP " , " Expand ▁ reference ▁ component " , Skip ) , 0xFFE0 : ( " APP0" , " Application ▁ segment ▁ 0" , APP ) , 0xFFE1 : ( " APP1" , " Application ▁ segment ▁ 1" , APP ) , 0xFFE2 : ( " APP2" , " Application ▁ segment ▁ 2" , APP ) , 0xFFE3 : ( " APP3" , " Application ▁ segment ▁ 3" , APP ) , 0xFFE4 : ( " APP4" , " Application ▁ segment ▁ 4" , APP ) , 0xFFE5 : ( " APP5" , " Application ▁ segment ▁ 5" , APP ) , 0xFFE6 : ( " APP6" , " Application ▁ segment ▁ 6" , APP ) , 0xFFE7 : ( " APP7" , " Application ▁ segment ▁ 7" , APP ) , 0xFFE8 : ( " APP8" , " Application ▁ segment ▁ 8" , APP ) , 0xFFE9 : ( " APP9" , " Application ▁ segment ▁ 9" , APP ) , 0xFFEA : ( " APP10" , " Application ▁ segment ▁ 10" , APP ) , 0xFFEB : ( " APP11" , " Application ▁ segment ▁ 11" , APP ) , 0xFFEC : ( " APP12" , " Application ▁ segment ▁ 12" , APP ) , 0xFFED : ( " APP13" , " Application ▁ segment ▁ 13" , APP ) , 0xFFEE : ( " APP14" , " Application ▁ segment ▁ 14" , APP ) , 0xFFEF : ( " APP15" , " Application ▁ segment ▁ 15" , APP ) , 0xFFF0 : ( " JPG0" , " Extension ▁ 0" , None ) , 0xFFF1 : ( " JPG1" , " Extension ▁ 1" , None ) , 0xFFF2 : ( " JPG2" , " Extension ▁ 2" , None ) , 0xFFF3 : ( " JPG3" , " Extension ▁ 3" , None ) , 0xFFF4 : ( " JPG4" , " Extension ▁ 4" , None ) , 0xFFF5 : ( " JPG5" , " Extension ▁ 5" , None ) , 0xFFF6 : ( " JPG6" , " Extension ▁ 6" , None ) , 0xFFF7 : ( " JPG7" , " Extension ▁ 7" , None ) , 0xFFF8 : ( " JPG8" , " Extension ▁ 8" , None ) , 0xFFF9 : ( " JPG9" , " Extension ▁ 9" , None ) , 0xFFFA : ( " JPG10" , " Extension ▁ 10" , None ) , 0xFFFB : ( " JPG11" , " Extension ▁ 11" , None ) , 0xFFFC : ( " JPG12" , " Extension ▁ 12" , None ) , 0xFFFD : ( " JPG13" , " Extension ▁ 13" , None ) , 0xFFFE : ( " COM " , " Comment " , COM ) } NEW_LINE def _accept ( prefix ) : NEW_LINE INDENT return prefix [ 0 : 1 ] == b " \377" NEW_LINE # ▁ Image ▁ plugin ▁ for ▁ JPEG ▁ and ▁ JFIF ▁ images . ENDCOM DEDENT class JpegImageFile ( ImageFile . ImageFile ) : NEW_LINE INDENT format = " JPEG " NEW_LINE format_description = " JPEG ▁ ( ISO ▁ 10918 ) " NEW_LINE def _open ( self ) : NEW_LINE INDENT s = self . fp . read ( 1 ) NEW_LINE if i8 ( s ) != 255 : NEW_LINE INDENT raise SyntaxError ( " not ▁ a ▁ JPEG ▁ file " ) NEW_LINE # ▁ Create ▁ attributes ENDCOM DEDENT self . bits = self . layers = 0 NEW_LINE # ▁ JPEG ▁ specifics ▁ ( internal ) ENDCOM self . layer = [ ] NEW_LINE self . huffman_dc = { } NEW_LINE self . huffman_ac = { } NEW_LINE self . quantization = { } NEW_LINE self . app = { } # ▁ compatibility ENDCOM NEW_LINE self . applist = [ ] NEW_LINE self . icclist = [ ] NEW_LINE while True : NEW_LINE INDENT i = i8 ( s ) NEW_LINE if i == 0xFF : NEW_LINE INDENT s = s + self . fp . read ( 1 ) NEW_LINE i = i16 ( s ) NEW_LINE DEDENT else : NEW_LINE # ▁ Skip ▁ non - 0xFF ▁ junk ENDCOM INDENT s = self . fp . read ( 1 ) NEW_LINE continue NEW_LINE DEDENT if i in MARKER : NEW_LINE INDENT name , description , handler = MARKER [ i ] NEW_LINE # ▁ print ( hex ( i ) , ▁ name , ▁ description ) ENDCOM if handler is not None : NEW_LINE INDENT handler ( self , i ) NEW_LINE DEDENT if i == 0xFFDA : # ▁ start ▁ of ▁ scan ENDCOM NEW_LINE INDENT rawmode = self . mode NEW_LINE if self . mode == " CMYK " : NEW_LINE INDENT rawmode = " CMYK ; I " # ▁ assume ▁ adobe ▁ conventions ENDCOM NEW_LINE DEDENT self . tile = [ ( " jpeg " , ( 0 , 0 ) + self . size , 0 , ( rawmode , " " ) ) ] NEW_LINE # ▁ self . _ _ offset ▁ = ▁ self . fp . tell ( ) ENDCOM break NEW_LINE DEDENT s = self . fp . read ( 1 ) NEW_LINE DEDENT elif i == 0 or i == 0xFFFF : NEW_LINE # ▁ padded ▁ marker ▁ or ▁ junk ; ▁ move ▁ on ENDCOM INDENT s = b " \xff " NEW_LINE DEDENT elif i == 0xFF00 : # ▁ Skip ▁ extraneous ▁ data ▁ ( escaped ▁ 0xFF ) ENDCOM NEW_LINE INDENT s = self . fp . read ( 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT raise SyntaxError ( " no ▁ marker ▁ found " ) NEW_LINE DEDENT DEDENT DEDENT def draft ( self , mode , size ) : NEW_LINE INDENT if len ( self . tile ) != 1 : NEW_LINE INDENT return NEW_LINE # ▁ Protect ▁ from ▁ second ▁ call ENDCOM DEDENT if self . decoderconfig : NEW_LINE INDENT return NEW_LINE DEDENT d , e , o , a = self . tile [ 0 ] NEW_LINE scale = 0 NEW_LINE if a [ 0 ] == " RGB " and mode in [ " L " , " YCbCr " ] : NEW_LINE INDENT self . mode = mode NEW_LINE a = mode , " " NEW_LINE DEDENT if size : NEW_LINE INDENT scale = min ( self . size [ 0 ] // size [ 0 ] , self . size [ 1 ] // size [ 1 ] ) NEW_LINE for s in [ 8 , 4 , 2 , 1 ] : NEW_LINE INDENT if scale >= s : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT e = e [ 0 ] , e [ 1 ] , ( e [ 2 ] - e [ 0 ] + s - 1 ) // s + e [ 0 ] , ( e [ 3 ] - e [ 1 ] + s - 1 ) // s + e [ 1 ] NEW_LINE self . size = ( ( self . size [ 0 ] + s - 1 ) // s , ( self . size [ 1 ] + s - 1 ) // s ) NEW_LINE scale = s NEW_LINE DEDENT self . tile = [ ( d , e , o , a ) ] NEW_LINE self . decoderconfig = ( scale , 0 ) NEW_LINE return self NEW_LINE DEDENT def load_djpeg ( self ) : NEW_LINE # ▁ ALTERNATIVE : ▁ handle ▁ JPEGs ▁ via ▁ the ▁ IJG ▁ command ▁ line ▁ utilities ENDCOM INDENT import subprocess NEW_LINE import tempfile NEW_LINE import os NEW_LINE f , path = tempfile . mkstemp ( ) NEW_LINE os . close ( f ) NEW_LINE if os . path . exists ( self . filename ) : NEW_LINE INDENT subprocess . check_call ( [ " djpeg " , " - outfile " , path , self . filename ] ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " Invalid ▁ Filename " ) NEW_LINE DEDENT try : NEW_LINE INDENT _im = Image . open ( path ) NEW_LINE _im . load ( ) NEW_LINE self . im = _im . im NEW_LINE DEDENT finally : NEW_LINE INDENT try : NEW_LINE INDENT os . unlink ( path ) NEW_LINE DEDENT except OSError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT self . mode = self . im . mode NEW_LINE self . size = self . im . size NEW_LINE self . tile = [ ] NEW_LINE DEDENT def _getexif ( self ) : NEW_LINE INDENT return _getexif ( self ) NEW_LINE DEDENT def _getmp ( self ) : NEW_LINE INDENT return _getmp ( self ) NEW_LINE DEDENT DEDENT def _fixup_dict ( src_dict ) : NEW_LINE # ▁ Helper ▁ function ▁ for ▁ _ getexif ( ) ENDCOM # ▁ returns ▁ a ▁ dict ▁ with ▁ any ▁ single ▁ item ▁ tuples / lists ▁ as ▁ individual ▁ values ENDCOM INDENT def _fixup ( value ) : NEW_LINE INDENT try : NEW_LINE INDENT if len ( value ) == 1 and not isinstance ( value , dict ) : NEW_LINE INDENT return value [ 0 ] NEW_LINE DEDENT DEDENT except : pass NEW_LINE return value NEW_LINE DEDENT return { k : _fixup ( v ) for k , v in src_dict . items ( ) } NEW_LINE DEDENT def _getexif ( self ) : NEW_LINE # ▁ Extract ▁ EXIF ▁ information . ▁ This ▁ method ▁ is ▁ highly ▁ experimental , ENDCOM # ▁ and ▁ is ▁ likely ▁ to ▁ be ▁ replaced ▁ with ▁ something ▁ better ▁ in ▁ a ▁ future ENDCOM # ▁ version . ENDCOM # ▁ The ▁ EXIF ▁ record ▁ consists ▁ of ▁ a ▁ TIFF ▁ file ▁ embedded ▁ in ▁ a ▁ JPEG ENDCOM # ▁ application ▁ marker ▁ ( ! ) . ENDCOM INDENT try : NEW_LINE INDENT data = self . info [ " exif " ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT file = io . BytesIO ( data [ 6 : ] ) NEW_LINE head = file . read ( 8 ) NEW_LINE # ▁ process ▁ dictionary ENDCOM info = TiffImagePlugin . ImageFileDirectory_v1 ( head ) NEW_LINE info . load ( file ) NEW_LINE exif = dict ( _fixup_dict ( info ) ) NEW_LINE # ▁ get ▁ exif ▁ extension ENDCOM try : NEW_LINE # ▁ exif ▁ field ▁ 0x8769 ▁ is ▁ an ▁ offset ▁ pointer ▁ to ▁ the ▁ location ENDCOM # ▁ of ▁ the ▁ nested ▁ embedded ▁ exif ▁ ifd . ENDCOM # ▁ It ▁ should ▁ be ▁ a ▁ long , ▁ but ▁ may ▁ be ▁ corrupted . ENDCOM INDENT file . seek ( exif [ 0x8769 ] ) NEW_LINE DEDENT except ( KeyError , TypeError ) : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT info = TiffImagePlugin . ImageFileDirectory_v1 ( head ) NEW_LINE info . load ( file ) NEW_LINE exif . update ( _fixup_dict ( info ) ) NEW_LINE # ▁ get ▁ gpsinfo ▁ extension ENDCOM DEDENT try : NEW_LINE # ▁ exif ▁ field ▁ 0x8825 ▁ is ▁ an ▁ offset ▁ pointer ▁ to ▁ the ▁ location ENDCOM # ▁ of ▁ the ▁ nested ▁ embedded ▁ gps ▁ exif ▁ ifd . ENDCOM # ▁ It ▁ should ▁ be ▁ a ▁ long , ▁ but ▁ may ▁ be ▁ corrupted . ENDCOM INDENT file . seek ( exif [ 0x8825 ] ) NEW_LINE DEDENT except ( KeyError , TypeError ) : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT info = TiffImagePlugin . ImageFileDirectory_v1 ( head ) NEW_LINE info . load ( file ) NEW_LINE exif [ 0x8825 ] = _fixup_dict ( info ) NEW_LINE DEDENT return exif NEW_LINE DEDENT def _getmp ( self ) : NEW_LINE # ▁ Extract ▁ MP ▁ information . ▁ This ▁ method ▁ was ▁ inspired ▁ by ▁ the ▁ " highly ENDCOM # ▁ experimental " ▁ _ getexif ▁ version ▁ that ' s ▁ been ▁ in ▁ use ▁ for ▁ years ▁ now , ENDCOM # ▁ itself ▁ based ▁ on ▁ the ▁ ImageFileDirectory ▁ class ▁ in ▁ the ▁ TIFF ▁ plug - in . ENDCOM # ▁ The ▁ MP ▁ record ▁ essentially ▁ consists ▁ of ▁ a ▁ TIFF ▁ file ▁ embedded ▁ in ▁ a ▁ JPEG ENDCOM # ▁ application ▁ marker . ENDCOM INDENT try : NEW_LINE INDENT data = self . info [ " mp " ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT file_contents = io . BytesIO ( data ) NEW_LINE head = file_contents . read ( 8 ) NEW_LINE endianness = ' > ' if head [ : 4 ] == b ' \x4d\x4d\x00\x2a ' else ' < ' NEW_LINE # ▁ process ▁ dictionary ENDCOM try : NEW_LINE INDENT info = TiffImagePlugin . ImageFileDirectory_v2 ( head ) NEW_LINE info . load ( file_contents ) NEW_LINE mp = dict ( info ) NEW_LINE DEDENT except : NEW_LINE INDENT raise SyntaxError ( " malformed ▁ MP ▁ Index ▁ ( unreadable ▁ directory ) " ) NEW_LINE # ▁ it ' s ▁ an ▁ error ▁ not ▁ to ▁ have ▁ a ▁ number ▁ of ▁ images ENDCOM DEDENT try : NEW_LINE INDENT quant = mp [ 0xB001 ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise SyntaxError ( " malformed ▁ MP ▁ Index ▁ ( no ▁ number ▁ of ▁ images ) " ) NEW_LINE # ▁ get ▁ MP ▁ entries ENDCOM DEDENT mpentries = [ ] NEW_LINE try : NEW_LINE INDENT rawmpentries = mp [ 0xB002 ] NEW_LINE for entrynum in range ( 0 , quant ) : NEW_LINE INDENT unpackedentry = unpack_from ( ' { } LLLHH ' . format ( endianness ) , rawmpentries , entrynum * 16 ) NEW_LINE labels = ( ' Attribute ' , ' Size ' , ' DataOffset ' , ' EntryNo1' , ' EntryNo2' ) NEW_LINE mpentry = dict ( zip ( labels , unpackedentry ) ) NEW_LINE mpentryattr = { ' DependentParentImageFlag ' : bool ( mpentry [ ' Attribute ' ] & ( 1 << 31 ) ) , ' DependentChildImageFlag ' : bool ( mpentry [ ' Attribute ' ] & ( 1 << 30 ) ) , ' RepresentativeImageFlag ' : bool ( mpentry [ ' Attribute ' ] & ( 1 << 29 ) ) , ' Reserved ' : ( mpentry [ ' Attribute ' ] & ( 3 << 27 ) ) >> 27 , ' ImageDataFormat ' : ( mpentry [ ' Attribute ' ] & ( 7 << 24 ) ) >> 24 , ' MPType ' : mpentry [ ' Attribute ' ] & 0x00FFFFFF } NEW_LINE if mpentryattr [ ' ImageDataFormat ' ] == 0 : NEW_LINE INDENT mpentryattr [ ' ImageDataFormat ' ] = ' JPEG ' NEW_LINE DEDENT else : NEW_LINE INDENT raise SyntaxError ( " unsupported ▁ picture ▁ format ▁ in ▁ MPO " ) NEW_LINE DEDENT mptypemap = { 0x000000 : ' Undefined ' , 0x010001 : ' Large ▁ Thumbnail ▁ ( VGA ▁ Equivalent ) ' , 0x010002 : ' Large ▁ Thumbnail ▁ ( Full ▁ HD ▁ Equivalent ) ' , 0x020001 : ' Multi - Frame ▁ Image ▁ ( Panorama ) ' , 0x020002 : ' Multi - Frame ▁ Image : ▁ ( Disparity ) ' , 0x020003 : ' Multi - Frame ▁ Image : ▁ ( Multi - Angle ) ' , 0x030000 : ' Baseline ▁ MP ▁ Primary ▁ Image ' } NEW_LINE mpentryattr [ ' MPType ' ] = mptypemap . get ( mpentryattr [ ' MPType ' ] , ' Unknown ' ) NEW_LINE mpentry [ ' Attribute ' ] = mpentryattr NEW_LINE mpentries . append ( mpentry ) NEW_LINE DEDENT mp [ 0xB002 ] = mpentries NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise SyntaxError ( " malformed ▁ MP ▁ Index ▁ ( bad ▁ MP ▁ Entry ) " ) NEW_LINE # ▁ Next ▁ we ▁ should ▁ try ▁ and ▁ parse ▁ the ▁ individual ▁ image ▁ unique ▁ ID ▁ list ; ENDCOM # ▁ we ▁ don ' t ▁ because ▁ I ' ve ▁ never ▁ seen ▁ this ▁ actually ▁ used ▁ in ▁ a ▁ real ▁ MPO ENDCOM # ▁ file ▁ and ▁ so ▁ can ' t ▁ test ▁ it . ENDCOM DEDENT return mp NEW_LINE # ▁ stuff ▁ to ▁ save ▁ JPEG ▁ files ENDCOM DEDENT RAWMODE = { "1" : " L " , " L " : " L " , " RGB " : " RGB " , " RGBA " : " RGB " , " RGBX " : " RGB " , " CMYK " : " CMYK ; I " , # ▁ assume ▁ adobe ▁ conventions ENDCOM " YCbCr " : " YCbCr " , } NEW_LINE zigzag_index = ( 0 , 1 , 5 , 6 , 14 , 15 , 27 , 28 , 2 , 4 , 7 , 13 , 16 , 26 , 29 , 42 , 3 , 8 , 12 , 17 , 25 , 30 , 41 , 43 , 9 , 11 , 18 , 24 , 31 , 40 , 44 , 53 , 10 , 19 , 23 , 32 , 39 , 45 , 52 , 54 , 20 , 22 , 33 , 38 , 46 , 51 , 55 , 60 , 21 , 34 , 37 , 47 , 50 , 56 , 59 , 61 , 35 , 36 , 48 , 49 , 57 , 58 , 62 , 63 ) NEW_LINE samplings = { ( 1 , 1 , 1 , 1 , 1 , 1 ) : 0 , ( 2 , 1 , 1 , 1 , 1 , 1 ) : 1 , ( 2 , 2 , 1 , 1 , 1 , 1 ) : 2 , } NEW_LINE def convert_dict_qtables ( qtables ) : NEW_LINE INDENT qtables = [ qtables [ key ] for key in range ( len ( qtables ) ) if key in qtables ] NEW_LINE for idx , table in enumerate ( qtables ) : NEW_LINE INDENT qtables [ idx ] = [ table [ i ] for i in zigzag_index ] NEW_LINE DEDENT return qtables NEW_LINE DEDENT def get_sampling ( im ) : NEW_LINE # ▁ There ' s ▁ no ▁ subsampling ▁ when ▁ image ▁ have ▁ only ▁ 1 ▁ layer ENDCOM # ▁ ( grayscale ▁ images ) ▁ or ▁ when ▁ they ▁ are ▁ CMYK ▁ ( 4 ▁ layers ) , ENDCOM # ▁ so ▁ set ▁ subsampling ▁ to ▁ default ▁ value . ENDCOM # ▁ NOTE : ▁ currently ▁ Pillow ▁ can ' t ▁ encode ▁ JPEG ▁ to ▁ YCCK ▁ format . ENDCOM # ▁ If ▁ YCCK ▁ support ▁ is ▁ added ▁ in ▁ the ▁ future , ▁ subsampling ▁ code ▁ will ▁ have ENDCOM # ▁ to ▁ be ▁ updated ▁ ( here ▁ and ▁ in ▁ JpegEncode . c ) ▁ to ▁ deal ▁ with ▁ 4 ▁ layers . ENDCOM INDENT if not hasattr ( im , ' layers ' ) or im . layers in ( 1 , 4 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT sampling = im . layer [ 0 ] [ 1 : 3 ] + im . layer [ 1 ] [ 1 : 3 ] + im . layer [ 2 ] [ 1 : 3 ] NEW_LINE return samplings . get ( sampling , - 1 ) NEW_LINE DEDENT def _save ( im , fp , filename ) : NEW_LINE INDENT try : NEW_LINE INDENT rawmode = RAWMODE [ im . mode ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise IOError ( " cannot ▁ write ▁ mode ▁ % s ▁ as ▁ JPEG " % im . mode ) NEW_LINE DEDENT if im . mode == ' RGBA ' : NEW_LINE INDENT warnings . warn ( ' You ▁ are ▁ saving ▁ RGBA ▁ image ▁ as ▁ JPEG . ▁ The ▁ alpha ▁ channel ▁ will ▁ be ▁ ' ' discarded . ▁ This ▁ conversion ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ disabled ▁ ' ' in ▁ Pillow ▁ 3.7 . ▁ Please , ▁ convert ▁ the ▁ image ▁ to ▁ RGB ▁ explicitly . ' , DeprecationWarning ) NEW_LINE DEDENT info = im . encoderinfo NEW_LINE dpi = [ int ( round ( x ) ) for x in info . get ( " dpi " , ( 0 , 0 ) ) ] NEW_LINE quality = info . get ( " quality " , 0 ) NEW_LINE subsampling = info . get ( " subsampling " , - 1 ) NEW_LINE qtables = info . get ( " qtables " ) NEW_LINE if quality == " keep " : NEW_LINE INDENT quality = 0 NEW_LINE subsampling = " keep " NEW_LINE qtables = " keep " NEW_LINE DEDENT elif quality in presets : NEW_LINE INDENT preset = presets [ quality ] NEW_LINE quality = 0 NEW_LINE subsampling = preset . get ( ' subsampling ' , - 1 ) NEW_LINE qtables = preset . get ( ' quantization ' ) NEW_LINE DEDENT elif not isinstance ( quality , int ) : NEW_LINE INDENT raise ValueError ( " Invalid ▁ quality ▁ setting " ) NEW_LINE DEDENT else : NEW_LINE INDENT if subsampling in presets : NEW_LINE INDENT subsampling = presets [ subsampling ] . get ( ' subsampling ' , - 1 ) NEW_LINE DEDENT if isStringType ( qtables ) and qtables in presets : NEW_LINE INDENT qtables = presets [ qtables ] . get ( ' quantization ' ) NEW_LINE DEDENT DEDENT if subsampling == "4:4:4" : NEW_LINE INDENT subsampling = 0 NEW_LINE DEDENT elif subsampling == "4:2:2" : NEW_LINE INDENT subsampling = 1 NEW_LINE DEDENT elif subsampling == "4:1:1" : NEW_LINE INDENT subsampling = 2 NEW_LINE DEDENT elif subsampling == " keep " : NEW_LINE INDENT if im . format != " JPEG " : NEW_LINE INDENT raise ValueError ( " Cannot ▁ use ▁ ' keep ' ▁ when ▁ original ▁ image ▁ is ▁ not ▁ a ▁ JPEG " ) NEW_LINE DEDENT subsampling = get_sampling ( im ) NEW_LINE DEDENT def validate_qtables ( qtables ) : NEW_LINE INDENT if qtables is None : NEW_LINE INDENT return qtables NEW_LINE DEDENT if isStringType ( qtables ) : NEW_LINE INDENT try : NEW_LINE INDENT lines = [ int ( num ) for line in qtables . splitlines ( ) for num in line . split ( ' # ' , 1 ) [ 0 ] . split ( ) ] NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise ValueError ( " Invalid ▁ quantization ▁ table " ) NEW_LINE DEDENT else : NEW_LINE INDENT qtables = [ lines [ s : s + 64 ] for s in range ( 0 , len ( lines ) , 64 ) ] NEW_LINE DEDENT DEDENT if isinstance ( qtables , ( tuple , list , dict ) ) : NEW_LINE INDENT if isinstance ( qtables , dict ) : NEW_LINE INDENT qtables = convert_dict_qtables ( qtables ) NEW_LINE DEDENT elif isinstance ( qtables , tuple ) : NEW_LINE INDENT qtables = list ( qtables ) NEW_LINE DEDENT if not ( 0 < len ( qtables ) < 5 ) : NEW_LINE INDENT raise ValueError ( " None ▁ or ▁ too ▁ many ▁ quantization ▁ tables " ) NEW_LINE DEDENT for idx , table in enumerate ( qtables ) : NEW_LINE INDENT try : NEW_LINE INDENT if len ( table ) != 64 : NEW_LINE INDENT raise NEW_LINE DEDENT table = array . array ( ' B ' , table ) NEW_LINE DEDENT except TypeError : NEW_LINE INDENT raise ValueError ( " Invalid ▁ quantization ▁ table " ) NEW_LINE DEDENT else : NEW_LINE INDENT qtables [ idx ] = list ( table ) NEW_LINE DEDENT DEDENT return qtables NEW_LINE DEDENT DEDENT if qtables == " keep " : NEW_LINE INDENT if im . format != " JPEG " : NEW_LINE INDENT raise ValueError ( " Cannot ▁ use ▁ ' keep ' ▁ when ▁ original ▁ image ▁ is ▁ not ▁ a ▁ JPEG " ) NEW_LINE DEDENT qtables = getattr ( im , " quantization " , None ) NEW_LINE DEDENT qtables = validate_qtables ( qtables ) NEW_LINE extra = b " " NEW_LINE icc_profile = info . get ( " icc _ profile " ) NEW_LINE if icc_profile : NEW_LINE INDENT ICC_OVERHEAD_LEN = 14 NEW_LINE MAX_BYTES_IN_MARKER = 65533 NEW_LINE MAX_DATA_BYTES_IN_MARKER = MAX_BYTES_IN_MARKER - ICC_OVERHEAD_LEN NEW_LINE markers = [ ] NEW_LINE while icc_profile : NEW_LINE INDENT markers . append ( icc_profile [ : MAX_DATA_BYTES_IN_MARKER ] ) NEW_LINE icc_profile = icc_profile [ MAX_DATA_BYTES_IN_MARKER : ] NEW_LINE DEDENT i = 1 NEW_LINE for marker in markers : NEW_LINE INDENT size = struct . pack ( " > H " , 2 + ICC_OVERHEAD_LEN + len ( marker ) ) NEW_LINE extra += ( b " \xFF\xE2" + size + b " ICC _ PROFILE\0" + o8 ( i ) + o8 ( len ( markers ) ) + marker ) NEW_LINE i += 1 NEW_LINE # ▁ " progressive " ▁ is ▁ the ▁ official ▁ name , ▁ but ▁ older ▁ documentation ENDCOM # ▁ says ▁ " progression " ENDCOM # ▁ FIXME : ▁ issue ▁ a ▁ warning ▁ if ▁ the ▁ wrong ▁ form ▁ is ▁ used ▁ ( post - 1.1.7 ) ENDCOM DEDENT DEDENT progressive = info . get ( " progressive " , False ) or info . get ( " progression " , False ) NEW_LINE optimize = info . get ( " optimize " , False ) NEW_LINE # ▁ get ▁ keyword ▁ arguments ENDCOM im . encoderconfig = ( quality , progressive , info . get ( " smooth " , 0 ) , optimize , info . get ( " streamtype " , 0 ) , dpi [ 0 ] , dpi [ 1 ] , subsampling , qtables , extra , info . get ( " exif " , b " " ) ) NEW_LINE # ▁ if ▁ we ▁ optimize , ▁ libjpeg ▁ needs ▁ a ▁ buffer ▁ big ▁ enough ▁ to ▁ hold ▁ the ▁ whole ▁ image ENDCOM # ▁ in ▁ a ▁ shot . ▁ Guessing ▁ on ▁ the ▁ size , ▁ at ▁ im . size ▁ bytes . ▁ ( raw ▁ pizel ▁ size ▁ is ENDCOM # ▁ channels * size , ▁ this ▁ is ▁ a ▁ value ▁ that ' s ▁ been ▁ used ▁ in ▁ a ▁ django ▁ patch . ENDCOM # ▁ https : / / github . com / matthewwithanm / django - imagekit / issues / 50 ENDCOM bufsize = 0 NEW_LINE if optimize or progressive : NEW_LINE # ▁ CMYK ▁ can ▁ be ▁ bigger ENDCOM INDENT if im . mode == ' CMYK ' : NEW_LINE INDENT bufsize = 4 * im . size [ 0 ] * im . size [ 1 ] NEW_LINE # ▁ keep ▁ sets ▁ quality ▁ to ▁ 0 , ▁ but ▁ the ▁ actual ▁ value ▁ may ▁ be ▁ high . ENDCOM DEDENT elif quality >= 95 or quality == 0 : NEW_LINE INDENT bufsize = 2 * im . size [ 0 ] * im . size [ 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT bufsize = im . size [ 0 ] * im . size [ 1 ] NEW_LINE # ▁ The ▁ exif ▁ info ▁ needs ▁ to ▁ be ▁ written ▁ as ▁ one ▁ block , ▁ + ▁ APP1 , ▁ + ▁ one ▁ spare ▁ byte . ENDCOM # ▁ Ensure ▁ that ▁ our ▁ buffer ▁ is ▁ big ▁ enough ENDCOM DEDENT DEDENT bufsize = max ( ImageFile . MAXBLOCK , bufsize , len ( info . get ( " exif " , b " " ) ) + 5 ) NEW_LINE ImageFile . _save ( im , fp , [ ( " jpeg " , ( 0 , 0 ) + im . size , 0 , rawmode ) ] , bufsize ) NEW_LINE DEDENT def _save_cjpeg ( im , fp , filename ) : NEW_LINE # ▁ ALTERNATIVE : ▁ handle ▁ JPEGs ▁ via ▁ the ▁ IJG ▁ command ▁ line ▁ utilities . ENDCOM INDENT import os NEW_LINE import subprocess NEW_LINE tempfile = im . _dump ( ) NEW_LINE subprocess . check_call ( [ " cjpeg " , " - outfile " , filename , tempfile ] ) NEW_LINE try : NEW_LINE INDENT os . unlink ( tempfile ) NEW_LINE DEDENT except OSError : NEW_LINE INDENT pass NEW_LINE # ▁ Factory ▁ for ▁ making ▁ JPEG ▁ and ▁ MPO ▁ instances ENDCOM DEDENT DEDENT def jpeg_factory ( fp = None , filename = None ) : NEW_LINE INDENT im = JpegImageFile ( fp , filename ) NEW_LINE try : NEW_LINE INDENT mpheader = im . _getmp ( ) NEW_LINE if mpheader [ 45057 ] > 1 : NEW_LINE # ▁ It ' s ▁ actually ▁ an ▁ MPO ENDCOM INDENT from . MpoImagePlugin import MpoImageFile NEW_LINE im = MpoImageFile ( fp , filename ) NEW_LINE DEDENT DEDENT except ( TypeError , IndexError ) : NEW_LINE # ▁ It ▁ is ▁ really ▁ a ▁ JPEG ENDCOM INDENT pass NEW_LINE DEDENT except SyntaxError : NEW_LINE INDENT warnings . warn ( " Image ▁ appears ▁ to ▁ be ▁ a ▁ malformed ▁ MPO ▁ file , ▁ it ▁ will ▁ be ▁ " " interpreted ▁ as ▁ a ▁ base ▁ JPEG ▁ file " ) NEW_LINE DEDENT return im NEW_LINE # ▁ Registry ▁ stuff ENDCOM DEDENT Image . register_open ( JpegImageFile . format , jpeg_factory , _accept ) NEW_LINE Image . register_save ( JpegImageFile . format , _save ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jfif " ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jpe " ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jpg " ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jpeg " ) NEW_LINE Image . register_mime ( JpegImageFile . format , " image / jpeg " ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="s40523220/2016fallcp_hw/tree/master/plugin/liquid_tags/test_generation.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM from __future__ import print_function NEW_LINE import filecmp NEW_LINE import os NEW_LINE import unittest NEW_LINE from shutil import rmtree NEW_LINE from tempfile import mkdtemp NEW_LINE import pytest NEW_LINE from pelican import Pelican NEW_LINE from pelican . settings import read_settings NEW_LINE from . notebook import IPYTHON_VERSION NEW_LINE PLUGIN_DIR = os . path . dirname ( __file__ ) NEW_LINE TEST_DATA_DIR = os . path . join ( PLUGIN_DIR , ' test _ data ' ) NEW_LINE class TestFullRun ( unittest . TestCase ) : NEW_LINE INDENT ''' Test ▁ running ▁ Pelican ▁ with ▁ the ▁ Plugin ''' NEW_LINE def setUp ( self ) : NEW_LINE INDENT ''' Create ▁ temporary ▁ output ▁ and ▁ cache ▁ folders ''' NEW_LINE self . temp_path = mkdtemp ( prefix = ' pelicantests . ' ) NEW_LINE self . temp_cache = mkdtemp ( prefix = ' pelican _ cache . ' ) NEW_LINE os . chdir ( TEST_DATA_DIR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT ''' Remove ▁ output ▁ and ▁ cache ▁ folders ''' NEW_LINE rmtree ( self . temp_path ) NEW_LINE rmtree ( self . temp_cache ) NEW_LINE os . chdir ( PLUGIN_DIR ) NEW_LINE DEDENT @ pytest . mark . skipif ( IPYTHON_VERSION >= 3 , reason = " output ▁ must ▁ be ▁ created ▁ with ▁ ipython ▁ version ▁ 2" ) NEW_LINE def test_generate_with_ipython3 ( self ) : NEW_LINE INDENT ''' Test ▁ generation ▁ of ▁ site ▁ with ▁ the ▁ plugin . ''' NEW_LINE base_path = os . path . dirname ( os . path . abspath ( __file__ ) ) NEW_LINE base_path = os . path . join ( base_path , ' test _ data ' ) NEW_LINE content_path = os . path . join ( base_path , ' content ' ) NEW_LINE output_path = os . path . join ( base_path , ' output ' ) NEW_LINE settings_path = os . path . join ( base_path , ' pelicanconf . py ' ) NEW_LINE settings = read_settings ( path = settings_path , override = { ' PATH ' : content_path , ' OUTPUT _ PATH ' : self . temp_path , ' CACHE _ PATH ' : self . temp_cache , } ) NEW_LINE pelican = Pelican ( settings ) NEW_LINE pelican . run ( ) NEW_LINE # ▁ test ▁ existence ENDCOM assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 3 . html ' ) ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 4 . html ' ) ) NEW_LINE # ▁ test ▁ differences ENDCOM # assert ▁ filecmp . cmp ( os . path . join ( output _ path , ENDCOM # ▁ ' test - ipython - notebook - v2 . html ' ) , ENDCOM # ▁ os . path . join ( self . temp _ path , ENDCOM # ▁ ' test - ipython - notebook . html ' ) ) ENDCOM DEDENT @ pytest . mark . skipif ( IPYTHON_VERSION < 3 , reason = " output ▁ must ▁ be ▁ created ▁ with ▁ ipython ▁ version ▁ 3" ) NEW_LINE def test_generate_with_ipython2 ( self ) : NEW_LINE INDENT ''' Test ▁ generation ▁ of ▁ site ▁ with ▁ the ▁ plugin . ''' NEW_LINE base_path = os . path . dirname ( os . path . abspath ( __file__ ) ) NEW_LINE base_path = os . path . join ( base_path , ' test _ data ' ) NEW_LINE content_path = os . path . join ( base_path , ' content ' ) NEW_LINE output_path = os . path . join ( base_path , ' output ' ) NEW_LINE settings_path = os . path . join ( base_path , ' pelicanconf . py ' ) NEW_LINE settings = read_settings ( path = settings_path , override = { ' PATH ' : content_path , ' OUTPUT _ PATH ' : self . temp_path , ' CACHE _ PATH ' : self . temp_cache , } ) NEW_LINE pelican = Pelican ( settings ) NEW_LINE pelican . run ( ) NEW_LINE # ▁ test ▁ existence ENDCOM assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 3 . html ' ) ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 4 . html ' ) ) NEW_LINE # ▁ test ▁ differences ENDCOM # assert ▁ filecmp . cmp ( os . path . join ( output _ path , ENDCOM # ▁ ' test - ipython - notebook - v3 . html ' ) , ENDCOM # ▁ os . path . join ( self . temp _ path , ENDCOM # ▁ ' test - ipython - notebook . html ' ) ) ENDCOM DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="achoy/cwapi/tree/master/backend/py-server/flask/lib/python3.6/site-packages/six.py"> """ Utilities ▁ for ▁ writing ▁ code ▁ that ▁ runs ▁ on ▁ Python ▁ 2 ▁ and ▁ 3 """ NEW_LINE # ▁ Copyright ▁ ( c ) ▁ 2010-2015 ▁ Benjamin ▁ Peterson ENDCOM # ▁ Permission ▁ is ▁ hereby ▁ granted , ▁ free ▁ of ▁ charge , ▁ to ▁ any ▁ person ▁ obtaining ▁ a ▁ copy ENDCOM # ▁ of ▁ this ▁ software ▁ and ▁ associated ▁ documentation ▁ files ▁ ( the ▁ " Software " ) , ▁ to ▁ deal ENDCOM # ▁ in ▁ the ▁ Software ▁ without ▁ restriction , ▁ including ▁ without ▁ limitation ▁ the ▁ rights ENDCOM # ▁ to ▁ use , ▁ copy , ▁ modify , ▁ merge , ▁ publish , ▁ distribute , ▁ sublicense , ▁ and / or ▁ sell ENDCOM # ▁ copies ▁ of ▁ the ▁ Software , ▁ and ▁ to ▁ permit ▁ persons ▁ to ▁ whom ▁ the ▁ Software ▁ is ENDCOM # ▁ furnished ▁ to ▁ do ▁ so , ▁ subject ▁ to ▁ the ▁ following ▁ conditions : ENDCOM # ▁ The ▁ above ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ shall ▁ be ▁ included ▁ in ▁ all ENDCOM # ▁ copies ▁ or ▁ substantial ▁ portions ▁ of ▁ the ▁ Software . ENDCOM # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ " AS ▁ IS " , ▁ WITHOUT ▁ WARRANTY ▁ OF ▁ ANY ▁ KIND , ▁ EXPRESS ▁ OR ENDCOM # ▁ IMPLIED , ▁ INCLUDING ▁ BUT ▁ NOT ▁ LIMITED ▁ TO ▁ THE ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY , ENDCOM # ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ AND ▁ NONINFRINGEMENT . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ENDCOM # ▁ AUTHORS ▁ OR ▁ COPYRIGHT ▁ HOLDERS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ CLAIM , ▁ DAMAGES ▁ OR ▁ OTHER ENDCOM # ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ AN ▁ ACTION ▁ OF ▁ CONTRACT , ▁ TORT ▁ OR ▁ OTHERWISE , ▁ ARISING ▁ FROM , ENDCOM # ▁ OUT ▁ OF ▁ OR ▁ IN ▁ CONNECTION ▁ WITH ▁ THE ▁ SOFTWARE ▁ OR ▁ THE ▁ USE ▁ OR ▁ OTHER ▁ DEALINGS ▁ IN ▁ THE ENDCOM # ▁ SOFTWARE . ENDCOM from __future__ import absolute_import NEW_LINE import functools NEW_LINE import itertools NEW_LINE import operator NEW_LINE import sys NEW_LINE import types NEW_LINE __author__ = " Benjamin ▁ Peterson ▁ < benjamin @ python . org > " NEW_LINE __version__ = "1.10.0" NEW_LINE # ▁ Useful ▁ for ▁ very ▁ coarse ▁ version ▁ differentiation . ENDCOM PY2 = sys . version_info [ 0 ] == 2 NEW_LINE PY3 = sys . version_info [ 0 ] == 3 NEW_LINE PY34 = sys . version_info [ 0 : 2 ] >= ( 3 , 4 ) NEW_LINE if PY3 : NEW_LINE INDENT string_types = str , NEW_LINE integer_types = int , NEW_LINE class_types = type , NEW_LINE text_type = str NEW_LINE binary_type = bytes NEW_LINE MAXSIZE = sys . maxsize NEW_LINE DEDENT else : NEW_LINE INDENT string_types = basestring , NEW_LINE integer_types = ( int , long ) NEW_LINE class_types = ( type , types . ClassType ) NEW_LINE text_type = unicode NEW_LINE binary_type = str NEW_LINE if sys . platform . startswith ( " java " ) : NEW_LINE # ▁ Jython ▁ always ▁ uses ▁ 32 ▁ bits . ENDCOM INDENT MAXSIZE = int ( ( 1 << 31 ) - 1 ) NEW_LINE DEDENT else : NEW_LINE # ▁ It ' s ▁ possible ▁ to ▁ have ▁ sizeof ( long ) ▁ ! = ▁ sizeof ( Py _ ssize _ t ) . ENDCOM INDENT class X ( object ) : NEW_LINE INDENT def __len__ ( self ) : NEW_LINE INDENT return 1 << 31 NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT len ( X ( ) ) NEW_LINE DEDENT except OverflowError : NEW_LINE # ▁ 32 - bit ENDCOM INDENT MAXSIZE = int ( ( 1 << 31 ) - 1 ) NEW_LINE DEDENT else : NEW_LINE # ▁ 64 - bit ENDCOM INDENT MAXSIZE = int ( ( 1 << 63 ) - 1 ) NEW_LINE DEDENT del X NEW_LINE DEDENT DEDENT def _add_doc ( func , doc ) : NEW_LINE INDENT """ Add ▁ documentation ▁ to ▁ a ▁ function . """ NEW_LINE func . __doc__ = doc NEW_LINE DEDENT def _import_module ( name ) : NEW_LINE INDENT """ Import ▁ module , ▁ returning ▁ the ▁ module ▁ after ▁ the ▁ last ▁ dot . """ NEW_LINE __import__ ( name ) NEW_LINE return sys . modules [ name ] NEW_LINE DEDENT class _LazyDescr ( object ) : NEW_LINE INDENT def __init__ ( self , name ) : NEW_LINE INDENT self . name = name NEW_LINE DEDENT def __get__ ( self , obj , tp ) : NEW_LINE INDENT result = self . _resolve ( ) NEW_LINE setattr ( obj , self . name , result ) # ▁ Invokes ▁ _ _ set _ _ . ENDCOM NEW_LINE try : NEW_LINE # ▁ This ▁ is ▁ a ▁ bit ▁ ugly , ▁ but ▁ it ▁ avoids ▁ running ▁ this ▁ again ▁ by ENDCOM # ▁ removing ▁ this ▁ descriptor . ENDCOM INDENT delattr ( obj . __class__ , self . name ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT pass NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT class MovedModule ( _LazyDescr ) : NEW_LINE INDENT def __init__ ( self , name , old , new = None ) : NEW_LINE INDENT super ( MovedModule , self ) . __init__ ( name ) NEW_LINE if PY3 : NEW_LINE INDENT if new is None : NEW_LINE INDENT new = name NEW_LINE DEDENT self . mod = new NEW_LINE DEDENT else : NEW_LINE INDENT self . mod = old NEW_LINE DEDENT DEDENT def _resolve ( self ) : NEW_LINE INDENT return _import_module ( self . mod ) NEW_LINE DEDENT def __getattr__ ( self , attr ) : NEW_LINE INDENT _module = self . _resolve ( ) NEW_LINE value = getattr ( _module , attr ) NEW_LINE setattr ( self , attr , value ) NEW_LINE return value NEW_LINE DEDENT DEDENT class _LazyModule ( types . ModuleType ) : NEW_LINE INDENT def __init__ ( self , name ) : NEW_LINE INDENT super ( _LazyModule , self ) . __init__ ( name ) NEW_LINE self . __doc__ = self . __class__ . __doc__ NEW_LINE DEDENT def __dir__ ( self ) : NEW_LINE INDENT attrs = [ " _ _ doc _ _ " , " _ _ name _ _ " ] NEW_LINE attrs += [ attr . name for attr in self . _moved_attributes ] NEW_LINE return attrs NEW_LINE # ▁ Subclasses ▁ should ▁ override ▁ this ENDCOM DEDENT _moved_attributes = [ ] NEW_LINE DEDENT class MovedAttribute ( _LazyDescr ) : NEW_LINE INDENT def __init__ ( self , name , old_mod , new_mod , old_attr = None , new_attr = None ) : NEW_LINE INDENT super ( MovedAttribute , self ) . __init__ ( name ) NEW_LINE if PY3 : NEW_LINE INDENT if new_mod is None : NEW_LINE INDENT new_mod = name NEW_LINE DEDENT self . mod = new_mod NEW_LINE if new_attr is None : NEW_LINE INDENT if old_attr is None : NEW_LINE INDENT new_attr = name NEW_LINE DEDENT else : NEW_LINE INDENT new_attr = old_attr NEW_LINE DEDENT DEDENT self . attr = new_attr NEW_LINE DEDENT else : NEW_LINE INDENT self . mod = old_mod NEW_LINE if old_attr is None : NEW_LINE INDENT old_attr = name NEW_LINE DEDENT self . attr = old_attr NEW_LINE DEDENT DEDENT def _resolve ( self ) : NEW_LINE INDENT module = _import_module ( self . mod ) NEW_LINE return getattr ( module , self . attr ) NEW_LINE DEDENT DEDENT class _SixMetaPathImporter ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ meta ▁ path ▁ importer ▁ to ▁ import ▁ six . moves ▁ and ▁ its ▁ submodules . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ implements ▁ a ▁ PEP302 ▁ finder ▁ and ▁ loader . ▁ It ▁ should ▁ be ▁ compatible STRNEWLINE ▁ with ▁ Python ▁ 2.5 ▁ and ▁ all ▁ existing ▁ versions ▁ of ▁ Python3 STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , six_module_name ) : NEW_LINE INDENT self . name = six_module_name NEW_LINE self . known_modules = { } NEW_LINE DEDENT def _add_module ( self , mod , * fullnames ) : NEW_LINE INDENT for fullname in fullnames : NEW_LINE INDENT self . known_modules [ self . name + " . " + fullname ] = mod NEW_LINE DEDENT DEDENT def _get_module ( self , fullname ) : NEW_LINE INDENT return self . known_modules [ self . name + " . " + fullname ] NEW_LINE DEDENT def find_module ( self , fullname , path = None ) : NEW_LINE INDENT if fullname in self . known_modules : NEW_LINE INDENT return self NEW_LINE DEDENT return None NEW_LINE DEDENT def __get_module ( self , fullname ) : NEW_LINE INDENT try : NEW_LINE INDENT return self . known_modules [ fullname ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ImportError ( " This ▁ loader ▁ does ▁ not ▁ know ▁ module ▁ " + fullname ) NEW_LINE DEDENT DEDENT def load_module ( self , fullname ) : NEW_LINE INDENT try : NEW_LINE # ▁ in ▁ case ▁ of ▁ a ▁ reload ENDCOM INDENT return sys . modules [ fullname ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT mod = self . __get_module ( fullname ) NEW_LINE if isinstance ( mod , MovedModule ) : NEW_LINE INDENT mod = mod . _resolve ( ) NEW_LINE DEDENT else : NEW_LINE INDENT mod . __loader__ = self NEW_LINE DEDENT sys . modules [ fullname ] = mod NEW_LINE return mod NEW_LINE DEDENT def is_package ( self , fullname ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ true , ▁ if ▁ the ▁ named ▁ module ▁ is ▁ a ▁ package . STRNEWLINE STRNEWLINE ▁ We ▁ need ▁ this ▁ method ▁ to ▁ get ▁ correct ▁ spec ▁ objects ▁ with STRNEWLINE ▁ Python ▁ 3.4 ▁ ( see ▁ PEP451 ) STRNEWLINE ▁ """ NEW_LINE return hasattr ( self . __get_module ( fullname ) , " _ _ path _ _ " ) NEW_LINE DEDENT def get_code ( self , fullname ) : NEW_LINE INDENT """ Return ▁ None STRNEWLINE STRNEWLINE ▁ Required , ▁ if ▁ is _ package ▁ is ▁ implemented """ NEW_LINE self . __get_module ( fullname ) # ▁ eventually ▁ raises ▁ ImportError ENDCOM NEW_LINE return None NEW_LINE DEDENT get_source = get_code # ▁ same ▁ as ▁ get _ code ENDCOM NEW_LINE DEDENT _importer = _SixMetaPathImporter ( __name__ ) NEW_LINE class _MovedItems ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects """ NEW_LINE __path__ = [ ] # ▁ mark ▁ as ▁ package ENDCOM NEW_LINE DEDENT _moved_attributes = [ MovedAttribute ( " cStringIO " , " cStringIO " , " io " , " StringIO " ) , MovedAttribute ( " filter " , " itertools " , " builtins " , " ifilter " , " filter " ) , MovedAttribute ( " filterfalse " , " itertools " , " itertools " , " ifilterfalse " , " filterfalse " ) , MovedAttribute ( " input " , " _ _ builtin _ _ " , " builtins " , " raw _ input " , " input " ) , MovedAttribute ( " intern " , " _ _ builtin _ _ " , " sys " ) , MovedAttribute ( " map " , " itertools " , " builtins " , " imap " , " map " ) , MovedAttribute ( " getcwd " , " os " , " os " , " getcwdu " , " getcwd " ) , MovedAttribute ( " getcwdb " , " os " , " os " , " getcwd " , " getcwdb " ) , MovedAttribute ( " range " , " _ _ builtin _ _ " , " builtins " , " xrange " , " range " ) , MovedAttribute ( " reload _ module " , " _ _ builtin _ _ " , " importlib " if PY34 else " imp " , " reload " ) , MovedAttribute ( " reduce " , " _ _ builtin _ _ " , " functools " ) , MovedAttribute ( " shlex _ quote " , " pipes " , " shlex " , " quote " ) , MovedAttribute ( " StringIO " , " StringIO " , " io " ) , MovedAttribute ( " UserDict " , " UserDict " , " collections " ) , MovedAttribute ( " UserList " , " UserList " , " collections " ) , MovedAttribute ( " UserString " , " UserString " , " collections " ) , MovedAttribute ( " xrange " , " _ _ builtin _ _ " , " builtins " , " xrange " , " range " ) , MovedAttribute ( " zip " , " itertools " , " builtins " , " izip " , " zip " ) , MovedAttribute ( " zip _ longest " , " itertools " , " itertools " , " izip _ longest " , " zip _ longest " ) , MovedModule ( " builtins " , " _ _ builtin _ _ " ) , MovedModule ( " configparser " , " ConfigParser " ) , MovedModule ( " copyreg " , " copy _ reg " ) , MovedModule ( " dbm _ gnu " , " gdbm " , " dbm . gnu " ) , MovedModule ( " _ dummy _ thread " , " dummy _ thread " , " _ dummy _ thread " ) , MovedModule ( " http _ cookiejar " , " cookielib " , " http . cookiejar " ) , MovedModule ( " http _ cookies " , " Cookie " , " http . cookies " ) , MovedModule ( " html _ entities " , " htmlentitydefs " , " html . entities " ) , MovedModule ( " html _ parser " , " HTMLParser " , " html . parser " ) , MovedModule ( " http _ client " , " httplib " , " http . client " ) , MovedModule ( " email _ mime _ multipart " , " email . MIMEMultipart " , " email . mime . multipart " ) , MovedModule ( " email _ mime _ nonmultipart " , " email . MIMENonMultipart " , " email . mime . nonmultipart " ) , MovedModule ( " email _ mime _ text " , " email . MIMEText " , " email . mime . text " ) , MovedModule ( " email _ mime _ base " , " email . MIMEBase " , " email . mime . base " ) , MovedModule ( " BaseHTTPServer " , " BaseHTTPServer " , " http . server " ) , MovedModule ( " CGIHTTPServer " , " CGIHTTPServer " , " http . server " ) , MovedModule ( " SimpleHTTPServer " , " SimpleHTTPServer " , " http . server " ) , MovedModule ( " cPickle " , " cPickle " , " pickle " ) , MovedModule ( " queue " , " Queue " ) , MovedModule ( " reprlib " , " repr " ) , MovedModule ( " socketserver " , " SocketServer " ) , MovedModule ( " _ thread " , " thread " , " _ thread " ) , MovedModule ( " tkinter " , " Tkinter " ) , MovedModule ( " tkinter _ dialog " , " Dialog " , " tkinter . dialog " ) , MovedModule ( " tkinter _ filedialog " , " FileDialog " , " tkinter . filedialog " ) , MovedModule ( " tkinter _ scrolledtext " , " ScrolledText " , " tkinter . scrolledtext " ) , MovedModule ( " tkinter _ simpledialog " , " SimpleDialog " , " tkinter . simpledialog " ) , MovedModule ( " tkinter _ tix " , " Tix " , " tkinter . tix " ) , MovedModule ( " tkinter _ ttk " , " ttk " , " tkinter . ttk " ) , MovedModule ( " tkinter _ constants " , " Tkconstants " , " tkinter . constants " ) , MovedModule ( " tkinter _ dnd " , " Tkdnd " , " tkinter . dnd " ) , MovedModule ( " tkinter _ colorchooser " , " tkColorChooser " , " tkinter . colorchooser " ) , MovedModule ( " tkinter _ commondialog " , " tkCommonDialog " , " tkinter . commondialog " ) , MovedModule ( " tkinter _ tkfiledialog " , " tkFileDialog " , " tkinter . filedialog " ) , MovedModule ( " tkinter _ font " , " tkFont " , " tkinter . font " ) , MovedModule ( " tkinter _ messagebox " , " tkMessageBox " , " tkinter . messagebox " ) , MovedModule ( " tkinter _ tksimpledialog " , " tkSimpleDialog " , " tkinter . simpledialog " ) , MovedModule ( " urllib _ parse " , __name__ + " . moves . urllib _ parse " , " urllib . parse " ) , MovedModule ( " urllib _ error " , __name__ + " . moves . urllib _ error " , " urllib . error " ) , MovedModule ( " urllib " , __name__ + " . moves . urllib " , __name__ + " . moves . urllib " ) , MovedModule ( " urllib _ robotparser " , " robotparser " , " urllib . robotparser " ) , MovedModule ( " xmlrpc _ client " , " xmlrpclib " , " xmlrpc . client " ) , MovedModule ( " xmlrpc _ server " , " SimpleXMLRPCServer " , " xmlrpc . server " ) , ] NEW_LINE # ▁ Add ▁ windows ▁ specific ▁ modules . ENDCOM if sys . platform == " win32" : NEW_LINE INDENT _moved_attributes += [ MovedModule ( " winreg " , " _ winreg " ) , ] NEW_LINE DEDENT for attr in _moved_attributes : NEW_LINE INDENT setattr ( _MovedItems , attr . name , attr ) NEW_LINE if isinstance ( attr , MovedModule ) : NEW_LINE INDENT _importer . _add_module ( attr , " moves . " + attr . name ) NEW_LINE DEDENT DEDENT del attr NEW_LINE _MovedItems . _moved_attributes = _moved_attributes NEW_LINE moves = _MovedItems ( __name__ + " . moves " ) NEW_LINE _importer . _add_module ( moves , " moves " ) NEW_LINE class Module_six_moves_urllib_parse ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ parse """ NEW_LINE DEDENT _urllib_parse_moved_attributes = [ MovedAttribute ( " ParseResult " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " SplitResult " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " parse _ qs " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " parse _ qsl " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urldefrag " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urljoin " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlparse " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlsplit " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlunparse " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlunsplit " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " quote " , " urllib " , " urllib . parse " ) , MovedAttribute ( " quote _ plus " , " urllib " , " urllib . parse " ) , MovedAttribute ( " unquote " , " urllib " , " urllib . parse " ) , MovedAttribute ( " unquote _ plus " , " urllib " , " urllib . parse " ) , MovedAttribute ( " urlencode " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splitquery " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splittag " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splituser " , " urllib " , " urllib . parse " ) , MovedAttribute ( " uses _ fragment " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ netloc " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ params " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ query " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ relative " , " urlparse " , " urllib . parse " ) , ] NEW_LINE for attr in _urllib_parse_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_parse , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_parse . _moved_attributes = _urllib_parse_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_parse ( __name__ + " . moves . urllib _ parse " ) , " moves . urllib _ parse " , " moves . urllib . parse " ) NEW_LINE class Module_six_moves_urllib_error ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ error """ NEW_LINE DEDENT _urllib_error_moved_attributes = [ MovedAttribute ( " URLError " , " urllib2" , " urllib . error " ) , MovedAttribute ( " HTTPError " , " urllib2" , " urllib . error " ) , MovedAttribute ( " ContentTooShortError " , " urllib " , " urllib . error " ) , ] NEW_LINE for attr in _urllib_error_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_error , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_error . _moved_attributes = _urllib_error_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_error ( __name__ + " . moves . urllib . error " ) , " moves . urllib _ error " , " moves . urllib . error " ) NEW_LINE class Module_six_moves_urllib_request ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ request """ NEW_LINE DEDENT _urllib_request_moved_attributes = [ MovedAttribute ( " urlopen " , " urllib2" , " urllib . request " ) , MovedAttribute ( " install _ opener " , " urllib2" , " urllib . request " ) , MovedAttribute ( " build _ opener " , " urllib2" , " urllib . request " ) , MovedAttribute ( " pathname2url " , " urllib " , " urllib . request " ) , MovedAttribute ( " url2pathname " , " urllib " , " urllib . request " ) , MovedAttribute ( " getproxies " , " urllib " , " urllib . request " ) , MovedAttribute ( " Request " , " urllib2" , " urllib . request " ) , MovedAttribute ( " OpenerDirector " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPDefaultErrorHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPRedirectHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPCookieProcessor " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " BaseHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPPasswordMgr " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPPasswordMgrWithDefaultRealm " , " urllib2" , " urllib . request " ) , MovedAttribute ( " AbstractBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " AbstractDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPSHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " FileHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " FTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " CacheFTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " UnknownHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPErrorProcessor " , " urllib2" , " urllib . request " ) , MovedAttribute ( " urlretrieve " , " urllib " , " urllib . request " ) , MovedAttribute ( " urlcleanup " , " urllib " , " urllib . request " ) , MovedAttribute ( " URLopener " , " urllib " , " urllib . request " ) , MovedAttribute ( " FancyURLopener " , " urllib " , " urllib . request " ) , MovedAttribute ( " proxy _ bypass " , " urllib " , " urllib . request " ) , ] NEW_LINE for attr in _urllib_request_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_request , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_request . _moved_attributes = _urllib_request_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_request ( __name__ + " . moves . urllib . request " ) , " moves . urllib _ request " , " moves . urllib . request " ) NEW_LINE class Module_six_moves_urllib_response ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ response """ NEW_LINE DEDENT _urllib_response_moved_attributes = [ MovedAttribute ( " addbase " , " urllib " , " urllib . response " ) , MovedAttribute ( " addclosehook " , " urllib " , " urllib . response " ) , MovedAttribute ( " addinfo " , " urllib " , " urllib . response " ) , MovedAttribute ( " addinfourl " , " urllib " , " urllib . response " ) , ] NEW_LINE for attr in _urllib_response_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_response , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_response . _moved_attributes = _urllib_response_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_response ( __name__ + " . moves . urllib . response " ) , " moves . urllib _ response " , " moves . urllib . response " ) NEW_LINE class Module_six_moves_urllib_robotparser ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ robotparser """ NEW_LINE DEDENT _urllib_robotparser_moved_attributes = [ MovedAttribute ( " RobotFileParser " , " robotparser " , " urllib . robotparser " ) , ] NEW_LINE for attr in _urllib_robotparser_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_robotparser , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_robotparser . _moved_attributes = _urllib_robotparser_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_robotparser ( __name__ + " . moves . urllib . robotparser " ) , " moves . urllib _ robotparser " , " moves . urllib . robotparser " ) NEW_LINE class Module_six_moves_urllib ( types . ModuleType ) : NEW_LINE INDENT """ Create ▁ a ▁ six . moves . urllib ▁ namespace ▁ that ▁ resembles ▁ the ▁ Python ▁ 3 ▁ namespace """ NEW_LINE __path__ = [ ] # ▁ mark ▁ as ▁ package ENDCOM NEW_LINE parse = _importer . _get_module ( " moves . urllib _ parse " ) NEW_LINE error = _importer . _get_module ( " moves . urllib _ error " ) NEW_LINE request = _importer . _get_module ( " moves . urllib _ request " ) NEW_LINE response = _importer . _get_module ( " moves . urllib _ response " ) NEW_LINE robotparser = _importer . _get_module ( " moves . urllib _ robotparser " ) NEW_LINE def __dir__ ( self ) : NEW_LINE INDENT return [ ' parse ' , ' error ' , ' request ' , ' response ' , ' robotparser ' ] NEW_LINE DEDENT DEDENT _importer . _add_module ( Module_six_moves_urllib ( __name__ + " . moves . urllib " ) , " moves . urllib " ) NEW_LINE def add_move ( move ) : NEW_LINE INDENT """ Add ▁ an ▁ item ▁ to ▁ six . moves . """ NEW_LINE setattr ( _MovedItems , move . name , move ) NEW_LINE DEDENT def remove_move ( name ) : NEW_LINE INDENT """ Remove ▁ item ▁ from ▁ six . moves . """ NEW_LINE try : NEW_LINE INDENT delattr ( _MovedItems , name ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT try : NEW_LINE INDENT del moves . __dict__ [ name ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise AttributeError ( " no ▁ such ▁ move , ▁ % r " % ( name , ) ) NEW_LINE DEDENT DEDENT DEDENT if PY3 : NEW_LINE INDENT _meth_func = " _ _ func _ _ " NEW_LINE _meth_self = " _ _ self _ _ " NEW_LINE _func_closure = " _ _ closure _ _ " NEW_LINE _func_code = " _ _ code _ _ " NEW_LINE _func_defaults = " _ _ defaults _ _ " NEW_LINE _func_globals = " _ _ globals _ _ " NEW_LINE DEDENT else : NEW_LINE INDENT _meth_func = " im _ func " NEW_LINE _meth_self = " im _ self " NEW_LINE _func_closure = " func _ closure " NEW_LINE _func_code = " func _ code " NEW_LINE _func_defaults = " func _ defaults " NEW_LINE _func_globals = " func _ globals " NEW_LINE DEDENT try : NEW_LINE INDENT advance_iterator = next NEW_LINE DEDENT except NameError : NEW_LINE INDENT def advance_iterator ( it ) : NEW_LINE INDENT return it . next ( ) NEW_LINE DEDENT DEDENT next = advance_iterator NEW_LINE try : NEW_LINE INDENT callable = callable NEW_LINE DEDENT except NameError : NEW_LINE INDENT def callable ( obj ) : NEW_LINE INDENT return any ( " _ _ call _ _ " in klass . __dict__ for klass in type ( obj ) . __mro__ ) NEW_LINE DEDENT DEDENT if PY3 : NEW_LINE INDENT def get_unbound_function ( unbound ) : NEW_LINE INDENT return unbound NEW_LINE DEDENT create_bound_method = types . MethodType NEW_LINE def create_unbound_method ( func , cls ) : NEW_LINE INDENT return func NEW_LINE DEDENT Iterator = object NEW_LINE DEDENT else : NEW_LINE INDENT def get_unbound_function ( unbound ) : NEW_LINE INDENT return unbound . im_func NEW_LINE DEDENT def create_bound_method ( func , obj ) : NEW_LINE INDENT return types . MethodType ( func , obj , obj . __class__ ) NEW_LINE DEDENT def create_unbound_method ( func , cls ) : NEW_LINE INDENT return types . MethodType ( func , None , cls ) NEW_LINE DEDENT class Iterator ( object ) : NEW_LINE INDENT def next ( self ) : NEW_LINE INDENT return type ( self ) . __next__ ( self ) NEW_LINE DEDENT DEDENT callable = callable NEW_LINE DEDENT _add_doc ( get_unbound_function , """ Get ▁ the ▁ function ▁ out ▁ of ▁ a ▁ possibly ▁ unbound ▁ function """ ) NEW_LINE get_method_function = operator . attrgetter ( _meth_func ) NEW_LINE get_method_self = operator . attrgetter ( _meth_self ) NEW_LINE get_function_closure = operator . attrgetter ( _func_closure ) NEW_LINE get_function_code = operator . attrgetter ( _func_code ) NEW_LINE get_function_defaults = operator . attrgetter ( _func_defaults ) NEW_LINE get_function_globals = operator . attrgetter ( _func_globals ) NEW_LINE if PY3 : NEW_LINE INDENT def iterkeys ( d , ** kw ) : NEW_LINE INDENT return iter ( d . keys ( ** kw ) ) NEW_LINE DEDENT def itervalues ( d , ** kw ) : NEW_LINE INDENT return iter ( d . values ( ** kw ) ) NEW_LINE DEDENT def iteritems ( d , ** kw ) : NEW_LINE INDENT return iter ( d . items ( ** kw ) ) NEW_LINE DEDENT def iterlists ( d , ** kw ) : NEW_LINE INDENT return iter ( d . lists ( ** kw ) ) NEW_LINE DEDENT viewkeys = operator . methodcaller ( " keys " ) NEW_LINE viewvalues = operator . methodcaller ( " values " ) NEW_LINE viewitems = operator . methodcaller ( " items " ) NEW_LINE DEDENT else : NEW_LINE INDENT def iterkeys ( d , ** kw ) : NEW_LINE INDENT return d . iterkeys ( ** kw ) NEW_LINE DEDENT def itervalues ( d , ** kw ) : NEW_LINE INDENT return d . itervalues ( ** kw ) NEW_LINE DEDENT def iteritems ( d , ** kw ) : NEW_LINE INDENT return d . iteritems ( ** kw ) NEW_LINE DEDENT def iterlists ( d , ** kw ) : NEW_LINE INDENT return d . iterlists ( ** kw ) NEW_LINE DEDENT viewkeys = operator . methodcaller ( " viewkeys " ) NEW_LINE viewvalues = operator . methodcaller ( " viewvalues " ) NEW_LINE viewitems = operator . methodcaller ( " viewitems " ) NEW_LINE DEDENT _add_doc ( iterkeys , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ keys ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( itervalues , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ values ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( iteritems , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ ( key , ▁ value ) ▁ pairs ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( iterlists , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ ( key , ▁ [ values ] ) ▁ pairs ▁ of ▁ a ▁ dictionary . " ) NEW_LINE if PY3 : NEW_LINE INDENT def b ( s ) : NEW_LINE INDENT return s . encode ( " latin - 1" ) NEW_LINE DEDENT def u ( s ) : NEW_LINE INDENT return s NEW_LINE DEDENT unichr = chr NEW_LINE import struct NEW_LINE int2byte = struct . Struct ( " > B " ) . pack NEW_LINE del struct NEW_LINE byte2int = operator . itemgetter ( 0 ) NEW_LINE indexbytes = operator . getitem NEW_LINE iterbytes = iter NEW_LINE import io NEW_LINE StringIO = io . StringIO NEW_LINE BytesIO = io . BytesIO NEW_LINE _assertCountEqual = " assertCountEqual " NEW_LINE if sys . version_info [ 1 ] <= 1 : NEW_LINE INDENT _assertRaisesRegex = " assertRaisesRegexp " NEW_LINE _assertRegex = " assertRegexpMatches " NEW_LINE DEDENT else : NEW_LINE INDENT _assertRaisesRegex = " assertRaisesRegex " NEW_LINE _assertRegex = " assertRegex " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def b ( s ) : NEW_LINE INDENT return s NEW_LINE # ▁ Workaround ▁ for ▁ standalone ▁ backslash ENDCOM DEDENT def u ( s ) : NEW_LINE INDENT return unicode ( s . replace ( r ' \\ ' , r ' \\\\ ' ) , " unicode _ escape " ) NEW_LINE DEDENT unichr = unichr NEW_LINE int2byte = chr NEW_LINE def byte2int ( bs ) : NEW_LINE INDENT return ord ( bs [ 0 ] ) NEW_LINE DEDENT def indexbytes ( buf , i ) : NEW_LINE INDENT return ord ( buf [ i ] ) NEW_LINE DEDENT iterbytes = functools . partial ( itertools . imap , ord ) NEW_LINE import StringIO NEW_LINE StringIO = BytesIO = StringIO . StringIO NEW_LINE _assertCountEqual = " assertItemsEqual " NEW_LINE _assertRaisesRegex = " assertRaisesRegexp " NEW_LINE _assertRegex = " assertRegexpMatches " NEW_LINE DEDENT _add_doc ( b , """ Byte ▁ literal """ ) NEW_LINE _add_doc ( u , """ Text ▁ literal """ ) NEW_LINE def assertCountEqual ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertCountEqual ) ( * args , ** kwargs ) NEW_LINE DEDENT def assertRaisesRegex ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertRaisesRegex ) ( * args , ** kwargs ) NEW_LINE DEDENT def assertRegex ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertRegex ) ( * args , ** kwargs ) NEW_LINE DEDENT if PY3 : NEW_LINE INDENT exec_ = getattr ( moves . builtins , " exec " ) NEW_LINE def reraise ( tp , value , tb = None ) : NEW_LINE INDENT if value is None : NEW_LINE INDENT value = tp ( ) NEW_LINE DEDENT if value . __traceback__ is not tb : NEW_LINE INDENT raise value . with_traceback ( tb ) NEW_LINE DEDENT raise value NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def exec_ ( _code_ , _globs_ = None , _locs_ = None ) : NEW_LINE INDENT """ Execute ▁ code ▁ in ▁ a ▁ namespace . """ NEW_LINE if _globs_ is None : NEW_LINE INDENT frame = sys . _getframe ( 1 ) NEW_LINE _globs_ = frame . f_globals NEW_LINE if _locs_ is None : NEW_LINE INDENT _locs_ = frame . f_locals NEW_LINE DEDENT del frame NEW_LINE DEDENT elif _locs_ is None : NEW_LINE INDENT _locs_ = _globs_ NEW_LINE DEDENT exec ( """ exec ▁ _ code _ ▁ in ▁ _ globs _ , ▁ _ locs _ """ ) NEW_LINE DEDENT exec_ ( """ def ▁ reraise ( tp , ▁ value , ▁ tb = None ) : STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ tp , ▁ value , ▁ tb STRNEWLINE """ ) NEW_LINE DEDENT if sys . version_info [ : 2 ] == ( 3 , 2 ) : NEW_LINE INDENT exec_ ( """ def ▁ raise _ from ( value , ▁ from _ value ) : STRNEWLINE ▁ ▁ ▁ ▁ if ▁ from _ value ▁ is ▁ None : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ raise ▁ value STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ value ▁ from ▁ from _ value STRNEWLINE """ ) NEW_LINE DEDENT elif sys . version_info [ : 2 ] > ( 3 , 2 ) : NEW_LINE INDENT exec_ ( """ def ▁ raise _ from ( value , ▁ from _ value ) : STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ value ▁ from ▁ from _ value STRNEWLINE """ ) NEW_LINE DEDENT else : NEW_LINE INDENT def raise_from ( value , from_value ) : NEW_LINE INDENT raise value NEW_LINE DEDENT DEDENT print_ = getattr ( moves . builtins , " print " , None ) NEW_LINE if print_ is None : NEW_LINE INDENT def print_ ( * args , ** kwargs ) : NEW_LINE INDENT """ The ▁ new - style ▁ print ▁ function ▁ for ▁ Python ▁ 2.4 ▁ and ▁ 2.5 . """ NEW_LINE fp = kwargs . pop ( " file " , sys . stdout ) NEW_LINE if fp is None : NEW_LINE INDENT return NEW_LINE DEDENT def write ( data ) : NEW_LINE INDENT if not isinstance ( data , basestring ) : NEW_LINE INDENT data = str ( data ) NEW_LINE # ▁ If ▁ the ▁ file ▁ has ▁ an ▁ encoding , ▁ encode ▁ unicode ▁ with ▁ it . ENDCOM DEDENT if ( isinstance ( fp , file ) and isinstance ( data , unicode ) and fp . encoding is not None ) : NEW_LINE INDENT errors = getattr ( fp , " errors " , None ) NEW_LINE if errors is None : NEW_LINE INDENT errors = " strict " NEW_LINE DEDENT data = data . encode ( fp . encoding , errors ) NEW_LINE DEDENT fp . write ( data ) NEW_LINE DEDENT want_unicode = False NEW_LINE sep = kwargs . pop ( " sep " , None ) NEW_LINE if sep is not None : NEW_LINE INDENT if isinstance ( sep , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE DEDENT elif not isinstance ( sep , str ) : NEW_LINE INDENT raise TypeError ( " sep ▁ must ▁ be ▁ None ▁ or ▁ a ▁ string " ) NEW_LINE DEDENT DEDENT end = kwargs . pop ( " end " , None ) NEW_LINE if end is not None : NEW_LINE INDENT if isinstance ( end , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE DEDENT elif not isinstance ( end , str ) : NEW_LINE INDENT raise TypeError ( " end ▁ must ▁ be ▁ None ▁ or ▁ a ▁ string " ) NEW_LINE DEDENT DEDENT if kwargs : NEW_LINE INDENT raise TypeError ( " invalid ▁ keyword ▁ arguments ▁ to ▁ print ( ) " ) NEW_LINE DEDENT if not want_unicode : NEW_LINE INDENT for arg in args : NEW_LINE INDENT if isinstance ( arg , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT if want_unicode : NEW_LINE INDENT newline = unicode ( " \n " ) NEW_LINE space = unicode ( " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT newline = " \n " NEW_LINE space = " ▁ " NEW_LINE DEDENT if sep is None : NEW_LINE INDENT sep = space NEW_LINE DEDENT if end is None : NEW_LINE INDENT end = newline NEW_LINE DEDENT for i , arg in enumerate ( args ) : NEW_LINE INDENT if i : NEW_LINE INDENT write ( sep ) NEW_LINE DEDENT write ( arg ) NEW_LINE DEDENT write ( end ) NEW_LINE DEDENT DEDENT if sys . version_info [ : 2 ] < ( 3 , 3 ) : NEW_LINE INDENT _print = print_ NEW_LINE def print_ ( * args , ** kwargs ) : NEW_LINE INDENT fp = kwargs . get ( " file " , sys . stdout ) NEW_LINE flush = kwargs . pop ( " flush " , False ) NEW_LINE _print ( * args , ** kwargs ) NEW_LINE if flush and fp is not None : NEW_LINE INDENT fp . flush ( ) NEW_LINE DEDENT DEDENT DEDENT _add_doc ( reraise , """ Reraise ▁ an ▁ exception . """ ) NEW_LINE if sys . version_info [ 0 : 2 ] < ( 3 , 4 ) : NEW_LINE INDENT def wraps ( wrapped , assigned = functools . WRAPPER_ASSIGNMENTS , updated = functools . WRAPPER_UPDATES ) : NEW_LINE INDENT def wrapper ( f ) : NEW_LINE INDENT f = functools . wraps ( wrapped , assigned , updated ) ( f ) NEW_LINE f . __wrapped__ = wrapped NEW_LINE return f NEW_LINE DEDENT return wrapper NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT wraps = functools . wraps NEW_LINE DEDENT def with_metaclass ( meta , * bases ) : NEW_LINE INDENT """ Create ▁ a ▁ base ▁ class ▁ with ▁ a ▁ metaclass . """ NEW_LINE # ▁ This ▁ requires ▁ a ▁ bit ▁ of ▁ explanation : ▁ the ▁ basic ▁ idea ▁ is ▁ to ▁ make ▁ a ▁ dummy ENDCOM # ▁ metaclass ▁ for ▁ one ▁ level ▁ of ▁ class ▁ instantiation ▁ that ▁ replaces ▁ itself ▁ with ENDCOM # ▁ the ▁ actual ▁ metaclass . ENDCOM class metaclass ( meta ) : NEW_LINE INDENT def __new__ ( cls , name , this_bases , d ) : NEW_LINE INDENT return meta ( name , bases , d ) NEW_LINE DEDENT DEDENT return type . __new__ ( metaclass , ' temporary _ class ' , ( ) , { } ) NEW_LINE DEDENT def add_metaclass ( metaclass ) : NEW_LINE INDENT """ Class ▁ decorator ▁ for ▁ creating ▁ a ▁ class ▁ with ▁ a ▁ metaclass . """ NEW_LINE def wrapper ( cls ) : NEW_LINE INDENT orig_vars = cls . __dict__ . copy ( ) NEW_LINE slots = orig_vars . get ( ' _ _ slots _ _ ' ) NEW_LINE if slots is not None : NEW_LINE INDENT if isinstance ( slots , str ) : NEW_LINE INDENT slots = [ slots ] NEW_LINE DEDENT for slots_var in slots : NEW_LINE INDENT orig_vars . pop ( slots_var ) NEW_LINE DEDENT DEDENT orig_vars . pop ( ' _ _ dict _ _ ' , None ) NEW_LINE orig_vars . pop ( ' _ _ weakref _ _ ' , None ) NEW_LINE return metaclass ( cls . __name__ , cls . __bases__ , orig_vars ) NEW_LINE DEDENT return wrapper NEW_LINE DEDENT def python_2_unicode_compatible ( klass ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ decorator ▁ that ▁ defines ▁ _ _ unicode _ _ ▁ and ▁ _ _ str _ _ ▁ methods ▁ under ▁ Python ▁ 2 . STRNEWLINE ▁ Under ▁ Python ▁ 3 ▁ it ▁ does ▁ nothing . STRNEWLINE STRNEWLINE ▁ To ▁ support ▁ Python ▁ 2 ▁ and ▁ 3 ▁ with ▁ a ▁ single ▁ code ▁ base , ▁ define ▁ a ▁ _ _ str _ _ ▁ method STRNEWLINE ▁ returning ▁ text ▁ and ▁ apply ▁ this ▁ decorator ▁ to ▁ the ▁ class . STRNEWLINE ▁ """ NEW_LINE if PY2 : NEW_LINE INDENT if ' _ _ str _ _ ' not in klass . __dict__ : NEW_LINE INDENT raise ValueError ( " @ python _ 2 _ unicode _ compatible ▁ cannot ▁ be ▁ applied ▁ " " to ▁ % s ▁ because ▁ it ▁ doesn ' t ▁ define ▁ _ _ str _ _ ( ) . " % klass . __name__ ) NEW_LINE DEDENT klass . __unicode__ = klass . __str__ NEW_LINE klass . __str__ = lambda self : self . __unicode__ ( ) . encode ( ' utf - 8' ) NEW_LINE DEDENT return klass NEW_LINE # ▁ Complete ▁ the ▁ moves ▁ implementation . ENDCOM # ▁ This ▁ code ▁ is ▁ at ▁ the ▁ end ▁ of ▁ this ▁ module ▁ to ▁ speed ▁ up ▁ module ▁ loading . ENDCOM # ▁ Turn ▁ this ▁ module ▁ into ▁ a ▁ package . ENDCOM DEDENT __path__ = [ ] # ▁ required ▁ for ▁ PEP ▁ 302 ▁ and ▁ PEP ▁ 451 ENDCOM NEW_LINE __package__ = __name__ # ▁ see ▁ PEP ▁ 366 ▁ @ ReservedAssignment ENDCOM NEW_LINE if globals ( ) . get ( " _ _ spec _ _ " ) is not None : NEW_LINE INDENT __spec__ . submodule_search_locations = [ ] # ▁ PEP ▁ 451 ▁ @ UndefinedVariable ENDCOM NEW_LINE # ▁ Remove ▁ other ▁ six ▁ meta ▁ path ▁ importers , ▁ since ▁ they ▁ cause ▁ problems . ▁ This ▁ can ENDCOM # ▁ happen ▁ if ▁ six ▁ is ▁ removed ▁ from ▁ sys . modules ▁ and ▁ then ▁ reloaded . ▁ ( Setuptools ▁ does ENDCOM # ▁ this ▁ for ▁ some ▁ reason . ) ENDCOM DEDENT if sys . meta_path : NEW_LINE INDENT for i , importer in enumerate ( sys . meta_path ) : NEW_LINE # ▁ Here ' s ▁ some ▁ real ▁ nastiness : ▁ Another ▁ " instance " ▁ of ▁ the ▁ six ▁ module ▁ might ENDCOM # ▁ be ▁ floating ▁ around . ▁ Therefore , ▁ we ▁ can ' t ▁ use ▁ isinstance ( ) ▁ to ▁ check ▁ for ENDCOM # ▁ the ▁ six ▁ meta ▁ path ▁ importer , ▁ since ▁ the ▁ other ▁ six ▁ instance ▁ will ▁ have ENDCOM # ▁ inserted ▁ an ▁ importer ▁ with ▁ different ▁ class . ENDCOM INDENT if ( type ( importer ) . __name__ == " _ SixMetaPathImporter " and importer . name == __name__ ) : NEW_LINE INDENT del sys . meta_path [ i ] NEW_LINE break NEW_LINE DEDENT DEDENT del i , importer NEW_LINE # ▁ Finally , ▁ add ▁ the ▁ importer ▁ to ▁ the ▁ meta ▁ path ▁ import ▁ hook . ENDCOM DEDENT sys . meta_path . append ( _importer ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="Thraxis/pymedusa/tree/master/lib/html5lib/treewalkers/etree.py"> from __future__ import absolute_import , division , unicode_literals NEW_LINE try : NEW_LINE INDENT from collections import OrderedDict NEW_LINE DEDENT except ImportError : NEW_LINE INDENT try : NEW_LINE INDENT from ordereddict import OrderedDict NEW_LINE DEDENT except ImportError : NEW_LINE INDENT OrderedDict = dict NEW_LINE DEDENT DEDENT import re NEW_LINE from six import string_types NEW_LINE from . import _base NEW_LINE from . . utils import moduleFactoryFactory NEW_LINE tag_regexp = re . compile ( " { ( [ ^ } ] * ) } ( . * ) " ) NEW_LINE def getETreeBuilder ( ElementTreeImplementation ) : NEW_LINE INDENT ElementTree = ElementTreeImplementation NEW_LINE ElementTreeCommentType = ElementTree . Comment ( " asd " ) . tag NEW_LINE class TreeWalker ( _base . NonRecursiveTreeWalker ) : NEW_LINE INDENT """ Given ▁ the ▁ particular ▁ ElementTree ▁ representation , ▁ this ▁ implementation , STRNEWLINE ▁ to ▁ avoid ▁ using ▁ recursion , ▁ returns ▁ " nodes " ▁ as ▁ tuples ▁ with ▁ the ▁ following STRNEWLINE ▁ content : STRNEWLINE STRNEWLINE ▁ 1 . ▁ The ▁ current ▁ element STRNEWLINE STRNEWLINE ▁ 2 . ▁ The ▁ index ▁ of ▁ the ▁ element ▁ relative ▁ to ▁ its ▁ parent STRNEWLINE STRNEWLINE ▁ 3 . ▁ A ▁ stack ▁ of ▁ ancestor ▁ elements STRNEWLINE STRNEWLINE ▁ 4 . ▁ A ▁ flag ▁ " text " , ▁ " tail " ▁ or ▁ None ▁ to ▁ indicate ▁ if ▁ the ▁ current ▁ node ▁ is ▁ a STRNEWLINE ▁ text ▁ node ; ▁ either ▁ the ▁ text ▁ or ▁ tail ▁ of ▁ the ▁ current ▁ element ▁ ( 1 ) STRNEWLINE ▁ """ NEW_LINE def getNodeDetails ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : # ▁ It ▁ might ▁ be ▁ the ▁ root ▁ Element ENDCOM NEW_LINE INDENT elt , key , parents , flag = node NEW_LINE if flag in ( " text " , " tail " ) : NEW_LINE INDENT return _base . TEXT , getattr ( elt , flag ) NEW_LINE DEDENT else : NEW_LINE INDENT node = elt NEW_LINE DEDENT DEDENT if not ( hasattr ( node , " tag " ) ) : NEW_LINE INDENT node = node . getroot ( ) NEW_LINE DEDENT if node . tag in ( " DOCUMENT _ ROOT " , " DOCUMENT _ FRAGMENT " ) : NEW_LINE INDENT return ( _base . DOCUMENT , ) NEW_LINE DEDENT elif node . tag == " < ! DOCTYPE > " : NEW_LINE INDENT return ( _base . DOCTYPE , node . text , node . get ( " publicId " ) , node . get ( " systemId " ) ) NEW_LINE DEDENT elif node . tag == ElementTreeCommentType : NEW_LINE INDENT return _base . COMMENT , node . text NEW_LINE DEDENT else : NEW_LINE INDENT assert isinstance ( node . tag , string_types ) , type ( node . tag ) NEW_LINE # ▁ This ▁ is ▁ assumed ▁ to ▁ be ▁ an ▁ ordinary ▁ element ENDCOM match = tag_regexp . match ( node . tag ) NEW_LINE if match : NEW_LINE INDENT namespace , tag = match . groups ( ) NEW_LINE DEDENT else : NEW_LINE INDENT namespace = None NEW_LINE tag = node . tag NEW_LINE DEDENT attrs = OrderedDict ( ) NEW_LINE for name , value in list ( node . attrib . items ( ) ) : NEW_LINE INDENT match = tag_regexp . match ( name ) NEW_LINE if match : NEW_LINE INDENT attrs [ ( match . group ( 1 ) , match . group ( 2 ) ) ] = value NEW_LINE DEDENT else : NEW_LINE INDENT attrs [ ( None , name ) ] = value NEW_LINE DEDENT DEDENT return ( _base . ELEMENT , namespace , tag , attrs , len ( node ) or node . text ) NEW_LINE DEDENT DEDENT def getFirstChild ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT element , key , parents , flag = node , None , [ ] , None NEW_LINE DEDENT if flag in ( " text " , " tail " ) : NEW_LINE INDENT return None NEW_LINE DEDENT else : NEW_LINE INDENT if element . text : NEW_LINE INDENT return element , key , parents , " text " NEW_LINE DEDENT elif len ( element ) : NEW_LINE INDENT parents . append ( element ) NEW_LINE return element [ 0 ] , 0 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT DEDENT def getNextSibling ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT if flag == " text " : NEW_LINE INDENT if len ( element ) : NEW_LINE INDENT parents . append ( element ) NEW_LINE return element [ 0 ] , 0 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if element . tail and flag != " tail " : NEW_LINE INDENT return element , key , parents , " tail " NEW_LINE DEDENT elif key < len ( parents [ - 1 ] ) - 1 : NEW_LINE INDENT return parents [ - 1 ] [ key + 1 ] , key + 1 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT DEDENT def getParentNode ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT if flag == " text " : NEW_LINE INDENT if not parents : NEW_LINE INDENT return element NEW_LINE DEDENT else : NEW_LINE INDENT return element , key , parents , None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT parent = parents . pop ( ) NEW_LINE if not parents : NEW_LINE INDENT return parent NEW_LINE DEDENT else : NEW_LINE INDENT return parent , list ( parents [ - 1 ] ) . index ( parent ) , parents , None NEW_LINE DEDENT DEDENT DEDENT DEDENT return locals ( ) NEW_LINE DEDENT getETreeModule = moduleFactoryFactory ( getETreeBuilder ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="coronary/RandomEpisode/tree/master/depends/Lib/encodings/cp1006.py"> """ ▁ Python ▁ Character ▁ Mapping ▁ Codec ▁ cp1006 ▁ generated ▁ from ▁ ' MAPPINGS / VENDORS / MISC / CP1006 . TXT ' ▁ with ▁ gencodec . py . STRNEWLINE STRNEWLINE """ NEW_LINE import codecs NEW_LINE # # # ▁ Codec ▁ APIs ENDCOM class Codec ( codecs . Codec ) : NEW_LINE INDENT def encode ( self , input , errors = ' strict ' ) : NEW_LINE INDENT return codecs . charmap_encode ( input , errors , encoding_table ) NEW_LINE DEDENT def decode ( self , input , errors = ' strict ' ) : NEW_LINE INDENT return codecs . charmap_decode ( input , errors , decoding_table ) NEW_LINE DEDENT DEDENT class IncrementalEncoder ( codecs . IncrementalEncoder ) : NEW_LINE INDENT def encode ( self , input , final = False ) : NEW_LINE INDENT return codecs . charmap_encode ( input , self . errors , encoding_table ) [ 0 ] NEW_LINE DEDENT DEDENT class IncrementalDecoder ( codecs . IncrementalDecoder ) : NEW_LINE INDENT def decode ( self , input , final = False ) : NEW_LINE INDENT return codecs . charmap_decode ( input , self . errors , decoding_table ) [ 0 ] NEW_LINE DEDENT DEDENT class StreamWriter ( Codec , codecs . StreamWriter ) : NEW_LINE INDENT pass NEW_LINE DEDENT class StreamReader ( Codec , codecs . StreamReader ) : NEW_LINE INDENT pass NEW_LINE # # # ▁ encodings ▁ module ▁ API ENDCOM DEDENT def getregentry ( ) : NEW_LINE INDENT return codecs . CodecInfo ( name = ' cp1006' , encode = Codec ( ) . encode , decode = Codec ( ) . decode , incrementalencoder = IncrementalEncoder , incrementaldecoder = IncrementalDecoder , streamreader = StreamReader , streamwriter = StreamWriter , ) NEW_LINE # # # ▁ Decoding ▁ Table ENDCOM DEDENT decoding_table = ( ' \x00' # ▁ 0x00 ▁ - > ▁ NULL ENDCOM ' \x01' # ▁ 0x01 ▁ - > ▁ START ▁ OF ▁ HEADING ENDCOM ' \x02' # ▁ 0x02 ▁ - > ▁ START ▁ OF ▁ TEXT ENDCOM ' \x03' # ▁ 0x03 ▁ - > ▁ END ▁ OF ▁ TEXT ENDCOM ' \x04' # ▁ 0x04 ▁ - > ▁ END ▁ OF ▁ TRANSMISSION ENDCOM ' \x05' # ▁ 0x05 ▁ - > ▁ ENQUIRY ENDCOM ' \x06' # ▁ 0x06 ▁ - > ▁ ACKNOWLEDGE ENDCOM ' \x07' # ▁ 0x07 ▁ - > ▁ BELL ENDCOM ' \x08' # ▁ 0x08 ▁ - > ▁ BACKSPACE ENDCOM ' \t ' # ▁ 0x09 ▁ - > ▁ HORIZONTAL ▁ TABULATION ENDCOM ' \n ' # ▁ 0x0A ▁ - > ▁ LINE ▁ FEED ENDCOM ' \x0b ' # ▁ 0x0B ▁ - > ▁ VERTICAL ▁ TABULATION ENDCOM ' \x0c ' # ▁ 0x0C ▁ - > ▁ FORM ▁ FEED ENDCOM ' ' # ▁ 0x0D ▁ - > ▁ CARRIAGE ▁ RETURN ENDCOM ' \x0e ' # ▁ 0x0E ▁ - > ▁ SHIFT ▁ OUT ENDCOM ' \x0f ' # ▁ 0x0F ▁ - > ▁ SHIFT ▁ IN ENDCOM ' \x10' # ▁ 0x10 ▁ - > ▁ DATA ▁ LINK ▁ ESCAPE ENDCOM ' \x11' # ▁ 0x11 ▁ - > ▁ DEVICE ▁ CONTROL ▁ ONE ENDCOM ' \x12' # ▁ 0x12 ▁ - > ▁ DEVICE ▁ CONTROL ▁ TWO ENDCOM ' \x13' # ▁ 0x13 ▁ - > ▁ DEVICE ▁ CONTROL ▁ THREE ENDCOM ' \x14' # ▁ 0x14 ▁ - > ▁ DEVICE ▁ CONTROL ▁ FOUR ENDCOM ' \x15' # ▁ 0x15 ▁ - > ▁ NEGATIVE ▁ ACKNOWLEDGE ENDCOM ' \x16' # ▁ 0x16 ▁ - > ▁ SYNCHRONOUS ▁ IDLE ENDCOM ' \x17' # ▁ 0x17 ▁ - > ▁ END ▁ OF ▁ TRANSMISSION ▁ BLOCK ENDCOM ' \x18' # ▁ 0x18 ▁ - > ▁ CANCEL ENDCOM ' \x19' # ▁ 0x19 ▁ - > ▁ END ▁ OF ▁ MEDIUM ENDCOM ' \x1a ' # ▁ 0x1A ▁ - > ▁ SUBSTITUTE ENDCOM ' \x1b ' # ▁ 0x1B ▁ - > ▁ ESCAPE ENDCOM ' \x1c ' # ▁ 0x1C ▁ - > ▁ FILE ▁ SEPARATOR ENDCOM ' \x1d ' # ▁ 0x1D ▁ - > ▁ GROUP ▁ SEPARATOR ENDCOM ' \x1e ' # ▁ 0x1E ▁ - > ▁ RECORD ▁ SEPARATOR ENDCOM ' \x1f ' # ▁ 0x1F ▁ - > ▁ UNIT ▁ SEPARATOR ENDCOM ' ▁ ' # ▁ 0x20 ▁ - > ▁ SPACE ENDCOM ' ! ' # ▁ 0x21 ▁ - > ▁ EXCLAMATION ▁ MARK ENDCOM ' " ' # ▁ 0x22 ▁ - > ▁ QUOTATION ▁ MARK ENDCOM ' # ' # ▁ 0x23 ▁ - > ▁ NUMBER ▁ SIGN ENDCOM ' $ ' # ▁ 0x24 ▁ - > ▁ DOLLAR ▁ SIGN ENDCOM ' % ' # ▁ 0x25 ▁ - > ▁ PERCENT ▁ SIGN ENDCOM ' & ' # ▁ 0x26 ▁ - > ▁ AMPERSAND ENDCOM " ' " # ▁ 0x27 ▁ - > ▁ APOSTROPHE ENDCOM ' ( ' # ▁ 0x28 ▁ - > ▁ LEFT ▁ PARENTHESIS ENDCOM ' ) ' # ▁ 0x29 ▁ - > ▁ RIGHT ▁ PARENTHESIS ENDCOM ' * ' # ▁ 0x2A ▁ - > ▁ ASTERISK ENDCOM ' + ' # ▁ 0x2B ▁ - > ▁ PLUS ▁ SIGN ENDCOM ' , ' # ▁ 0x2C ▁ - > ▁ COMMA ENDCOM ' - ' # ▁ 0x2D ▁ - > ▁ HYPHEN - MINUS ENDCOM ' . ' # ▁ 0x2E ▁ - > ▁ FULL ▁ STOP ENDCOM ' / ' # ▁ 0x2F ▁ - > ▁ SOLIDUS ENDCOM '0' # ▁ 0x30 ▁ - > ▁ DIGIT ▁ ZERO ENDCOM '1' # ▁ 0x31 ▁ - > ▁ DIGIT ▁ ONE ENDCOM '2' # ▁ 0x32 ▁ - > ▁ DIGIT ▁ TWO ENDCOM '3' # ▁ 0x33 ▁ - > ▁ DIGIT ▁ THREE ENDCOM '4' # ▁ 0x34 ▁ - > ▁ DIGIT ▁ FOUR ENDCOM '5' # ▁ 0x35 ▁ - > ▁ DIGIT ▁ FIVE ENDCOM '6' # ▁ 0x36 ▁ - > ▁ DIGIT ▁ SIX ENDCOM '7' # ▁ 0x37 ▁ - > ▁ DIGIT ▁ SEVEN ENDCOM '8' # ▁ 0x38 ▁ - > ▁ DIGIT ▁ EIGHT ENDCOM '9' # ▁ 0x39 ▁ - > ▁ DIGIT ▁ NINE ENDCOM ' : ' # ▁ 0x3A ▁ - > ▁ COLON ENDCOM ' ; ' # ▁ 0x3B ▁ - > ▁ SEMICOLON ENDCOM ' < ' # ▁ 0x3C ▁ - > ▁ LESS - THAN ▁ SIGN ENDCOM ' = ' # ▁ 0x3D ▁ - > ▁ EQUALS ▁ SIGN ENDCOM ' > ' # ▁ 0x3E ▁ - > ▁ GREATER - THAN ▁ SIGN ENDCOM ' ? ' # ▁ 0x3F ▁ - > ▁ QUESTION ▁ MARK ENDCOM ' @ ' # ▁ 0x40 ▁ - > ▁ COMMERCIAL ▁ AT ENDCOM ' A ' # ▁ 0x41 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ A ENDCOM ' B ' # ▁ 0x42 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ B ENDCOM ' C ' # ▁ 0x43 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ C ENDCOM ' D ' # ▁ 0x44 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ D ENDCOM ' E ' # ▁ 0x45 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ E ENDCOM ' F ' # ▁ 0x46 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ F ENDCOM ' G ' # ▁ 0x47 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ G ENDCOM ' H ' # ▁ 0x48 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ H ENDCOM ' I ' # ▁ 0x49 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ I ENDCOM ' J ' # ▁ 0x4A ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ J ENDCOM ' K ' # ▁ 0x4B ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ K ENDCOM ' L ' # ▁ 0x4C ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ L ENDCOM ' M ' # ▁ 0x4D ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ M ENDCOM ' N ' # ▁ 0x4E ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ N ENDCOM ' O ' # ▁ 0x4F ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ O ENDCOM ' P ' # ▁ 0x50 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ P ENDCOM ' Q ' # ▁ 0x51 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ Q ENDCOM ' R ' # ▁ 0x52 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ R ENDCOM ' S ' # ▁ 0x53 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ S ENDCOM ' T ' # ▁ 0x54 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ T ENDCOM ' U ' # ▁ 0x55 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ U ENDCOM ' V ' # ▁ 0x56 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ V ENDCOM ' W ' # ▁ 0x57 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ W ENDCOM ' X ' # ▁ 0x58 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ X ENDCOM ' Y ' # ▁ 0x59 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ Y ENDCOM ' Z ' # ▁ 0x5A ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ Z ENDCOM ' [ ' # ▁ 0x5B ▁ - > ▁ LEFT ▁ SQUARE ▁ BRACKET ENDCOM ' \\ ' # ▁ 0x5C ▁ - > ▁ REVERSE ▁ SOLIDUS ENDCOM ' ] ' # ▁ 0x5D ▁ - > ▁ RIGHT ▁ SQUARE ▁ BRACKET ENDCOM ' ^ ' # ▁ 0x5E ▁ - > ▁ CIRCUMFLEX ▁ ACCENT ENDCOM ' _ ' # ▁ 0x5F ▁ - > ▁ LOW ▁ LINE ENDCOM ' ` ' # ▁ 0x60 ▁ - > ▁ GRAVE ▁ ACCENT ENDCOM ' a ' # ▁ 0x61 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ A ENDCOM ' b ' # ▁ 0x62 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ B ENDCOM ' c ' # ▁ 0x63 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ C ENDCOM ' d ' # ▁ 0x64 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ D ENDCOM ' e ' # ▁ 0x65 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ E ENDCOM ' f ' # ▁ 0x66 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ F ENDCOM ' g ' # ▁ 0x67 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ G ENDCOM ' h ' # ▁ 0x68 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ H ENDCOM ' i ' # ▁ 0x69 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ I ENDCOM ' j ' # ▁ 0x6A ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ J ENDCOM ' k ' # ▁ 0x6B ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ K ENDCOM ' l ' # ▁ 0x6C ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ L ENDCOM ' m ' # ▁ 0x6D ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ M ENDCOM ' n ' # ▁ 0x6E ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ N ENDCOM ' o ' # ▁ 0x6F ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ O ENDCOM ' p ' # ▁ 0x70 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ P ENDCOM ' q ' # ▁ 0x71 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ Q ENDCOM ' r ' # ▁ 0x72 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ R ENDCOM ' s ' # ▁ 0x73 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ S ENDCOM ' t ' # ▁ 0x74 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ T ENDCOM ' u ' # ▁ 0x75 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ U ENDCOM ' v ' # ▁ 0x76 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ V ENDCOM ' w ' # ▁ 0x77 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ W ENDCOM ' x ' # ▁ 0x78 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ X ENDCOM ' y ' # ▁ 0x79 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ Y ENDCOM ' z ' # ▁ 0x7A ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ Z ENDCOM ' { ' # ▁ 0x7B ▁ - > ▁ LEFT ▁ CURLY ▁ BRACKET ENDCOM ' | ' # ▁ 0x7C ▁ - > ▁ VERTICAL ▁ LINE ENDCOM ' } ' # ▁ 0x7D ▁ - > ▁ RIGHT ▁ CURLY ▁ BRACKET ENDCOM ' ~ ' # ▁ 0x7E ▁ - > ▁ TILDE ENDCOM ' \x7f ' # ▁ 0x7F ▁ - > ▁ DELETE ENDCOM ' \x80' # ▁ 0x80 ▁ - > ▁ < control > ENDCOM ' \x81' # ▁ 0x81 ▁ - > ▁ < control > ENDCOM ' \x82' # ▁ 0x82 ▁ - > ▁ < control > ENDCOM ' \x83' # ▁ 0x83 ▁ - > ▁ < control > ENDCOM ' \x84' # ▁ 0x84 ▁ - > ▁ < control > ENDCOM ' \x85' # ▁ 0x85 ▁ - > ▁ < control > ENDCOM ' \x86' # ▁ 0x86 ▁ - > ▁ < control > ENDCOM ' \x87' # ▁ 0x87 ▁ - > ▁ < control > ENDCOM ' \x88' # ▁ 0x88 ▁ - > ▁ < control > ENDCOM ' \x89' # ▁ 0x89 ▁ - > ▁ < control > ENDCOM ' \x8a ' # ▁ 0x8A ▁ - > ▁ < control > ENDCOM ' \x8b ' # ▁ 0x8B ▁ - > ▁ < control > ENDCOM ' \x8c ' # ▁ 0x8C ▁ - > ▁ < control > ENDCOM ' \x8d ' # ▁ 0x8D ▁ - > ▁ < control > ENDCOM ' \x8e ' # ▁ 0x8E ▁ - > ▁ < control > ENDCOM ' \x8f ' # ▁ 0x8F ▁ - > ▁ < control > ENDCOM ' \x90' # ▁ 0x90 ▁ - > ▁ < control > ENDCOM ' \x91' # ▁ 0x91 ▁ - > ▁ < control > ENDCOM ' \x92' # ▁ 0x92 ▁ - > ▁ < control > ENDCOM ' \x93' # ▁ 0x93 ▁ - > ▁ < control > ENDCOM ' \x94' # ▁ 0x94 ▁ - > ▁ < control > ENDCOM ' \x95' # ▁ 0x95 ▁ - > ▁ < control > ENDCOM ' \x96' # ▁ 0x96 ▁ - > ▁ < control > ENDCOM ' \x97' # ▁ 0x97 ▁ - > ▁ < control > ENDCOM ' \x98' # ▁ 0x98 ▁ - > ▁ < control > ENDCOM ' \x99' # ▁ 0x99 ▁ - > ▁ < control > ENDCOM ' \x9a ' # ▁ 0x9A ▁ - > ▁ < control > ENDCOM ' \x9b ' # ▁ 0x9B ▁ - > ▁ < control > ENDCOM ' \x9c ' # ▁ 0x9C ▁ - > ▁ < control > ENDCOM ' \x9d ' # ▁ 0x9D ▁ - > ▁ < control > ENDCOM ' \x9e ' # ▁ 0x9E ▁ - > ▁ < control > ENDCOM ' \x9f ' # ▁ 0x9F ▁ - > ▁ < control > ENDCOM ' \xa0' # ▁ 0xA0 ▁ - > ▁ NO - BREAK ▁ SPACE ENDCOM ' \u06f0' # ▁ 0xA1 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ ZERO ENDCOM ' \u06f1' # ▁ 0xA2 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ ONE ENDCOM ' \u06f2' # ▁ 0xA3 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ TWO ENDCOM ' \u06f3' # ▁ 0xA4 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ THREE ENDCOM ' \u06f4' # ▁ 0xA5 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ FOUR ENDCOM ' \u06f5' # ▁ 0xA6 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ FIVE ENDCOM ' \u06f6' # ▁ 0xA7 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ SIX ENDCOM ' \u06f7' # ▁ 0xA8 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ SEVEN ENDCOM ' \u06f8' # ▁ 0xA9 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ EIGHT ENDCOM ' \u06f9' # ▁ 0xAA ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ NINE ENDCOM ' \u060c ' # ▁ 0xAB ▁ - > ▁ ARABIC ▁ COMMA ENDCOM ' \u061b ' # ▁ 0xAC ▁ - > ▁ ARABIC ▁ SEMICOLON ENDCOM ' \xad ' # ▁ 0xAD ▁ - > ▁ SOFT ▁ HYPHEN ENDCOM ' \u061f ' # ▁ 0xAE ▁ - > ▁ ARABIC ▁ QUESTION ▁ MARK ENDCOM ' \ufe81' # ▁ 0xAF ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ WITH ▁ MADDA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe8d ' # ▁ 0xB0 ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ ISOLATED ▁ FORM ENDCOM ' \ufe8e ' # ▁ 0xB1 ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ FINAL ▁ FORM ENDCOM ' \ufe8e ' # ▁ 0xB2 ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ FINAL ▁ FORM ENDCOM ' \ufe8f ' # ▁ 0xB3 ▁ - > ▁ ARABIC ▁ LETTER ▁ BEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufe91' # ▁ 0xB4 ▁ - > ▁ ARABIC ▁ LETTER ▁ BEH ▁ INITIAL ▁ FORM ENDCOM ' \ufb56' # ▁ 0xB5 ▁ - > ▁ ARABIC ▁ LETTER ▁ PEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb58' # ▁ 0xB6 ▁ - > ▁ ARABIC ▁ LETTER ▁ PEH ▁ INITIAL ▁ FORM ENDCOM ' \ufe93' # ▁ 0xB7 ▁ - > ▁ ARABIC ▁ LETTER ▁ TEH ▁ MARBUTA ▁ ISOLATED ▁ FORM ENDCOM ' \ufe95' # ▁ 0xB8 ▁ - > ▁ ARABIC ▁ LETTER ▁ TEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufe97' # ▁ 0xB9 ▁ - > ▁ ARABIC ▁ LETTER ▁ TEH ▁ INITIAL ▁ FORM ENDCOM ' \ufb66' # ▁ 0xBA ▁ - > ▁ ARABIC ▁ LETTER ▁ TTEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb68' # ▁ 0xBB ▁ - > ▁ ARABIC ▁ LETTER ▁ TTEH ▁ INITIAL ▁ FORM ENDCOM ' \ufe99' # ▁ 0xBC ▁ - > ▁ ARABIC ▁ LETTER ▁ THEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufe9b ' # ▁ 0xBD ▁ - > ▁ ARABIC ▁ LETTER ▁ THEH ▁ INITIAL ▁ FORM ENDCOM ' \ufe9d ' # ▁ 0xBE ▁ - > ▁ ARABIC ▁ LETTER ▁ JEEM ▁ ISOLATED ▁ FORM ENDCOM ' \ufe9f ' # ▁ 0xBF ▁ - > ▁ ARABIC ▁ LETTER ▁ JEEM ▁ INITIAL ▁ FORM ENDCOM ' \ufb7a ' # ▁ 0xC0 ▁ - > ▁ ARABIC ▁ LETTER ▁ TCHEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb7c ' # ▁ 0xC1 ▁ - > ▁ ARABIC ▁ LETTER ▁ TCHEH ▁ INITIAL ▁ FORM ENDCOM ' \ufea1' # ▁ 0xC2 ▁ - > ▁ ARABIC ▁ LETTER ▁ HAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufea3' # ▁ 0xC3 ▁ - > ▁ ARABIC ▁ LETTER ▁ HAH ▁ INITIAL ▁ FORM ENDCOM ' \ufea5' # ▁ 0xC4 ▁ - > ▁ ARABIC ▁ LETTER ▁ KHAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufea7' # ▁ 0xC5 ▁ - > ▁ ARABIC ▁ LETTER ▁ KHAH ▁ INITIAL ▁ FORM ENDCOM ' \ufea9' # ▁ 0xC6 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAL ▁ ISOLATED ▁ FORM ENDCOM ' \ufb84' # ▁ 0xC7 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAHAL ▁ ISOLATED ▁ FORMN ENDCOM ' \ufeab ' # ▁ 0xC8 ▁ - > ▁ ARABIC ▁ LETTER ▁ THAL ▁ ISOLATED ▁ FORM ENDCOM ' \ufead ' # ▁ 0xC9 ▁ - > ▁ ARABIC ▁ LETTER ▁ REH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb8c ' # ▁ 0xCA ▁ - > ▁ ARABIC ▁ LETTER ▁ RREH ▁ ISOLATED ▁ FORM ENDCOM ' \ufeaf ' # ▁ 0xCB ▁ - > ▁ ARABIC ▁ LETTER ▁ ZAIN ▁ ISOLATED ▁ FORM ENDCOM ' \ufb8a ' # ▁ 0xCC ▁ - > ▁ ARABIC ▁ LETTER ▁ JEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufeb1' # ▁ 0xCD ▁ - > ▁ ARABIC ▁ LETTER ▁ SEEN ▁ ISOLATED ▁ FORM ENDCOM ' \ufeb3' # ▁ 0xCE ▁ - > ▁ ARABIC ▁ LETTER ▁ SEEN ▁ INITIAL ▁ FORM ENDCOM ' \ufeb5' # ▁ 0xCF ▁ - > ▁ ARABIC ▁ LETTER ▁ SHEEN ▁ ISOLATED ▁ FORM ENDCOM ' \ufeb7' # ▁ 0xD0 ▁ - > ▁ ARABIC ▁ LETTER ▁ SHEEN ▁ INITIAL ▁ FORM ENDCOM ' \ufeb9' # ▁ 0xD1 ▁ - > ▁ ARABIC ▁ LETTER ▁ SAD ▁ ISOLATED ▁ FORM ENDCOM ' \ufebb ' # ▁ 0xD2 ▁ - > ▁ ARABIC ▁ LETTER ▁ SAD ▁ INITIAL ▁ FORM ENDCOM ' \ufebd ' # ▁ 0xD3 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAD ▁ ISOLATED ▁ FORM ENDCOM ' \ufebf ' # ▁ 0xD4 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAD ▁ INITIAL ▁ FORM ENDCOM ' \ufec1' # ▁ 0xD5 ▁ - > ▁ ARABIC ▁ LETTER ▁ TAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufec5' # ▁ 0xD6 ▁ - > ▁ ARABIC ▁ LETTER ▁ ZAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufec9' # ▁ 0xD7 ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ ISOLATED ▁ FORM ENDCOM ' \ufeca ' # ▁ 0xD8 ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ FINAL ▁ FORM ENDCOM ' \ufecb ' # ▁ 0xD9 ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ INITIAL ▁ FORM ENDCOM ' \ufecc ' # ▁ 0xDA ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ MEDIAL ▁ FORM ENDCOM ' \ufecd ' # ▁ 0xDB ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ ISOLATED ▁ FORM ENDCOM ' \ufece ' # ▁ 0xDC ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ FINAL ▁ FORM ENDCOM ' \ufecf ' # ▁ 0xDD ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ INITIAL ▁ FORM ENDCOM ' \ufed0' # ▁ 0xDE ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ MEDIAL ▁ FORM ENDCOM ' \ufed1' # ▁ 0xDF ▁ - > ▁ ARABIC ▁ LETTER ▁ FEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufed3' # ▁ 0xE0 ▁ - > ▁ ARABIC ▁ LETTER ▁ FEH ▁ INITIAL ▁ FORM ENDCOM ' \ufed5' # ▁ 0xE1 ▁ - > ▁ ARABIC ▁ LETTER ▁ QAF ▁ ISOLATED ▁ FORM ENDCOM ' \ufed7' # ▁ 0xE2 ▁ - > ▁ ARABIC ▁ LETTER ▁ QAF ▁ INITIAL ▁ FORM ENDCOM ' \ufed9' # ▁ 0xE3 ▁ - > ▁ ARABIC ▁ LETTER ▁ KAF ▁ ISOLATED ▁ FORM ENDCOM ' \ufedb ' # ▁ 0xE4 ▁ - > ▁ ARABIC ▁ LETTER ▁ KAF ▁ INITIAL ▁ FORM ENDCOM ' \ufb92' # ▁ 0xE5 ▁ - > ▁ ARABIC ▁ LETTER ▁ GAF ▁ ISOLATED ▁ FORM ENDCOM ' \ufb94' # ▁ 0xE6 ▁ - > ▁ ARABIC ▁ LETTER ▁ GAF ▁ INITIAL ▁ FORM ENDCOM ' \ufedd ' # ▁ 0xE7 ▁ - > ▁ ARABIC ▁ LETTER ▁ LAM ▁ ISOLATED ▁ FORM ENDCOM ' \ufedf ' # ▁ 0xE8 ▁ - > ▁ ARABIC ▁ LETTER ▁ LAM ▁ INITIAL ▁ FORM ENDCOM ' \ufee0' # ▁ 0xE9 ▁ - > ▁ ARABIC ▁ LETTER ▁ LAM ▁ MEDIAL ▁ FORM ENDCOM ' \ufee1' # ▁ 0xEA ▁ - > ▁ ARABIC ▁ LETTER ▁ MEEM ▁ ISOLATED ▁ FORM ENDCOM ' \ufee3' # ▁ 0xEB ▁ - > ▁ ARABIC ▁ LETTER ▁ MEEM ▁ INITIAL ▁ FORM ENDCOM ' \ufb9e ' # ▁ 0xEC ▁ - > ▁ ARABIC ▁ LETTER ▁ NOON ▁ GHUNNA ▁ ISOLATED ▁ FORM ENDCOM ' \ufee5' # ▁ 0xED ▁ - > ▁ ARABIC ▁ LETTER ▁ NOON ▁ ISOLATED ▁ FORM ENDCOM ' \ufee7' # ▁ 0xEE ▁ - > ▁ ARABIC ▁ LETTER ▁ NOON ▁ INITIAL ▁ FORM ENDCOM ' \ufe85' # ▁ 0xEF ▁ - > ▁ ARABIC ▁ LETTER ▁ WAW ▁ WITH ▁ HAMZA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufeed ' # ▁ 0xF0 ▁ - > ▁ ARABIC ▁ LETTER ▁ WAW ▁ ISOLATED ▁ FORM ENDCOM ' \ufba6' # ▁ 0xF1 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ GOAL ▁ ISOLATED ▁ FORM ENDCOM ' \ufba8' # ▁ 0xF2 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ GOAL ▁ INITIAL ▁ FORM ENDCOM ' \ufba9' # ▁ 0xF3 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ GOAL ▁ MEDIAL ▁ FORM ENDCOM ' \ufbaa ' # ▁ 0xF4 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ DOACHASHMEE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe80' # ▁ 0xF5 ▁ - > ▁ ARABIC ▁ LETTER ▁ HAMZA ▁ ISOLATED ▁ FORM ENDCOM ' \ufe89' # ▁ 0xF6 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ WITH ▁ HAMZA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe8a ' # ▁ 0xF7 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ WITH ▁ HAMZA ▁ ABOVE ▁ FINAL ▁ FORM ENDCOM ' \ufe8b ' # ▁ 0xF8 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ WITH ▁ HAMZA ▁ ABOVE ▁ INITIAL ▁ FORM ENDCOM ' \ufef1' # ▁ 0xF9 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufef2' # ▁ 0xFA ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ FINAL ▁ FORM ENDCOM ' \ufef3' # ▁ 0xFB ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ INITIAL ▁ FORM ENDCOM ' \ufbb0' # ▁ 0xFC ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ BARREE ▁ WITH ▁ HAMZA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufbae ' # ▁ 0xFD ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ BARREE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe7c ' # ▁ 0xFE ▁ - > ▁ ARABIC ▁ SHADDA ▁ ISOLATED ▁ FORM ENDCOM ' \ufe7d ' # ▁ 0xFF ▁ - > ▁ ARABIC ▁ SHADDA ▁ MEDIAL ▁ FORM ENDCOM ) NEW_LINE # # # ▁ Encoding ▁ table ENDCOM encoding_table = codecs . charmap_build ( decoding_table ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="alokotosh/mm-master/tree/master/mm/commands/misc.py"> import os NEW_LINE import json NEW_LINE import mm . util as util NEW_LINE import mm . config as config NEW_LINE from mm . exceptions import * NEW_LINE from mm . basecommand import Command NEW_LINE from mm . sfdc_client import MavensMateClient NEW_LINE class GetActiveSessionCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT if ' username ' not in self . params or self . params [ ' username ' ] == None or self . params [ ' username ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ enter ▁ a ▁ Salesforce . com ▁ username ' ) NEW_LINE DEDENT if ' password ' not in self . params or self . params [ ' password ' ] == None or self . params [ ' password ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ enter ▁ a ▁ Salesforce . com ▁ password ' ) NEW_LINE DEDENT if ' org _ type ' not in self . params or self . params [ ' org _ type ' ] == None or self . params [ ' org _ type ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ select ▁ an ▁ org ▁ type ' ) NEW_LINE DEDENT if ' org _ type ' in self . params and self . params [ ' org _ type ' ] == " custom " and " org _ url " not in self . params : NEW_LINE INDENT raise MMException ( ' To ▁ use ▁ a ▁ custom ▁ org ▁ type , ▁ please ▁ include ▁ a ▁ org _ url ▁ parameter ' ) NEW_LINE DEDENT if ' org _ type ' in self . params and self . params [ ' org _ type ' ] == " custom " and " org _ url " in self . params and self . params [ " org _ url " ] == " " : NEW_LINE INDENT raise MMException ( ' Please ▁ specify ▁ the ▁ org ▁ url ' ) NEW_LINE DEDENT config . logger . debug ( ' = = = = = = = = = = = = = = = = = > ' ) NEW_LINE config . logger . debug ( self . params ) NEW_LINE client = MavensMateClient ( credentials = { " username " : self . params [ ' username ' ] , " password " : self . params [ ' password ' ] , " org _ type " : self . params [ ' org _ type ' ] , " org _ url " : self . params . get ( ' org _ url ' , None ) } ) NEW_LINE response = { " sid " : client . sid , " user _ id " : client . user_id , " metadata _ server _ url " : client . metadata_server_url , " server _ url " : client . server_url , " metadata " : client . get_org_metadata ( subscription = self . params . get ( ' subscription ' , None ) ) , " org _ metadata _ types " : util . metadata_types ( ) , " success " : True } NEW_LINE return util . generate_response ( response ) NEW_LINE DEDENT DEDENT class IndexApexSymbolsCommand ( Command ) : NEW_LINE INDENT aliases = [ " index _ apex " , " index _ apex _ file _ properties " ] NEW_LINE """ STRNEWLINE ▁ Updates ▁ symbol ▁ index ▁ for ▁ one ▁ or ▁ more ▁ Apex ▁ Classes . ▁ If ▁ files ▁ is ▁ not ▁ included ▁ or ▁ empty , ▁ will ▁ force ▁ a ▁ full ▁ refresh STRNEWLINE ▁ """ NEW_LINE def execute ( self ) : NEW_LINE INDENT return config . project . index_apex_symbols ( self . params . get ( " files " , None ) ) NEW_LINE DEDENT DEDENT class ResetMetadataContainerCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT return config . project . reset_metadata_container ( accept = " json " ) NEW_LINE DEDENT DEDENT class OpenFileInClientCommand ( Command ) : NEW_LINE INDENT """ STRNEWLINE ▁ Opens ▁ the ▁ requested ▁ files ▁ in ▁ the ▁ plugin ▁ client ▁ ( Sublime ▁ Text , ▁ etc . ) STRNEWLINE ▁ """ NEW_LINE def execute ( self ) : NEW_LINE INDENT file_name = self . params [ " file _ name " ] NEW_LINE extension = util . get_file_extension_no_period ( file_name ) NEW_LINE mtype = util . get_meta_type_by_suffix ( extension ) NEW_LINE full_file_path = os . path . join ( config . project . location , " src " , mtype [ " directoryName " ] , file_name ) NEW_LINE params = { " project _ name " : config . project . project_name , " file _ name " : full_file_path , " line _ number " : self . params . get ( " line _ number " , 0 ) } NEW_LINE config . connection . run_subl_command ( " open _ file _ in _ project " , json . dumps ( params ) ) NEW_LINE return util . generate_success_response ( " ok " ) NEW_LINE DEDENT DEDENT class ExecuteApexCommand ( Command ) : NEW_LINE INDENT aliases = [ " run _ apex _ script " ] NEW_LINE """ STRNEWLINE ▁ executes ▁ a ▁ string ▁ of ▁ apex STRNEWLINE ▁ """ NEW_LINE def execute ( self ) : NEW_LINE INDENT if ' script _ name ' in self . params : # running ▁ an ▁ apex ▁ script ENDCOM NEW_LINE INDENT self . params [ " body " ] = util . get_file_as_string ( os . path . join ( config . project . location , " apex - scripts " , self . params [ " script _ name " ] ) ) NEW_LINE DEDENT if ' debug _ categories ' not in self . params and not os . path . isfile ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) : NEW_LINE INDENT self . params [ " debug _ categories " ] = [ { " category " : " Apex _ code " , " level " : " DEBUG " } ] NEW_LINE DEDENT elif os . path . isfile ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) : NEW_LINE INDENT log_settings = util . parse_json_from_file ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) NEW_LINE categories = [ ] NEW_LINE levels = log_settings [ " levels " ] NEW_LINE for category in levels . keys ( ) : NEW_LINE INDENT categories . append ( { " category " : category , " level " : levels [ category ] } ) NEW_LINE DEDENT self . params [ " debug _ categories " ] = categories NEW_LINE DEDENT elif ' debug _ categories ' not in self . params : NEW_LINE INDENT self . params [ " debug _ categories " ] = [ { " category " : " Apex _ code " , " level " : " DEBUG " } ] NEW_LINE DEDENT return_log = self . params . get ( " return _ log " , True ) NEW_LINE execute_result = config . sfdc_client . execute_apex ( self . params ) NEW_LINE result = { ' column ' : execute_result [ ' column ' ] , ' compileProblem ' : execute_result [ ' compileProblem ' ] , ' compiled ' : execute_result [ ' compiled ' ] , ' exceptionMessage ' : execute_result [ ' exceptionMessage ' ] , ' exceptionStackTrace ' : execute_result [ ' exceptionStackTrace ' ] , ' line ' : execute_result [ ' line ' ] , ' success ' : execute_result [ ' success ' ] , } NEW_LINE if ' log ' in execute_result and return_log : NEW_LINE INDENT result [ ' log ' ] = execute_result [ ' log ' ] NEW_LINE DEDENT if result [ ' success ' ] : NEW_LINE INDENT log_apex = config . connection . get_plugin_client_setting ( ' mm _ log _ anonymous _ apex ' , False ) NEW_LINE if log_apex : NEW_LINE INDENT location = config . project . log_anonymous_apex ( self . params [ ' body ' ] , execute_result [ ' log ' ] , self . params . get ( " script _ name " , None ) ) NEW_LINE result [ " log _ location " ] = location NEW_LINE DEDENT DEDENT return util . generate_response ( result ) NEW_LINE DEDENT DEDENT class SignInWithGithubCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT return config . connection . sign_in_with_github ( self . params ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="srvg/ansible/tree/master/lib/ansible/modules/network/netvisor/pn_vtep.py"> # ! / usr / bin / python ENDCOM # ▁ Copyright : ▁ ( c ) ▁ 2018 , ▁ Pluribus ▁ Networks ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM from __future__ import absolute_import , division , print_function NEW_LINE __metaclass__ = type NEW_LINE ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = """ STRNEWLINE - - - STRNEWLINE module : ▁ pn _ vtep STRNEWLINE author : ▁ " Pluribus ▁ Networks ▁ ( @ rajaspachipulusu17 ) " STRNEWLINE version _ added : ▁ " 2.9 " STRNEWLINE short _ description : ▁ CLI ▁ command ▁ to ▁ create / delete ▁ vtep STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ This ▁ module ▁ can ▁ be ▁ used ▁ to ▁ create ▁ a ▁ vtep ▁ and ▁ delete ▁ a ▁ vtep . STRNEWLINE options : STRNEWLINE ▁ ▁ pn _ cliswitch : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Target ▁ switch ▁ to ▁ run ▁ the ▁ CLI ▁ on . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ vtep ▁ configuration ▁ command . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' present ' , ▁ ' absent ' ] STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' present ' STRNEWLINE ▁ ▁ pn _ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ vtep ▁ name . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ ip : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Primary ▁ IP ▁ address . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ vrouter _ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name ▁ of ▁ the ▁ vrouter ▁ service . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ virtual _ ip : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Virtual / Secondary ▁ IP ▁ address . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ location : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ switch ▁ name . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ switch _ in _ cluster : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Tells ▁ whether ▁ switch ▁ in ▁ cluster ▁ or ▁ not . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ True STRNEWLINE """ NEW_LINE EXAMPLES = """ STRNEWLINE - ▁ name : ▁ create ▁ vtep STRNEWLINE ▁ ▁ pn _ vtep : STRNEWLINE ▁ ▁ ▁ ▁ pn _ cliswitch : ▁ ' sw01 ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ name : ▁ ' foo ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ vrouter _ name : ▁ ' foo - vrouter ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ ip : ▁ ' 22.22.22.2 ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ location : ▁ ' sw01 ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ virtual _ ip : ▁ " 22.22.22.1 " STRNEWLINE STRNEWLINE - ▁ name : ▁ delete ▁ vtep STRNEWLINE ▁ ▁ pn _ vtep : STRNEWLINE ▁ ▁ ▁ ▁ pn _ cliswitch : ▁ ' sw01 ' STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ ' absent ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ name : ▁ ' foo ' STRNEWLINE """ NEW_LINE RETURN = """ STRNEWLINE command : STRNEWLINE ▁ ▁ description : ▁ the ▁ CLI ▁ command ▁ run ▁ on ▁ the ▁ target ▁ node . STRNEWLINE ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ type : ▁ str STRNEWLINE stdout : STRNEWLINE ▁ ▁ description : ▁ set ▁ of ▁ responses ▁ from ▁ the ▁ vtep ▁ command . STRNEWLINE ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE stderr : STRNEWLINE ▁ ▁ description : ▁ set ▁ of ▁ error ▁ responses ▁ from ▁ the ▁ vtep ▁ command . STRNEWLINE ▁ ▁ returned : ▁ on ▁ error STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE changed : STRNEWLINE ▁ ▁ description : ▁ indicates ▁ whether ▁ the ▁ CLI ▁ caused ▁ changes ▁ on ▁ the ▁ target . STRNEWLINE ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ type : ▁ bool STRNEWLINE """ NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . network . netvisor . pn_nvos import pn_cli , run_cli NEW_LINE from ansible . module_utils . network . netvisor . netvisor import run_commands NEW_LINE def check_cli ( module , cli ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ method ▁ checks ▁ for ▁ idempotency ▁ using ▁ the ▁ vtep - show ▁ command . STRNEWLINE ▁ If ▁ a ▁ name ▁ exists , ▁ return ▁ True ▁ if ▁ name ▁ exists ▁ else ▁ False . STRNEWLINE ▁ : param ▁ module : ▁ The ▁ Ansible ▁ module ▁ to ▁ fetch ▁ input ▁ parameters STRNEWLINE ▁ : param ▁ cli : ▁ The ▁ CLI ▁ string STRNEWLINE ▁ """ NEW_LINE name = module . params [ ' pn _ name ' ] NEW_LINE cli += ' ▁ vtep - show ▁ format ▁ name ▁ no - show - headers ' NEW_LINE out = run_commands ( module , cli ) [ 1 ] NEW_LINE if out : NEW_LINE INDENT out = out . split ( ) NEW_LINE DEDENT return True if name in out else False NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT """ ▁ This ▁ section ▁ is ▁ for ▁ arguments ▁ parsing ▁ """ NEW_LINE state_map = dict ( present = ' vtep - create ' , absent = ' vtep - delete ' ) NEW_LINE argument_spec = dict ( pn_cliswitch = dict ( required = False , type = ' str ' ) , state = dict ( required = False , type = ' str ' , choices = state_map . keys ( ) , default = ' present ' ) , pn_name = dict ( required = False , type = ' str ' ) , pn_ip = dict ( required = False , type = ' str ' ) , pn_vrouter_name = dict ( required = False , type = ' str ' ) , pn_virtual_ip = dict ( required = False , type = ' str ' ) , pn_location = dict ( required = False , type = ' str ' ) , pn_switch_in_cluster = dict ( required = False , type = ' bool ' , default = ' True ' ) ) NEW_LINE module = AnsibleModule ( argument_spec = argument_spec , required_if = ( [ " state " , " present " , [ " pn _ name " , " pn _ ip " , " pn _ vrouter _ name " , " pn _ location " ] ] , [ " state " , " absent " , [ " pn _ name " ] ] , ) , ) NEW_LINE # ▁ Accessing ▁ the ▁ arguments ENDCOM cliswitch = module . params [ ' pn _ cliswitch ' ] NEW_LINE state = module . params [ ' state ' ] NEW_LINE name = module . params [ ' pn _ name ' ] NEW_LINE ip = module . params [ ' pn _ ip ' ] NEW_LINE vrouter_name = module . params [ ' pn _ vrouter _ name ' ] NEW_LINE virtual_ip = module . params [ ' pn _ virtual _ ip ' ] NEW_LINE location = module . params [ ' pn _ location ' ] NEW_LINE switch_in_cluster = module . params [ ' pn _ switch _ in _ cluster ' ] NEW_LINE if switch_in_cluster and not virtual_ip and state == ' present ' : NEW_LINE INDENT module . exit_json ( failed = True , msg = ' virtual ▁ ip ▁ is ▁ required ▁ when ▁ switch ▁ is ▁ in ▁ cluster ' ) NEW_LINE DEDENT command = state_map [ state ] NEW_LINE # ▁ Building ▁ the ▁ CLI ▁ command ▁ string ENDCOM cli = pn_cli ( module , cliswitch ) NEW_LINE NAME_EXISTS = check_cli ( module , cli ) NEW_LINE cli += ' ▁ % s ▁ name ▁ % s ▁ ' % ( command , name ) NEW_LINE if command == ' vtep - delete ' : NEW_LINE INDENT if NAME_EXISTS is False : NEW_LINE INDENT module . exit_json ( skipped = True , msg = ' vtep ▁ with ▁ name ▁ % s ▁ does ▁ not ▁ exist ' % name ) NEW_LINE DEDENT DEDENT if command == ' vtep - create ' : NEW_LINE INDENT if NAME_EXISTS is True : NEW_LINE INDENT module . exit_json ( skipped = True , msg = ' vtpe ▁ with ▁ name ▁ % s ▁ already ▁ exists ' % name ) NEW_LINE DEDENT cli += ' vrouter - name ▁ % s ▁ ' % vrouter_name NEW_LINE cli += ' ip ▁ % s ▁ ' % ip NEW_LINE cli += ' location ▁ % s ▁ ' % location NEW_LINE if virtual_ip : NEW_LINE INDENT cli += ' virtual - ip ▁ % s ▁ ' % virtual_ip NEW_LINE DEDENT DEDENT run_cli ( module , cli , state_map ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
