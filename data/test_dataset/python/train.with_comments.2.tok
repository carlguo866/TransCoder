<DOCUMENT_ID="arifgursel/pyglet/tree/master/pyglet/gl/lib.py"> # ▁ pyglet ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2006-2008 ▁ Alex ▁ Holkner ENDCOM # ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ ENDCOM # ▁ are ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ▁ copyright ▁ ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ▁ in ENDCOM # ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ENDCOM # ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ pyglet ▁ nor ▁ the ▁ names ▁ of ▁ its ENDCOM # ▁ contributors ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ENDCOM # ▁ derived ▁ from ▁ this ▁ software ▁ without ▁ specific ▁ prior ▁ written ENDCOM # ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ENDCOM # ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ENDCOM # ▁ COPYRIGHT ▁ OWNER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ENDCOM # ▁ INCIDENTAL , ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ENDCOM # ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ENDCOM # ▁ LOSS ▁ OF ▁ USE , ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ HOWEVER ENDCOM # ▁ CAUSED ▁ AND ▁ ON ▁ ANY ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ STRICT ENDCOM # ▁ LIABILITY , ▁ OR ▁ TORT ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ▁ ARISING ▁ IN ENDCOM # ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ENDCOM # ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM __docformat__ = ' restructuredtext ' NEW_LINE __version__ = ' $ Id $ ' NEW_LINE import ctypes NEW_LINE import pyglet NEW_LINE __all__ = [ ' link _ GL ' , ' link _ GLU ' , ' link _ AGL ' , ' link _ GLX ' , ' link _ WGL ' ] NEW_LINE _debug_gl = pyglet . options [ ' debug _ gl ' ] NEW_LINE _debug_gl_trace = pyglet . options [ ' debug _ gl _ trace ' ] NEW_LINE _debug_gl_trace_args = pyglet . options [ ' debug _ gl _ trace _ args ' ] NEW_LINE class MissingFunctionException ( Exception ) : NEW_LINE INDENT def __init__ ( self , name , requires = None , suggestions = None ) : NEW_LINE INDENT msg = ' % s ▁ is ▁ not ▁ exported ▁ by ▁ the ▁ available ▁ OpenGL ▁ driver . ' % name NEW_LINE if requires : NEW_LINE INDENT msg += ' ▁ ▁ % s ▁ is ▁ required ▁ for ▁ this ▁ functionality . ' % requires NEW_LINE DEDENT if suggestions : NEW_LINE INDENT msg += ' ▁ ▁ Consider ▁ alternative ( s ) ▁ % s . ' % ' , ▁ ' . join ( suggestions ) NEW_LINE DEDENT Exception . __init__ ( self , msg ) NEW_LINE DEDENT DEDENT def missing_function ( name , requires = None , suggestions = None ) : NEW_LINE INDENT def MissingFunction ( * args , ** kwargs ) : NEW_LINE INDENT raise MissingFunctionException ( name , requires , suggestions ) NEW_LINE DEDENT return MissingFunction NEW_LINE DEDENT _int_types = ( ctypes . c_int16 , ctypes . c_int32 ) NEW_LINE if hasattr ( ctypes , ' c _ int64' ) : NEW_LINE # ▁ Some ▁ builds ▁ of ▁ ctypes ▁ apparently ▁ do ▁ not ▁ have ▁ c _ int64 ENDCOM # ▁ defined ; ▁ it ' s ▁ a ▁ pretty ▁ good ▁ bet ▁ that ▁ these ▁ builds ▁ do ▁ not ENDCOM # ▁ have ▁ 64 - bit ▁ pointers . ENDCOM INDENT _int_types += ( ctypes . c_int64 , ) NEW_LINE DEDENT for t in _int_types : NEW_LINE INDENT if ctypes . sizeof ( t ) == ctypes . sizeof ( ctypes . c_size_t ) : NEW_LINE INDENT c_ptrdiff_t = t NEW_LINE DEDENT DEDENT class c_void ( ctypes . Structure ) : NEW_LINE # ▁ c _ void _ p ▁ is ▁ a ▁ buggy ▁ return ▁ type , ▁ converting ▁ to ▁ int , ▁ so ENDCOM # ▁ POINTER ( None ) ▁ = = ▁ c _ void _ p ▁ is ▁ actually ▁ written ▁ as ENDCOM # ▁ POINTER ( c _ void ) , ▁ so ▁ it ▁ can ▁ be ▁ treated ▁ as ▁ a ▁ real ▁ pointer . ENDCOM INDENT _fields_ = [ ( ' dummy ' , ctypes . c_int ) ] NEW_LINE DEDENT class GLException ( Exception ) : NEW_LINE INDENT pass NEW_LINE DEDENT def errcheck ( result , func , arguments ) : NEW_LINE INDENT if _debug_gl_trace : NEW_LINE INDENT try : NEW_LINE INDENT name = func . __name__ NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT name = repr ( func ) NEW_LINE DEDENT if _debug_gl_trace_args : NEW_LINE INDENT trace_args = ' , ▁ ' . join ( [ repr ( arg ) [ : 20 ] for arg in arguments ] ) NEW_LINE print ' % s ( % s ) ' % ( name , trace_args ) NEW_LINE DEDENT else : NEW_LINE INDENT print name NEW_LINE DEDENT DEDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT if not context . _gl_begin : NEW_LINE INDENT error = gl . glGetError ( ) NEW_LINE if error : NEW_LINE INDENT msg = ctypes . cast ( gl . gluErrorString ( error ) , ctypes . c_char_p ) . value NEW_LINE raise GLException ( msg ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def errcheck_glbegin ( result , func , arguments ) : NEW_LINE INDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT context . _gl_begin = True NEW_LINE return result NEW_LINE DEDENT def errcheck_glend ( result , func , arguments ) : NEW_LINE INDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT context . _gl_begin = False NEW_LINE return errcheck ( result , func , arguments ) NEW_LINE DEDENT def decorate_function ( func , name ) : NEW_LINE INDENT if _debug_gl : NEW_LINE INDENT if name == ' glBegin ' : NEW_LINE INDENT func . errcheck = errcheck_glbegin NEW_LINE DEDENT elif name == ' glEnd ' : NEW_LINE INDENT func . errcheck = errcheck_glend NEW_LINE DEDENT elif name not in ( ' glGetError ' , ' gluErrorString ' ) and name [ : 3 ] not in ( ' glX ' , ' agl ' , ' wgl ' ) : NEW_LINE INDENT func . errcheck = errcheck NEW_LINE DEDENT DEDENT DEDENT link_AGL = None NEW_LINE link_GLX = None NEW_LINE link_WGL = None NEW_LINE if pyglet . compat_platform in ( ' win32' , ' cygwin ' ) : NEW_LINE INDENT from pyglet . gl . lib_wgl import link_GL , link_GLU , link_WGL NEW_LINE DEDENT elif pyglet . compat_platform == ' darwin ' : NEW_LINE INDENT from pyglet . gl . lib_agl import link_GL , link_GLU , link_AGL NEW_LINE DEDENT else : NEW_LINE INDENT from pyglet . gl . lib_glx import link_GL , link_GLU , link_GLX NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="sparkslabs/kamaelia/tree/master/Sketches/CL/Topology/src/RelationTopology/Util/RelationAttributeParsing.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2010 ▁ British ▁ Broadcasting ▁ Corporation ▁ and ▁ Kamaelia ▁ Contributors ( 1 ) ENDCOM # ▁ ( 1 ) ▁ Kamaelia ▁ Contributors ▁ are ▁ listed ▁ in ▁ the ▁ AUTHORS ▁ file ▁ and ▁ at ENDCOM # ▁ http : / / www . kamaelia . org / AUTHORS ▁ - ▁ please ▁ extend ▁ this ▁ file , ENDCOM # ▁ not ▁ this ▁ notice . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ENDCOM # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ENDCOM # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM """ \ STRNEWLINE = = = = = STRNEWLINE Parse ▁ entities , ▁ attributes ▁ and ▁ relations ▁ definition ▁ received STRNEWLINE = = = = = STRNEWLINE STRNEWLINE Parse ▁ entities ▁ and ▁ relations ▁ definition ▁ received , ▁ one ▁ line ▁ one ▁ time . STRNEWLINE STRNEWLINE 1 . ▁ Definition ▁ format STRNEWLINE 1 . ) ▁ Empty ▁ line ▁ ( including ▁ any ▁ number ▁ of ▁ white ▁ spaces ) STRNEWLINE 2 . ) ▁ Line ▁ starting ▁ with ▁ # ▁ to ▁ comment STRNEWLINE 3 . ) ▁ Entity ▁ definition STRNEWLINE Example : STRNEWLINE - - - - - STRNEWLINE person ▁ mum STRNEWLINE person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80 STRNEWLINE person ▁ son ▁ gender = " male " , photo = " . . / Files / son . gif , width = 60 , height = 60 " STRNEWLINE person ▁ daughter ▁ radius = 100 STRNEWLINE 4 . ) ▁ Relation ▁ definition STRNEWLINE Example : ▁ STRNEWLINE - - - - - STRNEWLINE childof ( mum , ▁ son ) STRNEWLINE STRNEWLINE 2 . ▁ NOTE : STRNEWLINE 1 . ) ▁ Any ▁ number ▁ of ▁ spaces ▁ can ▁ exist ▁ before , ▁ after ▁ and ▁ between ▁ the ▁ above ▁ line STRNEWLINE Example : STRNEWLINE - - - - - STRNEWLINE ▁ person ▁ mum ▁ STRNEWLINE ▁ childof ▁ ( ▁ mum ▁ , ▁ son ▁ ) ▁ STRNEWLINE 2 . ) ▁ Parse ▁ one ▁ line ▁ one ▁ time ▁ and ▁ then ▁ send ▁ out STRNEWLINE 3 . ) ▁ Entity ▁ definition ▁ needs ▁ to ▁ come ▁ before ▁ relation ▁ definition ▁ STRNEWLINE if ▁ the ▁ relations ▁ definition ▁ uses ▁ the ▁ entity STRNEWLINE 4 . ) ▁ When ▁ encountering ▁ repeated ▁ entity , ▁ it ▁ will ▁ update ▁ its ▁ attributes ▁ rather ▁ than STRNEWLINE create ▁ a ▁ new ▁ one . ▁ STRNEWLINE """ NEW_LINE def parseEntity ( entityLine ) : NEW_LINE INDENT """ ▁ parse ▁ entity ▁ line ▁ """ NEW_LINE result = entityLine . split ( ) NEW_LINE # entity _ ID ▁ = ▁ result [ 0 ] + ' _ ' + result [ 1 ] ENDCOM entity_name = result [ 1 ] NEW_LINE # particle ▁ = ▁ ' - ' ENDCOM particle = ' GenericParticle ' NEW_LINE if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE # attributes ▁ = ▁ attributes . lower ( ) ENDCOM attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes + ' , type = ' + result [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' type = ' + result [ 0 ] NEW_LINE DEDENT return " ADD ▁ NODE ▁ % s ▁ % s ▁ auto ▁ % s ▁ % s " % ( entity_name , entity_name , particle , attributes ) NEW_LINE DEDENT def parseUpdatedEntity ( entityLine ) : NEW_LINE INDENT """ ▁ parse ▁ entity ▁ line ▁ """ NEW_LINE result = entityLine . split ( ) NEW_LINE # entity _ ID ▁ = ▁ result [ 0 ] + ' _ ' + result [ 1 ] ENDCOM entity_name = result [ 1 ] NEW_LINE # particle ▁ = ▁ ' - ' ENDCOM # particle ▁ = ▁ ' GenericParticle ' ENDCOM if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE # attributes ▁ = ▁ attributes . lower ( ) ENDCOM attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes . replace ( ' name ' , ' label ' ) NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' label = ' + entity_name NEW_LINE DEDENT return " UPDATE ▁ NODE ▁ % s ▁ % s " % ( entity_name , attributes ) NEW_LINE DEDENT def parseRelation ( relationLine ) : NEW_LINE INDENT """ ▁ parse ▁ relation ▁ line ▁ """ NEW_LINE result = relationLine . split ( ' ( ' ) NEW_LINE relation = result [ 0 ] . strip ( ) NEW_LINE entities_str = result [ 1 ] . rstrip ( ' ) ' ) NEW_LINE entities_list = entities_str . split ( ' , ' ) NEW_LINE src = entities_list [ 0 ] . strip ( ) NEW_LINE dst = entities_list [ 1 ] . strip ( ) NEW_LINE return " ADD ▁ LINK ▁ % s ▁ % s ▁ % s " % ( src , dst , relation ) NEW_LINE DEDENT import re NEW_LINE import Axon NEW_LINE from Axon . Ipc import producerFinished , shutdownMicroprocess NEW_LINE class RelationAttributeParser ( Axon . Component . component ) : NEW_LINE INDENT """ \ STRNEWLINE = = = = = STRNEWLINE A ▁ component ▁ to ▁ parse ▁ entities , ▁ attributes ▁ and ▁ relations ▁ definition STRNEWLINE = = = = = STRNEWLINE """ NEW_LINE def shutdown ( self ) : NEW_LINE INDENT """ ▁ shutdown ▁ method : ▁ define ▁ when ▁ to ▁ shun ▁ down """ NEW_LINE while self . dataReady ( " control " ) : NEW_LINE INDENT data = self . recv ( " control " ) NEW_LINE if isinstance ( data , producerFinished ) or isinstance ( data , shutdownMicroprocess ) : NEW_LINE INDENT self . shutdown_mess = data NEW_LINE return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def main ( self ) : NEW_LINE INDENT """ ▁ main ▁ method : ▁ do ▁ stuff ▁ """ NEW_LINE previousNodes = [ ] NEW_LINE # ▁ Put ▁ all ▁ codes ▁ within ▁ the ▁ loop , ▁ so ▁ that ▁ others ▁ can ▁ be ▁ run ▁ even ▁ it ▁ doesn ' t ▁ shut ▁ down ENDCOM while not self . shutdown ( ) : NEW_LINE INDENT X = [ ] NEW_LINE links = [ ] NEW_LINE nodes = [ ] NEW_LINE updatedNodes = [ ] NEW_LINE while not self . anyReady ( ) : NEW_LINE INDENT self . pause ( ) NEW_LINE yield 1 NEW_LINE DEDENT while self . dataReady ( " inbox " ) : NEW_LINE INDENT L = self . recv ( " inbox " ) NEW_LINE if L . strip ( ) == " " : continue # ▁ empty ▁ line ENDCOM NEW_LINE if L . lstrip ( ) [ 0 ] == " # " : continue # ▁ comment ENDCOM NEW_LINE X . append ( L . strip ( ) ) NEW_LINE # yield ▁ 1 ENDCOM DEDENT for item in X : NEW_LINE INDENT if re . match ( ' ( . + ) \ ( ( . + ) , ( . + ) \ ) ' , item ) : # ▁ relation ENDCOM NEW_LINE INDENT command = parseRelation ( item ) NEW_LINE links . append ( command ) NEW_LINE DEDENT else : NEW_LINE INDENT isRepeated = False NEW_LINE for node in previousNodes : NEW_LINE INDENT if item . split ( ) [ 1 ] == node . split ( ) [ 2 ] : NEW_LINE INDENT isRepeated = True NEW_LINE DEDENT DEDENT if not isRepeated : # ▁ new ▁ entity ENDCOM NEW_LINE INDENT command = parseEntity ( item ) NEW_LINE nodes . append ( command ) NEW_LINE previousNodes . append ( command ) NEW_LINE DEDENT else : # ▁ old ▁ entity ENDCOM NEW_LINE INDENT command = parseUpdatedEntity ( item ) NEW_LINE updatedNodes . append ( command ) NEW_LINE # yield ▁ 1 ENDCOM DEDENT DEDENT DEDENT for node in nodes : NEW_LINE INDENT self . send ( node , " outbox " ) NEW_LINE DEDENT for updatedNode in updatedNodes : NEW_LINE INDENT self . send ( updatedNode , " outbox " ) NEW_LINE DEDENT for link in links : NEW_LINE INDENT self . send ( link , " outbox " ) NEW_LINE DEDENT yield 1 NEW_LINE DEDENT self . send ( self . shutdown_mess , " signal " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT from Kamaelia . Util . DataSource import DataSource NEW_LINE from Kamaelia . Visualisation . PhysicsGraph . lines_to_tokenlists import lines_to_tokenlists NEW_LINE from Kamaelia . Util . Console import ConsoleReader , ConsoleEchoer NEW_LINE from GenericTopologyViewer import GenericTopologyViewer NEW_LINE from Kamaelia . Chassis . Graphline import Graphline NEW_LINE # ▁ Data ▁ can ▁ be ▁ from ▁ both ▁ DataSource ▁ and ▁ console ▁ inputs ENDCOM Graphline ( CONSOLEREADER = ConsoleReader ( ) , DATASOURCE = DataSource ( [ " ▁ ▁ person ▁ ▁ mum ▁ ▁ ▁ gender = female , photo = . . / Files / mum . jpg , width = 80 , height = 80 ▁ " , ' ▁ ▁ ' , """ ▁ ▁ ▁ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """ , ' person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80' , ' ▁ ▁ person ▁ ▁ son ▁ ▁ ▁ gender = male , photo = . . / Files / son . gif , width = 60 , height = 60' , ' person ▁ son ▁ photo = . . / Files / son1 . gif ' , ' person ▁ daughter ▁ radius = 20' , ' person ▁ daughter ▁ radius = 100' , ' ▁ childof ▁ ▁ ( ▁ ▁ mum ▁ ▁ , ▁ son ▁ ▁ ) ▁ ' , ' childof ( mum , ▁ daughter ) ' , ' childof ( dad , ▁ son ) ' , ' childof ( dad , ▁ daughter ) ' ] ) , PARSER = RelationAttributeParser ( ) , TOKENS = lines_to_tokenlists ( ) , VIEWER = GenericTopologyViewer ( ) , CONSOLEECHOER = ConsoleEchoer ( ) , linkages = { ( " CONSOLEREADER " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " DATASOURCE " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " PARSER " , " outbox " ) : ( " TOKENS " , " inbox " ) , ( " TOKENS " , " outbox " ) : ( " VIEWER " , " inbox " ) , ( " VIEWER " , " outbox " ) : ( " CONSOLEECHOER " , " inbox " ) , } ) . run ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="fabian4/trove/tree/master/trove/guestagent/datastore/experimental/redis/manager.py"> # ▁ Copyright ▁ ( c ) ▁ 2013 ▁ Rackspace ENDCOM # ▁ All ▁ Rights ▁ Reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM from oslo_log import log as logging NEW_LINE from oslo_service import periodic_task NEW_LINE from trove . common import cfg NEW_LINE from trove . common import exception NEW_LINE from trove . common . i18n import _ NEW_LINE from trove . common import instance as rd_instance NEW_LINE from trove . common import utils NEW_LINE from trove . guestagent import backup NEW_LINE from trove . guestagent . common import operating_system NEW_LINE from trove . guestagent . datastore . experimental . redis import service NEW_LINE from trove . guestagent import dbaas NEW_LINE from trove . guestagent . strategies . replication import get_replication_strategy NEW_LINE from trove . guestagent import volume NEW_LINE LOG = logging . getLogger ( __name__ ) NEW_LINE CONF = cfg . CONF NEW_LINE MANAGER = CONF . datastore_manager or ' redis ' NEW_LINE REPLICATION_STRATEGY = CONF . get ( MANAGER ) . replication_strategy NEW_LINE REPLICATION_NAMESPACE = CONF . get ( MANAGER ) . replication_namespace NEW_LINE REPLICATION_STRATEGY_CLASS = get_replication_strategy ( REPLICATION_STRATEGY , REPLICATION_NAMESPACE ) NEW_LINE class Manager ( periodic_task . PeriodicTasks ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ is ▁ the ▁ Redis ▁ manager ▁ class . ▁ It ▁ is ▁ dynamically ▁ loaded STRNEWLINE ▁ based ▁ off ▁ of ▁ the ▁ service _ type ▁ of ▁ the ▁ trove ▁ instance STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT super ( Manager , self ) . __init__ ( CONF ) NEW_LINE self . _app = service . RedisApp ( ) NEW_LINE DEDENT @ periodic_task . periodic_task NEW_LINE def update_status ( self , context ) : NEW_LINE INDENT """ STRNEWLINE ▁ Updates ▁ the ▁ redis ▁ trove ▁ instance . ▁ It ▁ is ▁ decorated ▁ with STRNEWLINE ▁ perodic ▁ task ▁ so ▁ it ▁ is ▁ automatically ▁ called ▁ every ▁ 3 ▁ ticks . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Update ▁ status ▁ called . " ) NEW_LINE self . _app . status . update ( ) NEW_LINE DEDENT def rpc_ping ( self , context ) : NEW_LINE INDENT LOG . debug ( " Responding ▁ to ▁ RPC ▁ ping . " ) NEW_LINE return True NEW_LINE DEDENT def change_passwords ( self , context , users ) : NEW_LINE INDENT """ STRNEWLINE ▁ Changes ▁ the ▁ redis ▁ instance ▁ password , STRNEWLINE ▁ it ▁ is ▁ currently ▁ not ▁ not ▁ implemented . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Change ▁ passwords ▁ called . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' change _ passwords ' , datastore = MANAGER ) NEW_LINE DEDENT def reset_configuration ( self , context , configuration ) : NEW_LINE INDENT """ STRNEWLINE ▁ Resets ▁ to ▁ the ▁ default ▁ configuration , STRNEWLINE ▁ currently ▁ this ▁ does ▁ nothing . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Reset ▁ configuration ▁ called . " ) NEW_LINE self . _app . reset_configuration ( configuration ) NEW_LINE DEDENT def _perform_restore ( self , backup_info , context , restore_location , app ) : NEW_LINE INDENT """ Perform ▁ a ▁ restore ▁ on ▁ this ▁ instance . """ NEW_LINE LOG . info ( _ ( " Restoring ▁ database ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE try : NEW_LINE INDENT backup . restore ( context , backup_info , restore_location ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ performing ▁ restore ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT LOG . info ( _ ( " Restored ▁ database ▁ successfully . " ) ) NEW_LINE DEDENT def prepare ( self , context , packages , databases , memory_mb , users , device_path = None , mount_point = None , backup_info = None , config_contents = None , root_password = None , overrides = None , cluster_config = None , snapshot = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ is ▁ called ▁ when ▁ the ▁ trove ▁ instance ▁ first ▁ comes ▁ online . STRNEWLINE ▁ It ▁ is ▁ the ▁ first ▁ rpc ▁ message ▁ passed ▁ from ▁ the ▁ task ▁ manager . STRNEWLINE ▁ prepare ▁ handles ▁ all ▁ the ▁ base ▁ configuration ▁ of ▁ the ▁ redis ▁ instance . STRNEWLINE ▁ """ NEW_LINE try : NEW_LINE INDENT self . _app . status . begin_install ( ) NEW_LINE if device_path : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE # ▁ unmount ▁ if ▁ device ▁ is ▁ already ▁ mounted ENDCOM device . unmount_device ( device_path ) NEW_LINE device . format ( ) NEW_LINE device . mount ( mount_point ) NEW_LINE operating_system . chown ( mount_point , ' redis ' , ' redis ' , as_root = True ) NEW_LINE LOG . debug ( ' Mounted ▁ the ▁ volume . ' ) NEW_LINE DEDENT self . _app . install_if_needed ( packages ) NEW_LINE LOG . info ( _ ( ' Writing ▁ redis ▁ configuration . ' ) ) NEW_LINE if cluster_config : NEW_LINE INDENT config_contents = ( config_contents + " \n " + " cluster - enabled ▁ yes \n " + " cluster - config - file ▁ cluster . conf \n " ) NEW_LINE DEDENT self . _app . configuration_manager . save_configuration ( config_contents ) NEW_LINE self . _app . apply_initial_guestagent_configuration ( ) NEW_LINE if backup_info : NEW_LINE INDENT persistence_dir = self . _app . get_working_dir ( ) NEW_LINE self . _perform_restore ( backup_info , context , persistence_dir , self . _app ) NEW_LINE DEDENT if snapshot : NEW_LINE INDENT self . attach_replica ( context , snapshot , snapshot [ ' config ' ] ) NEW_LINE DEDENT self . _app . restart ( ) NEW_LINE if cluster_config : NEW_LINE INDENT self . _app . status . set_status ( rd_instance . ServiceStatuses . BUILD_PENDING ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT LOG . info ( _ ( ' Redis ▁ instance ▁ has ▁ been ▁ setup ▁ and ▁ configured . ' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ setting ▁ up ▁ Redis ▁ instance . " ) ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def restart ( self , context ) : NEW_LINE INDENT """ STRNEWLINE ▁ Restart ▁ this ▁ redis ▁ instance . STRNEWLINE ▁ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ guest ▁ agent STRNEWLINE ▁ gets ▁ a ▁ restart ▁ message ▁ from ▁ the ▁ taskmanager . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Restart ▁ called . " ) NEW_LINE self . _app . restart ( ) NEW_LINE DEDENT def start_db_with_conf_changes ( self , context , config_contents ) : NEW_LINE INDENT """ STRNEWLINE ▁ Start ▁ this ▁ redis ▁ instance ▁ with ▁ new ▁ conf ▁ changes . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Start ▁ DB ▁ with ▁ conf ▁ changes ▁ called . " ) NEW_LINE self . _app . start_db_with_conf_changes ( config_contents ) NEW_LINE DEDENT def stop_db ( self , context , do_not_start_on_reboot = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Stop ▁ this ▁ redis ▁ instance . STRNEWLINE ▁ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ guest ▁ agent STRNEWLINE ▁ gets ▁ a ▁ stop ▁ message ▁ from ▁ the ▁ taskmanager . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Stop ▁ DB ▁ called . " ) NEW_LINE self . _app . stop_db ( do_not_start_on_reboot = do_not_start_on_reboot ) NEW_LINE DEDENT def get_filesystem_stats ( self , context , fs_path ) : NEW_LINE INDENT """ Gets ▁ the ▁ filesystem ▁ stats ▁ for ▁ the ▁ path ▁ given . """ NEW_LINE LOG . debug ( " Get ▁ Filesystem ▁ Stats . " ) NEW_LINE mount_point = CONF . get ( ' mysql ' if not MANAGER else MANAGER ) . mount_point NEW_LINE return dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE DEDENT def create_backup ( self , context , backup_info ) : NEW_LINE INDENT """ Create ▁ a ▁ backup ▁ of ▁ the ▁ database . """ NEW_LINE LOG . debug ( " Creating ▁ backup . " ) NEW_LINE backup . backup ( context , backup_info ) NEW_LINE DEDENT def mount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . mount ( mount_point , write_to_fstab = False ) NEW_LINE LOG . debug ( " Mounted ▁ the ▁ device ▁ % s ▁ at ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def unmount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . unmount ( mount_point ) NEW_LINE LOG . debug ( " Unmounted ▁ the ▁ device ▁ % s ▁ from ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def resize_fs ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . resize_fs ( mount_point ) NEW_LINE LOG . debug ( " Resized ▁ the ▁ filesystem ▁ at ▁ % s . " % mount_point ) NEW_LINE DEDENT def update_overrides ( self , context , overrides , remove = False ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ overrides . " ) NEW_LINE if remove : NEW_LINE INDENT self . _app . remove_overrides ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . update_overrides ( context , overrides , remove ) NEW_LINE DEDENT DEDENT def apply_overrides ( self , context , overrides ) : NEW_LINE INDENT LOG . debug ( " Applying ▁ overrides . " ) NEW_LINE self . _app . apply_overrides ( self . _app . admin , overrides ) NEW_LINE DEDENT def update_attributes ( self , context , username , hostname , user_attrs ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ attributes . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' update _ attributes ' , datastore = MANAGER ) NEW_LINE DEDENT def create_database ( self , context , databases ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def create_user ( self , context , users ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_database ( self , context , database ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_user ( self , context , user ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def get_user ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' get _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def grant_access ( self , context , username , hostname , databases ) : NEW_LINE INDENT LOG . debug ( " Granting ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' grant _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def revoke_access ( self , context , username , hostname , database ) : NEW_LINE INDENT LOG . debug ( " Revoking ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' revoke _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_access ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_databases ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ databases . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ databases ' , datastore = MANAGER ) NEW_LINE DEDENT def list_users ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ users . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ users ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root ( self , context ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root_with_password ( self , context , root_password = None ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root ▁ with ▁ password . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root _ with _ password ' , datastore = MANAGER ) NEW_LINE DEDENT def is_root_enabled ( self , context ) : NEW_LINE INDENT LOG . debug ( " Checking ▁ if ▁ root ▁ is ▁ enabled . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' is _ root _ enabled ' , datastore = MANAGER ) NEW_LINE DEDENT def backup_required_for_replication ( self , context ) : NEW_LINE INDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE return replication . backup_required_for_replication ( ) NEW_LINE DEDENT def get_replication_snapshot ( self , context , snapshot_info , replica_source_config = None ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replication ▁ snapshot . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE snapshot_id , log_position = ( replication . snapshot_for_replication ( context , self . _app , None , snapshot_info ) ) NEW_LINE mount_point = CONF . get ( MANAGER ) . mount_point NEW_LINE volume_stats = dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE replication_snapshot = { ' dataset ' : { ' datastore _ manager ' : MANAGER , ' dataset _ size ' : volume_stats . get ( ' used ' , 0.0 ) , ' volume _ size ' : volume_stats . get ( ' total ' , 0.0 ) , ' snapshot _ id ' : snapshot_id } , ' replication _ strategy ' : REPLICATION_STRATEGY , ' master ' : replication . get_master_ref ( self . _app , snapshot_info ) , ' log _ position ' : log_position } NEW_LINE return replication_snapshot NEW_LINE DEDENT def enable_as_master ( self , context , replica_source_config ) : NEW_LINE INDENT LOG . debug ( " Calling ▁ enable _ as _ master . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE DEDENT def detach_replica ( self , context , for_failover = False ) : NEW_LINE INDENT LOG . debug ( " Detaching ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . detach_slave ( self . _app , for_failover ) NEW_LINE return replica_info NEW_LINE DEDENT def get_replica_context ( self , context ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replica ▁ context . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . get_replica_context ( self . _app ) NEW_LINE return replica_info NEW_LINE DEDENT def _validate_slave_for_replication ( self , context , replica_info ) : NEW_LINE INDENT if ( replica_info [ ' replication _ strategy ' ] != REPLICATION_STRATEGY ) : NEW_LINE INDENT raise exception . IncompatibleReplicationStrategy ( replica_info . update ( { ' guest _ strategy ' : REPLICATION_STRATEGY } ) ) NEW_LINE DEDENT DEDENT def attach_replica ( self , context , replica_info , slave_config ) : NEW_LINE INDENT LOG . debug ( " Attaching ▁ replica . " ) NEW_LINE try : NEW_LINE INDENT if ' replication _ strategy ' in replica_info : NEW_LINE INDENT self . _validate_slave_for_replication ( context , replica_info ) NEW_LINE DEDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_slave ( self . _app , replica_info , slave_config ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( " Error ▁ enabling ▁ replication . " ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def make_read_only ( self , context , read_only ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ make _ read _ only ( % s ) " % read_only ) NEW_LINE self . _app . make_read_only ( read_only ) NEW_LINE DEDENT def _get_repl_info ( self ) : NEW_LINE INDENT return self . _app . admin . get_info ( ' replication ' ) NEW_LINE DEDENT def _get_master_host ( self ) : NEW_LINE INDENT slave_info = self . _get_repl_info ( ) NEW_LINE return slave_info and slave_info [ ' master _ host ' ] or None NEW_LINE DEDENT def _get_repl_offset ( self ) : NEW_LINE INDENT repl_info = self . _get_repl_info ( ) NEW_LINE LOG . debug ( " Got ▁ repl ▁ info : ▁ % s " % repl_info ) NEW_LINE offset_key = ' % s _ repl _ offset ' % repl_info [ ' role ' ] NEW_LINE offset = repl_info [ offset_key ] NEW_LINE LOG . debug ( " Found ▁ offset ▁ % s ▁ for ▁ key ▁ % s . " % ( offset , offset_key ) ) NEW_LINE return int ( offset ) NEW_LINE DEDENT def get_last_txn ( self , context ) : NEW_LINE INDENT master_host = self . _get_master_host ( ) NEW_LINE repl_offset = self . _get_repl_offset ( ) NEW_LINE return master_host , repl_offset NEW_LINE DEDENT def get_latest_txn_id ( self , context ) : NEW_LINE INDENT LOG . info ( _ ( " Retrieving ▁ latest ▁ repl ▁ offset . " ) ) NEW_LINE return self . _get_repl_offset ( ) NEW_LINE DEDENT def wait_for_txn ( self , context , txn ) : NEW_LINE INDENT LOG . info ( _ ( " Waiting ▁ on ▁ repl ▁ offset ▁ ' % s ' . " ) % txn ) NEW_LINE def _wait_for_txn ( ) : NEW_LINE INDENT current_offset = self . _get_repl_offset ( ) NEW_LINE LOG . debug ( " Current ▁ offset : ▁ % s . " % current_offset ) NEW_LINE return current_offset >= txn NEW_LINE DEDENT try : NEW_LINE INDENT utils . poll_until ( _wait_for_txn , time_out = 120 ) NEW_LINE DEDENT except exception . PollTimeOut : NEW_LINE INDENT raise RuntimeError ( _ ( " Timeout ▁ occurred ▁ waiting ▁ for ▁ Redis ▁ repl ▁ " " offset ▁ to ▁ change ▁ to ▁ ' % s ' . " ) % txn ) NEW_LINE DEDENT DEDENT def cleanup_source_on_replica_detach ( self , context , replica_info ) : NEW_LINE INDENT LOG . debug ( " Cleaning ▁ up ▁ the ▁ source ▁ on ▁ the ▁ detach ▁ of ▁ a ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . cleanup_source_on_replica_detach ( self . _app , replica_info ) NEW_LINE DEDENT def demote_replication_master ( self , context ) : NEW_LINE INDENT LOG . debug ( " Demoting ▁ replica ▁ source . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . demote_master ( self . _app ) NEW_LINE DEDENT def cluster_meet ( self , context , ip , port ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ meet ▁ to ▁ join ▁ node ▁ to ▁ cluster . " ) NEW_LINE self . _app . cluster_meet ( ip , port ) NEW_LINE DEDENT def get_node_ip ( self , context ) : NEW_LINE INDENT LOG . debug ( " Retrieving ▁ cluster ▁ node ▁ ip ▁ address . " ) NEW_LINE return self . _app . get_node_ip ( ) NEW_LINE DEDENT def get_node_id_for_removal ( self , context ) : NEW_LINE INDENT LOG . debug ( " Validating ▁ removal ▁ of ▁ node ▁ from ▁ cluster . " ) NEW_LINE return self . _app . get_node_id_for_removal ( ) NEW_LINE DEDENT def remove_nodes ( self , context , node_ids ) : NEW_LINE INDENT LOG . debug ( " Removing ▁ nodes ▁ from ▁ cluster . " ) NEW_LINE self . _app . remove_nodes ( node_ids ) NEW_LINE DEDENT def cluster_addslots ( self , context , first_slot , last_slot ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ addslots ▁ to ▁ assign ▁ hash ▁ slots ▁ % s - % s . " , first_slot , last_slot ) NEW_LINE self . _app . cluster_addslots ( first_slot , last_slot ) NEW_LINE DEDENT def cluster_complete ( self , context ) : NEW_LINE INDENT LOG . debug ( " Cluster ▁ creation ▁ complete , ▁ starting ▁ status ▁ checks . " ) NEW_LINE self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Hernanarce/pelisalacarta/tree/master/python/version-mediaserver/platformcode/platformtools.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ pelisalacarta ▁ 4 ENDCOM # ▁ Copyright ▁ 2015 ▁ tvalacarta @ gmail . com ENDCOM # ▁ http : / / blog . tvalacarta . info / plugin - xbmc / pelisalacarta / ENDCOM # ▁ Distributed ▁ under ▁ the ▁ terms ▁ of ▁ GNU ▁ General ▁ Public ▁ License ▁ v3 ▁ ( GPLv3 ) ENDCOM # ▁ http : / / www . gnu . org / licenses / gpl - 3.0 . html ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ pelisalacarta ▁ 4 . ENDCOM # ▁ pelisalacarta ▁ 4 ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ pelisalacarta ▁ 4 ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ pelisalacarta ▁ 4 . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM # ▁ platformtools ENDCOM # ▁ Herramientas ▁ responsables ▁ de ▁ adaptar ▁ los ▁ diferentes ▁ ENDCOM # ▁ cuadros ▁ de ▁ dialogo ▁ a ▁ una ▁ plataforma ▁ en ▁ concreto , ENDCOM # ▁ en ▁ este ▁ caso ▁ Mediserver . ENDCOM # ▁ version ▁ 1.3 ENDCOM import os NEW_LINE import sys NEW_LINE from core import config NEW_LINE from core import logger NEW_LINE import threading NEW_LINE controllers = { } NEW_LINE def dialog_ok ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_ok ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_notification ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_notification ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_yesno ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_yesno ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_select ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_select ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress_bg ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress_bg ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_input ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_input ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_numeric ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_numeric ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_refresh ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_refresh ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_update ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_update ( * args , ** kwargs ) NEW_LINE DEDENT def render_items ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . render_items ( * args , ** kwargs ) NEW_LINE DEDENT def is_playing ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . is_playing ( * args , ** kwargs ) NEW_LINE DEDENT def play_video ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . play_video ( * args , ** kwargs ) NEW_LINE DEDENT def open_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . open_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_channel_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_channel_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_video_info ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_video_info ( * args , ** kwargs ) NEW_LINE DEDENT def show_recaptcha ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_recaptcha ( * args , ** kwargs ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="apollo13/ansible/tree/master/lib/ansible/modules/cloud/amazon/elasticache.py"> # ! / usr / bin / python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2017 ▁ Ansible ▁ Project ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = """ STRNEWLINE - - - STRNEWLINE module : ▁ elasticache STRNEWLINE short _ description : ▁ Manage ▁ cache ▁ clusters ▁ in ▁ Amazon ▁ Elasticache . STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ Manage ▁ cache ▁ clusters ▁ in ▁ Amazon ▁ Elasticache . STRNEWLINE ▁ ▁ - ▁ Returns ▁ information ▁ about ▁ the ▁ specified ▁ cache ▁ cluster . STRNEWLINE version _ added : ▁ " 1.4 " STRNEWLINE requirements : ▁ [ ▁ boto3 ▁ ] STRNEWLINE author : ▁ " Jim ▁ Dalton ▁ ( @ jsdalton ) " STRNEWLINE options : STRNEWLINE ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ C ( absent ) ▁ or ▁ C ( present ) ▁ are ▁ idempotent ▁ actions ▁ that ▁ will ▁ create ▁ or ▁ destroy ▁ a ▁ cache ▁ cluster ▁ as ▁ needed . ▁ C ( rebooted ) ▁ will ▁ reboot ▁ the ▁ cluster , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ resulting ▁ in ▁ a ▁ momentary ▁ outage . STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' present ' , ▁ ' absent ' , ▁ ' rebooted ' ] STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ cache ▁ cluster ▁ identifier STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ engine : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ cache ▁ engine ▁ to ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ memcached STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' redis ' , ▁ ' memcached ' ] STRNEWLINE ▁ ▁ cache _ engine _ version : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ version ▁ number ▁ of ▁ the ▁ cache ▁ engine STRNEWLINE ▁ ▁ node _ type : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ compute ▁ and ▁ memory ▁ capacity ▁ of ▁ the ▁ nodes ▁ in ▁ the ▁ cache ▁ cluster STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ cache . m1 . small STRNEWLINE ▁ ▁ num _ nodes : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ initial ▁ number ▁ of ▁ cache ▁ nodes ▁ that ▁ the ▁ cache ▁ cluster ▁ will ▁ have . ▁ Required ▁ when ▁ state = present . STRNEWLINE ▁ ▁ cache _ port : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ port ▁ number ▁ on ▁ which ▁ each ▁ of ▁ the ▁ cache ▁ nodes ▁ will ▁ accept ▁ connections STRNEWLINE ▁ ▁ cache _ parameter _ group : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ name ▁ of ▁ the ▁ cache ▁ parameter ▁ group ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ If ▁ this ▁ argument ▁ is ▁ omitted , ▁ the ▁ default ▁ cache ▁ parameter ▁ group STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ for ▁ the ▁ specified ▁ engine ▁ will ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 2.0 " STRNEWLINE ▁ ▁ ▁ ▁ aliases : ▁ [ ▁ ' parameter _ group ' ▁ ] STRNEWLINE ▁ ▁ cache _ subnet _ group : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ subnet ▁ group ▁ name ▁ to ▁ associate ▁ with . ▁ Only ▁ use ▁ if ▁ inside ▁ a ▁ vpc . ▁ Required ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 2.0 " STRNEWLINE ▁ ▁ security _ group _ ids : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ list ▁ of ▁ vpc ▁ security ▁ group ▁ names ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ Only ▁ use ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 1.6 " STRNEWLINE ▁ ▁ cache _ security _ groups : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ list ▁ of ▁ cache ▁ security ▁ group ▁ names ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ Must ▁ be ▁ an ▁ empty ▁ list ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ zone : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ EC2 ▁ Availability ▁ Zone ▁ in ▁ which ▁ the ▁ cache ▁ cluster ▁ will ▁ be ▁ created STRNEWLINE ▁ ▁ wait : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Wait ▁ for ▁ cache ▁ cluster ▁ result ▁ before ▁ returning STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' yes ' STRNEWLINE ▁ ▁ hard _ modify : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Whether ▁ to ▁ destroy ▁ and ▁ recreate ▁ an ▁ existing ▁ cache ▁ cluster ▁ if ▁ necessary ▁ in ▁ order ▁ to ▁ modify ▁ its ▁ state STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE extends _ documentation _ fragment : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ aws STRNEWLINE ▁ ▁ ▁ ▁ - ▁ ec2 STRNEWLINE """ NEW_LINE EXAMPLES = """ STRNEWLINE # ▁ Note : ▁ None ▁ of ▁ these ▁ examples ▁ set ▁ aws _ access _ key , ▁ aws _ secret _ key , ▁ or ▁ region . STRNEWLINE # ▁ It ▁ is ▁ assumed ▁ that ▁ their ▁ matching ▁ environment ▁ variables ▁ are ▁ set . STRNEWLINE STRNEWLINE # ▁ Basic ▁ example STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ engine : ▁ memcached STRNEWLINE ▁ ▁ ▁ ▁ cache _ engine _ version : ▁ 1.4.14 STRNEWLINE ▁ ▁ ▁ ▁ node _ type : ▁ cache . m1 . small STRNEWLINE ▁ ▁ ▁ ▁ num _ nodes : ▁ 1 STRNEWLINE ▁ ▁ ▁ ▁ cache _ port : ▁ 11211 STRNEWLINE ▁ ▁ ▁ ▁ cache _ security _ groups : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ default STRNEWLINE ▁ ▁ ▁ ▁ zone : ▁ us - east - 1d STRNEWLINE STRNEWLINE STRNEWLINE # ▁ Ensure ▁ cache ▁ cluster ▁ is ▁ gone STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE STRNEWLINE # ▁ Reboot ▁ cache ▁ cluster STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ rebooted STRNEWLINE STRNEWLINE """ NEW_LINE from time import sleep NEW_LINE from traceback import format_exc NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . ec2 import ec2_argument_spec , get_aws_connection_info , boto3_conn , HAS_BOTO3 , camel_dict_to_snake_dict NEW_LINE try : NEW_LINE INDENT import boto3 NEW_LINE import botocore NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass # ▁ will ▁ be ▁ detected ▁ by ▁ imported ▁ HAS _ BOTO3 ENDCOM NEW_LINE DEDENT class ElastiCacheManager ( object ) : NEW_LINE INDENT """ Handles ▁ elasticache ▁ creation ▁ and ▁ destruction """ NEW_LINE EXIST_STATUSES = [ ' available ' , ' creating ' , ' rebooting ' , ' modifying ' ] NEW_LINE def __init__ ( self , module , name , engine , cache_engine_version , node_type , num_nodes , cache_port , cache_parameter_group , cache_subnet_group , cache_security_groups , security_group_ids , zone , wait , hard_modify , region , ** aws_connect_kwargs ) : NEW_LINE INDENT self . module = module NEW_LINE self . name = name NEW_LINE self . engine = engine . lower ( ) NEW_LINE self . cache_engine_version = cache_engine_version NEW_LINE self . node_type = node_type NEW_LINE self . num_nodes = num_nodes NEW_LINE self . cache_port = cache_port NEW_LINE self . cache_parameter_group = cache_parameter_group NEW_LINE self . cache_subnet_group = cache_subnet_group NEW_LINE self . cache_security_groups = cache_security_groups NEW_LINE self . security_group_ids = security_group_ids NEW_LINE self . zone = zone NEW_LINE self . wait = wait NEW_LINE self . hard_modify = hard_modify NEW_LINE self . region = region NEW_LINE self . aws_connect_kwargs = aws_connect_kwargs NEW_LINE self . changed = False NEW_LINE self . data = None NEW_LINE self . status = ' gone ' NEW_LINE self . conn = self . _get_elasticache_connection ( ) NEW_LINE self . _refresh_data ( ) NEW_LINE DEDENT def ensure_present ( self ) : NEW_LINE INDENT """ Ensure ▁ cache ▁ cluster ▁ exists ▁ or ▁ create ▁ it ▁ if ▁ not """ NEW_LINE if self . exists ( ) : NEW_LINE INDENT self . sync ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . create ( ) NEW_LINE DEDENT DEDENT def ensure_absent ( self ) : NEW_LINE INDENT """ Ensure ▁ cache ▁ cluster ▁ is ▁ gone ▁ or ▁ delete ▁ it ▁ if ▁ not """ NEW_LINE self . delete ( ) NEW_LINE DEDENT def ensure_rebooted ( self ) : NEW_LINE INDENT """ Ensure ▁ cache ▁ cluster ▁ is ▁ gone ▁ or ▁ delete ▁ it ▁ if ▁ not """ NEW_LINE self . reboot ( ) NEW_LINE DEDENT def exists ( self ) : NEW_LINE INDENT """ Check ▁ if ▁ cache ▁ cluster ▁ exists """ NEW_LINE return self . status in self . EXIST_STATUSES NEW_LINE DEDENT def create ( self ) : NEW_LINE INDENT """ Create ▁ an ▁ ElastiCache ▁ cluster """ NEW_LINE if self . status == ' available ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT return NEW_LINE DEDENT if self . status == ' deleting ' : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ deleting . ▁ Cannot ▁ create . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT DEDENT kwargs = dict ( CacheClusterId = self . name , NumCacheNodes = self . num_nodes , CacheNodeType = self . node_type , Engine = self . engine , EngineVersion = self . cache_engine_version , CacheSecurityGroupNames = self . cache_security_groups , SecurityGroupIds = self . security_group_ids , CacheParameterGroupName = self . cache_parameter_group , CacheSubnetGroupName = self . cache_subnet_group ) NEW_LINE if self . cache_port is not None : NEW_LINE INDENT kwargs [ ' Port ' ] = self . cache_port NEW_LINE DEDENT if self . zone is not None : NEW_LINE INDENT kwargs [ ' PreferredAvailabilityZone ' ] = self . zone NEW_LINE DEDENT try : NEW_LINE INDENT self . conn . create_cache_cluster ( ** kwargs ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT return True NEW_LINE DEDENT def delete ( self ) : NEW_LINE INDENT """ Destroy ▁ an ▁ ElastiCache ▁ cluster """ NEW_LINE if self . status == ' gone ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status == ' deleting ' : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ % s . ▁ Cannot ▁ delete . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT response = self . conn . delete_cache_cluster ( CacheClusterId = self . name ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT cache_cluster_data = response [ ' CacheCluster ' ] NEW_LINE self . _refresh_data ( cache_cluster_data ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT DEDENT def sync ( self ) : NEW_LINE INDENT """ Sync ▁ settings ▁ to ▁ cluster ▁ if ▁ required """ NEW_LINE if not self . exists ( ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ % s . ▁ Cannot ▁ sync . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE # ▁ Cluster ▁ can ▁ only ▁ be ▁ synced ▁ if ▁ available . ▁ If ▁ we ▁ can ' t ▁ wait ENDCOM # ▁ for ▁ this , ▁ then ▁ just ▁ be ▁ done . ENDCOM INDENT return NEW_LINE DEDENT DEDENT if self . _requires_destroy_and_create ( ) : NEW_LINE INDENT if not self . hard_modify : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ destructive ▁ modification . ▁ ' hard _ modify ' ▁ must ▁ be ▁ set ▁ to ▁ true ▁ to ▁ proceed . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT if not self . wait : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ destructive ▁ modification . ▁ ' wait ' ▁ must ▁ be ▁ set ▁ to ▁ true . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT self . delete ( ) NEW_LINE self . create ( ) NEW_LINE return NEW_LINE DEDENT if self . _requires_modification ( ) : NEW_LINE INDENT self . modify ( ) NEW_LINE DEDENT DEDENT def modify ( self ) : NEW_LINE INDENT """ Modify ▁ the ▁ cache ▁ cluster . ▁ Note ▁ it ' s ▁ only ▁ possible ▁ to ▁ modify ▁ a ▁ few ▁ select ▁ options . """ NEW_LINE nodes_to_remove = self . _get_nodes_to_remove ( ) NEW_LINE try : NEW_LINE INDENT self . conn . modify_cache_cluster ( CacheClusterId = self . name , NumCacheNodes = self . num_nodes , CacheNodeIdsToRemove = nodes_to_remove , CacheSecurityGroupNames = self . cache_security_groups , CacheParameterGroupName = self . cache_parameter_group , SecurityGroupIds = self . security_group_ids , ApplyImmediately = True , EngineVersion = self . cache_engine_version ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT DEDENT def reboot ( self ) : NEW_LINE INDENT """ Reboot ▁ the ▁ cache ▁ cluster """ NEW_LINE if not self . exists ( ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ % s . ▁ Cannot ▁ reboot . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT if self . status == ' rebooting ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ % s . ▁ Cannot ▁ reboot . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE # ▁ Collect ▁ ALL ▁ nodes ▁ for ▁ reboot ENDCOM DEDENT DEDENT cache_node_ids = [ cn [ ' CacheNodeId ' ] for cn in self . data [ ' CacheNodes ' ] ] NEW_LINE try : NEW_LINE INDENT self . conn . reboot_cache_cluster ( CacheClusterId = self . name , CacheNodeIdsToReboot = cache_node_ids ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT DEDENT def get_info ( self ) : NEW_LINE INDENT """ Return ▁ basic ▁ info ▁ about ▁ the ▁ cache ▁ cluster """ NEW_LINE info = { ' name ' : self . name , ' status ' : self . status } NEW_LINE if self . data : NEW_LINE INDENT info [ ' data ' ] = self . data NEW_LINE DEDENT return info NEW_LINE DEDENT def _wait_for_status ( self , awaited_status ) : NEW_LINE INDENT """ Wait ▁ for ▁ status ▁ to ▁ change ▁ from ▁ present ▁ status ▁ to ▁ awaited _ status """ NEW_LINE status_map = { ' creating ' : ' available ' , ' rebooting ' : ' available ' , ' modifying ' : ' available ' , ' deleting ' : ' gone ' } NEW_LINE if self . status == awaited_status : NEW_LINE # ▁ No ▁ need ▁ to ▁ wait , ▁ we ' re ▁ already ▁ done ENDCOM INDENT return NEW_LINE DEDENT if status_map [ self . status ] != awaited_status : NEW_LINE INDENT msg = " Invalid ▁ awaited ▁ status . ▁ ' % s ' ▁ cannot ▁ transition ▁ to ▁ ' % s ' " NEW_LINE self . module . fail_json ( msg = msg % ( self . status , awaited_status ) ) NEW_LINE DEDENT if awaited_status not in set ( status_map . values ( ) ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ not ▁ a ▁ valid ▁ awaited ▁ status . " NEW_LINE self . module . fail_json ( msg = msg % awaited_status ) NEW_LINE DEDENT while True : NEW_LINE INDENT sleep ( 1 ) NEW_LINE self . _refresh_data ( ) NEW_LINE if self . status == awaited_status : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT DEDENT def _requires_modification ( self ) : NEW_LINE INDENT """ Check ▁ if ▁ cluster ▁ requires ▁ ( nondestructive ) ▁ modification """ NEW_LINE # ▁ Check ▁ modifiable ▁ data ▁ attributes ENDCOM modifiable_data = { ' NumCacheNodes ' : self . num_nodes , ' EngineVersion ' : self . cache_engine_version } NEW_LINE for key , value in modifiable_data . items ( ) : NEW_LINE INDENT if value is not None and value and self . data [ key ] != value : NEW_LINE INDENT return True NEW_LINE # ▁ Check ▁ cache ▁ security ▁ groups ENDCOM DEDENT DEDENT cache_security_groups = [ ] NEW_LINE for sg in self . data [ ' CacheSecurityGroups ' ] : NEW_LINE INDENT cache_security_groups . append ( sg [ ' CacheSecurityGroupName ' ] ) NEW_LINE DEDENT if set ( cache_security_groups ) != set ( self . cache_security_groups ) : NEW_LINE INDENT return True NEW_LINE # ▁ check ▁ vpc ▁ security ▁ groups ENDCOM DEDENT if self . security_group_ids : NEW_LINE INDENT vpc_security_groups = [ ] NEW_LINE security_groups = self . data [ ' SecurityGroups ' ] or [ ] NEW_LINE for sg in security_groups : NEW_LINE INDENT vpc_security_groups . append ( sg [ ' SecurityGroupId ' ] ) NEW_LINE DEDENT if set ( vpc_security_groups ) != set ( self . security_group_ids ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def _requires_destroy_and_create ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Check ▁ whether ▁ a ▁ destroy ▁ and ▁ create ▁ is ▁ required ▁ to ▁ synchronize ▁ cluster . STRNEWLINE ▁ """ NEW_LINE unmodifiable_data = { ' node _ type ' : self . data [ ' CacheNodeType ' ] , ' engine ' : self . data [ ' Engine ' ] , ' cache _ port ' : self . _get_port ( ) } NEW_LINE # ▁ Only ▁ check ▁ for ▁ modifications ▁ if ▁ zone ▁ is ▁ specified ENDCOM if self . zone is not None : NEW_LINE INDENT unmodifiable_data [ ' zone ' ] = self . data [ ' PreferredAvailabilityZone ' ] NEW_LINE DEDENT for key , value in unmodifiable_data . items ( ) : NEW_LINE INDENT if getattr ( self , key ) is not None and getattr ( self , key ) != value : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def _get_elasticache_connection ( self ) : NEW_LINE INDENT """ Get ▁ an ▁ elasticache ▁ connection """ NEW_LINE region , ec2_url , aws_connect_params = get_aws_connection_info ( self . module , boto3 = True ) NEW_LINE if region : NEW_LINE INDENT return boto3_conn ( self . module , conn_type = ' client ' , resource = ' elasticache ' , region = region , endpoint = ec2_url , ** aws_connect_params ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = " region ▁ must ▁ be ▁ specified " ) NEW_LINE DEDENT DEDENT def _get_port ( self ) : NEW_LINE INDENT """ Get ▁ the ▁ port . ▁ Where ▁ this ▁ information ▁ is ▁ retrieved ▁ from ▁ is ▁ engine ▁ dependent . """ NEW_LINE if self . data [ ' Engine ' ] == ' memcached ' : NEW_LINE INDENT return self . data [ ' ConfigurationEndpoint ' ] [ ' Port ' ] NEW_LINE DEDENT elif self . data [ ' Engine ' ] == ' redis ' : NEW_LINE # ▁ Redis ▁ only ▁ supports ▁ a ▁ single ▁ node ▁ ( presently ) ▁ so ▁ just ▁ use ENDCOM # ▁ the ▁ first ▁ and ▁ only ENDCOM INDENT return self . data [ ' CacheNodes ' ] [ 0 ] [ ' Endpoint ' ] [ ' Port ' ] NEW_LINE DEDENT DEDENT def _refresh_data ( self , cache_cluster_data = None ) : NEW_LINE INDENT """ Refresh ▁ data ▁ about ▁ this ▁ cache ▁ cluster """ NEW_LINE if cache_cluster_data is None : NEW_LINE INDENT try : NEW_LINE INDENT response = self . conn . describe_cache_clusters ( CacheClusterId = self . name , ShowCacheNodeInfo = True ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT if e . response [ ' Error ' ] [ ' Code ' ] == ' CacheClusterNotFound ' : NEW_LINE INDENT self . data = None NEW_LINE self . status = ' gone ' NEW_LINE return NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT DEDENT cache_cluster_data = response [ ' CacheClusters ' ] [ 0 ] NEW_LINE DEDENT self . data = cache_cluster_data NEW_LINE self . status = self . data [ ' CacheClusterStatus ' ] NEW_LINE # ▁ The ▁ documentation ▁ for ▁ elasticache ▁ lies ▁ - - ▁ status ▁ on ▁ rebooting ▁ is ▁ set ENDCOM # ▁ to ▁ ' rebooting ▁ cache ▁ cluster ▁ nodes ' ▁ instead ▁ of ▁ ' rebooting ' . ▁ Fix ▁ it ENDCOM # ▁ here ▁ to ▁ make ▁ status ▁ checks ▁ etc . ▁ more ▁ sane . ENDCOM if self . status == ' rebooting ▁ cache ▁ cluster ▁ nodes ' : NEW_LINE INDENT self . status = ' rebooting ' NEW_LINE DEDENT DEDENT def _get_nodes_to_remove ( self ) : NEW_LINE INDENT """ If ▁ there ▁ are ▁ nodes ▁ to ▁ remove , ▁ it ▁ figures ▁ out ▁ which ▁ need ▁ to ▁ be ▁ removed """ NEW_LINE num_nodes_to_remove = self . data [ ' NumCacheNodes ' ] - self . num_nodes NEW_LINE if num_nodes_to_remove <= 0 : NEW_LINE INDENT return [ ] NEW_LINE DEDENT if not self . hard_modify : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ removal ▁ of ▁ cache ▁ nodes . ▁ ' hard _ modify ' ▁ must ▁ be ▁ set ▁ to ▁ true ▁ to ▁ proceed . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT cache_node_ids = [ cn [ ' CacheNodeId ' ] for cn in self . data [ ' CacheNodes ' ] ] NEW_LINE return cache_node_ids [ - num_nodes_to_remove : ] NEW_LINE DEDENT DEDENT def main ( ) : NEW_LINE INDENT """ ▁ elasticache ▁ ansible ▁ module ▁ """ NEW_LINE argument_spec = ec2_argument_spec ( ) NEW_LINE argument_spec . update ( dict ( state = dict ( required = True , choices = [ ' present ' , ' absent ' , ' rebooted ' ] ) , name = dict ( required = True ) , engine = dict ( default = ' memcached ' ) , cache_engine_version = dict ( default = " " ) , node_type = dict ( default = ' cache . t2 . small ' ) , num_nodes = dict ( default = 1 , type = ' int ' ) , # ▁ alias ▁ for ▁ compat ▁ with ▁ the ▁ original ▁ PR ▁ 1950 ENDCOM cache_parameter_group = dict ( default = " " , aliases = [ ' parameter _ group ' ] ) , cache_port = dict ( type = ' int ' ) , cache_subnet_group = dict ( default = " " ) , cache_security_groups = dict ( default = [ ] , type = ' list ' ) , security_group_ids = dict ( default = [ ] , type = ' list ' ) , zone = dict ( ) , wait = dict ( default = True , type = ' bool ' ) , hard_modify = dict ( type = ' bool ' ) ) ) NEW_LINE module = AnsibleModule ( argument_spec = argument_spec , ) NEW_LINE if not HAS_BOTO3 : NEW_LINE INDENT module . fail_json ( msg = ' boto3 ▁ required ▁ for ▁ this ▁ module ' ) NEW_LINE DEDENT region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module ) NEW_LINE name = module . params [ ' name ' ] NEW_LINE state = module . params [ ' state ' ] NEW_LINE engine = module . params [ ' engine ' ] NEW_LINE cache_engine_version = module . params [ ' cache _ engine _ version ' ] NEW_LINE node_type = module . params [ ' node _ type ' ] NEW_LINE num_nodes = module . params [ ' num _ nodes ' ] NEW_LINE cache_port = module . params [ ' cache _ port ' ] NEW_LINE cache_subnet_group = module . params [ ' cache _ subnet _ group ' ] NEW_LINE cache_security_groups = module . params [ ' cache _ security _ groups ' ] NEW_LINE security_group_ids = module . params [ ' security _ group _ ids ' ] NEW_LINE zone = module . params [ ' zone ' ] NEW_LINE wait = module . params [ ' wait ' ] NEW_LINE hard_modify = module . params [ ' hard _ modify ' ] NEW_LINE cache_parameter_group = module . params [ ' cache _ parameter _ group ' ] NEW_LINE if cache_subnet_group and cache_security_groups : NEW_LINE INDENT module . fail_json ( msg = " Can ' t ▁ specify ▁ both ▁ cache _ subnet _ group ▁ and ▁ cache _ security _ groups " ) NEW_LINE DEDENT if state == ' present ' and not num_nodes : NEW_LINE INDENT module . fail_json ( msg = " ' num _ nodes ' ▁ is ▁ a ▁ required ▁ parameter . ▁ Please ▁ specify ▁ num _ nodes ▁ > ▁ 0" ) NEW_LINE DEDENT elasticache_manager = ElastiCacheManager ( module , name , engine , cache_engine_version , node_type , num_nodes , cache_port , cache_parameter_group , cache_subnet_group , cache_security_groups , security_group_ids , zone , wait , hard_modify , region , ** aws_connect_kwargs ) NEW_LINE if state == ' present ' : NEW_LINE INDENT elasticache_manager . ensure_present ( ) NEW_LINE DEDENT elif state == ' absent ' : NEW_LINE INDENT elasticache_manager . ensure_absent ( ) NEW_LINE DEDENT elif state == ' rebooted ' : NEW_LINE INDENT elasticache_manager . ensure_rebooted ( ) NEW_LINE DEDENT facts_result = dict ( changed = elasticache_manager . changed , elasticache = elasticache_manager . get_info ( ) ) NEW_LINE module . exit_json ( ** facts_result ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="agabrown/PyGaia/tree/master/pygaia/utils.py"> __all__ = [ ' enum ' , ' degreesToRadians ' , ' radiansToDegrees ' ] NEW_LINE import numpy as np NEW_LINE from pygaia . astrometry . constants import auKmYearPerSec NEW_LINE def enum ( typename , field_names ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ a ▁ new ▁ enumeration ▁ type . STRNEWLINE ▁ STRNEWLINE ▁ Code ▁ is ▁ copyright ▁ ( c ) ▁ Gabriel ▁ Genellina , ▁ 2010 , ▁ MIT ▁ License . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ typename ▁ - ▁ Name ▁ of ▁ the ▁ enumerated ▁ type STRNEWLINE ▁ field _ names ▁ - ▁ Names ▁ of ▁ the ▁ fields ▁ of ▁ the ▁ enumerated ▁ type STRNEWLINE ▁ """ NEW_LINE if isinstance ( field_names , str ) : NEW_LINE INDENT field_names = field_names . replace ( ' , ' , ' ▁ ' ) . split ( ) NEW_LINE DEDENT d = dict ( ( reversed ( nv ) for nv in enumerate ( field_names ) ) , __slots__ = ( ) ) NEW_LINE return type ( typename , ( object , ) , d ) ( ) NEW_LINE DEDENT def degreesToRadians ( angle ) : NEW_LINE INDENT """ STRNEWLINE ▁ Convert ▁ from ▁ degrees ▁ to ▁ radians . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ angle ▁ - ▁ angle ▁ in ▁ degrees STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ Angle ▁ in ▁ radians . STRNEWLINE ▁ """ NEW_LINE return angle / 180.0 * np . pi NEW_LINE DEDENT def radiansToDegrees ( angle ) : NEW_LINE INDENT """ STRNEWLINE ▁ Convert ▁ from ▁ radians ▁ to ▁ degrees . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ angle ▁ - ▁ angle ▁ in ▁ radians . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ STRNEWLINE ▁ Angle ▁ in ▁ degrees . STRNEWLINE ▁ """ NEW_LINE return angle / np . pi * 180.0 NEW_LINE DEDENT def construct_covariance_matrix ( cvec , parallax , radial_velocity , radial_velocity_error ) : NEW_LINE INDENT """ STRNEWLINE ▁ Take ▁ the ▁ astrometric ▁ parameter ▁ standard ▁ uncertainties ▁ and ▁ the ▁ uncertainty ▁ correlations ▁ as ▁ quoted ▁ in STRNEWLINE ▁ the ▁ Gaia ▁ catalogue ▁ and ▁ construct ▁ the ▁ covariance ▁ matrix . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ cvec ▁ : ▁ array _ like STRNEWLINE ▁ Array ▁ of ▁ shape ▁ ( 15 , ) ▁ ( 1 ▁ source ) ▁ or ▁ ( n , 15 ) ▁ ( n ▁ sources ) ▁ for ▁ the ▁ astrometric ▁ parameter ▁ standard STRNEWLINE ▁ uncertainties ▁ and ▁ their ▁ correlations , ▁ as ▁ listed ▁ in ▁ the ▁ Gaia ▁ catalogue ▁ [ ra _ error , ▁ dec _ error , STRNEWLINE ▁ parallax _ error , ▁ pmra _ error , ▁ pmdec _ error , ▁ ra _ dec _ corr , ▁ ra _ parallax _ corr , ▁ ra _ pmra _ corr , STRNEWLINE ▁ ra _ pmdec _ corr , ▁ dec _ parallax _ corr , ▁ dec _ pmra _ corr , ▁ dec _ pmdec _ corr , ▁ parallax _ pmra _ corr , STRNEWLINE ▁ parallax _ pmdec _ corr , ▁ pmra _ pmdec _ corr ] . ▁ Units ▁ are ▁ ( mas ^ 2 , ▁ mas ^ 2 / yr , ▁ mas ^ 2 / yr ^ 2 ) . STRNEWLINE ▁ STRNEWLINE ▁ parallax ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ parallax ▁ ( mas ) . STRNEWLINE ▁ STRNEWLINE ▁ radial _ velocity ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ radial ▁ velocity ▁ ( km / s , ▁ does ▁ not ▁ have ▁ to ▁ be ▁ from ▁ Gaia ▁ RVS ! ) . ▁ If ▁ the ▁ radial ▁ velocity ▁ is ▁ not STRNEWLINE ▁ known ▁ it ▁ can ▁ be ▁ set ▁ to ▁ zero . STRNEWLINE STRNEWLINE ▁ radial _ velocity _ error ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ radial ▁ velocity ▁ uncertainty ▁ ( km / s ) . ▁ If ▁ the ▁ radial ▁ velocity ▁ is ▁ not ▁ know ▁ this ▁ can ▁ be ▁ set ▁ to STRNEWLINE ▁ the ▁ radial ▁ velocity ▁ dispersion ▁ for ▁ the ▁ population ▁ the ▁ source ▁ was ▁ drawn ▁ from . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ Covariance ▁ matrix ▁ as ▁ a ▁ 6x6 ▁ array . STRNEWLINE ▁ """ NEW_LINE if np . ndim ( cvec ) == 1 : NEW_LINE INDENT cmat = np . zeros ( ( 1 , 6 , 6 ) ) NEW_LINE nsources = 1 NEW_LINE cv = np . atleast_2d ( cvec ) NEW_LINE DEDENT else : NEW_LINE INDENT nsources = cvec . shape [ 0 ] NEW_LINE cmat = np . zeros ( ( nsources , 6 , 6 ) ) NEW_LINE cv = cvec NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 0 : 5 ] = cv [ k , 0 : 5 ] ** 2 NEW_LINE DEDENT iu = np . triu_indices ( 5 , k = 1 ) NEW_LINE for k in range ( 10 ) : NEW_LINE INDENT i = iu [ 0 ] [ k ] NEW_LINE j = iu [ 1 ] [ k ] NEW_LINE cmat [ : , i , j ] = cv [ : , i ] * cv [ : , j ] * cv [ : , k + 5 ] NEW_LINE cmat [ : , j , i ] = cmat [ : , i , j ] NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 5 ] = cmat [ k , 0 : 5 , 2 ] * np . atleast_1d ( radial_velocity ) [ k ] / auKmYearPerSec NEW_LINE DEDENT cmat [ : , 5 , 0 : 5 ] = cmat [ : , 0 : 5 , 5 ] NEW_LINE cmat [ : , 5 , 5 ] = cmat [ : , 2 , 2 ] * ( radial_velocity ** 2 + radial_velocity_error ** 2 ) / auKmYearPerSec ** 2 + ( parallax * radial_velocity_error / auKmYearPerSec ) ** 2 NEW_LINE return np . squeeze ( cmat ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="ftomassetti/intellij-community/tree/master/python/lib/Lib/site-packages/django/contrib/gis/geos/tests/test_geos.py"> import ctypes , random , unittest , sys NEW_LINE from django . contrib . gis . geos import * NEW_LINE from django . contrib . gis . geos . base import gdal , numpy , GEOSBase NEW_LINE from django . contrib . gis . geos . libgeos import GEOS_PREPARE NEW_LINE from django . contrib . gis . geometry . test_data import TestDataMixin NEW_LINE class GEOSTest ( unittest . TestCase , TestDataMixin ) : NEW_LINE INDENT @ property NEW_LINE def null_srid ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ the ▁ proper ▁ null ▁ SRID ▁ depending ▁ on ▁ the ▁ GEOS ▁ version . STRNEWLINE ▁ See ▁ the ▁ comments ▁ in ▁ ` test15 _ srid ` ▁ for ▁ more ▁ details . STRNEWLINE ▁ """ NEW_LINE info = geos_version_info ( ) NEW_LINE if info [ ' version ' ] == '3.0.0' and info [ ' release _ candidate ' ] : NEW_LINE INDENT return - 1 NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT def test00_base ( self ) : NEW_LINE INDENT " Tests ▁ out ▁ the ▁ GEOSBase ▁ class . " NEW_LINE # ▁ Testing ▁ out ▁ GEOSBase ▁ class , ▁ which ▁ provides ▁ a ▁ ` ptr ` ▁ property ENDCOM # ▁ that ▁ abstracts ▁ out ▁ access ▁ to ▁ underlying ▁ C ▁ pointers . ENDCOM class FakeGeom1 ( GEOSBase ) : NEW_LINE INDENT pass NEW_LINE # ▁ This ▁ one ▁ only ▁ accepts ▁ pointers ▁ to ▁ floats ENDCOM DEDENT c_float_p = ctypes . POINTER ( ctypes . c_float ) NEW_LINE class FakeGeom2 ( GEOSBase ) : NEW_LINE INDENT ptr_type = c_float_p NEW_LINE # ▁ Default ▁ ptr _ type ▁ is ▁ ` c _ void _ p ` . ENDCOM DEDENT fg1 = FakeGeom1 ( ) NEW_LINE # ▁ Default ▁ ptr _ type ▁ is ▁ C ▁ float ▁ pointer ENDCOM fg2 = FakeGeom2 ( ) NEW_LINE # ▁ These ▁ assignments ▁ are ▁ OK ▁ - - ▁ None ▁ is ▁ allowed ▁ because ENDCOM # ▁ it ' s ▁ equivalent ▁ to ▁ the ▁ NULL ▁ pointer . ENDCOM fg1 . ptr = ctypes . c_void_p ( ) NEW_LINE fg1 . ptr = None NEW_LINE fg2 . ptr = c_float_p ( ctypes . c_float ( 5.23 ) ) NEW_LINE fg2 . ptr = None NEW_LINE # ▁ Because ▁ pointers ▁ have ▁ been ▁ set ▁ to ▁ NULL , ▁ an ▁ exception ▁ should ▁ be ENDCOM # ▁ raised ▁ when ▁ we ▁ try ▁ to ▁ access ▁ it . ▁ Raising ▁ an ▁ exception ▁ is ENDCOM # ▁ preferrable ▁ to ▁ a ▁ segmentation ▁ fault ▁ that ▁ commonly ▁ occurs ▁ when ENDCOM # ▁ a ▁ C ▁ method ▁ is ▁ given ▁ a ▁ NULL ▁ memory ▁ reference . ENDCOM for fg in ( fg1 , fg2 ) : NEW_LINE # ▁ Equivalent ▁ to ▁ ` fg . ptr ` ENDCOM INDENT self . assertRaises ( GEOSException , fg . _get_ptr ) NEW_LINE # ▁ Anything ▁ that ▁ is ▁ either ▁ not ▁ None ▁ or ▁ the ▁ acceptable ▁ pointer ▁ type ▁ will ENDCOM # ▁ result ▁ in ▁ a ▁ TypeError ▁ when ▁ trying ▁ to ▁ assign ▁ it ▁ to ▁ the ▁ ` ptr ` ▁ property . ENDCOM # ▁ Thus , ▁ memmory ▁ addresses ▁ ( integers ) ▁ and ▁ pointers ▁ of ▁ the ▁ incorrect ▁ type ENDCOM # ▁ ( in ▁ ` bad _ ptrs ` ) ▁ will ▁ not ▁ be ▁ allowed . ENDCOM DEDENT bad_ptrs = ( 5 , ctypes . c_char_p ( ' foobar ' ) ) NEW_LINE for bad_ptr in bad_ptrs : NEW_LINE # ▁ Equivalent ▁ to ▁ ` fg . ptr ▁ = ▁ bad _ ptr ` ENDCOM INDENT self . assertRaises ( TypeError , fg1 . _set_ptr , bad_ptr ) NEW_LINE self . assertRaises ( TypeError , fg2 . _set_ptr , bad_ptr ) NEW_LINE DEDENT DEDENT def test01a_wkt ( self ) : NEW_LINE INDENT " Testing ▁ WKT ▁ output . " NEW_LINE for g in self . geometries . wkt_out : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( g . ewkt , geom . wkt ) NEW_LINE DEDENT DEDENT def test01b_hex ( self ) : NEW_LINE INDENT " Testing ▁ HEX ▁ output . " NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( g . hex , geom . hex ) NEW_LINE DEDENT DEDENT def test01b_hexewkb ( self ) : NEW_LINE INDENT " Testing ▁ ( HEX ) EWKB ▁ output . " NEW_LINE from binascii import a2b_hex NEW_LINE # ▁ For ▁ testing ▁ HEX ( EWKB ) . ENDCOM ogc_hex = '01010000000000000000000000000000000000F03F ' NEW_LINE # ▁ ` SELECT ▁ ST _ AsHEXEWKB ( ST _ GeomFromText ( ' POINT ( 0 ▁ 1 ) ' , ▁ 4326 ) ) ; ` ENDCOM hexewkb_2d = '0101000020E61000000000000000000000000000000000F03F ' NEW_LINE # ▁ ` SELECT ▁ ST _ AsHEXEWKB ( ST _ GeomFromEWKT ( ' SRID = 4326 ; POINT ( 0 ▁ 1 ▁ 2 ) ' ) ) ; ` ENDCOM hexewkb_3d = '01010000A0E61000000000000000000000000000000000F03F0000000000000040' NEW_LINE pnt_2d = Point ( 0 , 1 , srid = 4326 ) NEW_LINE pnt_3d = Point ( 0 , 1 , 2 , srid = 4326 ) NEW_LINE # ▁ OGC - compliant ▁ HEX ▁ will ▁ not ▁ have ▁ SRID ▁ nor ▁ Z ▁ value . ENDCOM self . assertEqual ( ogc_hex , pnt_2d . hex ) NEW_LINE self . assertEqual ( ogc_hex , pnt_3d . hex ) NEW_LINE # ▁ HEXEWKB ▁ should ▁ be ▁ appropriate ▁ for ▁ its ▁ dimension ▁ - - ▁ have ▁ to ▁ use ▁ an ENDCOM # ▁ a ▁ WKBWriter ▁ w / dimension ▁ set ▁ accordingly , ▁ else ▁ GEOS ▁ will ▁ insert ENDCOM # ▁ garbage ▁ into ▁ 3D ▁ coordinate ▁ if ▁ there ▁ is ▁ none . ▁ Also , ▁ GEOS ▁ has ▁ a ENDCOM # ▁ a ▁ bug ▁ in ▁ versions ▁ prior ▁ to ▁ 3.1 ▁ that ▁ puts ▁ the ▁ X ▁ coordinate ▁ in ENDCOM # ▁ place ▁ of ▁ Z ; ▁ an ▁ exception ▁ should ▁ be ▁ raised ▁ on ▁ those ▁ versions . ENDCOM self . assertEqual ( hexewkb_2d , pnt_2d . hexewkb ) NEW_LINE if GEOS_PREPARE : NEW_LINE INDENT self . assertEqual ( hexewkb_3d , pnt_3d . hexewkb ) NEW_LINE self . assertEqual ( True , GEOSGeometry ( hexewkb_3d ) . hasz ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT hexewkb = pnt_3d . hexewkb NEW_LINE DEDENT except GEOSException : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Should ▁ have ▁ raised ▁ GEOSException . ' ) NEW_LINE # ▁ Same ▁ for ▁ EWKB . ENDCOM DEDENT DEDENT self . assertEqual ( buffer ( a2b_hex ( hexewkb_2d ) ) , pnt_2d . ewkb ) NEW_LINE if GEOS_PREPARE : NEW_LINE INDENT self . assertEqual ( buffer ( a2b_hex ( hexewkb_3d ) ) , pnt_3d . ewkb ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT ewkb = pnt_3d . ewkb NEW_LINE DEDENT except GEOSException : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Should ▁ have ▁ raised ▁ GEOSException ' ) NEW_LINE # ▁ Redundant ▁ sanity ▁ check . ENDCOM DEDENT DEDENT self . assertEqual ( 4326 , GEOSGeometry ( hexewkb_2d ) . srid ) NEW_LINE DEDENT def test01c_kml ( self ) : NEW_LINE INDENT " Testing ▁ KML ▁ output . " NEW_LINE for tg in self . geometries . wkt_out : NEW_LINE INDENT geom = fromstr ( tg . wkt ) NEW_LINE kml = getattr ( tg , ' kml ' , False ) NEW_LINE if kml : self . assertEqual ( kml , geom . kml ) NEW_LINE DEDENT DEDENT def test01d_errors ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ Error ▁ handlers . " NEW_LINE # ▁ string - based ENDCOM print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ ERROR ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE for err in self . geometries . errors : NEW_LINE INDENT try : NEW_LINE INDENT g = fromstr ( err . wkt ) NEW_LINE DEDENT except ( GEOSException , ValueError ) : NEW_LINE INDENT pass NEW_LINE # ▁ Bad ▁ WKB ENDCOM DEDENT DEDENT self . assertRaises ( GEOSException , GEOSGeometry , buffer ( '0' ) ) NEW_LINE print " \n END ▁ - ▁ expecting ▁ GEOS _ ERROR ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE class NotAGeometry ( object ) : NEW_LINE INDENT pass NEW_LINE # ▁ Some ▁ other ▁ object ENDCOM DEDENT self . assertRaises ( TypeError , GEOSGeometry , NotAGeometry ( ) ) NEW_LINE # ▁ None ENDCOM self . assertRaises ( TypeError , GEOSGeometry , None ) NEW_LINE DEDENT def test01e_wkb ( self ) : NEW_LINE INDENT " Testing ▁ WKB ▁ output . " NEW_LINE from binascii import b2a_hex NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE wkb = geom . wkb NEW_LINE self . assertEqual ( b2a_hex ( wkb ) . upper ( ) , g . hex ) NEW_LINE DEDENT DEDENT def test01f_create_hex ( self ) : NEW_LINE INDENT " Testing ▁ creation ▁ from ▁ HEX . " NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom_h = GEOSGeometry ( g . hex ) NEW_LINE # ▁ we ▁ need ▁ to ▁ do ▁ this ▁ so ▁ decimal ▁ places ▁ get ▁ normalised ENDCOM geom_t = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( geom_t . wkt , geom_h . wkt ) NEW_LINE DEDENT DEDENT def test01g_create_wkb ( self ) : NEW_LINE INDENT " Testing ▁ creation ▁ from ▁ WKB . " NEW_LINE from binascii import a2b_hex NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT wkb = buffer ( a2b_hex ( g . hex ) ) NEW_LINE geom_h = GEOSGeometry ( wkb ) NEW_LINE # ▁ we ▁ need ▁ to ▁ do ▁ this ▁ so ▁ decimal ▁ places ▁ get ▁ normalised ENDCOM geom_t = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( geom_t . wkt , geom_h . wkt ) NEW_LINE DEDENT DEDENT def test01h_ewkt ( self ) : NEW_LINE INDENT " Testing ▁ EWKT . " NEW_LINE srid = 32140 NEW_LINE for p in self . geometries . polygons : NEW_LINE INDENT ewkt = ' SRID = % d ; % s ' % ( srid , p . wkt ) NEW_LINE poly = fromstr ( ewkt ) NEW_LINE self . assertEqual ( srid , poly . srid ) NEW_LINE self . assertEqual ( srid , poly . shell . srid ) NEW_LINE self . assertEqual ( srid , fromstr ( poly . ewkt ) . srid ) # ▁ Checking ▁ export ENDCOM NEW_LINE DEDENT DEDENT def test01i_json ( self ) : NEW_LINE INDENT " Testing ▁ GeoJSON ▁ input / output ▁ ( via ▁ GDAL ) . " NEW_LINE if not gdal or not gdal . GEOJSON : return NEW_LINE for g in self . geometries . json_geoms : NEW_LINE INDENT geom = GEOSGeometry ( g . wkt ) NEW_LINE if not hasattr ( g , ' not _ equal ' ) : NEW_LINE INDENT self . assertEqual ( g . json , geom . json ) NEW_LINE self . assertEqual ( g . json , geom . geojson ) NEW_LINE DEDENT self . assertEqual ( GEOSGeometry ( g . wkt ) , GEOSGeometry ( geom . json ) ) NEW_LINE DEDENT DEDENT def test01k_fromfile ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ fromfile ( ) ▁ factory . " NEW_LINE from StringIO import StringIO NEW_LINE ref_pnt = GEOSGeometry ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE wkt_f = StringIO ( ) NEW_LINE wkt_f . write ( ref_pnt . wkt ) NEW_LINE wkb_f = StringIO ( ) NEW_LINE wkb_f . write ( str ( ref_pnt . wkb ) ) NEW_LINE # ▁ Other ▁ tests ▁ use ▁ ` fromfile ( ) ` ▁ on ▁ string ▁ filenames ▁ so ▁ those ENDCOM # ▁ aren ' t ▁ tested ▁ here . ENDCOM for fh in ( wkt_f , wkb_f ) : NEW_LINE INDENT fh . seek ( 0 ) NEW_LINE pnt = fromfile ( fh ) NEW_LINE self . assertEqual ( ref_pnt , pnt ) NEW_LINE DEDENT DEDENT def test01k_eq ( self ) : NEW_LINE INDENT " Testing ▁ equivalence . " NEW_LINE p = fromstr ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE self . assertEqual ( p , p . wkt ) NEW_LINE self . assertNotEqual ( p , ' foo ' ) NEW_LINE ls = fromstr ( ' LINESTRING ( 0 ▁ 0 , ▁ 1 ▁ 1 , ▁ 5 ▁ 5 ) ' ) NEW_LINE self . assertEqual ( ls , ls . wkt ) NEW_LINE self . assertNotEqual ( p , ' bar ' ) NEW_LINE # ▁ Error ▁ shouldn ' t ▁ be ▁ raise ▁ on ▁ equivalence ▁ testing ▁ with ENDCOM # ▁ an ▁ invalid ▁ type . ENDCOM for g in ( p , ls ) : NEW_LINE INDENT self . assertNotEqual ( g , None ) NEW_LINE self . assertNotEqual ( g , { ' foo ' : ' bar ' } ) NEW_LINE self . assertNotEqual ( g , False ) NEW_LINE DEDENT DEDENT def test02a_points ( self ) : NEW_LINE INDENT " Testing ▁ Point ▁ objects . " NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for p in self . geometries . points : NEW_LINE # ▁ Creating ▁ the ▁ point ▁ from ▁ the ▁ WKT ENDCOM INDENT pnt = fromstr ( p . wkt ) NEW_LINE self . assertEqual ( pnt . geom_type , ' Point ' ) NEW_LINE self . assertEqual ( pnt . geom_typeid , 0 ) NEW_LINE self . assertEqual ( p . x , pnt . x ) NEW_LINE self . assertEqual ( p . y , pnt . y ) NEW_LINE self . assertEqual ( True , pnt == fromstr ( p . wkt ) ) NEW_LINE self . assertEqual ( False , pnt == prev ) NEW_LINE # ▁ Making ▁ sure ▁ that ▁ the ▁ point ' s ▁ X , ▁ Y ▁ components ▁ are ▁ what ▁ we ▁ expect ENDCOM self . assertAlmostEqual ( p . x , pnt . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( p . y , pnt . tuple [ 1 ] , 9 ) NEW_LINE # ▁ Testing ▁ the ▁ third ▁ dimension , ▁ and ▁ getting ▁ the ▁ tuple ▁ arguments ENDCOM if hasattr ( p , ' z ' ) : NEW_LINE INDENT self . assertEqual ( True , pnt . hasz ) NEW_LINE self . assertEqual ( p . z , pnt . z ) NEW_LINE self . assertEqual ( p . z , pnt . tuple [ 2 ] , 9 ) NEW_LINE tup_args = ( p . x , p . y , p . z ) NEW_LINE set_tup1 = ( 2.71 , 3.14 , 5.23 ) NEW_LINE set_tup2 = ( 5.23 , 2.71 , 3.14 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( False , pnt . hasz ) NEW_LINE self . assertEqual ( None , pnt . z ) NEW_LINE tup_args = ( p . x , p . y ) NEW_LINE set_tup1 = ( 2.71 , 3.14 ) NEW_LINE set_tup2 = ( 3.14 , 2.71 ) NEW_LINE # ▁ Centroid ▁ operation ▁ on ▁ point ▁ should ▁ be ▁ point ▁ itself ENDCOM DEDENT self . assertEqual ( p . centroid , pnt . centroid . tuple ) NEW_LINE # ▁ Now ▁ testing ▁ the ▁ different ▁ constructors ENDCOM pnt2 = Point ( tup_args ) # ▁ e . g . , ▁ Point ( (1 , ▁ 2 ) ) ENDCOM NEW_LINE pnt3 = Point ( * tup_args ) # ▁ e . g . , ▁ Point ( 1 , ▁ 2 ) ENDCOM NEW_LINE self . assertEqual ( True , pnt == pnt2 ) NEW_LINE self . assertEqual ( True , pnt == pnt3 ) NEW_LINE # ▁ Now ▁ testing ▁ setting ▁ the ▁ x ▁ and ▁ y ENDCOM pnt . y = 3.14 NEW_LINE pnt . x = 2.71 NEW_LINE self . assertEqual ( 3.14 , pnt . y ) NEW_LINE self . assertEqual ( 2.71 , pnt . x ) NEW_LINE # ▁ Setting ▁ via ▁ the ▁ tuple / coords ▁ property ENDCOM pnt . tuple = set_tup1 NEW_LINE self . assertEqual ( set_tup1 , pnt . tuple ) NEW_LINE pnt . coords = set_tup2 NEW_LINE self . assertEqual ( set_tup2 , pnt . coords ) NEW_LINE prev = pnt # ▁ setting ▁ the ▁ previous ▁ geometry ENDCOM NEW_LINE DEDENT DEDENT def test02b_multipoints ( self ) : NEW_LINE INDENT " Testing ▁ MultiPoint ▁ objects . " NEW_LINE for mp in self . geometries . multipoints : NEW_LINE INDENT mpnt = fromstr ( mp . wkt ) NEW_LINE self . assertEqual ( mpnt . geom_type , ' MultiPoint ' ) NEW_LINE self . assertEqual ( mpnt . geom_typeid , 4 ) NEW_LINE self . assertAlmostEqual ( mp . centroid [ 0 ] , mpnt . centroid . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( mp . centroid [ 1 ] , mpnt . centroid . tuple [ 1 ] , 9 ) NEW_LINE self . assertRaises ( GEOSIndexError , mpnt . __getitem__ , len ( mpnt ) ) NEW_LINE self . assertEqual ( mp . centroid , mpnt . centroid . tuple ) NEW_LINE self . assertEqual ( mp . coords , tuple ( m . tuple for m in mpnt ) ) NEW_LINE for p in mpnt : NEW_LINE INDENT self . assertEqual ( p . geom_type , ' Point ' ) NEW_LINE self . assertEqual ( p . geom_typeid , 0 ) NEW_LINE self . assertEqual ( p . empty , False ) NEW_LINE self . assertEqual ( p . valid , True ) NEW_LINE DEDENT DEDENT DEDENT def test03a_linestring ( self ) : NEW_LINE INDENT " Testing ▁ LineString ▁ objects . " NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for l in self . geometries . linestrings : NEW_LINE INDENT ls = fromstr ( l . wkt ) NEW_LINE self . assertEqual ( ls . geom_type , ' LineString ' ) NEW_LINE self . assertEqual ( ls . geom_typeid , 1 ) NEW_LINE self . assertEqual ( ls . empty , False ) NEW_LINE self . assertEqual ( ls . ring , False ) NEW_LINE if hasattr ( l , ' centroid ' ) : NEW_LINE INDENT self . assertEqual ( l . centroid , ls . centroid . tuple ) NEW_LINE DEDENT if hasattr ( l , ' tup ' ) : NEW_LINE INDENT self . assertEqual ( l . tup , ls . tuple ) NEW_LINE DEDENT self . assertEqual ( True , ls == fromstr ( l . wkt ) ) NEW_LINE self . assertEqual ( False , ls == prev ) NEW_LINE self . assertRaises ( GEOSIndexError , ls . __getitem__ , len ( ls ) ) NEW_LINE prev = ls NEW_LINE # ▁ Creating ▁ a ▁ LineString ▁ from ▁ a ▁ tuple , ▁ list , ▁ and ▁ numpy ▁ array ENDCOM self . assertEqual ( ls , LineString ( ls . tuple ) ) # ▁ tuple ENDCOM NEW_LINE self . assertEqual ( ls , LineString ( * ls . tuple ) ) # ▁ as ▁ individual ▁ arguments ENDCOM NEW_LINE self . assertEqual ( ls , LineString ( [ list ( tup ) for tup in ls . tuple ] ) ) # ▁ as ▁ list ENDCOM NEW_LINE self . assertEqual ( ls . wkt , LineString ( * tuple ( Point ( tup ) for tup in ls . tuple ) ) . wkt ) # ▁ Point ▁ individual ▁ arguments ENDCOM NEW_LINE if numpy : self . assertEqual ( ls , LineString ( numpy . array ( ls . tuple ) ) ) # ▁ as ▁ numpy ▁ array ENDCOM NEW_LINE DEDENT DEDENT def test03b_multilinestring ( self ) : NEW_LINE INDENT " Testing ▁ MultiLineString ▁ objects . " NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for l in self . geometries . multilinestrings : NEW_LINE INDENT ml = fromstr ( l . wkt ) NEW_LINE self . assertEqual ( ml . geom_type , ' MultiLineString ' ) NEW_LINE self . assertEqual ( ml . geom_typeid , 5 ) NEW_LINE self . assertAlmostEqual ( l . centroid [ 0 ] , ml . centroid . x , 9 ) NEW_LINE self . assertAlmostEqual ( l . centroid [ 1 ] , ml . centroid . y , 9 ) NEW_LINE self . assertEqual ( True , ml == fromstr ( l . wkt ) ) NEW_LINE self . assertEqual ( False , ml == prev ) NEW_LINE prev = ml NEW_LINE for ls in ml : NEW_LINE INDENT self . assertEqual ( ls . geom_type , ' LineString ' ) NEW_LINE self . assertEqual ( ls . geom_typeid , 1 ) NEW_LINE self . assertEqual ( ls . empty , False ) NEW_LINE DEDENT self . assertRaises ( GEOSIndexError , ml . __getitem__ , len ( ml ) ) NEW_LINE self . assertEqual ( ml . wkt , MultiLineString ( * tuple ( s . clone ( ) for s in ml ) ) . wkt ) NEW_LINE self . assertEqual ( ml , MultiLineString ( * tuple ( LineString ( s . tuple ) for s in ml ) ) ) NEW_LINE DEDENT DEDENT def test04_linearring ( self ) : NEW_LINE INDENT " Testing ▁ LinearRing ▁ objects . " NEW_LINE for rr in self . geometries . linearrings : NEW_LINE INDENT lr = fromstr ( rr . wkt ) NEW_LINE self . assertEqual ( lr . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( lr . geom_typeid , 2 ) NEW_LINE self . assertEqual ( rr . n_p , len ( lr ) ) NEW_LINE self . assertEqual ( True , lr . valid ) NEW_LINE self . assertEqual ( False , lr . empty ) NEW_LINE # ▁ Creating ▁ a ▁ LinearRing ▁ from ▁ a ▁ tuple , ▁ list , ▁ and ▁ numpy ▁ array ENDCOM self . assertEqual ( lr , LinearRing ( lr . tuple ) ) NEW_LINE self . assertEqual ( lr , LinearRing ( * lr . tuple ) ) NEW_LINE self . assertEqual ( lr , LinearRing ( [ list ( tup ) for tup in lr . tuple ] ) ) NEW_LINE if numpy : self . assertEqual ( lr , LinearRing ( numpy . array ( lr . tuple ) ) ) NEW_LINE DEDENT DEDENT def test05a_polygons ( self ) : NEW_LINE INDENT " Testing ▁ Polygon ▁ objects . " NEW_LINE # ▁ Testing ▁ ` from _ bbox ` ▁ class ▁ method ENDCOM bbox = ( - 180 , - 90 , 180 , 90 ) NEW_LINE p = Polygon . from_bbox ( bbox ) NEW_LINE self . assertEqual ( bbox , p . extent ) NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for p in self . geometries . polygons : NEW_LINE # ▁ Creating ▁ the ▁ Polygon , ▁ testing ▁ its ▁ properties . ENDCOM INDENT poly = fromstr ( p . wkt ) NEW_LINE self . assertEqual ( poly . geom_type , ' Polygon ' ) NEW_LINE self . assertEqual ( poly . geom_typeid , 3 ) NEW_LINE self . assertEqual ( poly . empty , False ) NEW_LINE self . assertEqual ( poly . ring , False ) NEW_LINE self . assertEqual ( p . n_i , poly . num_interior_rings ) NEW_LINE self . assertEqual ( p . n_i + 1 , len ( poly ) ) # ▁ Testing ▁ _ _ len _ _ ENDCOM NEW_LINE self . assertEqual ( p . n_p , poly . num_points ) NEW_LINE # ▁ Area ▁ & ▁ Centroid ENDCOM self . assertAlmostEqual ( p . area , poly . area , 9 ) NEW_LINE self . assertAlmostEqual ( p . centroid [ 0 ] , poly . centroid . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( p . centroid [ 1 ] , poly . centroid . tuple [ 1 ] , 9 ) NEW_LINE # ▁ Testing ▁ the ▁ geometry ▁ equivalence ENDCOM self . assertEqual ( True , poly == fromstr ( p . wkt ) ) NEW_LINE self . assertEqual ( False , poly == prev ) # ▁ Should ▁ not ▁ be ▁ equal ▁ to ▁ previous ▁ geometry ENDCOM NEW_LINE self . assertEqual ( True , poly != prev ) NEW_LINE # ▁ Testing ▁ the ▁ exterior ▁ ring ENDCOM ring = poly . exterior_ring NEW_LINE self . assertEqual ( ring . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( ring . geom_typeid , 2 ) NEW_LINE if p . ext_ring_cs : NEW_LINE INDENT self . assertEqual ( p . ext_ring_cs , ring . tuple ) NEW_LINE self . assertEqual ( p . ext_ring_cs , poly [ 0 ] . tuple ) # ▁ Testing ▁ _ _ getitem _ _ ENDCOM NEW_LINE # ▁ Testing ▁ _ _ getitem _ _ ▁ and ▁ _ _ setitem _ _ ▁ on ▁ invalid ▁ indices ENDCOM DEDENT self . assertRaises ( GEOSIndexError , poly . __getitem__ , len ( poly ) ) NEW_LINE self . assertRaises ( GEOSIndexError , poly . __setitem__ , len ( poly ) , False ) NEW_LINE self . assertRaises ( GEOSIndexError , poly . __getitem__ , - 1 * len ( poly ) - 1 ) NEW_LINE # ▁ Testing ▁ _ _ iter _ _ ENDCOM for r in poly : NEW_LINE INDENT self . assertEqual ( r . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( r . geom_typeid , 2 ) NEW_LINE # ▁ Testing ▁ polygon ▁ construction . ENDCOM DEDENT self . assertRaises ( TypeError , Polygon . __init__ , 0 , [ 1 , 2 , 3 ] ) NEW_LINE self . assertRaises ( TypeError , Polygon . __init__ , ' foo ' ) NEW_LINE # ▁ Polygon ( shell , ▁ ( hole1 , ▁ . . . ▁ holeN ) ) ENDCOM rings = tuple ( r for r in poly ) NEW_LINE self . assertEqual ( poly , Polygon ( rings [ 0 ] , rings [ 1 : ] ) ) NEW_LINE # ▁ Polygon ( shell _ tuple , ▁ hole _ tuple1 , ▁ . . . ▁ , ▁ hole _ tupleN ) ENDCOM ring_tuples = tuple ( r . tuple for r in poly ) NEW_LINE self . assertEqual ( poly , Polygon ( * ring_tuples ) ) NEW_LINE # ▁ Constructing ▁ with ▁ tuples ▁ of ▁ LinearRings . ENDCOM self . assertEqual ( poly . wkt , Polygon ( * tuple ( r for r in poly ) ) . wkt ) NEW_LINE self . assertEqual ( poly . wkt , Polygon ( * tuple ( LinearRing ( r . tuple ) for r in poly ) ) . wkt ) NEW_LINE DEDENT DEDENT def test05b_multipolygons ( self ) : NEW_LINE INDENT " Testing ▁ MultiPolygon ▁ objects . " NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE prev = fromstr ( ' POINT ▁ ( 0 ▁ 0 ) ' ) NEW_LINE for mp in self . geometries . multipolygons : NEW_LINE INDENT mpoly = fromstr ( mp . wkt ) NEW_LINE self . assertEqual ( mpoly . geom_type , ' MultiPolygon ' ) NEW_LINE self . assertEqual ( mpoly . geom_typeid , 6 ) NEW_LINE self . assertEqual ( mp . valid , mpoly . valid ) NEW_LINE if mp . valid : NEW_LINE INDENT self . assertEqual ( mp . num_geom , mpoly . num_geom ) NEW_LINE self . assertEqual ( mp . n_p , mpoly . num_coords ) NEW_LINE self . assertEqual ( mp . num_geom , len ( mpoly ) ) NEW_LINE self . assertRaises ( GEOSIndexError , mpoly . __getitem__ , len ( mpoly ) ) NEW_LINE for p in mpoly : NEW_LINE INDENT self . assertEqual ( p . geom_type , ' Polygon ' ) NEW_LINE self . assertEqual ( p . geom_typeid , 3 ) NEW_LINE self . assertEqual ( p . valid , True ) NEW_LINE DEDENT self . assertEqual ( mpoly . wkt , MultiPolygon ( * tuple ( poly . clone ( ) for poly in mpoly ) ) . wkt ) NEW_LINE DEDENT DEDENT print " \n END ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE DEDENT def test06a_memory_hijinks ( self ) : NEW_LINE INDENT " Testing ▁ Geometry ▁ _ _ del _ _ ( ) ▁ on ▁ rings ▁ and ▁ polygons . " NEW_LINE # # # # ▁ Memory ▁ issues ▁ with ▁ rings ▁ and ▁ polygons ENDCOM # ▁ These ▁ tests ▁ are ▁ needed ▁ to ▁ ensure ▁ sanity ▁ with ▁ writable ▁ geometries . ENDCOM # ▁ Getting ▁ a ▁ polygon ▁ with ▁ interior ▁ rings , ▁ and ▁ pulling ▁ out ▁ the ▁ interior ▁ rings ENDCOM poly = fromstr ( self . geometries . polygons [ 1 ] . wkt ) NEW_LINE ring1 = poly [ 0 ] NEW_LINE ring2 = poly [ 1 ] NEW_LINE # ▁ These ▁ deletes ▁ should ▁ be ▁ ' harmless ' ▁ since ▁ they ▁ are ▁ done ▁ on ▁ child ▁ geometries ENDCOM del ring1 NEW_LINE del ring2 NEW_LINE ring1 = poly [ 0 ] NEW_LINE ring2 = poly [ 1 ] NEW_LINE # ▁ Deleting ▁ the ▁ polygon ENDCOM del poly NEW_LINE # ▁ Access ▁ to ▁ these ▁ rings ▁ is ▁ OK ▁ since ▁ they ▁ are ▁ clones . ENDCOM s1 , s2 = str ( ring1 ) , str ( ring2 ) NEW_LINE DEDENT def test08_coord_seq ( self ) : NEW_LINE INDENT " Testing ▁ Coordinate ▁ Sequence ▁ objects . " NEW_LINE for p in self . geometries . polygons : NEW_LINE INDENT if p . ext_ring_cs : NEW_LINE # ▁ Constructing ▁ the ▁ polygon ▁ and ▁ getting ▁ the ▁ coordinate ▁ sequence ENDCOM INDENT poly = fromstr ( p . wkt ) NEW_LINE cs = poly . exterior_ring . coord_seq NEW_LINE self . assertEqual ( p . ext_ring_cs , cs . tuple ) # ▁ done ▁ in ▁ the ▁ Polygon ▁ test ▁ too . ENDCOM NEW_LINE self . assertEqual ( len ( p . ext_ring_cs ) , len ( cs ) ) # ▁ Making ▁ sure ▁ _ _ len _ _ ▁ works ENDCOM NEW_LINE # ▁ Checks ▁ _ _ getitem _ _ ▁ and ▁ _ _ setitem _ _ ENDCOM for i in xrange ( len ( p . ext_ring_cs ) ) : NEW_LINE INDENT c1 = p . ext_ring_cs [ i ] # ▁ Expected ▁ value ENDCOM NEW_LINE c2 = cs [ i ] # ▁ Value ▁ from ▁ coordseq ENDCOM NEW_LINE self . assertEqual ( c1 , c2 ) NEW_LINE # ▁ Constructing ▁ the ▁ test ▁ value ▁ to ▁ set ▁ the ▁ coordinate ▁ sequence ▁ with ENDCOM if len ( c1 ) == 2 : tset = ( 5 , 23 ) NEW_LINE else : tset = ( 5 , 23 , 8 ) NEW_LINE cs [ i ] = tset NEW_LINE # ▁ Making ▁ sure ▁ every ▁ set ▁ point ▁ matches ▁ what ▁ we ▁ expect ENDCOM for j in range ( len ( tset ) ) : NEW_LINE INDENT cs [ i ] = tset NEW_LINE self . assertEqual ( tset [ j ] , cs [ i ] [ j ] ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def test09_relate_pattern ( self ) : NEW_LINE INDENT " Testing ▁ relate ( ) ▁ and ▁ relate _ pattern ( ) . " NEW_LINE g = fromstr ( ' POINT ▁ ( 0 ▁ 0 ) ' ) NEW_LINE self . assertRaises ( GEOSException , g . relate_pattern , 0 , ' invalid ▁ pattern , ▁ yo ' ) NEW_LINE for rg in self . geometries . relate_geoms : NEW_LINE INDENT a = fromstr ( rg . wkt_a ) NEW_LINE b = fromstr ( rg . wkt_b ) NEW_LINE self . assertEqual ( rg . result , a . relate_pattern ( b , rg . pattern ) ) NEW_LINE self . assertEqual ( rg . pattern , a . relate ( b ) ) NEW_LINE DEDENT DEDENT def test10_intersection ( self ) : NEW_LINE INDENT " Testing ▁ intersects ( ) ▁ and ▁ intersection ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE i1 = fromstr ( self . geometries . intersect_geoms [ i ] . wkt ) NEW_LINE self . assertEqual ( True , a . intersects ( b ) ) NEW_LINE i2 = a . intersection ( b ) NEW_LINE self . assertEqual ( i1 , i2 ) NEW_LINE self . assertEqual ( i1 , a & b ) # ▁ _ _ and _ _ ▁ is ▁ intersection ▁ operator ENDCOM NEW_LINE a &= b # ▁ testing ▁ _ _ iand _ _ ENDCOM NEW_LINE self . assertEqual ( i1 , a ) NEW_LINE DEDENT DEDENT def test11_union ( self ) : NEW_LINE INDENT " Testing ▁ union ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE u1 = fromstr ( self . geometries . union_geoms [ i ] . wkt ) NEW_LINE u2 = a . union ( b ) NEW_LINE self . assertEqual ( u1 , u2 ) NEW_LINE self . assertEqual ( u1 , a | b ) # ▁ _ _ or _ _ ▁ is ▁ union ▁ operator ENDCOM NEW_LINE a |= b # ▁ testing ▁ _ _ ior _ _ ENDCOM NEW_LINE self . assertEqual ( u1 , a ) NEW_LINE DEDENT DEDENT def test12_difference ( self ) : NEW_LINE INDENT " Testing ▁ difference ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE d1 = fromstr ( self . geometries . diff_geoms [ i ] . wkt ) NEW_LINE d2 = a . difference ( b ) NEW_LINE self . assertEqual ( d1 , d2 ) NEW_LINE self . assertEqual ( d1 , a - b ) # ▁ _ _ sub _ _ ▁ is ▁ difference ▁ operator ENDCOM NEW_LINE a -= b # ▁ testing ▁ _ _ isub _ _ ENDCOM NEW_LINE self . assertEqual ( d1 , a ) NEW_LINE DEDENT DEDENT def test13_symdifference ( self ) : NEW_LINE INDENT " Testing ▁ sym _ difference ( ) . " NEW_LINE for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE d1 = fromstr ( self . geometries . sdiff_geoms [ i ] . wkt ) NEW_LINE d2 = a . sym_difference ( b ) NEW_LINE self . assertEqual ( d1 , d2 ) NEW_LINE self . assertEqual ( d1 , a ^ b ) # ▁ _ _ xor _ _ ▁ is ▁ symmetric ▁ difference ▁ operator ENDCOM NEW_LINE a ^= b # ▁ testing ▁ _ _ ixor _ _ ENDCOM NEW_LINE self . assertEqual ( d1 , a ) NEW_LINE DEDENT DEDENT def test14_buffer ( self ) : NEW_LINE INDENT " Testing ▁ buffer ( ) . " NEW_LINE for bg in self . geometries . buffer_geoms : NEW_LINE INDENT g = fromstr ( bg . wkt ) NEW_LINE # ▁ The ▁ buffer ▁ we ▁ expect ENDCOM exp_buf = fromstr ( bg . buffer_wkt ) NEW_LINE quadsegs = bg . quadsegs NEW_LINE width = bg . width NEW_LINE # ▁ Can ' t ▁ use ▁ a ▁ floating - point ▁ for ▁ the ▁ number ▁ of ▁ quadsegs . ENDCOM self . assertRaises ( ctypes . ArgumentError , g . buffer , width , float ( quadsegs ) ) NEW_LINE # ▁ Constructing ▁ our ▁ buffer ENDCOM buf = g . buffer ( width , quadsegs ) NEW_LINE self . assertEqual ( exp_buf . num_coords , buf . num_coords ) NEW_LINE self . assertEqual ( len ( exp_buf ) , len ( buf ) ) NEW_LINE # ▁ Now ▁ assuring ▁ that ▁ each ▁ point ▁ in ▁ the ▁ buffer ▁ is ▁ almost ▁ equal ENDCOM for j in xrange ( len ( exp_buf ) ) : NEW_LINE INDENT exp_ring = exp_buf [ j ] NEW_LINE buf_ring = buf [ j ] NEW_LINE self . assertEqual ( len ( exp_ring ) , len ( buf_ring ) ) NEW_LINE for k in xrange ( len ( exp_ring ) ) : NEW_LINE # ▁ Asserting ▁ the ▁ X , ▁ Y ▁ of ▁ each ▁ point ▁ are ▁ almost ▁ equal ▁ ( due ▁ to ▁ floating ▁ point ▁ imprecision ) ENDCOM INDENT self . assertAlmostEqual ( exp_ring [ k ] [ 0 ] , buf_ring [ k ] [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( exp_ring [ k ] [ 1 ] , buf_ring [ k ] [ 1 ] , 9 ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def test15_srid ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ SRID ▁ property ▁ and ▁ keyword . " NEW_LINE # ▁ Testing ▁ SRID ▁ keyword ▁ on ▁ Point ENDCOM pnt = Point ( 5 , 23 , srid = 4326 ) NEW_LINE self . assertEqual ( 4326 , pnt . srid ) NEW_LINE pnt . srid = 3084 NEW_LINE self . assertEqual ( 3084 , pnt . srid ) NEW_LINE self . assertRaises ( ctypes . ArgumentError , pnt . set_srid , '4326' ) NEW_LINE # ▁ Testing ▁ SRID ▁ keyword ▁ on ▁ fromstr ( ) , ▁ and ▁ on ▁ Polygon ▁ rings . ENDCOM poly = fromstr ( self . geometries . polygons [ 1 ] . wkt , srid = 4269 ) NEW_LINE self . assertEqual ( 4269 , poly . srid ) NEW_LINE for ring in poly : self . assertEqual ( 4269 , ring . srid ) NEW_LINE poly . srid = 4326 NEW_LINE self . assertEqual ( 4326 , poly . shell . srid ) NEW_LINE # ▁ Testing ▁ SRID ▁ keyword ▁ on ▁ GeometryCollection ENDCOM gc = GeometryCollection ( Point ( 5 , 23 ) , LineString ( ( 0 , 0 ) , ( 1.5 , 1.5 ) , ( 3 , 3 ) ) , srid = 32021 ) NEW_LINE self . assertEqual ( 32021 , gc . srid ) NEW_LINE for i in range ( len ( gc ) ) : self . assertEqual ( 32021 , gc [ i ] . srid ) NEW_LINE # ▁ GEOS ▁ may ▁ get ▁ the ▁ SRID ▁ from ▁ HEXEWKB ENDCOM # ▁ ' POINT ( 5 ▁ 23 ) ' ▁ at ▁ SRID = 4326 ▁ in ▁ hex ▁ form ▁ - - ▁ obtained ▁ from ▁ PostGIS ENDCOM # ▁ using ▁ ` SELECT ▁ GeomFromText ( ' POINT ▁ ( 5 ▁ 23 ) ' , ▁ 4326 ) ; ` . ENDCOM hex = '0101000020E610000000000000000014400000000000003740' NEW_LINE p1 = fromstr ( hex ) NEW_LINE self . assertEqual ( 4326 , p1 . srid ) NEW_LINE # ▁ In ▁ GEOS ▁ 3.0.0rc1-4 ▁ when ▁ the ▁ EWKB ▁ and / or ▁ HEXEWKB ▁ is ▁ exported , ENDCOM # ▁ the ▁ SRID ▁ information ▁ is ▁ lost ▁ and ▁ set ▁ to ▁ - 1 ▁ - - ▁ this ▁ is ▁ not ▁ a ENDCOM # ▁ problem ▁ on ▁ the ▁ 3.0.0 ▁ version ▁ ( another ▁ reason ▁ to ▁ upgrade ) . ENDCOM exp_srid = self . null_srid NEW_LINE p2 = fromstr ( p1 . hex ) NEW_LINE self . assertEqual ( exp_srid , p2 . srid ) NEW_LINE p3 = fromstr ( p1 . hex , srid = - 1 ) # ▁ - 1 ▁ is ▁ intended . ENDCOM NEW_LINE self . assertEqual ( - 1 , p3 . srid ) NEW_LINE DEDENT def test16_mutable_geometries ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ mutability ▁ of ▁ Polygons ▁ and ▁ Geometry ▁ Collections . " NEW_LINE # # # ▁ Testing ▁ the ▁ mutability ▁ of ▁ Polygons ▁ # # # ENDCOM for p in self . geometries . polygons : NEW_LINE INDENT poly = fromstr ( p . wkt ) NEW_LINE # ▁ Should ▁ only ▁ be ▁ able ▁ to ▁ use ▁ _ _ setitem _ _ ▁ with ▁ LinearRing ▁ geometries . ENDCOM self . assertRaises ( TypeError , poly . __setitem__ , 0 , LineString ( ( 1 , 1 ) , ( 2 , 2 ) ) ) NEW_LINE # ▁ Constructing ▁ the ▁ new ▁ shell ▁ by ▁ adding ▁ 500 ▁ to ▁ every ▁ point ▁ in ▁ the ▁ old ▁ shell . ENDCOM shell_tup = poly . shell . tuple NEW_LINE new_coords = [ ] NEW_LINE for point in shell_tup : new_coords . append ( ( point [ 0 ] + 500. , point [ 1 ] + 500. ) ) NEW_LINE new_shell = LinearRing ( * tuple ( new_coords ) ) NEW_LINE # ▁ Assigning ▁ polygon ' s ▁ exterior ▁ ring ▁ w / the ▁ new ▁ shell ENDCOM poly . exterior_ring = new_shell NEW_LINE s = str ( new_shell ) # ▁ new ▁ shell ▁ is ▁ still ▁ accessible ENDCOM NEW_LINE self . assertEqual ( poly . exterior_ring , new_shell ) NEW_LINE self . assertEqual ( poly [ 0 ] , new_shell ) NEW_LINE # # # ▁ Testing ▁ the ▁ mutability ▁ of ▁ Geometry ▁ Collections ENDCOM DEDENT for tg in self . geometries . multipoints : NEW_LINE INDENT mp = fromstr ( tg . wkt ) NEW_LINE for i in range ( len ( mp ) ) : NEW_LINE # ▁ Creating ▁ a ▁ random ▁ point . ENDCOM INDENT pnt = mp [ i ] NEW_LINE new = Point ( random . randint ( 1 , 100 ) , random . randint ( 1 , 100 ) ) NEW_LINE # ▁ Testing ▁ the ▁ assignment ENDCOM mp [ i ] = new NEW_LINE s = str ( new ) # ▁ what ▁ was ▁ used ▁ for ▁ the ▁ assignment ▁ is ▁ still ▁ accessible ENDCOM NEW_LINE self . assertEqual ( mp [ i ] , new ) NEW_LINE self . assertEqual ( mp [ i ] . wkt , new . wkt ) NEW_LINE self . assertNotEqual ( pnt , mp [ i ] ) NEW_LINE # ▁ MultiPolygons ▁ involve ▁ much ▁ more ▁ memory ▁ management ▁ because ▁ each ENDCOM # ▁ Polygon ▁ w / in ▁ the ▁ collection ▁ has ▁ its ▁ own ▁ rings . ENDCOM DEDENT DEDENT for tg in self . geometries . multipolygons : NEW_LINE INDENT mpoly = fromstr ( tg . wkt ) NEW_LINE for i in xrange ( len ( mpoly ) ) : NEW_LINE INDENT poly = mpoly [ i ] NEW_LINE old_poly = mpoly [ i ] NEW_LINE # ▁ Offsetting ▁ the ▁ each ▁ ring ▁ in ▁ the ▁ polygon ▁ by ▁ 500 . ENDCOM for j in xrange ( len ( poly ) ) : NEW_LINE INDENT r = poly [ j ] NEW_LINE for k in xrange ( len ( r ) ) : r [ k ] = ( r [ k ] [ 0 ] + 500. , r [ k ] [ 1 ] + 500. ) NEW_LINE poly [ j ] = r NEW_LINE DEDENT self . assertNotEqual ( mpoly [ i ] , poly ) NEW_LINE # ▁ Testing ▁ the ▁ assignment ENDCOM mpoly [ i ] = poly NEW_LINE s = str ( poly ) # ▁ Still ▁ accessible ENDCOM NEW_LINE self . assertEqual ( mpoly [ i ] , poly ) NEW_LINE self . assertNotEqual ( mpoly [ i ] , old_poly ) NEW_LINE # ▁ Extreme ▁ ( ! ! ) ▁ _ _ setitem _ _ ▁ - - ▁ no ▁ longer ▁ works , ▁ have ▁ to ▁ detect ENDCOM # ▁ in ▁ the ▁ first ▁ object ▁ that ▁ _ _ setitem _ _ ▁ is ▁ called ▁ in ▁ the ▁ subsequent ENDCOM # ▁ objects ▁ - - ▁ maybe ▁ mpoly [ 0 , ▁ 0 , ▁ 0 ] ▁ = ▁ ( 3.14 , ▁ 2.71 ) ? ENDCOM # mpoly [ 0 ] [ 0 ] [ 0 ] ▁ = ▁ ( 3.14 , ▁ 2.71 ) ENDCOM # self . assertEqual ( (3.14 , ▁ 2.71 ) , ▁ mpoly [ 0 ] [ 0 ] [ 0 ] ) ENDCOM # ▁ Doing ▁ it ▁ more ▁ slowly . . ENDCOM # self . assertEqual ( (3.14 , ▁ 2.71 ) , ▁ mpoly [ 0 ] . shell [ 0 ] ) ENDCOM # del ▁ mpoly ENDCOM DEDENT DEDENT DEDENT def test17_threed ( self ) : NEW_LINE INDENT " Testing ▁ three - dimensional ▁ geometries . " NEW_LINE # ▁ Testing ▁ a ▁ 3D ▁ Point ENDCOM pnt = Point ( 2 , 3 , 8 ) NEW_LINE self . assertEqual ( ( 2. , 3. , 8. ) , pnt . coords ) NEW_LINE self . assertRaises ( TypeError , pnt . set_coords , ( 1. , 2. ) ) NEW_LINE pnt . coords = ( 1. , 2. , 3. ) NEW_LINE self . assertEqual ( ( 1. , 2. , 3. ) , pnt . coords ) NEW_LINE # ▁ Testing ▁ a ▁ 3D ▁ LineString ENDCOM ls = LineString ( ( 2. , 3. , 8. ) , ( 50. , 250. , - 117. ) ) NEW_LINE self . assertEqual ( ( ( 2. , 3. , 8. ) , ( 50. , 250. , - 117. ) ) , ls . tuple ) NEW_LINE self . assertRaises ( TypeError , ls . __setitem__ , 0 , ( 1. , 2. ) ) NEW_LINE ls [ 0 ] = ( 1. , 2. , 3. ) NEW_LINE self . assertEqual ( ( 1. , 2. , 3. ) , ls [ 0 ] ) NEW_LINE DEDENT def test18_distance ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ distance ( ) ▁ function . " NEW_LINE # ▁ Distance ▁ to ▁ self ▁ should ▁ be ▁ 0 . ENDCOM pnt = Point ( 0 , 0 ) NEW_LINE self . assertEqual ( 0.0 , pnt . distance ( Point ( 0 , 0 ) ) ) NEW_LINE # ▁ Distance ▁ should ▁ be ▁ 1 ENDCOM self . assertEqual ( 1.0 , pnt . distance ( Point ( 0 , 1 ) ) ) NEW_LINE # ▁ Distance ▁ should ▁ be ▁ ~ ▁ sqrt ( 2 ) ENDCOM self . assertAlmostEqual ( 1.41421356237 , pnt . distance ( Point ( 1 , 1 ) ) , 11 ) NEW_LINE # ▁ Distances ▁ are ▁ from ▁ the ▁ closest ▁ vertex ▁ in ▁ each ▁ geometry ▁ - - ENDCOM # ▁ should ▁ be ▁ 3 ▁ ( distance ▁ from ▁ ( 2 , ▁ 2 ) ▁ to ▁ ( 5 , ▁ 2 ) ) . ENDCOM ls1 = LineString ( ( 0 , 0 ) , ( 1 , 1 ) , ( 2 , 2 ) ) NEW_LINE ls2 = LineString ( ( 5 , 2 ) , ( 6 , 1 ) , ( 7 , 0 ) ) NEW_LINE self . assertEqual ( 3 , ls1 . distance ( ls2 ) ) NEW_LINE DEDENT def test19_length ( self ) : NEW_LINE INDENT " Testing ▁ the ▁ length ▁ property . " NEW_LINE # ▁ Points ▁ have ▁ 0 ▁ length . ENDCOM pnt = Point ( 0 , 0 ) NEW_LINE self . assertEqual ( 0.0 , pnt . length ) NEW_LINE # ▁ Should ▁ be ▁ ~ ▁ sqrt ( 2 ) ENDCOM ls = LineString ( ( 0 , 0 ) , ( 1 , 1 ) ) NEW_LINE self . assertAlmostEqual ( 1.41421356237 , ls . length , 11 ) NEW_LINE # ▁ Should ▁ be ▁ circumfrence ▁ of ▁ Polygon ENDCOM poly = Polygon ( LinearRing ( ( 0 , 0 ) , ( 0 , 1 ) , ( 1 , 1 ) , ( 1 , 0 ) , ( 0 , 0 ) ) ) NEW_LINE self . assertEqual ( 4.0 , poly . length ) NEW_LINE # ▁ Should ▁ be ▁ sum ▁ of ▁ each ▁ element ' s ▁ length ▁ in ▁ collection . ENDCOM mpoly = MultiPolygon ( poly . clone ( ) , poly ) NEW_LINE self . assertEqual ( 8.0 , mpoly . length ) NEW_LINE DEDENT def test20a_emptyCollections ( self ) : NEW_LINE INDENT " Testing ▁ empty ▁ geometries ▁ and ▁ collections . " NEW_LINE gc1 = GeometryCollection ( [ ] ) NEW_LINE gc2 = fromstr ( ' GEOMETRYCOLLECTION ▁ EMPTY ' ) NEW_LINE pnt = fromstr ( ' POINT ▁ EMPTY ' ) NEW_LINE ls = fromstr ( ' LINESTRING ▁ EMPTY ' ) NEW_LINE poly = fromstr ( ' POLYGON ▁ EMPTY ' ) NEW_LINE mls = fromstr ( ' MULTILINESTRING ▁ EMPTY ' ) NEW_LINE mpoly1 = fromstr ( ' MULTIPOLYGON ▁ EMPTY ' ) NEW_LINE mpoly2 = MultiPolygon ( ( ) ) NEW_LINE for g in [ gc1 , gc2 , pnt , ls , poly , mls , mpoly1 , mpoly2 ] : NEW_LINE INDENT self . assertEqual ( True , g . empty ) NEW_LINE # ▁ Testing ▁ len ( ) ▁ and ▁ num _ geom . ENDCOM if isinstance ( g , Polygon ) : NEW_LINE INDENT self . assertEqual ( 1 , len ( g ) ) # ▁ Has ▁ one ▁ empty ▁ linear ▁ ring ENDCOM NEW_LINE self . assertEqual ( 1 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g [ 0 ] ) ) NEW_LINE DEDENT elif isinstance ( g , ( Point , LineString ) ) : NEW_LINE INDENT self . assertEqual ( 1 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( 0 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g ) ) NEW_LINE # ▁ Testing ▁ _ _ getitem _ _ ▁ ( doesn ' t ▁ work ▁ on ▁ Point ▁ or ▁ Polygon ) ENDCOM DEDENT if isinstance ( g , Point ) : NEW_LINE INDENT self . assertRaises ( GEOSIndexError , g . get_x ) NEW_LINE DEDENT elif isinstance ( g , Polygon ) : NEW_LINE INDENT lr = g . shell NEW_LINE self . assertEqual ( ' LINEARRING ▁ EMPTY ' , lr . wkt ) NEW_LINE self . assertEqual ( 0 , len ( lr ) ) NEW_LINE self . assertEqual ( True , lr . empty ) NEW_LINE self . assertRaises ( GEOSIndexError , lr . __getitem__ , 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertRaises ( GEOSIndexError , g . __getitem__ , 0 ) NEW_LINE DEDENT DEDENT DEDENT def test20b_collections_of_collections ( self ) : NEW_LINE INDENT " Testing ▁ GeometryCollection ▁ handling ▁ of ▁ other ▁ collections . " NEW_LINE # ▁ Creating ▁ a ▁ GeometryCollection ▁ WKT ▁ string ▁ composed ▁ of ▁ other ENDCOM # ▁ collections ▁ and ▁ polygons . ENDCOM coll = [ mp . wkt for mp in self . geometries . multipolygons if mp . valid ] NEW_LINE coll . extend ( [ mls . wkt for mls in self . geometries . multilinestrings ] ) NEW_LINE coll . extend ( [ p . wkt for p in self . geometries . polygons ] ) NEW_LINE coll . extend ( [ mp . wkt for mp in self . geometries . multipoints ] ) NEW_LINE gc_wkt = ' GEOMETRYCOLLECTION ( % s ) ' % ' , ' . join ( coll ) NEW_LINE # ▁ Should ▁ construct ▁ ok ▁ from ▁ WKT ENDCOM gc1 = GEOSGeometry ( gc_wkt ) NEW_LINE # ▁ Should ▁ also ▁ construct ▁ ok ▁ from ▁ individual ▁ geometry ▁ arguments . ENDCOM gc2 = GeometryCollection ( * tuple ( g for g in gc1 ) ) NEW_LINE # ▁ And , ▁ they ▁ should ▁ be ▁ equal . ENDCOM self . assertEqual ( gc1 , gc2 ) NEW_LINE DEDENT def test21_test_gdal ( self ) : NEW_LINE INDENT " Testing ▁ ` ogr ` ▁ and ▁ ` srs ` ▁ properties . " NEW_LINE if not gdal . HAS_GDAL : return NEW_LINE g1 = fromstr ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE self . assertEqual ( True , isinstance ( g1 . ogr , gdal . OGRGeometry ) ) NEW_LINE self . assertEqual ( g1 . srs , None ) NEW_LINE g2 = fromstr ( ' LINESTRING ( 0 ▁ 0 , ▁ 5 ▁ 5 , ▁ 23 ▁ 23 ) ' , srid = 4326 ) NEW_LINE self . assertEqual ( True , isinstance ( g2 . ogr , gdal . OGRGeometry ) ) NEW_LINE self . assertEqual ( True , isinstance ( g2 . srs , gdal . SpatialReference ) ) NEW_LINE self . assertEqual ( g2 . hex , g2 . ogr . hex ) NEW_LINE self . assertEqual ( ' WGS ▁ 84' , g2 . srs . name ) NEW_LINE DEDENT def test22_copy ( self ) : NEW_LINE INDENT " Testing ▁ use ▁ with ▁ the ▁ Python ▁ ` copy ` ▁ module . " NEW_LINE import django . utils . copycompat as copy NEW_LINE poly = GEOSGeometry ( ' POLYGON ( (0 ▁ 0 , ▁ 0 ▁ 23 , ▁ 23 ▁ 23 , ▁ 23 ▁ 0 , ▁ 0 ▁ 0 ) , ▁ ( 5 ▁ 5 , ▁ 5 ▁ 10 , ▁ 10 ▁ 10 , ▁ 10 ▁ 5 , ▁ 5 ▁ 5 ) ) ' ) NEW_LINE cpy1 = copy . copy ( poly ) NEW_LINE cpy2 = copy . deepcopy ( poly ) NEW_LINE self . assertNotEqual ( poly . _ptr , cpy1 . _ptr ) NEW_LINE self . assertNotEqual ( poly . _ptr , cpy2 . _ptr ) NEW_LINE DEDENT def test23_transform ( self ) : NEW_LINE INDENT " Testing ▁ ` transform ` ▁ method . " NEW_LINE if not gdal . HAS_GDAL : return NEW_LINE orig = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE trans = GEOSGeometry ( ' POINT ▁ ( 992385.4472045 ▁ 481455.4944650 ) ' , 2774 ) NEW_LINE # ▁ Using ▁ a ▁ srid , ▁ a ▁ SpatialReference ▁ object , ▁ and ▁ a ▁ CoordTransform ▁ object ENDCOM # ▁ for ▁ transformations . ENDCOM t1 , t2 , t3 = orig . clone ( ) , orig . clone ( ) , orig . clone ( ) NEW_LINE t1 . transform ( trans . srid ) NEW_LINE t2 . transform ( gdal . SpatialReference ( ' EPSG : 2774' ) ) NEW_LINE ct = gdal . CoordTransform ( gdal . SpatialReference ( ' WGS84' ) , gdal . SpatialReference ( 2774 ) ) NEW_LINE t3 . transform ( ct ) NEW_LINE # ▁ Testing ▁ use ▁ of ▁ the ▁ ` clone ` ▁ keyword . ENDCOM k1 = orig . clone ( ) NEW_LINE k2 = k1 . transform ( trans . srid , clone = True ) NEW_LINE self . assertEqual ( k1 , orig ) NEW_LINE self . assertNotEqual ( k1 , k2 ) NEW_LINE prec = 3 NEW_LINE for p in ( t1 , t2 , t3 , k2 ) : NEW_LINE INDENT self . assertAlmostEqual ( trans . x , p . x , prec ) NEW_LINE self . assertAlmostEqual ( trans . y , p . y , prec ) NEW_LINE DEDENT DEDENT def test23_transform_noop ( self ) : NEW_LINE INDENT """ ▁ Testing ▁ ` transform ` ▁ method ▁ ( SRID ▁ match ) ▁ """ NEW_LINE # ▁ transform ( ) ▁ should ▁ no - op ▁ if ▁ source ▁ & ▁ dest ▁ SRIDs ▁ match , ENDCOM # ▁ regardless ▁ of ▁ whether ▁ GDAL ▁ is ▁ available . ENDCOM if gdal . HAS_GDAL : NEW_LINE INDENT g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE gt = g . tuple NEW_LINE g . transform ( 4326 ) NEW_LINE self . assertEqual ( g . tuple , gt ) NEW_LINE self . assertEqual ( g . srid , 4326 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE g1 = g . transform ( 4326 , clone = True ) NEW_LINE self . assertEqual ( g1 . tuple , g . tuple ) NEW_LINE self . assertEqual ( g1 . srid , 4326 ) NEW_LINE self . assert_ ( g1 is not g , " Clone ▁ didn ' t ▁ happen " ) NEW_LINE DEDENT old_has_gdal = gdal . HAS_GDAL NEW_LINE try : NEW_LINE INDENT gdal . HAS_GDAL = False NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE gt = g . tuple NEW_LINE g . transform ( 4326 ) NEW_LINE self . assertEqual ( g . tuple , gt ) NEW_LINE self . assertEqual ( g . srid , 4326 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE g1 = g . transform ( 4326 , clone = True ) NEW_LINE self . assertEqual ( g1 . tuple , g . tuple ) NEW_LINE self . assertEqual ( g1 . srid , 4326 ) NEW_LINE self . assert_ ( g1 is not g , " Clone ▁ didn ' t ▁ happen " ) NEW_LINE DEDENT finally : NEW_LINE INDENT gdal . HAS_GDAL = old_has_gdal NEW_LINE DEDENT DEDENT def test23_transform_nosrid ( self ) : NEW_LINE INDENT """ ▁ Testing ▁ ` transform ` ▁ method ▁ ( no ▁ SRID ) ▁ """ NEW_LINE # ▁ raise ▁ a ▁ warning ▁ if ▁ SRID ▁ < 0 / None ENDCOM import warnings NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ Warnings ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE # ▁ test ▁ for ▁ do - nothing ▁ behaviour . ENDCOM try : NEW_LINE # ▁ Keeping ▁ line - noise ▁ down ▁ by ▁ only ▁ printing ▁ the ▁ relevant ENDCOM # ▁ warnings ▁ once . ENDCOM INDENT warnings . simplefilter ( ' once ' , UserWarning ) NEW_LINE warnings . simplefilter ( ' once ' , FutureWarning ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE g . transform ( 2774 ) NEW_LINE self . assertEqual ( g . tuple , ( - 104.609 , 38.255 ) ) NEW_LINE self . assertEqual ( g . srid , None ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE g1 = g . transform ( 2774 , clone = True ) NEW_LINE self . assert_ ( g1 is None ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE g . transform ( 2774 ) NEW_LINE self . assertEqual ( g . tuple , ( - 104.609 , 38.255 ) ) NEW_LINE self . assertEqual ( g . srid , - 1 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE g1 = g . transform ( 2774 , clone = True ) NEW_LINE self . assert_ ( g1 is None ) NEW_LINE DEDENT finally : NEW_LINE INDENT warnings . simplefilter ( ' default ' , UserWarning ) NEW_LINE warnings . simplefilter ( ' default ' , FutureWarning ) NEW_LINE DEDENT print " \n END ▁ - ▁ expecting ▁ Warnings ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE # ▁ test ▁ warning ▁ is ▁ raised ENDCOM try : NEW_LINE INDENT warnings . simplefilter ( ' error ' , FutureWarning ) NEW_LINE warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 , clone = True ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 , clone = True ) NEW_LINE DEDENT finally : NEW_LINE INDENT warnings . simplefilter ( ' default ' , FutureWarning ) NEW_LINE warnings . simplefilter ( ' default ' , UserWarning ) NEW_LINE DEDENT DEDENT def test23_transform_nogdal ( self ) : NEW_LINE INDENT """ ▁ Testing ▁ ` transform ` ▁ method ▁ ( GDAL ▁ not ▁ available ) ▁ """ NEW_LINE old_has_gdal = gdal . HAS_GDAL NEW_LINE try : NEW_LINE INDENT gdal . HAS_GDAL = False NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE self . assertRaises ( GEOSException , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE self . assertRaises ( GEOSException , g . transform , 2774 , clone = True ) NEW_LINE DEDENT finally : NEW_LINE INDENT gdal . HAS_GDAL = old_has_gdal NEW_LINE DEDENT DEDENT def test24_extent ( self ) : NEW_LINE INDENT " Testing ▁ ` extent ` ▁ method . " NEW_LINE # ▁ The ▁ xmin , ▁ ymin , ▁ xmax , ▁ ymax ▁ of ▁ the ▁ MultiPoint ▁ should ▁ be ▁ returned . ENDCOM mp = MultiPoint ( Point ( 5 , 23 ) , Point ( 0 , 0 ) , Point ( 10 , 50 ) ) NEW_LINE self . assertEqual ( ( 0.0 , 0.0 , 10.0 , 50.0 ) , mp . extent ) NEW_LINE pnt = Point ( 5.23 , 17.8 ) NEW_LINE # ▁ Extent ▁ of ▁ points ▁ is ▁ just ▁ the ▁ point ▁ itself ▁ repeated . ENDCOM self . assertEqual ( ( 5.23 , 17.8 , 5.23 , 17.8 ) , pnt . extent ) NEW_LINE # ▁ Testing ▁ on ▁ the ▁ ' real ▁ world ' ▁ Polygon . ENDCOM poly = fromstr ( self . geometries . polygons [ 3 ] . wkt ) NEW_LINE ring = poly . shell NEW_LINE x , y = ring . x , ring . y NEW_LINE xmin , ymin = min ( x ) , min ( y ) NEW_LINE xmax , ymax = max ( x ) , max ( y ) NEW_LINE self . assertEqual ( ( xmin , ymin , xmax , ymax ) , poly . extent ) NEW_LINE DEDENT def test25_pickle ( self ) : NEW_LINE INDENT " Testing ▁ pickling ▁ and ▁ unpickling ▁ support . " NEW_LINE # ▁ Using ▁ both ▁ pickle ▁ and ▁ cPickle ▁ - - ▁ just ▁ ' cause . ENDCOM import pickle , cPickle NEW_LINE # ▁ Creating ▁ a ▁ list ▁ of ▁ test ▁ geometries ▁ for ▁ pickling , ENDCOM # ▁ and ▁ setting ▁ the ▁ SRID ▁ on ▁ some ▁ of ▁ them . ENDCOM def get_geoms ( lst , srid = None ) : NEW_LINE INDENT return [ GEOSGeometry ( tg . wkt , srid ) for tg in lst ] NEW_LINE DEDENT tgeoms = get_geoms ( self . geometries . points ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . multilinestrings , 4326 ) ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . polygons , 3084 ) ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . multipolygons , 900913 ) ) NEW_LINE # ▁ The ▁ SRID ▁ won ' t ▁ be ▁ exported ▁ in ▁ GEOS ▁ 3.0 ▁ release ▁ candidates . ENDCOM no_srid = self . null_srid == - 1 NEW_LINE for geom in tgeoms : NEW_LINE INDENT s1 , s2 = cPickle . dumps ( geom ) , pickle . dumps ( geom ) NEW_LINE g1 , g2 = cPickle . loads ( s1 ) , pickle . loads ( s2 ) NEW_LINE for tmpg in ( g1 , g2 ) : NEW_LINE INDENT self . assertEqual ( geom , tmpg ) NEW_LINE if not no_srid : self . assertEqual ( geom . srid , tmpg . srid ) NEW_LINE DEDENT DEDENT DEDENT def test26_prepared ( self ) : NEW_LINE INDENT " Testing ▁ PreparedGeometry ▁ support . " NEW_LINE if not GEOS_PREPARE : return NEW_LINE # ▁ Creating ▁ a ▁ simple ▁ multipolygon ▁ and ▁ getting ▁ a ▁ prepared ▁ version . ENDCOM mpoly = GEOSGeometry ( ' MULTIPOLYGON ( ( ( 0 ▁ 0,0 ▁ 5,5 ▁ 5,5 ▁ 0,0 ▁ 0 ) ) , ( (5 ▁ 5,5 ▁ 10,10 ▁ 10,10 ▁ 5,5 ▁ 5 ) ) ) ' ) NEW_LINE prep = mpoly . prepared NEW_LINE # ▁ A ▁ set ▁ of ▁ test ▁ points . ENDCOM pnts = [ Point ( 5 , 5 ) , Point ( 7.5 , 7.5 ) , Point ( 2.5 , 7.5 ) ] NEW_LINE covers = [ True , True , False ] # ▁ No ▁ ` covers ` ▁ op ▁ for ▁ regular ▁ GEOS ▁ geoms . ENDCOM NEW_LINE for pnt , c in zip ( pnts , covers ) : NEW_LINE # ▁ Results ▁ should ▁ be ▁ the ▁ same ▁ ( but ▁ faster ) ENDCOM INDENT self . assertEqual ( mpoly . contains ( pnt ) , prep . contains ( pnt ) ) NEW_LINE self . assertEqual ( mpoly . intersects ( pnt ) , prep . intersects ( pnt ) ) NEW_LINE self . assertEqual ( c , prep . covers ( pnt ) ) NEW_LINE DEDENT DEDENT def test26_line_merge ( self ) : NEW_LINE INDENT " Testing ▁ line ▁ merge ▁ support " NEW_LINE ref_geoms = ( fromstr ( ' LINESTRING ( 1 ▁ 1 , ▁ 1 ▁ 1 , ▁ 3 ▁ 3 ) ' ) , fromstr ( ' MULTILINESTRING ( (1 ▁ 1 , ▁ 3 ▁ 3 ) , ▁ ( 3 ▁ 3 , ▁ 4 ▁ 2 ) ) ' ) , ) NEW_LINE ref_merged = ( fromstr ( ' LINESTRING ( 1 ▁ 1 , ▁ 3 ▁ 3 ) ' ) , fromstr ( ' LINESTRING ▁ ( 1 ▁ 1 , ▁ 3 ▁ 3 , ▁ 4 ▁ 2 ) ' ) , ) NEW_LINE for geom , merged in zip ( ref_geoms , ref_merged ) : NEW_LINE INDENT self . assertEqual ( merged , geom . merged ) NEW_LINE DEDENT DEDENT def test27_valid_reason ( self ) : NEW_LINE INDENT " Testing ▁ IsValidReason ▁ support " NEW_LINE # ▁ Skipping ▁ tests ▁ if ▁ GEOS ▁ < ▁ v3.1 . ENDCOM if not GEOS_PREPARE : return NEW_LINE g = GEOSGeometry ( " POINT ( 0 ▁ 0 ) " ) NEW_LINE self . assert_ ( g . valid ) NEW_LINE self . assert_ ( isinstance ( g . valid_reason , basestring ) ) NEW_LINE self . assertEqual ( g . valid_reason , " Valid ▁ Geometry " ) NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE g = GEOSGeometry ( " LINESTRING ( 0 ▁ 0 , ▁ 0 ▁ 0 ) " ) NEW_LINE self . assert_ ( not g . valid ) NEW_LINE self . assert_ ( isinstance ( g . valid_reason , basestring ) ) NEW_LINE self . assert_ ( g . valid_reason . startswith ( " Too ▁ few ▁ points ▁ in ▁ geometry ▁ component " ) ) NEW_LINE print " \n END ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE DEDENT DEDENT def suite ( ) : NEW_LINE INDENT s = unittest . TestSuite ( ) NEW_LINE s . addTest ( unittest . makeSuite ( GEOSTest ) ) NEW_LINE return s NEW_LINE DEDENT def run ( verbosity = 2 ) : NEW_LINE INDENT unittest . TextTestRunner ( verbosity = verbosity ) . run ( suite ( ) ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="dvliman/jaikuengine/tree/master/.google_appengine/lib/django-1.5/django/contrib/comments/views/moderation.py"> from __future__ import absolute_import NEW_LINE from django import template NEW_LINE from django . conf import settings NEW_LINE from django . contrib import comments NEW_LINE from django . contrib . auth . decorators import login_required , permission_required NEW_LINE from django . contrib . comments import signals NEW_LINE from django . contrib . comments . views . utils import next_redirect , confirmation_view NEW_LINE from django . shortcuts import get_object_or_404 , render_to_response NEW_LINE from django . views . decorators . csrf import csrf_protect NEW_LINE @ csrf_protect NEW_LINE @ login_required NEW_LINE def flag ( request , comment_id , next = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Flags ▁ a ▁ comment . ▁ Confirmation ▁ on ▁ GET , ▁ action ▁ on ▁ POST . STRNEWLINE STRNEWLINE ▁ Templates : ▁ : template : ` comments / flag . html ` , STRNEWLINE ▁ Context : STRNEWLINE ▁ comment STRNEWLINE ▁ the ▁ flagged ▁ ` comments . comment ` ▁ object STRNEWLINE ▁ """ NEW_LINE comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE # ▁ Flag ▁ on ▁ POST ENDCOM if request . method == ' POST ' : NEW_LINE INDENT perform_flag ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - flag - done ' , c = comment . pk ) NEW_LINE # ▁ Render ▁ a ▁ form ▁ on ▁ GET ENDCOM DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / flag . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT @ csrf_protect NEW_LINE @ permission_required ( " comments . can _ moderate " ) NEW_LINE def delete ( request , comment_id , next = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Deletes ▁ a ▁ comment . ▁ Confirmation ▁ on ▁ GET , ▁ action ▁ on ▁ POST . ▁ Requires ▁ the ▁ " can STRNEWLINE ▁ moderate ▁ comments " ▁ permission . STRNEWLINE STRNEWLINE ▁ Templates : ▁ : template : ` comments / delete . html ` , STRNEWLINE ▁ Context : STRNEWLINE ▁ comment STRNEWLINE ▁ the ▁ flagged ▁ ` comments . comment ` ▁ object STRNEWLINE ▁ """ NEW_LINE comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE # ▁ Delete ▁ on ▁ POST ENDCOM if request . method == ' POST ' : NEW_LINE # ▁ Flag ▁ the ▁ comment ▁ as ▁ deleted ▁ instead ▁ of ▁ actually ▁ deleting ▁ it . ENDCOM INDENT perform_delete ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - delete - done ' , c = comment . pk ) NEW_LINE # ▁ Render ▁ a ▁ form ▁ on ▁ GET ENDCOM DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / delete . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT @ csrf_protect NEW_LINE @ permission_required ( " comments . can _ moderate " ) NEW_LINE def approve ( request , comment_id , next = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Approve ▁ a ▁ comment ▁ ( that ▁ is , ▁ mark ▁ it ▁ as ▁ public ▁ and ▁ non - removed ) . ▁ Confirmation STRNEWLINE ▁ on ▁ GET , ▁ action ▁ on ▁ POST . ▁ Requires ▁ the ▁ " can ▁ moderate ▁ comments " ▁ permission . STRNEWLINE STRNEWLINE ▁ Templates : ▁ : template : ` comments / approve . html ` , STRNEWLINE ▁ Context : STRNEWLINE ▁ comment STRNEWLINE ▁ the ▁ ` comments . comment ` ▁ object ▁ for ▁ approval STRNEWLINE ▁ """ NEW_LINE comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE # ▁ Delete ▁ on ▁ POST ENDCOM if request . method == ' POST ' : NEW_LINE # ▁ Flag ▁ the ▁ comment ▁ as ▁ approved . ENDCOM INDENT perform_approve ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - approve - done ' , c = comment . pk ) NEW_LINE # ▁ Render ▁ a ▁ form ▁ on ▁ GET ENDCOM DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / approve . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE # ▁ The ▁ following ▁ functions ▁ actually ▁ perform ▁ the ▁ various ▁ flag / aprove / delete ENDCOM # ▁ actions . ▁ They ' ve ▁ been ▁ broken ▁ out ▁ into ▁ separate ▁ functions ▁ to ▁ that ▁ they ENDCOM # ▁ may ▁ be ▁ called ▁ from ▁ admin ▁ actions . ENDCOM DEDENT DEDENT def perform_flag ( request , comment ) : NEW_LINE INDENT """ STRNEWLINE ▁ Actually ▁ perform ▁ the ▁ flagging ▁ of ▁ a ▁ comment ▁ from ▁ a ▁ request . STRNEWLINE ▁ """ NEW_LINE flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . SUGGEST_REMOVAL ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT def perform_delete ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . MODERATOR_DELETION ) NEW_LINE comment . is_removed = True NEW_LINE comment . save ( ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT def perform_approve ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . MODERATOR_APPROVAL , ) NEW_LINE comment . is_removed = False NEW_LINE comment . is_public = True NEW_LINE comment . save ( ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE # ▁ Confirmation ▁ views . ENDCOM DEDENT flag_done = confirmation_view ( template = " comments / flagged . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ flagged " ▁ success ▁ page . ' ) NEW_LINE delete_done = confirmation_view ( template = " comments / deleted . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ deleted " ▁ success ▁ page . ' ) NEW_LINE approve_done = confirmation_view ( template = " comments / approved . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ approved " ▁ success ▁ page . ' ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="tacaswell/datamuxer/tree/master/datamuxer.py"> # ▁ Copyright ▁ ( c ) ▁ 2014 , ▁ Brookhaven ▁ Science ▁ Associates , ▁ Brookhaven ▁ # ENDCOM # ▁ National ▁ Laboratory . ▁ All ▁ rights ▁ reserved . ▁ # ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ▁ # ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ # ENDCOM # ▁ are ▁ met : ▁ # ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ▁ # ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ▁ # ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ▁ copyright ▁ # ENDCOM # ▁ notice ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ▁ in ▁ # ENDCOM # ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ▁ # ENDCOM # ▁ distribution . ▁ # ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ the ▁ Brookhaven ▁ Science ▁ Associates , ▁ Brookhaven ▁ # ENDCOM # ▁ National ▁ Laboratory ▁ nor ▁ the ▁ names ▁ of ▁ its ▁ contributors ▁ may ▁ be ▁ used ▁ # ENDCOM # ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ▁ this ▁ software ▁ without ▁ # ENDCOM # ▁ specific ▁ prior ▁ written ▁ permission . ▁ # ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ▁ # ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ▁ # ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ # ENDCOM # ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ # ENDCOM # ▁ COPYRIGHT ▁ HOLDER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ # ENDCOM # ▁ INDIRECT , ▁ INCIDENTAL , ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ # ENDCOM # ▁ ( INCLUDING , ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ # ENDCOM # ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ # ENDCOM # ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ # ENDCOM # ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OTHERWISE ) ▁ ARISING ▁ # ENDCOM # ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ▁ # ENDCOM # ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ▁ # ENDCOM from __future__ import ( absolute_import , division , print_function , unicode_literals ) NEW_LINE import six NEW_LINE from collections import namedtuple , deque NEW_LINE import logging NEW_LINE import pandas as pd NEW_LINE import tzlocal NEW_LINE import numpy as np NEW_LINE from scipy . interpolate import interp1d NEW_LINE import pandas . core . groupby # ▁ to ▁ get ▁ custom ▁ exception ENDCOM NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE __all__ = [ ' DataMuxer ' , ' dataframe _ to _ dict ' ] NEW_LINE TZ = str ( tzlocal . get_localzone ( ) ) NEW_LINE class BinningError ( Exception ) : NEW_LINE INDENT """ STRNEWLINE ▁ An ▁ exception ▁ to ▁ raise ▁ if ▁ there ▁ are ▁ insufficient ▁ sampling ▁ rules ▁ to STRNEWLINE ▁ upsampling ▁ or ▁ downsample ▁ a ▁ data ▁ column ▁ into ▁ specified ▁ bins . STRNEWLINE ▁ """ NEW_LINE pass NEW_LINE DEDENT class BadDownsamplerError ( Exception ) : NEW_LINE INDENT """ STRNEWLINE ▁ An ▁ exception ▁ to ▁ raise ▁ if ▁ a ▁ downsampler ▁ produces ▁ unexpected ▁ output . STRNEWLINE ▁ """ NEW_LINE pass NEW_LINE DEDENT class ColSpec ( namedtuple ( ' ColSpec ' , [ ' name ' , ' ndim ' , ' shape ' , ' upsample ' , ' downsample ' ] ) ) : NEW_LINE INDENT """ STRNEWLINE ▁ Named - tuple ▁ sub - class ▁ to ▁ validate ▁ the ▁ column ▁ specifications ▁ for ▁ the STRNEWLINE ▁ DataMuxer STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ name ▁ : ▁ hashable STRNEWLINE ▁ ndim ▁ : ▁ uint STRNEWLINE ▁ Dimensionality ▁ of ▁ the ▁ data ▁ stored ▁ in ▁ the ▁ column STRNEWLINE ▁ shape ▁ : ▁ tuple ▁ or ▁ None STRNEWLINE ▁ like ▁ ndarray . shape , ▁ where ▁ 0 ▁ or ▁ None ▁ are ▁ scalar STRNEWLINE ▁ upsample ▁ : ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , ▁ ' cubic ' , ▁ ' ffill ' , ▁ ' bfill ' } STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ The ▁ names ▁ refer ▁ to ▁ kinds ▁ of ▁ scipy . interpolator . ▁ See ▁ documentation STRNEWLINE ▁ link ▁ below . STRNEWLINE ▁ downsample ▁ : ▁ None ▁ or ▁ a ▁ function STRNEWLINE ▁ None ▁ if ▁ the ▁ data ▁ cannot ▁ be ▁ downsampled ▁ ( reduced ) . ▁ Otherwise , STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE # ▁ These ▁ reflect ▁ the ▁ ' method ' ▁ argument ▁ of ▁ pandas . DataFrame . fillna ENDCOM upsampling_methods = { ' None ' , ' linear ' , ' nearest ' , ' zero ' , ' slinear ' , ' quadratic ' , ' cubic ' , ' ffill ' , ' bfill ' } NEW_LINE downsampling_methods = { ' None ' , ' last ' , ' first ' , ' median ' , ' mean ' , ' sum ' , ' min ' , ' max ' } NEW_LINE _downsample_mapping = { ' last ' : lambda x : x [ - 1 ] , ' first ' : lambda x : x [ 0 ] , # ▁ new ▁ in ▁ np ▁ 1.9 ENDCOM ' median ' : lambda x : np . median ( x , 0 ) , ' mean ' : lambda x : np . mean ( x , 0 ) , ' sum ' : lambda x : np . sum ( x , 0 ) , ' min ' : lambda x : np . min ( x , 0 ) , ' max ' : lambda x : np . max ( x , 0 ) } NEW_LINE __slots__ = ( ) NEW_LINE def __new__ ( cls , name , ndim , shape , upsample , downsample ) : NEW_LINE # ▁ Validations ENDCOM INDENT upsample = _validate_upsample ( upsample ) NEW_LINE downsample = _validate_downsample ( downsample ) NEW_LINE if int ( ndim ) < 0 : NEW_LINE INDENT raise ValueError ( " ndim ▁ must ▁ be ▁ positive ▁ not ▁ { } " . format ( ndim ) ) NEW_LINE DEDENT if shape is not None : NEW_LINE INDENT shape = tuple ( shape ) NEW_LINE DEDENT return super ( ColSpec , cls ) . __new__ ( cls , name , int ( ndim ) , shape , upsample , downsample ) NEW_LINE DEDENT DEDENT def _validate_upsample ( input ) : NEW_LINE # ▁ TODO ▁ The ▁ upsampling ▁ method ▁ could ▁ be ▁ any ▁ callable . ENDCOM INDENT if input is None or input == ' None ' : NEW_LINE INDENT return ' None ' NEW_LINE DEDENT if not ( input in ColSpec . upsampling_methods ) : NEW_LINE INDENT raise ValueError ( " { } ▁ is ▁ not ▁ a ▁ valid ▁ upsampling ▁ method . ▁ It ▁ " " must ▁ be ▁ one ▁ of ▁ { } " . format ( input , ColSpec . upsampling_methods ) ) NEW_LINE DEDENT return input . lower ( ) NEW_LINE DEDENT def _validate_downsample ( input ) : NEW_LINE # ▁ TODO ▁ The ▁ downsampling ▁ methods ▁ could ▁ have ▁ string ▁ aliases ▁ like ▁ ' mean ' . ENDCOM INDENT if ( input is not None ) and ( not ( callable ( input ) or input in ColSpec . downsampling_methods ) ) : NEW_LINE INDENT raise ValueError ( " The ▁ downsampling ▁ method ▁ must ▁ be ▁ a ▁ callable , ▁ None , ▁ " " or ▁ one ▁ of ▁ { } . " . format ( ColSpec . downsampling_methods ) ) NEW_LINE DEDENT if input is None : NEW_LINE INDENT return ' None ' NEW_LINE DEDENT return input NEW_LINE DEDENT class DataMuxer ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ class ▁ provides ▁ a ▁ wrapper ▁ layer ▁ of ▁ signals ▁ and ▁ slots STRNEWLINE ▁ around ▁ a ▁ pandas ▁ DataFrame ▁ to ▁ make ▁ plugging ▁ stuff ▁ in ▁ for ▁ live STRNEWLINE ▁ view ▁ easier . STRNEWLINE STRNEWLINE ▁ The ▁ data ▁ collection / event ▁ model ▁ being ▁ used ▁ is ▁ all ▁ measurements STRNEWLINE ▁ ( that ▁ is ▁ values ▁ that ▁ come ▁ off ▁ of ▁ the ▁ hardware ) ▁ are ▁ time ▁ stamped STRNEWLINE ▁ to ▁ ring ▁ time . STRNEWLINE STRNEWLINE ▁ The ▁ language ▁ being ▁ used ▁ through ▁ out ▁ is ▁ that ▁ of ▁ pandas ▁ data ▁ frames . STRNEWLINE STRNEWLINE ▁ The ▁ data ▁ model ▁ is ▁ that ▁ of ▁ a ▁ sparse ▁ table ▁ keyed ▁ on ▁ time ▁ stamps ▁ which STRNEWLINE ▁ is ▁ ' densified ' ▁ on ▁ demand ▁ by ▁ propagating ▁ measurements ▁ forwards . ▁ Not STRNEWLINE ▁ all ▁ measurements ▁ ( ex ▁ images ) ▁ can ▁ be ▁ filled . ▁ This ▁ behavior ▁ is ▁ controlled STRNEWLINE ▁ by ▁ the ▁ ` col _ info ` ▁ tuple . STRNEWLINE STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ object ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE class Planner ( object ) : NEW_LINE INDENT def __init__ ( self , dm ) : NEW_LINE INDENT self . dm = dm NEW_LINE DEDENT def determine_upsample ( self , interpolation = None , use_cols = None ) : NEW_LINE INDENT " Resolve ▁ ( and ▁ if ▁ necessary ▁ validate ) ▁ upsampling ▁ rules . " NEW_LINE if interpolation is None : NEW_LINE INDENT interpolation = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_upsample ( interpolation . get ( name , col_info . upsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE if ( rule is not None ) and ( col_info . ndim > 0 ) : NEW_LINE INDENT raise NotImplementedError ( " Only ▁ scalar ▁ data ▁ can ▁ be ▁ upsampled . ▁ " " The ▁ { 0 } - dimensional ▁ source ▁ { 1 } ▁ was ▁ given ▁ the ▁ " " upsampling ▁ rule ▁ { 2 } . " . format ( col_info . ndim , name , rule ) ) NEW_LINE DEDENT rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT def determine_downsample ( self , agg = None , use_cols = None ) : NEW_LINE INDENT " Resolve ▁ ( and ▁ if ▁ necessary ▁ validate ) ▁ sampling ▁ rules . " NEW_LINE if agg is None : NEW_LINE INDENT agg = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_downsample ( agg . get ( name , col_info . downsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ Explain ▁ operation ▁ of ▁ DataMuxer . bin _ by _ edges STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ edges ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ two - element ▁ items ▁ like ▁ [ ( t1 , ▁ t2 ) , ▁ ( t3 , ▁ t4 ) , ▁ . . . ] STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be STRNEWLINE ▁ evaluated . ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' , ▁ ' ffill ' , ▁ ' bfill ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever STRNEWLINE ▁ dimension ) ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by STRNEWLINE ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ table ▁ giving ▁ upsample ▁ and ▁ downsample ▁ rules ▁ for ▁ each ▁ data ▁ column STRNEWLINE ▁ and ▁ indicating ▁ whether ▁ those ▁ rules ▁ are ▁ applicable STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE # ▁ TODO ▁ Cache ▁ the ▁ grouping ▁ for ▁ reuse ▁ by ▁ resample . ENDCOM grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ Explain ▁ operation ▁ of ▁ DataMuxer . bin _ on . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever STRNEWLINE ▁ dimension ) ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by STRNEWLINE ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ table ▁ giving ▁ upsample ▁ and ▁ downsample ▁ rules ▁ for ▁ each ▁ data ▁ column STRNEWLINE ▁ and ▁ indicating ▁ whether ▁ those ▁ rules ▁ are ▁ applicable STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE centers , bin_edges = self . dm . _bin_on ( source_name ) NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( centers , bin_edges ) NEW_LINE # ▁ TODO ▁ Cache ▁ the ▁ grouping ▁ for ▁ reuse ▁ by ▁ resample . ENDCOM grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT DEDENT default_upsample = None NEW_LINE default_downsample = None NEW_LINE def __init__ ( self ) : NEW_LINE INDENT self . sources = { } NEW_LINE self . col_info = { } NEW_LINE self . col_info [ ' time ' ] = ColSpec ( ' time ' , 0 , [ ] , ' linear ' , ' mean ' ) NEW_LINE self . _data = deque ( ) NEW_LINE self . _time = deque ( ) NEW_LINE self . _timestamps = deque ( ) NEW_LINE self . _timestamps_as_data = set ( ) NEW_LINE self . _known_events = set ( ) NEW_LINE self . _known_descriptors = set ( ) NEW_LINE self . _stale = True NEW_LINE self . plan = self . Planner ( self ) NEW_LINE self . convert_times = True NEW_LINE self . _reference_time = None NEW_LINE DEDENT @ property NEW_LINE def reference_time ( self ) : NEW_LINE INDENT return self . _reference_time NEW_LINE DEDENT @ reference_time . setter NEW_LINE def reference_time ( self , val ) : NEW_LINE INDENT self . _reference_time = pd . Timestamp ( val , unit = ' s ' ) NEW_LINE DEDENT @ property NEW_LINE def columns ( self ) : NEW_LINE INDENT " The ▁ columns ▁ of ▁ DataFrames ▁ returned ▁ by ▁ methods ▁ that ▁ return ▁ DataFrames . " NEW_LINE return set ( self . sources ) | self . _time_columns NEW_LINE DEDENT @ property NEW_LINE def _time_columns ( self ) : NEW_LINE INDENT ts_names = [ name + ' _ timestamp ' for name in self . _timestamps_as_data ] NEW_LINE return { ' time ' } | set ( ts_names ) NEW_LINE DEDENT @ classmethod NEW_LINE def from_events ( cls , events , verbose = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ a ▁ DataMuxer ▁ from ▁ a ▁ list ▁ of ▁ Events . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ objects ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE instance = cls ( ) NEW_LINE instance . append_events ( events , verbose ) NEW_LINE return instance NEW_LINE DEDENT def append_events ( self , events , verbose = False ) : NEW_LINE INDENT """ Add ▁ a ▁ list ▁ of ▁ events ▁ to ▁ the ▁ DataMuxer . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ objects ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE for idx , event in enumerate ( events ) : NEW_LINE INDENT if verbose and idx % 25 == 0 : NEW_LINE INDENT print ( ' loading ▁ event ▁ % s ' % idx ) , NEW_LINE DEDENT self . append_event ( event ) NEW_LINE DEDENT DEDENT def append_event ( self , event ) : NEW_LINE INDENT """ Add ▁ an ▁ event ▁ to ▁ the ▁ DataMuxer . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ event ▁ : ▁ Event STRNEWLINE ▁ Event ▁ Document ▁ or ▁ any ▁ object ▁ with ▁ the ▁ expected ▁ attributes STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ is _ new ▁ : ▁ bool STRNEWLINE ▁ True ▁ if ▁ event ▁ was ▁ added , ▁ False ▁ is ▁ it ▁ has ▁ already ▁ been ▁ added STRNEWLINE ▁ """ NEW_LINE if event . uid in self . _known_events : NEW_LINE INDENT return False NEW_LINE DEDENT self . _known_events . add ( event . uid ) NEW_LINE self . _stale = True NEW_LINE if event . descriptor . uid not in self . _known_descriptors : NEW_LINE INDENT self . _process_new_descriptor ( event . descriptor ) NEW_LINE # ▁ Both ▁ scalar ▁ and ▁ nonscalar ▁ data ▁ will ▁ get ▁ stored ▁ in ▁ the ▁ DataFrame . ENDCOM # ▁ This ▁ may ▁ be ▁ optimized ▁ later , ▁ but ▁ it ▁ might ▁ not ▁ actually ▁ help ▁ much . ENDCOM DEDENT self . _data . append ( { name : data for name , data in six . iteritems ( event . data ) } ) NEW_LINE self . _timestamps . append ( { name : ts for name , ts in six . iteritems ( event . timestamps ) } ) NEW_LINE self . _time . append ( event . time ) NEW_LINE return True NEW_LINE DEDENT def _process_new_descriptor ( self , descriptor ) : NEW_LINE INDENT " Build ▁ a ▁ ColSpec ▁ and ▁ update ▁ state . " NEW_LINE for name , description in six . iteritems ( descriptor . data_keys ) : NEW_LINE # ▁ If ▁ we ▁ already ▁ have ▁ this ▁ source ▁ name , ▁ the ▁ unique ▁ source ENDCOM # ▁ identifiers ▁ must ▁ match . ▁ Ambiguous ▁ names ▁ are ▁ not ▁ allowed . ENDCOM INDENT if name in self . sources : NEW_LINE INDENT if self . sources [ name ] != description [ ' source ' ] : NEW_LINE INDENT raise ValueError ( " In ▁ a ▁ previously ▁ loaded ▁ descriptor , ▁ " " ' {0 } ' ▁ refers ▁ to ▁ { 1 } ▁ but ▁ in ▁ Event ▁ " " Descriptor ▁ { 2 } ▁ it ▁ refers ▁ to ▁ { 3 } . " . format ( name , self . sources [ name ] , descriptor . uid , description [ ' source ' ] ) ) NEW_LINE DEDENT if name == ' time ' : NEW_LINE # ▁ We ▁ can ▁ argue ▁ later ▁ about ▁ how ▁ best ▁ to ▁ handle ▁ this ▁ corner ENDCOM # ▁ case , ▁ but ▁ anything ▁ is ▁ better ▁ than ▁ silently ▁ mislabeling ENDCOM # ▁ data . ENDCOM INDENT raise ValueError ( " The ▁ name ▁ ' time ' ▁ is ▁ reserved ▁ and ▁ cannot ▁ " " be ▁ used ▁ as ▁ an ▁ alias . " ) NEW_LINE # ▁ If ▁ it ▁ is ▁ a ▁ new ▁ name , ▁ determine ▁ a ▁ ColSpec . ENDCOM DEDENT DEDENT else : NEW_LINE INDENT self . sources [ name ] = description [ ' source ' ] NEW_LINE if ' external ' in description and ' shape ' in description : NEW_LINE INDENT shape = description [ ' shape ' ] NEW_LINE ndim = len ( shape ) NEW_LINE DEDENT else : NEW_LINE # ▁ External ▁ data ▁ can ▁ be ▁ scalar . ▁ Nonscalar ▁ data ▁ must ENDCOM # ▁ have ▁ a ▁ specified ▁ shape . ▁ Thus , ▁ if ▁ no ▁ shape ▁ is ▁ given , ENDCOM # ▁ assume ▁ scalar . ENDCOM INDENT shape = None NEW_LINE ndim = 0 NEW_LINE DEDENT upsample = self . default_upsample NEW_LINE if ndim > 0 : NEW_LINE INDENT upsample = None NEW_LINE DEDENT col_info = ColSpec ( name , ndim , shape , upsample , self . default_downsample ) # ▁ defaults ENDCOM NEW_LINE # ▁ TODO ▁ Look ▁ up ▁ source - specific ▁ default ▁ in ▁ a ▁ config ▁ file ENDCOM # ▁ or ▁ some ▁ other ▁ source ▁ of ▁ reference ▁ data . ENDCOM self . col_info [ name ] = col_info NEW_LINE DEDENT DEDENT self . _known_descriptors . add ( descriptor . uid ) NEW_LINE DEDENT @ property NEW_LINE def _dataframe ( self ) : NEW_LINE INDENT " See ▁ also ▁ to _ sparse _ dataframe , ▁ the ▁ public ▁ version ▁ of ▁ this . " NEW_LINE # ▁ Rebuild ▁ the ▁ DataFrame ▁ if ▁ more ▁ data ▁ has ▁ been ▁ added . ENDCOM if self . _stale : NEW_LINE INDENT df = pd . DataFrame ( list ( self . _data ) ) NEW_LINE df [ ' time ' ] = list ( self . _time ) NEW_LINE if self . _timestamps_as_data : NEW_LINE # ▁ Only ▁ build ▁ this ▁ if ▁ we ▁ need ▁ it . ENDCOM # ▁ TODO : ▁ We ▁ shouldn ' t ▁ have ▁ to ▁ build ENDCOM # ▁ the ▁ whole ▁ thing , ▁ but ▁ there ▁ is ▁ already ▁ a ▁ lot ▁ of ▁ trickiness ENDCOM # ▁ here ▁ so ▁ we ' ll ▁ worry ▁ about ▁ optimization ▁ later . ENDCOM INDENT timestamps = pd . DataFrame ( list ( self . _timestamps ) ) NEW_LINE DEDENT for source_name in self . _timestamps_as_data : NEW_LINE INDENT col_name = _timestamp_col_name ( source_name ) NEW_LINE df [ col_name ] = timestamps [ source_name ] NEW_LINE logger . debug ( " Including ▁ % s ▁ timestamps ▁ as ▁ data " , source_name ) NEW_LINE DEDENT self . _df = df . sort ( ' time ' ) . reset_index ( drop = True ) NEW_LINE self . _stale = False NEW_LINE DEDENT return self . _df NEW_LINE DEDENT def to_sparse_dataframe ( self , include_all_timestamps = False ) : NEW_LINE INDENT """ Obtain ▁ all ▁ measurements ▁ in ▁ a ▁ DataFrame , ▁ one ▁ row ▁ per ▁ Event ▁ time . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ include _ all _ timestamps ▁ : ▁ bool STRNEWLINE ▁ The ▁ result ▁ will ▁ always ▁ contain ▁ a ▁ ' time ' ▁ column ▁ but , ▁ by ▁ default , STRNEWLINE ▁ not ▁ timestamps ▁ for ▁ individual ▁ data ▁ sources ▁ like ▁ ' motor _ timestamp ' . STRNEWLINE ▁ Set ▁ this ▁ to ▁ True ▁ to ▁ export ▁ timestamp ▁ columns ▁ for ▁ each ▁ data ▁ column STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ """ NEW_LINE if include_all_timestamps : NEW_LINE INDENT raise NotImplementedError ( " TODO " ) NEW_LINE DEDENT result = self . _dataframe . copy ( ) NEW_LINE for col_name in self . _time_columns : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT return result NEW_LINE DEDENT def _maybe_convert_times ( self , data ) : NEW_LINE INDENT if self . convert_times : NEW_LINE INDENT t = pd . to_datetime ( data , unit = ' s ' , utc = True ) . dt . tz_localize ( TZ ) NEW_LINE if self . reference_time is None : NEW_LINE INDENT return t NEW_LINE DEDENT else : NEW_LINE INDENT return t - self . reference_time NEW_LINE DEDENT DEDENT return data # ▁ no - op ENDCOM NEW_LINE DEDENT def include_timestamp_data ( self , source_name ) : NEW_LINE INDENT """ Add ▁ the ▁ exact ▁ timing ▁ of ▁ a ▁ data ▁ source ▁ as ▁ a ▁ data ▁ column . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ one ▁ of ▁ the ▁ source ▁ names ▁ in ▁ DataMuxer . sources STRNEWLINE ▁ """ NEW_LINE # ▁ self . _ timestamps _ as _ data ▁ is ▁ a ▁ set ▁ of ▁ sources ▁ who ▁ timestamps ENDCOM # ▁ should ▁ be ▁ treated ▁ as ▁ data ▁ in ▁ the ▁ _ dataframe ▁ method ▁ above . ENDCOM self . _timestamps_as_data . add ( source_name ) NEW_LINE name = _timestamp_col_name ( source_name ) NEW_LINE self . col_info [ name ] = ColSpec ( name , 0 , None , None , np . mean ) NEW_LINE self . _stale = True NEW_LINE DEDENT def remove_timestamp_data ( self , source_name ) : NEW_LINE INDENT """ Remove ▁ the ▁ exact ▁ timing ▁ of ▁ a ▁ data ▁ source ▁ from ▁ the ▁ data ▁ columns . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ one ▁ of ▁ the ▁ source ▁ names ▁ in ▁ DataMuxer . sources STRNEWLINE ▁ """ NEW_LINE self . _timestamps_as_data . remove ( source_name ) NEW_LINE # ▁ Do ▁ not ▁ force ▁ a ▁ rebuilt ▁ ( i . e . , ▁ self . _ stale ) . ▁ Just ▁ remove ▁ it ▁ here . ENDCOM del self . _df [ _timestamp_col_name ( source_name ) ] NEW_LINE DEDENT def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ to ▁ align ▁ with ▁ the ▁ data ▁ from ▁ a ▁ particular ▁ source . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE centers , bin_edges = self . _bin_on ( source_name ) NEW_LINE return self . bin_by_edges ( bin_edges , bin_anchors = centers , interpolation = interpolation , agg = agg , use_cols = use_cols ) NEW_LINE DEDENT def _bin_on ( self , source_name ) : NEW_LINE INDENT " Compute ▁ bin ▁ edges ▁ spaced ▁ around ▁ centers ▁ defined ▁ by ▁ source _ name ▁ points . " NEW_LINE col = self . _dataframe [ source_name ] NEW_LINE centers = self . _dataframe [ ' time ' ] . reindex_like ( col . dropna ( ) ) . values NEW_LINE # ▁ [ 2 , ▁ 4 , ▁ 6 ] ▁ - > ▁ [ - inf , ▁ 3 , ▁ 5 , ▁ inf ] ENDCOM bin_edges = np . mean ( [ centers [ 1 : ] , centers [ : - 1 ] ] , 0 ) NEW_LINE # ▁ [ - inf , ▁ 3 , ▁ 5 , ▁ inf ] ▁ - > ▁ [ ( - inf , ▁ 3 ) , ▁ ( 3 , ▁ 5 ) , ▁ ( 5 , ▁ inf ) ] ENDCOM bin_edges = [ - np . inf ] + list ( np . repeat ( bin_edges , 2 ) ) + [ np . inf ] NEW_LINE bin_edges = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE return centers , bin_edges NEW_LINE DEDENT def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ into ▁ bins ▁ with ▁ the ▁ specified ▁ edges . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ edges ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ two - element ▁ items ▁ like ▁ [ ( t1 , ▁ t2 ) , ▁ ( t3 , ▁ t4 ) , ▁ . . . ] STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be ▁ evaluated . STRNEWLINE ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE bin_anchors , binning = self . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE return self . resample ( bin_anchors , binning , interpolation , agg , use_cols = use_cols ) NEW_LINE DEDENT def _bin_by_edges ( self , bin_anchors , bin_edges ) : NEW_LINE INDENT " Compute ▁ bin ▁ assignment ▁ and , ▁ if ▁ needed , ▁ bin _ anchors . " NEW_LINE time = self . _dataframe [ ' time ' ] . values NEW_LINE # ▁ Get ▁ edges ▁ into ▁ 1D ▁ array [ L , ▁ R , ▁ L , ▁ R , ▁ . . . ] ENDCOM edges_as_pairs = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE all_edges = np . ravel ( edges_as_pairs ) NEW_LINE if not np . all ( np . diff ( all_edges ) >= 0 ) : NEW_LINE INDENT raise ValueError ( " Illegal ▁ binning : ▁ the ▁ left ▁ edge ▁ must ▁ be ▁ less ▁ " " than ▁ the ▁ right ▁ edge . " ) NEW_LINE # ▁ Sort ▁ out ▁ where ▁ the ▁ array ▁ each ▁ time ▁ would ▁ be ▁ inserted . ENDCOM DEDENT binning = np . searchsorted ( all_edges , time ) . astype ( float ) NEW_LINE # ▁ Times ▁ that ▁ would ▁ get ▁ inserted ▁ at ▁ even ▁ positions ▁ are ▁ between ▁ bins . ENDCOM # ▁ Mark ▁ them ENDCOM binning [ binning % 2 == 0 ] = np . nan NEW_LINE binning //= 2 # ▁ Make ▁ bin ▁ number ▁ sequential , ▁ not ▁ odds ▁ only . ENDCOM NEW_LINE if bin_anchors is None : NEW_LINE INDENT bin_anchors = np . mean ( edges_as_pairs , axis = 1 ) # ▁ bin ▁ centers ENDCOM NEW_LINE DEDENT else : NEW_LINE INDENT if len ( bin_anchors ) != len ( bin_edges ) : NEW_LINE INDENT raise ValueError ( " There ▁ are ▁ { 0 } ▁ bin _ anchors ▁ but ▁ { 1 } ▁ pairs ▁ of ▁ " " bin _ edges . ▁ These ▁ must ▁ match . " . format ( len ( bin_anchors ) , len ( bin_edges ) ) ) NEW_LINE DEDENT DEDENT return bin_anchors , binning NEW_LINE DEDENT def resample ( self , bin_anchors , binning , interpolation = None , agg = None , verify_integrity = True , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ into ▁ bins ▁ with ▁ the ▁ specified ▁ edges . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be ▁ evaluated . STRNEWLINE ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ Bin ▁ assignment . ▁ Example : ▁ [ 1 , ▁ 1 , ▁ 2 , ▁ 2 , ▁ 3 , ▁ 3 ] ▁ puts ▁ six ▁ data ▁ points STRNEWLINE ▁ into ▁ three ▁ bins ▁ with ▁ two ▁ points ▁ each . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ verify _ integrity ▁ : ▁ bool , ▁ optional STRNEWLINE ▁ For ▁ a ▁ cost ▁ in ▁ performance , ▁ verify ▁ that ▁ the ▁ downsampling ▁ function STRNEWLINE ▁ produces ▁ data ▁ of ▁ the ▁ expected ▁ shape . ▁ True ▁ by ▁ default . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE if use_cols is None : NEW_LINE INDENT use_cols = self . columns NEW_LINE DEDENT plan = self . Planner ( self ) NEW_LINE upsampling_rules = plan . determine_upsample ( interpolation , use_cols ) NEW_LINE downsampling_rules = plan . determine_downsample ( agg , use_cols ) NEW_LINE grouped = self . _dataframe . groupby ( binning ) NEW_LINE first_point = grouped . first ( ) NEW_LINE counts = grouped . count ( ) NEW_LINE resampling_requirements = _is_resampling_applicable ( counts ) NEW_LINE index = np . arange ( len ( bin_anchors ) ) NEW_LINE result = { } # ▁ dict ▁ of ▁ DataFrames , ▁ to ▁ become ▁ one ▁ MultiIndexed ▁ DataFrame ENDCOM NEW_LINE for name in use_cols : NEW_LINE INDENT upsample = upsampling_rules [ name ] NEW_LINE downsample = downsampling_rules [ name ] NEW_LINE upsampling_possible = resampling_requirements [ ' upsampling _ possible ' ] [ name ] NEW_LINE downsampling_needed = resampling_requirements [ ' downsampling _ needed ' ] [ name ] NEW_LINE result [ name ] = pd . DataFrame ( index = index ) NEW_LINE # ▁ Put ▁ the ▁ first ▁ ( maybe ▁ only ) ▁ value ▁ into ▁ a ▁ Series . ENDCOM # ▁ We ▁ will ▁ overwrite ▁ as ▁ needed ▁ below . ENDCOM result [ name ] [ ' val ' ] = pd . Series ( data = first_point [ name ] ) NEW_LINE # ▁ Short - circuit ▁ if ▁ we ▁ are ▁ done . ENDCOM if not ( upsampling_possible or downsampling_needed ) : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ exactly ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE DEDENT result [ name ] [ ' count ' ] = counts [ name ] NEW_LINE # ▁ If ▁ any ▁ bin ▁ has ▁ no ▁ data , ▁ use ▁ the ▁ upsampling ▁ rule ▁ to ▁ interpolate ENDCOM # ▁ at ▁ the ▁ center ▁ of ▁ the ▁ empty ▁ bins . ▁ If ▁ there ▁ is ▁ no ▁ rule , ▁ simply ENDCOM # ▁ leave ▁ some ▁ bins ▁ empty . ▁ Do ▁ not ▁ raise ▁ an ▁ error . ENDCOM if upsampling_possible and ( upsample is not None ) : NEW_LINE INDENT if upsample in ( ' ffill ' , ' bfill ' ) : NEW_LINE INDENT result [ name ] [ ' val ' ] . fillna ( method = upsample , inplace = True ) NEW_LINE DEDENT else : NEW_LINE INDENT dense_col = self . _dataframe [ name ] . dropna ( ) NEW_LINE y = dense_col . values NEW_LINE x = self . _dataframe [ ' time ' ] . reindex_like ( dense_col ) . values NEW_LINE interpolator = interp1d ( x , y , kind = upsample ) NEW_LINE # ▁ Outside ▁ the ▁ limits ▁ of ▁ the ▁ data , ▁ the ▁ interpolator ▁ will ENDCOM # ▁ fail . ▁ Leave ▁ any ▁ such ▁ entires ▁ empty . ENDCOM is_safe = ( ( bin_anchors > np . min ( x ) ) & ( bin_anchors < np . max ( x ) ) ) NEW_LINE safe_times = bin_anchors [ is_safe ] NEW_LINE safe_bins = index [ is_safe ] NEW_LINE interp_points = pd . Series ( interpolator ( safe_times ) , index = safe_bins ) NEW_LINE logger . debug ( " Interpolating ▁ to ▁ fill ▁ % d ▁ of ▁ % d ▁ " " empty ▁ bins ▁ in ▁ % s " , len ( safe_bins ) , ( counts [ name ] == 0 ) . sum ( ) , name ) NEW_LINE result [ name ] [ ' val ' ] . fillna ( interp_points , inplace = True ) NEW_LINE # ▁ Short - circuit ▁ if ▁ we ▁ are ▁ done . ENDCOM DEDENT DEDENT if not downsampling_needed : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ at ▁ most ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE # ▁ Multi - valued ▁ bins ▁ must ▁ be ▁ downsampled ▁ ( reduced ) . ▁ If ▁ there ▁ is ▁ no ENDCOM # ▁ rule ▁ for ▁ downsampling , ▁ we ▁ have ▁ no ▁ recourse : ▁ we ▁ must ▁ raise . ENDCOM DEDENT if ( downsample is None ) : NEW_LINE INDENT raise BinningError ( " The ▁ specified ▁ binning ▁ puts ▁ multiple ▁ " " ' {0 } ' ▁ measurements ▁ in ▁ at ▁ least ▁ one ▁ bin , ▁ " " and ▁ there ▁ is ▁ no ▁ rule ▁ for ▁ downsampling ▁ " " ( i . e . , ▁ reducing ) ▁ it . " . format ( name ) ) NEW_LINE DEDENT if verify_integrity and callable ( downsample ) : NEW_LINE INDENT downsample = _build_verified_downsample ( downsample , self . col_info [ name ] . shape ) NEW_LINE DEDENT g = grouped [ name ] # ▁ for ▁ brevity ENDCOM NEW_LINE if self . col_info [ name ] . ndim == 0 : NEW_LINE INDENT logger . debug ( " The ▁ scalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE # ▁ For ▁ scalars , ▁ pandas ▁ knows ▁ what ▁ to ▁ do . ENDCOM downsampled = g . agg ( downsample ) NEW_LINE std_series = g . std ( ) NEW_LINE max_series = g . max ( ) NEW_LINE min_series = g . min ( ) NEW_LINE DEDENT else : NEW_LINE # ▁ For ▁ nonscalars , ▁ we ▁ are ▁ abusing ▁ groupby ▁ and ▁ must ▁ go ▁ to ▁ a ENDCOM # ▁ a ▁ little ▁ more ▁ trouble ▁ to ▁ guarantee ▁ success . ENDCOM INDENT logger . debug ( " The ▁ nonscalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE if not callable ( downsample ) : NEW_LINE # ▁ Do ▁ this ▁ lookup ▁ here ▁ so ▁ that ▁ strings ▁ can ▁ be ▁ passed ENDCOM # ▁ in ▁ the ▁ call ▁ to ▁ resample . ENDCOM INDENT downsample = ColSpec . _downsample_mapping [ downsample ] NEW_LINE DEDENT downsampled = g . apply ( lambda x : downsample ( np . asarray ( x . dropna ( ) ) ) ) NEW_LINE std_series = g . apply ( lambda x : np . std ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE max_series = g . apply ( lambda x : np . max ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE min_series = g . apply ( lambda x : np . min ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE # ▁ This ▁ ( counts [ name ] ▁ > ▁ 1 ) ▁ is ▁ redundant , ▁ but ▁ there ▁ is ▁ no ▁ clean ▁ way ▁ to ENDCOM # ▁ pass ▁ it ▁ here ▁ without ▁ refactoring . ▁ Not ▁ a ▁ huge ▁ cost . ENDCOM DEDENT result [ name ] [ ' val ' ] . where ( ~ ( counts [ name ] > 1 ) , downsampled , inplace = True ) NEW_LINE result [ name ] [ ' std ' ] = std_series NEW_LINE result [ name ] [ ' max ' ] = max_series NEW_LINE result [ name ] [ ' min ' ] = min_series NEW_LINE DEDENT result = pd . concat ( result , axis = 1 ) # ▁ one ▁ MultiIndexed ▁ DataFrame ENDCOM NEW_LINE result . index . name = ' bin ' NEW_LINE # ▁ Convert ▁ time ▁ timestamp ▁ or ▁ timedelta , ▁ depending ▁ on ▁ the ▁ state ▁ of ENDCOM # ▁ self . convert _ times ▁ and ▁ self . reference _ time . ENDCOM for col_name in self . _time_columns : NEW_LINE INDENT if isinstance ( result [ col_name ] , pd . DataFrame ) : NEW_LINE INDENT subcols = result [ col_name ] . columns NEW_LINE for subcol in subcols & { ' max ' , ' min ' , ' val ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = self . _maybe_convert_times ( result [ ( col_name , subcol ) ] ) NEW_LINE DEDENT for subcol in subcols & { ' std ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = pd . to_timedelta ( result [ ( col_name , subcol ) ] , unit = ' s ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT def __getitem__ ( self , source_name ) : NEW_LINE INDENT if source_name not in list ( self . col_info . keys ( ) ) + [ ' time ' ] : NEW_LINE INDENT raise KeyError ( " No ▁ data ▁ from ▁ a ▁ source ▁ called ▁ ' {0 } ' ▁ has ▁ been ▁ " " added . " . format ( source_name ) ) NEW_LINE # ▁ Unlike ▁ output ▁ from ▁ binning ▁ functions , ▁ this ▁ is ▁ indexed ENDCOM # ▁ on ▁ time . ENDCOM DEDENT result = self . _dataframe [ source_name ] . dropna ( ) NEW_LINE result . index = self . _dataframe [ ' time ' ] . reindex_like ( result ) NEW_LINE return result NEW_LINE DEDENT def __getattr__ ( self , attr ) : NEW_LINE # ▁ Developer ▁ beware : ▁ if ▁ any ▁ properties ▁ raise ▁ an ▁ AttributeError , ENDCOM # ▁ this ▁ will ▁ mask ▁ it . ▁ Comment ▁ this ▁ magic ▁ method ▁ to ▁ debug ▁ properties . ENDCOM INDENT if attr in self . col_info . keys ( ) : NEW_LINE INDENT return self [ attr ] NEW_LINE DEDENT else : NEW_LINE INDENT raise AttributeError ( " DataMuxer ▁ has ▁ no ▁ attribute ▁ { 0 } ▁ and ▁ no ▁ " " data ▁ source ▁ named ▁ ' {0 } ' " . format ( attr ) ) NEW_LINE DEDENT DEDENT @ property NEW_LINE def ncols ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ number ▁ of ▁ columns ▁ that ▁ the ▁ DataMuxer ▁ contains STRNEWLINE ▁ """ NEW_LINE return len ( self . col_info ) NEW_LINE DEDENT @ property NEW_LINE def col_info_by_ndim ( self ) : NEW_LINE INDENT """ Dictionary ▁ mapping ▁ dimensionality ▁ ( ndim ) ▁ onto ▁ a ▁ list ▁ of ▁ ColSpecs """ NEW_LINE result = { } NEW_LINE for name , col_spec in six . iteritems ( self . col_info ) : NEW_LINE INDENT try : NEW_LINE INDENT result [ col_spec . ndim ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT result [ col_spec . ndim ] = [ ] NEW_LINE DEDENT result [ col_spec . ndim ] . append ( col_spec ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def dataframe_to_dict ( df ) : NEW_LINE INDENT """ STRNEWLINE ▁ Turn ▁ a ▁ DataFrame ▁ into ▁ a ▁ dict ▁ of ▁ lists . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ DataFrame STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ index ▁ : ▁ ndarray STRNEWLINE ▁ The ▁ index ▁ of ▁ the ▁ data ▁ frame STRNEWLINE ▁ data ▁ : ▁ dict STRNEWLINE ▁ Dictionary ▁ keyed ▁ on ▁ column ▁ name ▁ of ▁ the ▁ column . ▁ The ▁ value ▁ is STRNEWLINE ▁ one ▁ of ▁ ( ndarray , ▁ list , ▁ pd . Series ) STRNEWLINE ▁ """ NEW_LINE dict_of_lists = { col : df [ col ] . to_list ( ) for col in df . columns } NEW_LINE return df . index . values , dict_of_lists NEW_LINE DEDENT def _build_verified_downsample ( downsample , expected_shape ) : NEW_LINE # ▁ Ensure ▁ two ▁ things : ENDCOM # ▁ 1 . ▁ The ▁ downsampling ▁ function ▁ shouldn ' t ▁ touch ▁ bins ▁ with ▁ only ▁ one ▁ point . ENDCOM # ▁ 2 . ▁ The ▁ result ▁ of ▁ downsample ▁ should ▁ have ▁ the ▁ right ▁ shape . ENDCOM INDENT def _downsample ( data ) : NEW_LINE INDENT if len ( data ) == 1 : NEW_LINE INDENT return data NEW_LINE DEDENT downsampled = downsample ( data ) NEW_LINE if ( expected_shape is None or expected_shape == 0 ) : NEW_LINE INDENT if not np . isscalar ( downsampled ) : NEW_LINE INDENT raise BadDownsamplerError ( " The ▁ ' agg ' ▁ ( downsampling ) ▁ function ▁ " " for ▁ { 0 } ▁ is ▁ expected ▁ to ▁ produce ▁ " " a ▁ scalar ▁ from ▁ the ▁ data ▁ in ▁ each ▁ " " bin . " . format ( downsampled ) ) NEW_LINE DEDENT DEDENT elif downsampled . shape != expected_shape : NEW_LINE INDENT raise BadDownsamplerError ( " An ▁ ' agg ' ▁ ( downsampling ) ▁ function ▁ " " returns ▁ data ▁ shaped ▁ { 0 } ▁ but ▁ the ▁ " " shape ▁ { 1 } ▁ is ▁ expected . " . format ( downsampled . shape , expected_shape ) ) NEW_LINE DEDENT return downsampled NEW_LINE DEDENT return _downsample NEW_LINE DEDENT def _timestamp_col_name ( source_name ) : NEW_LINE INDENT return ' { 0 } _ timestamp ' . format ( source_name ) NEW_LINE DEDENT def _normalize_string_none ( val ) : NEW_LINE INDENT " Replay ▁ passes ▁ ' None ' ▁ to ▁ mean ▁ None . " NEW_LINE try : NEW_LINE INDENT lowercase_val = val . lower ( ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT return val NEW_LINE DEDENT if lowercase_val == ' none ' : NEW_LINE INDENT return None NEW_LINE DEDENT else : NEW_LINE INDENT return val NEW_LINE DEDENT DEDENT def _is_resampling_applicable ( counts ) : NEW_LINE INDENT has_no_points = counts == 0 NEW_LINE has_multiple_points = counts > 1 NEW_LINE upsampling_possible = has_no_points . any ( ) NEW_LINE downsampling_needed = has_multiple_points . any ( ) NEW_LINE result = { } NEW_LINE result [ ' upsampling _ possible ' ] = upsampling_possible . to_dict ( ) NEW_LINE result [ ' downsampling _ needed ' ] = downsampling_needed . to_dict ( ) NEW_LINE return result NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="fernandog/Medusa/tree/master/ext/click/termui.py"> import os NEW_LINE import sys NEW_LINE import struct NEW_LINE from . _compat import raw_input , text_type , string_types , isatty , strip_ansi , get_winterm_size , DEFAULT_COLUMNS , WIN NEW_LINE from . utils import echo NEW_LINE from . exceptions import Abort , UsageError NEW_LINE from . types import convert_type NEW_LINE from . globals import resolve_color_default NEW_LINE # ▁ The ▁ prompt ▁ functions ▁ to ▁ use . ▁ The ▁ doc ▁ tools ▁ currently ▁ override ▁ these ENDCOM # ▁ functions ▁ to ▁ customize ▁ how ▁ they ▁ work . ENDCOM visible_prompt_func = raw_input NEW_LINE _ansi_colors = ( ' black ' , ' red ' , ' green ' , ' yellow ' , ' blue ' , ' magenta ' , ' cyan ' , ' white ' , ' reset ' ) NEW_LINE _ansi_reset_all = ' \033[0m ' NEW_LINE def hidden_prompt_func ( prompt ) : NEW_LINE INDENT import getpass NEW_LINE return getpass . getpass ( prompt ) NEW_LINE DEDENT def _build_prompt ( text , suffix , show_default = False , default = None ) : NEW_LINE INDENT prompt = text NEW_LINE if default is not None and show_default : NEW_LINE INDENT prompt = ' % s ▁ [ % s ] ' % ( prompt , default ) NEW_LINE DEDENT return prompt + suffix NEW_LINE DEDENT def prompt ( text , default = None , hide_input = False , confirmation_prompt = False , type = None , value_proc = None , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT """ Prompts ▁ a ▁ user ▁ for ▁ input . ▁ This ▁ is ▁ a ▁ convenience ▁ function ▁ that ▁ can STRNEWLINE ▁ be ▁ used ▁ to ▁ prompt ▁ a ▁ user ▁ for ▁ input ▁ later . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ user ▁ aborts ▁ the ▁ input ▁ by ▁ sending ▁ a ▁ interrupt ▁ signal , ▁ this STRNEWLINE ▁ function ▁ will ▁ catch ▁ it ▁ and ▁ raise ▁ a ▁ : exc : ` Abort ` ▁ exception . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 6.0 STRNEWLINE ▁ Added ▁ unicode ▁ support ▁ for ▁ cmd . exe ▁ on ▁ Windows . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ show ▁ for ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ default : ▁ the ▁ default ▁ value ▁ to ▁ use ▁ if ▁ no ▁ input ▁ happens . ▁ If ▁ this STRNEWLINE ▁ is ▁ not ▁ given ▁ it ▁ will ▁ prompt ▁ until ▁ it ' s ▁ aborted . STRNEWLINE ▁ : param ▁ hide _ input : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ true ▁ then ▁ the ▁ input ▁ value ▁ will STRNEWLINE ▁ be ▁ hidden . STRNEWLINE ▁ : param ▁ confirmation _ prompt : ▁ asks ▁ for ▁ confirmation ▁ for ▁ the ▁ value . STRNEWLINE ▁ : param ▁ type : ▁ the ▁ type ▁ to ▁ use ▁ to ▁ check ▁ the ▁ value ▁ against . STRNEWLINE ▁ : param ▁ value _ proc : ▁ if ▁ this ▁ parameter ▁ is ▁ provided ▁ it ' s ▁ a ▁ function ▁ that STRNEWLINE ▁ is ▁ invoked ▁ instead ▁ of ▁ the ▁ type ▁ conversion ▁ to STRNEWLINE ▁ convert ▁ a ▁ value . STRNEWLINE ▁ : param ▁ prompt _ suffix : ▁ a ▁ suffix ▁ that ▁ should ▁ be ▁ added ▁ to ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ show _ default : ▁ shows ▁ or ▁ hides ▁ the ▁ default ▁ value ▁ in ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ true ▁ the ▁ file ▁ defaults ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE result = None NEW_LINE def prompt_func ( text ) : NEW_LINE INDENT f = hide_input and hidden_prompt_func or visible_prompt_func NEW_LINE try : NEW_LINE # ▁ Write ▁ the ▁ prompt ▁ separately ▁ so ▁ that ▁ we ▁ get ▁ nice ENDCOM # ▁ coloring ▁ through ▁ colorama ▁ on ▁ Windows ENDCOM INDENT echo ( text , nl = False , err = err ) NEW_LINE return f ( ' ' ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE # ▁ getpass ▁ doesn ' t ▁ print ▁ a ▁ newline ▁ if ▁ the ▁ user ▁ aborts ▁ input ▁ with ▁ ^ C . ENDCOM # ▁ Allegedly ▁ this ▁ behavior ▁ is ▁ inherited ▁ from ▁ getpass ( 3 ) . ENDCOM # ▁ A ▁ doc ▁ bug ▁ has ▁ been ▁ filed ▁ at ▁ https : / / bugs . python . org / issue24711 ENDCOM INDENT if hide_input : NEW_LINE INDENT echo ( None , err = err ) NEW_LINE DEDENT raise Abort ( ) NEW_LINE DEDENT DEDENT if value_proc is None : NEW_LINE INDENT value_proc = convert_type ( type , default ) NEW_LINE DEDENT prompt = _build_prompt ( text , prompt_suffix , show_default , default ) NEW_LINE while 1 : NEW_LINE INDENT while 1 : NEW_LINE INDENT value = prompt_func ( prompt ) NEW_LINE if value : NEW_LINE INDENT break NEW_LINE # ▁ If ▁ a ▁ default ▁ is ▁ set ▁ and ▁ used , ▁ then ▁ the ▁ confirmation ENDCOM # ▁ prompt ▁ is ▁ always ▁ skipped ▁ because ▁ that ' s ▁ the ▁ only ▁ thing ENDCOM # ▁ that ▁ really ▁ makes ▁ sense . ENDCOM DEDENT elif default is not None : NEW_LINE INDENT return default NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT result = value_proc ( value ) NEW_LINE DEDENT except UsageError as e : NEW_LINE INDENT echo ( ' Error : ▁ % s ' % e . message , err = err ) NEW_LINE continue NEW_LINE DEDENT if not confirmation_prompt : NEW_LINE INDENT return result NEW_LINE DEDENT while 1 : NEW_LINE INDENT value2 = prompt_func ( ' Repeat ▁ for ▁ confirmation : ▁ ' ) NEW_LINE if value2 : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT if value == value2 : NEW_LINE INDENT return result NEW_LINE DEDENT echo ( ' Error : ▁ the ▁ two ▁ entered ▁ values ▁ do ▁ not ▁ match ' , err = err ) NEW_LINE DEDENT DEDENT def confirm ( text , default = False , abort = False , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT """ Prompts ▁ for ▁ confirmation ▁ ( yes / no ▁ question ) . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ user ▁ aborts ▁ the ▁ input ▁ by ▁ sending ▁ a ▁ interrupt ▁ signal ▁ this STRNEWLINE ▁ function ▁ will ▁ catch ▁ it ▁ and ▁ raise ▁ a ▁ : exc : ` Abort ` ▁ exception . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ question ▁ to ▁ ask . STRNEWLINE ▁ : param ▁ default : ▁ the ▁ default ▁ for ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ abort : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ ` True ` ▁ a ▁ negative ▁ answer ▁ aborts ▁ the STRNEWLINE ▁ exception ▁ by ▁ raising ▁ : exc : ` Abort ` . STRNEWLINE ▁ : param ▁ prompt _ suffix : ▁ a ▁ suffix ▁ that ▁ should ▁ be ▁ added ▁ to ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ show _ default : ▁ shows ▁ or ▁ hides ▁ the ▁ default ▁ value ▁ in ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ true ▁ the ▁ file ▁ defaults ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE prompt = _build_prompt ( text , prompt_suffix , show_default , default and ' Y / n ' or ' y / N ' ) NEW_LINE while 1 : NEW_LINE INDENT try : NEW_LINE # ▁ Write ▁ the ▁ prompt ▁ separately ▁ so ▁ that ▁ we ▁ get ▁ nice ENDCOM # ▁ coloring ▁ through ▁ colorama ▁ on ▁ Windows ENDCOM INDENT echo ( prompt , nl = False , err = err ) NEW_LINE value = visible_prompt_func ( ' ' ) . lower ( ) . strip ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT if value in ( ' y ' , ' yes ' ) : NEW_LINE INDENT rv = True NEW_LINE DEDENT elif value in ( ' n ' , ' no ' ) : NEW_LINE INDENT rv = False NEW_LINE DEDENT elif value == ' ' : NEW_LINE INDENT rv = default NEW_LINE DEDENT else : NEW_LINE INDENT echo ( ' Error : ▁ invalid ▁ input ' , err = err ) NEW_LINE continue NEW_LINE DEDENT break NEW_LINE DEDENT if abort and not rv : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT return rv NEW_LINE DEDENT def get_terminal_size ( ) : NEW_LINE INDENT """ Returns ▁ the ▁ current ▁ size ▁ of ▁ the ▁ terminal ▁ as ▁ tuple ▁ in ▁ the ▁ form STRNEWLINE ▁ ` ` ( width , ▁ height ) ` ` ▁ in ▁ columns ▁ and ▁ rows . STRNEWLINE ▁ """ NEW_LINE # ▁ If ▁ shutil ▁ has ▁ get _ terminal _ size ( ) ▁ ( Python ▁ 3.3 ▁ and ▁ later ) ▁ use ▁ that ENDCOM if sys . version_info >= ( 3 , 3 ) : NEW_LINE INDENT import shutil NEW_LINE shutil_get_terminal_size = getattr ( shutil , ' get _ terminal _ size ' , None ) NEW_LINE if shutil_get_terminal_size : NEW_LINE INDENT sz = shutil_get_terminal_size ( ) NEW_LINE return sz . columns , sz . lines NEW_LINE DEDENT DEDENT if get_winterm_size is not None : NEW_LINE INDENT return get_winterm_size ( ) NEW_LINE DEDENT def ioctl_gwinsz ( fd ) : NEW_LINE INDENT try : NEW_LINE INDENT import fcntl NEW_LINE import termios NEW_LINE cr = struct . unpack ( ' hh ' , fcntl . ioctl ( fd , termios . TIOCGWINSZ , '1234' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return NEW_LINE DEDENT return cr NEW_LINE DEDENT cr = ioctl_gwinsz ( 0 ) or ioctl_gwinsz ( 1 ) or ioctl_gwinsz ( 2 ) NEW_LINE if not cr : NEW_LINE INDENT try : NEW_LINE INDENT fd = os . open ( os . ctermid ( ) , os . O_RDONLY ) NEW_LINE try : NEW_LINE INDENT cr = ioctl_gwinsz ( fd ) NEW_LINE DEDENT finally : NEW_LINE INDENT os . close ( fd ) NEW_LINE DEDENT DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT if not cr or not cr [ 0 ] or not cr [ 1 ] : NEW_LINE INDENT cr = ( os . environ . get ( ' LINES ' , 25 ) , os . environ . get ( ' COLUMNS ' , DEFAULT_COLUMNS ) ) NEW_LINE DEDENT return int ( cr [ 1 ] ) , int ( cr [ 0 ] ) NEW_LINE DEDENT def echo_via_pager ( text , color = None ) : NEW_LINE INDENT """ This ▁ function ▁ takes ▁ a ▁ text ▁ and ▁ shows ▁ it ▁ via ▁ an ▁ environment ▁ specific STRNEWLINE ▁ pager ▁ on ▁ stdout . STRNEWLINE STRNEWLINE ▁ . . ▁ versionchanged : : ▁ 3.0 STRNEWLINE ▁ Added ▁ the ▁ ` color ` ▁ flag . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ page . STRNEWLINE ▁ : param ▁ color : ▁ controls ▁ if ▁ the ▁ pager ▁ supports ▁ ANSI ▁ colors ▁ or ▁ not . ▁ The STRNEWLINE ▁ default ▁ is ▁ autodetection . STRNEWLINE ▁ """ NEW_LINE color = resolve_color_default ( color ) NEW_LINE if not isinstance ( text , string_types ) : NEW_LINE INDENT text = text_type ( text ) NEW_LINE DEDENT from . _termui_impl import pager NEW_LINE return pager ( text + ' \n ' , color ) NEW_LINE DEDENT def progressbar ( iterable = None , length = None , label = None , show_eta = True , show_percent = None , show_pos = False , item_show_func = None , fill_char = ' # ' , empty_char = ' - ' , bar_template = ' % ( label ) s ▁ ▁ [ % ( bar ) s ] ▁ ▁ % ( info ) s ' , info_sep = ' ▁ ▁ ' , width = 36 , file = None , color = None ) : NEW_LINE INDENT """ This ▁ function ▁ creates ▁ an ▁ iterable ▁ context ▁ manager ▁ that ▁ can ▁ be ▁ used STRNEWLINE ▁ to ▁ iterate ▁ over ▁ something ▁ while ▁ showing ▁ a ▁ progress ▁ bar . ▁ It ▁ will STRNEWLINE ▁ either ▁ iterate ▁ over ▁ the ▁ ` iterable ` ▁ or ▁ ` length ` ▁ items ▁ ( that ▁ are ▁ counted STRNEWLINE ▁ up ) . ▁ While ▁ iteration ▁ happens , ▁ this ▁ function ▁ will ▁ print ▁ a ▁ rendered STRNEWLINE ▁ progress ▁ bar ▁ to ▁ the ▁ given ▁ ` file ` ▁ ( defaults ▁ to ▁ stdout ) ▁ and ▁ will ▁ attempt STRNEWLINE ▁ to ▁ calculate ▁ remaining ▁ time ▁ and ▁ more . ▁ By ▁ default , ▁ this ▁ progress ▁ bar STRNEWLINE ▁ will ▁ not ▁ be ▁ rendered ▁ if ▁ the ▁ file ▁ is ▁ not ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ The ▁ context ▁ manager ▁ creates ▁ the ▁ progress ▁ bar . ▁ When ▁ the ▁ context STRNEWLINE ▁ manager ▁ is ▁ entered ▁ the ▁ progress ▁ bar ▁ is ▁ already ▁ displayed . ▁ With ▁ every STRNEWLINE ▁ iteration ▁ over ▁ the ▁ progress ▁ bar , ▁ the ▁ iterable ▁ passed ▁ to ▁ the ▁ bar ▁ is STRNEWLINE ▁ advanced ▁ and ▁ the ▁ bar ▁ is ▁ updated . ▁ When ▁ the ▁ context ▁ manager ▁ exits , STRNEWLINE ▁ a ▁ newline ▁ is ▁ printed ▁ and ▁ the ▁ progress ▁ bar ▁ is ▁ finalized ▁ on ▁ screen . STRNEWLINE STRNEWLINE ▁ No ▁ printing ▁ must ▁ happen ▁ or ▁ the ▁ progress ▁ bar ▁ will ▁ be ▁ unintentionally STRNEWLINE ▁ destroyed . STRNEWLINE STRNEWLINE ▁ Example ▁ usage : : STRNEWLINE STRNEWLINE ▁ with ▁ progressbar ( items ) ▁ as ▁ bar : STRNEWLINE ▁ for ▁ item ▁ in ▁ bar : STRNEWLINE ▁ do _ something _ with ( item ) STRNEWLINE STRNEWLINE ▁ Alternatively , ▁ if ▁ no ▁ iterable ▁ is ▁ specified , ▁ one ▁ can ▁ manually ▁ update ▁ the STRNEWLINE ▁ progress ▁ bar ▁ through ▁ the ▁ ` update ( ) ` ▁ method ▁ instead ▁ of ▁ directly STRNEWLINE ▁ iterating ▁ over ▁ the ▁ progress ▁ bar . ▁ The ▁ update ▁ method ▁ accepts ▁ the ▁ number STRNEWLINE ▁ of ▁ steps ▁ to ▁ increment ▁ the ▁ bar ▁ with : : STRNEWLINE STRNEWLINE ▁ with ▁ progressbar ( length = chunks . total _ bytes ) ▁ as ▁ bar : STRNEWLINE ▁ for ▁ chunk ▁ in ▁ chunks : STRNEWLINE ▁ process _ chunk ( chunk ) STRNEWLINE ▁ bar . update ( chunks . bytes ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` color ` ▁ parameter . ▁ Added ▁ a ▁ ` update ` ▁ method ▁ to ▁ the STRNEWLINE ▁ progressbar ▁ object . STRNEWLINE STRNEWLINE ▁ : param ▁ iterable : ▁ an ▁ iterable ▁ to ▁ iterate ▁ over . ▁ If ▁ not ▁ provided ▁ the ▁ length STRNEWLINE ▁ is ▁ required . STRNEWLINE ▁ : param ▁ length : ▁ the ▁ number ▁ of ▁ items ▁ to ▁ iterate ▁ over . ▁ By ▁ default ▁ the STRNEWLINE ▁ progressbar ▁ will ▁ attempt ▁ to ▁ ask ▁ the ▁ iterator ▁ about ▁ its STRNEWLINE ▁ length , ▁ which ▁ might ▁ or ▁ might ▁ not ▁ work . ▁ If ▁ an ▁ iterable ▁ is STRNEWLINE ▁ also ▁ provided ▁ this ▁ parameter ▁ can ▁ be ▁ used ▁ to ▁ override ▁ the STRNEWLINE ▁ length . ▁ If ▁ an ▁ iterable ▁ is ▁ not ▁ provided ▁ the ▁ progress ▁ bar STRNEWLINE ▁ will ▁ iterate ▁ over ▁ a ▁ range ▁ of ▁ that ▁ length . STRNEWLINE ▁ : param ▁ label : ▁ the ▁ label ▁ to ▁ show ▁ next ▁ to ▁ the ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ show _ eta : ▁ enables ▁ or ▁ disables ▁ the ▁ estimated ▁ time ▁ display . ▁ This ▁ is STRNEWLINE ▁ automatically ▁ disabled ▁ if ▁ the ▁ length ▁ cannot ▁ be STRNEWLINE ▁ determined . STRNEWLINE ▁ : param ▁ show _ percent : ▁ enables ▁ or ▁ disables ▁ the ▁ percentage ▁ display . ▁ The STRNEWLINE ▁ default ▁ is ▁ ` True ` ▁ if ▁ the ▁ iterable ▁ has ▁ a ▁ length ▁ or STRNEWLINE ▁ ` False ` ▁ if ▁ not . STRNEWLINE ▁ : param ▁ show _ pos : ▁ enables ▁ or ▁ disables ▁ the ▁ absolute ▁ position ▁ display . ▁ The STRNEWLINE ▁ default ▁ is ▁ ` False ` . STRNEWLINE ▁ : param ▁ item _ show _ func : ▁ a ▁ function ▁ called ▁ with ▁ the ▁ current ▁ item ▁ which STRNEWLINE ▁ can ▁ return ▁ a ▁ string ▁ to ▁ show ▁ the ▁ current ▁ item STRNEWLINE ▁ next ▁ to ▁ the ▁ progress ▁ bar . ▁ Note ▁ that ▁ the ▁ current STRNEWLINE ▁ item ▁ can ▁ be ▁ ` None ` ! STRNEWLINE ▁ : param ▁ fill _ char : ▁ the ▁ character ▁ to ▁ use ▁ to ▁ show ▁ the ▁ filled ▁ part ▁ of ▁ the STRNEWLINE ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ empty _ char : ▁ the ▁ character ▁ to ▁ use ▁ to ▁ show ▁ the ▁ non - filled ▁ part ▁ of STRNEWLINE ▁ the ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ bar _ template : ▁ the ▁ format ▁ string ▁ to ▁ use ▁ as ▁ template ▁ for ▁ the ▁ bar . STRNEWLINE ▁ The ▁ parameters ▁ in ▁ it ▁ are ▁ ` ` label ` ` ▁ for ▁ the ▁ label , STRNEWLINE ▁ ` ` bar ` ` ▁ for ▁ the ▁ progress ▁ bar ▁ and ▁ ` ` info ` ` ▁ for ▁ the STRNEWLINE ▁ info ▁ section . STRNEWLINE ▁ : param ▁ info _ sep : ▁ the ▁ separator ▁ between ▁ multiple ▁ info ▁ items ▁ ( eta ▁ etc . ) STRNEWLINE ▁ : param ▁ width : ▁ the ▁ width ▁ of ▁ the ▁ progress ▁ bar ▁ in ▁ characters , ▁ 0 ▁ means ▁ full STRNEWLINE ▁ terminal ▁ width STRNEWLINE ▁ : param ▁ file : ▁ the ▁ file ▁ to ▁ write ▁ to . ▁ If ▁ this ▁ is ▁ not ▁ a ▁ terminal ▁ then STRNEWLINE ▁ only ▁ the ▁ label ▁ is ▁ printed . STRNEWLINE ▁ : param ▁ color : ▁ controls ▁ if ▁ the ▁ terminal ▁ supports ▁ ANSI ▁ colors ▁ or ▁ not . ▁ The STRNEWLINE ▁ default ▁ is ▁ autodetection . ▁ This ▁ is ▁ only ▁ needed ▁ if ▁ ANSI STRNEWLINE ▁ codes ▁ are ▁ included ▁ anywhere ▁ in ▁ the ▁ progress ▁ bar ▁ output STRNEWLINE ▁ which ▁ is ▁ not ▁ the ▁ case ▁ by ▁ default . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import ProgressBar NEW_LINE color = resolve_color_default ( color ) NEW_LINE return ProgressBar ( iterable = iterable , length = length , show_eta = show_eta , show_percent = show_percent , show_pos = show_pos , item_show_func = item_show_func , fill_char = fill_char , empty_char = empty_char , bar_template = bar_template , info_sep = info_sep , file = file , label = label , width = width , color = color ) NEW_LINE DEDENT def clear ( ) : NEW_LINE INDENT """ Clears ▁ the ▁ terminal ▁ screen . ▁ This ▁ will ▁ have ▁ the ▁ effect ▁ of ▁ clearing STRNEWLINE ▁ the ▁ whole ▁ visible ▁ space ▁ of ▁ the ▁ terminal ▁ and ▁ moving ▁ the ▁ cursor ▁ to ▁ the STRNEWLINE ▁ top ▁ left . ▁ This ▁ does ▁ not ▁ do ▁ anything ▁ if ▁ not ▁ connected ▁ to ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE ▁ """ NEW_LINE if not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE # ▁ If ▁ we ' re ▁ on ▁ Windows ▁ and ▁ we ▁ don ' t ▁ have ▁ colorama ▁ available , ▁ then ▁ we ENDCOM # ▁ clear ▁ the ▁ screen ▁ by ▁ shelling ▁ out . ▁ Otherwise ▁ we ▁ can ▁ use ▁ an ▁ escape ENDCOM # ▁ sequence . ENDCOM DEDENT if WIN : NEW_LINE INDENT os . system ( ' cls ' ) NEW_LINE DEDENT else : NEW_LINE INDENT sys . stdout . write ( ' \033[2J\033[1;1H ' ) NEW_LINE DEDENT DEDENT def style ( text , fg = None , bg = None , bold = None , dim = None , underline = None , blink = None , reverse = None , reset = True ) : NEW_LINE INDENT """ Styles ▁ a ▁ text ▁ with ▁ ANSI ▁ styles ▁ and ▁ returns ▁ the ▁ new ▁ string . ▁ By STRNEWLINE ▁ default ▁ the ▁ styling ▁ is ▁ self ▁ contained ▁ which ▁ means ▁ that ▁ at ▁ the ▁ end STRNEWLINE ▁ of ▁ the ▁ string ▁ a ▁ reset ▁ code ▁ is ▁ issued . ▁ This ▁ can ▁ be ▁ prevented ▁ by STRNEWLINE ▁ passing ▁ ` ` reset = False ` ` . STRNEWLINE STRNEWLINE ▁ Examples : : STRNEWLINE STRNEWLINE ▁ click . echo ( click . style ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) ) STRNEWLINE ▁ click . echo ( click . style ( ' ATTENTION ! ' , ▁ blink = True ) ) STRNEWLINE ▁ click . echo ( click . style ( ' Some ▁ things ' , ▁ reverse = True , ▁ fg = ' cyan ' ) ) STRNEWLINE STRNEWLINE ▁ Supported ▁ color ▁ names : STRNEWLINE STRNEWLINE ▁ * ▁ ` ` black ` ` ▁ ( might ▁ be ▁ a ▁ gray ) STRNEWLINE ▁ * ▁ ` ` red ` ` STRNEWLINE ▁ * ▁ ` ` green ` ` STRNEWLINE ▁ * ▁ ` ` yellow ` ` ▁ ( might ▁ be ▁ an ▁ orange ) STRNEWLINE ▁ * ▁ ` ` blue ` ` STRNEWLINE ▁ * ▁ ` ` magenta ` ` STRNEWLINE ▁ * ▁ ` ` cyan ` ` STRNEWLINE ▁ * ▁ ` ` white ` ` ▁ ( might ▁ be ▁ light ▁ gray ) STRNEWLINE ▁ * ▁ ` ` reset ` ` ▁ ( reset ▁ the ▁ color ▁ code ▁ only ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ string ▁ to ▁ style ▁ with ▁ ansi ▁ codes . STRNEWLINE ▁ : param ▁ fg : ▁ if ▁ provided ▁ this ▁ will ▁ become ▁ the ▁ foreground ▁ color . STRNEWLINE ▁ : param ▁ bg : ▁ if ▁ provided ▁ this ▁ will ▁ become ▁ the ▁ background ▁ color . STRNEWLINE ▁ : param ▁ bold : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ bold ▁ mode . STRNEWLINE ▁ : param ▁ dim : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ dim ▁ mode . ▁ This ▁ is STRNEWLINE ▁ badly ▁ supported . STRNEWLINE ▁ : param ▁ underline : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ underline . STRNEWLINE ▁ : param ▁ blink : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ blinking . STRNEWLINE ▁ : param ▁ reverse : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ inverse STRNEWLINE ▁ rendering ▁ ( foreground ▁ becomes ▁ background ▁ and ▁ the STRNEWLINE ▁ other ▁ way ▁ round ) . STRNEWLINE ▁ : param ▁ reset : ▁ by ▁ default ▁ a ▁ reset - all ▁ code ▁ is ▁ added ▁ at ▁ the ▁ end ▁ of ▁ the STRNEWLINE ▁ string ▁ which ▁ means ▁ that ▁ styles ▁ do ▁ not ▁ carry ▁ over . ▁ This STRNEWLINE ▁ can ▁ be ▁ disabled ▁ to ▁ compose ▁ styles . STRNEWLINE ▁ """ NEW_LINE bits = [ ] NEW_LINE if fg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( fg ) + 30 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % fg ) NEW_LINE DEDENT DEDENT if bg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( bg ) + 40 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % bg ) NEW_LINE DEDENT DEDENT if bold is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 1 if bold else 22 ) ) NEW_LINE DEDENT if dim is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 2 if dim else 22 ) ) NEW_LINE DEDENT if underline is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 4 if underline else 24 ) ) NEW_LINE DEDENT if blink is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 5 if blink else 25 ) ) NEW_LINE DEDENT if reverse is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 7 if reverse else 27 ) ) NEW_LINE DEDENT bits . append ( text ) NEW_LINE if reset : NEW_LINE INDENT bits . append ( _ansi_reset_all ) NEW_LINE DEDENT return ' ' . join ( bits ) NEW_LINE DEDENT def unstyle ( text ) : NEW_LINE INDENT """ Removes ▁ ANSI ▁ styling ▁ information ▁ from ▁ a ▁ string . ▁ Usually ▁ it ' s ▁ not STRNEWLINE ▁ necessary ▁ to ▁ use ▁ this ▁ function ▁ as ▁ Click ' s ▁ echo ▁ function ▁ will STRNEWLINE ▁ automatically ▁ remove ▁ styling ▁ if ▁ necessary . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ remove ▁ style ▁ information ▁ from . STRNEWLINE ▁ """ NEW_LINE return strip_ansi ( text ) NEW_LINE DEDENT def secho ( text , file = None , nl = True , err = False , color = None , ** styles ) : NEW_LINE INDENT """ This ▁ function ▁ combines ▁ : func : ` echo ` ▁ and ▁ : func : ` style ` ▁ into ▁ one STRNEWLINE ▁ call . ▁ As ▁ such ▁ the ▁ following ▁ two ▁ calls ▁ are ▁ the ▁ same : : STRNEWLINE STRNEWLINE ▁ click . secho ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) STRNEWLINE ▁ click . echo ( click . style ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) ) STRNEWLINE STRNEWLINE ▁ All ▁ keyword ▁ arguments ▁ are ▁ forwarded ▁ to ▁ the ▁ underlying ▁ functions STRNEWLINE ▁ depending ▁ on ▁ which ▁ one ▁ they ▁ go ▁ with . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE ▁ """ NEW_LINE return echo ( style ( text , ** styles ) , file = file , nl = nl , err = err , color = color ) NEW_LINE DEDENT def edit ( text = None , editor = None , env = None , require_save = True , extension = ' . txt ' , filename = None ) : NEW_LINE INDENT r """ Edits ▁ the ▁ given ▁ text ▁ in ▁ the ▁ defined ▁ editor . ▁ If ▁ an ▁ editor ▁ is ▁ given STRNEWLINE ▁ ( should ▁ be ▁ the ▁ full ▁ path ▁ to ▁ the ▁ executable ▁ but ▁ the ▁ regular ▁ operating STRNEWLINE ▁ system ▁ search ▁ path ▁ is ▁ used ▁ for ▁ finding ▁ the ▁ executable ) ▁ it ▁ overrides STRNEWLINE ▁ the ▁ detected ▁ editor . ▁ Optionally , ▁ some ▁ environment ▁ variables ▁ can ▁ be STRNEWLINE ▁ used . ▁ If ▁ the ▁ editor ▁ is ▁ closed ▁ without ▁ changes , ▁ ` None ` ▁ is ▁ returned . ▁ In STRNEWLINE ▁ case ▁ a ▁ file ▁ is ▁ edited ▁ directly ▁ the ▁ return ▁ value ▁ is ▁ always ▁ ` None ` ▁ and STRNEWLINE ▁ ` require _ save ` ▁ and ▁ ` extension ` ▁ are ▁ ignored . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ editor ▁ cannot ▁ be ▁ opened ▁ a ▁ : exc : ` UsageError ` ▁ is ▁ raised . STRNEWLINE STRNEWLINE ▁ Note ▁ for ▁ Windows : ▁ to ▁ simplify ▁ cross - platform ▁ usage , ▁ the ▁ newlines ▁ are STRNEWLINE ▁ automatically ▁ converted ▁ from ▁ POSIX ▁ to ▁ Windows ▁ and ▁ vice ▁ versa . ▁ As ▁ such , STRNEWLINE ▁ the ▁ message ▁ here ▁ will ▁ have ▁ ` ` \n ` ` ▁ as ▁ newline ▁ markers . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ edit . STRNEWLINE ▁ : param ▁ editor : ▁ optionally ▁ the ▁ editor ▁ to ▁ use . ▁ Defaults ▁ to ▁ automatic STRNEWLINE ▁ detection . STRNEWLINE ▁ : param ▁ env : ▁ environment ▁ variables ▁ to ▁ forward ▁ to ▁ the ▁ editor . STRNEWLINE ▁ : param ▁ require _ save : ▁ if ▁ this ▁ is ▁ true , ▁ then ▁ not ▁ saving ▁ in ▁ the ▁ editor STRNEWLINE ▁ will ▁ make ▁ the ▁ return ▁ value ▁ become ▁ ` None ` . STRNEWLINE ▁ : param ▁ extension : ▁ the ▁ extension ▁ to ▁ tell ▁ the ▁ editor ▁ about . ▁ This ▁ defaults STRNEWLINE ▁ to ▁ ` . txt ` ▁ but ▁ changing ▁ this ▁ might ▁ change ▁ syntax STRNEWLINE ▁ highlighting . STRNEWLINE ▁ : param ▁ filename : ▁ if ▁ provided ▁ it ▁ will ▁ edit ▁ this ▁ file ▁ instead ▁ of ▁ the STRNEWLINE ▁ provided ▁ text ▁ contents . ▁ It ▁ will ▁ not ▁ use ▁ a ▁ temporary STRNEWLINE ▁ file ▁ as ▁ an ▁ indirection ▁ in ▁ that ▁ case . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import Editor NEW_LINE editor = Editor ( editor = editor , env = env , require_save = require_save , extension = extension ) NEW_LINE if filename is None : NEW_LINE INDENT return editor . edit ( text ) NEW_LINE DEDENT editor . edit_file ( filename ) NEW_LINE DEDENT def launch ( url , wait = False , locate = False ) : NEW_LINE INDENT """ This ▁ function ▁ launches ▁ the ▁ given ▁ URL ▁ ( or ▁ filename ) ▁ in ▁ the ▁ default STRNEWLINE ▁ viewer ▁ application ▁ for ▁ this ▁ file ▁ type . ▁ If ▁ this ▁ is ▁ an ▁ executable , ▁ it STRNEWLINE ▁ might ▁ launch ▁ the ▁ executable ▁ in ▁ a ▁ new ▁ session . ▁ The ▁ return ▁ value ▁ is STRNEWLINE ▁ the ▁ exit ▁ code ▁ of ▁ the ▁ launched ▁ application . ▁ Usually , ▁ ` ` 0 ` ` ▁ indicates STRNEWLINE ▁ success . STRNEWLINE STRNEWLINE ▁ Examples : : STRNEWLINE STRNEWLINE ▁ click . launch ( ' http : / / click . pocoo . org / ' ) STRNEWLINE ▁ click . launch ( ' / my / downloaded / file ' , ▁ locate = True ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ url : ▁ URL ▁ or ▁ filename ▁ of ▁ the ▁ thing ▁ to ▁ launch . STRNEWLINE ▁ : param ▁ wait : ▁ waits ▁ for ▁ the ▁ program ▁ to ▁ stop . STRNEWLINE ▁ : param ▁ locate : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ ` True ` ▁ then ▁ instead ▁ of ▁ launching ▁ the STRNEWLINE ▁ application ▁ associated ▁ with ▁ the ▁ URL ▁ it ▁ will ▁ attempt ▁ to STRNEWLINE ▁ launch ▁ a ▁ file ▁ manager ▁ with ▁ the ▁ file ▁ located . ▁ This STRNEWLINE ▁ might ▁ have ▁ weird ▁ effects ▁ if ▁ the ▁ URL ▁ does ▁ not ▁ point ▁ to STRNEWLINE ▁ the ▁ filesystem . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import open_url NEW_LINE return open_url ( url , wait = wait , locate = locate ) NEW_LINE # ▁ If ▁ this ▁ is ▁ provided , ▁ getchar ( ) ▁ calls ▁ into ▁ this ▁ instead . ▁ This ▁ is ▁ used ENDCOM # ▁ for ▁ unittesting ▁ purposes . ENDCOM DEDENT _getchar = None NEW_LINE def getchar ( echo = False ) : NEW_LINE INDENT """ Fetches ▁ a ▁ single ▁ character ▁ from ▁ the ▁ terminal ▁ and ▁ returns ▁ it . ▁ This STRNEWLINE ▁ will ▁ always ▁ return ▁ a ▁ unicode ▁ character ▁ and ▁ under ▁ certain ▁ rare STRNEWLINE ▁ circumstances ▁ this ▁ might ▁ return ▁ more ▁ than ▁ one ▁ character . ▁ The STRNEWLINE ▁ situations ▁ which ▁ more ▁ than ▁ one ▁ character ▁ is ▁ returned ▁ is ▁ when ▁ for STRNEWLINE ▁ whatever ▁ reason ▁ multiple ▁ characters ▁ end ▁ up ▁ in ▁ the ▁ terminal ▁ buffer ▁ or STRNEWLINE ▁ standard ▁ input ▁ was ▁ not ▁ actually ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ Note ▁ that ▁ this ▁ will ▁ always ▁ read ▁ from ▁ the ▁ terminal , ▁ even ▁ if ▁ something STRNEWLINE ▁ is ▁ piped ▁ into ▁ the ▁ standard ▁ input . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ echo : ▁ if ▁ set ▁ to ▁ ` True ` , ▁ the ▁ character ▁ read ▁ will ▁ also ▁ show ▁ up ▁ on STRNEWLINE ▁ the ▁ terminal . ▁ The ▁ default ▁ is ▁ to ▁ not ▁ show ▁ it . STRNEWLINE ▁ """ NEW_LINE f = _getchar NEW_LINE if f is None : NEW_LINE INDENT from . _termui_impl import getchar as f NEW_LINE DEDENT return f ( echo ) NEW_LINE DEDENT def pause ( info = ' Press ▁ any ▁ key ▁ to ▁ continue ▁ . . . ' , err = False ) : NEW_LINE INDENT """ This ▁ command ▁ stops ▁ execution ▁ and ▁ waits ▁ for ▁ the ▁ user ▁ to ▁ press ▁ any STRNEWLINE ▁ key ▁ to ▁ continue . ▁ This ▁ is ▁ similar ▁ to ▁ the ▁ Windows ▁ batch ▁ " pause " STRNEWLINE ▁ command . ▁ If ▁ the ▁ program ▁ is ▁ not ▁ run ▁ through ▁ a ▁ terminal , ▁ this ▁ command STRNEWLINE ▁ will ▁ instead ▁ do ▁ nothing . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ info : ▁ the ▁ info ▁ string ▁ to ▁ print ▁ before ▁ pausing . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ message ▁ goes ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE if not isatty ( sys . stdin ) or not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE DEDENT try : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( info , nl = False , err = err ) NEW_LINE DEDENT try : NEW_LINE INDENT getchar ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT finally : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( err = err ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
