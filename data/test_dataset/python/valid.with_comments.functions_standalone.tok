def cmdForFile ( f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ▁ - - extra = + q ' ENDCOM # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + Ki ▁ - f ▁ - ' ENDCOM DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT
def ct_query ( filename ) : NEW_LINE INDENT args = cmdForFile ( filename ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( filename ) NEW_LINE try : NEW_LINE INDENT proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = _eintr_retry_call ( proc . communicate ) NEW_LINE out_data = out_data . split ( ' \n ' ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT out_data = [ ' Failed ▁ to ▁ run ▁ ctags ▁ cmd\tignore\t0 ; \t ▁ ' , ' cmd : ▁ % s\tignore\t0 ; \t ▁ ' % ' ▁ ' . join ( args ) , ' error : ▁ % s\tignore\t0 ; \t ▁ ' % str ( e ) , ' ctags ▁ not ▁ installed ▁ ? \tignore\t0 ; \t ▁ ' , ] NEW_LINE DEDENT res = [ ] NEW_LINE for line in out_data : NEW_LINE INDENT if ( line == ' ' ) : NEW_LINE INDENT break NEW_LINE DEDENT line = line . split ( ' \t ' ) NEW_LINE num = line [ 2 ] . split ( ' ; ' , 1 ) [ 0 ] NEW_LINE line = [ line [ 0 ] , num , line [ 3 ] ] NEW_LINE res . append ( line ) NEW_LINE DEDENT return res NEW_LINE DEDENT
def emptyOrderedDict ( ) : NEW_LINE INDENT if is_OrderedDict_available : NEW_LINE INDENT return OrderedDict ( { } ) NEW_LINE DEDENT return { } NEW_LINE DEDENT
def ct_tree_query ( filename ) : NEW_LINE INDENT ct = CtagsTreeBuilder ( ) NEW_LINE output = ct . doQuery ( filename ) NEW_LINE return output NEW_LINE DEDENT
def header ( map_file_name ) : NEW_LINE INDENT """ STRNEWLINE STRNEWLINE ▁ This ▁ function ▁ will ▁ return ▁ a ▁ dict ▁ of ▁ header ▁ details ▁ from ▁ map ▁ file STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : return : ▁ header ▁ details STRNEWLINE STRNEWLINE ▁ : rtype : ▁ dict STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if os . path . exists ( map_file_name ) : NEW_LINE INDENT nap_header = kip_reader . header ( map_file_name ) NEW_LINE return nap_header NEW_LINE DEDENT return None NEW_LINE # ▁ Copyright ▁ 2008-2012 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited ▁ ( ACN ▁ 127 ▁ 184 ▁ 954 ) ▁ ( Dr . ▁ D ▁ Studios ) ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ anim - studio - tools . ENDCOM # ▁ anim - studio - tools ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ anim - studio - tools ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ anim - studio - tools . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM DEDENT
def run ( command , ** kwargs ) : NEW_LINE INDENT fail_hard = kwargs . pop ( " fail _ hard " , True ) NEW_LINE # ▁ output ▁ to ▁ / dev / null ▁ by ▁ default : ENDCOM kwargs . setdefault ( " stdout " , open ( ' / dev / null ' , ' w ' ) ) NEW_LINE kwargs . setdefault ( " stderr " , open ( ' / dev / null ' , ' w ' ) ) NEW_LINE command = Template ( command ) . substitute ( os . environ ) NEW_LINE if " TRACE " in os . environ : NEW_LINE INDENT if ' cwd ' in kwargs : NEW_LINE INDENT print ( " [ cwd = % s ] ▁ % s " % ( kwargs [ ' cwd ' ] , command ) ) NEW_LINE DEDENT else : print ( command ) NEW_LINE DEDENT try : NEW_LINE INDENT process = subprocess . Popen ( command . split ( ' ▁ ' ) , ** kwargs ) NEW_LINE process . wait ( ) NEW_LINE DEDENT except KeyboardInterrupt : NEW_LINE INDENT process . terminate ( ) NEW_LINE raise NEW_LINE DEDENT if process . returncode != 0 and fail_hard : NEW_LINE INDENT raise RunError ( " Failed : ▁ " + command ) NEW_LINE DEDENT return process . returncode NEW_LINE DEDENT
def checkout_pull ( clone_url , commit , out ) : NEW_LINE # ▁ Init ENDCOM INDENT build_dir = os . environ [ " BUILD _ DIR " ] NEW_LINE run ( " umount ▁ $ { CHROOT _ COPY } / proc " , fail_hard = False ) NEW_LINE run ( " rsync ▁ - - delete ▁ - apv ▁ $ { CHROOT _ MASTER } / ▁ $ { CHROOT _ COPY } " ) NEW_LINE run ( " rm ▁ - rf ▁ $ { CHROOT _ COPY } $ { SCRIPTS _ DIR } " ) NEW_LINE run ( " cp ▁ - a ▁ $ { SCRIPTS _ DIR } ▁ $ { CHROOT _ COPY } $ { SCRIPTS _ DIR } " ) NEW_LINE # ▁ Merge ▁ onto ▁ upstream / master ENDCOM run ( " rm ▁ - rf ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " mkdir ▁ - p ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " git ▁ clone ▁ $ { CLONE _ URL } ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " git ▁ remote ▁ add ▁ pull ▁ " + clone_url , cwd = build_dir , stdout = out , stderr = out ) NEW_LINE run ( " git ▁ fetch ▁ pull " , cwd = build_dir , stdout = out , stderr = out ) NEW_LINE if run ( " git ▁ merge ▁ " + commit , fail_hard = False , cwd = build_dir , stdout = out , stderr = out ) != 0 : NEW_LINE INDENT return False NEW_LINE DEDENT run ( " chown ▁ - R ▁ $ { BUILD _ USER } : $ { BUILD _ GROUP } ▁ $ { BUILD _ DIR } " , stdout = out , stderr = out ) NEW_LINE run ( " mount ▁ - - bind ▁ / proc ▁ $ { CHROOT _ COPY } / proc " ) NEW_LINE return True NEW_LINE DEDENT
def commentOn ( commentUrl , success , inMerge , needTests , linkUrl ) : NEW_LINE INDENT common_message = """ STRNEWLINE This ▁ test ▁ script ▁ verifies ▁ pulls ▁ every ▁ time ▁ they ▁ are ▁ updated . ▁ It , ▁ however , ▁ dies ▁ sometimes ▁ and ▁ fails ▁ to ▁ test ▁ properly . ▁ ▁ If ▁ you ▁ are ▁ waiting ▁ on ▁ a ▁ test , ▁ please ▁ check ▁ timestamps ▁ to ▁ verify ▁ that ▁ the ▁ test . log ▁ is ▁ moving ▁ at ▁ http : / / jenkins . bluematt . me / pull - tester / current / STRNEWLINE Contact ▁ BlueMatt ▁ on ▁ freenode ▁ if ▁ something ▁ looks ▁ broken . """ NEW_LINE # ▁ Remove ▁ old ▁ BitcoinPullTester ▁ comments ▁ ( I ' m ▁ being ▁ lazy ▁ and ▁ not ▁ paginating ▁ here ) ENDCOM recentcomments = requests . get ( commentUrl + " ? sort = created & direction = desc " , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE for comment in recentcomments : NEW_LINE INDENT if comment [ " user " ] [ " login " ] == os . environ [ " GITHUB _ USER " ] and common_message in comment [ " body " ] : NEW_LINE INDENT requests . delete ( comment [ " url " ] , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) NEW_LINE DEDENT DEDENT if success == True : NEW_LINE INDENT if needTests : NEW_LINE INDENT message = " Automatic ▁ sanity - testing : ▁ PLEASE ▁ ADD ▁ TEST - CASES , ▁ though ▁ technically ▁ passed . ▁ See ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " NEW_LINE DEDENT else : NEW_LINE INDENT message = " Automatic ▁ sanity - testing : ▁ PASSED , ▁ see ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " NEW_LINE DEDENT post_data = { " body " : message + common_message } NEW_LINE DEDENT elif inMerge : NEW_LINE INDENT post_data = { " body " : " Automatic ▁ sanity - testing : ▁ FAILED ▁ MERGE , ▁ see ▁ " + linkUrl + " ▁ for ▁ test ▁ log . " + """ STRNEWLINE STRNEWLINE This ▁ pull ▁ does ▁ not ▁ merge ▁ cleanly ▁ onto ▁ current ▁ master """ + common_message } NEW_LINE DEDENT else : NEW_LINE INDENT post_data = { " body " : " Automatic ▁ sanity - testing : ▁ FAILED ▁ BUILD / TEST , ▁ see ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " + """ STRNEWLINE STRNEWLINE This ▁ could ▁ happen ▁ for ▁ one ▁ of ▁ several ▁ reasons : STRNEWLINE 1 . ▁ It ▁ chanages ▁ changes ▁ build ▁ scripts ▁ in ▁ a ▁ way ▁ that ▁ made ▁ them ▁ incompatible ▁ with ▁ the ▁ automated ▁ testing ▁ scripts ▁ ( please ▁ tweak ▁ those ▁ patches ▁ in ▁ qa / pull - tester ) STRNEWLINE 2 . ▁ It ▁ adds / modifies ▁ tests ▁ which ▁ test ▁ network ▁ rules ▁ ( thanks ▁ for ▁ doing ▁ that ) , ▁ which ▁ conflicts ▁ with ▁ a ▁ patch ▁ applied ▁ at ▁ test ▁ time STRNEWLINE 3 . ▁ It ▁ does ▁ not ▁ build ▁ on ▁ either ▁ Linux ▁ i386 ▁ or ▁ Win32 ▁ ( via ▁ MinGW ▁ cross ▁ compile ) STRNEWLINE 4 . ▁ The ▁ test ▁ suite ▁ fails ▁ on ▁ either ▁ Linux ▁ i386 ▁ or ▁ Win32 STRNEWLINE 5 . ▁ The ▁ block ▁ test - cases ▁ failed ▁ ( lookup ▁ the ▁ first ▁ bNN ▁ identifier ▁ which ▁ failed ▁ in ▁ https : / / github . com / TheBlueMatt / test - scripts / blob / master / FullBlockTestGenerator . java ) STRNEWLINE STRNEWLINE If ▁ you ▁ believe ▁ this ▁ to ▁ be ▁ in ▁ error , ▁ please ▁ ping ▁ BlueMatt ▁ on ▁ freenode ▁ or ▁ TheBlueMatt ▁ here . STRNEWLINE """ + common_message } NEW_LINE DEDENT resp = requests . post ( commentUrl , json . dumps ( post_data ) , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) NEW_LINE DEDENT
def testpull ( number , comment_url , clone_url , commit ) : NEW_LINE INDENT print ( " Testing ▁ pull ▁ % d : ▁ % s ▁ : ▁ % s " % ( number , clone_url , commit ) ) NEW_LINE dir = os . environ [ " RESULTS _ DIR " ] + " / " + commit + " / " NEW_LINE print ( " ▁ ouput ▁ to ▁ % s " % dir ) NEW_LINE if os . path . exists ( dir ) : NEW_LINE INDENT os . system ( " rm ▁ - r ▁ " + dir ) NEW_LINE DEDENT os . makedirs ( dir ) NEW_LINE currentdir = os . environ [ " RESULTS _ DIR " ] + " / current " NEW_LINE os . system ( " rm ▁ - r ▁ " + currentdir ) NEW_LINE os . system ( " ln ▁ - s ▁ " + dir + " ▁ " + currentdir ) NEW_LINE out = open ( dir + " test . log " , ' w + ' ) NEW_LINE resultsurl = os . environ [ " RESULTS _ URL " ] + commit NEW_LINE checkedout = checkout_pull ( clone_url , commit , out ) NEW_LINE if checkedout != True : NEW_LINE INDENT print ( " Failed ▁ to ▁ test ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , False , True , False , resultsurl ) NEW_LINE open ( os . environ [ " TESTED _ DB " ] , " a " ) . write ( commit + " \n " ) NEW_LINE return NEW_LINE DEDENT run ( " rm ▁ - rf ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) ; NEW_LINE run ( " mkdir ▁ - p ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) ; NEW_LINE run ( " chown ▁ - R ▁ $ { BUILD _ USER } : $ { BUILD _ GROUP } ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) NEW_LINE script = os . environ [ " BUILD _ PATH " ] + " / qa / pull - tester / pull - tester . sh " NEW_LINE script += " ▁ $ { BUILD _ PATH } ▁ $ { MINGW _ DEPS _ DIR } ▁ $ { SCRIPTS _ DIR } / BitcoindComparisonTool _ jar / BitcoindComparisonTool . jar ▁ 0 ▁ 6 ▁ $ { OUT _ DIR } " NEW_LINE returncode = run ( " chroot ▁ $ { CHROOT _ COPY } ▁ sudo ▁ - u ▁ $ { BUILD _ USER } ▁ - H ▁ timeout ▁ $ { TEST _ TIMEOUT } ▁ " + script , fail_hard = False , stdout = out , stderr = out ) NEW_LINE run ( " mv ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } ▁ " + dir ) NEW_LINE run ( " mv ▁ $ { BUILD _ DIR } ▁ " + dir ) NEW_LINE if returncode == 42 : NEW_LINE INDENT print ( " Successfully ▁ tested ▁ pull ▁ ( needs ▁ tests ) ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , True , False , True , resultsurl ) NEW_LINE DEDENT elif returncode != 0 : NEW_LINE INDENT print ( " Failed ▁ to ▁ test ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , False , False , False , resultsurl ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " Successfully ▁ tested ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , True , False , False , resultsurl ) NEW_LINE DEDENT open ( os . environ [ " TESTED _ DB " ] , " a " ) . write ( commit + " \n " ) NEW_LINE DEDENT
def environ_default ( setting , value ) : NEW_LINE INDENT if not setting in os . environ : NEW_LINE INDENT os . environ [ setting ] = value NEW_LINE DEDENT DEDENT
def _sort_locations ( locations , expand_dir = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Sort ▁ locations ▁ into ▁ " files " ▁ ( archives ) ▁ and ▁ " urls " , ▁ and ▁ return STRNEWLINE ▁ a ▁ pair ▁ of ▁ lists ▁ ( files , urls ) STRNEWLINE ▁ """ NEW_LINE files = [ ] NEW_LINE urls = [ ] NEW_LINE # ▁ puts ▁ the ▁ url ▁ for ▁ the ▁ given ▁ file ▁ path ▁ into ▁ the ▁ appropriate ▁ list ENDCOM def sort_path ( path ) : NEW_LINE INDENT url = path_to_url ( path ) NEW_LINE if mimetypes . guess_type ( url , strict = False ) [ 0 ] == ' text / html ' : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT else : NEW_LINE INDENT files . append ( url ) NEW_LINE DEDENT DEDENT for url in locations : NEW_LINE INDENT is_local_path = os . path . exists ( url ) NEW_LINE is_file_url = url . startswith ( ' file : ' ) NEW_LINE if is_local_path or is_file_url : NEW_LINE INDENT if is_local_path : NEW_LINE INDENT path = url NEW_LINE DEDENT else : NEW_LINE INDENT path = url_to_path ( url ) NEW_LINE DEDENT if os . path . isdir ( path ) : NEW_LINE INDENT if expand_dir : NEW_LINE INDENT path = os . path . realpath ( path ) NEW_LINE for item in os . listdir ( path ) : NEW_LINE INDENT sort_path ( os . path . join ( path , item ) ) NEW_LINE DEDENT DEDENT elif is_file_url : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT elif os . path . isfile ( path ) : NEW_LINE INDENT sort_path ( path ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT return files , urls NEW_LINE DEDENT
def egg_info_matches ( egg_info , search_name , link , _egg_info_re = re . compile ( r ' ( [ a - z0-9 _ . ] + ) - ( [ a - z0-9 _ . ! + - ] + ) ' , re . I ) ) : NEW_LINE INDENT """ Pull ▁ the ▁ version ▁ part ▁ out ▁ of ▁ a ▁ string . STRNEWLINE STRNEWLINE ▁ : param ▁ egg _ info : ▁ The ▁ string ▁ to ▁ parse . ▁ E . g . ▁ foo - 2.1 STRNEWLINE ▁ : param ▁ search _ name : ▁ The ▁ name ▁ of ▁ the ▁ package ▁ this ▁ belongs ▁ to . ▁ None ▁ to STRNEWLINE ▁ infer ▁ the ▁ name . ▁ Note ▁ that ▁ this ▁ cannot ▁ unambiguously ▁ parse ▁ strings STRNEWLINE ▁ like ▁ foo - 2-2 ▁ which ▁ might ▁ be ▁ foo , ▁ 2-2 ▁ or ▁ foo - 2 , ▁ 2 . STRNEWLINE ▁ : param ▁ link : ▁ The ▁ link ▁ the ▁ string ▁ came ▁ from , ▁ for ▁ logging ▁ on ▁ failure . STRNEWLINE ▁ """ NEW_LINE match = _egg_info_re . search ( egg_info ) NEW_LINE if not match : NEW_LINE INDENT logger . debug ( ' Could ▁ not ▁ parse ▁ version ▁ from ▁ link : ▁ % s ' , link ) NEW_LINE return None NEW_LINE DEDENT if search_name is None : NEW_LINE INDENT full_match = match . group ( 0 ) NEW_LINE return full_match [ full_match . index ( ' - ' ) : ] NEW_LINE DEDENT name = match . group ( 0 ) . lower ( ) NEW_LINE # ▁ To ▁ match ▁ the ▁ " safe " ▁ name ▁ that ▁ pkg _ resources ▁ creates : ENDCOM name = name . replace ( ' _ ' , ' - ' ) NEW_LINE # ▁ project ▁ name ▁ and ▁ version ▁ must ▁ be ▁ separated ▁ by ▁ a ▁ dash ENDCOM look_for = search_name . lower ( ) + " - " NEW_LINE if name . startswith ( look_for ) : NEW_LINE INDENT return match . group ( 0 ) [ len ( look_for ) : ] NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT
def get_page ( cls , link , skip_archives = True , session = None ) : NEW_LINE INDENT if session is None : NEW_LINE INDENT raise TypeError ( " get _ page ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ ' session ' " ) NEW_LINE DEDENT url = link . url NEW_LINE url = url . split ( ' # ' , 1 ) [ 0 ] NEW_LINE # ▁ Check ▁ for ▁ VCS ▁ schemes ▁ that ▁ do ▁ not ▁ support ▁ lookup ▁ as ▁ web ▁ pages . ENDCOM from pip . vcs import VcsSupport NEW_LINE for scheme in VcsSupport . schemes : NEW_LINE INDENT if url . lower ( ) . startswith ( scheme ) and url [ len ( scheme ) ] in ' + : ' : NEW_LINE INDENT logger . debug ( ' Cannot ▁ look ▁ at ▁ % s ▁ URL ▁ % s ' , scheme , link ) NEW_LINE return None NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT if skip_archives : NEW_LINE INDENT filename = link . filename NEW_LINE for bad_ext in ARCHIVE_EXTENSIONS : NEW_LINE INDENT if filename . endswith ( bad_ext ) : NEW_LINE INDENT content_type = cls . _get_content_type ( url , session = session , ) NEW_LINE if content_type . lower ( ) . startswith ( ' text / html ' ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT DEDENT DEDENT DEDENT logger . debug ( ' Getting ▁ page ▁ % s ' , url ) NEW_LINE # ▁ Tack ▁ index . html ▁ onto ▁ file : / / ▁ URLs ▁ that ▁ point ▁ to ▁ directories ENDCOM ( scheme , netloc , path , params , query , fragment ) = urllib_parse . urlparse ( url ) NEW_LINE if ( scheme == ' file ' and os . path . isdir ( urllib_request . url2pathname ( path ) ) ) : NEW_LINE # ▁ add ▁ trailing ▁ slash ▁ if ▁ not ▁ present ▁ so ▁ urljoin ▁ doesn ' t ▁ trim ENDCOM # ▁ final ▁ segment ENDCOM INDENT if not url . endswith ( ' / ' ) : NEW_LINE INDENT url += ' / ' NEW_LINE DEDENT url = urllib_parse . urljoin ( url , ' index . html ' ) NEW_LINE logger . debug ( ' ▁ file : ▁ URL ▁ is ▁ directory , ▁ getting ▁ % s ' , url ) NEW_LINE DEDENT resp = session . get ( url , headers = { " Accept " : " text / html " , " Cache - Control " : " max - age = 600" , } , ) NEW_LINE resp . raise_for_status ( ) NEW_LINE # ▁ The ▁ check ▁ for ▁ archives ▁ above ▁ only ▁ works ▁ if ▁ the ▁ url ▁ ends ▁ with ENDCOM # ▁ something ▁ that ▁ looks ▁ like ▁ an ▁ archive . ▁ However ▁ that ▁ is ▁ not ▁ a ENDCOM # ▁ requirement ▁ of ▁ an ▁ url . ▁ Unless ▁ we ▁ issue ▁ a ▁ HEAD ▁ request ▁ on ▁ every ENDCOM # ▁ url ▁ we ▁ cannot ▁ know ▁ ahead ▁ of ▁ time ▁ for ▁ sure ▁ if ▁ something ▁ is ▁ HTML ENDCOM # ▁ or ▁ not . ▁ However ▁ we ▁ can ▁ check ▁ after ▁ we ' ve ▁ downloaded ▁ it . ENDCOM content_type = resp . headers . get ( ' Content - Type ' , ' unknown ' ) NEW_LINE if not content_type . lower ( ) . startswith ( " text / html " ) : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT inst = cls ( resp . content , resp . url , resp . headers , trusted = link . trusted , ) NEW_LINE DEDENT except requests . HTTPError as exc : NEW_LINE INDENT level = 2 if exc . response . status_code == 404 else 1 NEW_LINE cls . _handle_fail ( link , exc , url , level = level ) NEW_LINE DEDENT except requests . ConnectionError as exc : NEW_LINE INDENT cls . _handle_fail ( link , " connection ▁ error : ▁ % s " % exc , url ) NEW_LINE DEDENT except requests . Timeout : NEW_LINE INDENT cls . _handle_fail ( link , " timed ▁ out " , url ) NEW_LINE DEDENT except SSLError as exc : NEW_LINE INDENT reason = ( " There ▁ was ▁ a ▁ problem ▁ confirming ▁ the ▁ ssl ▁ certificate : ▁ " " % s " % exc ) NEW_LINE cls . _handle_fail ( link , reason , url , level = 2 , meth = logger . info ) NEW_LINE DEDENT else : NEW_LINE INDENT return inst NEW_LINE DEDENT DEDENT
def _handle_fail ( link , reason , url , level = 1 , meth = None ) : NEW_LINE INDENT if meth is None : NEW_LINE INDENT meth = logger . debug NEW_LINE DEDENT meth ( " Could ▁ not ▁ fetch ▁ URL ▁ % s : ▁ % s ▁ - ▁ skipping " , link , reason ) NEW_LINE DEDENT
def _get_content_type ( url , session ) : NEW_LINE INDENT """ Get ▁ the ▁ Content - Type ▁ of ▁ the ▁ given ▁ url , ▁ using ▁ a ▁ HEAD ▁ request """ NEW_LINE scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( url ) NEW_LINE if scheme not in ( ' http ' , ' https ' ) : NEW_LINE # ▁ FIXME : ▁ some ▁ warning ▁ or ▁ something ? ENDCOM # ▁ assertion ▁ error ? ENDCOM INDENT return ' ' NEW_LINE DEDENT resp = session . head ( url , allow_redirects = True ) NEW_LINE resp . raise_for_status ( ) NEW_LINE return resp . headers . get ( " Content - Type " , " " ) NEW_LINE DEDENT
def fmt_ctl_handle_mutual_exclude ( value , target , other ) : NEW_LINE INDENT new = value . split ( ' , ' ) NEW_LINE while ' : all : ' in new : NEW_LINE INDENT other . clear ( ) NEW_LINE target . clear ( ) NEW_LINE target . add ( ' : all : ' ) NEW_LINE del new [ : new . index ( ' : all : ' ) + 1 ] NEW_LINE if ' : none : ' not in new : NEW_LINE # ▁ Without ▁ a ▁ none , ▁ we ▁ want ▁ to ▁ discard ▁ everything ▁ as ▁ : all : ▁ covers ▁ it ENDCOM INDENT return NEW_LINE DEDENT DEDENT for name in new : NEW_LINE INDENT if name == ' : none : ' : NEW_LINE INDENT target . clear ( ) NEW_LINE continue NEW_LINE DEDENT name = pkg_resources . safe_name ( name ) . lower ( ) NEW_LINE other . discard ( name ) NEW_LINE target . add ( name ) NEW_LINE DEDENT DEDENT
def fmt_ctl_formats ( fmt_ctl , canonical_name ) : NEW_LINE INDENT result = set ( [ " binary " , " source " ] ) NEW_LINE if canonical_name in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif canonical_name in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT return frozenset ( result ) NEW_LINE DEDENT
def fmt_ctl_no_binary ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_handle_mutual_exclude ( ' : all : ' , fmt_ctl . no_binary , fmt_ctl . only_binary ) NEW_LINE DEDENT
def fmt_ctl_no_use_wheel ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_no_binary ( fmt_ctl ) NEW_LINE warnings . warn ( ' - - no - use - wheel ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ removed ▁ in ▁ the ▁ future . ▁ ' ' ▁ Please ▁ use ▁ - - no - binary ▁ : all : ▁ instead . ' , DeprecationWarning , stacklevel = 2 ) NEW_LINE DEDENT
def append_when_current_valid ( current , menu , args , level = 0 , key = " " ) : NEW_LINE INDENT if current and current . valid ( ) and level <= config . usage . setup_level . index : NEW_LINE INDENT menu . append ( ChoiceEntryComponent ( key , args ) ) NEW_LINE DEDENT DEDENT
def removed_userbouquets_available ( ) : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT
