<DOCUMENT_ID="dssg/wikienergy/tree/master/disaggregator/build/pandas/pandas/io/tests/__init__.py"> def setUp ( ) : NEW_LINE INDENT import socket NEW_LINE socket . setdefaulttimeout ( 5 ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="mbrukman/libcloud/tree/master/libcloud/test/compute/test_gogrid.py"> # ▁ Licensed ▁ to ▁ the ▁ Apache ▁ Software ▁ Foundation ▁ ( ASF ) ▁ under ▁ one ▁ or ▁ more ENDCOM # ▁ contributor ▁ license ▁ agreements . ▁ See ▁ the ▁ NOTICE ▁ file ▁ distributed ▁ with ENDCOM # ▁ this ▁ work ▁ for ▁ additional ▁ information ▁ regarding ▁ copyright ▁ ownership . ENDCOM # ▁ The ▁ ASF ▁ licenses ▁ this ▁ file ▁ to ▁ You ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ENDCOM # ▁ ( the ▁ " License " ) ; ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ENDCOM # ▁ the ▁ License . ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM import sys NEW_LINE import unittest NEW_LINE from libcloud . utils . py3 import httplib NEW_LINE from libcloud . utils . py3 import urlparse NEW_LINE from libcloud . utils . py3 import parse_qs NEW_LINE from libcloud . compute . base import NodeState , NodeLocation NEW_LINE from libcloud . common . types import LibcloudError , InvalidCredsError NEW_LINE from libcloud . common . gogrid import GoGridIpAddress NEW_LINE from libcloud . compute . drivers . gogrid import GoGridNodeDriver NEW_LINE from libcloud . compute . base import Node , NodeImage , NodeSize NEW_LINE from libcloud . test import MockHttp # ▁ pylint : ▁ disable - msg = E0611 ENDCOM NEW_LINE from libcloud . test . compute import TestCaseMixin # ▁ pylint : ▁ disable - msg = E0611 ENDCOM NEW_LINE from libcloud . test . file_fixtures import ComputeFileFixtures # ▁ pylint : ▁ disable - msg = E0611 ENDCOM NEW_LINE class GoGridTests ( unittest . TestCase , TestCaseMixin ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT GoGridNodeDriver . connectionCls . conn_classes = ( None , GoGridMockHttp ) NEW_LINE GoGridMockHttp . type = None NEW_LINE self . driver = GoGridNodeDriver ( " foo " , " bar " ) NEW_LINE DEDENT def _get_test_512Mb_node_size ( self ) : NEW_LINE INDENT return NodeSize ( id = '512Mb ' , name = None , ram = None , disk = None , bandwidth = None , price = None , driver = self . driver ) NEW_LINE DEDENT def test_create_node ( self ) : NEW_LINE INDENT image = NodeImage ( 1531 , None , self . driver ) NEW_LINE node = self . driver . create_node ( name = ' test1' , image = image , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE self . assertEqual ( node . name , ' test1' ) NEW_LINE self . assertTrue ( node . id is not None ) NEW_LINE self . assertEqual ( node . extra [ ' password ' ] , ' bebebe ' ) NEW_LINE DEDENT def test_list_nodes ( self ) : NEW_LINE INDENT node = self . driver . list_nodes ( ) [ 0 ] NEW_LINE self . assertEqual ( node . id , '90967' ) NEW_LINE self . assertEqual ( node . extra [ ' password ' ] , ' bebebe ' ) NEW_LINE self . assertEqual ( node . extra [ ' description ' ] , ' test ▁ server ' ) NEW_LINE DEDENT def test_reboot_node ( self ) : NEW_LINE INDENT node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE ret = self . driver . reboot_node ( node ) NEW_LINE self . assertTrue ( ret ) NEW_LINE DEDENT def test_reboot_node_not_successful ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE try : NEW_LINE INDENT self . driver . reboot_node ( node ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Exception ▁ was ▁ not ▁ thrown ' ) NEW_LINE DEDENT DEDENT def test_destroy_node ( self ) : NEW_LINE INDENT node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE ret = self . driver . destroy_node ( node ) NEW_LINE self . assertTrue ( ret ) NEW_LINE DEDENT def test_list_images ( self ) : NEW_LINE INDENT images = self . driver . list_images ( ) NEW_LINE image = images [ 0 ] NEW_LINE self . assertEqual ( len ( images ) , 4 ) NEW_LINE self . assertEqual ( image . name , ' CentOS ▁ 5.3 ▁ ( 32 - bit ) ▁ w / ▁ None ' ) NEW_LINE self . assertEqual ( image . id , '1531' ) NEW_LINE location = NodeLocation ( id = ' gogrid / GSI - 939ef909-84b8-4a2f - ad56-02ccd7da05ff . img ' , name = ' test ▁ location ' , country = ' Slovenia ' , driver = self . driver ) NEW_LINE images = self . driver . list_images ( location = location ) NEW_LINE image = images [ 0 ] NEW_LINE self . assertEqual ( len ( images ) , 4 ) NEW_LINE self . assertEqual ( image . name , ' CentOS ▁ 5.3 ▁ ( 32 - bit ) ▁ w / ▁ None ' ) NEW_LINE self . assertEqual ( image . id , '1531' ) NEW_LINE DEDENT def test_malformed_reply ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE try : NEW_LINE INDENT self . driver . list_images ( ) NEW_LINE DEDENT except LibcloudError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( isinstance ( e , LibcloudError ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_invalid_creds ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE try : NEW_LINE INDENT self . driver . list_nodes ( ) NEW_LINE DEDENT except InvalidCredsError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( e . driver is not None ) NEW_LINE self . assertEqual ( e . driver . name , self . driver . name ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_node_creation_without_free_public_ips ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' NOPUBIPS ' NEW_LINE try : NEW_LINE INDENT image = NodeImage ( 1531 , None , self . driver ) NEW_LINE self . driver . create_node ( name = ' test1' , image = image , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE DEDENT except LibcloudError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( isinstance ( e , LibcloudError ) ) NEW_LINE self . assertTrue ( e . driver is not None ) NEW_LINE self . assertEqual ( e . driver . name , self . driver . name ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_list_locations ( self ) : NEW_LINE INDENT locations = self . driver . list_locations ( ) NEW_LINE location_names = [ location . name for location in locations ] NEW_LINE self . assertEqual ( len ( locations ) , 2 ) NEW_LINE for i in 0 , 1 : NEW_LINE INDENT self . assertTrue ( isinstance ( locations [ i ] , NodeLocation ) ) NEW_LINE DEDENT self . assertTrue ( " US - West - 1" in location_names ) NEW_LINE self . assertTrue ( " US - East - 1" in location_names ) NEW_LINE DEDENT def test_ex_save_image ( self ) : NEW_LINE INDENT node = self . driver . list_nodes ( ) [ 0 ] NEW_LINE image = self . driver . ex_save_image ( node , " testimage " ) NEW_LINE self . assertEqual ( image . name , " testimage " ) NEW_LINE DEDENT def test_ex_edit_image ( self ) : NEW_LINE INDENT image = self . driver . list_images ( ) [ 0 ] NEW_LINE ret = self . driver . ex_edit_image ( image = image , public = False , ex_description = " test " , name = " testname " ) NEW_LINE self . assertTrue ( isinstance ( ret , NodeImage ) ) NEW_LINE DEDENT def test_ex_edit_node ( self ) : NEW_LINE INDENT node = Node ( id = 90967 , name = None , state = None , public_ips = None , private_ips = None , driver = self . driver ) NEW_LINE ret = self . driver . ex_edit_node ( node = node , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE self . assertTrue ( isinstance ( ret , Node ) ) NEW_LINE DEDENT def test_ex_list_ips ( self ) : NEW_LINE INDENT ips = self . driver . ex_list_ips ( ) NEW_LINE expected_ips = { "192.168.75.66" : GoGridIpAddress ( id = "5348099" , ip = "192.168.75.66" , public = True , state = " Unassigned " , subnet = "192.168.75.64/255.255.255.240" ) , "192.168.75.67" : GoGridIpAddress ( id = "5348100" , ip = "192.168.75.67" , public = True , state = " Assigned " , subnet = "192.168.75.64/255.255.255.240" ) , "192.168.75.68" : GoGridIpAddress ( id = "5348101" , ip = "192.168.75.68" , public = False , state = " Unassigned " , subnet = "192.168.75.64/255.255.255.240" ) } NEW_LINE self . assertEqual ( len ( expected_ips ) , 3 ) NEW_LINE for ip in ips : NEW_LINE INDENT self . assertTrue ( ip . ip in expected_ips ) NEW_LINE self . assertEqual ( ip . public , expected_ips [ ip . ip ] . public ) NEW_LINE self . assertEqual ( ip . state , expected_ips [ ip . ip ] . state ) NEW_LINE self . assertEqual ( ip . subnet , expected_ips [ ip . ip ] . subnet ) NEW_LINE del expected_ips [ ip . ip ] NEW_LINE DEDENT self . assertEqual ( len ( expected_ips ) , 0 ) NEW_LINE DEDENT def test_get_state_invalid ( self ) : NEW_LINE INDENT state = self . driver . _get_state ( ' invalid ' ) NEW_LINE self . assertEqual ( state , NodeState . UNKNOWN ) NEW_LINE DEDENT DEDENT class GoGridMockHttp ( MockHttp ) : NEW_LINE INDENT fixtures = ComputeFileFixtures ( ' gogrid ' ) NEW_LINE def _api_grid_image_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_image_list_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT body = " < h3 > some ▁ non ▁ valid ▁ json ▁ here < / h3 > " NEW_LINE return ( httplib . SERVICE_UNAVAILABLE , body , { } , httplib . responses [ httplib . SERVICE_UNAVAILABLE ] ) NEW_LINE DEDENT def _api_grid_server_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_grid_server_list_NOPUBIPS = _api_grid_server_list NEW_LINE def _api_grid_server_list_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT return ( httplib . FORBIDDEN , "123" , { } , httplib . responses [ httplib . FORBIDDEN ] ) NEW_LINE DEDENT def _api_grid_ip_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' ip _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_ip_list_NOPUBIPS ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' ip _ list _ empty . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_power ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ power . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_power_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ power _ fail . json ' ) NEW_LINE return ( httplib . NOT_FOUND , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_add ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ add . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_grid_server_add_NOPUBIPS = _api_grid_server_add NEW_LINE def _api_grid_server_delete ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ delete . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_edit ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ edit . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_support_password_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' password _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_support_password_list_NOPUBIPS = _api_support_password_list NEW_LINE def _api_grid_image_save ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ save . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_image_edit ( self , method , url , body , headers ) : NEW_LINE # ▁ edit ▁ method ▁ is ▁ quite ▁ similar ▁ to ▁ save ▁ method ▁ from ▁ the ▁ response ENDCOM # ▁ perspective ENDCOM INDENT body = self . fixtures . load ( ' image _ save . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_common_lookup_list ( self , method , url , body , headers ) : NEW_LINE INDENT _valid_lookups = ( " ip . datacenter " , ) NEW_LINE lookup = parse_qs ( urlparse . urlparse ( url ) . query ) [ " lookup " ] [ 0 ] NEW_LINE if lookup in _valid_lookups : NEW_LINE INDENT fixture_path = " lookup _ list _ % s . json " % ( lookup . replace ( " . " , " _ " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT body = self . fixtures . load ( fixture_path ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT sys . exit ( unittest . main ( ) ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="RPi-Distro/python-gpiozero/tree/master/gpiozerocli/pinout.py"> # ▁ GPIO ▁ Zero : ▁ a ▁ library ▁ for ▁ controlling ▁ the ▁ Raspberry ▁ Pi ' s ▁ GPIO ▁ pins ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2017-2019 ▁ Dave ▁ Jones ▁ < dave @ waveform . org . uk > ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2017 ▁ Ben ▁ Nuttall ▁ < ben @ bennuttall . com > ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ are ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ▁ notice , ENDCOM # ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ▁ copyright ▁ notice , ENDCOM # ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ▁ in ▁ the ▁ documentation ENDCOM # ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ the ▁ copyright ▁ holder ▁ nor ▁ the ▁ names ▁ of ▁ its ▁ contributors ENDCOM # ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ▁ this ▁ software ENDCOM # ▁ without ▁ specific ▁ prior ▁ written ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ▁ " AS ▁ IS " ENDCOM # ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ THE ENDCOM # ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ENDCOM # ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ COPYRIGHT ▁ HOLDER ▁ OR ▁ CONTRIBUTORS ▁ BE ENDCOM # ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ▁ INCIDENTAL , ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ENDCOM # ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ▁ BUT ▁ NOT ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ENDCOM # ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ENDCOM # ▁ INTERRUPTION ) ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ENDCOM # ▁ CONTRACT , ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ENDCOM # ▁ ARISING ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ENDCOM # ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM """ STRNEWLINE A ▁ utility ▁ for ▁ querying ▁ Raspberry ▁ Pi ▁ GPIO ▁ pin - out ▁ information . STRNEWLINE """ NEW_LINE from __future__ import ( unicode_literals , absolute_import , print_function , division , ) NEW_LINE import argparse NEW_LINE import sys NEW_LINE import textwrap NEW_LINE import warnings NEW_LINE import webbrowser NEW_LINE from gpiozero import pi_info NEW_LINE class PinoutTool ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . parser = argparse . ArgumentParser ( description = __doc__ ) NEW_LINE self . parser . add_argument ( ' - r ' , ' - - revision ' , dest = ' revision ' , default = ' ' , help = ' RPi ▁ revision . ▁ Default ▁ is ▁ to ▁ autodetect ▁ revision ▁ of ▁ current ▁ device ' ) NEW_LINE self . parser . add_argument ( ' - c ' , ' - - color ' , action = " store _ true " , default = None , help = ' Force ▁ colored ▁ output ▁ ( by ▁ default , ▁ the ▁ output ▁ will ▁ include ▁ ANSI ' ' color ▁ codes ▁ if ▁ run ▁ in ▁ a ▁ color - capable ▁ terminal ) . ▁ See ▁ also ▁ - - monochrome ' ) NEW_LINE self . parser . add_argument ( ' - m ' , ' - - monochrome ' , dest = ' color ' , action = ' store _ false ' , help = ' Force ▁ monochrome ▁ output . ▁ See ▁ also ▁ - - color ' ) NEW_LINE self . parser . add_argument ( ' - x ' , ' - - xyz ' , dest = ' xyz ' , action = ' store _ true ' , help = ' Open ▁ pinout . xyz ▁ in ▁ the ▁ default ▁ web ▁ browser ' ) NEW_LINE DEDENT def __call__ ( self , args = None ) : NEW_LINE INDENT if args is None : NEW_LINE INDENT args = sys . argv [ 1 : ] NEW_LINE DEDENT try : NEW_LINE INDENT return self . main ( self . parser . parse_args ( args ) ) or 0 NEW_LINE DEDENT except argparse . ArgumentError as e : NEW_LINE # ▁ argparse ▁ errors ▁ are ▁ already ▁ nicely ▁ formatted , ▁ print ▁ to ▁ stderr ▁ and ENDCOM # ▁ exit ▁ with ▁ code ▁ 2 ENDCOM INDENT raise e NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT raise NEW_LINE # ▁ Output ▁ anything ▁ else ▁ nicely ▁ formatted ▁ on ▁ stderr ▁ and ▁ exit ▁ code ▁ 1 ENDCOM self . parser . exit ( 1 , ' { prog } : ▁ error : ▁ { message } \n ' . format ( prog = self . parser . prog , message = e ) ) NEW_LINE DEDENT DEDENT def main ( self , args ) : NEW_LINE INDENT warnings . simplefilter ( ' ignore ' ) NEW_LINE if args . xyz : NEW_LINE INDENT webbrowser . open ( ' https : / / pinout . xyz ' ) NEW_LINE DEDENT else : NEW_LINE INDENT if args . revision == ' ' : NEW_LINE INDENT try : NEW_LINE INDENT pi_info ( ) . pprint ( color = args . color ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT formatter = self . parser . _get_formatter ( ) NEW_LINE formatter . add_text ( " Unable ▁ to ▁ initialize ▁ GPIO ▁ Zero . ▁ This ▁ usually ▁ means ▁ " " that ▁ you ▁ are ▁ not ▁ running ▁ % ( prog ) s ▁ on ▁ a ▁ Raspberry ▁ Pi . ▁ " " If ▁ you ▁ still ▁ wish ▁ to ▁ run ▁ % ( prog ) s , ▁ set ▁ the ▁ " " GPIOZERO _ PIN _ FACTORY ▁ environment ▁ variable ▁ to ▁ ' mock ' ▁ " " and ▁ retry , ▁ or ▁ refer ▁ to ▁ the ▁ Remote ▁ GPIO ▁ section ▁ of ▁ " " the ▁ manual * ▁ to ▁ configure ▁ your ▁ environment ▁ to ▁ " " remotely ▁ access ▁ your ▁ Pi . " ) NEW_LINE formatter . add_text ( " * ▁ https : / / gpiozero . readthedocs . io / en / stable / " " remote _ gpio . html " ) NEW_LINE sys . stderr . write ( formatter . format_help ( ) ) NEW_LINE DEDENT except IOError : NEW_LINE INDENT raise IOError ( ' This ▁ device ▁ is ▁ not ▁ a ▁ Raspberry ▁ Pi ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT pi_info ( args . revision ) . pprint ( color = args . color ) NEW_LINE DEDENT formatter = self . parser . _get_formatter ( ) NEW_LINE formatter . add_text ( " For ▁ further ▁ information , ▁ please ▁ refer ▁ to ▁ " " https : / / pinout . xyz / " ) NEW_LINE sys . stdout . write ( ' \n ' ) NEW_LINE sys . stdout . write ( formatter . format_help ( ) ) NEW_LINE DEDENT DEDENT DEDENT main = PinoutTool ( ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="dentaku65/plugin.video.italyalacarta/tree/master/lib/gdata/tlslite/utils/PyCrypto_RSAKey.py"> """ PyCrypto ▁ RSA ▁ implementation . """ NEW_LINE from cryptomath import * NEW_LINE from RSAKey import * NEW_LINE from Python_RSAKey import Python_RSAKey NEW_LINE if pycryptoLoaded : NEW_LINE INDENT from Crypto . PublicKey import RSA NEW_LINE class PyCrypto_RSAKey ( RSAKey ) : NEW_LINE INDENT def __init__ ( self , n = 0 , e = 0 , d = 0 , p = 0 , q = 0 , dP = 0 , dQ = 0 , qInv = 0 ) : NEW_LINE INDENT if not d : NEW_LINE INDENT self . rsa = RSA . construct ( ( n , e ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . rsa = RSA . construct ( ( n , e , d , p , q ) ) NEW_LINE DEDENT DEDENT def __getattr__ ( self , name ) : NEW_LINE INDENT return getattr ( self . rsa , name ) NEW_LINE DEDENT def hasPrivateKey ( self ) : NEW_LINE INDENT return self . rsa . has_private ( ) NEW_LINE DEDENT def hash ( self ) : NEW_LINE INDENT return Python_RSAKey ( self . n , self . e ) . hash ( ) NEW_LINE DEDENT def _rawPrivateKeyOp ( self , m ) : NEW_LINE INDENT s = numberToString ( m ) NEW_LINE byteLength = numBytes ( self . n ) NEW_LINE if len ( s ) == byteLength : NEW_LINE INDENT pass NEW_LINE DEDENT elif len ( s ) == byteLength - 1 : NEW_LINE INDENT s = ' \0' + s NEW_LINE DEDENT else : NEW_LINE INDENT raise AssertionError ( ) NEW_LINE DEDENT c = stringToNumber ( self . rsa . decrypt ( ( s , ) ) ) NEW_LINE return c NEW_LINE DEDENT def _rawPublicKeyOp ( self , c ) : NEW_LINE INDENT s = numberToString ( c ) NEW_LINE byteLength = numBytes ( self . n ) NEW_LINE if len ( s ) == byteLength : NEW_LINE INDENT pass NEW_LINE DEDENT elif len ( s ) == byteLength - 1 : NEW_LINE INDENT s = ' \0' + s NEW_LINE DEDENT else : NEW_LINE INDENT raise AssertionError ( ) NEW_LINE DEDENT m = stringToNumber ( self . rsa . encrypt ( s , None ) [ 0 ] ) NEW_LINE return m NEW_LINE DEDENT def writeXMLPublicKey ( self , indent = ' ' ) : NEW_LINE INDENT return Python_RSAKey ( self . n , self . e ) . write ( indent ) NEW_LINE DEDENT def generate ( bits ) : NEW_LINE INDENT key = PyCrypto_RSAKey ( ) NEW_LINE def f ( numBytes ) : NEW_LINE INDENT return bytesToString ( getRandomBytes ( numBytes ) ) NEW_LINE DEDENT key . rsa = RSA . generate ( bits , f ) NEW_LINE return key NEW_LINE DEDENT generate = staticmethod ( generate ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="andrewburnheimer/ptpop/tree/master/ptpop/Console.py"> # ! / usr / local / bin / python ENDCOM ''' STRNEWLINE Console ▁ Class STRNEWLINE ''' NEW_LINE ''' STRNEWLINE To ▁ Do : STRNEWLINE ▁ - STRNEWLINE ''' NEW_LINE from Listener import Listener NEW_LINE from _version import __version__ NEW_LINE import time NEW_LINE # ▁ Console ENDCOM # ▁ Inheriting ▁ from ▁ ` object ` ▁ ( top - level ▁ class ) ENDCOM class Console ( object ) : NEW_LINE INDENT def __init__ ( self , args = None ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Console ▁ Initialization STRNEWLINE ▁ Input ▁ Attributes : STRNEWLINE ▁ - - - - - STRNEWLINE ▁ self . args ▁ - > ▁ argparse . Namespace : ▁ object ▁ holding ▁ attributes ▁ set STRNEWLINE ▁ on ▁ command - line . STRNEWLINE ▁ ''' NEW_LINE # ▁ Default ▁ Values ENDCOM delay = 3.0 NEW_LINE number = 1 # ▁ XXX ▁ should ▁ be ▁ = ▁ 0 ENDCOM NEW_LINE command = [ ] NEW_LINE interface = ' eth0' NEW_LINE listen = False NEW_LINE host = ' localhost ' NEW_LINE if args : NEW_LINE INDENT delay = float ( args . delay ) if args . delay else delay NEW_LINE number = args . number if ( args . number != None ) else number NEW_LINE command = args . command if args . command else command NEW_LINE interface = args . interface if args . interface else interface NEW_LINE listen = args . listen if args . listen else listen NEW_LINE host = args . host if args . host else host NEW_LINE # ▁ Input ▁ Checks ENDCOM DEDENT if command != [ ] : NEW_LINE INDENT raise NotImplementedError ( ' Issuing ▁ commands ▁ to ▁ hosts ▁ has ▁ ' + ' not ▁ been ▁ implemented ▁ yet ' ) NEW_LINE # ▁ init ▁ . . . ENDCOM DEDENT if listen : NEW_LINE INDENT self . listener = Listener ( interface ) NEW_LINE key = ''' STRNEWLINE remote ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ Dly ▁ St ▁ Dom ▁ Pr1 ▁ ▁ Cl ▁ Acc ▁ ▁ ▁ Var ▁ ▁ Pr2 ▁ ▁ ▁ ▁ ▁ ▁ ▁ Uniq ▁ ▁ ▁ ▁ ▁ ▁ ▁ SyncT ▁ ▁ DlyT ▁ ▁ AnnT STRNEWLINE = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ''' . strip ( ) NEW_LINE while number > 0 : NEW_LINE # ▁ Report ▁ output ▁ directly ▁ to ▁ console ENDCOM INDENT fmt = ' % a ▁ % b ▁ % d ▁ % Y ▁ % H : % M : % S ' NEW_LINE t = time . time ( ) NEW_LINE time_str = time . strftime ( fmt , time . localtime ( t ) ) NEW_LINE time_msecs = int ( ( t - int ( t ) ) * 1000 ) NEW_LINE print time_str + ' . %03d ▁ ' % ( time_msecs ) + time . tzname [ 0 ] NEW_LINE print key NEW_LINE # ▁ output ▁ data ▁ seen ▁ in ▁ since ▁ last ▁ iteration ENDCOM neighbor_stats = self . listener . ptp_neighbors NEW_LINE for neighbor in neighbor_stats : NEW_LINE INDENT print self . listener . ptp_neighbors [ neighbor ] NEW_LINE DEDENT print NEW_LINE number -= 1 NEW_LINE if number <= 0 : NEW_LINE INDENT exit ( 0 ) NEW_LINE # ▁ No ▁ need ▁ to ▁ wait ▁ after ▁ the ▁ last ▁ iteration ENDCOM DEDENT time . sleep ( delay ) NEW_LINE # ▁ Enter ▁ into ▁ the ▁ interactive ▁ environment , ▁ exit ▁ when ▁ q ▁ is ENDCOM # ▁ issued ENDCOM DEDENT DEDENT else : NEW_LINE INDENT for supplied_command in command : NEW_LINE INDENT command = supplied_command . lower ( ) NEW_LINE if command == ' rv ' or command == ' readvar ' : NEW_LINE INDENT None NEW_LINE # ▁ Assuming ▁ to ▁ be ▁ similar ▁ to ▁ NTPQ ENDCOM # ▁ root @ raspberrypi : / home / puppet # ▁ ntpq ▁ - n ▁ - c ▁ rv ▁ - c ▁ peers ENDCOM # associd = 0 ▁ status = 0615 ▁ leap _ none , ▁ sync _ ntp , ▁ 1 ▁ event , ▁ clock _ sync , ENDCOM # version = " ntpd ▁ 4.2.6p5@1.2349 - o ▁ Mon ▁ Nov ▁ 2 ▁ 04:29:47 ▁ UTC ▁ 2015 ▁ ( 1 ) " , ENDCOM # processor = " armv6l " , ▁ system = " Linux / 4.1.17 + " , ▁ leap = 00 , ▁ stratum = 3 , ENDCOM # precision = - 20 , ▁ rootdelay = 2.916 , ▁ rootdisp = 60.561 , ENDCOM # refid = 3.44.174.43 , ENDCOM # reftime = da7f3666.54078831 ▁ Mon , ▁ Feb ▁ 29 ▁ 2016 ▁ 21:28:06.328 , ENDCOM # clock = da7f38cd . 57a72dc6 ▁ Mon , ▁ Feb ▁ 29 ▁ 2016 ▁ 21:38:21.342 , ENDCOM # peer = 7185 , ▁ tc = 8 , ENDCOM # mintc = 3 , ▁ offset = 9.208 , ▁ frequency = - 48.954 , ▁ sys _ jitter = 0.000 , ENDCOM # clk _ jitter = 16.919 , ▁ clk _ wander = 4.216 ENDCOM DEDENT elif command == ' peers ' : NEW_LINE INDENT None NEW_LINE # ▁ Assuming ▁ to ▁ be ▁ similar ▁ to ▁ NTPQ ENDCOM # ▁ remote ▁ refid ▁ st ▁ t ▁ when ▁ poll ▁ reach ▁ delay ▁ offset ▁ jitter ENDCOM # * useclsifl158 . tf ▁ 3.199.96.254 ▁ 2 ▁ u ▁ 14 ▁ 1024 ▁ 377 ▁ 1.582 ▁ 0.186 ▁ 0.919 ENDCOM DEDENT else : NEW_LINE INDENT raise NotImplementedError ( ' Unknown ▁ command , ▁ \ ' ' + command + ' \ ' ' ) NEW_LINE # ▁ _ _ main _ _ . py ▁ is ▁ executed ▁ when ▁ the ▁ package ▁ is ▁ instantiated ENDCOM DEDENT DEDENT DEDENT DEDENT DEDENT import argparse NEW_LINE def main ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( prog = ' ptpop ' , description = ' Gain ▁ ' + ' insight ▁ into ▁ the ▁ operations ▁ of ▁ IEEE ▁ 1588 ▁ Precision ▁ Time ▁ Protocol ▁ ' + ' domains ▁ on ▁ a ▁ network . ▁ Press ▁ the ▁ \ ' q\ ' ▁ key ▁ to ▁ quit . ' ) NEW_LINE command_choices = [ ' readvar ' , ' rv ' , ' peers ' ] NEW_LINE parser . add_argument ( ' host ' , type = str , nargs = ' ? ' , help = ' each ▁ of ▁ the ▁ ' + ' commands ▁ will ▁ be ▁ sent ▁ to ▁ the ▁ PTP ▁ servers ▁ ' + ' running ▁ on ▁ the ▁ host ▁ provided , ▁ localhost ▁ by ▁ ' + ' default . ' ) NEW_LINE parser . add_argument ( ' - c ' , ' - - command ' , type = str , action = ' append ' , help = ' a ▁ command ▁ to ▁ run ▁ on ▁ the ▁ provided ▁ host , ▁ ' + ' i . e . ▁ ' + str ( command_choices ) + ' , ▁ \ ' readvar\ ' ▁ ' + ' by ▁ default . ▁ Multiple ▁ commands ▁ can ▁ be ▁ issued . ' ) NEW_LINE parser . add_argument ( ' - i ' , ' - - interface ' , type = str , help = ' interface ▁ to ▁ issue ▁ commands ▁ on ▁ or ▁ to ▁ ' + ' observe ▁ on ▁ in ▁ listen ▁ mode . ' ) NEW_LINE parser . add_argument ( ' - l ' , ' - - listen ' , action = ' store _ true ' , help = ' don\ ' t ▁ contact ▁ any ▁ PTP ▁ servers , ▁ but ▁ ' + ' report ▁ on ▁ any ▁ services ▁ currently ▁ observed ▁ ' + ' on ▁ the ▁ network , ▁ instead . ' ) NEW_LINE parser . add_argument ( ' - d ' , ' - - delay ' , metavar = ' SECS . TENTHS ' , type = str , help = ' Specifies ▁ the ▁ delay ▁ between ▁ screen ▁ ' + ' updates ▁ when ▁ interactive . ▁ Can ▁ be ▁ changed ▁ while ▁ ' + ' running ▁ using ▁ the ▁ \ ' d\ ' ▁ key . ▁ Negative ▁ ' + ' numbers ▁ are ▁ not ▁ allowed . ▁ Setting ▁ this ▁ value ▁ ' + ' to ▁ 0 ▁ is ▁ the ▁ same ▁ as ▁ issuing ▁ the ▁ \ ' - n ▁ 1\ ' ▁ ' + ' option . ' ) NEW_LINE parser . add_argument ( ' - n ' , ' - - number ' , metavar = ' COUNT ' , type = int , help = ' Specifies ▁ the ▁ maximum ▁ number ▁ of ▁ iterations ▁ ' + ' in ▁ interactive ▁ mode ▁ before ▁ ending . ' ) NEW_LINE parser . add_argument ( ' - v ' , ' - - version ' , action = ' version ' , version = ' % ( prog ) s ▁ ' + __version__ ) NEW_LINE args = parser . parse_args ( ) NEW_LINE try : NEW_LINE INDENT c = Console ( args ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT print type ( e ) . __name__ + " : ▁ " + str ( e . message ) NEW_LINE exit ( - 1 ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="xadahiya/django/tree/master/django/contrib/admin/actions.py"> """ STRNEWLINE Built - in , ▁ globally - available ▁ admin ▁ actions . STRNEWLINE """ NEW_LINE from django . contrib import messages NEW_LINE from django . contrib . admin import helpers NEW_LINE from django . contrib . admin . utils import get_deleted_objects , model_ngettext NEW_LINE from django . core . exceptions import PermissionDenied NEW_LINE from django . db import router NEW_LINE from django . template . response import TemplateResponse NEW_LINE from django . utils . encoding import force_text NEW_LINE from django . utils . translation import ugettext as _ , ugettext_lazy NEW_LINE def delete_selected ( modeladmin , request , queryset ) : NEW_LINE INDENT """ STRNEWLINE ▁ Default ▁ action ▁ which ▁ deletes ▁ the ▁ selected ▁ objects . STRNEWLINE STRNEWLINE ▁ This ▁ action ▁ first ▁ displays ▁ a ▁ confirmation ▁ page ▁ whichs ▁ shows ▁ all ▁ the STRNEWLINE ▁ deleteable ▁ objects , ▁ or , ▁ if ▁ the ▁ user ▁ has ▁ no ▁ permission ▁ one ▁ of ▁ the ▁ related STRNEWLINE ▁ childs ▁ ( foreignkeys ) , ▁ a ▁ " permission ▁ denied " ▁ message . STRNEWLINE STRNEWLINE ▁ Next , ▁ it ▁ deletes ▁ all ▁ selected ▁ objects ▁ and ▁ redirects ▁ back ▁ to ▁ the ▁ change ▁ list . STRNEWLINE ▁ """ NEW_LINE opts = modeladmin . model . _meta NEW_LINE app_label = opts . app_label NEW_LINE # ▁ Check ▁ that ▁ the ▁ user ▁ has ▁ delete ▁ permission ▁ for ▁ the ▁ actual ▁ model ENDCOM if not modeladmin . has_delete_permission ( request ) : NEW_LINE INDENT raise PermissionDenied NEW_LINE DEDENT using = router . db_for_write ( modeladmin . model ) NEW_LINE # ▁ Populate ▁ deletable _ objects , ▁ a ▁ data ▁ structure ▁ of ▁ all ▁ related ▁ objects ▁ that ENDCOM # ▁ will ▁ also ▁ be ▁ deleted . ENDCOM deletable_objects , model_count , perms_needed , protected = get_deleted_objects ( queryset , opts , request . user , modeladmin . admin_site , using ) NEW_LINE # ▁ The ▁ user ▁ has ▁ already ▁ confirmed ▁ the ▁ deletion . ENDCOM # ▁ Do ▁ the ▁ deletion ▁ and ▁ return ▁ a ▁ None ▁ to ▁ display ▁ the ▁ change ▁ list ▁ view ▁ again . ENDCOM if request . POST . get ( ' post ' ) : NEW_LINE INDENT if perms_needed : NEW_LINE INDENT raise PermissionDenied NEW_LINE DEDENT n = queryset . count ( ) NEW_LINE if n : NEW_LINE INDENT for obj in queryset : NEW_LINE INDENT obj_display = force_text ( obj ) NEW_LINE modeladmin . log_deletion ( request , obj , obj_display ) NEW_LINE DEDENT queryset . delete ( ) NEW_LINE modeladmin . message_user ( request , _ ( " Successfully ▁ deleted ▁ % ( count ) d ▁ % ( items ) s . " ) % { " count " : n , " items " : model_ngettext ( modeladmin . opts , n ) } , messages . SUCCESS ) NEW_LINE # ▁ Return ▁ None ▁ to ▁ display ▁ the ▁ change ▁ list ▁ page ▁ again . ENDCOM DEDENT return None NEW_LINE DEDENT if len ( queryset ) == 1 : NEW_LINE INDENT objects_name = force_text ( opts . verbose_name ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_name = force_text ( opts . verbose_name_plural ) NEW_LINE DEDENT if perms_needed or protected : NEW_LINE INDENT title = _ ( " Cannot ▁ delete ▁ % ( name ) s " ) % { " name " : objects_name } NEW_LINE DEDENT else : NEW_LINE INDENT title = _ ( " Are ▁ you ▁ sure ? " ) NEW_LINE DEDENT context = dict ( modeladmin . admin_site . each_context ( request ) , title = title , objects_name = objects_name , deletable_objects = [ deletable_objects ] , model_count = dict ( model_count ) . items ( ) , queryset = queryset , perms_lacking = perms_needed , protected = protected , opts = opts , action_checkbox_name = helpers . ACTION_CHECKBOX_NAME , ) NEW_LINE request . current_app = modeladmin . admin_site . name NEW_LINE # ▁ Display ▁ the ▁ confirmation ▁ page ENDCOM return TemplateResponse ( request , modeladmin . delete_selected_confirmation_template or [ " admin / % s / % s / delete _ selected _ confirmation . html " % ( app_label , opts . model_name ) , " admin / % s / delete _ selected _ confirmation . html " % app_label , " admin / delete _ selected _ confirmation . html " ] , context ) NEW_LINE DEDENT delete_selected . short_description = ugettext_lazy ( " Delete ▁ selected ▁ % ( verbose _ name _ plural ) s " ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="astronaut1712/taiga-back/tree/master/taiga/projects/wiki/models.py"> # ▁ Copyright ▁ ( C ) ▁ 2014 ▁ Andrey ▁ Antukh ▁ < niwi @ niwi . be > ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2014 ▁ Jesús ▁ Espino ▁ < jespinog @ gmail . com > ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2014 ▁ David ▁ Barragán ▁ < bameda @ dbarragan . com > ENDCOM # ▁ This ▁ program ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ as ENDCOM # ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ENDCOM # ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ this ▁ program . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM from django . db import models NEW_LINE from django . contrib . contenttypes import generic NEW_LINE from django . conf import settings NEW_LINE from django . utils . translation import ugettext_lazy as _ NEW_LINE from django . utils import timezone NEW_LINE from taiga . projects . notifications . mixins import WatchedModelMixin NEW_LINE from taiga . projects . occ import OCCModelMixin NEW_LINE class WikiPage ( OCCModelMixin , WatchedModelMixin , models . Model ) : NEW_LINE INDENT project = models . ForeignKey ( " projects . Project " , null = False , blank = False , related_name = " wiki _ pages " , verbose_name = _ ( " project " ) ) NEW_LINE slug = models . SlugField ( max_length = 500 , db_index = True , null = False , blank = False , verbose_name = _ ( " slug " ) ) NEW_LINE content = models . TextField ( null = False , blank = True , verbose_name = _ ( " content " ) ) NEW_LINE owner = models . ForeignKey ( settings . AUTH_USER_MODEL , null = True , blank = True , related_name = " owned _ wiki _ pages " , verbose_name = _ ( " owner " ) ) NEW_LINE last_modifier = models . ForeignKey ( settings . AUTH_USER_MODEL , null = True , blank = True , related_name = " last _ modified _ wiki _ pages " , verbose_name = _ ( " last ▁ modifier " ) ) NEW_LINE created_date = models . DateTimeField ( null = False , blank = False , verbose_name = _ ( " created ▁ date " ) , default = timezone . now ) NEW_LINE modified_date = models . DateTimeField ( null = False , blank = False , verbose_name = _ ( " modified ▁ date " ) ) NEW_LINE attachments = generic . GenericRelation ( " attachments . Attachment " ) NEW_LINE _importing = None NEW_LINE class Meta : NEW_LINE INDENT verbose_name = " wiki ▁ page " NEW_LINE verbose_name_plural = " wiki ▁ pages " NEW_LINE ordering = [ " project " , " slug " ] NEW_LINE unique_together = ( " project " , " slug " , ) NEW_LINE permissions = ( ( " view _ wikipage " , " Can ▁ view ▁ wiki ▁ page " ) , ) NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return " project ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . project_id , self . slug ) NEW_LINE DEDENT def save ( self , * args , ** kwargs ) : NEW_LINE INDENT if not self . _importing or not self . modified_date : NEW_LINE INDENT self . modified_date = timezone . now ( ) NEW_LINE DEDENT return super ( ) . save ( * args , ** kwargs ) NEW_LINE DEDENT DEDENT class WikiLink ( models . Model ) : NEW_LINE INDENT project = models . ForeignKey ( " projects . Project " , null = False , blank = False , related_name = " wiki _ links " , verbose_name = _ ( " project " ) ) NEW_LINE title = models . CharField ( max_length = 500 , null = False , blank = False ) NEW_LINE href = models . SlugField ( max_length = 500 , db_index = True , null = False , blank = False , verbose_name = _ ( " href " ) ) NEW_LINE order = models . PositiveSmallIntegerField ( default = 1 , null = False , blank = False , verbose_name = _ ( " order " ) ) NEW_LINE class Meta : NEW_LINE INDENT verbose_name = " wiki ▁ link " NEW_LINE verbose_name_plural = " wiki ▁ links " NEW_LINE ordering = [ " project " , " order " ] NEW_LINE unique_together = ( " project " , " href " ) NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return self . title NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="chouseknecht/ansible/tree/master/lib/ansible/module_utils/network/eos/argspec/facts/facts.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2019 ▁ Red ▁ Hat ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0 + ▁ ( see ▁ COPYING ▁ or ▁ https : / / www . gnu . org / licenses / gpl - 3.0 . txt ) ENDCOM """ STRNEWLINE The ▁ arg ▁ spec ▁ for ▁ the ▁ eos ▁ facts ▁ module . STRNEWLINE """ NEW_LINE from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE class FactsArgs ( object ) : NEW_LINE INDENT """ ▁ The ▁ arg ▁ spec ▁ for ▁ the ▁ eos ▁ facts ▁ module STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT argument_spec = { ' gather _ subset ' : dict ( default = [ ' ! config ' ] , type = ' list ' ) , ' gather _ network _ resources ' : dict ( type = ' list ' ) , } NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="robertglen/flask/tree/master/tests/test_instance_config.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM """ STRNEWLINE ▁ tests . test _ instance STRNEWLINE ▁ ~ ~ ~ ~ ~ STRNEWLINE STRNEWLINE ▁ : copyright : ▁ ( c ) ▁ 2015 ▁ by ▁ the ▁ Flask ▁ Team , ▁ see ▁ AUTHORS ▁ for ▁ more ▁ details . STRNEWLINE ▁ : license : ▁ BSD , ▁ see ▁ LICENSE ▁ for ▁ more ▁ details . STRNEWLINE """ NEW_LINE import os NEW_LINE import sys NEW_LINE import pytest NEW_LINE import flask NEW_LINE from flask . _compat import PY2 NEW_LINE def test_explicit_instance_paths ( modules_tmpdir ) : NEW_LINE INDENT with pytest . raises ( ValueError ) as excinfo : NEW_LINE INDENT flask . Flask ( __name__ , instance_path = ' instance ' ) NEW_LINE DEDENT assert ' must ▁ be ▁ absolute ' in str ( excinfo . value ) NEW_LINE app = flask . Flask ( __name__ , instance_path = str ( modules_tmpdir ) ) NEW_LINE assert app . instance_path == str ( modules_tmpdir ) NEW_LINE DEDENT def test_main_module_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' main _ app . py ' ) NEW_LINE app . write ( ' import ▁ flask \n \n app ▁ = ▁ flask . Flask ( " _ _ main _ _ " ) ' ) NEW_LINE purge_module ( ' main _ app ' ) NEW_LINE from main_app import app NEW_LINE here = os . path . abspath ( os . getcwd ( ) ) NEW_LINE assert app . instance_path == os . path . join ( here , ' instance ' ) NEW_LINE DEDENT def test_uninstalled_module_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' config _ module _ app . py ' ) . write ( ' import ▁ os \n ' ' import ▁ flask \n ' ' here ▁ = ▁ os . path . abspath ( os . path . dirname ( _ _ file _ _ ) ) \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' config _ module _ app ' ) NEW_LINE from config_module_app import app NEW_LINE assert app . instance_path == str ( modules_tmpdir . join ( ' instance ' ) ) NEW_LINE DEDENT def test_uninstalled_package_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . mkdir ( ' config _ package _ app ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ os \n ' ' import ▁ flask \n ' ' here ▁ = ▁ os . path . abspath ( os . path . dirname ( _ _ file _ _ ) ) \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' config _ package _ app ' ) NEW_LINE from config_package_app import app NEW_LINE assert app . instance_path == str ( modules_tmpdir . join ( ' instance ' ) ) NEW_LINE DEDENT def test_installed_module_paths ( modules_tmpdir , modules_tmpdir_prefix , purge_module , site_packages , limit_loader ) : NEW_LINE INDENT site_packages . join ( ' site _ app . py ' ) . write ( ' import ▁ flask \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' site _ app ' ) NEW_LINE from site_app import app NEW_LINE assert app . instance_path == modules_tmpdir . join ( ' var ' ) . join ( ' site _ app - instance ' ) NEW_LINE DEDENT def test_installed_package_paths ( limit_loader , modules_tmpdir , modules_tmpdir_prefix , purge_module , monkeypatch ) : NEW_LINE INDENT installed_path = modules_tmpdir . mkdir ( ' path ' ) NEW_LINE monkeypatch . syspath_prepend ( installed_path ) NEW_LINE app = installed_path . mkdir ( ' installed _ package ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE purge_module ( ' installed _ package ' ) NEW_LINE from installed_package import app NEW_LINE assert app . instance_path == modules_tmpdir . join ( ' var ' ) . join ( ' installed _ package - instance ' ) NEW_LINE DEDENT def test_prefix_package_paths ( limit_loader , modules_tmpdir , modules_tmpdir_prefix , purge_module , site_packages ) : NEW_LINE INDENT app = site_packages . mkdir ( ' site _ package ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE purge_module ( ' site _ package ' ) NEW_LINE import site_package NEW_LINE assert site_package . app . instance_path == modules_tmpdir . join ( ' var ' ) . join ( ' site _ package - instance ' ) NEW_LINE DEDENT def test_egg_installed_paths ( install_egg , modules_tmpdir , modules_tmpdir_prefix ) : NEW_LINE INDENT modules_tmpdir . mkdir ( ' site _ egg ' ) . join ( ' _ _ init _ _ . py ' ) . write ( ' import ▁ flask \n \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE install_egg ( ' site _ egg ' ) NEW_LINE try : NEW_LINE INDENT import site_egg NEW_LINE assert site_egg . app . instance_path == str ( modules_tmpdir . join ( ' var / ' ) . join ( ' site _ egg - instance ' ) ) NEW_LINE DEDENT finally : NEW_LINE INDENT if ' site _ egg ' in sys . modules : NEW_LINE INDENT del sys . modules [ ' site _ egg ' ] NEW_LINE DEDENT DEDENT DEDENT @ pytest . mark . skipif ( not PY2 , reason = ' This ▁ only ▁ works ▁ under ▁ Python ▁ 2 . ' ) NEW_LINE def test_meta_path_loader_without_is_package ( request , modules_tmpdir ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' unimportable . py ' ) NEW_LINE app . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE class Loader ( object ) : NEW_LINE INDENT def find_module ( self , name , path = None ) : NEW_LINE INDENT return self NEW_LINE DEDENT DEDENT sys . meta_path . append ( Loader ( ) ) NEW_LINE request . addfinalizer ( sys . meta_path . pop ) NEW_LINE with pytest . raises ( AttributeError ) : NEW_LINE INDENT import unimportable NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="s40523220/2016fallcp_hw/tree/master/plugin/liquid_tags/test_generation.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM from __future__ import print_function NEW_LINE import filecmp NEW_LINE import os NEW_LINE import unittest NEW_LINE from shutil import rmtree NEW_LINE from tempfile import mkdtemp NEW_LINE import pytest NEW_LINE from pelican import Pelican NEW_LINE from pelican . settings import read_settings NEW_LINE from . notebook import IPYTHON_VERSION NEW_LINE PLUGIN_DIR = os . path . dirname ( __file__ ) NEW_LINE TEST_DATA_DIR = os . path . join ( PLUGIN_DIR , ' test _ data ' ) NEW_LINE class TestFullRun ( unittest . TestCase ) : NEW_LINE INDENT ''' Test ▁ running ▁ Pelican ▁ with ▁ the ▁ Plugin ''' NEW_LINE def setUp ( self ) : NEW_LINE INDENT ''' Create ▁ temporary ▁ output ▁ and ▁ cache ▁ folders ''' NEW_LINE self . temp_path = mkdtemp ( prefix = ' pelicantests . ' ) NEW_LINE self . temp_cache = mkdtemp ( prefix = ' pelican _ cache . ' ) NEW_LINE os . chdir ( TEST_DATA_DIR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT ''' Remove ▁ output ▁ and ▁ cache ▁ folders ''' NEW_LINE rmtree ( self . temp_path ) NEW_LINE rmtree ( self . temp_cache ) NEW_LINE os . chdir ( PLUGIN_DIR ) NEW_LINE DEDENT @ pytest . mark . skipif ( IPYTHON_VERSION >= 3 , reason = " output ▁ must ▁ be ▁ created ▁ with ▁ ipython ▁ version ▁ 2" ) NEW_LINE def test_generate_with_ipython3 ( self ) : NEW_LINE INDENT ''' Test ▁ generation ▁ of ▁ site ▁ with ▁ the ▁ plugin . ''' NEW_LINE base_path = os . path . dirname ( os . path . abspath ( __file__ ) ) NEW_LINE base_path = os . path . join ( base_path , ' test _ data ' ) NEW_LINE content_path = os . path . join ( base_path , ' content ' ) NEW_LINE output_path = os . path . join ( base_path , ' output ' ) NEW_LINE settings_path = os . path . join ( base_path , ' pelicanconf . py ' ) NEW_LINE settings = read_settings ( path = settings_path , override = { ' PATH ' : content_path , ' OUTPUT _ PATH ' : self . temp_path , ' CACHE _ PATH ' : self . temp_cache , } ) NEW_LINE pelican = Pelican ( settings ) NEW_LINE pelican . run ( ) NEW_LINE # ▁ test ▁ existence ENDCOM assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 3 . html ' ) ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 4 . html ' ) ) NEW_LINE # ▁ test ▁ differences ENDCOM # assert ▁ filecmp . cmp ( os . path . join ( output _ path , ENDCOM # ▁ ' test - ipython - notebook - v2 . html ' ) , ENDCOM # ▁ os . path . join ( self . temp _ path , ENDCOM # ▁ ' test - ipython - notebook . html ' ) ) ENDCOM DEDENT @ pytest . mark . skipif ( IPYTHON_VERSION < 3 , reason = " output ▁ must ▁ be ▁ created ▁ with ▁ ipython ▁ version ▁ 3" ) NEW_LINE def test_generate_with_ipython2 ( self ) : NEW_LINE INDENT ''' Test ▁ generation ▁ of ▁ site ▁ with ▁ the ▁ plugin . ''' NEW_LINE base_path = os . path . dirname ( os . path . abspath ( __file__ ) ) NEW_LINE base_path = os . path . join ( base_path , ' test _ data ' ) NEW_LINE content_path = os . path . join ( base_path , ' content ' ) NEW_LINE output_path = os . path . join ( base_path , ' output ' ) NEW_LINE settings_path = os . path . join ( base_path , ' pelicanconf . py ' ) NEW_LINE settings = read_settings ( path = settings_path , override = { ' PATH ' : content_path , ' OUTPUT _ PATH ' : self . temp_path , ' CACHE _ PATH ' : self . temp_cache , } ) NEW_LINE pelican = Pelican ( settings ) NEW_LINE pelican . run ( ) NEW_LINE # ▁ test ▁ existence ENDCOM assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 3 . html ' ) ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 4 . html ' ) ) NEW_LINE # ▁ test ▁ differences ENDCOM # assert ▁ filecmp . cmp ( os . path . join ( output _ path , ENDCOM # ▁ ' test - ipython - notebook - v3 . html ' ) , ENDCOM # ▁ os . path . join ( self . temp _ path , ENDCOM # ▁ ' test - ipython - notebook . html ' ) ) ENDCOM DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="kcompher/BuildingMachineLearningSystemsWithPython/tree/master/ch03/rel_post_01.py"> # ▁ This ▁ code ▁ is ▁ supporting ▁ material ▁ for ▁ the ▁ book ENDCOM # ▁ Building ▁ Machine ▁ Learning ▁ Systems ▁ with ▁ Python ENDCOM # ▁ by ▁ Willi ▁ Richert ▁ and ▁ Luis ▁ Pedro ▁ Coelho ENDCOM # ▁ published ▁ by ▁ PACKT ▁ Publishing ENDCOM # ▁ It ▁ is ▁ made ▁ available ▁ under ▁ the ▁ MIT ▁ License ENDCOM import os NEW_LINE import sys NEW_LINE import scipy as sp NEW_LINE from sklearn . feature_extraction . text import CountVectorizer NEW_LINE DIR = r " . . / data / toy " NEW_LINE posts = [ open ( os . path . join ( DIR , f ) ) . read ( ) for f in os . listdir ( DIR ) ] NEW_LINE new_post = " imaging ▁ databases " NEW_LINE import nltk . stem NEW_LINE english_stemmer = nltk . stem . SnowballStemmer ( ' english ' ) NEW_LINE class StemmedCountVectorizer ( CountVectorizer ) : NEW_LINE INDENT def build_analyzer ( self ) : NEW_LINE INDENT analyzer = super ( StemmedCountVectorizer , self ) . build_analyzer ( ) NEW_LINE return lambda doc : ( english_stemmer . stem ( w ) for w in analyzer ( doc ) ) NEW_LINE # ▁ vectorizer ▁ = ▁ CountVectorizer ( min _ df = 1 , ▁ stop _ words = ' english ' , ENDCOM # ▁ preprocessor = stemmer ) ENDCOM DEDENT DEDENT vectorizer = StemmedCountVectorizer ( min_df = 1 , stop_words = ' english ' ) NEW_LINE from sklearn . feature_extraction . text import TfidfVectorizer NEW_LINE class StemmedTfidfVectorizer ( TfidfVectorizer ) : NEW_LINE INDENT def build_analyzer ( self ) : NEW_LINE INDENT analyzer = super ( StemmedTfidfVectorizer , self ) . build_analyzer ( ) NEW_LINE return lambda doc : ( english_stemmer . stem ( w ) for w in analyzer ( doc ) ) NEW_LINE DEDENT DEDENT vectorizer = StemmedTfidfVectorizer ( min_df = 1 , stop_words = ' english ' , charset_error = ' ignore ' ) NEW_LINE print ( vectorizer ) NEW_LINE X_train = vectorizer . fit_transform ( posts ) NEW_LINE num_samples , num_features = X_train . shape NEW_LINE print ( " # samples : ▁ % d , ▁ # features : ▁ % d " % ( num_samples , num_features ) ) NEW_LINE new_post_vec = vectorizer . transform ( [ new_post ] ) NEW_LINE print ( new_post_vec , type ( new_post_vec ) ) NEW_LINE print ( new_post_vec . toarray ( ) ) NEW_LINE print ( vectorizer . get_feature_names ( ) ) NEW_LINE def dist_raw ( v1 , v2 ) : NEW_LINE INDENT delta = v1 - v2 NEW_LINE return sp . linalg . norm ( delta . toarray ( ) ) NEW_LINE DEDENT def dist_norm ( v1 , v2 ) : NEW_LINE INDENT v1_normalized = v1 / sp . linalg . norm ( v1 . toarray ( ) ) NEW_LINE v2_normalized = v2 / sp . linalg . norm ( v2 . toarray ( ) ) NEW_LINE delta = v1_normalized - v2_normalized NEW_LINE return sp . linalg . norm ( delta . toarray ( ) ) NEW_LINE DEDENT dist = dist_norm NEW_LINE best_dist = sys . maxsize NEW_LINE best_i = None NEW_LINE for i in range ( 0 , num_samples ) : NEW_LINE INDENT post = posts [ i ] NEW_LINE if post == new_post : NEW_LINE INDENT continue NEW_LINE DEDENT post_vec = X_train . getrow ( i ) NEW_LINE d = dist ( post_vec , new_post_vec ) NEW_LINE print ( " = = = ▁ Post ▁ % i ▁ with ▁ dist = % .2f : ▁ % s " % ( i , d , post ) ) NEW_LINE if d < best_dist : NEW_LINE INDENT best_dist = d NEW_LINE best_i = i NEW_LINE DEDENT DEDENT print ( " Best ▁ post ▁ is ▁ % i ▁ with ▁ dist = % .2f " % ( best_i , best_dist ) ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="bollu/sandhi/tree/master/modules/gr36/grc/gui/Connection.py"> """ STRNEWLINE Copyright ▁ 2007 , ▁ 2008 , ▁ 2009 ▁ Free ▁ Software ▁ Foundation , ▁ Inc . STRNEWLINE This ▁ file ▁ is ▁ part ▁ of ▁ GNU ▁ Radio STRNEWLINE STRNEWLINE GNU ▁ Radio ▁ Companion ▁ is ▁ free ▁ software ; ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or STRNEWLINE modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License STRNEWLINE as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation ; ▁ either ▁ version ▁ 2 STRNEWLINE of ▁ the ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . STRNEWLINE STRNEWLINE GNU ▁ Radio ▁ Companion ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , STRNEWLINE but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of STRNEWLINE MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the STRNEWLINE GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . STRNEWLINE STRNEWLINE You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License STRNEWLINE along ▁ with ▁ this ▁ program ; ▁ if ▁ not , ▁ write ▁ to ▁ the ▁ Free ▁ Software STRNEWLINE Foundation , ▁ Inc . , ▁ 51 ▁ Franklin ▁ Street , ▁ Fifth ▁ Floor , ▁ Boston , ▁ MA ▁ 02110-1301 , ▁ USA STRNEWLINE """ NEW_LINE import Utils NEW_LINE from Element import Element NEW_LINE import Colors NEW_LINE from Constants import CONNECTOR_ARROW_BASE , CONNECTOR_ARROW_HEIGHT NEW_LINE class Connection ( Element ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL A ▁ graphical ▁ connection ▁ for ▁ ports . STRNEWLINE TABSYMBOL The ▁ connection ▁ has ▁ 2 ▁ parts , ▁ the ▁ arrow ▁ and ▁ the ▁ wire . STRNEWLINE TABSYMBOL The ▁ coloring ▁ of ▁ the ▁ arrow ▁ and ▁ wire ▁ exposes ▁ the ▁ status ▁ of ▁ 3 ▁ states : STRNEWLINE TABSYMBOL TABSYMBOL enabled / disabled , ▁ valid / invalid , ▁ highlighted / non - highlighted . STRNEWLINE TABSYMBOL The ▁ wire ▁ coloring ▁ exposes ▁ the ▁ enabled ▁ and ▁ highlighted ▁ states . STRNEWLINE TABSYMBOL The ▁ arrow ▁ coloring ▁ exposes ▁ the ▁ enabled ▁ and ▁ valid ▁ states . STRNEWLINE TABSYMBOL """ NEW_LINE def __init__ ( self ) : Element . __init__ ( self ) NEW_LINE def get_coordinate ( self ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Get ▁ the ▁ 0,0 ▁ coordinate . STRNEWLINE TABSYMBOL TABSYMBOL Coordinates ▁ are ▁ irrelevant ▁ in ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ return ▁ 0 , ▁ 0 STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE return ( 0 , 0 ) NEW_LINE DEDENT def get_rotation ( self ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Get ▁ the ▁ 0 ▁ degree ▁ rotation . STRNEWLINE TABSYMBOL TABSYMBOL Rotations ▁ are ▁ irrelevant ▁ in ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ return ▁ 0 STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE return 0 NEW_LINE DEDENT def create_shapes ( self ) : NEW_LINE INDENT """ Precalculate ▁ relative ▁ coordinates . """ NEW_LINE Element . create_shapes ( self ) NEW_LINE self . _sink_rot = None NEW_LINE self . _source_rot = None NEW_LINE self . _sink_coor = None NEW_LINE self . _source_coor = None NEW_LINE # get ▁ the ▁ source ▁ coordinate ENDCOM connector_length = self . get_source ( ) . get_connector_length ( ) NEW_LINE self . x1 , self . y1 = Utils . get_rotated_coordinate ( ( connector_length , 0 ) , self . get_source ( ) . get_rotation ( ) ) NEW_LINE # get ▁ the ▁ sink ▁ coordinate ENDCOM connector_length = self . get_sink ( ) . get_connector_length ( ) + CONNECTOR_ARROW_HEIGHT NEW_LINE self . x2 , self . y2 = Utils . get_rotated_coordinate ( ( - connector_length , 0 ) , self . get_sink ( ) . get_rotation ( ) ) NEW_LINE # build ▁ the ▁ arrow ENDCOM self . arrow = [ ( 0 , 0 ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , - CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , ] NEW_LINE self . _update_after_move ( ) NEW_LINE if not self . get_enabled ( ) : self . _arrow_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE elif not self . is_valid ( ) : self . _arrow_color = Colors . CONNECTION_ERROR_COLOR NEW_LINE else : self . _arrow_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE DEDENT def _update_after_move ( self ) : NEW_LINE INDENT """ Calculate ▁ coordinates . """ NEW_LINE self . clear ( ) # FIXME ▁ do ▁ i ▁ want ▁ this ▁ here ? ENDCOM NEW_LINE # source ▁ connector ENDCOM source = self . get_source ( ) NEW_LINE X , Y = source . get_connector_coordinate ( ) NEW_LINE x1 , y1 = self . x1 + X , self . y1 + Y NEW_LINE self . add_line ( ( x1 , y1 ) , ( X , Y ) ) NEW_LINE # sink ▁ connector ENDCOM sink = self . get_sink ( ) NEW_LINE X , Y = sink . get_connector_coordinate ( ) NEW_LINE x2 , y2 = self . x2 + X , self . y2 + Y NEW_LINE self . add_line ( ( x2 , y2 ) , ( X , Y ) ) NEW_LINE # adjust ▁ arrow ENDCOM self . _arrow = [ ( x + X , y + Y ) for x , y in self . arrow ] NEW_LINE # add ▁ the ▁ horizontal ▁ and ▁ vertical ▁ lines ▁ in ▁ this ▁ connection ENDCOM if abs ( source . get_connector_direction ( ) - sink . get_connector_direction ( ) ) == 180 : NEW_LINE # 2 ▁ possible ▁ point ▁ sets ▁ to ▁ create ▁ a ▁ 3 - line ▁ connector ENDCOM INDENT mid_x , mid_y = ( x1 + x2 ) / 2.0 , ( y1 + y2 ) / 2.0 NEW_LINE points = [ ( ( mid_x , y1 ) , ( mid_x , y2 ) ) , ( ( x1 , mid_y ) , ( x2 , mid_y ) ) ] NEW_LINE # source ▁ connector ▁ - > ▁ points [ 0 ] [ 0 ] ▁ should ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ▁ ( if ▁ possible ) ENDCOM if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] [ 0 ] ) != source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] [ 0 ] ▁ - > ▁ sink ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ sink ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] [ 0 ] ▁ - > ▁ source ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # create ▁ 3 - line ▁ connector ENDCOM p1 , p2 = map ( int , points [ 0 ] [ 0 ] ) , map ( int , points [ 0 ] [ 1 ] ) NEW_LINE self . add_line ( ( x1 , y1 ) , p1 ) NEW_LINE self . add_line ( p1 , p2 ) NEW_LINE self . add_line ( ( x2 , y2 ) , p2 ) NEW_LINE DEDENT else : NEW_LINE # 2 ▁ possible ▁ points ▁ to ▁ create ▁ a ▁ right - angled ▁ connector ENDCOM INDENT points = [ ( x1 , y2 ) , ( x2 , y1 ) ] NEW_LINE # source ▁ connector ▁ - > ▁ points [ 0 ] ▁ should ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ▁ ( if ▁ possible ) ENDCOM if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] ) != source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] ▁ - > ▁ sink ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ sink ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] ▁ - > ▁ source ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # create ▁ right - angled ▁ connector ENDCOM self . add_line ( ( x1 , y1 ) , points [ 0 ] ) NEW_LINE self . add_line ( ( x2 , y2 ) , points [ 0 ] ) NEW_LINE DEDENT DEDENT def draw ( self , gc , window ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Draw ▁ the ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ param ▁ gc ▁ the ▁ graphics ▁ context STRNEWLINE TABSYMBOL TABSYMBOL @ param ▁ window ▁ the ▁ gtk ▁ window ▁ to ▁ draw ▁ on STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE sink = self . get_sink ( ) NEW_LINE source = self . get_source ( ) NEW_LINE # check ▁ for ▁ changes ENDCOM if self . _sink_rot != sink . get_rotation ( ) or self . _source_rot != source . get_rotation ( ) : self . create_shapes ( ) NEW_LINE elif self . _sink_coor != sink . get_coordinate ( ) or self . _source_coor != source . get_coordinate ( ) : self . _update_after_move ( ) NEW_LINE # cache ▁ values ENDCOM self . _sink_rot = sink . get_rotation ( ) NEW_LINE self . _source_rot = source . get_rotation ( ) NEW_LINE self . _sink_coor = sink . get_coordinate ( ) NEW_LINE self . _source_coor = source . get_coordinate ( ) NEW_LINE # draw ENDCOM if self . is_highlighted ( ) : border_color = Colors . HIGHLIGHT_COLOR NEW_LINE elif self . get_enabled ( ) : border_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE else : border_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE Element . draw ( self , gc , window , bg_color = None , border_color = border_color ) NEW_LINE # draw ▁ arrow ▁ on ▁ sink ▁ port ENDCOM gc . set_foreground ( self . _arrow_color ) NEW_LINE window . draw_polygon ( gc , True , self . _arrow ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="alokotosh/mm-master/tree/master/mm/commands/misc.py"> import os NEW_LINE import json NEW_LINE import mm . util as util NEW_LINE import mm . config as config NEW_LINE from mm . exceptions import * NEW_LINE from mm . basecommand import Command NEW_LINE from mm . sfdc_client import MavensMateClient NEW_LINE class GetActiveSessionCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT if ' username ' not in self . params or self . params [ ' username ' ] == None or self . params [ ' username ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ enter ▁ a ▁ Salesforce . com ▁ username ' ) NEW_LINE DEDENT if ' password ' not in self . params or self . params [ ' password ' ] == None or self . params [ ' password ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ enter ▁ a ▁ Salesforce . com ▁ password ' ) NEW_LINE DEDENT if ' org _ type ' not in self . params or self . params [ ' org _ type ' ] == None or self . params [ ' org _ type ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ select ▁ an ▁ org ▁ type ' ) NEW_LINE DEDENT if ' org _ type ' in self . params and self . params [ ' org _ type ' ] == " custom " and " org _ url " not in self . params : NEW_LINE INDENT raise MMException ( ' To ▁ use ▁ a ▁ custom ▁ org ▁ type , ▁ please ▁ include ▁ a ▁ org _ url ▁ parameter ' ) NEW_LINE DEDENT if ' org _ type ' in self . params and self . params [ ' org _ type ' ] == " custom " and " org _ url " in self . params and self . params [ " org _ url " ] == " " : NEW_LINE INDENT raise MMException ( ' Please ▁ specify ▁ the ▁ org ▁ url ' ) NEW_LINE DEDENT config . logger . debug ( ' = = = = = = = = = = = = = = = = = > ' ) NEW_LINE config . logger . debug ( self . params ) NEW_LINE client = MavensMateClient ( credentials = { " username " : self . params [ ' username ' ] , " password " : self . params [ ' password ' ] , " org _ type " : self . params [ ' org _ type ' ] , " org _ url " : self . params . get ( ' org _ url ' , None ) } ) NEW_LINE response = { " sid " : client . sid , " user _ id " : client . user_id , " metadata _ server _ url " : client . metadata_server_url , " server _ url " : client . server_url , " metadata " : client . get_org_metadata ( subscription = self . params . get ( ' subscription ' , None ) ) , " org _ metadata _ types " : util . metadata_types ( ) , " success " : True } NEW_LINE return util . generate_response ( response ) NEW_LINE DEDENT DEDENT class IndexApexSymbolsCommand ( Command ) : NEW_LINE INDENT aliases = [ " index _ apex " , " index _ apex _ file _ properties " ] NEW_LINE """ STRNEWLINE ▁ Updates ▁ symbol ▁ index ▁ for ▁ one ▁ or ▁ more ▁ Apex ▁ Classes . ▁ If ▁ files ▁ is ▁ not ▁ included ▁ or ▁ empty , ▁ will ▁ force ▁ a ▁ full ▁ refresh STRNEWLINE ▁ """ NEW_LINE def execute ( self ) : NEW_LINE INDENT return config . project . index_apex_symbols ( self . params . get ( " files " , None ) ) NEW_LINE DEDENT DEDENT class ResetMetadataContainerCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT return config . project . reset_metadata_container ( accept = " json " ) NEW_LINE DEDENT DEDENT class OpenFileInClientCommand ( Command ) : NEW_LINE INDENT """ STRNEWLINE ▁ Opens ▁ the ▁ requested ▁ files ▁ in ▁ the ▁ plugin ▁ client ▁ ( Sublime ▁ Text , ▁ etc . ) STRNEWLINE ▁ """ NEW_LINE def execute ( self ) : NEW_LINE INDENT file_name = self . params [ " file _ name " ] NEW_LINE extension = util . get_file_extension_no_period ( file_name ) NEW_LINE mtype = util . get_meta_type_by_suffix ( extension ) NEW_LINE full_file_path = os . path . join ( config . project . location , " src " , mtype [ " directoryName " ] , file_name ) NEW_LINE params = { " project _ name " : config . project . project_name , " file _ name " : full_file_path , " line _ number " : self . params . get ( " line _ number " , 0 ) } NEW_LINE config . connection . run_subl_command ( " open _ file _ in _ project " , json . dumps ( params ) ) NEW_LINE return util . generate_success_response ( " ok " ) NEW_LINE DEDENT DEDENT class ExecuteApexCommand ( Command ) : NEW_LINE INDENT aliases = [ " run _ apex _ script " ] NEW_LINE """ STRNEWLINE ▁ executes ▁ a ▁ string ▁ of ▁ apex STRNEWLINE ▁ """ NEW_LINE def execute ( self ) : NEW_LINE INDENT if ' script _ name ' in self . params : # running ▁ an ▁ apex ▁ script ENDCOM NEW_LINE INDENT self . params [ " body " ] = util . get_file_as_string ( os . path . join ( config . project . location , " apex - scripts " , self . params [ " script _ name " ] ) ) NEW_LINE DEDENT if ' debug _ categories ' not in self . params and not os . path . isfile ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) : NEW_LINE INDENT self . params [ " debug _ categories " ] = [ { " category " : " Apex _ code " , " level " : " DEBUG " } ] NEW_LINE DEDENT elif os . path . isfile ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) : NEW_LINE INDENT log_settings = util . parse_json_from_file ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) NEW_LINE categories = [ ] NEW_LINE levels = log_settings [ " levels " ] NEW_LINE for category in levels . keys ( ) : NEW_LINE INDENT categories . append ( { " category " : category , " level " : levels [ category ] } ) NEW_LINE DEDENT self . params [ " debug _ categories " ] = categories NEW_LINE DEDENT elif ' debug _ categories ' not in self . params : NEW_LINE INDENT self . params [ " debug _ categories " ] = [ { " category " : " Apex _ code " , " level " : " DEBUG " } ] NEW_LINE DEDENT return_log = self . params . get ( " return _ log " , True ) NEW_LINE execute_result = config . sfdc_client . execute_apex ( self . params ) NEW_LINE result = { ' column ' : execute_result [ ' column ' ] , ' compileProblem ' : execute_result [ ' compileProblem ' ] , ' compiled ' : execute_result [ ' compiled ' ] , ' exceptionMessage ' : execute_result [ ' exceptionMessage ' ] , ' exceptionStackTrace ' : execute_result [ ' exceptionStackTrace ' ] , ' line ' : execute_result [ ' line ' ] , ' success ' : execute_result [ ' success ' ] , } NEW_LINE if ' log ' in execute_result and return_log : NEW_LINE INDENT result [ ' log ' ] = execute_result [ ' log ' ] NEW_LINE DEDENT if result [ ' success ' ] : NEW_LINE INDENT log_apex = config . connection . get_plugin_client_setting ( ' mm _ log _ anonymous _ apex ' , False ) NEW_LINE if log_apex : NEW_LINE INDENT location = config . project . log_anonymous_apex ( self . params [ ' body ' ] , execute_result [ ' log ' ] , self . params . get ( " script _ name " , None ) ) NEW_LINE result [ " log _ location " ] = location NEW_LINE DEDENT DEDENT return util . generate_response ( result ) NEW_LINE DEDENT DEDENT class SignInWithGithubCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT return config . connection . sign_in_with_github ( self . params ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Baumelbi/IntroPython2016/tree/master/Solutions/Session06/test_mailroom2.py"> # ! / usr / bin / env ▁ python ENDCOM """ STRNEWLINE unit ▁ tests ▁ for ▁ the ▁ mailroom ▁ program STRNEWLINE """ NEW_LINE import os NEW_LINE import mailroom2 as mailroom NEW_LINE # ▁ so ▁ that ▁ it ' s ▁ there ▁ for ▁ the ▁ tests ENDCOM mailroom . donor_db = mailroom . get_donor_db ( ) NEW_LINE def test_list_donors ( ) : NEW_LINE INDENT listing = mailroom . list_donors ( ) NEW_LINE # ▁ hard ▁ to ▁ test ▁ this ▁ throughly ▁ - - ▁ better ▁ not ▁ to ▁ hard ▁ code ▁ the ▁ entire ENDCOM # ▁ thing . ▁ But ▁ check ▁ for ▁ a ▁ few ▁ aspects ▁ - - ▁ this ▁ will ▁ catch ▁ the ▁ likely ENDCOM # ▁ errors ENDCOM assert listing . startswith ( " Donor ▁ list : \n " ) NEW_LINE assert " Jeff ▁ Bezos " in listing NEW_LINE assert " William ▁ Gates ▁ III " in listing NEW_LINE assert len ( listing . split ( ' \n ' ) ) == 5 NEW_LINE DEDENT def test_find_donor ( ) : NEW_LINE INDENT """ ▁ checks ▁ a ▁ donor ▁ that ▁ is ▁ there , ▁ but ▁ with ▁ odd ▁ case ▁ and ▁ spaces """ NEW_LINE donor = mailroom . find_donor ( " jefF ▁ beZos ▁ " ) NEW_LINE assert donor [ 0 ] == " Jeff ▁ Bezos " NEW_LINE DEDENT def test_find_donor_not ( ) : NEW_LINE INDENT " test ▁ one ▁ that ' s ▁ not ▁ there " NEW_LINE donor = mailroom . find_donor ( " Jeff ▁ Bzos " ) NEW_LINE assert donor is None NEW_LINE DEDENT def test_gen_letter ( ) : NEW_LINE INDENT """ ▁ test ▁ the ▁ donor ▁ letter ▁ """ NEW_LINE # ▁ create ▁ a ▁ sample ▁ donor ENDCOM donor = ( " Fred ▁ Flintstone " , [ 432.45 , 65.45 , 230.0 ] ) NEW_LINE letter = mailroom . gen_letter ( donor ) NEW_LINE # ▁ what ▁ to ▁ test ? ▁ tricky ! ENDCOM assert letter . startswith ( " Dear ▁ Fred ▁ Flintstone " ) NEW_LINE assert letter . endswith ( " - The ▁ Team \n " ) NEW_LINE assert " donation ▁ of ▁ $ 230.00" in letter NEW_LINE DEDENT def test_add_donor ( ) : NEW_LINE INDENT name = " Fred ▁ Flintstone ▁ ▁ " NEW_LINE donor = mailroom . add_donor ( name ) NEW_LINE donor [ 1 ] . append ( 300 ) NEW_LINE assert donor [ 0 ] == " Fred ▁ Flintstone " NEW_LINE assert donor [ 1 ] == [ 300 ] NEW_LINE assert mailroom . find_donor ( name ) == donor NEW_LINE DEDENT def test_generate_donor_report ( ) : NEW_LINE INDENT report = mailroom . generate_donor_report ( ) NEW_LINE print ( report ) # ▁ printing ▁ so ▁ you ▁ can ▁ see ▁ it ▁ if ▁ it ▁ fails ENDCOM NEW_LINE # ▁ this ▁ is ▁ pretty ▁ tough ▁ to ▁ test ENDCOM # ▁ these ▁ are ▁ not ▁ great , ▁ because ▁ they ▁ will ▁ fail ▁ if ▁ unimportant ▁ parts ▁ of ▁ the ENDCOM # ▁ report ▁ are ▁ changed . ENDCOM # ▁ but ▁ at ▁ least ▁ you ▁ know ▁ that ▁ codes ▁ working ▁ now . ENDCOM assert report . startswith ( " Donor ▁ Name ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ | ▁ Total ▁ Given ▁ | ▁ Num ▁ Gifts ▁ | ▁ Average ▁ Gift " ) NEW_LINE assert " Jeff ▁ Bezos ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ $ ▁ ▁ ▁ ▁ 877.33 ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ 1 ▁ ▁ ▁ $ ▁ ▁ ▁ ▁ ▁ 877.33" in report NEW_LINE DEDENT def test_save_letters_to_disk ( ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ only ▁ tests ▁ that ▁ the ▁ files ▁ get ▁ created , ▁ but ▁ that ' s ▁ a ▁ start STRNEWLINE STRNEWLINE ▁ Note ▁ that ▁ the ▁ contents ▁ of ▁ the ▁ letter ▁ was ▁ already STRNEWLINE ▁ tested ▁ with ▁ test _ gen _ letter STRNEWLINE ▁ """ NEW_LINE mailroom . save_letters_to_disk ( ) NEW_LINE assert os . path . isfile ( ' Jeff _ Bezos . txt ' ) NEW_LINE assert os . path . isfile ( ' William _ Gates _ III . txt ' ) NEW_LINE # ▁ check ▁ that ▁ it ' snot ▁ empty : ENDCOM with open ( ' William _ Gates _ III . txt ' ) as f : NEW_LINE INDENT size = len ( f . read ( ) ) NEW_LINE DEDENT assert size > 0 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE # ▁ this ▁ is ▁ best ▁ run ▁ with ▁ a ▁ test ▁ runner , ▁ like ▁ pytest ENDCOM # ▁ But ▁ if ▁ not , ▁ at ▁ least ▁ this ▁ will ▁ run ▁ them ▁ all . ENDCOM INDENT test_list_donors ( ) NEW_LINE test_find_donor ( ) NEW_LINE test_find_donor_not ( ) NEW_LINE test_gen_letter ( ) NEW_LINE test_add_donor ( ) NEW_LINE test_generate_donor_report ( ) NEW_LINE test_save_letters_to_disk ( ) NEW_LINE print ( " All ▁ tests ▁ Passed " ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="odoousers2014/odoo/tree/master/addons/website_sale_delivery/models/sale_order.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM from openerp . osv import orm , fields NEW_LINE from openerp import SUPERUSER_ID NEW_LINE from openerp . addons import decimal_precision NEW_LINE class delivery_carrier ( orm . Model ) : NEW_LINE INDENT _name = ' delivery . carrier ' NEW_LINE _inherit = [ ' delivery . carrier ' , ' website . published . mixin ' ] NEW_LINE _columns = { ' website _ description ' : fields . text ( ' Description ▁ for ▁ the ▁ website ' ) , } NEW_LINE _defaults = { ' website _ published ' : True } NEW_LINE DEDENT class SaleOrder ( orm . Model ) : NEW_LINE INDENT _inherit = ' sale . order ' NEW_LINE def _amount_all_wrapper ( self , cr , uid , ids , field_name , arg , context = None ) : NEW_LINE INDENT """ ▁ Wrapper ▁ because ▁ of ▁ direct ▁ method ▁ passing ▁ as ▁ parameter ▁ for ▁ function ▁ fields ▁ """ NEW_LINE return self . _amount_all ( cr , uid , ids , field_name , arg , context = context ) NEW_LINE DEDENT def _amount_all ( self , cr , uid , ids , field_name , arg , context = None ) : NEW_LINE INDENT res = super ( SaleOrder , self ) . _amount_all ( cr , uid , ids , field_name , arg , context = context ) NEW_LINE currency_pool = self . pool . get ( ' res . currency ' ) NEW_LINE for order in self . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT line_amount = sum ( [ line . price_subtotal for line in order . order_line if line . is_delivery ] ) NEW_LINE currency = order . pricelist_id . currency_id NEW_LINE res [ order . id ] [ ' amount _ delivery ' ] = currency_pool . round ( cr , uid , currency , line_amount ) NEW_LINE DEDENT return res NEW_LINE DEDENT def _get_order ( self , cr , uid , ids , context = None ) : NEW_LINE INDENT result = { } NEW_LINE for line in self . pool . get ( ' sale . order . line ' ) . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT result [ line . order_id . id ] = True NEW_LINE DEDENT return result . keys ( ) NEW_LINE DEDENT _columns = { ' amount _ delivery ' : fields . function ( _amount_all_wrapper , type = ' float ' , digits_compute = decimal_precision . get_precision ( ' Account ' ) , string = ' Delivery ▁ Amount ' , store = { ' sale . order ' : ( lambda self , cr , uid , ids , c = { } : ids , [ ' order _ line ' ] , 10 ) , ' sale . order . line ' : ( _get_order , [ ' price _ unit ' , ' tax _ id ' , ' discount ' , ' product _ uom _ qty ' ] , 10 ) , } , multi = ' sums ' , help = " The ▁ amount ▁ without ▁ tax . " , track_visibility = ' always ' ) , ' website _ order _ line ' : fields . one2many ( ' sale . order . line ' , ' order _ id ' , string = ' Order ▁ Lines ▁ displayed ▁ on ▁ Website ' , readonly = True , domain = [ ( ' is _ delivery ' , ' = ' , False ) ] , help = ' Order ▁ Lines ▁ to ▁ be ▁ displayed ▁ on ▁ the ▁ website . ▁ They ▁ should ▁ not ▁ be ▁ used ▁ for ▁ computation ▁ purpose . ' , ) , } NEW_LINE def _check_carrier_quotation ( self , cr , uid , order , force_carrier_id = None , context = None ) : NEW_LINE INDENT carrier_obj = self . pool . get ( ' delivery . carrier ' ) NEW_LINE # ▁ check ▁ to ▁ add ▁ or ▁ remove ▁ carrier _ id ENDCOM if not order : NEW_LINE INDENT return False NEW_LINE DEDENT if all ( line . product_id . type == " service " for line in order . website_order_line ) : NEW_LINE INDENT order . write ( { ' carrier _ id ' : None } ) NEW_LINE self . pool [ ' sale . order ' ] . _delivery_unset ( cr , SUPERUSER_ID , [ order . id ] , context = context ) NEW_LINE return True NEW_LINE DEDENT else : NEW_LINE INDENT carrier_id = force_carrier_id or order . carrier_id . id NEW_LINE carrier_ids = self . _get_delivery_methods ( cr , uid , order , context = context ) NEW_LINE if carrier_id : NEW_LINE INDENT if carrier_id not in carrier_ids : NEW_LINE INDENT carrier_id = False NEW_LINE DEDENT else : NEW_LINE INDENT carrier_ids . remove ( carrier_id ) NEW_LINE carrier_ids . insert ( 0 , carrier_id ) NEW_LINE DEDENT DEDENT if force_carrier_id or not carrier_id or not carrier_id in carrier_ids : NEW_LINE INDENT for delivery_id in carrier_ids : NEW_LINE INDENT grid_id = carrier_obj . grid_get ( cr , SUPERUSER_ID , [ delivery_id ] , order . partner_shipping_id . id ) NEW_LINE if grid_id : NEW_LINE INDENT carrier_id = delivery_id NEW_LINE break NEW_LINE DEDENT DEDENT order . write ( { ' carrier _ id ' : carrier_id } ) NEW_LINE DEDENT if carrier_id : NEW_LINE INDENT order . delivery_set ( ) NEW_LINE DEDENT else : NEW_LINE INDENT order . _delivery_unset ( ) NEW_LINE DEDENT DEDENT return bool ( carrier_id ) NEW_LINE DEDENT def _get_delivery_methods ( self , cr , uid , order , context = None ) : NEW_LINE INDENT carrier_obj = self . pool . get ( ' delivery . carrier ' ) NEW_LINE delivery_ids = carrier_obj . search ( cr , uid , [ ( ' website _ published ' , ' = ' , True ) ] , context = context ) NEW_LINE # ▁ Following ▁ loop ▁ is ▁ done ▁ to ▁ avoid ▁ displaying ▁ delivery ▁ methods ▁ who ▁ are ▁ not ▁ available ▁ for ▁ this ▁ order ENDCOM # ▁ This ▁ can ▁ surely ▁ be ▁ done ▁ in ▁ a ▁ more ▁ efficient ▁ way , ▁ but ▁ at ▁ the ▁ moment , ▁ it ▁ mimics ▁ the ▁ way ▁ it ' s ENDCOM # ▁ done ▁ in ▁ delivery _ set ▁ method ▁ of ▁ sale . py , ▁ from ▁ delivery ▁ module ENDCOM for delivery_id in carrier_obj . browse ( cr , SUPERUSER_ID , delivery_ids , context = dict ( context , order_id = order . id ) ) : NEW_LINE INDENT if not delivery_id . available : NEW_LINE INDENT delivery_ids . remove ( delivery_id . id ) NEW_LINE DEDENT DEDENT return delivery_ids NEW_LINE DEDENT def _get_errors ( self , cr , uid , order , context = None ) : NEW_LINE INDENT errors = super ( SaleOrder , self ) . _get_errors ( cr , uid , order , context = context ) NEW_LINE if not self . _get_delivery_methods ( cr , uid , order , context = context ) : NEW_LINE INDENT errors . append ( ( ' No ▁ delivery ▁ method ▁ available ' , ' There ▁ is ▁ no ▁ available ▁ delivery ▁ method ▁ for ▁ your ▁ order ' ) ) NEW_LINE DEDENT return errors NEW_LINE DEDENT def _get_website_data ( self , cr , uid , order , context = None ) : NEW_LINE INDENT """ ▁ Override ▁ to ▁ add ▁ delivery - related ▁ website ▁ data . ▁ """ NEW_LINE values = super ( SaleOrder , self ) . _get_website_data ( cr , uid , order , context = context ) NEW_LINE # ▁ We ▁ need ▁ a ▁ delivery ▁ only ▁ if ▁ we ▁ have ▁ stockable ▁ products ENDCOM has_stockable_products = False NEW_LINE for line in order . order_line : NEW_LINE INDENT if line . product_id . type in ( ' consu ' , ' product ' ) : NEW_LINE INDENT has_stockable_products = True NEW_LINE DEDENT DEDENT if not has_stockable_products : NEW_LINE INDENT return values NEW_LINE DEDENT delivery_ctx = dict ( context , order_id = order . id ) NEW_LINE DeliveryCarrier = self . pool . get ( ' delivery . carrier ' ) NEW_LINE delivery_ids = self . _get_delivery_methods ( cr , uid , order , context = context ) NEW_LINE values [ ' deliveries ' ] = DeliveryCarrier . browse ( cr , SUPERUSER_ID , delivery_ids , context = delivery_ctx ) NEW_LINE return values NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="mcrowson/django/tree/master/tests/choices/tests.py"> from django . test import TestCase NEW_LINE from . models import Person NEW_LINE class ChoicesTests ( TestCase ) : NEW_LINE INDENT def test_display ( self ) : NEW_LINE INDENT a = Person . objects . create ( name = ' Adrian ' , gender = ' M ' ) NEW_LINE s = Person . objects . create ( name = ' Sara ' , gender = ' F ' ) NEW_LINE self . assertEqual ( a . gender , ' M ' ) NEW_LINE self . assertEqual ( s . gender , ' F ' ) NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' Male ' ) NEW_LINE self . assertEqual ( s . get_gender_display ( ) , ' Female ' ) NEW_LINE # ▁ If ▁ the ▁ value ▁ for ▁ the ▁ field ▁ doesn ' t ▁ correspond ▁ to ▁ a ▁ valid ▁ choice , ENDCOM # ▁ the ▁ value ▁ itself ▁ is ▁ provided ▁ as ▁ a ▁ display ▁ value . ENDCOM a . gender = ' ' NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' ' ) NEW_LINE a . gender = ' U ' NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' U ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="sparkslabs/kamaelia/tree/master/Sketches/CL/Topology/src/RelationTopology/Util/RelationAttributeParsing.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2010 ▁ British ▁ Broadcasting ▁ Corporation ▁ and ▁ Kamaelia ▁ Contributors ( 1 ) ENDCOM # ▁ ( 1 ) ▁ Kamaelia ▁ Contributors ▁ are ▁ listed ▁ in ▁ the ▁ AUTHORS ▁ file ▁ and ▁ at ENDCOM # ▁ http : / / www . kamaelia . org / AUTHORS ▁ - ▁ please ▁ extend ▁ this ▁ file , ENDCOM # ▁ not ▁ this ▁ notice . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ENDCOM # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ENDCOM # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ENDCOM # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ENDCOM # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ENDCOM # ▁ limitations ▁ under ▁ the ▁ License . ENDCOM """ \ STRNEWLINE = = = = = STRNEWLINE Parse ▁ entities , ▁ attributes ▁ and ▁ relations ▁ definition ▁ received STRNEWLINE = = = = = STRNEWLINE STRNEWLINE Parse ▁ entities ▁ and ▁ relations ▁ definition ▁ received , ▁ one ▁ line ▁ one ▁ time . STRNEWLINE STRNEWLINE 1 . ▁ Definition ▁ format STRNEWLINE 1 . ) ▁ Empty ▁ line ▁ ( including ▁ any ▁ number ▁ of ▁ white ▁ spaces ) STRNEWLINE 2 . ) ▁ Line ▁ starting ▁ with ▁ # ▁ to ▁ comment STRNEWLINE 3 . ) ▁ Entity ▁ definition STRNEWLINE Example : STRNEWLINE - - - - - STRNEWLINE person ▁ mum STRNEWLINE person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80 STRNEWLINE person ▁ son ▁ gender = " male " , photo = " . . / Files / son . gif , width = 60 , height = 60 " STRNEWLINE person ▁ daughter ▁ radius = 100 STRNEWLINE 4 . ) ▁ Relation ▁ definition STRNEWLINE Example : ▁ STRNEWLINE - - - - - STRNEWLINE childof ( mum , ▁ son ) STRNEWLINE STRNEWLINE 2 . ▁ NOTE : STRNEWLINE 1 . ) ▁ Any ▁ number ▁ of ▁ spaces ▁ can ▁ exist ▁ before , ▁ after ▁ and ▁ between ▁ the ▁ above ▁ line STRNEWLINE Example : STRNEWLINE - - - - - STRNEWLINE ▁ person ▁ mum ▁ STRNEWLINE ▁ childof ▁ ( ▁ mum ▁ , ▁ son ▁ ) ▁ STRNEWLINE 2 . ) ▁ Parse ▁ one ▁ line ▁ one ▁ time ▁ and ▁ then ▁ send ▁ out STRNEWLINE 3 . ) ▁ Entity ▁ definition ▁ needs ▁ to ▁ come ▁ before ▁ relation ▁ definition ▁ STRNEWLINE if ▁ the ▁ relations ▁ definition ▁ uses ▁ the ▁ entity STRNEWLINE 4 . ) ▁ When ▁ encountering ▁ repeated ▁ entity , ▁ it ▁ will ▁ update ▁ its ▁ attributes ▁ rather ▁ than STRNEWLINE create ▁ a ▁ new ▁ one . ▁ STRNEWLINE """ NEW_LINE def parseEntity ( entityLine ) : NEW_LINE INDENT """ ▁ parse ▁ entity ▁ line ▁ """ NEW_LINE result = entityLine . split ( ) NEW_LINE # entity _ ID ▁ = ▁ result [ 0 ] + ' _ ' + result [ 1 ] ENDCOM entity_name = result [ 1 ] NEW_LINE # particle ▁ = ▁ ' - ' ENDCOM particle = ' GenericParticle ' NEW_LINE if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE # attributes ▁ = ▁ attributes . lower ( ) ENDCOM attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes + ' , type = ' + result [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' type = ' + result [ 0 ] NEW_LINE DEDENT return " ADD ▁ NODE ▁ % s ▁ % s ▁ auto ▁ % s ▁ % s " % ( entity_name , entity_name , particle , attributes ) NEW_LINE DEDENT def parseUpdatedEntity ( entityLine ) : NEW_LINE INDENT """ ▁ parse ▁ entity ▁ line ▁ """ NEW_LINE result = entityLine . split ( ) NEW_LINE # entity _ ID ▁ = ▁ result [ 0 ] + ' _ ' + result [ 1 ] ENDCOM entity_name = result [ 1 ] NEW_LINE # particle ▁ = ▁ ' - ' ENDCOM # particle ▁ = ▁ ' GenericParticle ' ENDCOM if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE # attributes ▁ = ▁ attributes . lower ( ) ENDCOM attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes . replace ( ' name ' , ' label ' ) NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' label = ' + entity_name NEW_LINE DEDENT return " UPDATE ▁ NODE ▁ % s ▁ % s " % ( entity_name , attributes ) NEW_LINE DEDENT def parseRelation ( relationLine ) : NEW_LINE INDENT """ ▁ parse ▁ relation ▁ line ▁ """ NEW_LINE result = relationLine . split ( ' ( ' ) NEW_LINE relation = result [ 0 ] . strip ( ) NEW_LINE entities_str = result [ 1 ] . rstrip ( ' ) ' ) NEW_LINE entities_list = entities_str . split ( ' , ' ) NEW_LINE src = entities_list [ 0 ] . strip ( ) NEW_LINE dst = entities_list [ 1 ] . strip ( ) NEW_LINE return " ADD ▁ LINK ▁ % s ▁ % s ▁ % s " % ( src , dst , relation ) NEW_LINE DEDENT import re NEW_LINE import Axon NEW_LINE from Axon . Ipc import producerFinished , shutdownMicroprocess NEW_LINE class RelationAttributeParser ( Axon . Component . component ) : NEW_LINE INDENT """ \ STRNEWLINE = = = = = STRNEWLINE A ▁ component ▁ to ▁ parse ▁ entities , ▁ attributes ▁ and ▁ relations ▁ definition STRNEWLINE = = = = = STRNEWLINE """ NEW_LINE def shutdown ( self ) : NEW_LINE INDENT """ ▁ shutdown ▁ method : ▁ define ▁ when ▁ to ▁ shun ▁ down """ NEW_LINE while self . dataReady ( " control " ) : NEW_LINE INDENT data = self . recv ( " control " ) NEW_LINE if isinstance ( data , producerFinished ) or isinstance ( data , shutdownMicroprocess ) : NEW_LINE INDENT self . shutdown_mess = data NEW_LINE return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def main ( self ) : NEW_LINE INDENT """ ▁ main ▁ method : ▁ do ▁ stuff ▁ """ NEW_LINE previousNodes = [ ] NEW_LINE # ▁ Put ▁ all ▁ codes ▁ within ▁ the ▁ loop , ▁ so ▁ that ▁ others ▁ can ▁ be ▁ run ▁ even ▁ it ▁ doesn ' t ▁ shut ▁ down ENDCOM while not self . shutdown ( ) : NEW_LINE INDENT X = [ ] NEW_LINE links = [ ] NEW_LINE nodes = [ ] NEW_LINE updatedNodes = [ ] NEW_LINE while not self . anyReady ( ) : NEW_LINE INDENT self . pause ( ) NEW_LINE yield 1 NEW_LINE DEDENT while self . dataReady ( " inbox " ) : NEW_LINE INDENT L = self . recv ( " inbox " ) NEW_LINE if L . strip ( ) == " " : continue # ▁ empty ▁ line ENDCOM NEW_LINE if L . lstrip ( ) [ 0 ] == " # " : continue # ▁ comment ENDCOM NEW_LINE X . append ( L . strip ( ) ) NEW_LINE # yield ▁ 1 ENDCOM DEDENT for item in X : NEW_LINE INDENT if re . match ( ' ( . + ) \ ( ( . + ) , ( . + ) \ ) ' , item ) : # ▁ relation ENDCOM NEW_LINE INDENT command = parseRelation ( item ) NEW_LINE links . append ( command ) NEW_LINE DEDENT else : NEW_LINE INDENT isRepeated = False NEW_LINE for node in previousNodes : NEW_LINE INDENT if item . split ( ) [ 1 ] == node . split ( ) [ 2 ] : NEW_LINE INDENT isRepeated = True NEW_LINE DEDENT DEDENT if not isRepeated : # ▁ new ▁ entity ENDCOM NEW_LINE INDENT command = parseEntity ( item ) NEW_LINE nodes . append ( command ) NEW_LINE previousNodes . append ( command ) NEW_LINE DEDENT else : # ▁ old ▁ entity ENDCOM NEW_LINE INDENT command = parseUpdatedEntity ( item ) NEW_LINE updatedNodes . append ( command ) NEW_LINE # yield ▁ 1 ENDCOM DEDENT DEDENT DEDENT for node in nodes : NEW_LINE INDENT self . send ( node , " outbox " ) NEW_LINE DEDENT for updatedNode in updatedNodes : NEW_LINE INDENT self . send ( updatedNode , " outbox " ) NEW_LINE DEDENT for link in links : NEW_LINE INDENT self . send ( link , " outbox " ) NEW_LINE DEDENT yield 1 NEW_LINE DEDENT self . send ( self . shutdown_mess , " signal " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT from Kamaelia . Util . DataSource import DataSource NEW_LINE from Kamaelia . Visualisation . PhysicsGraph . lines_to_tokenlists import lines_to_tokenlists NEW_LINE from Kamaelia . Util . Console import ConsoleReader , ConsoleEchoer NEW_LINE from GenericTopologyViewer import GenericTopologyViewer NEW_LINE from Kamaelia . Chassis . Graphline import Graphline NEW_LINE # ▁ Data ▁ can ▁ be ▁ from ▁ both ▁ DataSource ▁ and ▁ console ▁ inputs ENDCOM Graphline ( CONSOLEREADER = ConsoleReader ( ) , DATASOURCE = DataSource ( [ " ▁ ▁ person ▁ ▁ mum ▁ ▁ ▁ gender = female , photo = . . / Files / mum . jpg , width = 80 , height = 80 ▁ " , ' ▁ ▁ ' , """ ▁ ▁ ▁ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """ , ' person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80' , ' ▁ ▁ person ▁ ▁ son ▁ ▁ ▁ gender = male , photo = . . / Files / son . gif , width = 60 , height = 60' , ' person ▁ son ▁ photo = . . / Files / son1 . gif ' , ' person ▁ daughter ▁ radius = 20' , ' person ▁ daughter ▁ radius = 100' , ' ▁ childof ▁ ▁ ( ▁ ▁ mum ▁ ▁ , ▁ son ▁ ▁ ) ▁ ' , ' childof ( mum , ▁ daughter ) ' , ' childof ( dad , ▁ son ) ' , ' childof ( dad , ▁ daughter ) ' ] ) , PARSER = RelationAttributeParser ( ) , TOKENS = lines_to_tokenlists ( ) , VIEWER = GenericTopologyViewer ( ) , CONSOLEECHOER = ConsoleEchoer ( ) , linkages = { ( " CONSOLEREADER " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " DATASOURCE " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " PARSER " , " outbox " ) : ( " TOKENS " , " inbox " ) , ( " TOKENS " , " outbox " ) : ( " VIEWER " , " inbox " ) , ( " VIEWER " , " outbox " ) : ( " CONSOLEECHOER " , " inbox " ) , } ) . run ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="brandonivey/django-marimo/tree/master/marimo/templatetags/writecapture.py"> import json NEW_LINE import random NEW_LINE from django import template NEW_LINE import logging NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE register = template . Library ( ) NEW_LINE def jsescape ( string ) : NEW_LINE INDENT """ ▁ escaping ▁ so ▁ that ▁ javascript ▁ can ▁ be ▁ safely ▁ put ▁ into ▁ json ▁ dicts STRNEWLINE ▁ for ▁ some ▁ reason ▁ json ▁ newline ▁ escaping ▁ isn ' t ▁ enough ? ? STRNEWLINE ▁ """ NEW_LINE return string . replace ( ' < script ' , ' $ BEGINSCRIPT ' ) . replace ( ' < / script > ' , ' $ ENDSCRIPT ' ) . replace ( ' \n ' , ' $ NEWLINE ' ) . replace ( ' ' , ' ' ) NEW_LINE DEDENT @ register . tag ( name = ' writecapture ' ) NEW_LINE def write_capture ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture ▁ [ filter ] ▁ [ " prototype " ] ▁ [ " widget _ id " ] ▁ % } STRNEWLINE ▁ < script ▁ src = " evil . js " > STRNEWLINE ▁ document . write ( ' this ▁ is ▁ evil ' ) STRNEWLINE ▁ < script > STRNEWLINE ▁ { % ▁ endwritecapture ▁ % } STRNEWLINE STRNEWLINE ▁ Wraps ▁ the ▁ enclosed ▁ HTML ▁ inside ▁ of ▁ a ▁ marimo ▁ writecapture ▁ widget . STRNEWLINE STRNEWLINE ▁ The ▁ ` ` filter ` ` ▁ argument ▁ is ▁ a ▁ boolean ▁ ( default ▁ False ) ▁ that ▁ turns ▁ on ▁ a STRNEWLINE ▁ writecapture ▁ feature ▁ called ▁ writeOnGetElementById . ▁ This ▁ fixes ▁ some STRNEWLINE ▁ extra - bad ▁ scripts . STRNEWLINE STRNEWLINE ▁ The ▁ ` ` prototype ` ` ▁ argument ▁ defaults ▁ to ▁ ' writecapture . ' ▁ You ▁ will ▁ only STRNEWLINE ▁ need ▁ to ▁ use ▁ this ▁ if ▁ you ▁ have ▁ subclassed ▁ marimo ' s ▁ built - in ▁ writecapture STRNEWLINE ▁ widget ▁ and ▁ want ▁ to ▁ use ▁ that ▁ instead . STRNEWLINE STRNEWLINE ▁ The ▁ ` ` widget _ id ` ` ▁ argument ▁ defaults ▁ to ▁ a ▁ ' writecapture _ < randomnumber > . ' STRNEWLINE ▁ Use ▁ this ▁ only ▁ if ▁ you ▁ need ▁ to ▁ specify ▁ an ▁ alternate ▁ element ▁ id ▁ in ▁ the ▁ DOM STRNEWLINE ▁ to ▁ write ▁ to ▁ ( otherwise ▁ one ▁ will ▁ be ▁ created ▁ for ▁ you ▁ at ▁ the ▁ site ▁ of ▁ the STRNEWLINE ▁ { % writecapture % } ▁ invocation ) . . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE # ▁ TODO ▁ should ▁ work ▁ with ▁ marimo ▁ fast ▁ and ▁ widget _ id ▁ should ▁ be ▁ resolved ▁ maybe ENDCOM tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 4 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture ▁ block ▁ takes ▁ at ▁ most ▁ 3 ▁ arguments " ) NEW_LINE DEDENT nodelist = parser . parse ( ( ' endwritecapture ' , ) ) NEW_LINE parser . delete_first_token ( ) NEW_LINE if len ( tokens ) > 1 : NEW_LINE INDENT script_filter = tokens [ 1 ] NEW_LINE if script_filter == ' False ' : NEW_LINE INDENT script_filter = False NEW_LINE DEDENT elif script_filter == ' True ' : NEW_LINE INDENT script_filter = True NEW_LINE DEDENT else : NEW_LINE INDENT script_filter = template . Variable ( script_filter ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT script_filter = False NEW_LINE DEDENT return WriteCaptureNode ( nodelist , script_filter , * tokens [ 2 : ] ) NEW_LINE DEDENT class WriteCaptureNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , nodelist , script_filter = False , prototype = ' writecapture _ widget ' , widget_id = None ) : NEW_LINE INDENT self . nodelist = nodelist NEW_LINE self . script_filter = script_filter NEW_LINE self . prototype = prototype NEW_LINE self . widget_id = widget_id NEW_LINE if not self . widget_id : NEW_LINE INDENT self . widget_id = ' writecapture ' + str ( random . randint ( 0 , 99999999 ) ) NEW_LINE DEDENT DEDENT def render ( self , context ) : NEW_LINE INDENT eviloutput = jsescape ( self . nodelist . render ( context ) ) NEW_LINE if isinstance ( self . script_filter , template . Variable ) : NEW_LINE INDENT self . script_filter = bool ( self . script_filter . resolve ( context ) ) NEW_LINE # ▁ Set ▁ this ▁ flag ▁ in ▁ your ▁ template ▁ tag ▁ for ▁ advanced ▁ write ▁ capture ▁ widget ▁ sanitation . ENDCOM # ▁ Source : ▁ https : / / github . com / iamnoah / writeCapture / wiki / Usage ENDCOM DEDENT global_compatibility_mode = context . get ( ' wc _ compatibility _ mode ' , None ) NEW_LINE if global_compatibility_mode is None : NEW_LINE INDENT wc_compatibility_mode = self . script_filter NEW_LINE DEDENT else : NEW_LINE INDENT wc_compatibility_mode = global_compatibility_mode NEW_LINE DEDENT widget_dict = dict ( widget_prototype = self . prototype , id = self . widget_id , html = eviloutput , wc_compatibility_mode = wc_compatibility_mode , ) NEW_LINE output = """ < div ▁ id = " { widget _ id } " > < / div > STRNEWLINE < script ▁ type = " text / javascript " > STRNEWLINE ▁ ▁ ▁ ▁ marimo . emit ( ' { widget _ id } _ ready ' ) ; STRNEWLINE ▁ ▁ ▁ ▁ marimo . add _ widget ( { widget _ json } ) ; STRNEWLINE < / script > """ NEW_LINE output = output . format ( widget_id = self . widget_id , widget_json = json . dumps ( widget_dict ) , ) NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture _ delay ▁ [ event _ name ] ▁ % } STRNEWLINE ▁ """ NEW_LINE tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE # ▁ this ▁ should ▁ only ▁ be ▁ used ▁ once ▁ per ▁ page ▁ if ▁ it ' s ▁ uses ▁ a ▁ second ▁ time ENDCOM # ▁ overwrite ▁ but ▁ log ▁ an ▁ error ENDCOM DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture _ delay ▁ [ event _ name ] ▁ % } STRNEWLINE ▁ """ NEW_LINE tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE # ▁ this ▁ should ▁ only ▁ be ▁ used ▁ once ▁ per ▁ page ▁ if ▁ it ' s ▁ uses ▁ a ▁ second ▁ time ENDCOM # ▁ overwrite ▁ but ▁ log ▁ an ▁ error ENDCOM DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT """ STRNEWLINE ▁ Syntax : : STRNEWLINE ▁ { % ▁ writecapture _ delay ▁ [ event _ name ] ▁ % } STRNEWLINE ▁ """ NEW_LINE tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE # ▁ this ▁ should ▁ only ▁ be ▁ used ▁ once ▁ per ▁ page ▁ if ▁ it ' s ▁ uses ▁ a ▁ second ▁ time ENDCOM # ▁ overwrite ▁ but ▁ log ▁ an ▁ error ENDCOM DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Hernanarce/pelisalacarta/tree/master/python/version-mediaserver/platformcode/platformtools.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ pelisalacarta ▁ 4 ENDCOM # ▁ Copyright ▁ 2015 ▁ tvalacarta @ gmail . com ENDCOM # ▁ http : / / blog . tvalacarta . info / plugin - xbmc / pelisalacarta / ENDCOM # ▁ Distributed ▁ under ▁ the ▁ terms ▁ of ▁ GNU ▁ General ▁ Public ▁ License ▁ v3 ▁ ( GPLv3 ) ENDCOM # ▁ http : / / www . gnu . org / licenses / gpl - 3.0 . html ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ pelisalacarta ▁ 4 . ENDCOM # ▁ pelisalacarta ▁ 4 ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ pelisalacarta ▁ 4 ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ pelisalacarta ▁ 4 . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM # ▁ platformtools ENDCOM # ▁ Herramientas ▁ responsables ▁ de ▁ adaptar ▁ los ▁ diferentes ▁ ENDCOM # ▁ cuadros ▁ de ▁ dialogo ▁ a ▁ una ▁ plataforma ▁ en ▁ concreto , ENDCOM # ▁ en ▁ este ▁ caso ▁ Mediserver . ENDCOM # ▁ version ▁ 1.3 ENDCOM import os NEW_LINE import sys NEW_LINE from core import config NEW_LINE from core import logger NEW_LINE import threading NEW_LINE controllers = { } NEW_LINE def dialog_ok ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_ok ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_notification ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_notification ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_yesno ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_yesno ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_select ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_select ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress_bg ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress_bg ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_input ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_input ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_numeric ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_numeric ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_refresh ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_refresh ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_update ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_update ( * args , ** kwargs ) NEW_LINE DEDENT def render_items ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . render_items ( * args , ** kwargs ) NEW_LINE DEDENT def is_playing ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . is_playing ( * args , ** kwargs ) NEW_LINE DEDENT def play_video ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . play_video ( * args , ** kwargs ) NEW_LINE DEDENT def open_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . open_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_channel_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_channel_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_video_info ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_video_info ( * args , ** kwargs ) NEW_LINE DEDENT def show_recaptcha ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_recaptcha ( * args , ** kwargs ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="agabrown/PyGaia/tree/master/pygaia/utils.py"> __all__ = [ ' enum ' , ' degreesToRadians ' , ' radiansToDegrees ' ] NEW_LINE import numpy as np NEW_LINE from pygaia . astrometry . constants import auKmYearPerSec NEW_LINE def enum ( typename , field_names ) : NEW_LINE INDENT """ STRNEWLINE ▁ Create ▁ a ▁ new ▁ enumeration ▁ type . STRNEWLINE ▁ STRNEWLINE ▁ Code ▁ is ▁ copyright ▁ ( c ) ▁ Gabriel ▁ Genellina , ▁ 2010 , ▁ MIT ▁ License . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ typename ▁ - ▁ Name ▁ of ▁ the ▁ enumerated ▁ type STRNEWLINE ▁ field _ names ▁ - ▁ Names ▁ of ▁ the ▁ fields ▁ of ▁ the ▁ enumerated ▁ type STRNEWLINE ▁ """ NEW_LINE if isinstance ( field_names , str ) : NEW_LINE INDENT field_names = field_names . replace ( ' , ' , ' ▁ ' ) . split ( ) NEW_LINE DEDENT d = dict ( ( reversed ( nv ) for nv in enumerate ( field_names ) ) , __slots__ = ( ) ) NEW_LINE return type ( typename , ( object , ) , d ) ( ) NEW_LINE DEDENT def degreesToRadians ( angle ) : NEW_LINE INDENT """ STRNEWLINE ▁ Convert ▁ from ▁ degrees ▁ to ▁ radians . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ angle ▁ - ▁ angle ▁ in ▁ degrees STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ Angle ▁ in ▁ radians . STRNEWLINE ▁ """ NEW_LINE return angle / 180.0 * np . pi NEW_LINE DEDENT def radiansToDegrees ( angle ) : NEW_LINE INDENT """ STRNEWLINE ▁ Convert ▁ from ▁ radians ▁ to ▁ degrees . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ angle ▁ - ▁ angle ▁ in ▁ radians . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ STRNEWLINE ▁ Angle ▁ in ▁ degrees . STRNEWLINE ▁ """ NEW_LINE return angle / np . pi * 180.0 NEW_LINE DEDENT def construct_covariance_matrix ( cvec , parallax , radial_velocity , radial_velocity_error ) : NEW_LINE INDENT """ STRNEWLINE ▁ Take ▁ the ▁ astrometric ▁ parameter ▁ standard ▁ uncertainties ▁ and ▁ the ▁ uncertainty ▁ correlations ▁ as ▁ quoted ▁ in STRNEWLINE ▁ the ▁ Gaia ▁ catalogue ▁ and ▁ construct ▁ the ▁ covariance ▁ matrix . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ cvec ▁ : ▁ array _ like STRNEWLINE ▁ Array ▁ of ▁ shape ▁ ( 15 , ) ▁ ( 1 ▁ source ) ▁ or ▁ ( n , 15 ) ▁ ( n ▁ sources ) ▁ for ▁ the ▁ astrometric ▁ parameter ▁ standard STRNEWLINE ▁ uncertainties ▁ and ▁ their ▁ correlations , ▁ as ▁ listed ▁ in ▁ the ▁ Gaia ▁ catalogue ▁ [ ra _ error , ▁ dec _ error , STRNEWLINE ▁ parallax _ error , ▁ pmra _ error , ▁ pmdec _ error , ▁ ra _ dec _ corr , ▁ ra _ parallax _ corr , ▁ ra _ pmra _ corr , STRNEWLINE ▁ ra _ pmdec _ corr , ▁ dec _ parallax _ corr , ▁ dec _ pmra _ corr , ▁ dec _ pmdec _ corr , ▁ parallax _ pmra _ corr , STRNEWLINE ▁ parallax _ pmdec _ corr , ▁ pmra _ pmdec _ corr ] . ▁ Units ▁ are ▁ ( mas ^ 2 , ▁ mas ^ 2 / yr , ▁ mas ^ 2 / yr ^ 2 ) . STRNEWLINE ▁ STRNEWLINE ▁ parallax ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ parallax ▁ ( mas ) . STRNEWLINE ▁ STRNEWLINE ▁ radial _ velocity ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ radial ▁ velocity ▁ ( km / s , ▁ does ▁ not ▁ have ▁ to ▁ be ▁ from ▁ Gaia ▁ RVS ! ) . ▁ If ▁ the ▁ radial ▁ velocity ▁ is ▁ not STRNEWLINE ▁ known ▁ it ▁ can ▁ be ▁ set ▁ to ▁ zero . STRNEWLINE STRNEWLINE ▁ radial _ velocity _ error ▁ : ▁ array _ like ▁ ( n ▁ elements ) STRNEWLINE ▁ Source ▁ radial ▁ velocity ▁ uncertainty ▁ ( km / s ) . ▁ If ▁ the ▁ radial ▁ velocity ▁ is ▁ not ▁ know ▁ this ▁ can ▁ be ▁ set ▁ to STRNEWLINE ▁ the ▁ radial ▁ velocity ▁ dispersion ▁ for ▁ the ▁ population ▁ the ▁ source ▁ was ▁ drawn ▁ from . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE STRNEWLINE ▁ Covariance ▁ matrix ▁ as ▁ a ▁ 6x6 ▁ array . STRNEWLINE ▁ """ NEW_LINE if np . ndim ( cvec ) == 1 : NEW_LINE INDENT cmat = np . zeros ( ( 1 , 6 , 6 ) ) NEW_LINE nsources = 1 NEW_LINE cv = np . atleast_2d ( cvec ) NEW_LINE DEDENT else : NEW_LINE INDENT nsources = cvec . shape [ 0 ] NEW_LINE cmat = np . zeros ( ( nsources , 6 , 6 ) ) NEW_LINE cv = cvec NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 0 : 5 ] = cv [ k , 0 : 5 ] ** 2 NEW_LINE DEDENT iu = np . triu_indices ( 5 , k = 1 ) NEW_LINE for k in range ( 10 ) : NEW_LINE INDENT i = iu [ 0 ] [ k ] NEW_LINE j = iu [ 1 ] [ k ] NEW_LINE cmat [ : , i , j ] = cv [ : , i ] * cv [ : , j ] * cv [ : , k + 5 ] NEW_LINE cmat [ : , j , i ] = cmat [ : , i , j ] NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 5 ] = cmat [ k , 0 : 5 , 2 ] * np . atleast_1d ( radial_velocity ) [ k ] / auKmYearPerSec NEW_LINE DEDENT cmat [ : , 5 , 0 : 5 ] = cmat [ : , 0 : 5 , 5 ] NEW_LINE cmat [ : , 5 , 5 ] = cmat [ : , 2 , 2 ] * ( radial_velocity ** 2 + radial_velocity_error ** 2 ) / auKmYearPerSec ** 2 + ( parallax * radial_velocity_error / auKmYearPerSec ) ** 2 NEW_LINE return np . squeeze ( cmat ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="Thhhza/XlsxWriter/tree/master/xlsxwriter/test/comparison/test_chart_column04.py"> # ▁ Tests ▁ for ▁ XlsxWriter . ENDCOM # ▁ Copyright ▁ ( c ) , ▁ 2013-2015 , ▁ John ▁ McNamara , ▁ jmcnamara @ cpan . org ENDCOM from . . excel_comparsion_test import ExcelComparisonTest NEW_LINE from ... workbook import Workbook NEW_LINE class TestCompareXLSXFiles ( ExcelComparisonTest ) : NEW_LINE INDENT """ STRNEWLINE ▁ Test ▁ file ▁ created ▁ by ▁ XlsxWriter ▁ against ▁ a ▁ file ▁ created ▁ by ▁ Excel . STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def setUp ( self ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE filename = ' chart _ column04 . xlsx ' NEW_LINE test_dir = ' xlsxwriter / test / comparison / ' NEW_LINE self . got_filename = test_dir + ' _ test _ ' + filename NEW_LINE self . exp_filename = test_dir + ' xlsx _ files / ' + filename NEW_LINE self . ignore_files = [ ] NEW_LINE self . ignore_elements = { ' xl / workbook . xml ' : [ ' < fileVersion ' , ' < calcPr ' ] } NEW_LINE DEDENT def test_create_file ( self ) : NEW_LINE INDENT """ Test ▁ the ▁ creation ▁ of ▁ a ▁ simple ▁ XlsxWriter ▁ file . """ NEW_LINE workbook = Workbook ( self . got_filename ) NEW_LINE worksheet = workbook . add_worksheet ( ) NEW_LINE chart = workbook . add_chart ( { ' type ' : ' column ' } ) NEW_LINE chart . axis_ids = [ 63591936 , 63593856 ] NEW_LINE chart . axis2_ids = [ 63613568 , 63612032 ] NEW_LINE data = [ [ 1 , 2 , 3 , 4 , 5 ] , [ 6 , 8 , 6 , 4 , 2 ] ] NEW_LINE worksheet . write_column ( ' A1' , data [ 0 ] ) NEW_LINE worksheet . write_column ( ' B1' , data [ 1 ] ) NEW_LINE chart . add_series ( { ' values ' : ' = Sheet1 ! $ A $ 1 : $ A $ 5' } ) NEW_LINE chart . add_series ( { ' values ' : ' = Sheet1 ! $ B $ 1 : $ B $ 5' , ' y2 _ axis ' : 1 } ) NEW_LINE worksheet . insert_chart ( ' E9' , chart ) NEW_LINE workbook . close ( ) NEW_LINE self . assertExcelEqual ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="hobson/pyexiv2/tree/master/test/usercomment.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2010 ▁ Olivier ▁ Tilloy ▁ < olivier @ tilloy . net > ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ the ▁ pyexiv2 ▁ distribution . ENDCOM # ▁ pyexiv2 ▁ is ▁ free ▁ software ; ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ENDCOM # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation ; ▁ either ▁ version ▁ 2 ENDCOM # ▁ of ▁ the ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ pyexiv2 ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ pyexiv2 ; ▁ if ▁ not , ▁ write ▁ to ▁ the ▁ Free ▁ Software ENDCOM # ▁ Foundation , ▁ Inc . , ▁ 51 ▁ Franklin ▁ Street , ▁ 5th ▁ Floor , ▁ Boston , ▁ MA ▁ 02110-1301 ▁ USA . ENDCOM # ▁ Author : ▁ Olivier ▁ Tilloy ▁ < olivier @ tilloy . net > ENDCOM from pyexiv2 . metadata import ImageMetadata NEW_LINE import unittest NEW_LINE import testutils NEW_LINE import os NEW_LINE import tempfile NEW_LINE from testutils import EMPTY_JPG_DATA NEW_LINE class TestUserCommentReadWrite ( unittest . TestCase ) : NEW_LINE INDENT checksums = { ' usercomment - ascii . jpg ' : ' ad29ac65fb6f63c8361aaed6cb02f8c7' , ' usercomment - unicode - ii . jpg ' : '13b7cc09129a8677f2cf18634f5abd3c ' , ' usercomment - unicode - mm . jpg ' : '7addfed7823c556ba489cd4ab2037200' , } NEW_LINE def _read_image ( self , filename ) : NEW_LINE INDENT filepath = testutils . get_absolute_file_path ( os . path . join ( ' data ' , filename ) ) NEW_LINE self . assert_ ( testutils . CheckFileSum ( filepath , self . checksums [ filename ] ) ) NEW_LINE m = ImageMetadata ( filepath ) NEW_LINE m . read ( ) NEW_LINE return m NEW_LINE DEDENT def _expected_raw_value ( self , endianness , value ) : NEW_LINE INDENT from pyexiv2 import __exiv2_version__ NEW_LINE if __exiv2_version__ >= '0.20' : NEW_LINE INDENT return value NEW_LINE DEDENT else : NEW_LINE INDENT encodings = { ' ii ' : ' utf - 16le ' , ' mm ' : ' utf - 16be ' } NEW_LINE return value . decode ( ' utf - 8' ) . encode ( encodings [ endianness ] ) NEW_LINE DEDENT DEDENT def test_read_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Ascii " ▁ deja ▁ vu ' ) NEW_LINE self . assertEqual ( tag . value , u ' deja ▁ vu ' ) NEW_LINE DEDENT def test_read_unicode_little_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - ii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' ii ' , ' déjà ▁ vu ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' déjà ▁ vu ' ) NEW_LINE DEDENT def test_read_unicode_big_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - mm . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' mm ' , ' déjà ▁ vu ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' déjà ▁ vu ' ) NEW_LINE DEDENT def test_write_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = ' foo ▁ bar ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Ascii " ▁ foo ▁ bar ' ) NEW_LINE self . assertEqual ( tag . value , u ' foo ▁ bar ' ) NEW_LINE DEDENT def test_write_unicode_over_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u ' déjà ▁ vu ' NEW_LINE self . assertEqual ( tag . raw_value , ' déjà ▁ vu ' ) NEW_LINE self . assertEqual ( tag . value , u ' déjà ▁ vu ' ) NEW_LINE DEDENT def test_write_unicode_little_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - ii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u ' DÉJÀ ▁ VU ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' ii ' , ' DÉJÀ ▁ VU ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' DÉJÀ ▁ VU ' ) NEW_LINE DEDENT def test_write_unicode_big_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - mm . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u ' DÉJÀ ▁ VU ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' mm ' , ' DÉJÀ ▁ VU ' ) ) NEW_LINE self . assertEqual ( tag . value , u ' DÉJÀ ▁ VU ' ) NEW_LINE DEDENT DEDENT class TestUserCommentAdd ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE # ▁ Create ▁ an ▁ empty ▁ image ▁ file ENDCOM INDENT fd , self . pathname = tempfile . mkstemp ( suffix = ' . jpg ' ) NEW_LINE os . write ( fd , EMPTY_JPG_DATA ) NEW_LINE os . close ( fd ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT os . remove ( self . pathname ) NEW_LINE DEDENT def _test_add_comment ( self , value ) : NEW_LINE INDENT metadata = ImageMetadata ( self . pathname ) NEW_LINE metadata . read ( ) NEW_LINE key = ' Exif . Photo . UserComment ' NEW_LINE metadata [ key ] = value NEW_LINE metadata . write ( ) NEW_LINE metadata = ImageMetadata ( self . pathname ) NEW_LINE metadata . read ( ) NEW_LINE self . assert_ ( key in metadata . exif_keys ) NEW_LINE tag = metadata [ key ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . value , value ) NEW_LINE DEDENT def test_add_comment_ascii ( self ) : NEW_LINE INDENT self . _test_add_comment ( ' deja ▁ vu ' ) NEW_LINE DEDENT def test_add_comment_unicode ( self ) : NEW_LINE INDENT self . _test_add_comment ( u ' déjà ▁ vu ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="jonathonwalz/ansible/tree/master/test/units/modules/network/f5/test_bigip_iapp_service.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM # ▁ Copyright ▁ 2017 ▁ F5 ▁ Networks ▁ Inc . ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible ENDCOM # ▁ Ansible ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ Ansible . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE import os NEW_LINE import json NEW_LINE import sys NEW_LINE from nose . plugins . skip import SkipTest NEW_LINE if sys . version_info < ( 2 , 7 ) : NEW_LINE INDENT raise SkipTest ( " F5 ▁ Ansible ▁ modules ▁ require ▁ Python ▁ > = ▁ 2.7" ) NEW_LINE DEDENT from ansible . compat . tests import unittest NEW_LINE from ansible . compat . tests . mock import patch , Mock NEW_LINE from ansible . module_utils import basic NEW_LINE from ansible . module_utils . _text import to_bytes NEW_LINE from ansible . module_utils . f5_utils import AnsibleF5Client NEW_LINE try : NEW_LINE INDENT from library . bigip_iapp_service import Parameters NEW_LINE from library . bigip_iapp_service import ModuleManager NEW_LINE from library . bigip_iapp_service import ArgumentSpec NEW_LINE DEDENT except ImportError : NEW_LINE INDENT try : NEW_LINE INDENT from ansible . modules . network . f5 . bigip_iapp_service import Parameters NEW_LINE from ansible . modules . network . f5 . bigip_iapp_service import ModuleManager NEW_LINE from ansible . modules . network . f5 . bigip_iapp_service import ArgumentSpec NEW_LINE DEDENT except ImportError : NEW_LINE INDENT raise SkipTest ( " F5 ▁ Ansible ▁ modules ▁ require ▁ the ▁ f5 - sdk ▁ Python ▁ library " ) NEW_LINE DEDENT DEDENT fixture_path = os . path . join ( os . path . dirname ( __file__ ) , ' fixtures ' ) NEW_LINE fixture_data = { } NEW_LINE def set_module_args ( args ) : NEW_LINE INDENT args = json . dumps ( { ' ANSIBLE _ MODULE _ ARGS ' : args } ) NEW_LINE basic . _ANSIBLE_ARGS = to_bytes ( args ) NEW_LINE DEDENT def load_fixture ( name ) : NEW_LINE INDENT path = os . path . join ( fixture_path , name ) NEW_LINE if path in fixture_data : NEW_LINE INDENT return fixture_data [ path ] NEW_LINE DEDENT with open ( path ) as f : NEW_LINE INDENT data = f . read ( ) NEW_LINE DEDENT try : NEW_LINE INDENT data = json . loads ( data ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT fixture_data [ path ] = data NEW_LINE return data NEW_LINE DEDENT class TestParameters ( unittest . TestCase ) : NEW_LINE INDENT def test_module_parameters_keys ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE # ▁ Assert ▁ the ▁ top - level ▁ keys ENDCOM assert p . name == ' http _ example ' NEW_LINE assert p . partition == ' Common ' NEW_LINE assert p . template == ' / Common / f5 . http ' NEW_LINE DEDENT def test_module_parameters_lists ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' lists ' in p . _values NEW_LINE assert p . lists [ 0 ] [ ' name ' ] == ' irules _ _ irules ' NEW_LINE assert p . lists [ 0 ] [ ' encrypted ' ] == ' no ' NEW_LINE assert len ( p . lists [ 0 ] [ ' value ' ] ) == 1 NEW_LINE assert p . lists [ 0 ] [ ' value ' ] [ 0 ] == ' / Common / lgyft ' NEW_LINE assert p . lists [ 1 ] [ ' name ' ] == ' net _ _ client _ vlan ' NEW_LINE assert p . lists [ 1 ] [ ' encrypted ' ] == ' no ' NEW_LINE assert len ( p . lists [ 1 ] [ ' value ' ] ) == 1 NEW_LINE assert p . lists [ 1 ] [ ' value ' ] [ 0 ] == ' / Common / net2' NEW_LINE DEDENT def test_module_parameters_tables ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' tables ' in p . _values NEW_LINE assert ' columnNames ' in p . tables [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' columnNames ' ] ) == 1 NEW_LINE assert p . tables [ 0 ] [ ' columnNames ' ] [ 0 ] == ' name ' NEW_LINE assert ' name ' in p . tables [ 0 ] NEW_LINE assert p . tables [ 0 ] [ ' name ' ] == ' pool _ _ hosts ' NEW_LINE assert ' rows ' in p . tables [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] ) == 1 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] ) == 1 NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 0 ] == ' demo . example . com ' NEW_LINE assert len ( p . tables [ 1 ] [ ' rows ' ] ) == 2 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert len ( p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] ) == 2 NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 0 ] == '10.1.1.1' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 1 ] == '0' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 1 ] [ ' row ' ] [ 0 ] == '10.1.1.2' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 1 ] [ ' row ' ] [ 1 ] == '0' NEW_LINE DEDENT def test_module_parameters_variables ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' variables ' in p . _values NEW_LINE assert len ( p . variables ) == 34 NEW_LINE # ▁ Assert ▁ one ▁ configuration ▁ value ENDCOM assert ' name ' in p . variables [ 0 ] NEW_LINE assert ' value ' in p . variables [ 0 ] NEW_LINE assert p . variables [ 0 ] [ ' name ' ] == ' afm _ _ dos _ security _ profile ' NEW_LINE assert p . variables [ 0 ] [ ' value ' ] == ' / # do _ not _ use # ' NEW_LINE # ▁ Assert ▁ a ▁ second ▁ configuration ▁ value ENDCOM assert ' name ' in p . variables [ 1 ] NEW_LINE assert ' value ' in p . variables [ 1 ] NEW_LINE assert p . variables [ 1 ] [ ' name ' ] == ' afm _ _ policy ' NEW_LINE assert p . variables [ 1 ] [ ' value ' ] == ' / # do _ not _ use # ' NEW_LINE DEDENT def test_api_parameters_variables ( self ) : NEW_LINE INDENT args = dict ( variables = [ dict ( name = " client _ _ http _ compression " , encrypted = " no " , value = " / # create _ new # " ) ] ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . variables [ 0 ] [ ' name ' ] == ' client _ _ http _ compression ' NEW_LINE DEDENT def test_api_parameters_tables ( self ) : NEW_LINE INDENT args = dict ( tables = [ { " name " : " pool _ _ members " , " columnNames " : [ " addr " , " port " , " connection _ limit " ] , " rows " : [ { " row " : [ "12.12.12.12" , "80" , ] } , { " row " : [ "13.13.13.13" , "443" , 10 ] } ] } ] ) p = Parameters ( args ) NEW_LINE assert p . tables [ 0 ] [ ' name ' ] == ' pool _ _ members ' NEW_LINE assert p . tables [ 0 ] [ ' columnNames ' ] == [ ' addr ' , ' port ' , ' connection _ limit ' ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] ) == 2 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 1 ] NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] == [ '12.12.12.12' , '80' , '0' ] NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 1 ] [ ' row ' ] == [ '13.13.13.13' , '443' , '10' ] NEW_LINE DEDENT def test_module_template_same_partition ( self ) : NEW_LINE INDENT args = dict ( template = ' foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / bar / foo ' NEW_LINE DEDENT def test_module_template_same_partition_full_path ( self ) : NEW_LINE INDENT args = dict ( template = ' / bar / foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / bar / foo ' NEW_LINE DEDENT def test_module_template_different_partition_full_path ( self ) : NEW_LINE INDENT args = dict ( template = ' / Common / foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / Common / foo ' NEW_LINE DEDENT DEDENT @ patch ( ' ansible . module _ utils . f5 _ utils . AnsibleF5Client . _ get _ mgmt _ root ' , return_value = True ) NEW_LINE class TestManager ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . spec = ArgumentSpec ( ) NEW_LINE DEDENT def test_create_service ( self , * args ) : NEW_LINE INDENT parameters = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE set_module_args ( dict ( name = ' foo ' , template = ' f5 . http ' , parameters = parameters , state = ' present ' , password = ' passsword ' , server = ' localhost ' , user = ' admin ' ) ) NEW_LINE client = AnsibleF5Client ( argument_spec = self . spec . argument_spec , supports_check_mode = self . spec . supports_check_mode , f5_product_name = self . spec . f5_product_name ) NEW_LINE mm = ModuleManager ( client ) NEW_LINE # ▁ Override ▁ methods ▁ to ▁ force ▁ specific ▁ logic ▁ in ▁ the ▁ module ▁ to ▁ happen ENDCOM mm . exists = Mock ( return_value = False ) NEW_LINE mm . create_on_device = Mock ( return_value = True ) NEW_LINE results = mm . exec_module ( ) NEW_LINE assert results [ ' changed ' ] is True NEW_LINE DEDENT def test_update_agent_status_traps ( self , * args ) : NEW_LINE INDENT parameters = load_fixture ( ' update _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE set_module_args ( dict ( name = ' foo ' , template = ' f5 . http ' , parameters = parameters , state = ' present ' , password = ' passsword ' , server = ' localhost ' , user = ' admin ' ) ) NEW_LINE # ▁ Configure ▁ the ▁ parameters ▁ that ▁ would ▁ be ▁ returned ▁ by ▁ querying ▁ the ENDCOM # ▁ remote ▁ device ENDCOM parameters = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE current = Parameters ( parameters ) NEW_LINE client = AnsibleF5Client ( argument_spec = self . spec . argument_spec , supports_check_mode = self . spec . supports_check_mode , f5_product_name = self . spec . f5_product_name ) NEW_LINE mm = ModuleManager ( client ) NEW_LINE # ▁ Override ▁ methods ▁ to ▁ force ▁ specific ▁ logic ▁ in ▁ the ▁ module ▁ to ▁ happen ENDCOM mm . exists = Mock ( return_value = True ) NEW_LINE mm . update_on_device = Mock ( return_value = True ) NEW_LINE mm . read_current_from_device = Mock ( return_value = current ) NEW_LINE results = mm . exec_module ( ) NEW_LINE assert results [ ' changed ' ] is True NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="thierry1985/project-1022/tree/master/MISC/TFD-0.2.2/translate/pddl/parser.py"> __all__ = [ " ParseError " , " parse _ nested _ list " ] NEW_LINE class ParseError ( Exception ) : NEW_LINE INDENT pass NEW_LINE # ▁ Basic ▁ functions ▁ for ▁ parsing ▁ PDDL ▁ ( Lisp ) ▁ files . ENDCOM DEDENT def parse_nested_list ( input_file ) : NEW_LINE INDENT tokens = tokenize ( input_file ) NEW_LINE next_token = tokens . next ( ) NEW_LINE if next_token != " ( " : NEW_LINE INDENT raise ParseError ( " Expected ▁ ' ( ' , ▁ got ▁ % s . " % next_token ) NEW_LINE DEDENT result = list ( parse_list_aux ( tokens ) ) NEW_LINE for tok in tokens : # ▁ Check ▁ that ▁ generator ▁ is ▁ exhausted . ENDCOM NEW_LINE INDENT raise ParseError ( " Unexpected ▁ token : ▁ % s . " % tok ) NEW_LINE DEDENT return result NEW_LINE DEDENT def tokenize ( input ) : NEW_LINE INDENT for line in input : NEW_LINE INDENT line = line . split ( " ; " , 1 ) [ 0 ] # ▁ Strip ▁ comments . ENDCOM NEW_LINE line = line . replace ( " ( " , " ▁ ( ▁ " ) . replace ( " ) " , " ▁ ) ▁ " ) . replace ( " ? " , " ▁ ? " ) NEW_LINE for token in line . split ( ) : NEW_LINE INDENT yield token . lower ( ) NEW_LINE DEDENT DEDENT DEDENT def parse_list_aux ( tokenstream ) : NEW_LINE # ▁ Leading ▁ " ( " ▁ has ▁ already ▁ been ▁ swallowed . ENDCOM INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT token = tokenstream . next ( ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise ParseError ( ) NEW_LINE DEDENT if token == " ) " : NEW_LINE INDENT return NEW_LINE DEDENT elif token == " ( " : NEW_LINE INDENT yield list ( parse_list_aux ( tokenstream ) ) NEW_LINE DEDENT else : NEW_LINE INDENT yield token NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Syrcon/servo/tree/master/tests/wpt/web-platform-tests/tools/serve/serve.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import argparse NEW_LINE import json NEW_LINE import os NEW_LINE import signal NEW_LINE import socket NEW_LINE import sys NEW_LINE import threading NEW_LINE import time NEW_LINE import traceback NEW_LINE import urllib2 NEW_LINE import uuid NEW_LINE from collections import defaultdict , OrderedDict NEW_LINE from multiprocessing import Process , Event NEW_LINE from . . import localpaths NEW_LINE import sslutils NEW_LINE from wptserve import server as wptserve , handlers NEW_LINE from wptserve import stash NEW_LINE from wptserve . logger import set_logger NEW_LINE from mod_pywebsocket import standalone as pywebsocket NEW_LINE repo_root = localpaths . repo_root NEW_LINE class WorkersHandler ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . handler = handlers . handler ( self . handle_request ) NEW_LINE DEDENT def __call__ ( self , request , response ) : NEW_LINE INDENT return self . handler ( request , response ) NEW_LINE DEDENT def handle_request ( self , request , response ) : NEW_LINE INDENT worker_path = request . url_parts . path . replace ( " . worker " , " . worker . js " ) NEW_LINE return """ < ! doctype ▁ html > STRNEWLINE < meta ▁ charset = utf - 8 > STRNEWLINE < script ▁ src = " / resources / testharness . js " > < / script > STRNEWLINE < script ▁ src = " / resources / testharnessreport . js " > < / script > STRNEWLINE < div ▁ id = log > < / div > STRNEWLINE < script > STRNEWLINE fetch _ tests _ from _ worker ( new ▁ Worker ( " % s " ) ) ; STRNEWLINE < / script > STRNEWLINE """ % ( worker_path , ) NEW_LINE DEDENT DEDENT rewrites = [ ( " GET " , " / resources / WebIDLParser . js " , " / resources / webidl2 / lib / webidl2 . js " ) ] NEW_LINE subdomains = [ u " www " , u " www1" , u " www2" , u " 天気の良い日 " , u " élève " ] NEW_LINE class RoutesBuilder ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . forbidden_override = [ ( " GET " , " / tools / runner / * " , handlers . file_handler ) , ( " POST " , " / tools / runner / update _ manifest . py " , handlers . python_script_handler ) ] NEW_LINE self . forbidden = [ ( " * " , " / _ certs / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " / tools / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " { spec } / tools / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " / serve . py " , handlers . ErrorHandler ( 404 ) ) ] NEW_LINE self . static = [ ( " GET " , " * . worker " , WorkersHandler ( ) ) ] NEW_LINE self . mountpoint_routes = OrderedDict ( ) NEW_LINE self . add_mount_point ( " / " , None ) NEW_LINE DEDENT def get_routes ( self ) : NEW_LINE INDENT routes = self . forbidden_override + self . forbidden + self . static NEW_LINE # ▁ Using ▁ reversed ▁ here ▁ means ▁ that ▁ mount ▁ points ▁ that ▁ are ▁ added ▁ later ENDCOM # ▁ get ▁ higher ▁ priority . ▁ This ▁ makes ▁ sense ▁ since ▁ / ▁ is ▁ typically ▁ added ENDCOM # ▁ first . ENDCOM for item in reversed ( self . mountpoint_routes . values ( ) ) : NEW_LINE INDENT routes . extend ( item ) NEW_LINE DEDENT return routes NEW_LINE DEDENT def add_static ( self , path , format_args , content_type , route ) : NEW_LINE INDENT handler = handlers . StaticHandler ( path , format_args , content_type ) NEW_LINE self . static . append ( ( b " GET " , str ( route ) , handler ) ) NEW_LINE DEDENT def add_mount_point ( self , url_base , path ) : NEW_LINE INDENT url_base = " / % s / " % url_base . strip ( " / " ) if url_base != " / " else " / " NEW_LINE self . mountpoint_routes [ url_base ] = [ ] NEW_LINE routes = [ ( " GET " , " * . asis " , handlers . AsIsHandler ) , ( " * " , " * . py " , handlers . PythonScriptHandler ) , ( " GET " , " * " , handlers . FileHandler ) ] NEW_LINE for ( method , suffix , handler_cls ) in routes : NEW_LINE INDENT self . mountpoint_routes [ url_base ] . append ( ( method , b " % s % s " % ( str ( url_base ) if url_base != " / " else " " , str ( suffix ) ) , handler_cls ( base_path = path , url_base = url_base ) ) ) NEW_LINE DEDENT DEDENT DEDENT def default_routes ( ) : NEW_LINE INDENT return RoutesBuilder ( ) . get_routes ( ) NEW_LINE DEDENT def setup_logger ( level ) : NEW_LINE INDENT import logging NEW_LINE global logger NEW_LINE logger = logging . getLogger ( " web - platform - tests " ) NEW_LINE logging . basicConfig ( level = getattr ( logging , level . upper ( ) ) ) NEW_LINE set_logger ( logger ) NEW_LINE DEDENT def open_socket ( port ) : NEW_LINE INDENT sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) NEW_LINE if port != 0 : NEW_LINE INDENT sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) NEW_LINE DEDENT sock . bind ( ( '127.0.0.1' , port ) ) NEW_LINE sock . listen ( 5 ) NEW_LINE return sock NEW_LINE DEDENT def get_port ( ) : NEW_LINE INDENT free_socket = open_socket ( 0 ) NEW_LINE port = free_socket . getsockname ( ) [ 1 ] NEW_LINE logger . debug ( " Going ▁ to ▁ use ▁ port ▁ % s " % port ) NEW_LINE free_socket . close ( ) NEW_LINE return port NEW_LINE DEDENT class ServerProc ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . proc = None NEW_LINE self . daemon = None NEW_LINE self . stop = Event ( ) NEW_LINE DEDENT def start ( self , init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT self . proc = Process ( target = self . create_daemon , args = ( init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config ) ) NEW_LINE self . proc . daemon = True NEW_LINE self . proc . start ( ) NEW_LINE DEDENT def create_daemon ( self , init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT try : NEW_LINE INDENT self . daemon = init_func ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE DEDENT except socket . error : NEW_LINE INDENT print >> sys . stderr , " Socket ▁ error ▁ on ▁ port ▁ % s " % port NEW_LINE raise NEW_LINE DEDENT except : NEW_LINE INDENT print >> sys . stderr , traceback . format_exc ( ) NEW_LINE raise NEW_LINE DEDENT if self . daemon : NEW_LINE INDENT try : NEW_LINE INDENT self . daemon . start ( block = False ) NEW_LINE try : NEW_LINE INDENT self . stop . wait ( ) NEW_LINE DEDENT except KeyboardInterrupt : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT print >> sys . stderr , traceback . format_exc ( ) NEW_LINE raise NEW_LINE DEDENT DEDENT DEDENT def wait ( self ) : NEW_LINE INDENT self . stop . set ( ) NEW_LINE self . proc . join ( ) NEW_LINE DEDENT def kill ( self ) : NEW_LINE INDENT self . stop . set ( ) NEW_LINE self . proc . terminate ( ) NEW_LINE self . proc . join ( ) NEW_LINE DEDENT def is_alive ( self ) : NEW_LINE INDENT return self . proc . is_alive ( ) NEW_LINE DEDENT DEDENT def check_subdomains ( host , paths , bind_hostname , ssl_config ) : NEW_LINE INDENT port = get_port ( ) NEW_LINE subdomains = get_subdomains ( host ) NEW_LINE wrapper = ServerProc ( ) NEW_LINE wrapper . start ( start_http_server , host , port , paths , default_routes ( ) , bind_hostname , None , ssl_config ) NEW_LINE connected = False NEW_LINE for i in range ( 10 ) : NEW_LINE INDENT try : NEW_LINE INDENT urllib2 . urlopen ( " http : / / % s : % d / " % ( host , port ) ) NEW_LINE connected = True NEW_LINE break NEW_LINE DEDENT except urllib2 . URLError : NEW_LINE INDENT time . sleep ( 1 ) NEW_LINE DEDENT DEDENT if not connected : NEW_LINE INDENT logger . critical ( " Failed ▁ to ▁ connect ▁ to ▁ test ▁ server ▁ on ▁ http : / / % s : % s ▁ You ▁ may ▁ need ▁ to ▁ edit ▁ / etc / hosts ▁ or ▁ similar " % ( host , port ) ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT for subdomain , ( punycode , host ) in subdomains . iteritems ( ) : NEW_LINE INDENT domain = " % s . % s " % ( punycode , host ) NEW_LINE try : NEW_LINE INDENT urllib2 . urlopen ( " http : / / % s : % d / " % ( domain , port ) ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT logger . critical ( " Failed ▁ probing ▁ domain ▁ % s . ▁ You ▁ may ▁ need ▁ to ▁ edit ▁ / etc / hosts ▁ or ▁ similar . " % domain ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT DEDENT wrapper . wait ( ) NEW_LINE DEDENT def get_subdomains ( host ) : NEW_LINE # This ▁ assumes ▁ that ▁ the ▁ tld ▁ is ▁ ascii - only ▁ or ▁ already ▁ in ▁ punycode ENDCOM INDENT return { subdomain : ( subdomain . encode ( " idna " ) , host ) for subdomain in subdomains } NEW_LINE DEDENT def start_servers ( host , ports , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT servers = defaultdict ( list ) NEW_LINE for scheme , ports in ports . iteritems ( ) : NEW_LINE INDENT assert len ( ports ) == { " http " : 2 } . get ( scheme , 1 ) NEW_LINE for port in ports : NEW_LINE INDENT if port is None : NEW_LINE INDENT continue NEW_LINE DEDENT init_func = { " http " : start_http_server , " https " : start_https_server , " ws " : start_ws_server , " wss " : start_wss_server } [ scheme ] NEW_LINE server_proc = ServerProc ( ) NEW_LINE server_proc . start ( init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE servers [ scheme ] . append ( ( port , server_proc ) ) NEW_LINE DEDENT DEDENT return servers NEW_LINE DEDENT def start_http_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return wptserve . WebTestHttpd ( host = host , port = port , doc_root = paths [ " doc _ root " ] , routes = routes , rewrites = rewrites , bind_hostname = bind_hostname , config = external_config , use_ssl = False , key_file = None , certificate = None , latency = kwargs . get ( " latency " ) ) NEW_LINE DEDENT def start_https_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return wptserve . WebTestHttpd ( host = host , port = port , doc_root = paths [ " doc _ root " ] , routes = routes , rewrites = rewrites , bind_hostname = bind_hostname , config = external_config , use_ssl = True , key_file = ssl_config [ " key _ path " ] , certificate = ssl_config [ " cert _ path " ] , encrypt_after_connect = ssl_config [ " encrypt _ after _ connect " ] , latency = kwargs . get ( " latency " ) ) NEW_LINE DEDENT class WebSocketDaemon ( object ) : NEW_LINE INDENT def __init__ ( self , host , port , doc_root , handlers_root , log_level , bind_hostname , ssl_config ) : NEW_LINE INDENT self . host = host NEW_LINE cmd_args = [ " - p " , port , " - d " , doc_root , " - w " , handlers_root , " - - log - level " , log_level ] NEW_LINE if ssl_config is not None : NEW_LINE # ▁ This ▁ is ▁ usually ▁ done ▁ through ▁ pywebsocket . main , ▁ however ▁ we ' re ENDCOM # ▁ working ▁ around ▁ that ▁ to ▁ get ▁ the ▁ server ▁ instance ▁ and ▁ manually ENDCOM # ▁ setup ▁ the ▁ wss ▁ server . ENDCOM INDENT if pywebsocket . _import_ssl ( ) : NEW_LINE INDENT tls_module = pywebsocket . _TLS_BY_STANDARD_MODULE NEW_LINE DEDENT elif pywebsocket . _import_pyopenssl ( ) : NEW_LINE INDENT tls_module = pywebsocket . _TLS_BY_PYOPENSSL NEW_LINE DEDENT else : NEW_LINE INDENT print " No ▁ SSL ▁ module ▁ available " NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT cmd_args += [ " - - tls " , " - - private - key " , ssl_config [ " key _ path " ] , " - - certificate " , ssl_config [ " cert _ path " ] , " - - tls - module " , tls_module ] NEW_LINE DEDENT if ( bind_hostname ) : NEW_LINE INDENT cmd_args = [ " - H " , host ] + cmd_args NEW_LINE DEDENT opts , args = pywebsocket . _parse_args_and_config ( cmd_args ) NEW_LINE opts . cgi_directories = [ ] NEW_LINE opts . is_executable_method = None NEW_LINE self . server = pywebsocket . WebSocketServer ( opts ) NEW_LINE ports = [ item [ 0 ] . getsockname ( ) [ 1 ] for item in self . server . _sockets ] NEW_LINE assert all ( item == ports [ 0 ] for item in ports ) NEW_LINE self . port = ports [ 0 ] NEW_LINE self . started = False NEW_LINE self . server_thread = None NEW_LINE DEDENT def start ( self , block = False ) : NEW_LINE INDENT self . started = True NEW_LINE if block : NEW_LINE INDENT self . server . serve_forever ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . server_thread = threading . Thread ( target = self . server . serve_forever ) NEW_LINE self . server_thread . setDaemon ( True ) # ▁ don ' t ▁ hang ▁ on ▁ exit ENDCOM NEW_LINE self . server_thread . start ( ) NEW_LINE DEDENT DEDENT def stop ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Stops ▁ the ▁ server . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ server ▁ is ▁ not ▁ running , ▁ this ▁ method ▁ has ▁ no ▁ effect . STRNEWLINE ▁ """ NEW_LINE if self . started : NEW_LINE INDENT try : NEW_LINE INDENT self . server . shutdown ( ) NEW_LINE self . server . server_close ( ) NEW_LINE self . server_thread . join ( ) NEW_LINE self . server_thread = None NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT pass NEW_LINE DEDENT self . started = False NEW_LINE DEDENT self . server = None NEW_LINE DEDENT DEDENT def start_ws_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return WebSocketDaemon ( host , str ( port ) , repo_root , paths [ " ws _ doc _ root " ] , " debug " , bind_hostname , ssl_config = None ) NEW_LINE DEDENT def start_wss_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return WebSocketDaemon ( host , str ( port ) , repo_root , paths [ " ws _ doc _ root " ] , " debug " , bind_hostname , ssl_config ) NEW_LINE DEDENT def get_ports ( config , ssl_environment ) : NEW_LINE INDENT rv = defaultdict ( list ) NEW_LINE for scheme , ports in config [ " ports " ] . iteritems ( ) : NEW_LINE INDENT for i , port in enumerate ( ports ) : NEW_LINE INDENT if scheme in [ " wss " , " https " ] and not ssl_environment . ssl_enabled : NEW_LINE INDENT port = None NEW_LINE DEDENT if port == " auto " : NEW_LINE INDENT port = get_port ( ) NEW_LINE DEDENT else : NEW_LINE INDENT port = port NEW_LINE DEDENT rv [ scheme ] . append ( port ) NEW_LINE DEDENT DEDENT return rv NEW_LINE DEDENT def normalise_config ( config , ports ) : NEW_LINE INDENT host = config [ " external _ host " ] if config [ " external _ host " ] else config [ " host " ] NEW_LINE domains = get_subdomains ( host ) NEW_LINE ports_ = { } NEW_LINE for scheme , ports_used in ports . iteritems ( ) : NEW_LINE INDENT ports_ [ scheme ] = ports_used NEW_LINE DEDENT for key , value in domains . iteritems ( ) : NEW_LINE INDENT domains [ key ] = " . " . join ( value ) NEW_LINE DEDENT domains [ " " ] = host NEW_LINE ports_ = { } NEW_LINE for scheme , ports_used in ports . iteritems ( ) : NEW_LINE INDENT ports_ [ scheme ] = ports_used NEW_LINE DEDENT return { " host " : host , " domains " : domains , " ports " : ports_ } NEW_LINE DEDENT def get_ssl_config ( config , external_domains , ssl_environment ) : NEW_LINE INDENT key_path , cert_path = ssl_environment . host_cert_path ( external_domains ) NEW_LINE return { " key _ path " : key_path , " cert _ path " : cert_path , " encrypt _ after _ connect " : config [ " ssl " ] [ " encrypt _ after _ connect " ] } NEW_LINE DEDENT def start ( config , ssl_environment , routes , ** kwargs ) : NEW_LINE INDENT host = config [ " host " ] NEW_LINE domains = get_subdomains ( host ) NEW_LINE ports = get_ports ( config , ssl_environment ) NEW_LINE bind_hostname = config [ " bind _ hostname " ] NEW_LINE paths = { " doc _ root " : config [ " doc _ root " ] , " ws _ doc _ root " : config [ " ws _ doc _ root " ] } NEW_LINE external_config = normalise_config ( config , ports ) NEW_LINE ssl_config = get_ssl_config ( config , external_config [ " domains " ] . values ( ) , ssl_environment ) NEW_LINE if config [ " check _ subdomains " ] : NEW_LINE INDENT check_subdomains ( host , paths , bind_hostname , ssl_config ) NEW_LINE DEDENT servers = start_servers ( host , ports , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE return external_config , servers NEW_LINE DEDENT def iter_procs ( servers ) : NEW_LINE INDENT for servers in servers . values ( ) : NEW_LINE INDENT for port , server in servers : NEW_LINE INDENT yield server . proc NEW_LINE DEDENT DEDENT DEDENT def value_set ( config , key ) : NEW_LINE INDENT return key in config and config [ key ] is not None NEW_LINE DEDENT def get_value_or_default ( config , key , default = None ) : NEW_LINE INDENT return config [ key ] if value_set ( config , key ) else default NEW_LINE DEDENT def set_computed_defaults ( config ) : NEW_LINE INDENT if not value_set ( config , " doc _ root " ) : NEW_LINE INDENT config [ " doc _ root " ] = repo_root NEW_LINE DEDENT if not value_set ( config , " ws _ doc _ root " ) : NEW_LINE INDENT root = get_value_or_default ( config , " doc _ root " , default = repo_root ) NEW_LINE config [ " ws _ doc _ root " ] = os . path . join ( root , " websockets " , " handlers " ) NEW_LINE DEDENT DEDENT def merge_json ( base_obj , override_obj ) : NEW_LINE INDENT rv = { } NEW_LINE for key , value in base_obj . iteritems ( ) : NEW_LINE INDENT if key not in override_obj : NEW_LINE INDENT rv [ key ] = value NEW_LINE DEDENT else : NEW_LINE INDENT if isinstance ( value , dict ) : NEW_LINE INDENT rv [ key ] = merge_json ( value , override_obj [ key ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rv [ key ] = override_obj [ key ] NEW_LINE DEDENT DEDENT DEDENT return rv NEW_LINE DEDENT def get_ssl_environment ( config ) : NEW_LINE INDENT implementation_type = config [ " ssl " ] [ " type " ] NEW_LINE cls = sslutils . environments [ implementation_type ] NEW_LINE try : NEW_LINE INDENT kwargs = config [ " ssl " ] [ implementation_type ] . copy ( ) NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ValueError ( " % s ▁ is ▁ not ▁ a ▁ vaid ▁ ssl ▁ type . " % implementation_type ) NEW_LINE DEDENT return cls ( logger , ** kwargs ) NEW_LINE DEDENT def load_config ( default_path , override_path = None , ** kwargs ) : NEW_LINE INDENT if os . path . exists ( default_path ) : NEW_LINE INDENT with open ( default_path ) as f : NEW_LINE INDENT base_obj = json . load ( f ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise ValueError ( " Config ▁ path ▁ % s ▁ does ▁ not ▁ exist " % default_path ) NEW_LINE DEDENT if os . path . exists ( override_path ) : NEW_LINE INDENT with open ( override_path ) as f : NEW_LINE INDENT override_obj = json . load ( f ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT override_obj = { } NEW_LINE DEDENT rv = merge_json ( base_obj , override_obj ) NEW_LINE if kwargs . get ( " config _ path " ) : NEW_LINE INDENT other_path = os . path . abspath ( os . path . expanduser ( kwargs . get ( " config _ path " ) ) ) NEW_LINE if os . path . exists ( other_path ) : NEW_LINE INDENT base_obj = rv NEW_LINE with open ( other_path ) as f : NEW_LINE INDENT override_obj = json . load ( f ) NEW_LINE DEDENT rv = merge_json ( base_obj , override_obj ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " Config ▁ path ▁ % s ▁ does ▁ not ▁ exist " % other_path ) NEW_LINE DEDENT DEDENT overriding_path_args = [ ( " doc _ root " , " Document ▁ root " ) , ( " ws _ doc _ root " , " WebSockets ▁ document ▁ root " ) ] NEW_LINE for key , title in overriding_path_args : NEW_LINE INDENT value = kwargs . get ( key ) NEW_LINE if value is None : NEW_LINE INDENT continue NEW_LINE DEDENT value = os . path . abspath ( os . path . expanduser ( value ) ) NEW_LINE if not os . path . exists ( value ) : NEW_LINE INDENT raise ValueError ( " % s ▁ path ▁ % s ▁ does ▁ not ▁ exist " % ( title , value ) ) NEW_LINE DEDENT rv [ key ] = value NEW_LINE DEDENT set_computed_defaults ( rv ) NEW_LINE return rv NEW_LINE DEDENT def get_parser ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( ) NEW_LINE parser . add_argument ( " - - latency " , type = int , help = " Artificial ▁ latency ▁ to ▁ add ▁ before ▁ sending ▁ http ▁ responses , ▁ in ▁ ms " ) NEW_LINE parser . add_argument ( " - - config " , action = " store " , dest = " config _ path " , help = " Path ▁ to ▁ external ▁ config ▁ file " ) NEW_LINE parser . add_argument ( " - - doc _ root " , action = " store " , dest = " doc _ root " , help = " Path ▁ to ▁ document ▁ root . ▁ Overrides ▁ config . " ) NEW_LINE parser . add_argument ( " - - ws _ doc _ root " , action = " store " , dest = " ws _ doc _ root " , help = " Path ▁ to ▁ WebSockets ▁ document ▁ root . ▁ Overrides ▁ config . " ) NEW_LINE return parser NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT kwargs = vars ( get_parser ( ) . parse_args ( ) ) NEW_LINE config = load_config ( " config . default . json " , " config . json " , ** kwargs ) NEW_LINE setup_logger ( config [ " log _ level " ] ) NEW_LINE with stash . StashServer ( ( config [ " host " ] , get_port ( ) ) , authkey = str ( uuid . uuid4 ( ) ) ) : NEW_LINE INDENT with get_ssl_environment ( config ) as ssl_env : NEW_LINE INDENT config_ , servers = start ( config , ssl_env , default_routes ( ) , ** kwargs ) NEW_LINE try : NEW_LINE INDENT while any ( item . is_alive ( ) for item in iter_procs ( servers ) ) : NEW_LINE INDENT for item in iter_procs ( servers ) : NEW_LINE INDENT item . join ( 1 ) NEW_LINE DEDENT DEDENT DEDENT except KeyboardInterrupt : NEW_LINE INDENT logger . info ( " Shutting ▁ down " ) NEW_LINE DEDENT DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="xxxIsaacPeralxxx/anim-studio-tools/tree/master/kip/houdini/code/kip_houdini/convert.py"> # ▁ Dr . ▁ D ▁ Studios ▁ - ▁ Software ▁ Disclaimer ENDCOM # ▁ Copyright ▁ 2009 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited ▁ ( ACN ▁ 127 ▁ 184 ▁ 954 ) ▁ ( Dr . ▁ D ▁ Studios ) , ▁ its ENDCOM # ▁ affiliates ▁ and / or ▁ its ▁ licensors . ENDCOM """ STRNEWLINE This ▁ module ▁ will ▁ help ▁ TD ' s ▁ to ▁ convert ▁ houdini ▁ animation ▁ curve ▁ to ▁ nuke ▁ or ▁ maya STRNEWLINE the ▁ other ▁ way ▁ around ▁ also . STRNEWLINE STRNEWLINE . . ▁ note : : STRNEWLINE STRNEWLINE ▁ Please ▁ make ▁ sure ▁ you ▁ are ▁ running ▁ in ▁ proper ▁ kipHoudini ▁ environment STRNEWLINE STRNEWLINE . . ▁ warning : : STRNEWLINE STRNEWLINE ▁ Dont ▁ import ▁ this ▁ module ▁ as ▁ standalone ▁ , ▁ use ▁ this ▁ module ▁ with ▁ kip ▁ project STRNEWLINE STRNEWLINE """ NEW_LINE __authors__ = [ " kurian . os " ] NEW_LINE __version__ = " $ Revision : ▁ 104961 ▁ $ " . split ( ) [ 1 ] NEW_LINE __revision__ = __version__ NEW_LINE __date__ = " $ Date : ▁ ▁ July ▁ 19 , ▁ 2011 ▁ 12:00:00 ▁ PM $ " . split ( ) [ 1 ] NEW_LINE __copyright__ = "2011" NEW_LINE __license__ = " Copyright ▁ 2011 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited " NEW_LINE __contact__ = " kurian . os @ drdstudios . com " NEW_LINE __status__ = " Development " NEW_LINE import os NEW_LINE import traceback NEW_LINE # import ▁ hou ENDCOM import napalm . core as nap_core NEW_LINE import node_curves as node_curves NEW_LINE import kip . kip_reader as kip_reader NEW_LINE reload ( node_curves ) NEW_LINE reload ( kip_reader ) NEW_LINE from rodin import logging NEW_LINE from kip . kip_curve_class import * NEW_LINE from kip . kip_napalm_class import * NEW_LINE from kip . utils . kipError import * NEW_LINE from kip . template import * NEW_LINE rodin_logger = logging . get_logger ( ' kipHoudini ' ) NEW_LINE napalm_func = Napalm ( ) NEW_LINE GLOBAL_FPS = 24 NEW_LINE GLOBAL_TIME = 1 NEW_LINE class HoudiniWriter ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ Creating ▁ houdini ▁ curve ▁ writer ▁ class STRNEWLINE STRNEWLINE ▁ * Parents : * STRNEWLINE STRNEWLINE ▁ None STRNEWLINE STRNEWLINE ▁ * Children : * STRNEWLINE STRNEWLINE ▁ * ▁ : func : ` writeOutCurves ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Base ▁ init ▁ function ▁ for ▁ houdini ▁ convert . write ▁ Class . STRNEWLINE ▁ """ NEW_LINE rodin_logger . info ( " kip ▁ houdini ▁ writing ▁ class ▁ initialized " ) NEW_LINE self . houdini_version = " houdini , % s " % hou . applicationVersionString ( ) NEW_LINE self . kip_houdini_version = " kipHoudini % s " % os . getenv ( " DRD _ KIPHOUDINI _ VERSION " ) NEW_LINE DEDENT def writeOutCurves ( self , nap_file_name = None , houdini_nodes = [ ] , houdini_node_attributes = [ ] , start_frame = None , end_frame = None , write_xml = False , silent = False , left_eyes = [ ] , right_eyes = [ ] , map_file_name = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ function ▁ will ▁ create ▁ a ▁ curve ▁ class ▁ object ▁ first ▁ and ▁ then ▁ it ▁ will ▁ write ▁ out ▁ the ▁ napalm ▁ file . STRNEWLINE STRNEWLINE ▁ . . ▁ warning : : STRNEWLINE STRNEWLINE ▁ If ▁ you ▁ are ▁ unable ▁ to ▁ write ▁ out ▁ napalm ▁ file ▁ or ▁ write _ status = False ▁ that ▁ means ▁ napalm ▁ failed ▁ to ▁ write ▁ out . STRNEWLINE STRNEWLINE ▁ : param ▁ nap _ file _ name : ▁ User ▁ must ▁ pass ▁ a ▁ file ▁ where ▁ he ▁ want ▁ to ▁ write ▁ out ▁ curves ▁ and ▁ make ▁ sure ▁ you ▁ supply ▁ a ▁ . nap ▁ or ▁ . xml ▁ file ▁ format ( strict ) STRNEWLINE STRNEWLINE ▁ : type ▁ nap _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ nodes : ▁ list ▁ of ▁ houdini ▁ objects ( strict ) STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ nodes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ node _ attribute : ▁ if ▁ you ▁ want ▁ to ▁ replace ▁ attribute ▁ from ▁ the ▁ map ▁ file ▁ then ▁ you ▁ can ▁ specify ▁ the ▁ override ▁ attribute ▁ here STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ node _ attribute : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ start _ frame : ▁ start ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ start _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ end _ frame : ▁ end ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ end _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ write _ xml : ▁ If ▁ you ▁ want ▁ to ▁ write ▁ out ▁ a ▁ xml ▁ file ▁ instead ▁ of ▁ napalm ▁ file ▁ then ▁ this ▁ should ▁ be ▁ true STRNEWLINE STRNEWLINE ▁ : type ▁ end _ frame : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ left _ eyes : ▁ Left ▁ eye ▁ objects STRNEWLINE STRNEWLINE ▁ : type ▁ left _ eyes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ right _ eyes : ▁ Right ▁ eye ▁ objects STRNEWLINE STRNEWLINE ▁ : type ▁ right _ eyes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : return : ▁ Status , channel ▁ file ▁ , ▁ map ▁ file STRNEWLINE STRNEWLINE ▁ : rtype : ▁ boot , string , string STRNEWLINE STRNEWLINE ▁ Example STRNEWLINE STRNEWLINE ▁ > > > ▁ import ▁ kip _ houdini . convert ▁ as ▁ kh STRNEWLINE ▁ > > > ▁ reload ( kh ) STRNEWLINE ▁ > > > ▁ khcw ▁ = ▁ kh . HoudiniWriter ( ) STRNEWLINE ▁ > > > ▁ status , nap _ file , map _ file = khcw . writeOutCurves ( nap _ file _ name ▁ = ▁ " / tmp / houdini _ kip _ test _ s . nap " , map _ file _ name = ▁ " / tmp / houdini _ kip _ test _ m . nap " , houdini _ nodes ▁ = ▁ [ " / obj / geo / xform _ 1 " , " / obj / geo / xform _ 2 " ] , left _ eyes = [ " / obj / geo / xform _ 1 " ] , right _ eyes = [ " / obj / geo / xform _ 2 " ] ) STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if nap_file_name : NEW_LINE INDENT node_curv = node_curves . NodeCurves ( ) NEW_LINE get_all_curves = node_curv . getCurves ( houdini_node_curves = houdini_nodes , houdini_attribute_curves = houdini_node_attributes , start_frame = start_frame , end_frame = end_frame , silent = silent , left_eye_curves = left_eyes , right_eye_curves = right_eyes ) NEW_LINE if write_xml : NEW_LINE INDENT if not nap_file_name . endswith ( " . xml " ) : NEW_LINE INDENT split_base_ext = os . path . splitext ( nap_file_name ) NEW_LINE if split_base_ext [ - 1 ] : NEW_LINE INDENT nap_file_name = " % s / . xml " % ( split_base_ext [ 0 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT nap_file_name = " % s / . xml " % ( nap_file_name ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if not nap_file_name . endswith ( " . nap " ) : NEW_LINE INDENT raise KipBaseError ( " Unknown ▁ file ▁ extension ▁ found ▁ in ▁ % s ▁ ! " % nap_file_name ) NEW_LINE DEDENT DEDENT write_status , map_file , nap_file = napalm_func . write ( nap_file_name , get_all_curves , debug = True , map_file_name = map_file_name , software = self . houdini_version , app_version = self . kip_houdini_version ) NEW_LINE rodin_logger . info ( " % s ▁ % s ▁ % s " % ( write_status , map_file , nap_file ) ) NEW_LINE return ( write_status , map_file , nap_file ) NEW_LINE DEDENT else : NEW_LINE INDENT raise KipBaseError ( " Expected ▁ napalm ▁ file ▁ name ▁ for ▁ write ▁ curve ▁ ! " ) NEW_LINE DEDENT DEDENT DEDENT class HoudiniReader ( object ) : NEW_LINE INDENT """ STRNEWLINE STRNEWLINE ▁ Creating ▁ houdini ▁ curve ▁ reader ▁ class STRNEWLINE STRNEWLINE ▁ * Parents : * STRNEWLINE STRNEWLINE ▁ None STRNEWLINE STRNEWLINE ▁ * Children : * STRNEWLINE STRNEWLINE ▁ * ▁ : func : ` houSetAttr ` STRNEWLINE STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Base ▁ init ▁ function ▁ for ▁ houdini ▁ convert . write ▁ Class . STRNEWLINE ▁ """ NEW_LINE rodin_logger . info ( " kip ▁ houdini ▁ read ▁ class ▁ initialized " ) NEW_LINE self . nuke_tan_types = { " spline " : " spline ( ) " , " linear " : " linear ( ) " , " constant " : " constant ( ) " , " cubic " : " bezier ( ) " } NEW_LINE self . channel_match = { ' translateX ' : ' tx ' , ' translateY ' : ' ty ' , ' translateZ ' : ' tz ' , ' rotateX ' : ' rx ' , ' rotateY ' : ' ry ' , ' rotateZ ' : ' rz ' , ' scaleX ' : ' sx ' , ' scaleY ' : ' sy ' , ' scaleZ ' : ' sz ' } NEW_LINE DEDENT def houSetAttr ( self , nap_file_name = None , houdini_nodes = [ ] , houdini_node_attribute = None , map_file_name = None , offset_value = 0 , start_frame = None , end_frame = None , attribute_map = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ function ▁ will ▁ get ▁ all ▁ curve ▁ data ▁ from ▁ a ▁ map ▁ and ▁ channel ▁ file ▁ then ▁ those ▁ data ▁ will ▁ be ▁ applied ▁ to ▁ proper ▁ nodes STRNEWLINE STRNEWLINE ▁ : param ▁ nap _ file _ name : ▁ User ▁ must ▁ pass ▁ a ▁ file ▁ where ▁ he ▁ want ▁ to ▁ write ▁ out ▁ curves ▁ and ▁ make ▁ sure ▁ you ▁ supply ▁ a ▁ . nap ▁ or ▁ . xml ▁ file ▁ format STRNEWLINE STRNEWLINE ▁ : type ▁ nap _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ nodes : ▁ list ▁ of ▁ houdini ▁ objects STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ nodes : ▁ list STRNEWLINE STRNEWLINE ▁ : param ▁ houdini _ node _ attribute : ▁ if ▁ you ▁ want ▁ to ▁ replace ▁ attribute ▁ from ▁ the ▁ map ▁ file ▁ then ▁ you ▁ can ▁ specify ▁ the ▁ override ▁ attribute ▁ here STRNEWLINE STRNEWLINE ▁ : type ▁ houdini _ node _ attribute : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : param ▁ offset _ value : ▁ Animation ▁ key ▁ offset ▁ value STRNEWLINE STRNEWLINE ▁ : type ▁ offset _ value : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ start _ frame : ▁ start ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ start _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ end _ frame : ▁ end ▁ frame ▁ to ▁ capture STRNEWLINE STRNEWLINE ▁ : type ▁ end _ frame : ▁ int STRNEWLINE STRNEWLINE ▁ : param ▁ attribute _ map : ▁ This ▁ a ▁ template ▁ object ▁ from ▁ template ▁ module STRNEWLINE STRNEWLINE ▁ : type ▁ attribute _ map : ▁ list ▁ of ▁ tuple STRNEWLINE STRNEWLINE ▁ Example STRNEWLINE STRNEWLINE ▁ > > > ▁ import ▁ kip _ houdini . convert ▁ as ▁ kh STRNEWLINE ▁ > > > ▁ reload ( kh ) STRNEWLINE ▁ > > > ▁ khpr = kh . HoudiniReader ( ) STRNEWLINE ▁ > > > ▁ import ▁ kip . template ▁ as ▁ template STRNEWLINE ▁ > > > ▁ attr _ mp ▁ = ▁ template . KipTemplates ( ) STRNEWLINE ▁ > > > ▁ attr _ mp . ATTRMAP = { " t1 . cutatt1 " : " / obj / geo1 / xform1 . ottr _ 1 " , " t1 . cutatt2 " : " / obj / geo1 / xform1 . ottr _ 2 " , " t2 . cutatt1 " : " / obj / geo1 / xform1 . ottr _ 3 " , " t2 . cutatt2 " : " / obj / geo1 / xform1 . ottr _ 4 " } STRNEWLINE ▁ > > > ▁ a ▁ = ▁ attr _ mp . ATTRMAP STRNEWLINE ▁ > > > ▁ khpr . houSetAttr ( nap _ file _ name = " / tmp / single _ maya _ test . nap " , houdini _ nodes = " / obj / geo1 / xform1 " , attribute _ map = a ) STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if nap_file_name : NEW_LINE INDENT if not map_file_name : NEW_LINE INDENT map_file_name = kip_reader . build_map_file_name ( nap_file_name ) NEW_LINE DEDENT header_info = kip_reader . header ( map_file_name ) NEW_LINE array_index = kip_reader . find_software_index ( header_info [ " client _ software " ] ) NEW_LINE houdini_node_list = houdini_nodes NEW_LINE knob_read = kip_reader . ReadCurve ( ) NEW_LINE get_curve_class = knob_read . getCurves ( nap_file_name = nap_file_name , map_file_name = map_file_name , offset_value = offset_value ) NEW_LINE DEDENT for each_node in get_curve_class : NEW_LINE INDENT node_key = get_curve_class . index ( each_node ) NEW_LINE current_node_curve = each_node [ 2 ] NEW_LINE curent_source_node = each_node [ 0 ] NEW_LINE for each_curve in current_node_curve : NEW_LINE INDENT curve_attr = each_curve [ 1 ] NEW_LINE current_key_dict = each_curve [ 2 ] NEW_LINE time_keys = current_key_dict [ " time " ] NEW_LINE key_value = current_key_dict [ " key _ value " ] NEW_LINE in_angle = current_key_dict [ " in _ angle " ] NEW_LINE out_angle = current_key_dict [ " out _ angle " ] NEW_LINE in_weight = current_key_dict [ " in _ weight " ] NEW_LINE out_weight = current_key_dict [ " out _ weight " ] NEW_LINE in_tan_type = current_key_dict [ " in _ tan _ type " ] NEW_LINE out_tan_type = current_key_dict [ " out _ tan _ type " ] NEW_LINE in_slope = current_key_dict [ " in _ slope " ] NEW_LINE out_slope = current_key_dict [ " out _ slope " ] NEW_LINE try : NEW_LINE INDENT for time in time_keys : NEW_LINE INDENT if houdini_node_attribute : NEW_LINE INDENT curve_attr = houdini_node_attribute NEW_LINE DEDENT else : NEW_LINE INDENT if attribute_map : NEW_LINE INDENT temp_attr_keys = attribute_map . keys ( ) NEW_LINE for each_template in temp_attr_keys : NEW_LINE INDENT source_details = each_template . split ( " . " ) NEW_LINE current_node_attr = " % s . % s " % ( curent_source_node , each_curve [ 1 ] ) NEW_LINE if current_node_attr == each_template : NEW_LINE INDENT destenation_details = attribute_map [ each_template ] . split ( " . " ) NEW_LINE curve_attr = destenation_details [ 1 ] NEW_LINE current_houdini_node = destenation_details [ 0 ] NEW_LINE current_houdini_node = hou . node ( current_houdini_node ) NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT current_houdini_node = hou . node ( houdini_node_list [ node_key ] ) NEW_LINE DEDENT DEDENT if start_frame and end_frame : NEW_LINE INDENT if time in range ( start_frame , end_frame + 1 ) : NEW_LINE INDENT key_index = time_keys . index ( time ) NEW_LINE DEDENT else : NEW_LINE INDENT print " % s ▁ not ▁ in ▁ range ▁ not ▁ applying ▁ the ▁ key " % time NEW_LINE continue NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT key_index = time_keys . index ( time ) NEW_LINE DEDENT in_tan_v = in_tan_type [ key_index ] NEW_LINE if self . nuke_tan_types . has_key ( in_tan_v ) : NEW_LINE INDENT in_tan_v = self . nuke_tan_types [ in_tan_v ] NEW_LINE DEDENT else : NEW_LINE INDENT in_tan_v = " bezier ( ) " NEW_LINE DEDENT hkey = hou . Keyframe ( ) NEW_LINE hkey . setTime ( ( time_keys [ key_index ] / GLOBAL_FPS ) ) NEW_LINE hkey . setValue ( key_value [ key_index ] ) NEW_LINE hkey . setExpression ( " bezier ( ) " ) NEW_LINE hkey . setExpression ( " spline ( ) " ) NEW_LINE hkey . setInAccel ( in_weight [ key_index ] ) NEW_LINE hkey . setAccel ( out_weight [ key_index ] ) NEW_LINE hkey . setInSlope ( in_slope [ key_index ] ) NEW_LINE hkey . setSlope ( out_slope [ key_index ] ) NEW_LINE this_node_attr = curve_attr NEW_LINE if self . channel_match . has_key ( curve_attr ) : NEW_LINE INDENT this_node_attr = self . channel_match [ curve_attr ] NEW_LINE DEDENT hou_nod = current_houdini_node . parm ( this_node_attr ) . setKeyframe ( hkey ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT traceback . print_exc ( ) NEW_LINE raise KipBaseError ( " No ▁ objects ▁ found ▁ in ▁ node ▁ list ! " ) NEW_LINE DEDENT DEDENT DEDENT rodin_logger . info ( " Aniamtion ▁ curve ▁ trasfer ▁ is ▁ finished ▁ ! " ) NEW_LINE return True NEW_LINE DEDENT DEDENT def header ( map_file_name ) : NEW_LINE INDENT """ STRNEWLINE STRNEWLINE ▁ This ▁ function ▁ will ▁ return ▁ a ▁ dict ▁ of ▁ header ▁ details ▁ from ▁ map ▁ file STRNEWLINE STRNEWLINE ▁ : param ▁ map _ file _ name : ▁ Filepath ▁ of ▁ napalm ▁ channel ▁ data STRNEWLINE STRNEWLINE ▁ : type ▁ map _ file _ name : ▁ string STRNEWLINE STRNEWLINE ▁ : return : ▁ header ▁ details STRNEWLINE STRNEWLINE ▁ : rtype : ▁ dict STRNEWLINE STRNEWLINE ▁ """ NEW_LINE if os . path . exists ( map_file_name ) : NEW_LINE INDENT nap_header = kip_reader . header ( map_file_name ) NEW_LINE return nap_header NEW_LINE DEDENT return None NEW_LINE # ▁ Copyright ▁ 2008-2012 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited ▁ ( ACN ▁ 127 ▁ 184 ▁ 954 ) ▁ ( Dr . ▁ D ▁ Studios ) ENDCOM # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ anim - studio - tools . ENDCOM # ▁ anim - studio - tools ▁ is ▁ free ▁ software : ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ▁ modify ENDCOM # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ENDCOM # ▁ the ▁ Free ▁ Software ▁ Foundation , ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License , ▁ or ENDCOM # ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ anim - studio - tools ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ENDCOM # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ENDCOM # ▁ along ▁ with ▁ anim - studio - tools . ▁ If ▁ not , ▁ see ▁ < http : / / www . gnu . org / licenses / > . ENDCOM DEDENT </DOCUMENT>
<DOCUMENT_ID="xboxfanj/android_kernel_htc_msm8974/tree/master/tools/perf/scripts/python/check-perf-trace.py"> # ▁ perf ▁ script ▁ event ▁ handlers , ▁ generated ▁ by ▁ perf ▁ script ▁ - g ▁ python ENDCOM # ▁ ( c ) ▁ 2010 , ▁ Tom ▁ Zanussi ▁ < tzanussi @ gmail . com > ENDCOM # ▁ Licensed ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ GPL ▁ License ▁ version ▁ 2 ENDCOM # ▁ This ▁ script ▁ tests ▁ basic ▁ functionality ▁ such ▁ as ▁ flag ▁ and ▁ symbol ENDCOM # ▁ strings , ▁ common _ xxx ( ) ▁ calls ▁ back ▁ into ▁ perf , ▁ begin , ▁ end , ▁ unhandled ENDCOM # ▁ events , ▁ etc . ▁ Basically , ▁ if ▁ this ▁ script ▁ runs ▁ successfully ▁ and ENDCOM # ▁ displays ▁ expected ▁ results , ▁ Python ▁ scripting ▁ support ▁ should ▁ be ▁ ok . ENDCOM import os NEW_LINE import sys NEW_LINE sys . path . append ( os . environ [ ' PERF _ EXEC _ PATH ' ] + ' / scripts / python / Perf - Trace - Util / lib / Perf / Trace ' ) NEW_LINE from Core import * NEW_LINE from perf_trace_context import * NEW_LINE unhandled = autodict ( ) NEW_LINE def trace_begin ( ) : NEW_LINE INDENT print " trace _ begin " NEW_LINE pass NEW_LINE DEDENT def trace_end ( ) : NEW_LINE INDENT print_unhandled ( ) NEW_LINE DEDENT def irq__softirq_entry ( event_name , context , common_cpu , common_secs , common_nsecs , common_pid , common_comm , vec ) : NEW_LINE INDENT print_header ( event_name , common_cpu , common_secs , common_nsecs , common_pid , common_comm ) NEW_LINE print_uncommon ( context ) NEW_LINE print " vec = % s \n " % ( symbol_str ( " irq _ _ softirq _ entry " , " vec " , vec ) ) , NEW_LINE DEDENT def kmem__kmalloc ( event_name , context , common_cpu , common_secs , common_nsecs , common_pid , common_comm , call_site , ptr , bytes_req , bytes_alloc , gfp_flags ) : NEW_LINE INDENT print_header ( event_name , common_cpu , common_secs , common_nsecs , common_pid , common_comm ) NEW_LINE print_uncommon ( context ) NEW_LINE print " call _ site = % u , ▁ ptr = % u , ▁ bytes _ req = % u , ▁ " " bytes _ alloc = % u , ▁ gfp _ flags = % s \n " % ( call_site , ptr , bytes_req , bytes_alloc , flag_str ( " kmem _ _ kmalloc " , " gfp _ flags " , gfp_flags ) ) , NEW_LINE DEDENT def trace_unhandled ( event_name , context , event_fields_dict ) : NEW_LINE INDENT try : NEW_LINE INDENT unhandled [ event_name ] += 1 NEW_LINE DEDENT except TypeError : NEW_LINE INDENT unhandled [ event_name ] = 1 NEW_LINE DEDENT DEDENT def print_header ( event_name , cpu , secs , nsecs , pid , comm ) : NEW_LINE INDENT print " % -20s ▁ % 5u ▁ % 05u . %09u ▁ % 8u ▁ % -20s ▁ " % ( event_name , cpu , secs , nsecs , pid , comm ) , NEW_LINE # ▁ print ▁ trace ▁ fields ▁ not ▁ included ▁ in ▁ handler ▁ args ENDCOM DEDENT def print_uncommon ( context ) : NEW_LINE INDENT print " common _ preempt _ count = % d , ▁ common _ flags = % s , ▁ common _ lock _ depth = % d , ▁ " % ( common_pc ( context ) , trace_flag_str ( common_flags ( context ) ) , common_lock_depth ( context ) ) NEW_LINE DEDENT def print_unhandled ( ) : NEW_LINE INDENT keys = unhandled . keys ( ) NEW_LINE if not keys : NEW_LINE INDENT return NEW_LINE DEDENT print " \n unhandled ▁ events : \n \n " , NEW_LINE print " % -40s ▁ ▁ % 10s \n " % ( " event " , " count " ) , NEW_LINE print " % -40s ▁ ▁ % 10s \n " % ( " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - " , " - - - - - - - - - - - " ) , NEW_LINE for event_name in keys : NEW_LINE INDENT print " % -40s ▁ ▁ % 10d \n " % ( event_name , unhandled [ event_name ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="ffantast/magnum/tree/master/magnum/tests/unit/objects/test_objects.py"> # ▁ Copyright ▁ 2015 ▁ IBM ▁ Corp . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM import datetime NEW_LINE import gettext NEW_LINE import iso8601 NEW_LINE import netaddr NEW_LINE from oslo_utils import timeutils NEW_LINE from oslo_versionedobjects import fields NEW_LINE from magnum . common import context as magnum_context NEW_LINE from magnum . common import exception NEW_LINE from magnum . objects import base NEW_LINE from magnum . objects import utils NEW_LINE from magnum . tests import base as test_base NEW_LINE gettext . install ( ' magnum ' ) NEW_LINE @ base . MagnumObjectRegistry . register NEW_LINE class MyObj ( base . MagnumObject ) : NEW_LINE INDENT VERSION = '1.0' NEW_LINE fields = { ' foo ' : fields . IntegerField ( ) , ' bar ' : fields . StringField ( ) , ' missing ' : fields . StringField ( ) , } NEW_LINE def obj_load_attr ( self , attrname ) : NEW_LINE INDENT setattr ( self , attrname , ' loaded ! ' ) NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def query ( cls , context ) : NEW_LINE INDENT obj = cls ( context ) NEW_LINE obj . foo = 1 NEW_LINE obj . bar = ' bar ' NEW_LINE obj . obj_reset_changes ( ) NEW_LINE return obj NEW_LINE DEDENT @ base . remotable NEW_LINE def marco ( self , context ) : NEW_LINE INDENT return ' polo ' NEW_LINE DEDENT @ base . remotable NEW_LINE def update_test ( self , context ) : NEW_LINE INDENT if context . project_id == ' alternate ' : NEW_LINE INDENT self . bar = ' alternate - context ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bar = ' updated ' NEW_LINE DEDENT DEDENT @ base . remotable NEW_LINE def save ( self , context ) : NEW_LINE INDENT self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def refresh ( self , context ) : NEW_LINE INDENT self . foo = 321 NEW_LINE self . bar = ' refreshed ' NEW_LINE self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def modify_save_modify ( self , context ) : NEW_LINE INDENT self . bar = ' meow ' NEW_LINE self . save ( ) NEW_LINE self . foo = 42 NEW_LINE DEDENT DEDENT class MyObj2 ( object ) : NEW_LINE INDENT @ classmethod NEW_LINE def obj_name ( cls ) : NEW_LINE INDENT return ' MyObj ' NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def get ( cls , * args , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class TestSubclassedObject ( MyObj ) : NEW_LINE INDENT fields = { ' new _ field ' : fields . StringField ( ) } NEW_LINE DEDENT class TestUtils ( test_base . TestCase ) : NEW_LINE INDENT def test_datetime_or_none ( self ) : NEW_LINE INDENT naive_dt = datetime . datetime . now ( ) NEW_LINE dt = timeutils . parse_isotime ( timeutils . isotime ( naive_dt ) ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , dt ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , naive_dt . replace ( tzinfo = iso8601 . iso8601 . Utc ( ) , microsecond = 0 ) ) NEW_LINE self . assertIsNone ( utils . datetime_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_none , ' foo ' ) NEW_LINE DEDENT def test_datetime_or_str_or_none ( self ) : NEW_LINE INDENT dts = timeutils . isotime ( ) NEW_LINE dt = timeutils . parse_isotime ( dts ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dt ) , dt ) NEW_LINE self . assertIsNone ( utils . datetime_or_str_or_none ( None ) ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dts ) , dt ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_str_or_none , ' foo ' ) NEW_LINE DEDENT def test_int_or_none ( self ) : NEW_LINE INDENT self . assertEqual ( utils . int_or_none ( 1 ) , 1 ) NEW_LINE self . assertEqual ( utils . int_or_none ( '1' ) , 1 ) NEW_LINE self . assertIsNone ( utils . int_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . int_or_none , ' foo ' ) NEW_LINE DEDENT def test_str_or_none ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT pass NEW_LINE DEDENT self . assertEqual ( utils . str_or_none ( ' foo ' ) , ' foo ' ) NEW_LINE self . assertEqual ( utils . str_or_none ( 1 ) , '1' ) NEW_LINE self . assertIsNone ( utils . str_or_none ( None ) ) NEW_LINE DEDENT def test_ip_or_none ( self ) : NEW_LINE INDENT ip4 = netaddr . IPAddress ( '1.2.3.4' , 4 ) NEW_LINE ip6 = netaddr . IPAddress ( '1 : : 2' , 6 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 4 ) ( '1.2.3.4' ) , ip4 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 6 ) ( '1 : : 2' ) , ip6 ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 4 ) ( None ) ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 6 ) ( None ) ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 4 ) , ' foo ' ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 6 ) , ' foo ' ) NEW_LINE DEDENT def test_dt_serializer ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT foo = utils . dt_serializer ( ' bar ' ) NEW_LINE DEDENT obj = Obj ( ) NEW_LINE obj . bar = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( '1955-11-05T00:00:00Z ' , obj . foo ( ) ) NEW_LINE obj . bar = None NEW_LINE self . assertIsNone ( obj . foo ( ) ) NEW_LINE obj . bar = ' foo ' NEW_LINE self . assertRaises ( AttributeError , obj . foo ) NEW_LINE DEDENT def test_dt_deserializer ( self ) : NEW_LINE INDENT dt = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( utils . dt_deserializer ( None , timeutils . isotime ( dt ) ) , dt ) NEW_LINE self . assertIsNone ( utils . dt_deserializer ( None , None ) ) NEW_LINE self . assertRaises ( ValueError , utils . dt_deserializer , None , ' foo ' ) NEW_LINE DEDENT DEDENT class _TestObject ( object ) : NEW_LINE INDENT def test_hydration_type_error ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : ' a ' } } NEW_LINE self . assertRaises ( ValueError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_hydration ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_hydration_bad_ns ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' foo ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE self . assertRaises ( exception . UnsupportedObjectError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_dehydration ( self ) : NEW_LINE INDENT expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_get_updates ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_object_property ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_object_property_type_error ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE def fail ( ) : NEW_LINE INDENT obj . foo = ' a ' NEW_LINE DEDENT self . assertRaises ( ValueError , fail ) NEW_LINE DEDENT def test_load ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE DEDENT def test_load_in_base ( self ) : NEW_LINE INDENT class Foo ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foobar ' : fields . IntegerField ( ) } NEW_LINE DEDENT obj = Foo ( self . context ) NEW_LINE # ▁ NOTE ( danms ) : ▁ Can ' t ▁ use ▁ assertRaisesRegexp ( ) ▁ because ▁ of ▁ py26 ENDCOM raised = False NEW_LINE try : NEW_LINE INDENT obj . foobar NEW_LINE DEDENT except NotImplementedError as ex : NEW_LINE INDENT raised = True NEW_LINE DEDENT self . assertTrue ( raised ) NEW_LINE self . assertTrue ( ' foobar ' in str ( ex ) ) NEW_LINE DEDENT def test_loaded_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' bar ' ] , ' magnum _ object . data ' : { ' foo ' : 1 , ' bar ' : ' loaded ! ' } } NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_changes_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE primitive = obj . obj_to_primitive ( ) NEW_LINE self . assertTrue ( ' magnum _ object . changes ' in primitive ) NEW_LINE obj2 = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj2 . obj_what_changed ( ) ) NEW_LINE obj2 . obj_reset_changes ( ) NEW_LINE self . assertEqual ( set ( ) , obj2 . obj_what_changed ( ) ) NEW_LINE DEDENT def test_unknown_objtype ( self ) : NEW_LINE INDENT self . assertRaises ( exception . UnsupportedObjectError , base . MagnumObject . obj_class_from_name , ' foo ' , '1.0' ) NEW_LINE DEDENT def test_with_alternate_context ( self ) : NEW_LINE INDENT context1 = magnum_context . RequestContext ( ' foo ' , ' foo ' ) NEW_LINE context2 = magnum_context . RequestContext ( ' bar ' , project_id = ' alternate ' ) NEW_LINE obj = MyObj . query ( context1 ) NEW_LINE obj . update_test ( context2 ) NEW_LINE self . assertEqual ( ' alternate - context ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_orphaned_object ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . _context = None NEW_LINE self . assertRaises ( exception . OrphanedObjectError , obj . update_test ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_1 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . update_test ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_2 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . save ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_3 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . refresh ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 321 , obj . foo ) NEW_LINE self . assertEqual ( ' refreshed ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_4 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . bar = ' something ' NEW_LINE self . assertEqual ( set ( [ ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . modify_save_modify ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 42 , obj . foo ) NEW_LINE self . assertEqual ( ' meow ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_static_result ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( ' bar ' , obj . bar ) NEW_LINE result = obj . marco ( ) NEW_LINE self . assertEqual ( ' polo ' , result ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_updates ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE obj . update_test ( ) NEW_LINE self . assertEqual ( ' updated ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_base_attributes ( self ) : NEW_LINE INDENT dt = datetime . datetime ( 1955 , 11 , 5 ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . created_at = dt NEW_LINE obj . updated_at = dt NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' created _ at ' , ' updated _ at ' ] , ' magnum _ object . data ' : { ' created _ at ' : timeutils . isotime ( dt ) , ' updated _ at ' : timeutils . isotime ( dt ) } } NEW_LINE actual = obj . obj_to_primitive ( ) NEW_LINE # ▁ magnum _ object . changes ▁ is ▁ built ▁ from ▁ a ▁ set ▁ and ▁ order ▁ is ▁ undefined ENDCOM self . assertEqual ( sorted ( expected [ ' magnum _ object . changes ' ] ) , sorted ( actual [ ' magnum _ object . changes ' ] ) ) NEW_LINE del expected [ ' magnum _ object . changes ' ] , actual [ ' magnum _ object . changes ' ] NEW_LINE self . assertEqual ( expected , actual ) NEW_LINE DEDENT def test_contains ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertFalse ( ' foo ' in obj ) NEW_LINE obj . foo = 1 NEW_LINE self . assertTrue ( ' foo ' in obj ) NEW_LINE self . assertFalse ( ' does _ not _ exist ' in obj ) NEW_LINE DEDENT def test_obj_attr_is_set ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertTrue ( obj . obj_attr_is_set ( ' foo ' ) ) NEW_LINE self . assertFalse ( obj . obj_attr_is_set ( ' bar ' ) ) NEW_LINE self . assertRaises ( AttributeError , obj . obj_attr_is_set , ' bang ' ) NEW_LINE DEDENT def test_get ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE # ▁ Foo ▁ has ▁ value , ▁ should ▁ not ▁ get ▁ the ▁ default ENDCOM self . assertEqual ( obj . get ( ' foo ' , 2 ) , 1 ) NEW_LINE # ▁ Foo ▁ has ▁ value , ▁ should ▁ return ▁ the ▁ value ▁ without ▁ error ENDCOM self . assertEqual ( obj . get ( ' foo ' ) , 1 ) NEW_LINE # ▁ Bar ▁ is ▁ not ▁ loaded , ▁ so ▁ we ▁ should ▁ get ▁ the ▁ default ENDCOM self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' not - loaded ' ) NEW_LINE # ▁ Bar ▁ without ▁ a ▁ default ▁ should ▁ lazy - load ENDCOM self . assertEqual ( obj . get ( ' bar ' ) , ' loaded ! ' ) NEW_LINE # ▁ Bar ▁ now ▁ has ▁ a ▁ default , ▁ but ▁ loaded ▁ value ▁ should ▁ be ▁ returned ENDCOM self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' loaded ! ' ) NEW_LINE # ▁ Invalid ▁ attribute ▁ should ▁ raise ▁ AttributeError ENDCOM self . assertRaises ( AttributeError , obj . get , ' nothing ' ) NEW_LINE # ▁ . . . even ▁ with ▁ a ▁ default ENDCOM self . assertRaises ( AttributeError , obj . get , ' nothing ' , 3 ) NEW_LINE DEDENT def test_object_inheritance ( self ) : NEW_LINE INDENT base_fields = list ( base . MagnumObject . fields . keys ( ) ) NEW_LINE myobj_fields = [ ' foo ' , ' bar ' , ' missing ' ] + base_fields NEW_LINE myobj3_fields = [ ' new _ field ' ] NEW_LINE self . assertTrue ( issubclass ( TestSubclassedObject , MyObj ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) , len ( MyObj . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) , set ( MyObj . fields . keys ( ) ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) + len ( myobj3_fields ) , len ( TestSubclassedObject . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) | set ( myobj3_fields ) , set ( TestSubclassedObject . fields . keys ( ) ) ) NEW_LINE DEDENT def test_get_changes ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_obj_fields ( self ) : NEW_LINE INDENT class TestObj ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foo ' : fields . IntegerField ( ) } NEW_LINE obj_extra_fields = [ ' bar ' ] NEW_LINE @ property NEW_LINE def bar ( self ) : NEW_LINE INDENT return ' this ▁ is ▁ bar ' NEW_LINE DEDENT DEDENT obj = TestObj ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' created _ at ' , ' updated _ at ' , ' foo ' , ' bar ' ] ) , set ( obj . obj_fields ) ) NEW_LINE DEDENT def test_obj_constructor ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 123 , bar = ' abc ' ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertEqual ( ' abc ' , obj . bar ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE DEDENT DEDENT class TestObjectSerializer ( test_base . TestCase ) : NEW_LINE INDENT def test_object_serialization ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE primitive = ser . serialize_entity ( self . context , obj ) NEW_LINE self . assertTrue ( ' magnum _ object . name ' in primitive ) NEW_LINE obj2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertIsInstance ( obj2 , MyObj ) NEW_LINE self . assertEqual ( self . context , obj2 . _context ) NEW_LINE DEDENT def test_object_serialization_iterables ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE for iterable in ( list , tuple , set ) : NEW_LINE INDENT thing = iterable ( [ obj ] ) NEW_LINE primitive = ser . serialize_entity ( self . context , thing ) NEW_LINE self . assertEqual ( 1 , len ( primitive ) ) NEW_LINE for item in primitive : NEW_LINE INDENT self . assertFalse ( isinstance ( item , base . MagnumObject ) ) NEW_LINE DEDENT thing2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertEqual ( 1 , len ( thing2 ) ) NEW_LINE for item in thing2 : NEW_LINE INDENT self . assertIsInstance ( item , MyObj ) NEW_LINE DEDENT DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="moijes12/oh-mainline/tree/master/vendor/packages/sphinx/tests/test_intersphinx.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM """ STRNEWLINE ▁ test _ intersphinx STRNEWLINE ▁ ~ ~ ~ ~ ~ STRNEWLINE STRNEWLINE ▁ Test ▁ the ▁ intersphinx ▁ extension . STRNEWLINE STRNEWLINE ▁ : copyright : ▁ Copyright ▁ 2007-2013 ▁ by ▁ the ▁ Sphinx ▁ team , ▁ see ▁ AUTHORS . STRNEWLINE ▁ : license : ▁ BSD , ▁ see ▁ LICENSE ▁ for ▁ details . STRNEWLINE """ NEW_LINE import zlib NEW_LINE import posixpath NEW_LINE try : NEW_LINE INDENT from io import BytesIO NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from cStringIO import StringIO as BytesIO NEW_LINE DEDENT from docutils import nodes NEW_LINE from sphinx import addnodes NEW_LINE from sphinx . ext . intersphinx import read_inventory_v1 , read_inventory_v2 , load_mappings , missing_reference NEW_LINE from util import with_app , with_tempdir , write_file NEW_LINE inventory_v1 = ''' \ STRNEWLINE # ▁ Sphinx ▁ inventory ▁ version ▁ 1 STRNEWLINE # ▁ Project : ▁ foo STRNEWLINE # ▁ Version : ▁ 1.0 STRNEWLINE module ▁ mod ▁ foo . html STRNEWLINE module . cls ▁ class ▁ foo . html STRNEWLINE ''' . encode ( ' utf - 8' ) NEW_LINE inventory_v2 = ''' \ STRNEWLINE # ▁ Sphinx ▁ inventory ▁ version ▁ 2 STRNEWLINE # ▁ Project : ▁ foo STRNEWLINE # ▁ Version : ▁ 2.0 STRNEWLINE # ▁ The ▁ remainder ▁ of ▁ this ▁ file ▁ is ▁ compressed ▁ with ▁ zlib . STRNEWLINE ''' . encode ( ' utf - 8' ) + zlib . compress ( ''' \ STRNEWLINE module1 ▁ py : module ▁ 0 ▁ foo . html # module - module1 ▁ Long ▁ Module ▁ desc STRNEWLINE module2 ▁ py : module ▁ 0 ▁ foo . html # module - $ ▁ - STRNEWLINE module1 . func ▁ py : function ▁ 1 ▁ sub / foo . html # $ ▁ - STRNEWLINE CFunc ▁ c : function ▁ 2 ▁ cfunc . html # CFunc ▁ - STRNEWLINE a ▁ term ▁ std : term ▁ - 1 ▁ glossary . html # term - a - term ▁ - STRNEWLINE ''' . encode ( ' utf - 8' ) ) NEW_LINE def test_read_inventory_v1 ( ) : NEW_LINE INDENT f = BytesIO ( inventory_v1 ) NEW_LINE f . readline ( ) NEW_LINE invdata = read_inventory_v1 ( f , ' / util ' , posixpath . join ) NEW_LINE assert invdata [ ' py : module ' ] [ ' module ' ] == ( ' foo ' , '1.0' , ' / util / foo . html # module - module ' , ' - ' ) NEW_LINE assert invdata [ ' py : class ' ] [ ' module . cls ' ] == ( ' foo ' , '1.0' , ' / util / foo . html # module . cls ' , ' - ' ) NEW_LINE DEDENT def test_read_inventory_v2 ( ) : NEW_LINE INDENT f = BytesIO ( inventory_v2 ) NEW_LINE f . readline ( ) NEW_LINE invdata1 = read_inventory_v2 ( f , ' / util ' , posixpath . join ) NEW_LINE # ▁ try ▁ again ▁ with ▁ a ▁ small ▁ buffer ▁ size ▁ to ▁ test ▁ the ▁ chunking ▁ algorithm ENDCOM f = BytesIO ( inventory_v2 ) NEW_LINE f . readline ( ) NEW_LINE invdata2 = read_inventory_v2 ( f , ' / util ' , posixpath . join , bufsize = 5 ) NEW_LINE assert invdata1 == invdata2 NEW_LINE assert len ( invdata1 [ ' py : module ' ] ) == 2 NEW_LINE assert invdata1 [ ' py : module ' ] [ ' module1' ] == ( ' foo ' , '2.0' , ' / util / foo . html # module - module1' , ' Long ▁ Module ▁ desc ' ) NEW_LINE assert invdata1 [ ' py : module ' ] [ ' module2' ] == ( ' foo ' , '2.0' , ' / util / foo . html # module - module2' , ' - ' ) NEW_LINE assert invdata1 [ ' py : function ' ] [ ' module1 . func ' ] [ 2 ] == ' / util / sub / foo . html # module1 . func ' NEW_LINE assert invdata1 [ ' c : function ' ] [ ' CFunc ' ] [ 2 ] == ' / util / cfunc . html # CFunc ' NEW_LINE assert invdata1 [ ' std : term ' ] [ ' a ▁ term ' ] [ 2 ] == ' / util / glossary . html # term - a - term ' NEW_LINE DEDENT @ with_app ( confoverrides = { ' extensions ' : ' sphinx . ext . intersphinx ' } ) NEW_LINE @ with_tempdir NEW_LINE def test_missing_reference ( tempdir , app ) : NEW_LINE INDENT inv_file = tempdir / ' inventory ' NEW_LINE write_file ( inv_file , inventory_v2 ) NEW_LINE app . config . intersphinx_mapping = { ' http : / / docs . python . org / ' : inv_file , ' py3k ' : ( ' http : / / docs . python . org / py3k / ' , inv_file ) , } NEW_LINE app . config . intersphinx_cache_limit = 0 NEW_LINE # ▁ load ▁ the ▁ inventory ▁ and ▁ check ▁ if ▁ it ' s ▁ done ▁ correctly ENDCOM load_mappings ( app ) NEW_LINE inv = app . env . intersphinx_inventory NEW_LINE assert inv [ ' py : module ' ] [ ' module2' ] == ( ' foo ' , '2.0' , ' http : / / docs . python . org / foo . html # module - module2' , ' - ' ) NEW_LINE # ▁ create ▁ fake ▁ nodes ▁ and ▁ check ▁ referencing ENDCOM def fake_node ( domain , type , target , content , ** attrs ) : NEW_LINE INDENT contnode = nodes . emphasis ( content , content ) NEW_LINE node = addnodes . pending_xref ( ' ' ) NEW_LINE node [ ' reftarget ' ] = target NEW_LINE node [ ' reftype ' ] = type NEW_LINE node [ ' refdomain ' ] = domain NEW_LINE node . attributes . update ( attrs ) NEW_LINE node += contnode NEW_LINE return node , contnode NEW_LINE DEDENT def reference_check ( * args , ** kwds ) : NEW_LINE INDENT node , contnode = fake_node ( * args , ** kwds ) NEW_LINE return missing_reference ( app , app . env , node , contnode ) NEW_LINE # ▁ check ▁ resolution ▁ when ▁ a ▁ target ▁ is ▁ found ENDCOM DEDENT rn = reference_check ( ' py ' , ' func ' , ' module1 . func ' , ' foo ' ) NEW_LINE assert isinstance ( rn , nodes . reference ) NEW_LINE assert rn [ ' refuri ' ] == ' http : / / docs . python . org / sub / foo . html # module1 . func ' NEW_LINE assert rn [ ' reftitle ' ] == ' ( in ▁ foo ▁ v2.0 ) ' NEW_LINE assert rn [ 0 ] . astext ( ) == ' foo ' NEW_LINE # ▁ create ▁ unresolvable ▁ nodes ▁ and ▁ check ▁ None ▁ return ▁ value ENDCOM assert reference_check ( ' py ' , ' foo ' , ' module1 . func ' , ' foo ' ) is None NEW_LINE assert reference_check ( ' py ' , ' func ' , ' foo ' , ' foo ' ) is None NEW_LINE assert reference_check ( ' py ' , ' func ' , ' foo ' , ' foo ' ) is None NEW_LINE # ▁ check ▁ handling ▁ of ▁ prefixes ENDCOM # ▁ prefix ▁ given , ▁ target ▁ found : ▁ prefix ▁ is ▁ stripped ENDCOM rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' py3k : module2' ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' module2' NEW_LINE # ▁ prefix ▁ given , ▁ but ▁ not ▁ in ▁ title : ▁ nothing ▁ stripped ENDCOM rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' module2' ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' module2' NEW_LINE # ▁ prefix ▁ given , ▁ but ▁ explicit : ▁ nothing ▁ stripped ENDCOM rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' py3k : module2' , refexplicit = True ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' py3k : module2' NEW_LINE # ▁ prefix ▁ given , ▁ target ▁ not ▁ found ▁ and ▁ nonexplicit ▁ title : ▁ prefix ▁ is ▁ stripped ENDCOM node , contnode = fake_node ( ' py ' , ' mod ' , ' py3k : unknown ' , ' py3k : unknown ' , refexplicit = False ) NEW_LINE rn = missing_reference ( app , app . env , node , contnode ) NEW_LINE assert rn is None NEW_LINE assert contnode [ 0 ] . astext ( ) == ' unknown ' NEW_LINE # ▁ prefix ▁ given , ▁ target ▁ not ▁ found ▁ and ▁ explicit ▁ title : ▁ nothing ▁ is ▁ changed ENDCOM node , contnode = fake_node ( ' py ' , ' mod ' , ' py3k : unknown ' , ' py3k : unknown ' , refexplicit = True ) NEW_LINE rn = missing_reference ( app , app . env , node , contnode ) NEW_LINE assert rn is None NEW_LINE assert contnode [ 0 ] . astext ( ) == ' py3k : unknown ' NEW_LINE DEDENT @ with_app ( confoverrides = { ' extensions ' : ' sphinx . ext . intersphinx ' } ) NEW_LINE @ with_tempdir NEW_LINE def test_load_mappings_warnings ( tempdir , app ) : NEW_LINE INDENT """ STRNEWLINE ▁ load _ mappings ▁ issues ▁ a ▁ warning ▁ if ▁ new - style ▁ mapping STRNEWLINE ▁ identifiers ▁ are ▁ not ▁ alphanumeric STRNEWLINE ▁ """ NEW_LINE inv_file = tempdir / ' inventory ' NEW_LINE write_file ( inv_file , inventory_v2 ) NEW_LINE app . config . intersphinx_mapping = { ' http : / / docs . python . org / ' : inv_file , ' py3k ' : ( ' http : / / docs . python . org / py3k / ' , inv_file ) , ' repoze . workflow ' : ( ' http : / / docs . repoze . org / workflow / ' , inv_file ) , ' django - taggit ' : ( ' http : / / django - taggit . readthedocs . org / en / latest / ' , inv_file ) } NEW_LINE app . config . intersphinx_cache_limit = 0 NEW_LINE # ▁ load ▁ the ▁ inventory ▁ and ▁ check ▁ if ▁ it ' s ▁ done ▁ correctly ENDCOM load_mappings ( app ) NEW_LINE assert len ( app . _warning . content ) == 2 NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="xianjunzhengbackup/Cloud-Native-Python/tree/master/env/lib/python3.6/site-packages/pip/_vendor/progress/__init__.py"> # ▁ Copyright ▁ ( c ) ▁ 2012 ▁ Giorgos ▁ Verigakis ▁ < verigak @ gmail . com > ENDCOM # ▁ Permission ▁ to ▁ use , ▁ copy , ▁ modify , ▁ and ▁ distribute ▁ this ▁ software ▁ for ▁ any ENDCOM # ▁ purpose ▁ with ▁ or ▁ without ▁ fee ▁ is ▁ hereby ▁ granted , ▁ provided ▁ that ▁ the ▁ above ENDCOM # ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ appear ▁ in ▁ all ▁ copies . ENDCOM # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ " AS ▁ IS " ▁ AND ▁ THE ▁ AUTHOR ▁ DISCLAIMS ▁ ALL ▁ WARRANTIES ENDCOM # ▁ WITH ▁ REGARD ▁ TO ▁ THIS ▁ SOFTWARE ▁ INCLUDING ▁ ALL ▁ IMPLIED ▁ WARRANTIES ▁ OF ENDCOM # ▁ MERCHANTABILITY ▁ AND ▁ FITNESS . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ AUTHOR ▁ BE ▁ LIABLE ▁ FOR ENDCOM # ▁ ANY ▁ SPECIAL , ▁ DIRECT , ▁ INDIRECT , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ OR ▁ ANY ▁ DAMAGES ENDCOM # ▁ WHATSOEVER ▁ RESULTING ▁ FROM ▁ LOSS ▁ OF ▁ USE , ▁ DATA ▁ OR ▁ PROFITS , ▁ WHETHER ▁ IN ▁ AN ENDCOM # ▁ ACTION ▁ OF ▁ CONTRACT , ▁ NEGLIGENCE ▁ OR ▁ OTHER ▁ TORTIOUS ▁ ACTION , ▁ ARISING ▁ OUT ▁ OF ENDCOM # ▁ OR ▁ IN ▁ CONNECTION ▁ WITH ▁ THE ▁ USE ▁ OR ▁ PERFORMANCE ▁ OF ▁ THIS ▁ SOFTWARE . ENDCOM from __future__ import division NEW_LINE from collections import deque NEW_LINE from datetime import timedelta NEW_LINE from math import ceil NEW_LINE from sys import stderr NEW_LINE from time import time NEW_LINE __version__ = '1.2' NEW_LINE class Infinite ( object ) : NEW_LINE INDENT file = stderr NEW_LINE sma_window = 10 NEW_LINE def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT self . index = 0 NEW_LINE self . start_ts = time ( ) NEW_LINE self . _ts = self . start_ts NEW_LINE self . _dt = deque ( maxlen = self . sma_window ) NEW_LINE for key , val in kwargs . items ( ) : NEW_LINE INDENT setattr ( self , key , val ) NEW_LINE DEDENT DEDENT def __getitem__ ( self , key ) : NEW_LINE INDENT if key . startswith ( ' _ ' ) : NEW_LINE INDENT return None NEW_LINE DEDENT return getattr ( self , key , None ) NEW_LINE DEDENT @ property NEW_LINE def avg ( self ) : NEW_LINE INDENT return sum ( self . _dt ) / len ( self . _dt ) if self . _dt else 0 NEW_LINE DEDENT @ property NEW_LINE def elapsed ( self ) : NEW_LINE INDENT return int ( time ( ) - self . start_ts ) NEW_LINE DEDENT @ property NEW_LINE def elapsed_td ( self ) : NEW_LINE INDENT return timedelta ( seconds = self . elapsed ) NEW_LINE DEDENT def update ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def start ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def finish ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def next ( self , n = 1 ) : NEW_LINE INDENT if n > 0 : NEW_LINE INDENT now = time ( ) NEW_LINE dt = ( now - self . _ts ) / n NEW_LINE self . _dt . append ( dt ) NEW_LINE self . _ts = now NEW_LINE DEDENT self . index = self . index + n NEW_LINE self . update ( ) NEW_LINE DEDENT def iter ( self , it ) : NEW_LINE INDENT for x in it : NEW_LINE INDENT yield x NEW_LINE self . next ( ) NEW_LINE DEDENT self . finish ( ) NEW_LINE DEDENT DEDENT class Progress ( Infinite ) : NEW_LINE INDENT def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT super ( Progress , self ) . __init__ ( * args , ** kwargs ) NEW_LINE self . max = kwargs . get ( ' max ' , 100 ) NEW_LINE DEDENT @ property NEW_LINE def eta ( self ) : NEW_LINE INDENT return int ( ceil ( self . avg * self . remaining ) ) NEW_LINE DEDENT @ property NEW_LINE def eta_td ( self ) : NEW_LINE INDENT return timedelta ( seconds = self . eta ) NEW_LINE DEDENT @ property NEW_LINE def percent ( self ) : NEW_LINE INDENT return self . progress * 100 NEW_LINE DEDENT @ property NEW_LINE def progress ( self ) : NEW_LINE INDENT return min ( 1 , self . index / self . max ) NEW_LINE DEDENT @ property NEW_LINE def remaining ( self ) : NEW_LINE INDENT return max ( self . max - self . index , 0 ) NEW_LINE DEDENT def start ( self ) : NEW_LINE INDENT self . update ( ) NEW_LINE DEDENT def goto ( self , index ) : NEW_LINE INDENT incr = index - self . index NEW_LINE self . next ( incr ) NEW_LINE DEDENT def iter ( self , it ) : NEW_LINE INDENT try : NEW_LINE INDENT self . max = len ( it ) NEW_LINE DEDENT except TypeError : NEW_LINE INDENT pass NEW_LINE DEDENT for x in it : NEW_LINE INDENT yield x NEW_LINE self . next ( ) NEW_LINE DEDENT self . finish ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="helenst/django/tree/master/django/contrib/gis/db/backends/mysql/introspection.py"> from MySQLdb . constants import FIELD_TYPE NEW_LINE from django . contrib . gis . gdal import OGRGeomType NEW_LINE from django . db . backends . mysql . introspection import DatabaseIntrospection NEW_LINE class MySQLIntrospection ( DatabaseIntrospection ) : NEW_LINE # ▁ Updating ▁ the ▁ data _ types _ reverse ▁ dictionary ▁ with ▁ the ▁ appropriate ENDCOM # ▁ type ▁ for ▁ Geometry ▁ fields . ENDCOM INDENT data_types_reverse = DatabaseIntrospection . data_types_reverse . copy ( ) NEW_LINE data_types_reverse [ FIELD_TYPE . GEOMETRY ] = ' GeometryField ' NEW_LINE def get_geometry_type ( self , table_name , geo_col ) : NEW_LINE INDENT cursor = self . connection . cursor ( ) NEW_LINE try : NEW_LINE # ▁ In ▁ order ▁ to ▁ get ▁ the ▁ specific ▁ geometry ▁ type ▁ of ▁ the ▁ field , ENDCOM # ▁ we ▁ introspect ▁ on ▁ the ▁ table ▁ definition ▁ using ▁ ` DESCRIBE ` . ENDCOM INDENT cursor . execute ( ' DESCRIBE ▁ % s ' % self . connection . ops . quote_name ( table_name ) ) NEW_LINE # ▁ Increment ▁ over ▁ description ▁ info ▁ until ▁ we ▁ get ▁ to ▁ the ▁ geometry ENDCOM # ▁ column . ENDCOM for column , typ , null , key , default , extra in cursor . fetchall ( ) : NEW_LINE INDENT if column == geo_col : NEW_LINE # ▁ Using ▁ OGRGeomType ▁ to ▁ convert ▁ from ▁ OGC ▁ name ▁ to ▁ Django ▁ field . ENDCOM # ▁ MySQL ▁ does ▁ not ▁ support ▁ 3D ▁ or ▁ SRIDs , ▁ so ▁ the ▁ field ▁ params ENDCOM # ▁ are ▁ empty . ENDCOM INDENT field_type = OGRGeomType ( typ ) . django NEW_LINE field_params = { } NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT finally : NEW_LINE INDENT cursor . close ( ) NEW_LINE DEDENT return field_type , field_params NEW_LINE DEDENT def supports_spatial_index ( self , cursor , table_name ) : NEW_LINE # ▁ Supported ▁ with ▁ MyISAM , ▁ or ▁ InnoDB ▁ on ▁ MySQL ▁ 5.7.5 + ENDCOM INDENT storage_engine = self . get_storage_engine ( cursor , table_name ) NEW_LINE return ( ( storage_engine == ' InnoDB ' and self . connection . mysql_version >= ( 5 , 7 , 5 ) ) or storage_engine == ' MyISAM ' ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="wsmith323/django/tree/master/tests/save_delete_hooks/tests.py"> from __future__ import unicode_literals NEW_LINE from django . test import TestCase NEW_LINE from django . utils import six NEW_LINE from . models import Person NEW_LINE class SaveDeleteHookTests ( TestCase ) : NEW_LINE INDENT def test_basic ( self ) : NEW_LINE INDENT p = Person ( first_name = " John " , last_name = " Smith " ) NEW_LINE self . assertEqual ( p . data , [ ] ) NEW_LINE p . save ( ) NEW_LINE self . assertEqual ( p . data , [ " Before ▁ save " , " After ▁ save " , ] ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) , [ " John ▁ Smith " , ] , six . text_type ) NEW_LINE p . delete ( ) NEW_LINE self . assertEqual ( p . data , [ " Before ▁ save " , " After ▁ save " , " Before ▁ deletion " , " After ▁ deletion " , ] ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) , [ ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="Thraxis/pymedusa/tree/master/lib/html5lib/treewalkers/etree.py"> from __future__ import absolute_import , division , unicode_literals NEW_LINE try : NEW_LINE INDENT from collections import OrderedDict NEW_LINE DEDENT except ImportError : NEW_LINE INDENT try : NEW_LINE INDENT from ordereddict import OrderedDict NEW_LINE DEDENT except ImportError : NEW_LINE INDENT OrderedDict = dict NEW_LINE DEDENT DEDENT import re NEW_LINE from six import string_types NEW_LINE from . import _base NEW_LINE from . . utils import moduleFactoryFactory NEW_LINE tag_regexp = re . compile ( " { ( [ ^ } ] * ) } ( . * ) " ) NEW_LINE def getETreeBuilder ( ElementTreeImplementation ) : NEW_LINE INDENT ElementTree = ElementTreeImplementation NEW_LINE ElementTreeCommentType = ElementTree . Comment ( " asd " ) . tag NEW_LINE class TreeWalker ( _base . NonRecursiveTreeWalker ) : NEW_LINE INDENT """ Given ▁ the ▁ particular ▁ ElementTree ▁ representation , ▁ this ▁ implementation , STRNEWLINE ▁ to ▁ avoid ▁ using ▁ recursion , ▁ returns ▁ " nodes " ▁ as ▁ tuples ▁ with ▁ the ▁ following STRNEWLINE ▁ content : STRNEWLINE STRNEWLINE ▁ 1 . ▁ The ▁ current ▁ element STRNEWLINE STRNEWLINE ▁ 2 . ▁ The ▁ index ▁ of ▁ the ▁ element ▁ relative ▁ to ▁ its ▁ parent STRNEWLINE STRNEWLINE ▁ 3 . ▁ A ▁ stack ▁ of ▁ ancestor ▁ elements STRNEWLINE STRNEWLINE ▁ 4 . ▁ A ▁ flag ▁ " text " , ▁ " tail " ▁ or ▁ None ▁ to ▁ indicate ▁ if ▁ the ▁ current ▁ node ▁ is ▁ a STRNEWLINE ▁ text ▁ node ; ▁ either ▁ the ▁ text ▁ or ▁ tail ▁ of ▁ the ▁ current ▁ element ▁ ( 1 ) STRNEWLINE ▁ """ NEW_LINE def getNodeDetails ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : # ▁ It ▁ might ▁ be ▁ the ▁ root ▁ Element ENDCOM NEW_LINE INDENT elt , key , parents , flag = node NEW_LINE if flag in ( " text " , " tail " ) : NEW_LINE INDENT return _base . TEXT , getattr ( elt , flag ) NEW_LINE DEDENT else : NEW_LINE INDENT node = elt NEW_LINE DEDENT DEDENT if not ( hasattr ( node , " tag " ) ) : NEW_LINE INDENT node = node . getroot ( ) NEW_LINE DEDENT if node . tag in ( " DOCUMENT _ ROOT " , " DOCUMENT _ FRAGMENT " ) : NEW_LINE INDENT return ( _base . DOCUMENT , ) NEW_LINE DEDENT elif node . tag == " < ! DOCTYPE > " : NEW_LINE INDENT return ( _base . DOCTYPE , node . text , node . get ( " publicId " ) , node . get ( " systemId " ) ) NEW_LINE DEDENT elif node . tag == ElementTreeCommentType : NEW_LINE INDENT return _base . COMMENT , node . text NEW_LINE DEDENT else : NEW_LINE INDENT assert isinstance ( node . tag , string_types ) , type ( node . tag ) NEW_LINE # ▁ This ▁ is ▁ assumed ▁ to ▁ be ▁ an ▁ ordinary ▁ element ENDCOM match = tag_regexp . match ( node . tag ) NEW_LINE if match : NEW_LINE INDENT namespace , tag = match . groups ( ) NEW_LINE DEDENT else : NEW_LINE INDENT namespace = None NEW_LINE tag = node . tag NEW_LINE DEDENT attrs = OrderedDict ( ) NEW_LINE for name , value in list ( node . attrib . items ( ) ) : NEW_LINE INDENT match = tag_regexp . match ( name ) NEW_LINE if match : NEW_LINE INDENT attrs [ ( match . group ( 1 ) , match . group ( 2 ) ) ] = value NEW_LINE DEDENT else : NEW_LINE INDENT attrs [ ( None , name ) ] = value NEW_LINE DEDENT DEDENT return ( _base . ELEMENT , namespace , tag , attrs , len ( node ) or node . text ) NEW_LINE DEDENT DEDENT def getFirstChild ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT element , key , parents , flag = node , None , [ ] , None NEW_LINE DEDENT if flag in ( " text " , " tail " ) : NEW_LINE INDENT return None NEW_LINE DEDENT else : NEW_LINE INDENT if element . text : NEW_LINE INDENT return element , key , parents , " text " NEW_LINE DEDENT elif len ( element ) : NEW_LINE INDENT parents . append ( element ) NEW_LINE return element [ 0 ] , 0 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT DEDENT def getNextSibling ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT if flag == " text " : NEW_LINE INDENT if len ( element ) : NEW_LINE INDENT parents . append ( element ) NEW_LINE return element [ 0 ] , 0 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if element . tail and flag != " tail " : NEW_LINE INDENT return element , key , parents , " tail " NEW_LINE DEDENT elif key < len ( parents [ - 1 ] ) - 1 : NEW_LINE INDENT return parents [ - 1 ] [ key + 1 ] , key + 1 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT DEDENT def getParentNode ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT if flag == " text " : NEW_LINE INDENT if not parents : NEW_LINE INDENT return element NEW_LINE DEDENT else : NEW_LINE INDENT return element , key , parents , None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT parent = parents . pop ( ) NEW_LINE if not parents : NEW_LINE INDENT return parent NEW_LINE DEDENT else : NEW_LINE INDENT return parent , list ( parents [ - 1 ] ) . index ( parent ) , parents , None NEW_LINE DEDENT DEDENT DEDENT DEDENT return locals ( ) NEW_LINE DEDENT getETreeModule = moduleFactoryFactory ( getETreeBuilder ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="Affix/CouchPotatoServer/tree/master/couchpotato/core/media/_base/providers/torrent/sceneaccess.py"> import traceback NEW_LINE from bs4 import BeautifulSoup NEW_LINE from couchpotato . core . helpers . encoding import toUnicode NEW_LINE from couchpotato . core . helpers . variable import tryInt NEW_LINE from couchpotato . core . logger import CPLog NEW_LINE from couchpotato . core . media . _base . providers . torrent . base import TorrentProvider NEW_LINE log = CPLog ( __name__ ) NEW_LINE class Base ( TorrentProvider ) : NEW_LINE INDENT urls = { ' test ' : ' https : / / www . sceneaccess . eu / ' , ' login ' : ' https : / / www . sceneaccess . eu / login ' , ' login _ check ' : ' https : / / www . sceneaccess . eu / inbox ' , ' detail ' : ' https : / / www . sceneaccess . eu / details ? id = % s ' , ' search ' : ' https : / / www . sceneaccess . eu / browse ? c % d = % d ' , ' archive ' : ' https : / / www . sceneaccess . eu / archive ? & c % d = % d ' , ' download ' : ' https : / / www . sceneaccess . eu / % s ' , } NEW_LINE http_time_between_calls = 1 # ▁ Seconds ENDCOM NEW_LINE def _searchOnTitle ( self , title , media , quality , results ) : NEW_LINE INDENT url = self . buildUrl ( title , media , quality ) NEW_LINE data = self . getHTMLData ( url ) NEW_LINE if data : NEW_LINE INDENT html = BeautifulSoup ( data ) NEW_LINE try : NEW_LINE INDENT resultsTable = html . find ( ' table ' , attrs = { ' id ' : ' torrents - table ' } ) NEW_LINE if resultsTable is None : NEW_LINE INDENT return NEW_LINE DEDENT entries = resultsTable . find_all ( ' tr ' , attrs = { ' class ' : ' tt _ row ' } ) NEW_LINE for result in entries : NEW_LINE INDENT link = result . find ( ' td ' , attrs = { ' class ' : ' ttr _ name ' } ) . find ( ' a ' ) NEW_LINE url = result . find ( ' td ' , attrs = { ' class ' : ' td _ dl ' } ) . find ( ' a ' ) NEW_LINE leechers = result . find ( ' td ' , attrs = { ' class ' : ' ttr _ leechers ' } ) . find ( ' a ' ) NEW_LINE torrent_id = link [ ' href ' ] . replace ( ' details ? id = ' , ' ' ) NEW_LINE results . append ( { ' id ' : torrent_id , ' name ' : link [ ' title ' ] , ' url ' : self . urls [ ' download ' ] % url [ ' href ' ] , ' detail _ url ' : self . urls [ ' detail ' ] % torrent_id , ' size ' : self . parseSize ( result . find ( ' td ' , attrs = { ' class ' : ' ttr _ size ' } ) . contents [ 0 ] ) , ' seeders ' : tryInt ( result . find ( ' td ' , attrs = { ' class ' : ' ttr _ seeders ' } ) . find ( ' a ' ) . string ) , ' leechers ' : tryInt ( leechers . string ) if leechers else 0 , ' get _ more _ info ' : self . getMoreInfo , } ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT log . error ( ' Failed ▁ getting ▁ results ▁ from ▁ % s : ▁ % s ' , ( self . getName ( ) , traceback . format_exc ( ) ) ) NEW_LINE DEDENT DEDENT DEDENT def getMoreInfo ( self , item ) : NEW_LINE INDENT full_description = self . getCache ( ' sceneaccess . % s ' % item [ ' id ' ] , item [ ' detail _ url ' ] , cache_timeout = 25920000 ) NEW_LINE html = BeautifulSoup ( full_description ) NEW_LINE nfo_pre = html . find ( ' div ' , attrs = { ' id ' : ' details _ table ' } ) NEW_LINE description = toUnicode ( nfo_pre . text ) if nfo_pre else ' ' NEW_LINE item [ ' description ' ] = description NEW_LINE return item NEW_LINE # ▁ Login ENDCOM DEDENT def getLoginParams ( self ) : NEW_LINE INDENT return { ' username ' : self . conf ( ' username ' ) , ' password ' : self . conf ( ' password ' ) , ' submit ' : ' come ▁ on ▁ in ' , } NEW_LINE DEDENT def loginSuccess ( self , output ) : NEW_LINE INDENT return ' / inbox ' in output . lower ( ) NEW_LINE DEDENT loginCheckSuccess = loginSuccess NEW_LINE DEDENT config = [ { ' name ' : ' sceneaccess ' , ' groups ' : [ { ' tab ' : ' searcher ' , ' list ' : ' torrent _ providers ' , ' name ' : ' SceneAccess ' , ' description ' : ' < a ▁ href = " https : / / sceneaccess . eu / " > SceneAccess < / a > ' , ' wizard ' : True , ' icon ' : ' iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAABnRSTlMAAAAAAABupgeRAAACT0lEQVR4AYVQS0sbURidO3OTmajJ5FElTTOkPmZ01GhHrIq0aoWAj1Vc + A / cuRMXbl24V9SlCGqrLhVFCrooEhCp2BAx0mobTY2kaR7qmOm87EXL1EWxh29xL + c7nPMdgGHYO5bF / gdbefnr6WlbWRnxluMwAB4Z0uEgXa7nwaDL7 + / RNPzxbYvb / XJ0FBYVfd / ayh0fQ4qCGEHcm0KLRZUk7Pb2YRJPRwcsKMidnKD3t9VVT3s7BDh + z5FOZ3Vfn3h + Hltfx00mRRSRWFcUmmVNhYVqPn8dj3va2oh + txvcQRVF9ebm1fi4k + dRFbosY5rm4Hk7xxULQnJnx93S4g0EIEEQRoDLo6PrWEw8Pc0eHLwYGopMTDirqlJ7eyhYYGHhfgfHCcKYksZGVB / NcXI2mw6HhZERqrjYTNPHi4tFPh8aJIYIhgPlcCRDoZLW1s75 + Z / 7 + 59nZ / OJhLWigqAoKZX6Mjf3dXkZ3pydGYLc4aEoCCkInzQ1fRobS2xuvllaonkedfArnY5OTdGVldBkOADgqq2Nr6z8CIWaJietDHOhKB + HhwFKC6Gnq4ukKJvP9zcSbjYDXbeVlkKzuZBhnnV3e3t6UOmaJO0ODibW1hB1GYkg8R / gup7Z3TVZLJ5AILW9LcZiVpYtYBhw16O3t7cauckyeF9Tgz0ATpL2 + nopmWycmbnY2LiKRjFk6 / d7 + / vRJfl4HGzV1T0UIM43MGBvaIBWK / YvwM5w + IMgGH8tkyEgvIpE7M3Nt6qqZrNyOq1kMmouh455Ggz + BhKY4GEc2CfwAAAAAElFTkSuQmCC ' , ' options ' : [ { ' name ' : ' enabled ' , ' type ' : ' enabler ' , ' default ' : False , } , { ' name ' : ' username ' , ' default ' : ' ' , } , { ' name ' : ' password ' , ' default ' : ' ' , ' type ' : ' password ' , } , { ' name ' : ' seed _ ratio ' , ' label ' : ' Seed ▁ ratio ' , ' type ' : ' float ' , ' default ' : 1 , ' description ' : ' Will ▁ not ▁ be ▁ ( re ) moved ▁ until ▁ this ▁ seed ▁ ratio ▁ is ▁ met . ' , } , { ' name ' : ' seed _ time ' , ' label ' : ' Seed ▁ time ' , ' type ' : ' int ' , ' default ' : 40 , ' description ' : ' Will ▁ not ▁ be ▁ ( re ) moved ▁ until ▁ this ▁ seed ▁ time ▁ ( in ▁ hours ) ▁ is ▁ met . ' , } , { ' name ' : ' extra _ score ' , ' advanced ' : True , ' label ' : ' Extra ▁ Score ' , ' type ' : ' int ' , ' default ' : 20 , ' description ' : ' Starting ▁ score ▁ for ▁ each ▁ release ▁ found ▁ via ▁ this ▁ provider . ' , } ] , } , ] , } ] NEW_LINE </DOCUMENT>
<DOCUMENT_ID="thomasgilgenast/gilgistatus-nonrel/tree/master/django/db/backends/creation.py"> import sys NEW_LINE import time NEW_LINE from django . conf import settings NEW_LINE from django . utils . datastructures import DictWrapper NEW_LINE # ▁ The ▁ prefix ▁ to ▁ put ▁ on ▁ the ▁ default ▁ database ▁ name ▁ when ▁ creating ENDCOM # ▁ the ▁ test ▁ database . ENDCOM TEST_DATABASE_PREFIX = ' test _ ' NEW_LINE class BaseDatabaseCreation ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ class ▁ encapsulates ▁ all ▁ backend - specific ▁ differences ▁ that ▁ pertain ▁ to STRNEWLINE ▁ database ▁ * creation * , ▁ such ▁ as ▁ the ▁ column ▁ types ▁ to ▁ use ▁ for ▁ particular ▁ Django STRNEWLINE ▁ Fields , ▁ the ▁ SQL ▁ used ▁ to ▁ create ▁ and ▁ destroy ▁ tables , ▁ and ▁ the ▁ creation ▁ and STRNEWLINE ▁ destruction ▁ of ▁ test ▁ databases . STRNEWLINE ▁ """ NEW_LINE data_types = { } NEW_LINE def __init__ ( self , connection ) : NEW_LINE INDENT self . connection = connection NEW_LINE DEDENT def _digest ( self , * args ) : NEW_LINE INDENT """ STRNEWLINE ▁ Generates ▁ a ▁ 32 - bit ▁ digest ▁ of ▁ a ▁ set ▁ of ▁ arguments ▁ that ▁ can ▁ be ▁ used ▁ to STRNEWLINE ▁ shorten ▁ identifying ▁ names . STRNEWLINE ▁ """ NEW_LINE return ' % x ' % ( abs ( hash ( args ) ) % 4294967296 L ) # ▁ 2 * * 32 ENDCOM NEW_LINE DEDENT def db_type ( self , field ) : NEW_LINE INDENT return self . _db_type ( field , field . get_internal_type ( ) ) NEW_LINE DEDENT def related_db_type ( self , field ) : NEW_LINE INDENT return self . _db_type ( field , field . get_related_internal_type ( ) ) NEW_LINE DEDENT def _db_type ( self , field , internal_type ) : NEW_LINE INDENT data = DictWrapper ( field . __dict__ , self . connection . ops . quote_name , " qn _ " ) NEW_LINE try : NEW_LINE INDENT return self . connection . creation . data_types [ internal_type ] % data NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT def sql_create_model ( self , model , style , known_models = set ( ) ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ the ▁ SQL ▁ required ▁ to ▁ create ▁ a ▁ single ▁ model , ▁ as ▁ a ▁ tuple ▁ of : STRNEWLINE ▁ ( list _ of _ sql , ▁ pending _ references _ dict ) STRNEWLINE ▁ """ NEW_LINE opts = model . _meta NEW_LINE if not opts . managed or opts . proxy : NEW_LINE INDENT return [ ] , { } NEW_LINE DEDENT final_output = [ ] NEW_LINE table_output = [ ] NEW_LINE pending_references = { } NEW_LINE qn = self . connection . ops . quote_name NEW_LINE for f in opts . local_fields : NEW_LINE INDENT col_type = f . db_type ( connection = self . connection ) NEW_LINE tablespace = f . db_tablespace or opts . db_tablespace NEW_LINE if col_type is None : NEW_LINE # ▁ Skip ▁ ManyToManyFields , ▁ because ▁ they ' re ▁ not ▁ represented ▁ as ENDCOM # ▁ database ▁ columns ▁ in ▁ this ▁ table . ENDCOM INDENT continue NEW_LINE # ▁ Make ▁ the ▁ definition ▁ ( e . g . ▁ ' foo ▁ VARCHAR ( 30 ) ' ) ▁ for ▁ this ▁ field . ENDCOM DEDENT field_output = [ style . SQL_FIELD ( qn ( f . column ) ) , style . SQL_COLTYPE ( col_type ) ] NEW_LINE if not f . null : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' NOT ▁ NULL ' ) ) NEW_LINE DEDENT if f . primary_key : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' PRIMARY ▁ KEY ' ) ) NEW_LINE DEDENT elif f . unique : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' UNIQUE ' ) ) NEW_LINE DEDENT if tablespace and f . unique : NEW_LINE # ▁ We ▁ must ▁ specify ▁ the ▁ index ▁ tablespace ▁ inline , ▁ because ▁ we ENDCOM # ▁ won ' t ▁ be ▁ generating ▁ a ▁ CREATE ▁ INDEX ▁ statement ▁ for ▁ this ▁ field . ENDCOM INDENT field_output . append ( self . connection . ops . tablespace_sql ( tablespace , inline = True ) ) NEW_LINE DEDENT if f . rel : NEW_LINE INDENT ref_output , pending = self . sql_for_inline_foreign_key_references ( f , known_models , style ) NEW_LINE if pending : NEW_LINE INDENT pr = pending_references . setdefault ( f . rel . to , [ ] ) . append ( ( model , f ) ) NEW_LINE DEDENT else : NEW_LINE INDENT field_output . extend ( ref_output ) NEW_LINE DEDENT DEDENT table_output . append ( ' ▁ ' . join ( field_output ) ) NEW_LINE DEDENT for field_constraints in opts . unique_together : NEW_LINE INDENT table_output . append ( style . SQL_KEYWORD ( ' UNIQUE ' ) + ' ▁ ( % s ) ' % " , ▁ " . join ( [ style . SQL_FIELD ( qn ( opts . get_field ( f ) . column ) ) for f in field_constraints ] ) ) NEW_LINE DEDENT full_statement = [ style . SQL_KEYWORD ( ' CREATE ▁ TABLE ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( opts . db_table ) ) + ' ▁ ( ' ] NEW_LINE for i , line in enumerate ( table_output ) : # ▁ Combine ▁ and ▁ add ▁ commas . ENDCOM NEW_LINE INDENT full_statement . append ( ' ▁ ▁ ▁ ▁ % s % s ' % ( line , i < len ( table_output ) - 1 and ' , ' or ' ' ) ) NEW_LINE DEDENT full_statement . append ( ' ) ' ) NEW_LINE if opts . db_tablespace : NEW_LINE INDENT full_statement . append ( self . connection . ops . tablespace_sql ( opts . db_tablespace ) ) NEW_LINE DEDENT full_statement . append ( ' ; ' ) NEW_LINE final_output . append ( ' \n ' . join ( full_statement ) ) NEW_LINE if opts . has_auto_field : NEW_LINE # ▁ Add ▁ any ▁ extra ▁ SQL ▁ needed ▁ to ▁ support ▁ auto - incrementing ▁ primary ▁ keys . ENDCOM INDENT auto_column = opts . auto_field . db_column or opts . auto_field . name NEW_LINE autoinc_sql = self . connection . ops . autoinc_sql ( opts . db_table , auto_column ) NEW_LINE if autoinc_sql : NEW_LINE INDENT for stmt in autoinc_sql : NEW_LINE INDENT final_output . append ( stmt ) NEW_LINE DEDENT DEDENT DEDENT return final_output , pending_references NEW_LINE DEDENT def sql_for_inline_foreign_key_references ( self , field , known_models , style ) : NEW_LINE INDENT " Return ▁ the ▁ SQL ▁ snippet ▁ defining ▁ the ▁ foreign ▁ key ▁ reference ▁ for ▁ a ▁ field " NEW_LINE qn = self . connection . ops . quote_name NEW_LINE if field . rel . to in known_models : NEW_LINE INDENT output = [ style . SQL_KEYWORD ( ' REFERENCES ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( field . rel . to . _meta . db_table ) ) + ' ▁ ( ' + style . SQL_FIELD ( qn ( field . rel . to . _meta . get_field ( field . rel . field_name ) . column ) ) + ' ) ' + self . connection . ops . deferrable_sql ( ) ] NEW_LINE pending = False NEW_LINE DEDENT else : NEW_LINE # ▁ We ▁ haven ' t ▁ yet ▁ created ▁ the ▁ table ▁ to ▁ which ▁ this ▁ field ENDCOM # ▁ is ▁ related , ▁ so ▁ save ▁ it ▁ for ▁ later . ENDCOM INDENT output = [ ] NEW_LINE pending = True NEW_LINE DEDENT return output , pending NEW_LINE DEDENT def sql_for_pending_references ( self , model , style , pending_references ) : NEW_LINE INDENT " Returns ▁ any ▁ ALTER ▁ TABLE ▁ statements ▁ to ▁ add ▁ constraints ▁ after ▁ the ▁ fact . " NEW_LINE from django . db . backends . util import truncate_name NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT qn = self . connection . ops . quote_name NEW_LINE final_output = [ ] NEW_LINE opts = model . _meta NEW_LINE if model in pending_references : NEW_LINE INDENT for rel_class , f in pending_references [ model ] : NEW_LINE INDENT rel_opts = rel_class . _meta NEW_LINE r_table = rel_opts . db_table NEW_LINE r_col = f . column NEW_LINE table = opts . db_table NEW_LINE col = opts . get_field ( f . rel . field_name ) . column NEW_LINE # ▁ For ▁ MySQL , ▁ r _ name ▁ must ▁ be ▁ unique ▁ in ▁ the ▁ first ▁ 64 ▁ characters . ENDCOM # ▁ So ▁ we ▁ are ▁ careful ▁ with ▁ character ▁ usage ▁ here . ENDCOM r_name = ' % s _ refs _ % s _ % s ' % ( r_col , col , self . _digest ( r_table , table ) ) NEW_LINE final_output . append ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) + ' ▁ % s ▁ ADD ▁ CONSTRAINT ▁ % s ▁ FOREIGN ▁ KEY ▁ ( % s ) ▁ REFERENCES ▁ % s ▁ ( % s ) % s ; ' % ( qn ( r_table ) , qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) , qn ( r_col ) , qn ( table ) , qn ( col ) , self . connection . ops . deferrable_sql ( ) ) ) NEW_LINE DEDENT del pending_references [ model ] NEW_LINE DEDENT return final_output NEW_LINE DEDENT def sql_for_many_to_many ( self , model , style ) : NEW_LINE INDENT " Return ▁ the ▁ CREATE ▁ TABLE ▁ statments ▁ for ▁ all ▁ the ▁ many - to - many ▁ tables ▁ defined ▁ on ▁ a ▁ model " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE output = [ ] NEW_LINE for f in model . _meta . local_many_to_many : NEW_LINE INDENT if model . _meta . managed or f . rel . to . _meta . managed : NEW_LINE INDENT output . extend ( self . sql_for_many_to_many_field ( model , f , style ) ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def sql_for_many_to_many_field ( self , model , f , style ) : NEW_LINE INDENT " Return ▁ the ▁ CREATE ▁ TABLE ▁ statements ▁ for ▁ a ▁ single ▁ m2m ▁ field " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE from django . db import models NEW_LINE from django . db . backends . util import truncate_name NEW_LINE output = [ ] NEW_LINE if f . auto_created : NEW_LINE INDENT opts = model . _meta NEW_LINE qn = self . connection . ops . quote_name NEW_LINE tablespace = f . db_tablespace or opts . db_tablespace NEW_LINE if tablespace : NEW_LINE INDENT sql = self . connection . ops . tablespace_sql ( tablespace , inline = True ) NEW_LINE if sql : NEW_LINE INDENT tablespace_sql = ' ▁ ' + sql NEW_LINE DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT table_output = [ style . SQL_KEYWORD ( ' CREATE ▁ TABLE ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( f . m2m_db_table ( ) ) ) + ' ▁ ( ' ] NEW_LINE table_output . append ( ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s % s , ' % ( style . SQL_FIELD ( qn ( ' id ' ) ) , style . SQL_COLTYPE ( models . AutoField ( primary_key = True ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ PRIMARY ▁ KEY ' ) , tablespace_sql ) ) NEW_LINE deferred = [ ] NEW_LINE inline_output , deferred = self . sql_for_inline_many_to_many_references ( model , f , style ) NEW_LINE table_output . extend ( inline_output ) NEW_LINE table_output . append ( ' ▁ ▁ ▁ ▁ % s ▁ ( % s , ▁ % s ) % s ' % ( style . SQL_KEYWORD ( ' UNIQUE ' ) , style . SQL_FIELD ( qn ( f . m2m_column_name ( ) ) ) , style . SQL_FIELD ( qn ( f . m2m_reverse_name ( ) ) ) , tablespace_sql ) ) NEW_LINE table_output . append ( ' ) ' ) NEW_LINE if opts . db_tablespace : NEW_LINE # ▁ f . db _ tablespace ▁ is ▁ only ▁ for ▁ indices , ▁ so ▁ ignore ▁ its ▁ value ▁ here . ENDCOM INDENT table_output . append ( self . connection . ops . tablespace_sql ( opts . db_tablespace ) ) NEW_LINE DEDENT table_output . append ( ' ; ' ) NEW_LINE output . append ( ' \n ' . join ( table_output ) ) NEW_LINE for r_table , r_col , table , col in deferred : NEW_LINE INDENT r_name = ' % s _ refs _ % s _ % s ' % ( r_col , col , self . _digest ( r_table , table ) ) NEW_LINE output . append ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) + ' ▁ % s ▁ ADD ▁ CONSTRAINT ▁ % s ▁ FOREIGN ▁ KEY ▁ ( % s ) ▁ REFERENCES ▁ % s ▁ ( % s ) % s ; ' % ( qn ( r_table ) , qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) , qn ( r_col ) , qn ( table ) , qn ( col ) , self . connection . ops . deferrable_sql ( ) ) ) NEW_LINE # ▁ Add ▁ any ▁ extra ▁ SQL ▁ needed ▁ to ▁ support ▁ auto - incrementing ▁ PKs ENDCOM DEDENT autoinc_sql = self . connection . ops . autoinc_sql ( f . m2m_db_table ( ) , ' id ' ) NEW_LINE if autoinc_sql : NEW_LINE INDENT for stmt in autoinc_sql : NEW_LINE INDENT output . append ( stmt ) NEW_LINE DEDENT DEDENT DEDENT return output NEW_LINE DEDENT def sql_for_inline_many_to_many_references ( self , model , field , style ) : NEW_LINE INDENT " Create ▁ the ▁ references ▁ to ▁ other ▁ tables ▁ required ▁ by ▁ a ▁ many - to - many ▁ table " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE from django . db import models NEW_LINE opts = model . _meta NEW_LINE qn = self . connection . ops . quote_name NEW_LINE table_output = [ ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s ▁ % s ▁ ( % s ) % s , ' % ( style . SQL_FIELD ( qn ( field . m2m_column_name ( ) ) ) , style . SQL_COLTYPE ( models . ForeignKey ( model ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ REFERENCES ' ) , style . SQL_TABLE ( qn ( opts . db_table ) ) , style . SQL_FIELD ( qn ( opts . pk . column ) ) , self . connection . ops . deferrable_sql ( ) ) , ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s ▁ % s ▁ ( % s ) % s , ' % ( style . SQL_FIELD ( qn ( field . m2m_reverse_name ( ) ) ) , style . SQL_COLTYPE ( models . ForeignKey ( field . rel . to ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ REFERENCES ' ) , style . SQL_TABLE ( qn ( field . rel . to . _meta . db_table ) ) , style . SQL_FIELD ( qn ( field . rel . to . _meta . pk . column ) ) , self . connection . ops . deferrable_sql ( ) ) ] NEW_LINE deferred = [ ] NEW_LINE return table_output , deferred NEW_LINE DEDENT def sql_indexes_for_model ( self , model , style ) : NEW_LINE INDENT " Returns ▁ the ▁ CREATE ▁ INDEX ▁ SQL ▁ statements ▁ for ▁ a ▁ single ▁ model " NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT output = [ ] NEW_LINE for f in model . _meta . local_fields : NEW_LINE INDENT output . extend ( self . sql_indexes_for_field ( model , f , style ) ) NEW_LINE DEDENT return output NEW_LINE DEDENT def sql_indexes_for_field ( self , model , f , style ) : NEW_LINE INDENT " Return ▁ the ▁ CREATE ▁ INDEX ▁ SQL ▁ statements ▁ for ▁ a ▁ single ▁ model ▁ field " NEW_LINE from django . db . backends . util import truncate_name NEW_LINE if f . db_index and not f . unique : NEW_LINE INDENT qn = self . connection . ops . quote_name NEW_LINE tablespace = f . db_tablespace or model . _meta . db_tablespace NEW_LINE if tablespace : NEW_LINE INDENT sql = self . connection . ops . tablespace_sql ( tablespace ) NEW_LINE if sql : NEW_LINE INDENT tablespace_sql = ' ▁ ' + sql NEW_LINE DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT i_name = ' % s _ % s ' % ( model . _meta . db_table , self . _digest ( f . column ) ) NEW_LINE output = [ style . SQL_KEYWORD ( ' CREATE ▁ INDEX ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( truncate_name ( i_name , self . connection . ops . max_name_length ( ) ) ) ) + ' ▁ ' + style . SQL_KEYWORD ( ' ON ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( model . _meta . db_table ) ) + ' ▁ ' + " ( % s ) " % style . SQL_FIELD ( qn ( f . column ) ) + " % s ; " % tablespace_sql ] NEW_LINE DEDENT else : NEW_LINE INDENT output = [ ] NEW_LINE DEDENT return output NEW_LINE DEDENT def sql_destroy_model ( self , model , references_to_delete , style ) : NEW_LINE INDENT " Return ▁ the ▁ DROP ▁ TABLE ▁ and ▁ restraint ▁ dropping ▁ statements ▁ for ▁ a ▁ single ▁ model " NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE # ▁ Drop ▁ the ▁ table ▁ now ENDCOM DEDENT qn = self . connection . ops . quote_name NEW_LINE output = [ ' % s ▁ % s ; ' % ( style . SQL_KEYWORD ( ' DROP ▁ TABLE ' ) , style . SQL_TABLE ( qn ( model . _meta . db_table ) ) ) ] NEW_LINE if model in references_to_delete : NEW_LINE INDENT output . extend ( self . sql_remove_table_constraints ( model , references_to_delete , style ) ) NEW_LINE DEDENT if model . _meta . has_auto_field : NEW_LINE INDENT ds = self . connection . ops . drop_sequence_sql ( model . _meta . db_table ) NEW_LINE if ds : NEW_LINE INDENT output . append ( ds ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def sql_remove_table_constraints ( self , model , references_to_delete , style ) : NEW_LINE INDENT from django . db . backends . util import truncate_name NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT output = [ ] NEW_LINE qn = self . connection . ops . quote_name NEW_LINE for rel_class , f in references_to_delete [ model ] : NEW_LINE INDENT table = rel_class . _meta . db_table NEW_LINE col = f . column NEW_LINE r_table = model . _meta . db_table NEW_LINE r_col = model . _meta . get_field ( f . rel . field_name ) . column NEW_LINE r_name = ' % s _ refs _ % s _ % s ' % ( col , r_col , self . _digest ( table , r_table ) ) NEW_LINE output . append ( ' % s ▁ % s ▁ % s ▁ % s ; ' % ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) , style . SQL_TABLE ( qn ( table ) ) , style . SQL_KEYWORD ( self . connection . ops . drop_foreignkey_sql ( ) ) , style . SQL_FIELD ( qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) ) ) ) NEW_LINE DEDENT del references_to_delete [ model ] NEW_LINE return output NEW_LINE DEDENT def sql_destroy_many_to_many ( self , model , f , style ) : NEW_LINE INDENT " Returns ▁ the ▁ DROP ▁ TABLE ▁ statements ▁ for ▁ a ▁ single ▁ m2m ▁ field " NEW_LINE import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE qn = self . connection . ops . quote_name NEW_LINE output = [ ] NEW_LINE if f . auto_created : NEW_LINE INDENT output . append ( " % s ▁ % s ; " % ( style . SQL_KEYWORD ( ' DROP ▁ TABLE ' ) , style . SQL_TABLE ( qn ( f . m2m_db_table ( ) ) ) ) ) NEW_LINE ds = self . connection . ops . drop_sequence_sql ( " % s _ % s " % ( model . _meta . db_table , f . column ) ) NEW_LINE if ds : NEW_LINE INDENT output . append ( ds ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def create_test_db ( self , verbosity = 1 , autoclobber = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Creates ▁ a ▁ test ▁ database , ▁ prompting ▁ the ▁ user ▁ for ▁ confirmation ▁ if ▁ the STRNEWLINE ▁ database ▁ already ▁ exists . ▁ Returns ▁ the ▁ name ▁ of ▁ the ▁ test ▁ database ▁ created . STRNEWLINE ▁ """ NEW_LINE # ▁ Don ' t ▁ import ▁ django . core . management ▁ if ▁ it ▁ isn ' t ▁ needed . ENDCOM from django . core . management import call_command NEW_LINE test_database_name = self . _get_test_db_name ( ) NEW_LINE if verbosity >= 1 : NEW_LINE INDENT test_db_repr = ' ' NEW_LINE if verbosity >= 2 : NEW_LINE INDENT test_db_repr = " ▁ ( ' % s ' ) " % test_database_name NEW_LINE DEDENT print " Creating ▁ test ▁ database ▁ for ▁ alias ▁ ' % s ' % s . . . " % ( self . connection . alias , test_db_repr ) NEW_LINE DEDENT self . _create_test_db ( verbosity , autoclobber ) NEW_LINE self . connection . close ( ) NEW_LINE self . connection . settings_dict [ " NAME " ] = test_database_name NEW_LINE # ▁ Confirm ▁ the ▁ feature ▁ set ▁ of ▁ the ▁ test ▁ database ENDCOM self . connection . features . confirm ( ) NEW_LINE # ▁ Report ▁ syncdb ▁ messages ▁ at ▁ one ▁ level ▁ lower ▁ than ▁ that ▁ requested . ENDCOM # ▁ This ▁ ensures ▁ we ▁ don ' t ▁ get ▁ flooded ▁ with ▁ messages ▁ during ▁ testing ENDCOM # ▁ ( unless ▁ you ▁ really ▁ ask ▁ to ▁ be ▁ flooded ) ENDCOM call_command ( ' syncdb ' , verbosity = max ( verbosity - 1 , 0 ) , interactive = False , database = self . connection . alias , load_initial_data = False ) NEW_LINE # ▁ We ▁ need ▁ to ▁ then ▁ do ▁ a ▁ flush ▁ to ▁ ensure ▁ that ▁ any ▁ data ▁ installed ▁ by ENDCOM # ▁ custom ▁ SQL ▁ has ▁ been ▁ removed . ▁ The ▁ only ▁ test ▁ data ▁ should ▁ come ▁ from ENDCOM # ▁ test ▁ fixtures , ▁ or ▁ autogenerated ▁ from ▁ post _ syncdb ▁ triggers . ENDCOM # ▁ This ▁ has ▁ the ▁ side ▁ effect ▁ of ▁ loading ▁ initial ▁ data ▁ ( which ▁ was ENDCOM # ▁ intentionally ▁ skipped ▁ in ▁ the ▁ syncdb ) . ENDCOM call_command ( ' flush ' , verbosity = max ( verbosity - 1 , 0 ) , interactive = False , database = self . connection . alias ) NEW_LINE from django . core . cache import get_cache NEW_LINE from django . core . cache . backends . db import BaseDatabaseCache NEW_LINE for cache_alias in settings . CACHES : NEW_LINE INDENT cache = get_cache ( cache_alias ) NEW_LINE if isinstance ( cache , BaseDatabaseCache ) : NEW_LINE INDENT from django . db import router NEW_LINE if router . allow_syncdb ( self . connection . alias , cache . cache_model_class ) : NEW_LINE INDENT call_command ( ' createcachetable ' , cache . _table , database = self . connection . alias ) NEW_LINE # ▁ Get ▁ a ▁ cursor ▁ ( even ▁ though ▁ we ▁ don ' t ▁ need ▁ one ▁ yet ) . ▁ This ▁ has ENDCOM # ▁ the ▁ side ▁ effect ▁ of ▁ initializing ▁ the ▁ test ▁ database . ENDCOM DEDENT DEDENT DEDENT cursor = self . connection . cursor ( ) NEW_LINE return test_database_name NEW_LINE DEDENT def _get_test_db_name ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Internal ▁ implementation ▁ - ▁ returns ▁ the ▁ name ▁ of ▁ the ▁ test ▁ DB ▁ that ▁ will ▁ be STRNEWLINE ▁ created . ▁ Only ▁ useful ▁ when ▁ called ▁ from ▁ create _ test _ db ( ) ▁ and STRNEWLINE ▁ _ create _ test _ db ( ) ▁ and ▁ when ▁ no ▁ external ▁ munging ▁ is ▁ done ▁ with ▁ the ▁ ' NAME ' STRNEWLINE ▁ or ▁ ' TEST _ NAME ' ▁ settings . STRNEWLINE ▁ """ NEW_LINE if self . connection . settings_dict [ ' TEST _ NAME ' ] : NEW_LINE INDENT return self . connection . settings_dict [ ' TEST _ NAME ' ] NEW_LINE DEDENT return TEST_DATABASE_PREFIX + self . connection . settings_dict [ ' NAME ' ] NEW_LINE DEDENT def _create_test_db ( self , verbosity , autoclobber ) : NEW_LINE INDENT " Internal ▁ implementation ▁ - ▁ creates ▁ the ▁ test ▁ db ▁ tables . " NEW_LINE suffix = self . sql_table_creation_suffix ( ) NEW_LINE test_database_name = self . _get_test_db_name ( ) NEW_LINE qn = self . connection . ops . quote_name NEW_LINE # ▁ Create ▁ the ▁ test ▁ database ▁ and ▁ connect ▁ to ▁ it . ▁ We ▁ need ▁ to ▁ autocommit ENDCOM # ▁ if ▁ the ▁ database ▁ supports ▁ it ▁ because ▁ PostgreSQL ▁ doesn ' t ▁ allow ENDCOM # ▁ CREATE / DROP ▁ DATABASE ▁ statements ▁ within ▁ transactions . ENDCOM cursor = self . connection . cursor ( ) NEW_LINE self . set_autocommit ( ) NEW_LINE try : NEW_LINE INDENT cursor . execute ( " CREATE ▁ DATABASE ▁ % s ▁ % s " % ( qn ( test_database_name ) , suffix ) ) NEW_LINE DEDENT except Exception , e : NEW_LINE INDENT sys . stderr . write ( " Got ▁ an ▁ error ▁ creating ▁ the ▁ test ▁ database : ▁ % s \n " % e ) NEW_LINE if not autoclobber : NEW_LINE INDENT confirm = raw_input ( " Type ▁ ' yes ' ▁ if ▁ you ▁ would ▁ like ▁ to ▁ try ▁ deleting ▁ the ▁ test ▁ database ▁ ' % s ' , ▁ or ▁ ' no ' ▁ to ▁ cancel : ▁ " % test_database_name ) NEW_LINE DEDENT if autoclobber or confirm == ' yes ' : NEW_LINE INDENT try : NEW_LINE INDENT if verbosity >= 1 : NEW_LINE INDENT print " Destroying ▁ old ▁ test ▁ database ▁ ' % s ' . . . " % self . connection . alias NEW_LINE DEDENT cursor . execute ( " DROP ▁ DATABASE ▁ % s " % qn ( test_database_name ) ) NEW_LINE cursor . execute ( " CREATE ▁ DATABASE ▁ % s ▁ % s " % ( qn ( test_database_name ) , suffix ) ) NEW_LINE DEDENT except Exception , e : NEW_LINE INDENT sys . stderr . write ( " Got ▁ an ▁ error ▁ recreating ▁ the ▁ test ▁ database : ▁ % s \n " % e ) NEW_LINE sys . exit ( 2 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " Tests ▁ cancelled . " NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT DEDENT return test_database_name NEW_LINE DEDENT def destroy_test_db ( self , old_database_name , verbosity = 1 ) : NEW_LINE INDENT """ STRNEWLINE ▁ Destroy ▁ a ▁ test ▁ database , ▁ prompting ▁ the ▁ user ▁ for ▁ confirmation ▁ if ▁ the STRNEWLINE ▁ database ▁ already ▁ exists . ▁ Returns ▁ the ▁ name ▁ of ▁ the ▁ test ▁ database ▁ created . STRNEWLINE ▁ """ NEW_LINE self . connection . close ( ) NEW_LINE test_database_name = self . connection . settings_dict [ ' NAME ' ] NEW_LINE if verbosity >= 1 : NEW_LINE INDENT test_db_repr = ' ' NEW_LINE if verbosity >= 2 : NEW_LINE INDENT test_db_repr = " ▁ ( ' % s ' ) " % test_database_name NEW_LINE DEDENT print " Destroying ▁ test ▁ database ▁ for ▁ alias ▁ ' % s ' % s . . . " % ( self . connection . alias , test_db_repr ) NEW_LINE DEDENT self . connection . settings_dict [ ' NAME ' ] = old_database_name NEW_LINE self . _destroy_test_db ( test_database_name , verbosity ) NEW_LINE DEDENT def _destroy_test_db ( self , test_database_name , verbosity ) : NEW_LINE INDENT " Internal ▁ implementation ▁ - ▁ remove ▁ the ▁ test ▁ db ▁ tables . " NEW_LINE # ▁ Remove ▁ the ▁ test ▁ database ▁ to ▁ clean ▁ up ▁ after ENDCOM # ▁ ourselves . ▁ Connect ▁ to ▁ the ▁ previous ▁ database ▁ ( not ▁ the ▁ test ▁ database ) ENDCOM # ▁ to ▁ do ▁ so , ▁ because ▁ it ' s ▁ not ▁ allowed ▁ to ▁ delete ▁ a ▁ database ▁ while ▁ being ENDCOM # ▁ connected ▁ to ▁ it . ENDCOM cursor = self . connection . cursor ( ) NEW_LINE self . set_autocommit ( ) NEW_LINE time . sleep ( 1 ) # ▁ To ▁ avoid ▁ " database ▁ is ▁ being ▁ accessed ▁ by ▁ other ▁ users " ▁ errors . ENDCOM NEW_LINE cursor . execute ( " DROP ▁ DATABASE ▁ % s " % self . connection . ops . quote_name ( test_database_name ) ) NEW_LINE self . connection . close ( ) NEW_LINE DEDENT def set_autocommit ( self ) : NEW_LINE INDENT " Make ▁ sure ▁ a ▁ connection ▁ is ▁ in ▁ autocommit ▁ mode . " NEW_LINE if hasattr ( self . connection . connection , " autocommit " ) : NEW_LINE INDENT if callable ( self . connection . connection . autocommit ) : NEW_LINE INDENT self . connection . connection . autocommit ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . connection . connection . autocommit = True NEW_LINE DEDENT DEDENT elif hasattr ( self . connection . connection , " set _ isolation _ level " ) : NEW_LINE INDENT self . connection . connection . set_isolation_level ( 0 ) NEW_LINE DEDENT DEDENT def sql_table_creation_suffix ( self ) : NEW_LINE INDENT " SQL ▁ to ▁ append ▁ to ▁ the ▁ end ▁ of ▁ the ▁ test ▁ table ▁ creation ▁ statements " NEW_LINE return ' ' NEW_LINE DEDENT def test_db_signature ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ a ▁ tuple ▁ with ▁ elements ▁ of ▁ self . connection . settings _ dict ▁ ( a STRNEWLINE ▁ DATABASES ▁ setting ▁ value ) ▁ that ▁ uniquely ▁ identify ▁ a ▁ database STRNEWLINE ▁ accordingly ▁ to ▁ the ▁ RDBMS ▁ particularities . STRNEWLINE ▁ """ NEW_LINE settings_dict = self . connection . settings_dict NEW_LINE return ( settings_dict [ ' HOST ' ] , settings_dict [ ' PORT ' ] , settings_dict [ ' ENGINE ' ] , settings_dict [ ' NAME ' ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="eaglexmw/seascope/tree/master/src/view/filecontext/plugins/ctags_view/CtagsManager.py"> # ▁ Copyright ▁ ( c ) ▁ 2010 ▁ Anil ▁ Kumar ENDCOM # ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ License : ▁ BSD ▁ ENDCOM import subprocess NEW_LINE import re , os NEW_LINE def _eintr_retry_call ( func , * args ) : NEW_LINE INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT return func ( * args ) NEW_LINE DEDENT except OSError , e : NEW_LINE INDENT if e . errno == errno . EINTR : NEW_LINE INDENT continue NEW_LINE DEDENT raise NEW_LINE DEDENT DEDENT DEDENT def cmdForFile ( f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ▁ - - extra = + q ' ENDCOM # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + Ki ▁ - f ▁ - ' ENDCOM DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def ct_query ( filename ) : NEW_LINE INDENT args = cmdForFile ( filename ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( filename ) NEW_LINE try : NEW_LINE INDENT proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = _eintr_retry_call ( proc . communicate ) NEW_LINE out_data = out_data . split ( ' \n ' ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT out_data = [ ' Failed ▁ to ▁ run ▁ ctags ▁ cmd\tignore\t0 ; \t ▁ ' , ' cmd : ▁ % s\tignore\t0 ; \t ▁ ' % ' ▁ ' . join ( args ) , ' error : ▁ % s\tignore\t0 ; \t ▁ ' % str ( e ) , ' ctags ▁ not ▁ installed ▁ ? \tignore\t0 ; \t ▁ ' , ] NEW_LINE DEDENT res = [ ] NEW_LINE for line in out_data : NEW_LINE INDENT if ( line == ' ' ) : NEW_LINE INDENT break NEW_LINE DEDENT line = line . split ( ' \t ' ) NEW_LINE num = line [ 2 ] . split ( ' ; ' , 1 ) [ 0 ] NEW_LINE line = [ line [ 0 ] , num , line [ 3 ] ] NEW_LINE res . append ( line ) NEW_LINE DEDENT return res NEW_LINE DEDENT is_OrderedDict_available = False NEW_LINE try : NEW_LINE # ▁ OrderedDict ▁ available ▁ only ▁ in ▁ python ▁ > = ▁ 2.7 ENDCOM INDENT from collections import OrderedDict NEW_LINE is_OrderedDict_available = True NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT def emptyOrderedDict ( ) : NEW_LINE INDENT if is_OrderedDict_available : NEW_LINE INDENT return OrderedDict ( { } ) NEW_LINE DEDENT return { } NEW_LINE DEDENT class CtagsTreeBuilder : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . symTree = emptyOrderedDict ( ) NEW_LINE DEDENT def cmdForFile ( self , f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ▁ - - extra = + q ' ENDCOM # args ▁ = ▁ ' ctags ▁ - n ▁ - u ▁ - - fields = + Ki ▁ - f ▁ - ' ENDCOM DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K - f - t ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def runCtags ( self , f ) : NEW_LINE INDENT args = self . cmdForFile ( f ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( f ) NEW_LINE # ▁ In ▁ python ▁ > = ▁ 2.7 ▁ can ▁ use ▁ subprocess . check _ output ENDCOM # ▁ output ▁ = ▁ subprocess . check _ output ( args ) ENDCOM # ▁ return ▁ output ENDCOM proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = proc . communicate ( ) NEW_LINE return out_data NEW_LINE DEDENT def parseCtagsOutput ( self , data ) : NEW_LINE INDENT data = re . split ( ' ? \n ' , data ) NEW_LINE res = [ ] NEW_LINE for line in data : NEW_LINE INDENT if line == ' ' : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT line = line . split ( ' \t ' , 4 ) NEW_LINE res . append ( line ) NEW_LINE DEDENT except : NEW_LINE INDENT print ' bad ▁ line : ' , line NEW_LINE DEDENT DEDENT return res NEW_LINE DEDENT def addToSymLayout ( self , sc ) : NEW_LINE INDENT t = self . symTree NEW_LINE if sc and sc != ' ' : NEW_LINE INDENT for s in re . split ( ' : : | \ . ' , sc ) : NEW_LINE INDENT if s not in t : NEW_LINE INDENT t [ s ] = emptyOrderedDict ( ) NEW_LINE DEDENT t = t [ s ] NEW_LINE DEDENT DEDENT DEDENT def addToSymTree ( self , sc , line ) : NEW_LINE INDENT t = self . symTree NEW_LINE if sc and sc != ' ' : NEW_LINE INDENT for s in re . split ( ' : : | \ . ' , sc ) : NEW_LINE INDENT assert s in t NEW_LINE t = t [ s ] NEW_LINE DEDENT DEDENT cline = [ line [ 0 ] , line [ 2 ] . split ( ' ; ' ) [ 0 ] , line [ 3 ] ] NEW_LINE if line [ 0 ] in t : NEW_LINE # print ▁ line [ 0 ] , ▁ ' in ' , ▁ t ENDCOM INDENT x = t [ line [ 0 ] ] NEW_LINE if ' + ' not in x : NEW_LINE INDENT x [ ' + ' ] = cline NEW_LINE return NEW_LINE DEDENT DEDENT if ' * ' not in t : NEW_LINE INDENT t [ ' * ' ] = [ ] NEW_LINE DEDENT t [ ' * ' ] . append ( cline ) NEW_LINE # print ▁ ' . . . ' , ▁ t , ▁ line ENDCOM DEDENT def buildTree ( self , data ) : NEW_LINE INDENT type_list = [ ' namespace ' , ' class ' , ' interface ' , ' struct ' , ' union ' , ' enum ' , ' function ' ] NEW_LINE # ▁ build ▁ layout ▁ using ▁ 5th ▁ field ENDCOM for line in data : NEW_LINE INDENT if len ( line ) == 4 : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT sd = dict ( [ x . split ( ' : ' , 1 ) for x in line [ 4 ] . split ( ' \t ' ) ] ) NEW_LINE DEDENT except : NEW_LINE INDENT print ' bad ▁ line ' , line NEW_LINE continue NEW_LINE DEDENT line [ 4 ] = sd NEW_LINE count = 0 NEW_LINE for t in type_list : NEW_LINE INDENT if t in sd : NEW_LINE INDENT self . addToSymLayout ( sd [ t ] ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT if count != 1 : NEW_LINE INDENT print ' * * * * * * * * ▁ count ▁ = = ▁ 1 ▁ * * * * * * * * * ' NEW_LINE print data NEW_LINE print line NEW_LINE # assert ▁ count ▁ = = ▁ 1 ENDCOM DEDENT DEDENT if len ( self . symTree ) == 0 : NEW_LINE INDENT return ( data , False ) NEW_LINE DEDENT for line in data : NEW_LINE INDENT if len ( line ) == 4 : NEW_LINE INDENT self . addToSymTree ( None , line ) NEW_LINE continue NEW_LINE DEDENT sd = line [ 4 ] NEW_LINE count = 0 NEW_LINE for t in type_list : NEW_LINE INDENT if t in sd : NEW_LINE INDENT self . addToSymTree ( sd [ t ] , line ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT if count != 1 : NEW_LINE INDENT print ' * * * * * * * * ▁ count ▁ = = ▁ 1 ▁ * * * * * * * * * ' NEW_LINE print data NEW_LINE print line NEW_LINE # assert ▁ count ▁ = = ▁ 1 ENDCOM DEDENT DEDENT return ( self . symTree , True ) NEW_LINE DEDENT def doQuery ( self , filename ) : NEW_LINE INDENT try : NEW_LINE INDENT output = self . runCtags ( filename ) NEW_LINE output = self . parseCtagsOutput ( output ) NEW_LINE output = self . buildTree ( output ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT print str ( e ) NEW_LINE output = [ None , False ] NEW_LINE DEDENT return output NEW_LINE DEDENT DEDENT def ct_tree_query ( filename ) : NEW_LINE INDENT ct = CtagsTreeBuilder ( ) NEW_LINE output = ct . doQuery ( filename ) NEW_LINE return output NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT import optparse NEW_LINE import sys NEW_LINE depth = 0 NEW_LINE def recursePrint ( t ) : NEW_LINE INDENT global depth NEW_LINE for k , v in t . items ( ) : NEW_LINE INDENT if k == ' * ' : NEW_LINE INDENT for line in v : NEW_LINE INDENT print ' % s % s ' % ( ' ▁ ' * depth , line ) NEW_LINE DEDENT continue NEW_LINE DEDENT if k == ' + ' : NEW_LINE INDENT continue NEW_LINE DEDENT if ' + ' in v : NEW_LINE INDENT k = v [ ' + ' ] NEW_LINE DEDENT print ' % s % s ' % ( ' ▁ ' * depth , k ) NEW_LINE depth = depth + 4 NEW_LINE recursePrint ( v ) NEW_LINE depth = depth - 4 NEW_LINE DEDENT DEDENT op = optparse . OptionParser ( ) NEW_LINE ( options , args ) = op . parse_args ( ) NEW_LINE if len ( args ) != 1 : NEW_LINE INDENT print ' Please ▁ specify ▁ a ▁ file ' NEW_LINE sys . exit ( - 1 ) NEW_LINE DEDENT ( output , isTree ) = ct_tree_query ( args [ 0 ] ) NEW_LINE if isTree : NEW_LINE INDENT recursePrint ( output ) NEW_LINE DEDENT else : NEW_LINE INDENT for line in output : NEW_LINE INDENT print line NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="nischalsheth/contrail-controller/tree/master/src/vnsw/provisioning/contrail_vrouter_provisioning/network.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ Copyright ▁ ( c ) ▁ 2013 ▁ Juniper ▁ Networks , ▁ Inc . ▁ All ▁ rights ▁ reserved . ENDCOM import os NEW_LINE import re NEW_LINE import glob NEW_LINE import struct NEW_LINE import socket NEW_LINE import logging NEW_LINE import netifaces NEW_LINE from contrail_vrouter_provisioning import local NEW_LINE log = logging . getLogger ( ' contrail _ vrouter _ provisioning . network ' ) NEW_LINE class ComputeNetworkSetup ( object ) : NEW_LINE INDENT def find_gateway ( self , dev ) : NEW_LINE INDENT gateway = ' ' NEW_LINE cmd = " sudo ▁ netstat ▁ - rn ▁ | ▁ sudo ▁ grep ▁ ^ \ " 0.0.0.0\ " ▁ | ▁ " NEW_LINE cmd += " sudo ▁ head ▁ - n ▁ 1 ▁ | ▁ sudo ▁ grep ▁ % s ▁ | ▁ sudo ▁ awk ▁ ' { ▁ print ▁ $ 2 ▁ } ' " % dev NEW_LINE gateway = local ( cmd , capture = True ) . strip ( ) NEW_LINE return gateway NEW_LINE # ▁ end ▁ find _ gateway ENDCOM DEDENT def get_dns_servers ( self , dev ) : NEW_LINE INDENT cmd = " sudo ▁ grep ▁ \ " ^ nameserver\\ > \ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ▁ ' { print ▁ $ 2 } ' " NEW_LINE dns_list = local ( cmd , capture = True ) NEW_LINE return dns_list . split ( ) NEW_LINE # ▁ end ▁ get _ dns _ servers ENDCOM DEDENT def get_domain_search_list ( self ) : NEW_LINE INDENT domain_list = ' ' NEW_LINE cmd = " sudo ▁ grep ▁ ^ \ " search\ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ' { $ 1 = \ " \ " ; print ▁ $ 0 } ' " NEW_LINE domain_list = local ( cmd , capture = True ) . strip ( ) NEW_LINE if not domain_list : NEW_LINE INDENT cmd = " sudo ▁ grep ▁ ^ \ " domain\ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ' { $ 1 = \ " \ " ; ▁ print ▁ $ 0 } ' " NEW_LINE domain_list = local ( cmd , capture = True ) . strip ( ) NEW_LINE DEDENT return domain_list NEW_LINE DEDENT def get_if_mtu ( self , dev ) : NEW_LINE INDENT cmd = " sudo ▁ ifconfig ▁ % s ▁ | ▁ sudo ▁ grep ▁ mtu ▁ | ▁ sudo ▁ awk ▁ ' { ▁ print ▁ $ NF ▁ } ' " % dev NEW_LINE mtu = local ( cmd , capture = True ) . strip ( ) NEW_LINE if not mtu : NEW_LINE # ▁ for ▁ debian ENDCOM INDENT cmd = r " sudo ▁ ifconfig ▁ % s ▁ | ▁ sudo ▁ grep ▁ MTU ▁ | ▁ " % dev NEW_LINE cmd += r " sudo ▁ sed ▁ ' s / . * MTU . \ ( [0-9 ] \ + \ ) . * / \1 / g ' " NEW_LINE mtu = local ( cmd , capture = True ) . strip ( ) NEW_LINE DEDENT if ( mtu and mtu != '1500' ) : NEW_LINE INDENT return mtu NEW_LINE DEDENT return ' ' NEW_LINE # ▁ end ▁ if _ mtu ENDCOM DEDENT def get_device_by_ip ( self , ip ) : NEW_LINE INDENT for i in netifaces . interfaces ( ) : NEW_LINE INDENT try : NEW_LINE INDENT if i == ' pkt1' : NEW_LINE INDENT continue NEW_LINE DEDENT if netifaces . AF_INET in netifaces . ifaddresses ( i ) : NEW_LINE INDENT interfaces = netifaces . ifaddresses ( i ) [ netifaces . AF_INET ] NEW_LINE for interface in interfaces : NEW_LINE INDENT if ip == interface [ ' addr ' ] : NEW_LINE INDENT if i == ' vhost0' : NEW_LINE INDENT log . info ( " vhost0 ▁ is ▁ already ▁ present ! " ) NEW_LINE DEDENT return i NEW_LINE DEDENT DEDENT DEDENT DEDENT except ValueError : NEW_LINE INDENT log . info ( " Skipping ▁ interface ▁ % s " , i ) NEW_LINE DEDENT DEDENT raise RuntimeError ( ' % s ▁ not ▁ configured , ▁ rerun ▁ w / ▁ - - physical _ interface ' % ip ) NEW_LINE # ▁ end ▁ get _ device _ by _ ip ENDCOM DEDENT def get_device_info ( self , ip ) : NEW_LINE INDENT reprov = False NEW_LINE cfg_file = " / etc / contrail / contrail - vrouter - agent . conf " NEW_LINE try : NEW_LINE INDENT dev = self . get_device_by_ip ( ip ) NEW_LINE if dev == " vhost0" : NEW_LINE INDENT dev = self . get_config ( cfg_file , " VIRTUAL - HOST - INTERFACE " , " physical _ interface " ) NEW_LINE log . info ( " Re - provision . ▁ vhost0 ▁ present " ) NEW_LINE reprov = True NEW_LINE DEDENT else : NEW_LINE INDENT log . info ( " Fresh ▁ Install . ▁ vhost0 ▁ not ▁ present " ) NEW_LINE DEDENT DEDENT except RuntimeError : NEW_LINE INDENT dev = self . get_config ( cfg_file , " VIRTUAL - HOST - INTERFACE " , " physical _ interface " ) NEW_LINE if not dev . succeeded : NEW_LINE INDENT raise NEW_LINE DEDENT log . info ( " vhost0 ▁ not ▁ present , ▁ vrouter ▁ not ▁ running " ) NEW_LINE reprov = True NEW_LINE DEDENT return ( dev . strip ( ) , reprov ) NEW_LINE # ▁ end ▁ get _ device _ info ENDCOM DEDENT def get_secondary_device ( self , primary ) : NEW_LINE INDENT for i in netifaces . interfaces ( ) : NEW_LINE INDENT try : NEW_LINE INDENT if i == ' pkt1' : NEW_LINE INDENT continue NEW_LINE DEDENT if i == primary : NEW_LINE INDENT continue NEW_LINE DEDENT if i == ' vhost0' : NEW_LINE INDENT continue NEW_LINE DEDENT if netifaces . AF_INET not in netifaces . ifaddresses ( i ) : NEW_LINE INDENT return i NEW_LINE DEDENT DEDENT except ValueError : NEW_LINE INDENT log . info ( " Skipping ▁ interface ▁ % s " % i ) NEW_LINE DEDENT DEDENT raise RuntimeError ( ' Secondary ▁ interace ▁ ▁ not ▁ configured , ' , ' rerun ▁ w / ▁ - - physical _ interface ' ) NEW_LINE # ▁ end ▁ get _ secondary _ device ENDCOM DEDENT def get_if_mac ( self , dev ) : NEW_LINE INDENT iface_addr = netifaces . ifaddresses ( dev ) NEW_LINE link_info = iface_addr [ netifaces . AF_LINK ] NEW_LINE mac_addr = link_info [ 0 ] [ ' addr ' ] NEW_LINE return mac_addr NEW_LINE # ▁ end ▁ get _ if _ mac ENDCOM DEDENT @ staticmethod NEW_LINE def is_interface_vlan ( interface ) : NEW_LINE INDENT iface = local ( " sudo ▁ ip ▁ link ▁ show ▁ % s ▁ | ▁ head ▁ - 1" % interface + " | ▁ cut ▁ - f2 ▁ - d ' : ' ▁ | ▁ grep ▁ ' @ ' " , capture = True , warn_only = True ) NEW_LINE if iface . succeeded : NEW_LINE INDENT return True NEW_LINE DEDENT else : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def get_physical_interface_of_vlan ( interface ) : NEW_LINE INDENT iface = local ( " sudo ▁ ip ▁ link ▁ show ▁ % s ▁ | ▁ head ▁ - 1 ▁ | ▁ cut ▁ - f2 ▁ - d ' : ' " % interface + " | ▁ cut ▁ - f2 ▁ - d ' @ ' " , capture = True ) NEW_LINE return iface NEW_LINE DEDENT def _rewrite_ifcfg_file ( self , filename , dev , prsv_cfg ) : NEW_LINE INDENT bond = False NEW_LINE mac = ' ' NEW_LINE temp_dir_name = self . _temp_dir_name NEW_LINE vlan = False NEW_LINE if os . path . isfile ( ' / proc / net / vlan / % s ' % dev ) : NEW_LINE INDENT vlan_info = open ( ' / proc / net / vlan / config ' ) . readlines ( ) NEW_LINE match = re . search ( ' ^ % s . * \ | \s + ( \S + ) $ ' % dev , " \n " . join ( vlan_info ) , flags = re . M | re . I ) NEW_LINE if not match : NEW_LINE INDENT raise RuntimeError ( " Configured ▁ vlan ▁ % s ▁ is ▁ not ▁ found ▁ in " , " / proc / net / vlan / config " % dev ) NEW_LINE DEDENT vlan = True NEW_LINE DEDENT if os . path . isdir ( ' / sys / class / net / % s / bonding ' % dev ) : NEW_LINE INDENT bond = True NEW_LINE # ▁ end ▁ if ▁ os . path . isdir . . . ENDCOM DEDENT mac = netifaces . ifaddresses ( dev ) [ netifaces . AF_LINK ] [ 0 ] [ ' addr ' ] NEW_LINE ifcfg_file = ' / etc / sysconfig / network - scripts / ifcfg - % s ' % dev NEW_LINE if not os . path . isfile ( ifcfg_file ) : NEW_LINE INDENT ifcfg_file = temp_dir_name + ' ifcfg - ' + dev NEW_LINE with open ( ifcfg_file , ' w ' ) as f : NEW_LINE INDENT f . write ( ''' # Contrail ▁ % s STRNEWLINE TYPE = Ethernet STRNEWLINE ONBOOT = yes STRNEWLINE DEVICE = " % s " STRNEWLINE USERCTL = yes STRNEWLINE NM _ CONTROLLED = no STRNEWLINE HWADDR = % s STRNEWLINE ''' % ( dev , dev , mac ) ) NEW_LINE for dcfg in prsv_cfg : NEW_LINE INDENT f . write ( dcfg + ' \n ' ) NEW_LINE DEDENT if vlan : NEW_LINE INDENT f . write ( ' VLAN = yes \n ' ) NEW_LINE DEDENT DEDENT DEDENT fd = open ( ifcfg_file ) NEW_LINE f_lines = fd . readlines ( ) NEW_LINE fd . close ( ) NEW_LINE local ( " sudo ▁ rm ▁ - f ▁ % s " % ifcfg_file ) NEW_LINE new_f_lines = [ ] NEW_LINE remove_items = [ ' IPADDR ' , ' NETMASK ' , ' PREFIX ' , ' GATEWAY ' , ' HWADDR ' , ' DNS1' , ' DNS2' , ' BOOTPROTO ' , ' NM _ CONTROLLED ' , ' # Contrail ' ] NEW_LINE remove_items . append ( ' DEVICE ' ) NEW_LINE new_f_lines . append ( ' # Contrail ▁ % s \n ' % dev ) NEW_LINE new_f_lines . append ( ' DEVICE = % s \n ' % dev ) NEW_LINE for line in f_lines : NEW_LINE INDENT found = False NEW_LINE for text in remove_items : NEW_LINE INDENT if text in line : NEW_LINE INDENT found = True NEW_LINE DEDENT DEDENT if not found : NEW_LINE INDENT new_f_lines . append ( line ) NEW_LINE DEDENT DEDENT new_f_lines . append ( ' NM _ CONTROLLED = no \n ' ) NEW_LINE if bond : NEW_LINE INDENT new_f_lines . append ( ' SUBCHANNELS = 1,2,3 \n ' ) NEW_LINE DEDENT elif not vlan : NEW_LINE INDENT new_f_lines . append ( ' HWADDR = % s \n ' % mac ) NEW_LINE DEDENT fdw = open ( filename , ' w ' ) NEW_LINE fdw . writelines ( new_f_lines ) NEW_LINE fdw . close ( ) NEW_LINE DEDENT def migrate_routes ( self , device ) : NEW_LINE INDENT ''' STRNEWLINE ▁ add ▁ route ▁ entries ▁ in ▁ / proc / net / route STRNEWLINE ▁ ''' NEW_LINE temp_dir_name = self . _temp_dir_name NEW_LINE cfg_file = ' / etc / sysconfig / network - scripts / route - vhost0' NEW_LINE tmp_file = ' % s / route - vhost0' % temp_dir_name NEW_LINE with open ( tmp_file , ' w ' ) as route_cfg_file : NEW_LINE INDENT for route in open ( ' / proc / net / route ' , ' r ' ) . readlines ( ) : NEW_LINE INDENT if route . startswith ( device ) : NEW_LINE INDENT route_fields = route . split ( ) NEW_LINE destination = int ( route_fields [ 1 ] , 16 ) NEW_LINE gateway = int ( route_fields [ 2 ] , 16 ) NEW_LINE flags = int ( route_fields [ 3 ] , 16 ) NEW_LINE mask = int ( route_fields [ 7 ] , 16 ) NEW_LINE if flags & 0x2 : NEW_LINE INDENT if destination != 0 : NEW_LINE INDENT route_cfg_file . write ( socket . inet_ntoa ( struct . pack ( ' I ' , destination ) ) ) NEW_LINE route_cfg_file . write ( ' / ' + str ( bin ( mask ) . count ( '1' ) ) + ' ▁ ' ) NEW_LINE route_cfg_file . write ( ' via ▁ ' ) NEW_LINE route_cfg_file . write ( socket . inet_ntoa ( struct . pack ( ' I ' , gateway ) ) + ' ▁ ' ) NEW_LINE route_cfg_file . write ( ' dev ▁ vhost0' ) NEW_LINE # ▁ end ▁ if ▁ detination . . . ENDCOM # ▁ end ▁ if ▁ flags ▁ & . . . ENDCOM # ▁ end ▁ if ▁ route . startswith . . . ENDCOM # ▁ end ▁ for ▁ route . . . ENDCOM # ▁ end ▁ with ▁ open . . . ENDCOM DEDENT DEDENT DEDENT DEDENT DEDENT local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( tmp_file , cfg_file ) ) NEW_LINE # ▁ delete ▁ the ▁ route - dev ▁ file ENDCOM if os . path . isfile ( ' / etc / sysconfig / network - scripts / route - % s ' % device ) : NEW_LINE INDENT os . unlink ( ' / etc / sysconfig / network - scripts / route - % s ' % device ) NEW_LINE # ▁ end ▁ def ▁ migrate _ routes ENDCOM DEDENT DEDENT def get_cfgfile_for_dev ( self , iface , cfg_files ) : NEW_LINE INDENT if not cfg_files : NEW_LINE INDENT return None NEW_LINE DEDENT mapped_intf_cfgfile = None NEW_LINE for file in cfg_files : NEW_LINE INDENT with open ( file , ' r ' ) as fd : NEW_LINE INDENT contents = fd . read ( ) NEW_LINE regex = ' ( ? : ^ | \n ) \s * iface\s + % s\s + ' % iface NEW_LINE if re . search ( regex , contents ) : NEW_LINE INDENT mapped_intf_cfgfile = file NEW_LINE DEDENT DEDENT DEDENT return mapped_intf_cfgfile NEW_LINE DEDENT def get_sourced_files ( self ) : NEW_LINE INDENT ''' Get ▁ all ▁ sourced ▁ config ▁ files ''' NEW_LINE files = self . get_valid_files ( self . get_source_entries ( ) ) NEW_LINE files += self . get_source_directory_files ( ) NEW_LINE return list ( set ( files ) ) NEW_LINE DEDENT def get_source_directory_files ( self ) : NEW_LINE INDENT ''' Get ▁ source - directory ▁ entry ▁ and ▁ make ▁ list ▁ of ▁ valid ▁ files ''' NEW_LINE regex = ' ( ? : ^ | \n ) \s * source - directory\s + ( \S + ) ' NEW_LINE files = list ( ) NEW_LINE with open ( self . default_cfg_file , ' r ' ) as fd : NEW_LINE INDENT entries = re . findall ( regex , fd . read ( ) ) NEW_LINE DEDENT dirs = [ d for d in self . get_valid_files ( entries ) if os . path . isdir ( d ) ] NEW_LINE for dir in dirs : NEW_LINE INDENT files . extend ( [ os . path . join ( dir , f ) for f in os . listdir ( dir ) if os . path . isfile ( os . path . join ( dir , f ) ) and re . match ( ' ^ [ a - zA - Z0-9 _ - ] + $ ' , f ) ] ) NEW_LINE DEDENT return files NEW_LINE DEDENT def get_source_entries ( self ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Get ▁ entries ▁ matching ▁ source ▁ keyword ▁ from STRNEWLINE ▁ / etc / network / interfaces ▁ file . STRNEWLINE ▁ ''' NEW_LINE regex = ' ( ? : ^ | \n ) \s * source\s + ( \S + ) ' NEW_LINE with open ( self . default_cfg_file , ' r ' ) as fd : NEW_LINE INDENT return re . findall ( regex , fd . read ( ) ) NEW_LINE DEDENT DEDENT def get_valid_files ( self , entries ) : NEW_LINE INDENT ''' Provided ▁ a ▁ list ▁ of ▁ glob ' d ▁ strings , ▁ return ▁ matching ▁ file ▁ names ''' NEW_LINE files = list ( ) NEW_LINE prepend = os . path . join ( os . path . sep , ' etc ' , ' network ' ) + os . path . sep NEW_LINE for entry in entries : NEW_LINE INDENT entry = entry . lstrip ( ' . / ' ) if entry . startswith ( ' . / ' ) else entry NEW_LINE if entry . startswith ( os . path . sep ) : NEW_LINE INDENT entry = entry NEW_LINE DEDENT else : NEW_LINE INDENT entry = prepend + entry NEW_LINE DEDENT files . extend ( glob . glob ( entry ) ) NEW_LINE DEDENT return files NEW_LINE DEDENT def _rewrite_net_interfaces_file ( self , dev , mac , vhost_ip , netmask , gateway_ip , esxi_vm , vmpg_mtu , datapg_mtu ) : NEW_LINE INDENT self . default_cfg_file = ' / etc / network / interfaces ' NEW_LINE cfg_files = self . get_sourced_files ( ) NEW_LINE cfg_files . append ( self . default_cfg_file ) NEW_LINE intf_cfgfile = self . get_cfgfile_for_dev ( ' vhost0' , cfg_files ) NEW_LINE if intf_cfgfile : NEW_LINE INDENT log . info ( " Interface ▁ vhost0 ▁ is ▁ already ▁ present ▁ in " + " / etc / network / interfaces " ) NEW_LINE log . info ( " Skipping ▁ rewrite ▁ of ▁ this ▁ file " ) NEW_LINE return NEW_LINE # ▁ endif ENDCOM DEDENT vlan = False NEW_LINE if os . path . isfile ( ' / proc / net / vlan / % s ' % dev ) : NEW_LINE INDENT vlan_info = open ( ' / proc / net / vlan / config ' ) . readlines ( ) NEW_LINE match = re . search ( ' ^ % s . * \ | \s + ( \S + ) $ ' % dev , " \n " . join ( vlan_info ) , flags = re . M | re . I ) NEW_LINE if not match : NEW_LINE INDENT raise RuntimeError ( ' Configured ▁ vlan ▁ % s ▁ is ▁ not ▁ found ▁ in ' , ' / proc / net / vlan / config ' % dev ) NEW_LINE DEDENT phydev = match . group ( 1 ) NEW_LINE vlan = True NEW_LINE # ▁ Replace ▁ strings ▁ matching ▁ dev ▁ to ▁ vhost0 ▁ in ▁ ifup ▁ and ▁ ifdown ▁ parts ▁ file ENDCOM # ▁ Any ▁ changes ▁ to ▁ the ▁ file / logic ▁ with ▁ static ▁ routes ▁ has ▁ to ▁ be ENDCOM # ▁ reflected ▁ in ▁ setup - vnc - static - routes . py ▁ too ENDCOM DEDENT ifup_parts_file = os . path . join ( os . path . sep , ' etc ' , ' network ' , ' if - up . d ' , ' routes ' ) NEW_LINE ifdown_parts_file = os . path . join ( os . path . sep , ' etc ' , ' network ' , ' if - down . d ' , ' routes ' ) NEW_LINE if ( os . path . isfile ( ifup_parts_file ) and os . path . isfile ( ifdown_parts_file ) ) : NEW_LINE INDENT local ( " sudo ▁ sed ▁ - i ▁ ' s / % s / vhost0 / g ' ▁ % s " % ( dev , ifup_parts_file ) , warn_only = True ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' s / % s / vhost0 / g ' ▁ % s " % ( dev , ifdown_parts_file ) , warn_only = True ) NEW_LINE DEDENT dev_cfgfile = self . get_cfgfile_for_dev ( dev , cfg_files ) NEW_LINE temp_intf_file = ' % s / interfaces ' % self . _temp_dir_name NEW_LINE local ( " sudo ▁ cp ▁ % s ▁ % s " % ( dev_cfgfile , temp_intf_file ) ) NEW_LINE with open ( dev_cfgfile , ' r ' ) as fd : NEW_LINE INDENT cfg_file = fd . read ( ) NEW_LINE DEDENT if not self . _args . non_mgmt_ip : NEW_LINE # ▁ remove ▁ entry ▁ from ▁ auto ▁ < dev > ▁ to ▁ auto ▁ excluding ▁ these ▁ pattern ENDCOM # ▁ then ▁ delete ▁ specifically ▁ auto ▁ < dev > ENDCOM INDENT local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / , / auto / { / auto / ! d } ' ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / d ' ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE # ▁ add ▁ manual ▁ entry ▁ for ▁ dev ENDCOM local ( " sudo ▁ echo ▁ ' auto ▁ % s ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ % s ▁ inet ▁ manual ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE if vlan : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - up ▁ ifconfig ▁ % s ▁ up ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE DEDENT else : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE DEDENT if esxi_vm : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( dev , datapg_mtu , temp_intf_file ) ) NEW_LINE cmd = " sudo ▁ ethtool ▁ - i ▁ % s ▁ | ▁ grep ▁ driver ▁ | ▁ cut ▁ - f ▁ 2 ▁ - d ▁ ' ▁ ' " % dev NEW_LINE device_driver = local ( cmd , capture = True ) NEW_LINE if ( device_driver == " vmxnet3" ) : NEW_LINE INDENT cmd = " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ " NEW_LINE rx_cmd = ( cmd + " % s ▁ rx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE tx_cmd = ( cmd + " % s ▁ tx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( rx_cmd ) NEW_LINE local ( tx_cmd ) NEW_LINE DEDENT DEDENT if vlan : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ vlan - raw - device ▁ % s ' ▁ > > ▁ % s " % ( phydev , temp_intf_file ) ) NEW_LINE DEDENT if ' bond ' in dev . lower ( ) : NEW_LINE INDENT iters = re . finditer ( ' ^ \s * auto\s ' , cfg_file , re . M ) NEW_LINE indices = [ pat_match . start ( ) for pat_match in iters ] NEW_LINE matches = map ( cfg_file . __getslice__ , indices , indices [ 1 : ] + [ len ( cfg_file ) ] ) NEW_LINE for each in matches : NEW_LINE INDENT each = each . strip ( ) NEW_LINE if re . match ( ' ^ auto\s + % s ' % dev , each ) : NEW_LINE INDENT string = ' ' NEW_LINE for lines in each . splitlines ( ) : NEW_LINE INDENT if ' bond - ' in lines : NEW_LINE INDENT string += lines + os . linesep NEW_LINE DEDENT DEDENT local ( " sudo ▁ echo ▁ ' % s ' ▁ > > ▁ % s " % ( string , temp_intf_file ) ) NEW_LINE DEDENT else : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE DEDENT else : NEW_LINE # ▁ remove ▁ ip ▁ address ▁ and ▁ gateway ENDCOM INDENT local ( " sudo ▁ sed ▁ - i ▁ ' / iface ▁ % s ▁ inet ▁ static / , ▁ + 2d ' ▁ % s " % ( dev , temp_intf_file ) , warn_only = True ) NEW_LINE if esxi_vm : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( dev , datapg_mtu , temp_intf_file ) , warn_only = True ) NEW_LINE cmd = " sudo ▁ ethtool ▁ - i ▁ % s ▁ | ▁ " % dev NEW_LINE cmd += " sudo ▁ grep ▁ driver ▁ | ▁ sudo ▁ cut ▁ - f ▁ 2 ▁ - d ▁ ' ▁ ' " NEW_LINE device_driver = local ( cmd , capture = True , warn_only = True ) NEW_LINE if ( device_driver == " vmxnet3" ) : NEW_LINE INDENT cmd = " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ " NEW_LINE rx_cmd = cmd + " % s ▁ rx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) NEW_LINE tx_cmd = cmd + " % s ▁ tx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( rx_cmd , warn_only = True ) NEW_LINE local ( tx_cmd , warn_only = True ) NEW_LINE DEDENT DEDENT if vlan : NEW_LINE INDENT cmd = " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / ▁ a\iface ▁ % s ▁ inet ▁ manual\ \n ▁ ▁ ▁ ▁ " % ( dev , dev ) NEW_LINE cmd += " post - up ▁ ifconfig ▁ % s ▁ up\ \n ▁ ▁ ▁ ▁ " % dev NEW_LINE cmd += " pre - down ▁ ifconfig ▁ % s ▁ down\ ' ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( cmd ) NEW_LINE DEDENT else : NEW_LINE INDENT cmd = " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / ▁ a\iface ▁ % s ▁ inet ▁ manual\ \n ▁ ▁ ▁ ▁ " % ( dev , dev ) NEW_LINE cmd += " pre - up ▁ ifconfig ▁ % s ▁ up\ \n ▁ ▁ ▁ ▁ " % dev NEW_LINE cmd += " post - down ▁ ifconfig ▁ % s ▁ down\ ' ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( cmd ) NEW_LINE DEDENT DEDENT if esxi_vm and vmpg_mtu : NEW_LINE INDENT intf = self . get_secondary_device ( self . dev ) NEW_LINE mac_addr = self . get_if_mac ( intf ) NEW_LINE udev_net_file = ' / etc / udev / rules . d / 70 - persistent - net . rules ' NEW_LINE temp_udev_net_file = ' % s / 70 - persistent - net . rules ' % ( self . _temp_dir_name ) NEW_LINE local ( " sudo ▁ touch ▁ % s " % temp_udev_net_file ) NEW_LINE local ( " sudo ▁ cp ▁ % s ▁ % s " % ( udev_net_file , temp_udev_net_file ) ) NEW_LINE cmd = " sudo ▁ echo ▁ ' SUBSYSTEM = = \ " net\ " , ▁ ACTION = = \ " add\ " , " NEW_LINE cmd += " ▁ DRIVERS = = \ " ? * \ " , " NEW_LINE cmd += " ▁ ATTR { address } = = \ " % s\ " , ▁ ATTR { dev _ id } = = \ " 0x0\ " , ▁ " % mac_addr NEW_LINE cmd += " ATTR { type } = = \ " 1\ " , ▁ KERNEL = = \ " eth * \ " , ▁ NAME = \ " % s\ " ' ▁ > > ▁ % s " % ( intf , temp_udev_net_file ) NEW_LINE local ( cmd ) NEW_LINE local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( temp_udev_net_file , udev_net_file ) ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / , / down / d ' ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' \n auto ▁ % s ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ % s ▁ inet ▁ manual ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( intf , vmpg_mtu , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ % s ▁ lro ▁ off ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE # ▁ populte ▁ vhost0 ▁ as ▁ static ENDCOM DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' auto ▁ vhost0 ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ vhost0 ▁ inet ▁ static ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ % s / if - vhost0 ' ▁ > > ▁ % s " % ( self . contrail_bin_dir , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ netmask ▁ % s ' ▁ > > ▁ % s " % ( netmask , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ network _ name ▁ application ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE if esxi_vm and datapg_mtu : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( datapg_mtu , temp_intf_file ) ) NEW_LINE DEDENT if vhost_ip : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ address ▁ % s ' ▁ > > ▁ % s " % ( vhost_ip , temp_intf_file ) ) NEW_LINE DEDENT if ( not self . _args . non_mgmt_ip ) and gateway_ip : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ gateway ▁ % s ' ▁ > > ▁ % s " % ( gateway_ip , temp_intf_file ) ) NEW_LINE DEDENT domain = self . get_domain_search_list ( ) NEW_LINE if domain : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ dns - search ▁ % s ' ▁ > > ▁ % s " % ( domain , temp_intf_file ) ) NEW_LINE DEDENT dns_list = self . get_dns_servers ( dev ) NEW_LINE if dns_list : NEW_LINE INDENT local ( " sudo ▁ echo ▁ - n ▁ ' ▁ ▁ ▁ ▁ dns - nameservers ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE for dns in dns_list : NEW_LINE INDENT local ( " sudo ▁ echo ▁ - n ▁ ' ▁ % s ' ▁ > > ▁ % s " % ( dns , temp_intf_file ) ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - up ▁ ip ▁ link ▁ set ▁ vhost0 ▁ address ▁ % s ' ▁ > > ▁ % s " % ( mac , temp_intf_file ) ) NEW_LINE # ▁ move ▁ it ▁ to ▁ right ▁ place ENDCOM local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( temp_intf_file , dev_cfgfile ) ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="fabian4/trove/tree/master/trove/guestagent/datastore/experimental/redis/manager.py"> # ▁ Copyright ▁ ( c ) ▁ 2013 ▁ Rackspace ENDCOM # ▁ All ▁ Rights ▁ Reserved . ENDCOM # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License , ▁ Version ▁ 2.0 ▁ ( the ▁ " License " ) ; ▁ you ▁ may ENDCOM # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License . ▁ You ▁ may ▁ obtain ENDCOM # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at ENDCOM # ▁ http : / / www . apache . org / licenses / LICENSE - 2.0 ENDCOM # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing , ▁ software ENDCOM # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁ " AS ▁ IS " ▁ BASIS , ▁ WITHOUT ENDCOM # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND , ▁ either ▁ express ▁ or ▁ implied . ▁ See ▁ the ENDCOM # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations ENDCOM # ▁ under ▁ the ▁ License . ENDCOM from oslo_log import log as logging NEW_LINE from oslo_service import periodic_task NEW_LINE from trove . common import cfg NEW_LINE from trove . common import exception NEW_LINE from trove . common . i18n import _ NEW_LINE from trove . common import instance as rd_instance NEW_LINE from trove . common import utils NEW_LINE from trove . guestagent import backup NEW_LINE from trove . guestagent . common import operating_system NEW_LINE from trove . guestagent . datastore . experimental . redis import service NEW_LINE from trove . guestagent import dbaas NEW_LINE from trove . guestagent . strategies . replication import get_replication_strategy NEW_LINE from trove . guestagent import volume NEW_LINE LOG = logging . getLogger ( __name__ ) NEW_LINE CONF = cfg . CONF NEW_LINE MANAGER = CONF . datastore_manager or ' redis ' NEW_LINE REPLICATION_STRATEGY = CONF . get ( MANAGER ) . replication_strategy NEW_LINE REPLICATION_NAMESPACE = CONF . get ( MANAGER ) . replication_namespace NEW_LINE REPLICATION_STRATEGY_CLASS = get_replication_strategy ( REPLICATION_STRATEGY , REPLICATION_NAMESPACE ) NEW_LINE class Manager ( periodic_task . PeriodicTasks ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ is ▁ the ▁ Redis ▁ manager ▁ class . ▁ It ▁ is ▁ dynamically ▁ loaded STRNEWLINE ▁ based ▁ off ▁ of ▁ the ▁ service _ type ▁ of ▁ the ▁ trove ▁ instance STRNEWLINE ▁ """ NEW_LINE def __init__ ( self ) : NEW_LINE INDENT super ( Manager , self ) . __init__ ( CONF ) NEW_LINE self . _app = service . RedisApp ( ) NEW_LINE DEDENT @ periodic_task . periodic_task NEW_LINE def update_status ( self , context ) : NEW_LINE INDENT """ STRNEWLINE ▁ Updates ▁ the ▁ redis ▁ trove ▁ instance . ▁ It ▁ is ▁ decorated ▁ with STRNEWLINE ▁ perodic ▁ task ▁ so ▁ it ▁ is ▁ automatically ▁ called ▁ every ▁ 3 ▁ ticks . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Update ▁ status ▁ called . " ) NEW_LINE self . _app . status . update ( ) NEW_LINE DEDENT def rpc_ping ( self , context ) : NEW_LINE INDENT LOG . debug ( " Responding ▁ to ▁ RPC ▁ ping . " ) NEW_LINE return True NEW_LINE DEDENT def change_passwords ( self , context , users ) : NEW_LINE INDENT """ STRNEWLINE ▁ Changes ▁ the ▁ redis ▁ instance ▁ password , STRNEWLINE ▁ it ▁ is ▁ currently ▁ not ▁ not ▁ implemented . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Change ▁ passwords ▁ called . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' change _ passwords ' , datastore = MANAGER ) NEW_LINE DEDENT def reset_configuration ( self , context , configuration ) : NEW_LINE INDENT """ STRNEWLINE ▁ Resets ▁ to ▁ the ▁ default ▁ configuration , STRNEWLINE ▁ currently ▁ this ▁ does ▁ nothing . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Reset ▁ configuration ▁ called . " ) NEW_LINE self . _app . reset_configuration ( configuration ) NEW_LINE DEDENT def _perform_restore ( self , backup_info , context , restore_location , app ) : NEW_LINE INDENT """ Perform ▁ a ▁ restore ▁ on ▁ this ▁ instance . """ NEW_LINE LOG . info ( _ ( " Restoring ▁ database ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE try : NEW_LINE INDENT backup . restore ( context , backup_info , restore_location ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ performing ▁ restore ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT LOG . info ( _ ( " Restored ▁ database ▁ successfully . " ) ) NEW_LINE DEDENT def prepare ( self , context , packages , databases , memory_mb , users , device_path = None , mount_point = None , backup_info = None , config_contents = None , root_password = None , overrides = None , cluster_config = None , snapshot = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ This ▁ is ▁ called ▁ when ▁ the ▁ trove ▁ instance ▁ first ▁ comes ▁ online . STRNEWLINE ▁ It ▁ is ▁ the ▁ first ▁ rpc ▁ message ▁ passed ▁ from ▁ the ▁ task ▁ manager . STRNEWLINE ▁ prepare ▁ handles ▁ all ▁ the ▁ base ▁ configuration ▁ of ▁ the ▁ redis ▁ instance . STRNEWLINE ▁ """ NEW_LINE try : NEW_LINE INDENT self . _app . status . begin_install ( ) NEW_LINE if device_path : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE # ▁ unmount ▁ if ▁ device ▁ is ▁ already ▁ mounted ENDCOM device . unmount_device ( device_path ) NEW_LINE device . format ( ) NEW_LINE device . mount ( mount_point ) NEW_LINE operating_system . chown ( mount_point , ' redis ' , ' redis ' , as_root = True ) NEW_LINE LOG . debug ( ' Mounted ▁ the ▁ volume . ' ) NEW_LINE DEDENT self . _app . install_if_needed ( packages ) NEW_LINE LOG . info ( _ ( ' Writing ▁ redis ▁ configuration . ' ) ) NEW_LINE if cluster_config : NEW_LINE INDENT config_contents = ( config_contents + " \n " + " cluster - enabled ▁ yes \n " + " cluster - config - file ▁ cluster . conf \n " ) NEW_LINE DEDENT self . _app . configuration_manager . save_configuration ( config_contents ) NEW_LINE self . _app . apply_initial_guestagent_configuration ( ) NEW_LINE if backup_info : NEW_LINE INDENT persistence_dir = self . _app . get_working_dir ( ) NEW_LINE self . _perform_restore ( backup_info , context , persistence_dir , self . _app ) NEW_LINE DEDENT if snapshot : NEW_LINE INDENT self . attach_replica ( context , snapshot , snapshot [ ' config ' ] ) NEW_LINE DEDENT self . _app . restart ( ) NEW_LINE if cluster_config : NEW_LINE INDENT self . _app . status . set_status ( rd_instance . ServiceStatuses . BUILD_PENDING ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT LOG . info ( _ ( ' Redis ▁ instance ▁ has ▁ been ▁ setup ▁ and ▁ configured . ' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ setting ▁ up ▁ Redis ▁ instance . " ) ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def restart ( self , context ) : NEW_LINE INDENT """ STRNEWLINE ▁ Restart ▁ this ▁ redis ▁ instance . STRNEWLINE ▁ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ guest ▁ agent STRNEWLINE ▁ gets ▁ a ▁ restart ▁ message ▁ from ▁ the ▁ taskmanager . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Restart ▁ called . " ) NEW_LINE self . _app . restart ( ) NEW_LINE DEDENT def start_db_with_conf_changes ( self , context , config_contents ) : NEW_LINE INDENT """ STRNEWLINE ▁ Start ▁ this ▁ redis ▁ instance ▁ with ▁ new ▁ conf ▁ changes . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Start ▁ DB ▁ with ▁ conf ▁ changes ▁ called . " ) NEW_LINE self . _app . start_db_with_conf_changes ( config_contents ) NEW_LINE DEDENT def stop_db ( self , context , do_not_start_on_reboot = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Stop ▁ this ▁ redis ▁ instance . STRNEWLINE ▁ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ guest ▁ agent STRNEWLINE ▁ gets ▁ a ▁ stop ▁ message ▁ from ▁ the ▁ taskmanager . STRNEWLINE ▁ """ NEW_LINE LOG . debug ( " Stop ▁ DB ▁ called . " ) NEW_LINE self . _app . stop_db ( do_not_start_on_reboot = do_not_start_on_reboot ) NEW_LINE DEDENT def get_filesystem_stats ( self , context , fs_path ) : NEW_LINE INDENT """ Gets ▁ the ▁ filesystem ▁ stats ▁ for ▁ the ▁ path ▁ given . """ NEW_LINE LOG . debug ( " Get ▁ Filesystem ▁ Stats . " ) NEW_LINE mount_point = CONF . get ( ' mysql ' if not MANAGER else MANAGER ) . mount_point NEW_LINE return dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE DEDENT def create_backup ( self , context , backup_info ) : NEW_LINE INDENT """ Create ▁ a ▁ backup ▁ of ▁ the ▁ database . """ NEW_LINE LOG . debug ( " Creating ▁ backup . " ) NEW_LINE backup . backup ( context , backup_info ) NEW_LINE DEDENT def mount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . mount ( mount_point , write_to_fstab = False ) NEW_LINE LOG . debug ( " Mounted ▁ the ▁ device ▁ % s ▁ at ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def unmount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . unmount ( mount_point ) NEW_LINE LOG . debug ( " Unmounted ▁ the ▁ device ▁ % s ▁ from ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def resize_fs ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . resize_fs ( mount_point ) NEW_LINE LOG . debug ( " Resized ▁ the ▁ filesystem ▁ at ▁ % s . " % mount_point ) NEW_LINE DEDENT def update_overrides ( self , context , overrides , remove = False ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ overrides . " ) NEW_LINE if remove : NEW_LINE INDENT self . _app . remove_overrides ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . update_overrides ( context , overrides , remove ) NEW_LINE DEDENT DEDENT def apply_overrides ( self , context , overrides ) : NEW_LINE INDENT LOG . debug ( " Applying ▁ overrides . " ) NEW_LINE self . _app . apply_overrides ( self . _app . admin , overrides ) NEW_LINE DEDENT def update_attributes ( self , context , username , hostname , user_attrs ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ attributes . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' update _ attributes ' , datastore = MANAGER ) NEW_LINE DEDENT def create_database ( self , context , databases ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def create_user ( self , context , users ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_database ( self , context , database ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_user ( self , context , user ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def get_user ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' get _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def grant_access ( self , context , username , hostname , databases ) : NEW_LINE INDENT LOG . debug ( " Granting ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' grant _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def revoke_access ( self , context , username , hostname , database ) : NEW_LINE INDENT LOG . debug ( " Revoking ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' revoke _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_access ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_databases ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ databases . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ databases ' , datastore = MANAGER ) NEW_LINE DEDENT def list_users ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ users . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ users ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root ( self , context ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root_with_password ( self , context , root_password = None ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root ▁ with ▁ password . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root _ with _ password ' , datastore = MANAGER ) NEW_LINE DEDENT def is_root_enabled ( self , context ) : NEW_LINE INDENT LOG . debug ( " Checking ▁ if ▁ root ▁ is ▁ enabled . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' is _ root _ enabled ' , datastore = MANAGER ) NEW_LINE DEDENT def backup_required_for_replication ( self , context ) : NEW_LINE INDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE return replication . backup_required_for_replication ( ) NEW_LINE DEDENT def get_replication_snapshot ( self , context , snapshot_info , replica_source_config = None ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replication ▁ snapshot . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE snapshot_id , log_position = ( replication . snapshot_for_replication ( context , self . _app , None , snapshot_info ) ) NEW_LINE mount_point = CONF . get ( MANAGER ) . mount_point NEW_LINE volume_stats = dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE replication_snapshot = { ' dataset ' : { ' datastore _ manager ' : MANAGER , ' dataset _ size ' : volume_stats . get ( ' used ' , 0.0 ) , ' volume _ size ' : volume_stats . get ( ' total ' , 0.0 ) , ' snapshot _ id ' : snapshot_id } , ' replication _ strategy ' : REPLICATION_STRATEGY , ' master ' : replication . get_master_ref ( self . _app , snapshot_info ) , ' log _ position ' : log_position } NEW_LINE return replication_snapshot NEW_LINE DEDENT def enable_as_master ( self , context , replica_source_config ) : NEW_LINE INDENT LOG . debug ( " Calling ▁ enable _ as _ master . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE DEDENT def detach_replica ( self , context , for_failover = False ) : NEW_LINE INDENT LOG . debug ( " Detaching ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . detach_slave ( self . _app , for_failover ) NEW_LINE return replica_info NEW_LINE DEDENT def get_replica_context ( self , context ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replica ▁ context . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . get_replica_context ( self . _app ) NEW_LINE return replica_info NEW_LINE DEDENT def _validate_slave_for_replication ( self , context , replica_info ) : NEW_LINE INDENT if ( replica_info [ ' replication _ strategy ' ] != REPLICATION_STRATEGY ) : NEW_LINE INDENT raise exception . IncompatibleReplicationStrategy ( replica_info . update ( { ' guest _ strategy ' : REPLICATION_STRATEGY } ) ) NEW_LINE DEDENT DEDENT def attach_replica ( self , context , replica_info , slave_config ) : NEW_LINE INDENT LOG . debug ( " Attaching ▁ replica . " ) NEW_LINE try : NEW_LINE INDENT if ' replication _ strategy ' in replica_info : NEW_LINE INDENT self . _validate_slave_for_replication ( context , replica_info ) NEW_LINE DEDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_slave ( self . _app , replica_info , slave_config ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( " Error ▁ enabling ▁ replication . " ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def make_read_only ( self , context , read_only ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ make _ read _ only ( % s ) " % read_only ) NEW_LINE self . _app . make_read_only ( read_only ) NEW_LINE DEDENT def _get_repl_info ( self ) : NEW_LINE INDENT return self . _app . admin . get_info ( ' replication ' ) NEW_LINE DEDENT def _get_master_host ( self ) : NEW_LINE INDENT slave_info = self . _get_repl_info ( ) NEW_LINE return slave_info and slave_info [ ' master _ host ' ] or None NEW_LINE DEDENT def _get_repl_offset ( self ) : NEW_LINE INDENT repl_info = self . _get_repl_info ( ) NEW_LINE LOG . debug ( " Got ▁ repl ▁ info : ▁ % s " % repl_info ) NEW_LINE offset_key = ' % s _ repl _ offset ' % repl_info [ ' role ' ] NEW_LINE offset = repl_info [ offset_key ] NEW_LINE LOG . debug ( " Found ▁ offset ▁ % s ▁ for ▁ key ▁ % s . " % ( offset , offset_key ) ) NEW_LINE return int ( offset ) NEW_LINE DEDENT def get_last_txn ( self , context ) : NEW_LINE INDENT master_host = self . _get_master_host ( ) NEW_LINE repl_offset = self . _get_repl_offset ( ) NEW_LINE return master_host , repl_offset NEW_LINE DEDENT def get_latest_txn_id ( self , context ) : NEW_LINE INDENT LOG . info ( _ ( " Retrieving ▁ latest ▁ repl ▁ offset . " ) ) NEW_LINE return self . _get_repl_offset ( ) NEW_LINE DEDENT def wait_for_txn ( self , context , txn ) : NEW_LINE INDENT LOG . info ( _ ( " Waiting ▁ on ▁ repl ▁ offset ▁ ' % s ' . " ) % txn ) NEW_LINE def _wait_for_txn ( ) : NEW_LINE INDENT current_offset = self . _get_repl_offset ( ) NEW_LINE LOG . debug ( " Current ▁ offset : ▁ % s . " % current_offset ) NEW_LINE return current_offset >= txn NEW_LINE DEDENT try : NEW_LINE INDENT utils . poll_until ( _wait_for_txn , time_out = 120 ) NEW_LINE DEDENT except exception . PollTimeOut : NEW_LINE INDENT raise RuntimeError ( _ ( " Timeout ▁ occurred ▁ waiting ▁ for ▁ Redis ▁ repl ▁ " " offset ▁ to ▁ change ▁ to ▁ ' % s ' . " ) % txn ) NEW_LINE DEDENT DEDENT def cleanup_source_on_replica_detach ( self , context , replica_info ) : NEW_LINE INDENT LOG . debug ( " Cleaning ▁ up ▁ the ▁ source ▁ on ▁ the ▁ detach ▁ of ▁ a ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . cleanup_source_on_replica_detach ( self . _app , replica_info ) NEW_LINE DEDENT def demote_replication_master ( self , context ) : NEW_LINE INDENT LOG . debug ( " Demoting ▁ replica ▁ source . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . demote_master ( self . _app ) NEW_LINE DEDENT def cluster_meet ( self , context , ip , port ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ meet ▁ to ▁ join ▁ node ▁ to ▁ cluster . " ) NEW_LINE self . _app . cluster_meet ( ip , port ) NEW_LINE DEDENT def get_node_ip ( self , context ) : NEW_LINE INDENT LOG . debug ( " Retrieving ▁ cluster ▁ node ▁ ip ▁ address . " ) NEW_LINE return self . _app . get_node_ip ( ) NEW_LINE DEDENT def get_node_id_for_removal ( self , context ) : NEW_LINE INDENT LOG . debug ( " Validating ▁ removal ▁ of ▁ node ▁ from ▁ cluster . " ) NEW_LINE return self . _app . get_node_id_for_removal ( ) NEW_LINE DEDENT def remove_nodes ( self , context , node_ids ) : NEW_LINE INDENT LOG . debug ( " Removing ▁ nodes ▁ from ▁ cluster . " ) NEW_LINE self . _app . remove_nodes ( node_ids ) NEW_LINE DEDENT def cluster_addslots ( self , context , first_slot , last_slot ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ addslots ▁ to ▁ assign ▁ hash ▁ slots ▁ % s - % s . " , first_slot , last_slot ) NEW_LINE self . _app . cluster_addslots ( first_slot , last_slot ) NEW_LINE DEDENT def cluster_complete ( self , context ) : NEW_LINE INDENT LOG . debug ( " Cluster ▁ creation ▁ complete , ▁ starting ▁ status ▁ checks . " ) NEW_LINE self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="PaulWay/insights-core/tree/master/insights/parsers/tests/test_foreman_log.py"> from insights . tests import context_wrap NEW_LINE from insights . parsers . foreman_log import SatelliteLog , ProductionLog NEW_LINE from insights . parsers . foreman_log import CandlepinLog , ProxyLog NEW_LINE PRODUCTION_LOG = """ STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 1783ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 172.9ms ) STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : V2 : : RepositoriesController # sync _ complete ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " call _ report " = > " [ FILTERED ] " , ▁ " event _ type " = > " repo . sync . finish " , ▁ " payload " = > { " importer _ id " = > " yum _ importer " , ▁ " exception " = > nil , ▁ " repo _ id " = > " 1 - Gulfstream _ Aerospace _ Corp _ - Red _ Hat _ Enterprise _ Linux _ Server - Red _ Hat _ Satellite _ Tools _ 6_1 _ for _ RHEL _ 6 _ Server _ RPMs _ i386 " , ▁ " traceback " = > nil , ▁ " started " = > " 2015-11-13T08:30:00Z " , ▁ " _ ns " = > " repo _ sync _ results " , ▁ " completed " = > " 2015-11-13T08:30:06Z " , ▁ " importer _ type _ id " = > " yum _ importer " , ▁ " error _ message " = > nil , ▁ " summary " = > { " content " = > { " state " = > " FINISHED " } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " state " = > " FINISHED " } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " added _ count " = > 0 , ▁ " result " = > " success " , ▁ " updated _ count " = > 3 , ▁ " details " = > { " content " = > { " size _ total " = > 0 , ▁ " items _ left " = > 0 , ▁ " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " size _ left " = > 0 , ▁ " details " = > { " rpm _ total " = > 0 , ▁ " rpm _ done " = > 0 , ▁ " drpm _ total " = > 0 , ▁ " drpm _ done " = > 0 } , ▁ " error _ details " = > [ ] } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " error _ details " = > [ ] , ▁ " items _ left " = > 0 } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " id " = > " 56459f8ef301a213bbfd87bb " , ▁ " removed _ count " = > 0 } , ▁ " token " = > " oQumn3XsKrdRkijuvpCNhKF2PDWZt6az " , ▁ " api _ version " = > " v2 " , ▁ " repository " = > { } } STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ Red ▁ Hat ▁ Satellite ▁ Tools ▁ 6.1 ▁ for ▁ RHEL ▁ 6 ▁ Server ▁ RPMs ▁ i386 , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:30:09 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 1995ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 81.5ms ) STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : V2 : : RepositoriesController # sync _ complete ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " call _ report " = > " [ FILTERED ] " , ▁ " event _ type " = > " repo . sync . finish " , ▁ " payload " = > { " importer _ id " = > " yum _ importer " , ▁ " exception " = > nil , ▁ " repo _ id " = > " 1 - Gulfstream _ Aerospace _ Corp _ - Red _ Hat _ Enterprise _ Linux _ Server - Red _ Hat _ Satellite _ Tools _ 6_1 _ for _ RHEL _ 5 _ Server _ RPMs _ i386 " , ▁ " traceback " = > nil , ▁ " started " = > " 2015-11-13T08:30:05Z " , ▁ " _ ns " = > " repo _ sync _ results " , ▁ " completed " = > " 2015-11-13T08:30:10Z " , ▁ " importer _ type _ id " = > " yum _ importer " , ▁ " error _ message " = > nil , ▁ " summary " = > { " content " = > { " state " = > " FINISHED " } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " state " = > " FINISHED " } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " added _ count " = > 0 , ▁ " result " = > " success " , ▁ " updated _ count " = > 3 , ▁ " details " = > { " content " = > { " size _ total " = > 0 , ▁ " items _ left " = > 0 , ▁ " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " size _ left " = > 0 , ▁ " details " = > { " rpm _ total " = > 0 , ▁ " rpm _ done " = > 0 , ▁ " drpm _ total " = > 0 , ▁ " drpm _ done " = > 0 } , ▁ " error _ details " = > [ ] } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " error _ details " = > [ ] , ▁ " items _ left " = > 0 } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " id " = > " 56459f92f301a2137cd6b802 " , ▁ " removed _ count " = > 0 } , ▁ " token " = > " oQumn3XsKrdRkijuvpCNhKF2PDWZt6az " , ▁ " api _ version " = > " v2 " , ▁ " repository " = > { } } STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ Red ▁ Hat ▁ Satellite ▁ Tools ▁ 6.1 ▁ for ▁ RHEL ▁ 5 ▁ Server ▁ RPMs ▁ i386 , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 818ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 77.2ms ) STRNEWLINE 2015-11-13 ▁ 03:30:17 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:26 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ RHN ▁ Tools ▁ for ▁ Red ▁ Hat ▁ Enterprise ▁ Linux ▁ 5 ▁ Server ▁ RPMs ▁ x86_64 ▁ 5Server , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:50:46 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 2583ms ▁ ( Views : ▁ 2.7ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 06:58:25 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 06:58:25 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 249ms ▁ ( Views : ▁ 3.1ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 84ms ▁ ( Views : ▁ 3.1ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " facts " = > " [ FILTERED ] " , ▁ " name " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " certname " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " apiv " = > " v2 " , ▁ : host = > { " name " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " certname " = > " infrhnpl002 . gac . gulfaero . com " } } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Import ▁ facts ▁ for ▁ ' infrhnpl002 . gac . gulfaero . com ' ▁ completed . ▁ Added : ▁ 0 , ▁ Updated : ▁ 6 , ▁ Deleted ▁ 0 ▁ facts STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 201 ▁ Created ▁ in ▁ 251ms ▁ ( Views : ▁ 179.3ms ▁ | ▁ ActiveRecord : ▁ 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Processing ▁ by ▁ HostsController # externalNodes ▁ as ▁ YML STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " name " = > " infrhnpl002 . gac . gulfaero . com " } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Rendered ▁ text ▁ template ▁ ( 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 48ms ▁ ( Views : ▁ 0.5ms ▁ | ▁ ActiveRecord : ▁ 6.6ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Processing ▁ by ▁ Api : : V2 : : ReportsController # create ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " report " = > " [ FILTERED ] " , ▁ " apiv " = > " v2 " } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Rendered ▁ text ▁ template ▁ ( 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ processing ▁ report ▁ for ▁ infrhnpl002 . gac . gulfaero . com STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Imported ▁ report ▁ for ▁ infrhnpl002 . gac . gulfaero . com ▁ in ▁ 0.02 ▁ seconds STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 201 ▁ Created ▁ in ▁ 28ms ▁ ( Views : ▁ 1.2ms ▁ | ▁ ActiveRecord : ▁ 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:30:17 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 110ms ▁ ( Views : ▁ 2.7ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 07:30:33 ▁ [ I ] ▁ 2015-11-13 ▁ 07:30:33 ▁ - 0500 : ▁ Expired ▁ 48 ▁ Reports STRNEWLINE 2015-11-13 ▁ 07:30:33 ▁ [ I ] ▁ Client ▁ disconnected . STRNEWLINE 2015-11-13 ▁ 09:41:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 93ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 80ms ▁ ( Views : ▁ 3.6ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 09:43:58 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 09:43:58 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 09:43:59 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 80ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE """ . strip ( ) NEW_LINE SATELLITE_OUT = """ STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ cert ] / require : ▁ requires ▁ Class [ Certs : : Pulp _ client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ cert ] / require : ▁ requires ▁ Exec [ foreman - rake - db : seed ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ key ] / require : ▁ requires ▁ Class [ Certs : : Pulp _ client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ key ] / require : ▁ requires ▁ Exec [ foreman - rake - db : seed ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / before : ▁ requires ▁ Class [ Foreman : : Database ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / before : ▁ requires ▁ Exec [ foreman - rake - db : migrate ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / notify : ▁ subscribes ▁ to ▁ Service [ foreman - tasks ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / notify : ▁ subscribes ▁ to ▁ Class [ Foreman : : Service ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / Foreman : : Config : : Passenger : : Fragment [ katello ] / require : ▁ requires ▁ Class [ Foreman : : Config : : Passenger ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / notify : ▁ subscribes ▁ to ▁ Class [ Certs : : Candlepin ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Cert [ kam1opapp999 . connex . bclc . com - qpid - broker ] / notify : ▁ subscribes ▁ to ▁ Pubkey [ / etc / pki / katello / certs / kam1opapp999 . connex . bclc . com - qpid - broker . crt ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Pubkey [ / etc / pki / katello / certs / kam1opapp999 . connex . bclc . com - qpid - broker . crt ] / notify : ▁ subscribes ▁ to ▁ Privkey [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Privkey [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb ] / notify : ▁ subscribes ▁ to ▁ Exec [ generate - nss - password ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ generate - nss - password ] / before : ▁ requires ▁ File [ / etc / pki / katello / nssdb / nss _ db _ password - file ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / nss _ db _ password - file ] / notify : ▁ subscribes ▁ to ▁ Exec [ create - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ ca ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ amqp - client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ ca ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / cert8 . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / key3 . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / secmod . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / cert8 . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / key3 . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / secmod . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ broker ] / notify : ▁ subscribes ▁ to ▁ Exec [ generate - pfx - for - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ generate - pfx - for - nss - db ] / notify : ▁ subscribes ▁ to ▁ Exec [ add - private - key - to - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ add - private - key - to - nss - db ] / notify : ▁ subscribes ▁ to ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Cert [ java - client ] / notify : ▁ subscribes ▁ to ▁ Pubkey [ / etc / pki / katello / certs / java - client . crt ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / pki / katello / keystore _ password - file ] / notify : ▁ subscribes ▁ to ▁ Exec [ candlepin - generate - ssl - keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ candlepin - generate - ssl - keystore ] / notify : ▁ subscribes ▁ to ▁ File [ / usr / share / tomcat / conf / keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / usr / share / tomcat / conf / keystore ] / notify : ▁ subscribes ▁ to ▁ Service [ tomcat ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Pubkey [ / etc / pki / katello / certs / java - client . crt ] / notify : ▁ subscribes ▁ to ▁ Privkey [ / etc / pki / katello / private / java - client . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Privkey [ / etc / pki / katello / private / java - client . key ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ amqp - client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / subscribe : ▁ subscribes ▁ to ▁ Exec [ create - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / notify : ▁ subscribes ▁ to ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / candlepin / certs / amqp ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / candlepin / certs / amqp ] / notify : ▁ subscribes ▁ to ▁ Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] / require : ▁ requires ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] / notify : ▁ subscribes ▁ to ▁ Exec [ import ▁ CA ▁ into ▁ Candlepin ▁ truststore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ import ▁ CA ▁ into ▁ Candlepin ▁ truststore ] / notify : ▁ subscribes ▁ to ▁ Exec [ import ▁ client ▁ certificate ▁ into ▁ Candlepin ▁ keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ import ▁ client ▁ certificate ▁ into ▁ Candlepin ▁ keystore ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / candlepin / certs / amqp / candlepin . jks ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / candlepin / certs / amqp / candlepin . jks ] / notify : ▁ subscribes ▁ to ▁ Service [ tomcat ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin / notify : ▁ subscribes ▁ to ▁ Class [ Qpid ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Install / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Config ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Config / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Database ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Database / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Service ] STRNEWLINE """ . strip ( ) NEW_LINE CANDLEPIN_LOG = """ STRNEWLINE 2016-09-09 ▁ 13:45:52,650 ▁ [ req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b STRNEWLINE 2016-09-09 ▁ 13:45:52,784 ▁ [ req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc , ▁ org = ING _ Luxembourg _ SA ] ▁ INFO ▁ ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 134 STRNEWLINE 2016-09-09 ▁ 13:45:52,947 ▁ [ req = 909ca4c5 - f24e - 4212-8f23 - cc754d06ac57 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b / content _ overrides STRNEWLINE 2016-09-09 ▁ 13:45:52,976 ▁ [ req = 909ca4c5 - f24e - 4212-8f23 - cc754d06ac57 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 29 STRNEWLINE 2016-09-09 ▁ 13:45:53,072 ▁ [ req = 49becd26-5dfe - 4d2f - 8667-470519230d88 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b / release STRNEWLINE 2016-09-09 ▁ 13:45:53,115 ▁ [ req = 49becd26-5dfe - 4d2f - 8667-470519230d88 , ▁ org = ING _ Luxembourg _ SA ] ▁ INFO ▁ ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 43 STRNEWLINE """ . strip ( ) NEW_LINE PROXY_LOG = """ STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:28 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL _ 6_5 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 6.1205 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:38 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL _ 7_6 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 4.4754 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:49 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL6_8 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 4.5776 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:57:34 ▁ - 0400 ] ▁ " GET ▁ / tftp / serverName ▁ HTTP / 1.1 " ▁ 200 ▁ 38 ▁ 0.0014 STRNEWLINE E , ▁ [ 2016-05-31T09:57:34.884636 ▁ # 4494 ] ▁ ERROR ▁ - - ▁ : ▁ Record ▁ 172.16.100.0/172.16.100.17 ▁ not ▁ found ▁ ] STRNEWLINE """ . strip ( ) NEW_LINE def test_production_log ( ) : NEW_LINE INDENT fm_log = ProductionLog ( context_wrap ( PRODUCTION_LOG ) ) NEW_LINE assert 2 == len ( fm_log . get ( " Rendered ▁ text ▁ template " ) ) NEW_LINE assert " Expired ▁ 48 ▁ Reports " in fm_log NEW_LINE assert fm_log . get ( " Completed ▁ 200 ▁ OK ▁ in ▁ 93" ) [ 0 ] == "2015-11-13 ▁ 09:41:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 93ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) " NEW_LINE DEDENT def test_proxy_log ( ) : NEW_LINE INDENT px_log = ProxyLog ( context_wrap ( PROXY_LOG ) ) NEW_LINE assert " ERROR ▁ - - ▁ " in px_log NEW_LINE assert len ( px_log . get ( " KT _ Encore _ Library _ RHEL " ) ) == 3 NEW_LINE DEDENT def test_candlepin_log ( ) : NEW_LINE INDENT cp_log = CandlepinLog ( context_wrap ( CANDLEPIN_LOG ) ) NEW_LINE assert " req = 49becd26-5dfe - 4d2f - 8667-470519230d88" in cp_log NEW_LINE assert len ( cp_log . get ( " req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc " ) ) == 2 NEW_LINE DEDENT def test_satellite_log ( ) : NEW_LINE INDENT sat_log = SatelliteLog ( context_wrap ( SATELLITE_OUT ) ) NEW_LINE assert " subscribes ▁ to ▁ Class [ Qpid ] " in sat_log NEW_LINE assert len ( sat_log . get ( " notify : ▁ subscribes ▁ to ▁ Class [ " ) ) == 7 NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="itsjeyd/edx-platform/tree/master/cms/djangoapps/contentstore/tests/test_import_draft_order.py"> """ STRNEWLINE Tests ▁ Draft ▁ import ▁ order . STRNEWLINE """ NEW_LINE from xmodule . modulestore . xml_importer import import_course_from_xml NEW_LINE from xmodule . modulestore . tests . django_utils import ModuleStoreTestCase NEW_LINE from xmodule . modulestore . django import modulestore NEW_LINE from django . conf import settings NEW_LINE TEST_DATA_DIR = settings . COMMON_TEST_DATA_ROOT NEW_LINE # ▁ This ▁ test ▁ is ▁ in ▁ the ▁ CMS ▁ module ▁ because ▁ the ▁ test ▁ configuration ▁ to ▁ use ▁ a ▁ draft ENDCOM # ▁ modulestore ▁ is ▁ dependent ▁ on ▁ django . ENDCOM class DraftReorderTestCase ( ModuleStoreTestCase ) : NEW_LINE INDENT def test_order ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Verify ▁ that ▁ drafts ▁ are ▁ imported ▁ in ▁ the ▁ correct ▁ order . STRNEWLINE ▁ """ NEW_LINE store = modulestore ( ) NEW_LINE course_items = import_course_from_xml ( store , self . user . id , TEST_DATA_DIR , [ ' import _ draft _ order ' ] , create_if_not_present = True ) NEW_LINE course_key = course_items [ 0 ] . id NEW_LINE sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , '0f4f7649b10141b0bdc9922dcf94515a ' ) ) NEW_LINE verticals = sequential . children NEW_LINE # ▁ The ▁ order ▁ that ▁ files ▁ are ▁ read ▁ in ▁ from ▁ the ▁ file ▁ system ▁ is ▁ not ▁ guaranteed ▁ ( cannot ▁ rely ▁ on ENDCOM # ▁ alphabetical ▁ ordering , ▁ for ▁ example ) . ▁ Therefore , ▁ I ▁ have ▁ added ▁ a ▁ lot ▁ of ▁ variation ▁ in ▁ filename ▁ and ▁ desired ENDCOM # ▁ ordering ▁ so ▁ that ▁ the ▁ test ▁ reliably ▁ failed ▁ with ▁ the ▁ bug , ▁ at ▁ least ▁ on ▁ Linux . ENDCOM # ▁ ' a ' , ▁ ' b ' , ▁ ' c ' , ▁ ' d ' , ▁ and ▁ ' z ' ▁ are ▁ all ▁ drafts , ▁ with ▁ ' index _ in _ children _ list ' ▁ of ENDCOM # ▁ 2 ▁ , ▁ 4 ▁ , ▁ 6 ▁ , ▁ 5 ▁ , ▁ and ▁ 0 ▁ respectively . ENDCOM # ▁ ' 5a05be9d59fc4bb79282c94c9e6b88c7 ' ▁ and ▁ ' second ' ▁ are ▁ public ▁ verticals . ENDCOM self . assertEqual ( 7 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' z ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , '5a05be9d59fc4bb79282c94c9e6b88c7' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' a ' ) , verticals [ 2 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' second ' ) , verticals [ 3 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' b ' ) , verticals [ 4 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' d ' ) , verticals [ 5 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' c ' ) , verticals [ 6 ] ) NEW_LINE # ▁ Now ▁ also ▁ test ▁ that ▁ the ▁ verticals ▁ in ▁ a ▁ second ▁ sequential ▁ are ▁ correct . ENDCOM sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , ' secondseq ' ) ) NEW_LINE verticals = sequential . children NEW_LINE # ▁ ' asecond ' ▁ and ▁ ' zsecond ' ▁ are ▁ drafts ▁ with ▁ ' index _ in _ children _ list ' ▁ 0 ▁ and ▁ 2 , ▁ respectively . ENDCOM # ▁ ' secondsubsection ' ▁ is ▁ a ▁ public ▁ vertical . ENDCOM self . assertEqual ( 3 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' asecond ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' secondsubsection ' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' zsecond ' ) , verticals [ 2 ] ) NEW_LINE DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="patrickstocklin/chattR/tree/master/lib/python2.7/site-packages/pip/index.py"> """ Routines ▁ related ▁ to ▁ PyPI , ▁ indexes """ NEW_LINE from __future__ import absolute_import NEW_LINE import logging NEW_LINE import cgi NEW_LINE from collections import namedtuple NEW_LINE import itertools NEW_LINE import sys NEW_LINE import os NEW_LINE import re NEW_LINE import mimetypes NEW_LINE import posixpath NEW_LINE import warnings NEW_LINE from pip . _vendor . six . moves . urllib import parse as urllib_parse NEW_LINE from pip . _vendor . six . moves . urllib import request as urllib_request NEW_LINE from pip . compat import ipaddress NEW_LINE from pip . utils import ( Inf , cached_property , normalize_name , splitext , normalize_path , ARCHIVE_EXTENSIONS , SUPPORTED_EXTENSIONS ) NEW_LINE from pip . utils . deprecation import RemovedInPip8Warning NEW_LINE from pip . utils . logging import indent_log NEW_LINE from pip . exceptions import ( DistributionNotFound , BestVersionAlreadyInstalled , InvalidWheelFilename , UnsupportedWheel , ) NEW_LINE from pip . download import HAS_TLS , url_to_path , path_to_url NEW_LINE from pip . models import PyPI NEW_LINE from pip . wheel import Wheel , wheel_ext NEW_LINE from pip . pep425tags import supported_tags , supported_tags_noarch , get_platform NEW_LINE from pip . _vendor import html5lib , requests , pkg_resources , six NEW_LINE from pip . _vendor . packaging . version import parse as parse_version NEW_LINE from pip . _vendor . requests . exceptions import SSLError NEW_LINE __all__ = [ ' FormatControl ' , ' fmt _ ctl _ handle _ mutual _ exclude ' , ' PackageFinder ' ] NEW_LINE # ▁ Taken ▁ from ▁ Chrome ' s ▁ list ▁ of ▁ secure ▁ origins ▁ ( See : ▁ http : / / bit . ly / 1qrySKC ) ENDCOM SECURE_ORIGINS = [ # ▁ protocol , ▁ hostname , ▁ port ENDCOM ( " https " , " * " , " * " ) , ( " * " , " localhost " , " * " ) , ( " * " , "127.0.0.0/8" , " * " ) , ( " * " , " : :1/128" , " * " ) , ( " file " , " * " , None ) , ] NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE class InstallationCandidate ( object ) : NEW_LINE INDENT def __init__ ( self , project , version , location ) : NEW_LINE INDENT self . project = project NEW_LINE self . version = parse_version ( version ) NEW_LINE self . location = location NEW_LINE self . _key = ( self . project , self . version , self . location ) NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return " < InstallationCandidate ( {0 ! r } , ▁ { 1 ! r } , ▁ { 2 ! r } ) > " . format ( self . project , self . version , self . location , ) NEW_LINE DEDENT def __hash__ ( self ) : NEW_LINE INDENT return hash ( self . _key ) NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s < o ) NEW_LINE DEDENT def __le__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s <= o ) NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s == o ) NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s >= o ) NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s > o ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s != o ) NEW_LINE DEDENT def _compare ( self , other , method ) : NEW_LINE INDENT if not isinstance ( other , InstallationCandidate ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return method ( self . _key , other . _key ) NEW_LINE DEDENT DEDENT class PackageFinder ( object ) : NEW_LINE INDENT """ This ▁ finds ▁ packages . STRNEWLINE STRNEWLINE ▁ This ▁ is ▁ meant ▁ to ▁ match ▁ easy _ install ' s ▁ technique ▁ for ▁ looking ▁ for STRNEWLINE ▁ packages , ▁ by ▁ reading ▁ pages ▁ and ▁ looking ▁ for ▁ appropriate ▁ links . STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , find_links , index_urls , allow_external = ( ) , allow_unverified = ( ) , allow_all_external = False , allow_all_prereleases = False , trusted_hosts = None , process_dependency_links = False , session = None , format_control = None ) : NEW_LINE INDENT """ Create ▁ a ▁ PackageFinder . STRNEWLINE STRNEWLINE ▁ : param ▁ format _ control : ▁ A ▁ FormatControl ▁ object ▁ or ▁ None . ▁ Used ▁ to ▁ control STRNEWLINE ▁ the ▁ selection ▁ of ▁ source ▁ packages ▁ / ▁ binary ▁ packages ▁ when ▁ consulting STRNEWLINE ▁ the ▁ index ▁ and ▁ links . STRNEWLINE ▁ """ NEW_LINE if session is None : NEW_LINE INDENT raise TypeError ( " PackageFinder ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ " " ' session ' " ) NEW_LINE # ▁ Build ▁ find _ links . ▁ If ▁ an ▁ argument ▁ starts ▁ with ▁ ~ , ▁ it ▁ may ▁ be ENDCOM # ▁ a ▁ local ▁ file ▁ relative ▁ to ▁ a ▁ home ▁ directory . ▁ So ▁ try ▁ normalizing ENDCOM # ▁ it ▁ and ▁ if ▁ it ▁ exists , ▁ use ▁ the ▁ normalized ▁ version . ENDCOM # ▁ This ▁ is ▁ deliberately ▁ conservative ▁ - ▁ it ▁ might ▁ be ▁ fine ▁ just ▁ to ENDCOM # ▁ blindly ▁ normalize ▁ anything ▁ starting ▁ with ▁ a ▁ ~ . . . ENDCOM DEDENT self . find_links = [ ] NEW_LINE for link in find_links : NEW_LINE INDENT if link . startswith ( ' ~ ' ) : NEW_LINE INDENT new_link = normalize_path ( link ) NEW_LINE if os . path . exists ( new_link ) : NEW_LINE INDENT link = new_link NEW_LINE DEDENT DEDENT self . find_links . append ( link ) NEW_LINE DEDENT self . index_urls = index_urls NEW_LINE self . dependency_links = [ ] NEW_LINE # ▁ These ▁ are ▁ boring ▁ links ▁ that ▁ have ▁ already ▁ been ▁ logged ▁ somehow : ENDCOM self . logged_links = set ( ) NEW_LINE self . format_control = format_control or FormatControl ( set ( ) , set ( ) ) NEW_LINE # ▁ Do ▁ we ▁ allow ▁ ( safe ▁ and ▁ verifiable ) ▁ externally ▁ hosted ▁ files ? ENDCOM self . allow_external = set ( normalize_name ( n ) for n in allow_external ) NEW_LINE # ▁ Which ▁ names ▁ are ▁ allowed ▁ to ▁ install ▁ insecure ▁ and ▁ unverifiable ▁ files ? ENDCOM self . allow_unverified = set ( normalize_name ( n ) for n in allow_unverified ) NEW_LINE # ▁ Anything ▁ that ▁ is ▁ allowed ▁ unverified ▁ is ▁ also ▁ allowed ▁ external ENDCOM self . allow_external |= self . allow_unverified NEW_LINE # ▁ Do ▁ we ▁ allow ▁ all ▁ ( safe ▁ and ▁ verifiable ) ▁ externally ▁ hosted ▁ files ? ENDCOM self . allow_all_external = allow_all_external NEW_LINE # ▁ Domains ▁ that ▁ we ▁ won ' t ▁ emit ▁ warnings ▁ for ▁ when ▁ not ▁ using ▁ HTTPS ENDCOM self . secure_origins = [ ( " * " , host , " * " ) for host in ( trusted_hosts if trusted_hosts else [ ] ) ] NEW_LINE # ▁ Stores ▁ if ▁ we ▁ ignored ▁ any ▁ external ▁ links ▁ so ▁ that ▁ we ▁ can ▁ instruct ENDCOM # ▁ end ▁ users ▁ how ▁ to ▁ install ▁ them ▁ if ▁ no ▁ distributions ▁ are ▁ available ENDCOM self . need_warn_external = False NEW_LINE # ▁ Stores ▁ if ▁ we ▁ ignored ▁ any ▁ unsafe ▁ links ▁ so ▁ that ▁ we ▁ can ▁ instruct ENDCOM # ▁ end ▁ users ▁ how ▁ to ▁ install ▁ them ▁ if ▁ no ▁ distributions ▁ are ▁ available ENDCOM self . need_warn_unverified = False NEW_LINE # ▁ Do ▁ we ▁ want ▁ to ▁ allow ▁ _ all _ ▁ pre - releases ? ENDCOM self . allow_all_prereleases = allow_all_prereleases NEW_LINE # ▁ Do ▁ we ▁ process ▁ dependency ▁ links ? ENDCOM self . process_dependency_links = process_dependency_links NEW_LINE # ▁ The ▁ Session ▁ we ' ll ▁ use ▁ to ▁ make ▁ requests ENDCOM self . session = session NEW_LINE # ▁ If ▁ we ▁ don ' t ▁ have ▁ TLS ▁ enabled , ▁ then ▁ WARN ▁ if ▁ anyplace ▁ we ' re ▁ looking ENDCOM # ▁ relies ▁ on ▁ TLS . ENDCOM if not HAS_TLS : NEW_LINE INDENT for link in itertools . chain ( self . index_urls , self . find_links ) : NEW_LINE INDENT parsed = urllib_parse . urlparse ( link ) NEW_LINE if parsed . scheme == " https " : NEW_LINE INDENT logger . warning ( " pip ▁ is ▁ configured ▁ with ▁ locations ▁ that ▁ require ▁ " " TLS / SSL , ▁ however ▁ the ▁ ssl ▁ module ▁ in ▁ Python ▁ is ▁ not ▁ " " available . " ) NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT DEDENT def add_dependency_links ( self , links ) : NEW_LINE # ▁ # ▁ FIXME : ▁ this ▁ shouldn ' t ▁ be ▁ global ▁ list ▁ this , ▁ it ▁ should ▁ only ENDCOM # ▁ # ▁ apply ▁ to ▁ requirements ▁ of ▁ the ▁ package ▁ that ▁ specifies ▁ the ENDCOM # ▁ # ▁ dependency _ links ▁ value ENDCOM # ▁ # ▁ FIXME : ▁ also , ▁ we ▁ should ▁ track ▁ comes _ from ▁ ( i . e . , ▁ use ▁ Link ) ENDCOM INDENT if self . process_dependency_links : NEW_LINE INDENT warnings . warn ( " Dependency ▁ Links ▁ processing ▁ has ▁ been ▁ deprecated ▁ and ▁ will ▁ be ▁ " " removed ▁ in ▁ a ▁ future ▁ release . " , RemovedInPip8Warning , ) NEW_LINE self . dependency_links . extend ( links ) NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def _sort_locations ( locations , expand_dir = False ) : NEW_LINE INDENT """ STRNEWLINE ▁ Sort ▁ locations ▁ into ▁ " files " ▁ ( archives ) ▁ and ▁ " urls " , ▁ and ▁ return STRNEWLINE ▁ a ▁ pair ▁ of ▁ lists ▁ ( files , urls ) STRNEWLINE ▁ """ NEW_LINE files = [ ] NEW_LINE urls = [ ] NEW_LINE # ▁ puts ▁ the ▁ url ▁ for ▁ the ▁ given ▁ file ▁ path ▁ into ▁ the ▁ appropriate ▁ list ENDCOM def sort_path ( path ) : NEW_LINE INDENT url = path_to_url ( path ) NEW_LINE if mimetypes . guess_type ( url , strict = False ) [ 0 ] == ' text / html ' : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT else : NEW_LINE INDENT files . append ( url ) NEW_LINE DEDENT DEDENT for url in locations : NEW_LINE INDENT is_local_path = os . path . exists ( url ) NEW_LINE is_file_url = url . startswith ( ' file : ' ) NEW_LINE if is_local_path or is_file_url : NEW_LINE INDENT if is_local_path : NEW_LINE INDENT path = url NEW_LINE DEDENT else : NEW_LINE INDENT path = url_to_path ( url ) NEW_LINE DEDENT if os . path . isdir ( path ) : NEW_LINE INDENT if expand_dir : NEW_LINE INDENT path = os . path . realpath ( path ) NEW_LINE for item in os . listdir ( path ) : NEW_LINE INDENT sort_path ( os . path . join ( path , item ) ) NEW_LINE DEDENT DEDENT elif is_file_url : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT elif os . path . isfile ( path ) : NEW_LINE INDENT sort_path ( path ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT return files , urls NEW_LINE DEDENT def _candidate_sort_key ( self , candidate ) : NEW_LINE INDENT """ STRNEWLINE ▁ Function ▁ used ▁ to ▁ generate ▁ link ▁ sort ▁ key ▁ for ▁ link ▁ tuples . STRNEWLINE ▁ The ▁ greater ▁ the ▁ return ▁ value , ▁ the ▁ more ▁ preferred ▁ it ▁ is . STRNEWLINE ▁ If ▁ not ▁ finding ▁ wheels , ▁ then ▁ sorted ▁ by ▁ version ▁ only . STRNEWLINE ▁ If ▁ finding ▁ wheels , ▁ then ▁ the ▁ sort ▁ order ▁ is ▁ by ▁ version , ▁ then : STRNEWLINE ▁ 1 . ▁ existing ▁ installs STRNEWLINE ▁ 2 . ▁ wheels ▁ ordered ▁ via ▁ Wheel . support _ index _ min ( ) STRNEWLINE ▁ 3 . ▁ source ▁ archives STRNEWLINE ▁ Note : ▁ it ▁ was ▁ considered ▁ to ▁ embed ▁ this ▁ logic ▁ into ▁ the ▁ Link STRNEWLINE ▁ comparison ▁ operators , ▁ but ▁ then ▁ different ▁ sdist ▁ links STRNEWLINE ▁ with ▁ the ▁ same ▁ version , ▁ would ▁ have ▁ to ▁ be ▁ considered ▁ equal STRNEWLINE ▁ """ NEW_LINE support_num = len ( supported_tags ) NEW_LINE if candidate . location == INSTALLED_VERSION : NEW_LINE INDENT pri = 1 NEW_LINE DEDENT elif candidate . location . is_wheel : NEW_LINE # ▁ can ▁ raise ▁ InvalidWheelFilename ENDCOM INDENT wheel = Wheel ( candidate . location . filename ) NEW_LINE if not wheel . supported ( ) : NEW_LINE INDENT raise UnsupportedWheel ( " % s ▁ is ▁ not ▁ a ▁ supported ▁ wheel ▁ for ▁ this ▁ platform . ▁ It ▁ " " can ' t ▁ be ▁ sorted . " % wheel . filename ) NEW_LINE DEDENT pri = - ( wheel . support_index_min ( ) ) NEW_LINE DEDENT else : # ▁ sdist ENDCOM NEW_LINE INDENT pri = - ( support_num ) NEW_LINE DEDENT return ( candidate . version , pri ) NEW_LINE DEDENT def _sort_versions ( self , applicable_versions ) : NEW_LINE INDENT """ STRNEWLINE ▁ Bring ▁ the ▁ latest ▁ version ▁ ( and ▁ wheels ) ▁ to ▁ the ▁ front , ▁ but ▁ maintain ▁ the STRNEWLINE ▁ existing ▁ ordering ▁ as ▁ secondary . ▁ See ▁ the ▁ docstring ▁ for ▁ ` _ link _ sort _ key ` STRNEWLINE ▁ for ▁ details . ▁ This ▁ function ▁ is ▁ isolated ▁ for ▁ easier ▁ unit ▁ testing . STRNEWLINE ▁ """ NEW_LINE return sorted ( applicable_versions , key = self . _candidate_sort_key , reverse = True ) NEW_LINE DEDENT def _validate_secure_origin ( self , logger , location ) : NEW_LINE # ▁ Determine ▁ if ▁ this ▁ url ▁ used ▁ a ▁ secure ▁ transport ▁ mechanism ENDCOM INDENT parsed = urllib_parse . urlparse ( str ( location ) ) NEW_LINE origin = ( parsed . scheme , parsed . hostname , parsed . port ) NEW_LINE # ▁ Determine ▁ if ▁ our ▁ origin ▁ is ▁ a ▁ secure ▁ origin ▁ by ▁ looking ▁ through ▁ our ENDCOM # ▁ hardcoded ▁ list ▁ of ▁ secure ▁ origins , ▁ as ▁ well ▁ as ▁ any ▁ additional ▁ ones ENDCOM # ▁ configured ▁ on ▁ this ▁ PackageFinder ▁ instance . ENDCOM for secure_origin in ( SECURE_ORIGINS + self . secure_origins ) : NEW_LINE # ▁ Check ▁ to ▁ see ▁ if ▁ the ▁ protocol ▁ matches ENDCOM INDENT if origin [ 0 ] != secure_origin [ 0 ] and secure_origin [ 0 ] != " * " : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE # ▁ We ▁ need ▁ to ▁ do ▁ this ▁ decode ▁ dance ▁ to ▁ ensure ▁ that ▁ we ▁ have ▁ a ENDCOM # ▁ unicode ▁ object , ▁ even ▁ on ▁ Python ▁ 2 . x . ENDCOM INDENT addr = ipaddress . ip_address ( origin [ 1 ] if ( isinstance ( origin [ 1 ] , six . text_type ) or origin [ 1 ] is None ) else origin [ 1 ] . decode ( " utf8" ) ) NEW_LINE network = ipaddress . ip_network ( secure_origin [ 1 ] if isinstance ( secure_origin [ 1 ] , six . text_type ) else secure_origin [ 1 ] . decode ( " utf8" ) ) NEW_LINE DEDENT except ValueError : NEW_LINE # ▁ We ▁ don ' t ▁ have ▁ both ▁ a ▁ valid ▁ address ▁ or ▁ a ▁ valid ▁ network , ▁ so ENDCOM # ▁ we ' ll ▁ check ▁ this ▁ origin ▁ against ▁ hostnames . ENDCOM INDENT if origin [ 1 ] != secure_origin [ 1 ] and secure_origin [ 1 ] != " * " : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT else : NEW_LINE # ▁ We ▁ have ▁ a ▁ valid ▁ address ▁ and ▁ network , ▁ so ▁ see ▁ if ▁ the ▁ address ENDCOM # ▁ is ▁ contained ▁ within ▁ the ▁ network . ENDCOM INDENT if addr not in network : NEW_LINE INDENT continue NEW_LINE # ▁ Check ▁ to ▁ see ▁ if ▁ the ▁ port ▁ patches ENDCOM DEDENT DEDENT if ( origin [ 2 ] != secure_origin [ 2 ] and secure_origin [ 2 ] != " * " and secure_origin [ 2 ] is not None ) : NEW_LINE INDENT continue NEW_LINE # ▁ If ▁ we ' ve ▁ gotten ▁ here , ▁ then ▁ this ▁ origin ▁ matches ▁ the ▁ current ENDCOM # ▁ secure ▁ origin ▁ and ▁ we ▁ should ▁ return ▁ True ENDCOM DEDENT return True NEW_LINE # ▁ If ▁ we ' ve ▁ gotten ▁ to ▁ this ▁ point , ▁ then ▁ the ▁ origin ▁ isn ' t ▁ secure ▁ and ▁ we ENDCOM # ▁ will ▁ not ▁ accept ▁ it ▁ as ▁ a ▁ valid ▁ location ▁ to ▁ search . ▁ We ▁ will ▁ however ENDCOM # ▁ log ▁ a ▁ warning ▁ that ▁ we ▁ are ▁ ignoring ▁ it . ENDCOM DEDENT logger . warning ( " The ▁ repository ▁ located ▁ at ▁ % s ▁ is ▁ not ▁ a ▁ trusted ▁ or ▁ secure ▁ host ▁ and ▁ " " is ▁ being ▁ ignored . ▁ If ▁ this ▁ repository ▁ is ▁ available ▁ via ▁ HTTPS ▁ it ▁ " " is ▁ recommended ▁ to ▁ use ▁ HTTPS ▁ instead , ▁ otherwise ▁ you ▁ may ▁ silence ▁ " " this ▁ warning ▁ and ▁ allow ▁ it ▁ anyways ▁ with ▁ ' - - trusted - host ▁ % s ' . " , parsed . hostname , parsed . hostname , ) NEW_LINE return False NEW_LINE DEDENT def _get_index_urls_locations ( self , project_name ) : NEW_LINE INDENT """ Returns ▁ the ▁ locations ▁ found ▁ via ▁ self . index _ urls STRNEWLINE STRNEWLINE ▁ Checks ▁ the ▁ url _ name ▁ on ▁ the ▁ main ▁ ( first ▁ in ▁ the ▁ list ) ▁ index ▁ and STRNEWLINE ▁ use ▁ this ▁ url _ name ▁ to ▁ produce ▁ all ▁ locations STRNEWLINE ▁ """ NEW_LINE def mkurl_pypi_url ( url ) : NEW_LINE INDENT loc = posixpath . join ( url , project_url_name ) NEW_LINE # ▁ For ▁ maximum ▁ compatibility ▁ with ▁ easy _ install , ▁ ensure ▁ the ▁ path ENDCOM # ▁ ends ▁ in ▁ a ▁ trailing ▁ slash . ▁ Although ▁ this ▁ isn ' t ▁ in ▁ the ▁ spec ENDCOM # ▁ ( and ▁ PyPI ▁ can ▁ handle ▁ it ▁ without ▁ the ▁ slash ) ▁ some ▁ other ▁ index ENDCOM # ▁ implementations ▁ might ▁ break ▁ if ▁ they ▁ relied ▁ on ▁ easy _ install ' s ENDCOM # ▁ behavior . ENDCOM if not loc . endswith ( ' / ' ) : NEW_LINE INDENT loc = loc + ' / ' NEW_LINE DEDENT return loc NEW_LINE DEDENT project_url_name = urllib_parse . quote ( project_name . lower ( ) ) NEW_LINE if self . index_urls : NEW_LINE # ▁ Check ▁ that ▁ we ▁ have ▁ the ▁ url _ name ▁ correctly ▁ spelled : ENDCOM # ▁ Only ▁ check ▁ main ▁ index ▁ if ▁ index ▁ URL ▁ is ▁ given ENDCOM INDENT main_index_url = Link ( mkurl_pypi_url ( self . index_urls [ 0 ] ) , trusted = True , ) NEW_LINE page = self . _get_page ( main_index_url ) NEW_LINE if page is None and PyPI . netloc not in str ( main_index_url ) : NEW_LINE INDENT warnings . warn ( " Failed ▁ to ▁ find ▁ % r ▁ at ▁ % s . ▁ It ▁ is ▁ suggested ▁ to ▁ upgrade ▁ " " your ▁ index ▁ to ▁ support ▁ normalized ▁ names ▁ as ▁ the ▁ name ▁ in ▁ " " / simple / { name } . " % ( project_name , main_index_url ) , RemovedInPip8Warning , ) NEW_LINE project_url_name = self . _find_url_name ( Link ( self . index_urls [ 0 ] , trusted = True ) , project_url_name , ) or project_url_name NEW_LINE DEDENT DEDENT if project_url_name is not None : NEW_LINE INDENT return [ mkurl_pypi_url ( url ) for url in self . index_urls ] NEW_LINE DEDENT return [ ] NEW_LINE DEDENT def _find_all_versions ( self , project_name ) : NEW_LINE INDENT """ Find ▁ all ▁ available ▁ versions ▁ for ▁ project _ name STRNEWLINE STRNEWLINE ▁ This ▁ checks ▁ index _ urls , ▁ find _ links ▁ and ▁ dependency _ links STRNEWLINE ▁ All ▁ versions ▁ found ▁ are ▁ returned STRNEWLINE STRNEWLINE ▁ See ▁ _ link _ package _ versions ▁ for ▁ details ▁ on ▁ which ▁ files ▁ are ▁ accepted STRNEWLINE ▁ """ NEW_LINE index_locations = self . _get_index_urls_locations ( project_name ) NEW_LINE index_file_loc , index_url_loc = self . _sort_locations ( index_locations ) NEW_LINE fl_file_loc , fl_url_loc = self . _sort_locations ( self . find_links , expand_dir = True ) NEW_LINE dep_file_loc , dep_url_loc = self . _sort_locations ( self . dependency_links ) NEW_LINE file_locations = ( Link ( url ) for url in itertools . chain ( index_file_loc , fl_file_loc , dep_file_loc ) ) NEW_LINE # ▁ We ▁ trust ▁ every ▁ url ▁ that ▁ the ▁ user ▁ has ▁ given ▁ us ▁ whether ▁ it ▁ was ▁ given ENDCOM # ▁ via ▁ - - index - url ▁ or ▁ - - find - links ENDCOM # ▁ We ▁ explicitly ▁ do ▁ not ▁ trust ▁ links ▁ that ▁ came ▁ from ▁ dependency _ links ENDCOM # ▁ We ▁ want ▁ to ▁ filter ▁ out ▁ any ▁ thing ▁ which ▁ does ▁ not ▁ have ▁ a ▁ secure ▁ origin . ENDCOM url_locations = [ link for link in itertools . chain ( ( Link ( url , trusted = True ) for url in index_url_loc ) , ( Link ( url , trusted = True ) for url in fl_url_loc ) , ( Link ( url ) for url in dep_url_loc ) , ) if self . _validate_secure_origin ( logger , link ) ] NEW_LINE logger . debug ( ' % d ▁ location ( s ) ▁ to ▁ search ▁ for ▁ versions ▁ of ▁ % s : ' , len ( url_locations ) , project_name ) NEW_LINE for location in url_locations : NEW_LINE INDENT logger . debug ( ' * ▁ % s ' , location ) NEW_LINE DEDENT canonical_name = pkg_resources . safe_name ( project_name ) . lower ( ) NEW_LINE formats = fmt_ctl_formats ( self . format_control , canonical_name ) NEW_LINE search = Search ( project_name . lower ( ) , canonical_name , formats ) NEW_LINE find_links_versions = self . _package_versions ( # ▁ We ▁ trust ▁ every ▁ directly ▁ linked ▁ archive ▁ in ▁ find _ links ENDCOM ( Link ( url , ' - f ' , trusted = True ) for url in self . find_links ) , search ) NEW_LINE page_versions = [ ] NEW_LINE for page in self . _get_pages ( url_locations , project_name ) : NEW_LINE INDENT logger . debug ( ' Analyzing ▁ links ▁ from ▁ page ▁ % s ' , page . url ) NEW_LINE with indent_log ( ) : NEW_LINE INDENT page_versions . extend ( self . _package_versions ( page . links , search ) ) NEW_LINE DEDENT DEDENT dependency_versions = self . _package_versions ( ( Link ( url ) for url in self . dependency_links ) , search ) NEW_LINE if dependency_versions : NEW_LINE INDENT logger . debug ( ' dependency _ links ▁ found : ▁ % s ' , ' , ▁ ' . join ( [ version . location . url for version in dependency_versions ] ) ) NEW_LINE DEDENT file_versions = self . _package_versions ( file_locations , search ) NEW_LINE if file_versions : NEW_LINE INDENT file_versions . sort ( reverse = True ) NEW_LINE logger . debug ( ' Local ▁ files ▁ found : ▁ % s ' , ' , ▁ ' . join ( [ url_to_path ( candidate . location . url ) for candidate in file_versions ] ) ) NEW_LINE # ▁ This ▁ is ▁ an ▁ intentional ▁ priority ▁ ordering ENDCOM DEDENT return ( file_versions + find_links_versions + page_versions + dependency_versions ) NEW_LINE DEDENT def find_requirement ( self , req , upgrade ) : NEW_LINE INDENT """ Try ▁ to ▁ find ▁ an ▁ InstallationCandidate ▁ for ▁ req STRNEWLINE STRNEWLINE ▁ Expects ▁ req , ▁ an ▁ InstallRequirement ▁ and ▁ upgrade , ▁ a ▁ boolean STRNEWLINE ▁ Returns ▁ an ▁ InstallationCandidate ▁ or ▁ None STRNEWLINE ▁ May ▁ raise ▁ DistributionNotFound ▁ or ▁ BestVersionAlreadyInstalled STRNEWLINE ▁ """ NEW_LINE all_versions = self . _find_all_versions ( req . name ) NEW_LINE # ▁ Filter ▁ out ▁ anything ▁ which ▁ doesn ' t ▁ match ▁ our ▁ specifier ENDCOM _versions = set ( req . specifier . filter ( # ▁ We ▁ turn ▁ the ▁ version ▁ object ▁ into ▁ a ▁ str ▁ here ▁ because ▁ otherwise ENDCOM # ▁ when ▁ we ' re ▁ debundled ▁ but ▁ setuptools ▁ isn ' t , ▁ Python ▁ will ▁ see ENDCOM # ▁ packaging . version . Version ▁ and ENDCOM # ▁ pkg _ resources . _ vendor . packaging . version . Version ▁ as ▁ different ENDCOM # ▁ types . ▁ This ▁ way ▁ we ' ll ▁ use ▁ a ▁ str ▁ as ▁ a ▁ common ▁ data ▁ interchange ENDCOM # ▁ format . ▁ If ▁ we ▁ stop ▁ using ▁ the ▁ pkg _ resources ▁ provided ▁ specifier ENDCOM # ▁ and ▁ start ▁ using ▁ our ▁ own , ▁ we ▁ can ▁ drop ▁ the ▁ cast ▁ to ▁ str ( ) . ENDCOM [ str ( x . version ) for x in all_versions ] , prereleases = ( self . allow_all_prereleases if self . allow_all_prereleases else None ) , ) ) NEW_LINE applicable_versions = [ # ▁ Again , ▁ converting ▁ to ▁ str ▁ to ▁ deal ▁ with ▁ debundling . ENDCOM x for x in all_versions if str ( x . version ) in _versions ] NEW_LINE if req . satisfied_by is not None : NEW_LINE # ▁ Finally ▁ add ▁ our ▁ existing ▁ versions ▁ to ▁ the ▁ front ▁ of ▁ our ▁ versions . ENDCOM INDENT applicable_versions . insert ( 0 , InstallationCandidate ( req . name , req . satisfied_by . version , INSTALLED_VERSION , ) ) NEW_LINE existing_applicable = True NEW_LINE DEDENT else : NEW_LINE INDENT existing_applicable = False NEW_LINE DEDENT applicable_versions = self . _sort_versions ( applicable_versions ) NEW_LINE if not upgrade and existing_applicable : NEW_LINE INDENT if applicable_versions [ 0 ] . location is INSTALLED_VERSION : NEW_LINE INDENT logger . debug ( ' Existing ▁ installed ▁ version ▁ ( % s ) ▁ is ▁ most ▁ up - to - date ▁ and ▁ ' ' satisfies ▁ requirement ' , req . satisfied_by . version , ) NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Existing ▁ installed ▁ version ▁ ( % s ) ▁ satisfies ▁ requirement ▁ ' ' ( most ▁ up - to - date ▁ version ▁ is ▁ % s ) ' , req . satisfied_by . version , applicable_versions [ 0 ] [ 2 ] , ) NEW_LINE DEDENT return None NEW_LINE DEDENT if not applicable_versions : NEW_LINE INDENT logger . critical ( ' Could ▁ not ▁ find ▁ a ▁ version ▁ that ▁ satisfies ▁ the ▁ requirement ▁ % s ▁ ' ' ( from ▁ versions : ▁ % s ) ' , req , ' , ▁ ' . join ( sorted ( set ( str ( i . version ) for i in all_versions ) , key = parse_version , ) ) ) NEW_LINE if self . need_warn_external : NEW_LINE INDENT logger . warning ( " Some ▁ externally ▁ hosted ▁ files ▁ were ▁ ignored ▁ as ▁ access ▁ to ▁ " " them ▁ may ▁ be ▁ unreliable ▁ ( use ▁ - - allow - external ▁ % s ▁ to ▁ " " allow ) . " , req . name , ) NEW_LINE DEDENT if self . need_warn_unverified : NEW_LINE INDENT logger . warning ( " Some ▁ insecure ▁ and ▁ unverifiable ▁ files ▁ were ▁ ignored " " ▁ ( use ▁ - - allow - unverified ▁ % s ▁ to ▁ allow ) . " , req . name , ) NEW_LINE DEDENT raise DistributionNotFound ( ' No ▁ matching ▁ distribution ▁ found ▁ for ▁ % s ' % req ) NEW_LINE DEDENT if applicable_versions [ 0 ] . location is INSTALLED_VERSION : NEW_LINE # ▁ We ▁ have ▁ an ▁ existing ▁ version , ▁ and ▁ its ▁ the ▁ best ▁ version ENDCOM INDENT logger . debug ( ' Installed ▁ version ▁ ( % s ) ▁ is ▁ most ▁ up - to - date ▁ ( past ▁ versions : ▁ ' ' % s ) ' , req . satisfied_by . version , ' , ▁ ' . join ( str ( i . version ) for i in applicable_versions [ 1 : ] ) or " none " , ) NEW_LINE raise BestVersionAlreadyInstalled NEW_LINE DEDENT if len ( applicable_versions ) > 1 : NEW_LINE INDENT logger . debug ( ' Using ▁ version ▁ % s ▁ ( newest ▁ of ▁ versions : ▁ % s ) ' , applicable_versions [ 0 ] . version , ' , ▁ ' . join ( str ( i . version ) for i in applicable_versions ) ) NEW_LINE DEDENT selected_version = applicable_versions [ 0 ] . location NEW_LINE if ( selected_version . verifiable is not None and not selected_version . verifiable ) : NEW_LINE INDENT logger . warning ( " % s ▁ is ▁ potentially ▁ insecure ▁ and ▁ unverifiable . " , req . name , ) NEW_LINE DEDENT return selected_version NEW_LINE DEDENT def _find_url_name ( self , index_url , url_name ) : NEW_LINE INDENT """ STRNEWLINE ▁ Finds ▁ the ▁ true ▁ URL ▁ name ▁ of ▁ a ▁ package , ▁ when ▁ the ▁ given ▁ name ▁ isn ' t ▁ quite STRNEWLINE ▁ correct . STRNEWLINE ▁ This ▁ is ▁ usually ▁ used ▁ to ▁ implement ▁ case - insensitivity . STRNEWLINE ▁ """ NEW_LINE if not index_url . url . endswith ( ' / ' ) : NEW_LINE # ▁ Vaguely ▁ part ▁ of ▁ the ▁ PyPI ▁ API . . . ▁ weird ▁ but ▁ true . ENDCOM # ▁ FIXME : ▁ bad ▁ to ▁ modify ▁ this ? ENDCOM INDENT index_url . url += ' / ' NEW_LINE DEDENT page = self . _get_page ( index_url ) NEW_LINE if page is None : NEW_LINE INDENT logger . critical ( ' Cannot ▁ fetch ▁ index ▁ base ▁ URL ▁ % s ' , index_url ) NEW_LINE return NEW_LINE DEDENT norm_name = normalize_name ( url_name ) NEW_LINE for link in page . links : NEW_LINE INDENT base = posixpath . basename ( link . path . rstrip ( ' / ' ) ) NEW_LINE if norm_name == normalize_name ( base ) : NEW_LINE INDENT logger . debug ( ' Real ▁ name ▁ of ▁ requirement ▁ % s ▁ is ▁ % s ' , url_name , base , ) NEW_LINE return base NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def _get_pages ( self , locations , project_name ) : NEW_LINE INDENT """ STRNEWLINE ▁ Yields ▁ ( page , ▁ page _ url ) ▁ from ▁ the ▁ given ▁ locations , ▁ skipping STRNEWLINE ▁ locations ▁ that ▁ have ▁ errors , ▁ and ▁ adding ▁ download / homepage ▁ links STRNEWLINE ▁ """ NEW_LINE all_locations = list ( locations ) NEW_LINE seen = set ( ) NEW_LINE normalized = normalize_name ( project_name ) NEW_LINE while all_locations : NEW_LINE INDENT location = all_locations . pop ( 0 ) NEW_LINE if location in seen : NEW_LINE INDENT continue NEW_LINE DEDENT seen . add ( location ) NEW_LINE page = self . _get_page ( location ) NEW_LINE if page is None : NEW_LINE INDENT continue NEW_LINE DEDENT yield page NEW_LINE for link in page . rel_links ( ) : NEW_LINE INDENT if ( normalized not in self . allow_external and not self . allow_all_external ) : NEW_LINE INDENT self . need_warn_external = True NEW_LINE logger . debug ( " Not ▁ searching ▁ % s ▁ for ▁ files ▁ because ▁ external ▁ " " urls ▁ are ▁ disallowed . " , link , ) NEW_LINE continue NEW_LINE DEDENT if ( link . trusted is not None and not link . trusted and normalized not in self . allow_unverified ) : NEW_LINE INDENT logger . debug ( " Not ▁ searching ▁ % s ▁ for ▁ urls , ▁ it ▁ is ▁ an ▁ " " untrusted ▁ link ▁ and ▁ cannot ▁ produce ▁ safe ▁ or ▁ " " verifiable ▁ files . " , link , ) NEW_LINE self . need_warn_unverified = True NEW_LINE continue NEW_LINE DEDENT all_locations . append ( link ) NEW_LINE DEDENT DEDENT DEDENT _py_version_re = re . compile ( r ' - py ( [123 ] \ . ? [ 0-9 ] ? ) $ ' ) NEW_LINE def _sort_links ( self , links ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ elements ▁ of ▁ links ▁ in ▁ order , ▁ non - egg ▁ links ▁ first , ▁ egg ▁ links STRNEWLINE ▁ second , ▁ while ▁ eliminating ▁ duplicates STRNEWLINE ▁ """ NEW_LINE eggs , no_eggs = [ ] , [ ] NEW_LINE seen = set ( ) NEW_LINE for link in links : NEW_LINE INDENT if link not in seen : NEW_LINE INDENT seen . add ( link ) NEW_LINE if link . egg_fragment : NEW_LINE INDENT eggs . append ( link ) NEW_LINE DEDENT else : NEW_LINE INDENT no_eggs . append ( link ) NEW_LINE DEDENT DEDENT DEDENT return no_eggs + eggs NEW_LINE DEDENT def _package_versions ( self , links , search ) : NEW_LINE INDENT result = [ ] NEW_LINE for link in self . _sort_links ( links ) : NEW_LINE INDENT v = self . _link_package_versions ( link , search ) NEW_LINE if v is not None : NEW_LINE INDENT result . append ( v ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT def _log_skipped_link ( self , link , reason ) : NEW_LINE INDENT if link not in self . logged_links : NEW_LINE INDENT logger . debug ( ' Skipping ▁ link ▁ % s ; ▁ % s ' , link , reason ) NEW_LINE self . logged_links . add ( link ) NEW_LINE DEDENT DEDENT def _link_package_versions ( self , link , search ) : NEW_LINE INDENT """ Return ▁ an ▁ InstallationCandidate ▁ or ▁ None """ NEW_LINE platform = get_platform ( ) NEW_LINE version = None NEW_LINE if link . egg_fragment : NEW_LINE INDENT egg_info = link . egg_fragment NEW_LINE ext = link . ext NEW_LINE DEDENT else : NEW_LINE INDENT egg_info , ext = link . splitext ( ) NEW_LINE if not ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' not ▁ a ▁ file ' ) NEW_LINE return NEW_LINE DEDENT if ext not in SUPPORTED_EXTENSIONS : NEW_LINE INDENT self . _log_skipped_link ( link , ' unsupported ▁ archive ▁ format : ▁ % s ' % ext ) NEW_LINE return NEW_LINE DEDENT if " binary " not in search . formats and ext == wheel_ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' No ▁ binaries ▁ permitted ▁ for ▁ % s ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if " macosx10" in link . path and ext == ' . zip ' : NEW_LINE INDENT self . _log_skipped_link ( link , ' macosx10 ▁ one ' ) NEW_LINE return NEW_LINE DEDENT if ext == wheel_ext : NEW_LINE INDENT try : NEW_LINE INDENT wheel = Wheel ( link . filename ) NEW_LINE DEDENT except InvalidWheelFilename : NEW_LINE INDENT self . _log_skipped_link ( link , ' invalid ▁ wheel ▁ filename ' ) NEW_LINE return NEW_LINE DEDENT if ( pkg_resources . safe_name ( wheel . name ) . lower ( ) != search . canonical ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' wrong ▁ project ▁ name ▁ ( not ▁ % s ) ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if not wheel . supported ( ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ not ▁ compatible ▁ with ▁ this ▁ Python ' ) NEW_LINE return NEW_LINE # ▁ This ▁ is ▁ a ▁ dirty ▁ hack ▁ to ▁ prevent ▁ installing ▁ Binary ▁ Wheels ▁ from ENDCOM # ▁ PyPI ▁ unless ▁ it ▁ is ▁ a ▁ Windows ▁ or ▁ Mac ▁ Binary ▁ Wheel . ▁ This ▁ is ENDCOM # ▁ paired ▁ with ▁ a ▁ change ▁ to ▁ PyPI ▁ disabling ▁ uploads ▁ for ▁ the ENDCOM # ▁ same . ▁ Once ▁ we ▁ have ▁ a ▁ mechanism ▁ for ▁ enabling ▁ support ▁ for ENDCOM # ▁ binary ▁ wheels ▁ on ▁ linux ▁ that ▁ deals ▁ with ▁ the ▁ inherent ▁ problems ENDCOM # ▁ of ▁ binary ▁ distribution ▁ this ▁ can ▁ be ▁ removed . ENDCOM DEDENT comes_from = getattr ( link , " comes _ from " , None ) NEW_LINE if ( ( not platform . startswith ( ' win ' ) and not platform . startswith ( ' macosx ' ) and not platform == ' cli ' ) and comes_from is not None and urllib_parse . urlparse ( comes_from . url ) . netloc . endswith ( PyPI . netloc ) ) : NEW_LINE INDENT if not wheel . supported ( tags = supported_tags_noarch ) : NEW_LINE INDENT self . _log_skipped_link ( link , " it ▁ is ▁ a ▁ pypi - hosted ▁ binary ▁ " " Wheel ▁ on ▁ an ▁ unsupported ▁ platform " , ) NEW_LINE return NEW_LINE DEDENT DEDENT version = wheel . version NEW_LINE # ▁ This ▁ should ▁ be ▁ up ▁ by ▁ the ▁ search . ok _ binary ▁ check , ▁ but ▁ see ▁ issue ▁ 2700 . ENDCOM DEDENT DEDENT if " source " not in search . formats and ext != wheel_ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' No ▁ sources ▁ permitted ▁ for ▁ % s ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if not version : NEW_LINE INDENT version = egg_info_matches ( egg_info , search . supplied , link ) NEW_LINE DEDENT if version is None : NEW_LINE INDENT self . _log_skipped_link ( link , ' wrong ▁ project ▁ name ▁ ( not ▁ % s ) ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if ( link . internal is not None and not link . internal and not normalize_name ( search . supplied ) . lower ( ) in self . allow_external and not self . allow_all_external ) : NEW_LINE # ▁ We ▁ have ▁ a ▁ link ▁ that ▁ we ▁ are ▁ sure ▁ is ▁ external , ▁ so ▁ we ▁ should ▁ skip ENDCOM # ▁ it ▁ unless ▁ we ▁ are ▁ allowing ▁ externals ENDCOM INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ externally ▁ hosted ' ) NEW_LINE self . need_warn_external = True NEW_LINE return NEW_LINE DEDENT if ( link . verifiable is not None and not link . verifiable and not ( normalize_name ( search . supplied ) . lower ( ) in self . allow_unverified ) ) : NEW_LINE # ▁ We ▁ have ▁ a ▁ link ▁ that ▁ we ▁ are ▁ sure ▁ we ▁ cannot ▁ verify ▁ its ▁ integrity , ENDCOM # ▁ so ▁ we ▁ should ▁ skip ▁ it ▁ unless ▁ we ▁ are ▁ allowing ▁ unsafe ▁ installs ENDCOM # ▁ for ▁ this ▁ requirement . ENDCOM INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ an ▁ insecure ▁ and ▁ unverifiable ▁ file ' ) NEW_LINE self . need_warn_unverified = True NEW_LINE return NEW_LINE DEDENT match = self . _py_version_re . search ( version ) NEW_LINE if match : NEW_LINE INDENT version = version [ : match . start ( ) ] NEW_LINE py_version = match . group ( 1 ) NEW_LINE if py_version != sys . version [ : 3 ] : NEW_LINE INDENT self . _log_skipped_link ( link , ' Python ▁ version ▁ is ▁ incorrect ' ) NEW_LINE return NEW_LINE DEDENT DEDENT logger . debug ( ' Found ▁ link ▁ % s , ▁ version : ▁ % s ' , link , version ) NEW_LINE return InstallationCandidate ( search . supplied , version , link ) NEW_LINE DEDENT def _get_page ( self , link ) : NEW_LINE INDENT return HTMLPage . get_page ( link , session = self . session ) NEW_LINE DEDENT DEDENT def egg_info_matches ( egg_info , search_name , link , _egg_info_re = re . compile ( r ' ( [ a - z0-9 _ . ] + ) - ( [ a - z0-9 _ . ! + - ] + ) ' , re . I ) ) : NEW_LINE INDENT """ Pull ▁ the ▁ version ▁ part ▁ out ▁ of ▁ a ▁ string . STRNEWLINE STRNEWLINE ▁ : param ▁ egg _ info : ▁ The ▁ string ▁ to ▁ parse . ▁ E . g . ▁ foo - 2.1 STRNEWLINE ▁ : param ▁ search _ name : ▁ The ▁ name ▁ of ▁ the ▁ package ▁ this ▁ belongs ▁ to . ▁ None ▁ to STRNEWLINE ▁ infer ▁ the ▁ name . ▁ Note ▁ that ▁ this ▁ cannot ▁ unambiguously ▁ parse ▁ strings STRNEWLINE ▁ like ▁ foo - 2-2 ▁ which ▁ might ▁ be ▁ foo , ▁ 2-2 ▁ or ▁ foo - 2 , ▁ 2 . STRNEWLINE ▁ : param ▁ link : ▁ The ▁ link ▁ the ▁ string ▁ came ▁ from , ▁ for ▁ logging ▁ on ▁ failure . STRNEWLINE ▁ """ NEW_LINE match = _egg_info_re . search ( egg_info ) NEW_LINE if not match : NEW_LINE INDENT logger . debug ( ' Could ▁ not ▁ parse ▁ version ▁ from ▁ link : ▁ % s ' , link ) NEW_LINE return None NEW_LINE DEDENT if search_name is None : NEW_LINE INDENT full_match = match . group ( 0 ) NEW_LINE return full_match [ full_match . index ( ' - ' ) : ] NEW_LINE DEDENT name = match . group ( 0 ) . lower ( ) NEW_LINE # ▁ To ▁ match ▁ the ▁ " safe " ▁ name ▁ that ▁ pkg _ resources ▁ creates : ENDCOM name = name . replace ( ' _ ' , ' - ' ) NEW_LINE # ▁ project ▁ name ▁ and ▁ version ▁ must ▁ be ▁ separated ▁ by ▁ a ▁ dash ENDCOM look_for = search_name . lower ( ) + " - " NEW_LINE if name . startswith ( look_for ) : NEW_LINE INDENT return match . group ( 0 ) [ len ( look_for ) : ] NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT class HTMLPage ( object ) : NEW_LINE INDENT """ Represents ▁ one ▁ page , ▁ along ▁ with ▁ its ▁ URL """ NEW_LINE def __init__ ( self , content , url , headers = None , trusted = None ) : NEW_LINE # ▁ Determine ▁ if ▁ we ▁ have ▁ any ▁ encoding ▁ information ▁ in ▁ our ▁ headers ENDCOM INDENT encoding = None NEW_LINE if headers and " Content - Type " in headers : NEW_LINE INDENT content_type , params = cgi . parse_header ( headers [ " Content - Type " ] ) NEW_LINE if " charset " in params : NEW_LINE INDENT encoding = params [ ' charset ' ] NEW_LINE DEDENT DEDENT self . content = content NEW_LINE self . parsed = html5lib . parse ( self . content , encoding = encoding , namespaceHTMLElements = False , ) NEW_LINE self . url = url NEW_LINE self . headers = headers NEW_LINE self . trusted = trusted NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return self . url NEW_LINE DEDENT @ classmethod NEW_LINE def get_page ( cls , link , skip_archives = True , session = None ) : NEW_LINE INDENT if session is None : NEW_LINE INDENT raise TypeError ( " get _ page ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ ' session ' " ) NEW_LINE DEDENT url = link . url NEW_LINE url = url . split ( ' # ' , 1 ) [ 0 ] NEW_LINE # ▁ Check ▁ for ▁ VCS ▁ schemes ▁ that ▁ do ▁ not ▁ support ▁ lookup ▁ as ▁ web ▁ pages . ENDCOM from pip . vcs import VcsSupport NEW_LINE for scheme in VcsSupport . schemes : NEW_LINE INDENT if url . lower ( ) . startswith ( scheme ) and url [ len ( scheme ) ] in ' + : ' : NEW_LINE INDENT logger . debug ( ' Cannot ▁ look ▁ at ▁ % s ▁ URL ▁ % s ' , scheme , link ) NEW_LINE return None NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT if skip_archives : NEW_LINE INDENT filename = link . filename NEW_LINE for bad_ext in ARCHIVE_EXTENSIONS : NEW_LINE INDENT if filename . endswith ( bad_ext ) : NEW_LINE INDENT content_type = cls . _get_content_type ( url , session = session , ) NEW_LINE if content_type . lower ( ) . startswith ( ' text / html ' ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT DEDENT DEDENT DEDENT logger . debug ( ' Getting ▁ page ▁ % s ' , url ) NEW_LINE # ▁ Tack ▁ index . html ▁ onto ▁ file : / / ▁ URLs ▁ that ▁ point ▁ to ▁ directories ENDCOM ( scheme , netloc , path , params , query , fragment ) = urllib_parse . urlparse ( url ) NEW_LINE if ( scheme == ' file ' and os . path . isdir ( urllib_request . url2pathname ( path ) ) ) : NEW_LINE # ▁ add ▁ trailing ▁ slash ▁ if ▁ not ▁ present ▁ so ▁ urljoin ▁ doesn ' t ▁ trim ENDCOM # ▁ final ▁ segment ENDCOM INDENT if not url . endswith ( ' / ' ) : NEW_LINE INDENT url += ' / ' NEW_LINE DEDENT url = urllib_parse . urljoin ( url , ' index . html ' ) NEW_LINE logger . debug ( ' ▁ file : ▁ URL ▁ is ▁ directory , ▁ getting ▁ % s ' , url ) NEW_LINE DEDENT resp = session . get ( url , headers = { " Accept " : " text / html " , " Cache - Control " : " max - age = 600" , } , ) NEW_LINE resp . raise_for_status ( ) NEW_LINE # ▁ The ▁ check ▁ for ▁ archives ▁ above ▁ only ▁ works ▁ if ▁ the ▁ url ▁ ends ▁ with ENDCOM # ▁ something ▁ that ▁ looks ▁ like ▁ an ▁ archive . ▁ However ▁ that ▁ is ▁ not ▁ a ENDCOM # ▁ requirement ▁ of ▁ an ▁ url . ▁ Unless ▁ we ▁ issue ▁ a ▁ HEAD ▁ request ▁ on ▁ every ENDCOM # ▁ url ▁ we ▁ cannot ▁ know ▁ ahead ▁ of ▁ time ▁ for ▁ sure ▁ if ▁ something ▁ is ▁ HTML ENDCOM # ▁ or ▁ not . ▁ However ▁ we ▁ can ▁ check ▁ after ▁ we ' ve ▁ downloaded ▁ it . ENDCOM content_type = resp . headers . get ( ' Content - Type ' , ' unknown ' ) NEW_LINE if not content_type . lower ( ) . startswith ( " text / html " ) : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT inst = cls ( resp . content , resp . url , resp . headers , trusted = link . trusted , ) NEW_LINE DEDENT except requests . HTTPError as exc : NEW_LINE INDENT level = 2 if exc . response . status_code == 404 else 1 NEW_LINE cls . _handle_fail ( link , exc , url , level = level ) NEW_LINE DEDENT except requests . ConnectionError as exc : NEW_LINE INDENT cls . _handle_fail ( link , " connection ▁ error : ▁ % s " % exc , url ) NEW_LINE DEDENT except requests . Timeout : NEW_LINE INDENT cls . _handle_fail ( link , " timed ▁ out " , url ) NEW_LINE DEDENT except SSLError as exc : NEW_LINE INDENT reason = ( " There ▁ was ▁ a ▁ problem ▁ confirming ▁ the ▁ ssl ▁ certificate : ▁ " " % s " % exc ) NEW_LINE cls . _handle_fail ( link , reason , url , level = 2 , meth = logger . info ) NEW_LINE DEDENT else : NEW_LINE INDENT return inst NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def _handle_fail ( link , reason , url , level = 1 , meth = None ) : NEW_LINE INDENT if meth is None : NEW_LINE INDENT meth = logger . debug NEW_LINE DEDENT meth ( " Could ▁ not ▁ fetch ▁ URL ▁ % s : ▁ % s ▁ - ▁ skipping " , link , reason ) NEW_LINE DEDENT @ staticmethod NEW_LINE def _get_content_type ( url , session ) : NEW_LINE INDENT """ Get ▁ the ▁ Content - Type ▁ of ▁ the ▁ given ▁ url , ▁ using ▁ a ▁ HEAD ▁ request """ NEW_LINE scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( url ) NEW_LINE if scheme not in ( ' http ' , ' https ' ) : NEW_LINE # ▁ FIXME : ▁ some ▁ warning ▁ or ▁ something ? ENDCOM # ▁ assertion ▁ error ? ENDCOM INDENT return ' ' NEW_LINE DEDENT resp = session . head ( url , allow_redirects = True ) NEW_LINE resp . raise_for_status ( ) NEW_LINE return resp . headers . get ( " Content - Type " , " " ) NEW_LINE DEDENT @ cached_property NEW_LINE def api_version ( self ) : NEW_LINE INDENT metas = [ x for x in self . parsed . findall ( " . / / meta " ) if x . get ( " name " , " " ) . lower ( ) == " api - version " ] NEW_LINE if metas : NEW_LINE INDENT try : NEW_LINE INDENT return int ( metas [ 0 ] . get ( " value " , None ) ) NEW_LINE DEDENT except ( TypeError , ValueError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT @ cached_property NEW_LINE def base_url ( self ) : NEW_LINE INDENT bases = [ x for x in self . parsed . findall ( " . / / base " ) if x . get ( " href " ) is not None ] NEW_LINE if bases and bases [ 0 ] . get ( " href " ) : NEW_LINE INDENT return bases [ 0 ] . get ( " href " ) NEW_LINE DEDENT else : NEW_LINE INDENT return self . url NEW_LINE DEDENT DEDENT @ property NEW_LINE def links ( self ) : NEW_LINE INDENT """ Yields ▁ all ▁ links ▁ in ▁ the ▁ page """ NEW_LINE for anchor in self . parsed . findall ( " . / / a " ) : NEW_LINE INDENT if anchor . get ( " href " ) : NEW_LINE INDENT href = anchor . get ( " href " ) NEW_LINE url = self . clean_link ( urllib_parse . urljoin ( self . base_url , href ) ) NEW_LINE # ▁ Determine ▁ if ▁ this ▁ link ▁ is ▁ internal . ▁ If ▁ that ▁ distinction ENDCOM # ▁ doesn ' t ▁ make ▁ sense ▁ in ▁ this ▁ context , ▁ then ▁ we ▁ don ' t ▁ make ENDCOM # ▁ any ▁ distinction . ENDCOM internal = None NEW_LINE if self . api_version and self . api_version >= 2 : NEW_LINE # ▁ Only ▁ api _ versions ▁ > = ▁ 2 ▁ have ▁ a ▁ distinction ▁ between ENDCOM # ▁ external ▁ and ▁ internal ▁ links ENDCOM INDENT internal = bool ( anchor . get ( " rel " ) and " internal " in anchor . get ( " rel " ) . split ( ) ) NEW_LINE DEDENT yield Link ( url , self , internal = internal ) NEW_LINE DEDENT DEDENT DEDENT def rel_links ( self , rels = ( ' homepage ' , ' download ' ) ) : NEW_LINE INDENT """ Yields ▁ all ▁ links ▁ with ▁ the ▁ given ▁ relations """ NEW_LINE rels = set ( rels ) NEW_LINE for anchor in self . parsed . findall ( " . / / a " ) : NEW_LINE INDENT if anchor . get ( " rel " ) and anchor . get ( " href " ) : NEW_LINE INDENT found_rels = set ( anchor . get ( " rel " ) . split ( ) ) NEW_LINE # ▁ Determine ▁ the ▁ intersection ▁ between ▁ what ▁ rels ▁ were ▁ found ▁ and ENDCOM # ▁ what ▁ rels ▁ were ▁ being ▁ looked ▁ for ENDCOM if found_rels & rels : NEW_LINE INDENT href = anchor . get ( " href " ) NEW_LINE url = self . clean_link ( urllib_parse . urljoin ( self . base_url , href ) ) NEW_LINE yield Link ( url , self , trusted = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT _clean_re = re . compile ( r ' [ ^ a - z0-9 $ & + , / : ; = ? @ . # % _ \\ | - ] ' , re . I ) NEW_LINE def clean_link ( self , url ) : NEW_LINE INDENT """ Makes ▁ sure ▁ a ▁ link ▁ is ▁ fully ▁ encoded . ▁ That ▁ is , ▁ if ▁ a ▁ ' ▁ ' ▁ shows ▁ up ▁ in STRNEWLINE ▁ the ▁ link , ▁ it ▁ will ▁ be ▁ rewritten ▁ to ▁ % 20 ▁ ( while ▁ not ▁ over - quoting STRNEWLINE ▁ % ▁ or ▁ other ▁ characters ) . """ NEW_LINE return self . _clean_re . sub ( lambda match : ' % % % 2x ' % ord ( match . group ( 0 ) ) , url ) NEW_LINE DEDENT DEDENT class Link ( object ) : NEW_LINE INDENT def __init__ ( self , url , comes_from = None , internal = None , trusted = None ) : NEW_LINE # ▁ url ▁ can ▁ be ▁ a ▁ UNC ▁ windows ▁ share ENDCOM INDENT if url != Inf and url . startswith ( ' \\\\ ' ) : NEW_LINE INDENT url = path_to_url ( url ) NEW_LINE DEDENT self . url = url NEW_LINE self . comes_from = comes_from NEW_LINE self . internal = internal NEW_LINE self . trusted = trusted NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT if self . comes_from : NEW_LINE INDENT return ' % s ▁ ( from ▁ % s ) ' % ( self . url , self . comes_from ) NEW_LINE DEDENT else : NEW_LINE INDENT return str ( self . url ) NEW_LINE DEDENT DEDENT def __repr__ ( self ) : NEW_LINE INDENT return ' < Link ▁ % s > ' % self NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url == other . url NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url != other . url NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url < other . url NEW_LINE DEDENT def __le__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url <= other . url NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url > other . url NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url >= other . url NEW_LINE DEDENT def __hash__ ( self ) : NEW_LINE INDENT return hash ( self . url ) NEW_LINE DEDENT @ property NEW_LINE def filename ( self ) : NEW_LINE INDENT _ , netloc , path , _ , _ = urllib_parse . urlsplit ( self . url ) NEW_LINE name = posixpath . basename ( path . rstrip ( ' / ' ) ) or netloc NEW_LINE name = urllib_parse . unquote ( name ) NEW_LINE assert name , ( ' URL ▁ % r ▁ produced ▁ no ▁ filename ' % self . url ) NEW_LINE return name NEW_LINE DEDENT @ property NEW_LINE def scheme ( self ) : NEW_LINE INDENT return urllib_parse . urlsplit ( self . url ) [ 0 ] NEW_LINE DEDENT @ property NEW_LINE def netloc ( self ) : NEW_LINE INDENT return urllib_parse . urlsplit ( self . url ) [ 1 ] NEW_LINE DEDENT @ property NEW_LINE def path ( self ) : NEW_LINE INDENT return urllib_parse . unquote ( urllib_parse . urlsplit ( self . url ) [ 2 ] ) NEW_LINE DEDENT def splitext ( self ) : NEW_LINE INDENT return splitext ( posixpath . basename ( self . path . rstrip ( ' / ' ) ) ) NEW_LINE DEDENT @ property NEW_LINE def ext ( self ) : NEW_LINE INDENT return self . splitext ( ) [ 1 ] NEW_LINE DEDENT @ property NEW_LINE def url_without_fragment ( self ) : NEW_LINE INDENT scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( self . url ) NEW_LINE return urllib_parse . urlunsplit ( ( scheme , netloc , path , query , None ) ) NEW_LINE DEDENT _egg_fragment_re = re . compile ( r ' # egg = ( [ ^ & ] * ) ' ) NEW_LINE @ property NEW_LINE def egg_fragment ( self ) : NEW_LINE INDENT match = self . _egg_fragment_re . search ( self . url ) NEW_LINE if not match : NEW_LINE INDENT return None NEW_LINE DEDENT return match . group ( 1 ) NEW_LINE DEDENT _hash_re = re . compile ( r ' ( sha1 | sha224 | sha384 | sha256 | sha512 | md5 ) = ( [ a - f0-9 ] + ) ' ) NEW_LINE @ property NEW_LINE def hash ( self ) : NEW_LINE INDENT match = self . _hash_re . search ( self . url ) NEW_LINE if match : NEW_LINE INDENT return match . group ( 2 ) NEW_LINE DEDENT return None NEW_LINE DEDENT @ property NEW_LINE def hash_name ( self ) : NEW_LINE INDENT match = self . _hash_re . search ( self . url ) NEW_LINE if match : NEW_LINE INDENT return match . group ( 1 ) NEW_LINE DEDENT return None NEW_LINE DEDENT @ property NEW_LINE def show_url ( self ) : NEW_LINE INDENT return posixpath . basename ( self . url . split ( ' # ' , 1 ) [ 0 ] . split ( ' ? ' , 1 ) [ 0 ] ) NEW_LINE DEDENT @ property NEW_LINE def verifiable ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Returns ▁ True ▁ if ▁ this ▁ link ▁ can ▁ be ▁ verified ▁ after ▁ download , ▁ False ▁ if ▁ it STRNEWLINE ▁ cannot , ▁ and ▁ None ▁ if ▁ we ▁ cannot ▁ determine . STRNEWLINE ▁ """ NEW_LINE trusted = self . trusted or getattr ( self . comes_from , " trusted " , None ) NEW_LINE if trusted is not None and trusted : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ a ▁ trusted ▁ source . ▁ It ▁ * may * ▁ be ▁ verifiable ▁ but ENDCOM # ▁ first ▁ we ▁ need ▁ to ▁ see ▁ if ▁ this ▁ page ▁ is ▁ operating ▁ under ▁ the ▁ new ENDCOM # ▁ API ▁ version . ENDCOM INDENT try : NEW_LINE INDENT api_version = getattr ( self . comes_from , " api _ version " , None ) NEW_LINE api_version = int ( api_version ) NEW_LINE DEDENT except ( ValueError , TypeError ) : NEW_LINE INDENT api_version = None NEW_LINE DEDENT if api_version is None or api_version <= 1 : NEW_LINE # ▁ This ▁ link ▁ is ▁ either ▁ trusted , ▁ or ▁ it ▁ came ▁ from ▁ a ▁ trusted , ENDCOM # ▁ however ▁ it ▁ is ▁ not ▁ operating ▁ under ▁ the ▁ API ▁ version ▁ 2 ▁ so ENDCOM # ▁ we ▁ can ' t ▁ make ▁ any ▁ claims ▁ about ▁ if ▁ it ' s ▁ safe ▁ or ▁ not ENDCOM INDENT return NEW_LINE DEDENT if self . hash : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ a ▁ trusted ▁ source ▁ and ▁ it ▁ has ▁ a ▁ hash , ▁ so ▁ we ENDCOM # ▁ can ▁ consider ▁ it ▁ safe . ENDCOM INDENT return True NEW_LINE DEDENT else : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ a ▁ trusted ▁ source , ▁ using ▁ the ▁ new ▁ API ENDCOM # ▁ version , ▁ and ▁ it ▁ does ▁ not ▁ have ▁ a ▁ hash . ▁ It ▁ is ▁ NOT ▁ verifiable ENDCOM INDENT return False NEW_LINE DEDENT DEDENT elif trusted is not None : NEW_LINE # ▁ This ▁ link ▁ came ▁ from ▁ an ▁ untrusted ▁ source ▁ and ▁ we ▁ cannot ▁ trust ▁ it ENDCOM INDENT return False NEW_LINE DEDENT DEDENT @ property NEW_LINE def is_wheel ( self ) : NEW_LINE INDENT return self . ext == wheel_ext NEW_LINE DEDENT @ property NEW_LINE def is_artifact ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ Determines ▁ if ▁ this ▁ points ▁ to ▁ an ▁ actual ▁ artifact ▁ ( e . g . ▁ a ▁ tarball ) ▁ or ▁ if STRNEWLINE ▁ it ▁ points ▁ to ▁ an ▁ " abstract " ▁ thing ▁ like ▁ a ▁ path ▁ or ▁ a ▁ VCS ▁ location . STRNEWLINE ▁ """ NEW_LINE from pip . vcs import vcs NEW_LINE if self . scheme in vcs . all_schemes : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE # ▁ An ▁ object ▁ to ▁ represent ▁ the ▁ " link " ▁ for ▁ the ▁ installed ▁ version ▁ of ▁ a ▁ requirement . ENDCOM # ▁ Using ▁ Inf ▁ as ▁ the ▁ url ▁ makes ▁ it ▁ sort ▁ higher . ENDCOM DEDENT DEDENT INSTALLED_VERSION = Link ( Inf ) NEW_LINE FormatControl = namedtuple ( ' FormatControl ' , ' no _ binary ▁ only _ binary ' ) NEW_LINE """ This ▁ object ▁ has ▁ two ▁ fields , ▁ no _ binary ▁ and ▁ only _ binary . STRNEWLINE STRNEWLINE If ▁ a ▁ field ▁ is ▁ falsy , ▁ it ▁ isn ' t ▁ set . ▁ If ▁ it ▁ is ▁ { ' : all : ' } , ▁ it ▁ should ▁ match ▁ all STRNEWLINE packages ▁ except ▁ those ▁ listed ▁ in ▁ the ▁ other ▁ field . ▁ Only ▁ one ▁ field ▁ can ▁ be ▁ set STRNEWLINE to ▁ { ' : all : ' } ▁ at ▁ a ▁ time . ▁ The ▁ rest ▁ of ▁ the ▁ time ▁ exact ▁ package ▁ name ▁ matches STRNEWLINE are ▁ listed , ▁ with ▁ any ▁ given ▁ package ▁ only ▁ showing ▁ up ▁ in ▁ one ▁ field ▁ at ▁ a ▁ time . STRNEWLINE """ NEW_LINE def fmt_ctl_handle_mutual_exclude ( value , target , other ) : NEW_LINE INDENT new = value . split ( ' , ' ) NEW_LINE while ' : all : ' in new : NEW_LINE INDENT other . clear ( ) NEW_LINE target . clear ( ) NEW_LINE target . add ( ' : all : ' ) NEW_LINE del new [ : new . index ( ' : all : ' ) + 1 ] NEW_LINE if ' : none : ' not in new : NEW_LINE # ▁ Without ▁ a ▁ none , ▁ we ▁ want ▁ to ▁ discard ▁ everything ▁ as ▁ : all : ▁ covers ▁ it ENDCOM INDENT return NEW_LINE DEDENT DEDENT for name in new : NEW_LINE INDENT if name == ' : none : ' : NEW_LINE INDENT target . clear ( ) NEW_LINE continue NEW_LINE DEDENT name = pkg_resources . safe_name ( name ) . lower ( ) NEW_LINE other . discard ( name ) NEW_LINE target . add ( name ) NEW_LINE DEDENT DEDENT def fmt_ctl_formats ( fmt_ctl , canonical_name ) : NEW_LINE INDENT result = set ( [ " binary " , " source " ] ) NEW_LINE if canonical_name in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif canonical_name in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT return frozenset ( result ) NEW_LINE DEDENT def fmt_ctl_no_binary ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_handle_mutual_exclude ( ' : all : ' , fmt_ctl . no_binary , fmt_ctl . only_binary ) NEW_LINE DEDENT def fmt_ctl_no_use_wheel ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_no_binary ( fmt_ctl ) NEW_LINE warnings . warn ( ' - - no - use - wheel ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ removed ▁ in ▁ the ▁ future . ▁ ' ' ▁ Please ▁ use ▁ - - no - binary ▁ : all : ▁ instead . ' , DeprecationWarning , stacklevel = 2 ) NEW_LINE DEDENT Search = namedtuple ( ' Search ' , ' supplied ▁ canonical ▁ formats ' ) NEW_LINE """ Capture ▁ key ▁ aspects ▁ of ▁ a ▁ search . STRNEWLINE STRNEWLINE : attribute ▁ supplied : ▁ The ▁ user ▁ supplied ▁ package . STRNEWLINE : attribute ▁ canonical : ▁ The ▁ canonical ▁ package ▁ name . STRNEWLINE : attribute ▁ formats : ▁ The ▁ formats ▁ allowed ▁ for ▁ this ▁ package . ▁ Should ▁ be ▁ a ▁ set STRNEWLINE ▁ with ▁ ' binary ' ▁ or ▁ ' source ' ▁ or ▁ both ▁ in ▁ it . STRNEWLINE """ NEW_LINE </DOCUMENT>
<DOCUMENT_ID="coronary/RandomEpisode/tree/master/depends/Lib/encodings/cp1006.py"> """ ▁ Python ▁ Character ▁ Mapping ▁ Codec ▁ cp1006 ▁ generated ▁ from ▁ ' MAPPINGS / VENDORS / MISC / CP1006 . TXT ' ▁ with ▁ gencodec . py . STRNEWLINE STRNEWLINE """ NEW_LINE import codecs NEW_LINE # # # ▁ Codec ▁ APIs ENDCOM class Codec ( codecs . Codec ) : NEW_LINE INDENT def encode ( self , input , errors = ' strict ' ) : NEW_LINE INDENT return codecs . charmap_encode ( input , errors , encoding_table ) NEW_LINE DEDENT def decode ( self , input , errors = ' strict ' ) : NEW_LINE INDENT return codecs . charmap_decode ( input , errors , decoding_table ) NEW_LINE DEDENT DEDENT class IncrementalEncoder ( codecs . IncrementalEncoder ) : NEW_LINE INDENT def encode ( self , input , final = False ) : NEW_LINE INDENT return codecs . charmap_encode ( input , self . errors , encoding_table ) [ 0 ] NEW_LINE DEDENT DEDENT class IncrementalDecoder ( codecs . IncrementalDecoder ) : NEW_LINE INDENT def decode ( self , input , final = False ) : NEW_LINE INDENT return codecs . charmap_decode ( input , self . errors , decoding_table ) [ 0 ] NEW_LINE DEDENT DEDENT class StreamWriter ( Codec , codecs . StreamWriter ) : NEW_LINE INDENT pass NEW_LINE DEDENT class StreamReader ( Codec , codecs . StreamReader ) : NEW_LINE INDENT pass NEW_LINE # # # ▁ encodings ▁ module ▁ API ENDCOM DEDENT def getregentry ( ) : NEW_LINE INDENT return codecs . CodecInfo ( name = ' cp1006' , encode = Codec ( ) . encode , decode = Codec ( ) . decode , incrementalencoder = IncrementalEncoder , incrementaldecoder = IncrementalDecoder , streamreader = StreamReader , streamwriter = StreamWriter , ) NEW_LINE # # # ▁ Decoding ▁ Table ENDCOM DEDENT decoding_table = ( ' \x00' # ▁ 0x00 ▁ - > ▁ NULL ENDCOM ' \x01' # ▁ 0x01 ▁ - > ▁ START ▁ OF ▁ HEADING ENDCOM ' \x02' # ▁ 0x02 ▁ - > ▁ START ▁ OF ▁ TEXT ENDCOM ' \x03' # ▁ 0x03 ▁ - > ▁ END ▁ OF ▁ TEXT ENDCOM ' \x04' # ▁ 0x04 ▁ - > ▁ END ▁ OF ▁ TRANSMISSION ENDCOM ' \x05' # ▁ 0x05 ▁ - > ▁ ENQUIRY ENDCOM ' \x06' # ▁ 0x06 ▁ - > ▁ ACKNOWLEDGE ENDCOM ' \x07' # ▁ 0x07 ▁ - > ▁ BELL ENDCOM ' \x08' # ▁ 0x08 ▁ - > ▁ BACKSPACE ENDCOM ' \t ' # ▁ 0x09 ▁ - > ▁ HORIZONTAL ▁ TABULATION ENDCOM ' \n ' # ▁ 0x0A ▁ - > ▁ LINE ▁ FEED ENDCOM ' \x0b ' # ▁ 0x0B ▁ - > ▁ VERTICAL ▁ TABULATION ENDCOM ' \x0c ' # ▁ 0x0C ▁ - > ▁ FORM ▁ FEED ENDCOM ' ' # ▁ 0x0D ▁ - > ▁ CARRIAGE ▁ RETURN ENDCOM ' \x0e ' # ▁ 0x0E ▁ - > ▁ SHIFT ▁ OUT ENDCOM ' \x0f ' # ▁ 0x0F ▁ - > ▁ SHIFT ▁ IN ENDCOM ' \x10' # ▁ 0x10 ▁ - > ▁ DATA ▁ LINK ▁ ESCAPE ENDCOM ' \x11' # ▁ 0x11 ▁ - > ▁ DEVICE ▁ CONTROL ▁ ONE ENDCOM ' \x12' # ▁ 0x12 ▁ - > ▁ DEVICE ▁ CONTROL ▁ TWO ENDCOM ' \x13' # ▁ 0x13 ▁ - > ▁ DEVICE ▁ CONTROL ▁ THREE ENDCOM ' \x14' # ▁ 0x14 ▁ - > ▁ DEVICE ▁ CONTROL ▁ FOUR ENDCOM ' \x15' # ▁ 0x15 ▁ - > ▁ NEGATIVE ▁ ACKNOWLEDGE ENDCOM ' \x16' # ▁ 0x16 ▁ - > ▁ SYNCHRONOUS ▁ IDLE ENDCOM ' \x17' # ▁ 0x17 ▁ - > ▁ END ▁ OF ▁ TRANSMISSION ▁ BLOCK ENDCOM ' \x18' # ▁ 0x18 ▁ - > ▁ CANCEL ENDCOM ' \x19' # ▁ 0x19 ▁ - > ▁ END ▁ OF ▁ MEDIUM ENDCOM ' \x1a ' # ▁ 0x1A ▁ - > ▁ SUBSTITUTE ENDCOM ' \x1b ' # ▁ 0x1B ▁ - > ▁ ESCAPE ENDCOM ' \x1c ' # ▁ 0x1C ▁ - > ▁ FILE ▁ SEPARATOR ENDCOM ' \x1d ' # ▁ 0x1D ▁ - > ▁ GROUP ▁ SEPARATOR ENDCOM ' \x1e ' # ▁ 0x1E ▁ - > ▁ RECORD ▁ SEPARATOR ENDCOM ' \x1f ' # ▁ 0x1F ▁ - > ▁ UNIT ▁ SEPARATOR ENDCOM ' ▁ ' # ▁ 0x20 ▁ - > ▁ SPACE ENDCOM ' ! ' # ▁ 0x21 ▁ - > ▁ EXCLAMATION ▁ MARK ENDCOM ' " ' # ▁ 0x22 ▁ - > ▁ QUOTATION ▁ MARK ENDCOM ' # ' # ▁ 0x23 ▁ - > ▁ NUMBER ▁ SIGN ENDCOM ' $ ' # ▁ 0x24 ▁ - > ▁ DOLLAR ▁ SIGN ENDCOM ' % ' # ▁ 0x25 ▁ - > ▁ PERCENT ▁ SIGN ENDCOM ' & ' # ▁ 0x26 ▁ - > ▁ AMPERSAND ENDCOM " ' " # ▁ 0x27 ▁ - > ▁ APOSTROPHE ENDCOM ' ( ' # ▁ 0x28 ▁ - > ▁ LEFT ▁ PARENTHESIS ENDCOM ' ) ' # ▁ 0x29 ▁ - > ▁ RIGHT ▁ PARENTHESIS ENDCOM ' * ' # ▁ 0x2A ▁ - > ▁ ASTERISK ENDCOM ' + ' # ▁ 0x2B ▁ - > ▁ PLUS ▁ SIGN ENDCOM ' , ' # ▁ 0x2C ▁ - > ▁ COMMA ENDCOM ' - ' # ▁ 0x2D ▁ - > ▁ HYPHEN - MINUS ENDCOM ' . ' # ▁ 0x2E ▁ - > ▁ FULL ▁ STOP ENDCOM ' / ' # ▁ 0x2F ▁ - > ▁ SOLIDUS ENDCOM '0' # ▁ 0x30 ▁ - > ▁ DIGIT ▁ ZERO ENDCOM '1' # ▁ 0x31 ▁ - > ▁ DIGIT ▁ ONE ENDCOM '2' # ▁ 0x32 ▁ - > ▁ DIGIT ▁ TWO ENDCOM '3' # ▁ 0x33 ▁ - > ▁ DIGIT ▁ THREE ENDCOM '4' # ▁ 0x34 ▁ - > ▁ DIGIT ▁ FOUR ENDCOM '5' # ▁ 0x35 ▁ - > ▁ DIGIT ▁ FIVE ENDCOM '6' # ▁ 0x36 ▁ - > ▁ DIGIT ▁ SIX ENDCOM '7' # ▁ 0x37 ▁ - > ▁ DIGIT ▁ SEVEN ENDCOM '8' # ▁ 0x38 ▁ - > ▁ DIGIT ▁ EIGHT ENDCOM '9' # ▁ 0x39 ▁ - > ▁ DIGIT ▁ NINE ENDCOM ' : ' # ▁ 0x3A ▁ - > ▁ COLON ENDCOM ' ; ' # ▁ 0x3B ▁ - > ▁ SEMICOLON ENDCOM ' < ' # ▁ 0x3C ▁ - > ▁ LESS - THAN ▁ SIGN ENDCOM ' = ' # ▁ 0x3D ▁ - > ▁ EQUALS ▁ SIGN ENDCOM ' > ' # ▁ 0x3E ▁ - > ▁ GREATER - THAN ▁ SIGN ENDCOM ' ? ' # ▁ 0x3F ▁ - > ▁ QUESTION ▁ MARK ENDCOM ' @ ' # ▁ 0x40 ▁ - > ▁ COMMERCIAL ▁ AT ENDCOM ' A ' # ▁ 0x41 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ A ENDCOM ' B ' # ▁ 0x42 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ B ENDCOM ' C ' # ▁ 0x43 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ C ENDCOM ' D ' # ▁ 0x44 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ D ENDCOM ' E ' # ▁ 0x45 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ E ENDCOM ' F ' # ▁ 0x46 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ F ENDCOM ' G ' # ▁ 0x47 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ G ENDCOM ' H ' # ▁ 0x48 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ H ENDCOM ' I ' # ▁ 0x49 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ I ENDCOM ' J ' # ▁ 0x4A ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ J ENDCOM ' K ' # ▁ 0x4B ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ K ENDCOM ' L ' # ▁ 0x4C ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ L ENDCOM ' M ' # ▁ 0x4D ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ M ENDCOM ' N ' # ▁ 0x4E ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ N ENDCOM ' O ' # ▁ 0x4F ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ O ENDCOM ' P ' # ▁ 0x50 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ P ENDCOM ' Q ' # ▁ 0x51 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ Q ENDCOM ' R ' # ▁ 0x52 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ R ENDCOM ' S ' # ▁ 0x53 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ S ENDCOM ' T ' # ▁ 0x54 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ T ENDCOM ' U ' # ▁ 0x55 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ U ENDCOM ' V ' # ▁ 0x56 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ V ENDCOM ' W ' # ▁ 0x57 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ W ENDCOM ' X ' # ▁ 0x58 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ X ENDCOM ' Y ' # ▁ 0x59 ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ Y ENDCOM ' Z ' # ▁ 0x5A ▁ - > ▁ LATIN ▁ CAPITAL ▁ LETTER ▁ Z ENDCOM ' [ ' # ▁ 0x5B ▁ - > ▁ LEFT ▁ SQUARE ▁ BRACKET ENDCOM ' \\ ' # ▁ 0x5C ▁ - > ▁ REVERSE ▁ SOLIDUS ENDCOM ' ] ' # ▁ 0x5D ▁ - > ▁ RIGHT ▁ SQUARE ▁ BRACKET ENDCOM ' ^ ' # ▁ 0x5E ▁ - > ▁ CIRCUMFLEX ▁ ACCENT ENDCOM ' _ ' # ▁ 0x5F ▁ - > ▁ LOW ▁ LINE ENDCOM ' ` ' # ▁ 0x60 ▁ - > ▁ GRAVE ▁ ACCENT ENDCOM ' a ' # ▁ 0x61 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ A ENDCOM ' b ' # ▁ 0x62 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ B ENDCOM ' c ' # ▁ 0x63 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ C ENDCOM ' d ' # ▁ 0x64 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ D ENDCOM ' e ' # ▁ 0x65 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ E ENDCOM ' f ' # ▁ 0x66 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ F ENDCOM ' g ' # ▁ 0x67 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ G ENDCOM ' h ' # ▁ 0x68 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ H ENDCOM ' i ' # ▁ 0x69 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ I ENDCOM ' j ' # ▁ 0x6A ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ J ENDCOM ' k ' # ▁ 0x6B ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ K ENDCOM ' l ' # ▁ 0x6C ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ L ENDCOM ' m ' # ▁ 0x6D ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ M ENDCOM ' n ' # ▁ 0x6E ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ N ENDCOM ' o ' # ▁ 0x6F ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ O ENDCOM ' p ' # ▁ 0x70 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ P ENDCOM ' q ' # ▁ 0x71 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ Q ENDCOM ' r ' # ▁ 0x72 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ R ENDCOM ' s ' # ▁ 0x73 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ S ENDCOM ' t ' # ▁ 0x74 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ T ENDCOM ' u ' # ▁ 0x75 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ U ENDCOM ' v ' # ▁ 0x76 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ V ENDCOM ' w ' # ▁ 0x77 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ W ENDCOM ' x ' # ▁ 0x78 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ X ENDCOM ' y ' # ▁ 0x79 ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ Y ENDCOM ' z ' # ▁ 0x7A ▁ - > ▁ LATIN ▁ SMALL ▁ LETTER ▁ Z ENDCOM ' { ' # ▁ 0x7B ▁ - > ▁ LEFT ▁ CURLY ▁ BRACKET ENDCOM ' | ' # ▁ 0x7C ▁ - > ▁ VERTICAL ▁ LINE ENDCOM ' } ' # ▁ 0x7D ▁ - > ▁ RIGHT ▁ CURLY ▁ BRACKET ENDCOM ' ~ ' # ▁ 0x7E ▁ - > ▁ TILDE ENDCOM ' \x7f ' # ▁ 0x7F ▁ - > ▁ DELETE ENDCOM ' \x80' # ▁ 0x80 ▁ - > ▁ < control > ENDCOM ' \x81' # ▁ 0x81 ▁ - > ▁ < control > ENDCOM ' \x82' # ▁ 0x82 ▁ - > ▁ < control > ENDCOM ' \x83' # ▁ 0x83 ▁ - > ▁ < control > ENDCOM ' \x84' # ▁ 0x84 ▁ - > ▁ < control > ENDCOM ' \x85' # ▁ 0x85 ▁ - > ▁ < control > ENDCOM ' \x86' # ▁ 0x86 ▁ - > ▁ < control > ENDCOM ' \x87' # ▁ 0x87 ▁ - > ▁ < control > ENDCOM ' \x88' # ▁ 0x88 ▁ - > ▁ < control > ENDCOM ' \x89' # ▁ 0x89 ▁ - > ▁ < control > ENDCOM ' \x8a ' # ▁ 0x8A ▁ - > ▁ < control > ENDCOM ' \x8b ' # ▁ 0x8B ▁ - > ▁ < control > ENDCOM ' \x8c ' # ▁ 0x8C ▁ - > ▁ < control > ENDCOM ' \x8d ' # ▁ 0x8D ▁ - > ▁ < control > ENDCOM ' \x8e ' # ▁ 0x8E ▁ - > ▁ < control > ENDCOM ' \x8f ' # ▁ 0x8F ▁ - > ▁ < control > ENDCOM ' \x90' # ▁ 0x90 ▁ - > ▁ < control > ENDCOM ' \x91' # ▁ 0x91 ▁ - > ▁ < control > ENDCOM ' \x92' # ▁ 0x92 ▁ - > ▁ < control > ENDCOM ' \x93' # ▁ 0x93 ▁ - > ▁ < control > ENDCOM ' \x94' # ▁ 0x94 ▁ - > ▁ < control > ENDCOM ' \x95' # ▁ 0x95 ▁ - > ▁ < control > ENDCOM ' \x96' # ▁ 0x96 ▁ - > ▁ < control > ENDCOM ' \x97' # ▁ 0x97 ▁ - > ▁ < control > ENDCOM ' \x98' # ▁ 0x98 ▁ - > ▁ < control > ENDCOM ' \x99' # ▁ 0x99 ▁ - > ▁ < control > ENDCOM ' \x9a ' # ▁ 0x9A ▁ - > ▁ < control > ENDCOM ' \x9b ' # ▁ 0x9B ▁ - > ▁ < control > ENDCOM ' \x9c ' # ▁ 0x9C ▁ - > ▁ < control > ENDCOM ' \x9d ' # ▁ 0x9D ▁ - > ▁ < control > ENDCOM ' \x9e ' # ▁ 0x9E ▁ - > ▁ < control > ENDCOM ' \x9f ' # ▁ 0x9F ▁ - > ▁ < control > ENDCOM ' \xa0' # ▁ 0xA0 ▁ - > ▁ NO - BREAK ▁ SPACE ENDCOM ' \u06f0' # ▁ 0xA1 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ ZERO ENDCOM ' \u06f1' # ▁ 0xA2 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ ONE ENDCOM ' \u06f2' # ▁ 0xA3 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ TWO ENDCOM ' \u06f3' # ▁ 0xA4 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ THREE ENDCOM ' \u06f4' # ▁ 0xA5 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ FOUR ENDCOM ' \u06f5' # ▁ 0xA6 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ FIVE ENDCOM ' \u06f6' # ▁ 0xA7 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ SIX ENDCOM ' \u06f7' # ▁ 0xA8 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ SEVEN ENDCOM ' \u06f8' # ▁ 0xA9 ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ EIGHT ENDCOM ' \u06f9' # ▁ 0xAA ▁ - > ▁ EXTENDED ▁ ARABIC - INDIC ▁ DIGIT ▁ NINE ENDCOM ' \u060c ' # ▁ 0xAB ▁ - > ▁ ARABIC ▁ COMMA ENDCOM ' \u061b ' # ▁ 0xAC ▁ - > ▁ ARABIC ▁ SEMICOLON ENDCOM ' \xad ' # ▁ 0xAD ▁ - > ▁ SOFT ▁ HYPHEN ENDCOM ' \u061f ' # ▁ 0xAE ▁ - > ▁ ARABIC ▁ QUESTION ▁ MARK ENDCOM ' \ufe81' # ▁ 0xAF ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ WITH ▁ MADDA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe8d ' # ▁ 0xB0 ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ ISOLATED ▁ FORM ENDCOM ' \ufe8e ' # ▁ 0xB1 ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ FINAL ▁ FORM ENDCOM ' \ufe8e ' # ▁ 0xB2 ▁ - > ▁ ARABIC ▁ LETTER ▁ ALEF ▁ FINAL ▁ FORM ENDCOM ' \ufe8f ' # ▁ 0xB3 ▁ - > ▁ ARABIC ▁ LETTER ▁ BEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufe91' # ▁ 0xB4 ▁ - > ▁ ARABIC ▁ LETTER ▁ BEH ▁ INITIAL ▁ FORM ENDCOM ' \ufb56' # ▁ 0xB5 ▁ - > ▁ ARABIC ▁ LETTER ▁ PEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb58' # ▁ 0xB6 ▁ - > ▁ ARABIC ▁ LETTER ▁ PEH ▁ INITIAL ▁ FORM ENDCOM ' \ufe93' # ▁ 0xB7 ▁ - > ▁ ARABIC ▁ LETTER ▁ TEH ▁ MARBUTA ▁ ISOLATED ▁ FORM ENDCOM ' \ufe95' # ▁ 0xB8 ▁ - > ▁ ARABIC ▁ LETTER ▁ TEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufe97' # ▁ 0xB9 ▁ - > ▁ ARABIC ▁ LETTER ▁ TEH ▁ INITIAL ▁ FORM ENDCOM ' \ufb66' # ▁ 0xBA ▁ - > ▁ ARABIC ▁ LETTER ▁ TTEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb68' # ▁ 0xBB ▁ - > ▁ ARABIC ▁ LETTER ▁ TTEH ▁ INITIAL ▁ FORM ENDCOM ' \ufe99' # ▁ 0xBC ▁ - > ▁ ARABIC ▁ LETTER ▁ THEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufe9b ' # ▁ 0xBD ▁ - > ▁ ARABIC ▁ LETTER ▁ THEH ▁ INITIAL ▁ FORM ENDCOM ' \ufe9d ' # ▁ 0xBE ▁ - > ▁ ARABIC ▁ LETTER ▁ JEEM ▁ ISOLATED ▁ FORM ENDCOM ' \ufe9f ' # ▁ 0xBF ▁ - > ▁ ARABIC ▁ LETTER ▁ JEEM ▁ INITIAL ▁ FORM ENDCOM ' \ufb7a ' # ▁ 0xC0 ▁ - > ▁ ARABIC ▁ LETTER ▁ TCHEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb7c ' # ▁ 0xC1 ▁ - > ▁ ARABIC ▁ LETTER ▁ TCHEH ▁ INITIAL ▁ FORM ENDCOM ' \ufea1' # ▁ 0xC2 ▁ - > ▁ ARABIC ▁ LETTER ▁ HAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufea3' # ▁ 0xC3 ▁ - > ▁ ARABIC ▁ LETTER ▁ HAH ▁ INITIAL ▁ FORM ENDCOM ' \ufea5' # ▁ 0xC4 ▁ - > ▁ ARABIC ▁ LETTER ▁ KHAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufea7' # ▁ 0xC5 ▁ - > ▁ ARABIC ▁ LETTER ▁ KHAH ▁ INITIAL ▁ FORM ENDCOM ' \ufea9' # ▁ 0xC6 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAL ▁ ISOLATED ▁ FORM ENDCOM ' \ufb84' # ▁ 0xC7 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAHAL ▁ ISOLATED ▁ FORMN ENDCOM ' \ufeab ' # ▁ 0xC8 ▁ - > ▁ ARABIC ▁ LETTER ▁ THAL ▁ ISOLATED ▁ FORM ENDCOM ' \ufead ' # ▁ 0xC9 ▁ - > ▁ ARABIC ▁ LETTER ▁ REH ▁ ISOLATED ▁ FORM ENDCOM ' \ufb8c ' # ▁ 0xCA ▁ - > ▁ ARABIC ▁ LETTER ▁ RREH ▁ ISOLATED ▁ FORM ENDCOM ' \ufeaf ' # ▁ 0xCB ▁ - > ▁ ARABIC ▁ LETTER ▁ ZAIN ▁ ISOLATED ▁ FORM ENDCOM ' \ufb8a ' # ▁ 0xCC ▁ - > ▁ ARABIC ▁ LETTER ▁ JEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufeb1' # ▁ 0xCD ▁ - > ▁ ARABIC ▁ LETTER ▁ SEEN ▁ ISOLATED ▁ FORM ENDCOM ' \ufeb3' # ▁ 0xCE ▁ - > ▁ ARABIC ▁ LETTER ▁ SEEN ▁ INITIAL ▁ FORM ENDCOM ' \ufeb5' # ▁ 0xCF ▁ - > ▁ ARABIC ▁ LETTER ▁ SHEEN ▁ ISOLATED ▁ FORM ENDCOM ' \ufeb7' # ▁ 0xD0 ▁ - > ▁ ARABIC ▁ LETTER ▁ SHEEN ▁ INITIAL ▁ FORM ENDCOM ' \ufeb9' # ▁ 0xD1 ▁ - > ▁ ARABIC ▁ LETTER ▁ SAD ▁ ISOLATED ▁ FORM ENDCOM ' \ufebb ' # ▁ 0xD2 ▁ - > ▁ ARABIC ▁ LETTER ▁ SAD ▁ INITIAL ▁ FORM ENDCOM ' \ufebd ' # ▁ 0xD3 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAD ▁ ISOLATED ▁ FORM ENDCOM ' \ufebf ' # ▁ 0xD4 ▁ - > ▁ ARABIC ▁ LETTER ▁ DAD ▁ INITIAL ▁ FORM ENDCOM ' \ufec1' # ▁ 0xD5 ▁ - > ▁ ARABIC ▁ LETTER ▁ TAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufec5' # ▁ 0xD6 ▁ - > ▁ ARABIC ▁ LETTER ▁ ZAH ▁ ISOLATED ▁ FORM ENDCOM ' \ufec9' # ▁ 0xD7 ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ ISOLATED ▁ FORM ENDCOM ' \ufeca ' # ▁ 0xD8 ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ FINAL ▁ FORM ENDCOM ' \ufecb ' # ▁ 0xD9 ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ INITIAL ▁ FORM ENDCOM ' \ufecc ' # ▁ 0xDA ▁ - > ▁ ARABIC ▁ LETTER ▁ AIN ▁ MEDIAL ▁ FORM ENDCOM ' \ufecd ' # ▁ 0xDB ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ ISOLATED ▁ FORM ENDCOM ' \ufece ' # ▁ 0xDC ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ FINAL ▁ FORM ENDCOM ' \ufecf ' # ▁ 0xDD ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ INITIAL ▁ FORM ENDCOM ' \ufed0' # ▁ 0xDE ▁ - > ▁ ARABIC ▁ LETTER ▁ GHAIN ▁ MEDIAL ▁ FORM ENDCOM ' \ufed1' # ▁ 0xDF ▁ - > ▁ ARABIC ▁ LETTER ▁ FEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufed3' # ▁ 0xE0 ▁ - > ▁ ARABIC ▁ LETTER ▁ FEH ▁ INITIAL ▁ FORM ENDCOM ' \ufed5' # ▁ 0xE1 ▁ - > ▁ ARABIC ▁ LETTER ▁ QAF ▁ ISOLATED ▁ FORM ENDCOM ' \ufed7' # ▁ 0xE2 ▁ - > ▁ ARABIC ▁ LETTER ▁ QAF ▁ INITIAL ▁ FORM ENDCOM ' \ufed9' # ▁ 0xE3 ▁ - > ▁ ARABIC ▁ LETTER ▁ KAF ▁ ISOLATED ▁ FORM ENDCOM ' \ufedb ' # ▁ 0xE4 ▁ - > ▁ ARABIC ▁ LETTER ▁ KAF ▁ INITIAL ▁ FORM ENDCOM ' \ufb92' # ▁ 0xE5 ▁ - > ▁ ARABIC ▁ LETTER ▁ GAF ▁ ISOLATED ▁ FORM ENDCOM ' \ufb94' # ▁ 0xE6 ▁ - > ▁ ARABIC ▁ LETTER ▁ GAF ▁ INITIAL ▁ FORM ENDCOM ' \ufedd ' # ▁ 0xE7 ▁ - > ▁ ARABIC ▁ LETTER ▁ LAM ▁ ISOLATED ▁ FORM ENDCOM ' \ufedf ' # ▁ 0xE8 ▁ - > ▁ ARABIC ▁ LETTER ▁ LAM ▁ INITIAL ▁ FORM ENDCOM ' \ufee0' # ▁ 0xE9 ▁ - > ▁ ARABIC ▁ LETTER ▁ LAM ▁ MEDIAL ▁ FORM ENDCOM ' \ufee1' # ▁ 0xEA ▁ - > ▁ ARABIC ▁ LETTER ▁ MEEM ▁ ISOLATED ▁ FORM ENDCOM ' \ufee3' # ▁ 0xEB ▁ - > ▁ ARABIC ▁ LETTER ▁ MEEM ▁ INITIAL ▁ FORM ENDCOM ' \ufb9e ' # ▁ 0xEC ▁ - > ▁ ARABIC ▁ LETTER ▁ NOON ▁ GHUNNA ▁ ISOLATED ▁ FORM ENDCOM ' \ufee5' # ▁ 0xED ▁ - > ▁ ARABIC ▁ LETTER ▁ NOON ▁ ISOLATED ▁ FORM ENDCOM ' \ufee7' # ▁ 0xEE ▁ - > ▁ ARABIC ▁ LETTER ▁ NOON ▁ INITIAL ▁ FORM ENDCOM ' \ufe85' # ▁ 0xEF ▁ - > ▁ ARABIC ▁ LETTER ▁ WAW ▁ WITH ▁ HAMZA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufeed ' # ▁ 0xF0 ▁ - > ▁ ARABIC ▁ LETTER ▁ WAW ▁ ISOLATED ▁ FORM ENDCOM ' \ufba6' # ▁ 0xF1 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ GOAL ▁ ISOLATED ▁ FORM ENDCOM ' \ufba8' # ▁ 0xF2 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ GOAL ▁ INITIAL ▁ FORM ENDCOM ' \ufba9' # ▁ 0xF3 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ GOAL ▁ MEDIAL ▁ FORM ENDCOM ' \ufbaa ' # ▁ 0xF4 ▁ - > ▁ ARABIC ▁ LETTER ▁ HEH ▁ DOACHASHMEE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe80' # ▁ 0xF5 ▁ - > ▁ ARABIC ▁ LETTER ▁ HAMZA ▁ ISOLATED ▁ FORM ENDCOM ' \ufe89' # ▁ 0xF6 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ WITH ▁ HAMZA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe8a ' # ▁ 0xF7 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ WITH ▁ HAMZA ▁ ABOVE ▁ FINAL ▁ FORM ENDCOM ' \ufe8b ' # ▁ 0xF8 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ WITH ▁ HAMZA ▁ ABOVE ▁ INITIAL ▁ FORM ENDCOM ' \ufef1' # ▁ 0xF9 ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ ISOLATED ▁ FORM ENDCOM ' \ufef2' # ▁ 0xFA ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ FINAL ▁ FORM ENDCOM ' \ufef3' # ▁ 0xFB ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ INITIAL ▁ FORM ENDCOM ' \ufbb0' # ▁ 0xFC ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ BARREE ▁ WITH ▁ HAMZA ▁ ABOVE ▁ ISOLATED ▁ FORM ENDCOM ' \ufbae ' # ▁ 0xFD ▁ - > ▁ ARABIC ▁ LETTER ▁ YEH ▁ BARREE ▁ ISOLATED ▁ FORM ENDCOM ' \ufe7c ' # ▁ 0xFE ▁ - > ▁ ARABIC ▁ SHADDA ▁ ISOLATED ▁ FORM ENDCOM ' \ufe7d ' # ▁ 0xFF ▁ - > ▁ ARABIC ▁ SHADDA ▁ MEDIAL ▁ FORM ENDCOM ) NEW_LINE # # # ▁ Encoding ▁ table ENDCOM encoding_table = codecs . charmap_build ( decoding_table ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="fernandog/Medusa/tree/master/ext/click/termui.py"> import os NEW_LINE import sys NEW_LINE import struct NEW_LINE from . _compat import raw_input , text_type , string_types , isatty , strip_ansi , get_winterm_size , DEFAULT_COLUMNS , WIN NEW_LINE from . utils import echo NEW_LINE from . exceptions import Abort , UsageError NEW_LINE from . types import convert_type NEW_LINE from . globals import resolve_color_default NEW_LINE # ▁ The ▁ prompt ▁ functions ▁ to ▁ use . ▁ The ▁ doc ▁ tools ▁ currently ▁ override ▁ these ENDCOM # ▁ functions ▁ to ▁ customize ▁ how ▁ they ▁ work . ENDCOM visible_prompt_func = raw_input NEW_LINE _ansi_colors = ( ' black ' , ' red ' , ' green ' , ' yellow ' , ' blue ' , ' magenta ' , ' cyan ' , ' white ' , ' reset ' ) NEW_LINE _ansi_reset_all = ' \033[0m ' NEW_LINE def hidden_prompt_func ( prompt ) : NEW_LINE INDENT import getpass NEW_LINE return getpass . getpass ( prompt ) NEW_LINE DEDENT def _build_prompt ( text , suffix , show_default = False , default = None ) : NEW_LINE INDENT prompt = text NEW_LINE if default is not None and show_default : NEW_LINE INDENT prompt = ' % s ▁ [ % s ] ' % ( prompt , default ) NEW_LINE DEDENT return prompt + suffix NEW_LINE DEDENT def prompt ( text , default = None , hide_input = False , confirmation_prompt = False , type = None , value_proc = None , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT """ Prompts ▁ a ▁ user ▁ for ▁ input . ▁ This ▁ is ▁ a ▁ convenience ▁ function ▁ that ▁ can STRNEWLINE ▁ be ▁ used ▁ to ▁ prompt ▁ a ▁ user ▁ for ▁ input ▁ later . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ user ▁ aborts ▁ the ▁ input ▁ by ▁ sending ▁ a ▁ interrupt ▁ signal , ▁ this STRNEWLINE ▁ function ▁ will ▁ catch ▁ it ▁ and ▁ raise ▁ a ▁ : exc : ` Abort ` ▁ exception . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 6.0 STRNEWLINE ▁ Added ▁ unicode ▁ support ▁ for ▁ cmd . exe ▁ on ▁ Windows . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ show ▁ for ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ default : ▁ the ▁ default ▁ value ▁ to ▁ use ▁ if ▁ no ▁ input ▁ happens . ▁ If ▁ this STRNEWLINE ▁ is ▁ not ▁ given ▁ it ▁ will ▁ prompt ▁ until ▁ it ' s ▁ aborted . STRNEWLINE ▁ : param ▁ hide _ input : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ true ▁ then ▁ the ▁ input ▁ value ▁ will STRNEWLINE ▁ be ▁ hidden . STRNEWLINE ▁ : param ▁ confirmation _ prompt : ▁ asks ▁ for ▁ confirmation ▁ for ▁ the ▁ value . STRNEWLINE ▁ : param ▁ type : ▁ the ▁ type ▁ to ▁ use ▁ to ▁ check ▁ the ▁ value ▁ against . STRNEWLINE ▁ : param ▁ value _ proc : ▁ if ▁ this ▁ parameter ▁ is ▁ provided ▁ it ' s ▁ a ▁ function ▁ that STRNEWLINE ▁ is ▁ invoked ▁ instead ▁ of ▁ the ▁ type ▁ conversion ▁ to STRNEWLINE ▁ convert ▁ a ▁ value . STRNEWLINE ▁ : param ▁ prompt _ suffix : ▁ a ▁ suffix ▁ that ▁ should ▁ be ▁ added ▁ to ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ show _ default : ▁ shows ▁ or ▁ hides ▁ the ▁ default ▁ value ▁ in ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ true ▁ the ▁ file ▁ defaults ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE result = None NEW_LINE def prompt_func ( text ) : NEW_LINE INDENT f = hide_input and hidden_prompt_func or visible_prompt_func NEW_LINE try : NEW_LINE # ▁ Write ▁ the ▁ prompt ▁ separately ▁ so ▁ that ▁ we ▁ get ▁ nice ENDCOM # ▁ coloring ▁ through ▁ colorama ▁ on ▁ Windows ENDCOM INDENT echo ( text , nl = False , err = err ) NEW_LINE return f ( ' ' ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE # ▁ getpass ▁ doesn ' t ▁ print ▁ a ▁ newline ▁ if ▁ the ▁ user ▁ aborts ▁ input ▁ with ▁ ^ C . ENDCOM # ▁ Allegedly ▁ this ▁ behavior ▁ is ▁ inherited ▁ from ▁ getpass ( 3 ) . ENDCOM # ▁ A ▁ doc ▁ bug ▁ has ▁ been ▁ filed ▁ at ▁ https : / / bugs . python . org / issue24711 ENDCOM INDENT if hide_input : NEW_LINE INDENT echo ( None , err = err ) NEW_LINE DEDENT raise Abort ( ) NEW_LINE DEDENT DEDENT if value_proc is None : NEW_LINE INDENT value_proc = convert_type ( type , default ) NEW_LINE DEDENT prompt = _build_prompt ( text , prompt_suffix , show_default , default ) NEW_LINE while 1 : NEW_LINE INDENT while 1 : NEW_LINE INDENT value = prompt_func ( prompt ) NEW_LINE if value : NEW_LINE INDENT break NEW_LINE # ▁ If ▁ a ▁ default ▁ is ▁ set ▁ and ▁ used , ▁ then ▁ the ▁ confirmation ENDCOM # ▁ prompt ▁ is ▁ always ▁ skipped ▁ because ▁ that ' s ▁ the ▁ only ▁ thing ENDCOM # ▁ that ▁ really ▁ makes ▁ sense . ENDCOM DEDENT elif default is not None : NEW_LINE INDENT return default NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT result = value_proc ( value ) NEW_LINE DEDENT except UsageError as e : NEW_LINE INDENT echo ( ' Error : ▁ % s ' % e . message , err = err ) NEW_LINE continue NEW_LINE DEDENT if not confirmation_prompt : NEW_LINE INDENT return result NEW_LINE DEDENT while 1 : NEW_LINE INDENT value2 = prompt_func ( ' Repeat ▁ for ▁ confirmation : ▁ ' ) NEW_LINE if value2 : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT if value == value2 : NEW_LINE INDENT return result NEW_LINE DEDENT echo ( ' Error : ▁ the ▁ two ▁ entered ▁ values ▁ do ▁ not ▁ match ' , err = err ) NEW_LINE DEDENT DEDENT def confirm ( text , default = False , abort = False , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT """ Prompts ▁ for ▁ confirmation ▁ ( yes / no ▁ question ) . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ user ▁ aborts ▁ the ▁ input ▁ by ▁ sending ▁ a ▁ interrupt ▁ signal ▁ this STRNEWLINE ▁ function ▁ will ▁ catch ▁ it ▁ and ▁ raise ▁ a ▁ : exc : ` Abort ` ▁ exception . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ question ▁ to ▁ ask . STRNEWLINE ▁ : param ▁ default : ▁ the ▁ default ▁ for ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ abort : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ ` True ` ▁ a ▁ negative ▁ answer ▁ aborts ▁ the STRNEWLINE ▁ exception ▁ by ▁ raising ▁ : exc : ` Abort ` . STRNEWLINE ▁ : param ▁ prompt _ suffix : ▁ a ▁ suffix ▁ that ▁ should ▁ be ▁ added ▁ to ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ show _ default : ▁ shows ▁ or ▁ hides ▁ the ▁ default ▁ value ▁ in ▁ the ▁ prompt . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ true ▁ the ▁ file ▁ defaults ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE prompt = _build_prompt ( text , prompt_suffix , show_default , default and ' Y / n ' or ' y / N ' ) NEW_LINE while 1 : NEW_LINE INDENT try : NEW_LINE # ▁ Write ▁ the ▁ prompt ▁ separately ▁ so ▁ that ▁ we ▁ get ▁ nice ENDCOM # ▁ coloring ▁ through ▁ colorama ▁ on ▁ Windows ENDCOM INDENT echo ( prompt , nl = False , err = err ) NEW_LINE value = visible_prompt_func ( ' ' ) . lower ( ) . strip ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT if value in ( ' y ' , ' yes ' ) : NEW_LINE INDENT rv = True NEW_LINE DEDENT elif value in ( ' n ' , ' no ' ) : NEW_LINE INDENT rv = False NEW_LINE DEDENT elif value == ' ' : NEW_LINE INDENT rv = default NEW_LINE DEDENT else : NEW_LINE INDENT echo ( ' Error : ▁ invalid ▁ input ' , err = err ) NEW_LINE continue NEW_LINE DEDENT break NEW_LINE DEDENT if abort and not rv : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT return rv NEW_LINE DEDENT def get_terminal_size ( ) : NEW_LINE INDENT """ Returns ▁ the ▁ current ▁ size ▁ of ▁ the ▁ terminal ▁ as ▁ tuple ▁ in ▁ the ▁ form STRNEWLINE ▁ ` ` ( width , ▁ height ) ` ` ▁ in ▁ columns ▁ and ▁ rows . STRNEWLINE ▁ """ NEW_LINE # ▁ If ▁ shutil ▁ has ▁ get _ terminal _ size ( ) ▁ ( Python ▁ 3.3 ▁ and ▁ later ) ▁ use ▁ that ENDCOM if sys . version_info >= ( 3 , 3 ) : NEW_LINE INDENT import shutil NEW_LINE shutil_get_terminal_size = getattr ( shutil , ' get _ terminal _ size ' , None ) NEW_LINE if shutil_get_terminal_size : NEW_LINE INDENT sz = shutil_get_terminal_size ( ) NEW_LINE return sz . columns , sz . lines NEW_LINE DEDENT DEDENT if get_winterm_size is not None : NEW_LINE INDENT return get_winterm_size ( ) NEW_LINE DEDENT def ioctl_gwinsz ( fd ) : NEW_LINE INDENT try : NEW_LINE INDENT import fcntl NEW_LINE import termios NEW_LINE cr = struct . unpack ( ' hh ' , fcntl . ioctl ( fd , termios . TIOCGWINSZ , '1234' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return NEW_LINE DEDENT return cr NEW_LINE DEDENT cr = ioctl_gwinsz ( 0 ) or ioctl_gwinsz ( 1 ) or ioctl_gwinsz ( 2 ) NEW_LINE if not cr : NEW_LINE INDENT try : NEW_LINE INDENT fd = os . open ( os . ctermid ( ) , os . O_RDONLY ) NEW_LINE try : NEW_LINE INDENT cr = ioctl_gwinsz ( fd ) NEW_LINE DEDENT finally : NEW_LINE INDENT os . close ( fd ) NEW_LINE DEDENT DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT if not cr or not cr [ 0 ] or not cr [ 1 ] : NEW_LINE INDENT cr = ( os . environ . get ( ' LINES ' , 25 ) , os . environ . get ( ' COLUMNS ' , DEFAULT_COLUMNS ) ) NEW_LINE DEDENT return int ( cr [ 1 ] ) , int ( cr [ 0 ] ) NEW_LINE DEDENT def echo_via_pager ( text , color = None ) : NEW_LINE INDENT """ This ▁ function ▁ takes ▁ a ▁ text ▁ and ▁ shows ▁ it ▁ via ▁ an ▁ environment ▁ specific STRNEWLINE ▁ pager ▁ on ▁ stdout . STRNEWLINE STRNEWLINE ▁ . . ▁ versionchanged : : ▁ 3.0 STRNEWLINE ▁ Added ▁ the ▁ ` color ` ▁ flag . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ page . STRNEWLINE ▁ : param ▁ color : ▁ controls ▁ if ▁ the ▁ pager ▁ supports ▁ ANSI ▁ colors ▁ or ▁ not . ▁ The STRNEWLINE ▁ default ▁ is ▁ autodetection . STRNEWLINE ▁ """ NEW_LINE color = resolve_color_default ( color ) NEW_LINE if not isinstance ( text , string_types ) : NEW_LINE INDENT text = text_type ( text ) NEW_LINE DEDENT from . _termui_impl import pager NEW_LINE return pager ( text + ' \n ' , color ) NEW_LINE DEDENT def progressbar ( iterable = None , length = None , label = None , show_eta = True , show_percent = None , show_pos = False , item_show_func = None , fill_char = ' # ' , empty_char = ' - ' , bar_template = ' % ( label ) s ▁ ▁ [ % ( bar ) s ] ▁ ▁ % ( info ) s ' , info_sep = ' ▁ ▁ ' , width = 36 , file = None , color = None ) : NEW_LINE INDENT """ This ▁ function ▁ creates ▁ an ▁ iterable ▁ context ▁ manager ▁ that ▁ can ▁ be ▁ used STRNEWLINE ▁ to ▁ iterate ▁ over ▁ something ▁ while ▁ showing ▁ a ▁ progress ▁ bar . ▁ It ▁ will STRNEWLINE ▁ either ▁ iterate ▁ over ▁ the ▁ ` iterable ` ▁ or ▁ ` length ` ▁ items ▁ ( that ▁ are ▁ counted STRNEWLINE ▁ up ) . ▁ While ▁ iteration ▁ happens , ▁ this ▁ function ▁ will ▁ print ▁ a ▁ rendered STRNEWLINE ▁ progress ▁ bar ▁ to ▁ the ▁ given ▁ ` file ` ▁ ( defaults ▁ to ▁ stdout ) ▁ and ▁ will ▁ attempt STRNEWLINE ▁ to ▁ calculate ▁ remaining ▁ time ▁ and ▁ more . ▁ By ▁ default , ▁ this ▁ progress ▁ bar STRNEWLINE ▁ will ▁ not ▁ be ▁ rendered ▁ if ▁ the ▁ file ▁ is ▁ not ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ The ▁ context ▁ manager ▁ creates ▁ the ▁ progress ▁ bar . ▁ When ▁ the ▁ context STRNEWLINE ▁ manager ▁ is ▁ entered ▁ the ▁ progress ▁ bar ▁ is ▁ already ▁ displayed . ▁ With ▁ every STRNEWLINE ▁ iteration ▁ over ▁ the ▁ progress ▁ bar , ▁ the ▁ iterable ▁ passed ▁ to ▁ the ▁ bar ▁ is STRNEWLINE ▁ advanced ▁ and ▁ the ▁ bar ▁ is ▁ updated . ▁ When ▁ the ▁ context ▁ manager ▁ exits , STRNEWLINE ▁ a ▁ newline ▁ is ▁ printed ▁ and ▁ the ▁ progress ▁ bar ▁ is ▁ finalized ▁ on ▁ screen . STRNEWLINE STRNEWLINE ▁ No ▁ printing ▁ must ▁ happen ▁ or ▁ the ▁ progress ▁ bar ▁ will ▁ be ▁ unintentionally STRNEWLINE ▁ destroyed . STRNEWLINE STRNEWLINE ▁ Example ▁ usage : : STRNEWLINE STRNEWLINE ▁ with ▁ progressbar ( items ) ▁ as ▁ bar : STRNEWLINE ▁ for ▁ item ▁ in ▁ bar : STRNEWLINE ▁ do _ something _ with ( item ) STRNEWLINE STRNEWLINE ▁ Alternatively , ▁ if ▁ no ▁ iterable ▁ is ▁ specified , ▁ one ▁ can ▁ manually ▁ update ▁ the STRNEWLINE ▁ progress ▁ bar ▁ through ▁ the ▁ ` update ( ) ` ▁ method ▁ instead ▁ of ▁ directly STRNEWLINE ▁ iterating ▁ over ▁ the ▁ progress ▁ bar . ▁ The ▁ update ▁ method ▁ accepts ▁ the ▁ number STRNEWLINE ▁ of ▁ steps ▁ to ▁ increment ▁ the ▁ bar ▁ with : : STRNEWLINE STRNEWLINE ▁ with ▁ progressbar ( length = chunks . total _ bytes ) ▁ as ▁ bar : STRNEWLINE ▁ for ▁ chunk ▁ in ▁ chunks : STRNEWLINE ▁ process _ chunk ( chunk ) STRNEWLINE ▁ bar . update ( chunks . bytes ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` color ` ▁ parameter . ▁ Added ▁ a ▁ ` update ` ▁ method ▁ to ▁ the STRNEWLINE ▁ progressbar ▁ object . STRNEWLINE STRNEWLINE ▁ : param ▁ iterable : ▁ an ▁ iterable ▁ to ▁ iterate ▁ over . ▁ If ▁ not ▁ provided ▁ the ▁ length STRNEWLINE ▁ is ▁ required . STRNEWLINE ▁ : param ▁ length : ▁ the ▁ number ▁ of ▁ items ▁ to ▁ iterate ▁ over . ▁ By ▁ default ▁ the STRNEWLINE ▁ progressbar ▁ will ▁ attempt ▁ to ▁ ask ▁ the ▁ iterator ▁ about ▁ its STRNEWLINE ▁ length , ▁ which ▁ might ▁ or ▁ might ▁ not ▁ work . ▁ If ▁ an ▁ iterable ▁ is STRNEWLINE ▁ also ▁ provided ▁ this ▁ parameter ▁ can ▁ be ▁ used ▁ to ▁ override ▁ the STRNEWLINE ▁ length . ▁ If ▁ an ▁ iterable ▁ is ▁ not ▁ provided ▁ the ▁ progress ▁ bar STRNEWLINE ▁ will ▁ iterate ▁ over ▁ a ▁ range ▁ of ▁ that ▁ length . STRNEWLINE ▁ : param ▁ label : ▁ the ▁ label ▁ to ▁ show ▁ next ▁ to ▁ the ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ show _ eta : ▁ enables ▁ or ▁ disables ▁ the ▁ estimated ▁ time ▁ display . ▁ This ▁ is STRNEWLINE ▁ automatically ▁ disabled ▁ if ▁ the ▁ length ▁ cannot ▁ be STRNEWLINE ▁ determined . STRNEWLINE ▁ : param ▁ show _ percent : ▁ enables ▁ or ▁ disables ▁ the ▁ percentage ▁ display . ▁ The STRNEWLINE ▁ default ▁ is ▁ ` True ` ▁ if ▁ the ▁ iterable ▁ has ▁ a ▁ length ▁ or STRNEWLINE ▁ ` False ` ▁ if ▁ not . STRNEWLINE ▁ : param ▁ show _ pos : ▁ enables ▁ or ▁ disables ▁ the ▁ absolute ▁ position ▁ display . ▁ The STRNEWLINE ▁ default ▁ is ▁ ` False ` . STRNEWLINE ▁ : param ▁ item _ show _ func : ▁ a ▁ function ▁ called ▁ with ▁ the ▁ current ▁ item ▁ which STRNEWLINE ▁ can ▁ return ▁ a ▁ string ▁ to ▁ show ▁ the ▁ current ▁ item STRNEWLINE ▁ next ▁ to ▁ the ▁ progress ▁ bar . ▁ Note ▁ that ▁ the ▁ current STRNEWLINE ▁ item ▁ can ▁ be ▁ ` None ` ! STRNEWLINE ▁ : param ▁ fill _ char : ▁ the ▁ character ▁ to ▁ use ▁ to ▁ show ▁ the ▁ filled ▁ part ▁ of ▁ the STRNEWLINE ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ empty _ char : ▁ the ▁ character ▁ to ▁ use ▁ to ▁ show ▁ the ▁ non - filled ▁ part ▁ of STRNEWLINE ▁ the ▁ progress ▁ bar . STRNEWLINE ▁ : param ▁ bar _ template : ▁ the ▁ format ▁ string ▁ to ▁ use ▁ as ▁ template ▁ for ▁ the ▁ bar . STRNEWLINE ▁ The ▁ parameters ▁ in ▁ it ▁ are ▁ ` ` label ` ` ▁ for ▁ the ▁ label , STRNEWLINE ▁ ` ` bar ` ` ▁ for ▁ the ▁ progress ▁ bar ▁ and ▁ ` ` info ` ` ▁ for ▁ the STRNEWLINE ▁ info ▁ section . STRNEWLINE ▁ : param ▁ info _ sep : ▁ the ▁ separator ▁ between ▁ multiple ▁ info ▁ items ▁ ( eta ▁ etc . ) STRNEWLINE ▁ : param ▁ width : ▁ the ▁ width ▁ of ▁ the ▁ progress ▁ bar ▁ in ▁ characters , ▁ 0 ▁ means ▁ full STRNEWLINE ▁ terminal ▁ width STRNEWLINE ▁ : param ▁ file : ▁ the ▁ file ▁ to ▁ write ▁ to . ▁ If ▁ this ▁ is ▁ not ▁ a ▁ terminal ▁ then STRNEWLINE ▁ only ▁ the ▁ label ▁ is ▁ printed . STRNEWLINE ▁ : param ▁ color : ▁ controls ▁ if ▁ the ▁ terminal ▁ supports ▁ ANSI ▁ colors ▁ or ▁ not . ▁ The STRNEWLINE ▁ default ▁ is ▁ autodetection . ▁ This ▁ is ▁ only ▁ needed ▁ if ▁ ANSI STRNEWLINE ▁ codes ▁ are ▁ included ▁ anywhere ▁ in ▁ the ▁ progress ▁ bar ▁ output STRNEWLINE ▁ which ▁ is ▁ not ▁ the ▁ case ▁ by ▁ default . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import ProgressBar NEW_LINE color = resolve_color_default ( color ) NEW_LINE return ProgressBar ( iterable = iterable , length = length , show_eta = show_eta , show_percent = show_percent , show_pos = show_pos , item_show_func = item_show_func , fill_char = fill_char , empty_char = empty_char , bar_template = bar_template , info_sep = info_sep , file = file , label = label , width = width , color = color ) NEW_LINE DEDENT def clear ( ) : NEW_LINE INDENT """ Clears ▁ the ▁ terminal ▁ screen . ▁ This ▁ will ▁ have ▁ the ▁ effect ▁ of ▁ clearing STRNEWLINE ▁ the ▁ whole ▁ visible ▁ space ▁ of ▁ the ▁ terminal ▁ and ▁ moving ▁ the ▁ cursor ▁ to ▁ the STRNEWLINE ▁ top ▁ left . ▁ This ▁ does ▁ not ▁ do ▁ anything ▁ if ▁ not ▁ connected ▁ to ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE ▁ """ NEW_LINE if not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE # ▁ If ▁ we ' re ▁ on ▁ Windows ▁ and ▁ we ▁ don ' t ▁ have ▁ colorama ▁ available , ▁ then ▁ we ENDCOM # ▁ clear ▁ the ▁ screen ▁ by ▁ shelling ▁ out . ▁ Otherwise ▁ we ▁ can ▁ use ▁ an ▁ escape ENDCOM # ▁ sequence . ENDCOM DEDENT if WIN : NEW_LINE INDENT os . system ( ' cls ' ) NEW_LINE DEDENT else : NEW_LINE INDENT sys . stdout . write ( ' \033[2J\033[1;1H ' ) NEW_LINE DEDENT DEDENT def style ( text , fg = None , bg = None , bold = None , dim = None , underline = None , blink = None , reverse = None , reset = True ) : NEW_LINE INDENT """ Styles ▁ a ▁ text ▁ with ▁ ANSI ▁ styles ▁ and ▁ returns ▁ the ▁ new ▁ string . ▁ By STRNEWLINE ▁ default ▁ the ▁ styling ▁ is ▁ self ▁ contained ▁ which ▁ means ▁ that ▁ at ▁ the ▁ end STRNEWLINE ▁ of ▁ the ▁ string ▁ a ▁ reset ▁ code ▁ is ▁ issued . ▁ This ▁ can ▁ be ▁ prevented ▁ by STRNEWLINE ▁ passing ▁ ` ` reset = False ` ` . STRNEWLINE STRNEWLINE ▁ Examples : : STRNEWLINE STRNEWLINE ▁ click . echo ( click . style ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) ) STRNEWLINE ▁ click . echo ( click . style ( ' ATTENTION ! ' , ▁ blink = True ) ) STRNEWLINE ▁ click . echo ( click . style ( ' Some ▁ things ' , ▁ reverse = True , ▁ fg = ' cyan ' ) ) STRNEWLINE STRNEWLINE ▁ Supported ▁ color ▁ names : STRNEWLINE STRNEWLINE ▁ * ▁ ` ` black ` ` ▁ ( might ▁ be ▁ a ▁ gray ) STRNEWLINE ▁ * ▁ ` ` red ` ` STRNEWLINE ▁ * ▁ ` ` green ` ` STRNEWLINE ▁ * ▁ ` ` yellow ` ` ▁ ( might ▁ be ▁ an ▁ orange ) STRNEWLINE ▁ * ▁ ` ` blue ` ` STRNEWLINE ▁ * ▁ ` ` magenta ` ` STRNEWLINE ▁ * ▁ ` ` cyan ` ` STRNEWLINE ▁ * ▁ ` ` white ` ` ▁ ( might ▁ be ▁ light ▁ gray ) STRNEWLINE ▁ * ▁ ` ` reset ` ` ▁ ( reset ▁ the ▁ color ▁ code ▁ only ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ string ▁ to ▁ style ▁ with ▁ ansi ▁ codes . STRNEWLINE ▁ : param ▁ fg : ▁ if ▁ provided ▁ this ▁ will ▁ become ▁ the ▁ foreground ▁ color . STRNEWLINE ▁ : param ▁ bg : ▁ if ▁ provided ▁ this ▁ will ▁ become ▁ the ▁ background ▁ color . STRNEWLINE ▁ : param ▁ bold : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ bold ▁ mode . STRNEWLINE ▁ : param ▁ dim : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ dim ▁ mode . ▁ This ▁ is STRNEWLINE ▁ badly ▁ supported . STRNEWLINE ▁ : param ▁ underline : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ underline . STRNEWLINE ▁ : param ▁ blink : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ blinking . STRNEWLINE ▁ : param ▁ reverse : ▁ if ▁ provided ▁ this ▁ will ▁ enable ▁ or ▁ disable ▁ inverse STRNEWLINE ▁ rendering ▁ ( foreground ▁ becomes ▁ background ▁ and ▁ the STRNEWLINE ▁ other ▁ way ▁ round ) . STRNEWLINE ▁ : param ▁ reset : ▁ by ▁ default ▁ a ▁ reset - all ▁ code ▁ is ▁ added ▁ at ▁ the ▁ end ▁ of ▁ the STRNEWLINE ▁ string ▁ which ▁ means ▁ that ▁ styles ▁ do ▁ not ▁ carry ▁ over . ▁ This STRNEWLINE ▁ can ▁ be ▁ disabled ▁ to ▁ compose ▁ styles . STRNEWLINE ▁ """ NEW_LINE bits = [ ] NEW_LINE if fg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( fg ) + 30 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % fg ) NEW_LINE DEDENT DEDENT if bg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( bg ) + 40 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % bg ) NEW_LINE DEDENT DEDENT if bold is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 1 if bold else 22 ) ) NEW_LINE DEDENT if dim is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 2 if dim else 22 ) ) NEW_LINE DEDENT if underline is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 4 if underline else 24 ) ) NEW_LINE DEDENT if blink is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 5 if blink else 25 ) ) NEW_LINE DEDENT if reverse is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 7 if reverse else 27 ) ) NEW_LINE DEDENT bits . append ( text ) NEW_LINE if reset : NEW_LINE INDENT bits . append ( _ansi_reset_all ) NEW_LINE DEDENT return ' ' . join ( bits ) NEW_LINE DEDENT def unstyle ( text ) : NEW_LINE INDENT """ Removes ▁ ANSI ▁ styling ▁ information ▁ from ▁ a ▁ string . ▁ Usually ▁ it ' s ▁ not STRNEWLINE ▁ necessary ▁ to ▁ use ▁ this ▁ function ▁ as ▁ Click ' s ▁ echo ▁ function ▁ will STRNEWLINE ▁ automatically ▁ remove ▁ styling ▁ if ▁ necessary . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ remove ▁ style ▁ information ▁ from . STRNEWLINE ▁ """ NEW_LINE return strip_ansi ( text ) NEW_LINE DEDENT def secho ( text , file = None , nl = True , err = False , color = None , ** styles ) : NEW_LINE INDENT """ This ▁ function ▁ combines ▁ : func : ` echo ` ▁ and ▁ : func : ` style ` ▁ into ▁ one STRNEWLINE ▁ call . ▁ As ▁ such ▁ the ▁ following ▁ two ▁ calls ▁ are ▁ the ▁ same : : STRNEWLINE STRNEWLINE ▁ click . secho ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) STRNEWLINE ▁ click . echo ( click . style ( ' Hello ▁ World ! ' , ▁ fg = ' green ' ) ) STRNEWLINE STRNEWLINE ▁ All ▁ keyword ▁ arguments ▁ are ▁ forwarded ▁ to ▁ the ▁ underlying ▁ functions STRNEWLINE ▁ depending ▁ on ▁ which ▁ one ▁ they ▁ go ▁ with . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE ▁ """ NEW_LINE return echo ( style ( text , ** styles ) , file = file , nl = nl , err = err , color = color ) NEW_LINE DEDENT def edit ( text = None , editor = None , env = None , require_save = True , extension = ' . txt ' , filename = None ) : NEW_LINE INDENT r """ Edits ▁ the ▁ given ▁ text ▁ in ▁ the ▁ defined ▁ editor . ▁ If ▁ an ▁ editor ▁ is ▁ given STRNEWLINE ▁ ( should ▁ be ▁ the ▁ full ▁ path ▁ to ▁ the ▁ executable ▁ but ▁ the ▁ regular ▁ operating STRNEWLINE ▁ system ▁ search ▁ path ▁ is ▁ used ▁ for ▁ finding ▁ the ▁ executable ) ▁ it ▁ overrides STRNEWLINE ▁ the ▁ detected ▁ editor . ▁ Optionally , ▁ some ▁ environment ▁ variables ▁ can ▁ be STRNEWLINE ▁ used . ▁ If ▁ the ▁ editor ▁ is ▁ closed ▁ without ▁ changes , ▁ ` None ` ▁ is ▁ returned . ▁ In STRNEWLINE ▁ case ▁ a ▁ file ▁ is ▁ edited ▁ directly ▁ the ▁ return ▁ value ▁ is ▁ always ▁ ` None ` ▁ and STRNEWLINE ▁ ` require _ save ` ▁ and ▁ ` extension ` ▁ are ▁ ignored . STRNEWLINE STRNEWLINE ▁ If ▁ the ▁ editor ▁ cannot ▁ be ▁ opened ▁ a ▁ : exc : ` UsageError ` ▁ is ▁ raised . STRNEWLINE STRNEWLINE ▁ Note ▁ for ▁ Windows : ▁ to ▁ simplify ▁ cross - platform ▁ usage , ▁ the ▁ newlines ▁ are STRNEWLINE ▁ automatically ▁ converted ▁ from ▁ POSIX ▁ to ▁ Windows ▁ and ▁ vice ▁ versa . ▁ As ▁ such , STRNEWLINE ▁ the ▁ message ▁ here ▁ will ▁ have ▁ ` ` \n ` ` ▁ as ▁ newline ▁ markers . STRNEWLINE STRNEWLINE ▁ : param ▁ text : ▁ the ▁ text ▁ to ▁ edit . STRNEWLINE ▁ : param ▁ editor : ▁ optionally ▁ the ▁ editor ▁ to ▁ use . ▁ Defaults ▁ to ▁ automatic STRNEWLINE ▁ detection . STRNEWLINE ▁ : param ▁ env : ▁ environment ▁ variables ▁ to ▁ forward ▁ to ▁ the ▁ editor . STRNEWLINE ▁ : param ▁ require _ save : ▁ if ▁ this ▁ is ▁ true , ▁ then ▁ not ▁ saving ▁ in ▁ the ▁ editor STRNEWLINE ▁ will ▁ make ▁ the ▁ return ▁ value ▁ become ▁ ` None ` . STRNEWLINE ▁ : param ▁ extension : ▁ the ▁ extension ▁ to ▁ tell ▁ the ▁ editor ▁ about . ▁ This ▁ defaults STRNEWLINE ▁ to ▁ ` . txt ` ▁ but ▁ changing ▁ this ▁ might ▁ change ▁ syntax STRNEWLINE ▁ highlighting . STRNEWLINE ▁ : param ▁ filename : ▁ if ▁ provided ▁ it ▁ will ▁ edit ▁ this ▁ file ▁ instead ▁ of ▁ the STRNEWLINE ▁ provided ▁ text ▁ contents . ▁ It ▁ will ▁ not ▁ use ▁ a ▁ temporary STRNEWLINE ▁ file ▁ as ▁ an ▁ indirection ▁ in ▁ that ▁ case . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import Editor NEW_LINE editor = Editor ( editor = editor , env = env , require_save = require_save , extension = extension ) NEW_LINE if filename is None : NEW_LINE INDENT return editor . edit ( text ) NEW_LINE DEDENT editor . edit_file ( filename ) NEW_LINE DEDENT def launch ( url , wait = False , locate = False ) : NEW_LINE INDENT """ This ▁ function ▁ launches ▁ the ▁ given ▁ URL ▁ ( or ▁ filename ) ▁ in ▁ the ▁ default STRNEWLINE ▁ viewer ▁ application ▁ for ▁ this ▁ file ▁ type . ▁ If ▁ this ▁ is ▁ an ▁ executable , ▁ it STRNEWLINE ▁ might ▁ launch ▁ the ▁ executable ▁ in ▁ a ▁ new ▁ session . ▁ The ▁ return ▁ value ▁ is STRNEWLINE ▁ the ▁ exit ▁ code ▁ of ▁ the ▁ launched ▁ application . ▁ Usually , ▁ ` ` 0 ` ` ▁ indicates STRNEWLINE ▁ success . STRNEWLINE STRNEWLINE ▁ Examples : : STRNEWLINE STRNEWLINE ▁ click . launch ( ' http : / / click . pocoo . org / ' ) STRNEWLINE ▁ click . launch ( ' / my / downloaded / file ' , ▁ locate = True ) STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ url : ▁ URL ▁ or ▁ filename ▁ of ▁ the ▁ thing ▁ to ▁ launch . STRNEWLINE ▁ : param ▁ wait : ▁ waits ▁ for ▁ the ▁ program ▁ to ▁ stop . STRNEWLINE ▁ : param ▁ locate : ▁ if ▁ this ▁ is ▁ set ▁ to ▁ ` True ` ▁ then ▁ instead ▁ of ▁ launching ▁ the STRNEWLINE ▁ application ▁ associated ▁ with ▁ the ▁ URL ▁ it ▁ will ▁ attempt ▁ to STRNEWLINE ▁ launch ▁ a ▁ file ▁ manager ▁ with ▁ the ▁ file ▁ located . ▁ This STRNEWLINE ▁ might ▁ have ▁ weird ▁ effects ▁ if ▁ the ▁ URL ▁ does ▁ not ▁ point ▁ to STRNEWLINE ▁ the ▁ filesystem . STRNEWLINE ▁ """ NEW_LINE from . _termui_impl import open_url NEW_LINE return open_url ( url , wait = wait , locate = locate ) NEW_LINE # ▁ If ▁ this ▁ is ▁ provided , ▁ getchar ( ) ▁ calls ▁ into ▁ this ▁ instead . ▁ This ▁ is ▁ used ENDCOM # ▁ for ▁ unittesting ▁ purposes . ENDCOM DEDENT _getchar = None NEW_LINE def getchar ( echo = False ) : NEW_LINE INDENT """ Fetches ▁ a ▁ single ▁ character ▁ from ▁ the ▁ terminal ▁ and ▁ returns ▁ it . ▁ This STRNEWLINE ▁ will ▁ always ▁ return ▁ a ▁ unicode ▁ character ▁ and ▁ under ▁ certain ▁ rare STRNEWLINE ▁ circumstances ▁ this ▁ might ▁ return ▁ more ▁ than ▁ one ▁ character . ▁ The STRNEWLINE ▁ situations ▁ which ▁ more ▁ than ▁ one ▁ character ▁ is ▁ returned ▁ is ▁ when ▁ for STRNEWLINE ▁ whatever ▁ reason ▁ multiple ▁ characters ▁ end ▁ up ▁ in ▁ the ▁ terminal ▁ buffer ▁ or STRNEWLINE ▁ standard ▁ input ▁ was ▁ not ▁ actually ▁ a ▁ terminal . STRNEWLINE STRNEWLINE ▁ Note ▁ that ▁ this ▁ will ▁ always ▁ read ▁ from ▁ the ▁ terminal , ▁ even ▁ if ▁ something STRNEWLINE ▁ is ▁ piped ▁ into ▁ the ▁ standard ▁ input . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ : param ▁ echo : ▁ if ▁ set ▁ to ▁ ` True ` , ▁ the ▁ character ▁ read ▁ will ▁ also ▁ show ▁ up ▁ on STRNEWLINE ▁ the ▁ terminal . ▁ The ▁ default ▁ is ▁ to ▁ not ▁ show ▁ it . STRNEWLINE ▁ """ NEW_LINE f = _getchar NEW_LINE if f is None : NEW_LINE INDENT from . _termui_impl import getchar as f NEW_LINE DEDENT return f ( echo ) NEW_LINE DEDENT def pause ( info = ' Press ▁ any ▁ key ▁ to ▁ continue ▁ . . . ' , err = False ) : NEW_LINE INDENT """ This ▁ command ▁ stops ▁ execution ▁ and ▁ waits ▁ for ▁ the ▁ user ▁ to ▁ press ▁ any STRNEWLINE ▁ key ▁ to ▁ continue . ▁ This ▁ is ▁ similar ▁ to ▁ the ▁ Windows ▁ batch ▁ " pause " STRNEWLINE ▁ command . ▁ If ▁ the ▁ program ▁ is ▁ not ▁ run ▁ through ▁ a ▁ terminal , ▁ this ▁ command STRNEWLINE ▁ will ▁ instead ▁ do ▁ nothing . STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 2.0 STRNEWLINE STRNEWLINE ▁ . . ▁ versionadded : : ▁ 4.0 STRNEWLINE ▁ Added ▁ the ▁ ` err ` ▁ parameter . STRNEWLINE STRNEWLINE ▁ : param ▁ info : ▁ the ▁ info ▁ string ▁ to ▁ print ▁ before ▁ pausing . STRNEWLINE ▁ : param ▁ err : ▁ if ▁ set ▁ to ▁ message ▁ goes ▁ to ▁ ` ` stderr ` ` ▁ instead ▁ of STRNEWLINE ▁ ` ` stdout ` ` , ▁ the ▁ same ▁ as ▁ with ▁ echo . STRNEWLINE ▁ """ NEW_LINE if not isatty ( sys . stdin ) or not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE DEDENT try : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( info , nl = False , err = err ) NEW_LINE DEDENT try : NEW_LINE INDENT getchar ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT finally : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( err = err ) NEW_LINE DEDENT DEDENT DEDENT </DOCUMENT>
<DOCUMENT_ID="soulxu/libvirt-xuhj/tree/master/src/esx/esx_vi_generator.py"> # ! / usr / bin / env ▁ python ENDCOM # ▁ esx _ vi _ generator . py : ▁ generates ▁ most ▁ of ▁ the ▁ SOAP ▁ type ▁ mapping ▁ code ENDCOM # ▁ Copyright ▁ ( C ) ▁ 2010-2011 ▁ Matthias ▁ Bolte ▁ < matthias . bolte @ googlemail . com > ENDCOM # ▁ This ▁ library ▁ is ▁ free ▁ software ; ▁ you ▁ can ▁ redistribute ▁ it ▁ and / or ENDCOM # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ENDCOM # ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation ; ▁ either ENDCOM # ▁ version ▁ 2.1 ▁ of ▁ the ▁ License , ▁ or ▁ ( at ▁ your ▁ option ) ▁ any ▁ later ▁ version . ENDCOM # ▁ This ▁ library ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful , ENDCOM # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY ; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ENDCOM # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE . ▁ See ▁ the ▁ GNU ENDCOM # ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details . ENDCOM # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ENDCOM # ▁ License ▁ along ▁ with ▁ this ▁ library ; ▁ if ▁ not , ▁ write ▁ to ▁ the ▁ Free ▁ Software ENDCOM # ▁ Foundation , ▁ Inc . , ▁ 59 ▁ Temple ▁ Place , ▁ Suite ▁ 330 , ▁ Boston , ▁ MA ▁ 02111-1307 ▁ USA ENDCOM import sys NEW_LINE import os NEW_LINE import os . path NEW_LINE OCCURRENCE__REQUIRED_ITEM = " r " NEW_LINE OCCURRENCE__REQUIRED_LIST = " rl " NEW_LINE OCCURRENCE__OPTIONAL_ITEM = " o " NEW_LINE OCCURRENCE__OPTIONAL_LIST = " ol " NEW_LINE OCCURRENCE__IGNORED = " i " NEW_LINE valid_occurrences = [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_ITEM , OCCURRENCE__OPTIONAL_LIST , OCCURRENCE__IGNORED ] NEW_LINE autobind_names = set ( ) NEW_LINE separator = " / * ▁ " + ( " * ▁ " * 37 ) + " * \n " NEW_LINE def aligned ( left , right , length = 59 ) : NEW_LINE INDENT while len ( left ) < length : NEW_LINE INDENT left += " ▁ " NEW_LINE DEDENT return left + right NEW_LINE DEDENT class Member : NEW_LINE INDENT def __init__ ( self , type , occurrence ) : NEW_LINE INDENT self . type = type NEW_LINE self . occurrence = occurrence NEW_LINE DEDENT def is_enum ( self ) : NEW_LINE INDENT return self . type in predefined_enums or self . type in enums_by_name NEW_LINE DEDENT def is_object ( self ) : NEW_LINE INDENT return self . type in predefined_objects or self . type in objects_by_name NEW_LINE DEDENT def is_type_generated ( self ) : NEW_LINE INDENT return self . type in enums_by_name or self . type in objects_by_name NEW_LINE DEDENT def get_occurrence_comment ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__REQUIRED_ITEM : NEW_LINE INDENT return " / * ▁ required ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__REQUIRED_LIST : NEW_LINE INDENT return " / * ▁ required , ▁ list ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_ITEM : NEW_LINE INDENT return " / * ▁ optional ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT return " / * ▁ optional , ▁ list ▁ * / " NEW_LINE DEDENT raise ValueError ( " unknown ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT DEDENT class Parameter ( Member ) : NEW_LINE INDENT def __init__ ( self , type , name , occurrence ) : NEW_LINE INDENT Member . __init__ ( self , type , occurrence ) NEW_LINE if ' : ' in name and name . startswith ( " _ this " ) : NEW_LINE INDENT self . name , self . autobind_name = name . split ( " : " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . name = name NEW_LINE self . autobind_name = None NEW_LINE DEDENT DEDENT def generate_parameter ( self , is_last = False , is_header = True , offset = 0 ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT raise ValueError ( " invalid ▁ function ▁ parameter ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT elif self . autobind_name is not None : NEW_LINE INDENT return " " NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ " NEW_LINE string += " ▁ " * offset NEW_LINE string += " % s % s " % ( self . get_type_string ( ) , self . name ) NEW_LINE if is_last : NEW_LINE INDENT if is_header : NEW_LINE INDENT string += " ) ; ▁ " NEW_LINE DEDENT else : NEW_LINE INDENT string += " ) , ▁ " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT string += " , ▁ " NEW_LINE DEDENT return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_return ( self , offset = 0 , end_of_line = " ; " ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT raise ValueError ( " invalid ▁ function ▁ parameter ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ " NEW_LINE string += " ▁ " * offset NEW_LINE string += " % s % s ) % s " % ( self . get_type_string ( True ) , self . name , end_of_line ) NEW_LINE return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_require_code ( self ) : NEW_LINE INDENT if self . occurrence in [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ REQUIRE ( % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " " NEW_LINE DEDENT DEDENT def generate_serialize_code ( self ) : NEW_LINE INDENT if self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def get_type_string ( self , as_return_value = False ) : NEW_LINE INDENT string = " " NEW_LINE if self . type == " String " and self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT if as_return_value : NEW_LINE INDENT string += " char ▁ * " NEW_LINE DEDENT else : NEW_LINE INDENT string += " const ▁ char ▁ * " NEW_LINE DEDENT DEDENT elif self . is_enum ( ) : NEW_LINE INDENT string += " esxVI _ % s ▁ " % self . type NEW_LINE DEDENT else : NEW_LINE INDENT string += " esxVI _ % s ▁ * " % self . type NEW_LINE DEDENT if as_return_value : NEW_LINE INDENT string += " * " NEW_LINE DEDENT return string NEW_LINE DEDENT def get_occurrence_short_enum ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__REQUIRED_ITEM : NEW_LINE INDENT return " RequiredItem " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__REQUIRED_LIST : NEW_LINE INDENT return " RequiredList " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_ITEM : NEW_LINE INDENT return " OptionalItem " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT return " OptionalList " NEW_LINE DEDENT raise ValueError ( " unknown ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT DEDENT class Method : NEW_LINE INDENT def __init__ ( self , name , parameters , returns ) : NEW_LINE INDENT self . name = name NEW_LINE self . parameters = [ ] NEW_LINE self . autobind_parameter = None NEW_LINE self . returns = returns NEW_LINE for parameter in parameters : NEW_LINE INDENT if parameter . autobind_name is None : NEW_LINE INDENT self . parameters . append ( parameter ) NEW_LINE DEDENT else : NEW_LINE INDENT self . autobind_parameter = parameter NEW_LINE DEDENT DEDENT DEDENT def generate_header ( self ) : NEW_LINE INDENT header = " int ▁ esxVI _ % s \n " % self . name NEW_LINE header += " ▁ ▁ ▁ ▁ ▁ ▁ ( esxVI _ Context ▁ * ctx " NEW_LINE if len ( self . parameters ) > 0 or self . returns is not None : NEW_LINE INDENT header += " , \n " NEW_LINE for parameter in self . parameters [ : - 1 ] : NEW_LINE INDENT header += parameter . generate_parameter ( ) NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT header += self . parameters [ - 1 ] . generate_parameter ( is_last = True ) NEW_LINE DEDENT else : NEW_LINE INDENT header += self . parameters [ - 1 ] . generate_parameter ( ) NEW_LINE header += self . returns . generate_return ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT header += " ) ; \n " NEW_LINE DEDENT header += " \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = " / * ▁ esxVI _ % s ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ METHOD ( % s , " % self . name NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT autobind_names . add ( self . autobind_parameter . autobind_name ) NEW_LINE source += " ▁ % s , \n " % self . autobind_parameter . autobind_name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ / * ▁ explicit ▁ _ this ▁ * / , \n " NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ( esxVI _ Context ▁ * ctx " NEW_LINE if len ( self . parameters ) > 0 or self . returns is not None : NEW_LINE INDENT source += " , \n " NEW_LINE for parameter in self . parameters [ : - 1 ] : NEW_LINE INDENT source += parameter . generate_parameter ( is_header = False , offset = 9 ) NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT source += self . parameters [ - 1 ] . generate_parameter ( is_last = True , is_header = False , offset = 9 ) NEW_LINE DEDENT else : NEW_LINE INDENT source += self . parameters [ - 1 ] . generate_parameter ( is_header = False , offset = 9 ) NEW_LINE source += self . returns . generate_return ( offset = 9 , end_of_line = " , " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT source += " ) , \n " NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ void , ▁ / * ▁ nothing ▁ * / , ▁ None , \n " NEW_LINE DEDENT elif self . returns . type == " String " : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ String , ▁ Value , ▁ % s , \n " % self . returns . get_occurrence_short_enum ( ) NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s , ▁ / * ▁ nothing ▁ * / , ▁ % s , \n " % ( self . returns . type , self . returns . get_occurrence_short_enum ( ) ) NEW_LINE DEDENT source += " { \n " NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT source += self . autobind_parameter . generate_require_code ( ) NEW_LINE DEDENT for parameter in self . parameters : NEW_LINE INDENT source += parameter . generate_require_code ( ) NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT source += self . autobind_parameter . generate_serialize_code ( ) NEW_LINE DEDENT for parameter in self . parameters : NEW_LINE INDENT source += parameter . generate_serialize_code ( ) NEW_LINE DEDENT source += " } ) \n \n \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class Property ( Member ) : NEW_LINE INDENT def __init__ ( self , type , name , occurrence ) : NEW_LINE INDENT Member . __init__ ( self , type , occurrence ) NEW_LINE self . name = name NEW_LINE DEDENT def generate_struct_member ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ % s % s ; ▁ " % ( self . get_type_string ( ) , self . name ) NEW_LINE return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_free_code ( self ) : NEW_LINE INDENT if self . type == " String " and self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST , OCCURRENCE__IGNORED ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ VIR _ FREE ( item - > % s ) ; \n " % self . name NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " " NEW_LINE DEDENT else : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > % s ) ; \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT DEDENT def generate_validate_code ( self , managed = False ) : NEW_LINE INDENT if managed : NEW_LINE INDENT macro = " ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ MANAGED _ REQUIRE " NEW_LINE DEDENT else : NEW_LINE INDENT macro = " ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ REQUIRE " NEW_LINE DEDENT if self . occurrence in [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ % s ( % s ) \n " % ( macro , self . name ) NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " " NEW_LINE DEDENT DEDENT def generate_deep_copy_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ( * dest ) - > % s ▁ = ▁ src - > % s ; \n " % ( self . name , self . name ) NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_serialize_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_deserialize_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ IGNORE ( % s ) ▁ / * ▁ FIXME ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ LIST ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ VALUE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_lookup_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ FROM _ ANY _ TYPE _ IGNORE ( % s ) ▁ / * ▁ FIXME ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ LIST _ FROM _ ANY _ TYPE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ VALUE _ FROM _ ANY _ TYPE ( String , ▁ % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ FROM _ ANY _ TYPE ( % s , ▁ % s ) \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def get_type_string ( self ) : NEW_LINE INDENT if self . type == " String " and self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " char ▁ * " NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " esxVI _ % s ▁ " % self . type NEW_LINE DEDENT else : NEW_LINE INDENT return " esxVI _ % s ▁ * " % self . type NEW_LINE DEDENT DEDENT DEDENT class Type : NEW_LINE INDENT def __init__ ( self , kind , name ) : NEW_LINE INDENT self . kind = kind NEW_LINE self . name = name NEW_LINE DEDENT def generate_typedef ( self ) : NEW_LINE INDENT return " typedef ▁ % s ▁ _ esxVI _ % s ▁ esxVI _ % s ; \n " % ( self . kind , self . name , self . name ) NEW_LINE DEDENT def generate_typeenum ( self ) : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ esxVI _ Type _ % s , \n " % self . name NEW_LINE DEDENT def generate_typetostring ( self ) : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ case ▁ esxVI _ Type _ % s : \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ return ▁ \ " % s\ " ; \n \n " % self . name NEW_LINE return string NEW_LINE DEDENT def generate_typefromstring ( self ) : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ else ▁ if ▁ ( STREQ ( type , ▁ \ " % s\ " ) ) ▁ { \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ return ▁ esxVI _ Type _ % s ; \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } \n " NEW_LINE return string NEW_LINE DEDENT DEDENT class Object ( Type ) : NEW_LINE INDENT FEATURE__DYNAMIC_CAST = ( 1 << 1 ) NEW_LINE FEATURE__LIST = ( 1 << 2 ) NEW_LINE FEATURE__DEEP_COPY = ( 1 << 3 ) NEW_LINE FEATURE__ANY_TYPE = ( 1 << 4 ) NEW_LINE FEATURE__SERIALIZE = ( 1 << 5 ) NEW_LINE FEATURE__DESERIALIZE = ( 1 << 6 ) NEW_LINE def __init__ ( self , name , extends , properties , features = 0 , extended_by = None ) : NEW_LINE INDENT Type . __init__ ( self , " struct " , name ) NEW_LINE self . extends = extends NEW_LINE self . features = features NEW_LINE self . properties = properties NEW_LINE self . extended_by = extended_by NEW_LINE self . candidate_for_dynamic_cast = False NEW_LINE if self . extended_by is not None : NEW_LINE INDENT self . extended_by . sort ( ) NEW_LINE DEDENT DEDENT def generate_struct_members ( self , add_banner = False , struct_gap = False ) : NEW_LINE INDENT members = " " NEW_LINE if struct_gap : NEW_LINE INDENT members += " \n " NEW_LINE DEDENT if self . extends is not None : NEW_LINE INDENT members += objects_by_name [ self . extends ] . generate_struct_members ( add_banner = True , struct_gap = False ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT for property in self . properties : NEW_LINE INDENT members += property . generate_struct_member ( ) NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT return members NEW_LINE DEDENT def generate_free_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_free_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_free_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ freed ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_validate_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_validate_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_validate_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ required ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_dynamic_cast_code ( self , is_first = True ) : NEW_LINE INDENT source = " " NEW_LINE if self . extended_by is not None : NEW_LINE INDENT if not is_first : NEW_LINE INDENT source += " \n " NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST _ _ ACCEPT ( % s ) \n " % extended_by NEW_LINE DEDENT for extended_by in self . extended_by : NEW_LINE INDENT source += objects_by_name [ extended_by ] . generate_dynamic_cast_code ( False ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_deep_copy_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_deep_copy_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_deep_copy_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ deep ▁ copied ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_serialize_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_serialize_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT for property in self . properties : NEW_LINE INDENT source += property . generate_serialize_code ( ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_deserialize_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] . generate_deserialize_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT for property in self . properties : NEW_LINE INDENT source += property . generate_deserialize_code ( ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = separator NEW_LINE header += " ▁ * ▁ VI ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT header += " ▁ * / \n \n " NEW_LINE # ▁ struct ENDCOM header += " struct ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ next ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT else : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ unused ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ Type ▁ _ type ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += self . generate_struct_members ( struct_gap = True ) NEW_LINE header += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM header += " int ▁ esxVI _ % s _ Alloc ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " void ▁ esxVI _ % s _ Free ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " int ▁ esxVI _ % s _ Validate ( esxVI _ % s ▁ * item ) ; \n " % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__DYNAMIC_CAST : NEW_LINE INDENT if self . extended_by is not None or self . extends is not None : NEW_LINE INDENT header += " esxVI _ % s ▁ * esxVI _ % s _ DynamicCast ( void ▁ * item ) ; \n " % ( self . name , self . name ) NEW_LINE DEDENT else : NEW_LINE INDENT report_error ( " cannot ▁ add ▁ dynamic ▁ cast ▁ support ▁ for ▁ an ▁ untyped ▁ object " ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ AppendToList ( esxVI _ % s ▁ * * list , ▁ esxVI _ % s ▁ * item ) ; \n " % ( self . name , self . name , self . name ) NEW_LINE DEDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ DeepCopy ( esxVI _ % s ▁ * * dst , ▁ esxVI _ % s ▁ * src ) ; \n " % ( self . name , self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ DeepCopyList ( esxVI _ % s ▁ * * dstList , ▁ " " esxVI _ % s ▁ * srcList ) ; \n " ) % ( self . name , self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * * item ) ; \n " ) % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastListFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * * list ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Serialize ( esxVI _ % s ▁ * item , ▁ " " const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ SerializeList ( esxVI _ % s ▁ * list , ▁ " " const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ Deserialize ( xmlNodePtr ▁ node , ▁ esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ DeserializeList ( xmlNodePtr ▁ node , ▁ " " esxVI _ % s ▁ * * list ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = separator NEW_LINE source += " ▁ * ▁ VI ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT source += " ▁ * / \n \n " NEW_LINE # ▁ functions ENDCOM source += " / * ▁ esxVI _ % s _ Alloc ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ALLOC ( % s ) \n \n " % self . name NEW_LINE # ▁ free ENDCOM if self . extended_by is None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ break ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n \n " % self . name NEW_LINE DEDENT DEDENT source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ FREE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ brea ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n \n " % self . name NEW_LINE DEDENT DEDENT source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ validate ENDCOM DEDENT source += " / * ▁ esxVI _ % s _ Validate ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ VALIDATE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_validate_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ dynamic ▁ cast ENDCOM if self . features & Object . FEATURE__DYNAMIC_CAST : NEW_LINE INDENT if self . extended_by is not None or self . extends is not None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DynamicCast ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_dynamic_cast_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT report_error ( " cannot ▁ add ▁ dynamic ▁ cast ▁ support ▁ for ▁ an ▁ untyped ▁ object " ) NEW_LINE # ▁ append ▁ to ▁ list ENDCOM DEDENT DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ AppendToList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ APPEND ( % s ) \n \n " % self . name NEW_LINE # ▁ deep ▁ copy ENDCOM DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopy ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DEEP _ COPY ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_deep_copy_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopyList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DEEP _ COPY ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopy ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ DEEP _ COPY ( % s ) \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ DEEP _ COPY ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_deep_copy_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopyList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DEEP _ COPY ( % s ) \n \n " % self . name NEW_LINE # ▁ cast ▁ from ▁ any ▁ type ENDCOM DEDENT DEDENT DEDENT if self . features & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastFromAnyType ▁ * / \n " % self . name NEW_LINE if self . extended_by is None : NEW_LINE INDENT source += " ESX _ VI _ _ TEMPLATE _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST _ FROM _ ANY _ TYPE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } ) \n \n " NEW_LINE DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastListFromAnyType ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " % self . name NEW_LINE # ▁ serialize ENDCOM DEDENT DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ SERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_serialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ SerializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ SERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ SERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ SERIALIZE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_serialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ SerializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ SERIALIZE ( % s ) \n \n " % self . name NEW_LINE # ▁ deserialize ENDCOM DEDENT DEDENT DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DESERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_deserialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeserializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DESERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ DESERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ DESERIALIZE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_deserialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeserializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DESERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT DEDENT DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class ManagedObject ( Type ) : NEW_LINE INDENT FEATURE__LIST = ( 1 << 2 ) NEW_LINE def __init__ ( self , name , extends , properties , features = 0 , extended_by = None ) : NEW_LINE INDENT Type . __init__ ( self , " struct " , name ) NEW_LINE self . extends = extends NEW_LINE self . features = features NEW_LINE self . properties = properties NEW_LINE self . extended_by = extended_by NEW_LINE if self . extended_by is not None : NEW_LINE INDENT self . extended_by . sort ( ) NEW_LINE DEDENT DEDENT def generate_struct_members ( self , add_banner = False , struct_gap = False ) : NEW_LINE INDENT members = " " NEW_LINE if struct_gap : NEW_LINE INDENT members += " \n " NEW_LINE DEDENT if self . extends is not None : NEW_LINE INDENT members += managed_objects_by_name [ self . extends ] . generate_struct_members ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT for property in self . properties : NEW_LINE INDENT members += property . generate_struct_member ( ) NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT return members NEW_LINE DEDENT def generate_free_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_free_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_free_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ freed ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_validate_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_validate_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_validate_code ( managed = True ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ required ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_lookup_code1 ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_lookup_code1 ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += " ▁ ▁ ▁ ▁ \ " % s\\0\ " \n " % property . name NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_lookup_code2 ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] . generate_lookup_code2 ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_lookup_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_comment ( self ) : NEW_LINE INDENT comment = separator NEW_LINE comment += " ▁ * ▁ VI ▁ Managed ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT comment += " ▁ * / \n \n " NEW_LINE return comment NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = self . generate_comment ( ) NEW_LINE # ▁ struct ENDCOM header += " struct ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ next ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT else : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ unused ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ Type ▁ _ type ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference ▁ * _ reference ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += " \n " NEW_LINE header += self . generate_struct_members ( ) NEW_LINE header += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM header += " int ▁ esxVI _ % s _ Alloc ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " void ▁ esxVI _ % s _ Free ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += ( " int ▁ esxVI _ % s _ Validate ( esxVI _ % s ▁ * item , ▁ " " esxVI _ String ▁ * selectedPropertyNameList ) ; \n " ) % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ AppendToList ( esxVI _ % s ▁ * * list , ▁ esxVI _ % s ▁ * item ) ; \n " % ( self . name , self . name , self . name ) NEW_LINE DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_helper_header ( self ) : NEW_LINE INDENT header = " " NEW_LINE # ▁ functions ENDCOM header += ( " int ▁ esxVI _ Lookup % s ( esxVI _ Context ▁ * ctx , ▁ " " const ▁ char ▁ * name , ▁ " " esxVI _ ManagedObjectReference ▁ * root , ▁ " " esxVI _ String ▁ * selectedPropertyNameList , ▁ " " esxVI _ % s ▁ * * item , ▁ " " esxVI _ Occurrence ▁ occurrence ) ; \n " ) % ( self . name , self . name ) NEW_LINE header += " \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = self . generate_comment ( ) NEW_LINE # ▁ functions ENDCOM source += " / * ▁ esxVI _ % s _ Alloc ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ALLOC ( % s ) \n \n " % self . name NEW_LINE # ▁ free ENDCOM if self . extended_by is None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE if self . features & ManagedObject . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ break ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n " % self . name NEW_LINE DEDENT DEDENT source += " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference _ Free ( & item - > _ reference ) ; \n \n " NEW_LINE source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ FREE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE # ▁ avoid ▁ " dereferencing ▁ type - punned ▁ pointer ▁ will ▁ break ENDCOM # ▁ strict - aliasing ▁ rules " ▁ warnings ENDCOM INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n " % self . name NEW_LINE DEDENT DEDENT source += " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference _ Free ( & item - > _ reference ) ; \n \n " NEW_LINE source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ validate ENDCOM DEDENT source += " / * ▁ esxVI _ % s _ Validate ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ MANAGED _ VALIDATE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_validate_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE # ▁ append ▁ to ▁ list ENDCOM if self . features & ManagedObject . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ AppendToList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ APPEND ( % s ) \n \n " % self . name NEW_LINE DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT def generate_helper_source ( self ) : NEW_LINE INDENT source = " " NEW_LINE # ▁ lookup ENDCOM source += " / * ▁ esxVI _ Lookup % s ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LOOKUP ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_lookup_code1 ( ) NEW_LINE source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_lookup_code2 ( ) NEW_LINE source += " } ) \n \n " NEW_LINE source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class Enum ( Type ) : NEW_LINE INDENT FEATURE__ANY_TYPE = ( 1 << 1 ) NEW_LINE FEATURE__SERIALIZE = ( 1 << 2 ) NEW_LINE FEATURE__DESERIALIZE = ( 1 << 3 ) NEW_LINE def __init__ ( self , name , values , features = 0 ) : NEW_LINE INDENT Type . __init__ ( self , " enum " , name ) NEW_LINE self . values = values NEW_LINE self . features = features NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = separator NEW_LINE header += " ▁ * ▁ VI ▁ Enum : ▁ % s \n " % self . name NEW_LINE header += " ▁ * / \n \n " NEW_LINE # ▁ enum ENDCOM header += " enum ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE header += " ▁ ▁ ▁ ▁ esxVI _ % s _ Undefined ▁ = ▁ 0 , \n " % self . name NEW_LINE for value in self . values : NEW_LINE INDENT header += " ▁ ▁ ▁ ▁ esxVI _ % s _ % s , \n " % ( self . name , capitalize_first ( value ) ) NEW_LINE DEDENT header += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM if self . features & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * item ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT if self . features & Enum . FEATURE__SERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Serialize ( esxVI _ % s ▁ item , ▁ const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT if self . features & Enum . FEATURE__DESERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Deserialize ( xmlNodePtr ▁ node , ▁ " " esxVI _ % s ▁ * item ) ; \n " ) % ( self . name , self . name ) NEW_LINE DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = separator NEW_LINE source += " ▁ * ▁ VI ▁ Enum : ▁ % s \n " % self . name NEW_LINE source += " ▁ * / \n \n " NEW_LINE source += " static ▁ const ▁ esxVI _ Enumeration ▁ _ esxVI _ % s _ Enumeration ▁ = ▁ { \n " % self . name NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ Type _ % s , ▁ { \n " % self . name NEW_LINE for value in self . values : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { ▁ \ " % s\ " , ▁ esxVI _ % s _ % s ▁ } , \n " % ( value , self . name , capitalize_first ( value ) ) NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { ▁ NULL , ▁ - 1 ▁ } , \n " NEW_LINE source += " ▁ ▁ ▁ ▁ } , \n " NEW_LINE source += " } ; \n \n " NEW_LINE # ▁ functions ENDCOM if self . features & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastFromAnyType ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " % self . name NEW_LINE DEDENT if self . features & Enum . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ SERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT if self . features & Enum . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ DESERIALIZE ( % s ) \n \n " % self . name NEW_LINE DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT def report_error ( message ) : NEW_LINE INDENT print " error : ▁ " + message NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT def capitalize_first ( string ) : NEW_LINE INDENT return string [ : 1 ] . upper ( ) + string [ 1 : ] NEW_LINE DEDENT def parse_object ( block ) : NEW_LINE # ▁ expected ▁ format : ▁ [ managed ] ▁ object ▁ < name > ▁ [ extends ▁ < name > ] ENDCOM INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE managed = False NEW_LINE if header_items [ 0 ] == " managed " : NEW_LINE INDENT managed = True NEW_LINE del header_items [ 0 ] NEW_LINE DEDENT if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " object " NEW_LINE name = header_items [ 1 ] NEW_LINE extends = None NEW_LINE if len ( header_items ) > 2 : NEW_LINE INDENT if header_items [ 2 ] != " extends " : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT extends = header_items [ 3 ] NEW_LINE DEDENT DEDENT properties = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE # ▁ expected ▁ format : ▁ < type > ▁ < name > ▁ < occurrence > ENDCOM INDENT items = line [ 1 ] . split ( ) NEW_LINE if len ( items ) != 3 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ property " % line [ 0 ] ) NEW_LINE DEDENT if items [ 2 ] not in valid_occurrences : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ occurrence " % line [ 0 ] ) NEW_LINE DEDENT properties . append ( Property ( type = items [ 0 ] , name = items [ 1 ] , occurrence = items [ 2 ] ) ) NEW_LINE DEDENT if managed : NEW_LINE INDENT return ManagedObject ( name = name , extends = extends , properties = properties ) NEW_LINE DEDENT else : NEW_LINE INDENT return Object ( name = name , extends = extends , properties = properties ) NEW_LINE DEDENT DEDENT def parse_enum ( block ) : NEW_LINE # ▁ expected ▁ format : ▁ enum ▁ < name > ENDCOM INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " enum " NEW_LINE name = header_items [ 1 ] NEW_LINE values = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE # ▁ expected ▁ format : ▁ < value > ENDCOM INDENT values . append ( line [ 1 ] ) NEW_LINE DEDENT return Enum ( name = name , values = values ) NEW_LINE DEDENT def parse_method ( block ) : NEW_LINE # ▁ expected ▁ format : ▁ method ▁ < name > ▁ [ returns ▁ < type > ▁ < occurrence > ] ENDCOM INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " method " NEW_LINE name = header_items [ 1 ] NEW_LINE returns = None NEW_LINE if len ( header_items ) > 2 : NEW_LINE INDENT if header_items [ 2 ] != " returns " : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT returns = Parameter ( type = header_items [ 3 ] , name = " output " , occurrence = header_items [ 4 ] ) NEW_LINE DEDENT DEDENT parameters = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE # ▁ expected ▁ format : ▁ < type > ▁ < name > ▁ < occurrence > ENDCOM INDENT items = line [ 1 ] . split ( ) NEW_LINE if len ( items ) != 3 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ property " % line [ 0 ] ) NEW_LINE DEDENT if items [ 2 ] not in valid_occurrences : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ occurrence " % line [ 0 ] ) NEW_LINE DEDENT parameters . append ( Parameter ( type = items [ 0 ] , name = items [ 1 ] , occurrence = items [ 2 ] ) ) NEW_LINE DEDENT return Method ( name = name , parameters = parameters , returns = returns ) NEW_LINE DEDENT def is_known_type ( type ) : NEW_LINE INDENT return type in predefined_objects or type in predefined_enums or type in objects_by_name or type in managed_objects_by_name or type in enums_by_name NEW_LINE DEDENT def open_and_print ( filename ) : NEW_LINE INDENT if filename . startswith ( " . / " ) : NEW_LINE INDENT print " ▁ ▁ GEN ▁ ▁ ▁ ▁ " + filename [ 2 : ] NEW_LINE DEDENT else : NEW_LINE INDENT print " ▁ ▁ GEN ▁ ▁ ▁ ▁ " + filename NEW_LINE DEDENT return open ( filename , " wb " ) NEW_LINE DEDENT predefined_enums = [ " Boolean " ] NEW_LINE predefined_objects = [ " AnyType " , " Int " , " Long " , " String " , " DateTime " , " MethodFault " , " ManagedObjectReference " ] NEW_LINE additional_enum_features = { " ManagedEntityStatus " : Enum . FEATURE__ANY_TYPE , " TaskInfoState " : Enum . FEATURE__ANY_TYPE , " VirtualMachinePowerState " : Enum . FEATURE__ANY_TYPE } NEW_LINE additional_object_features = { " AutoStartDefaults " : Object . FEATURE__ANY_TYPE , " AutoStartPowerInfo " : Object . FEATURE__ANY_TYPE , " DatastoreHostMount " : Object . FEATURE__DEEP_COPY | Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " DatastoreInfo " : Object . FEATURE__ANY_TYPE | Object . FEATURE__DYNAMIC_CAST , " HostConfigManager " : Object . FEATURE__ANY_TYPE , " HostCpuIdInfo " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " HostDatastoreBrowserSearchResults " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " ManagedObjectReference " : Object . FEATURE__ANY_TYPE , " ObjectContent " : Object . FEATURE__DEEP_COPY , " ResourcePoolResourceUsage " : Object . FEATURE__ANY_TYPE , " ServiceContent " : Object . FEATURE__DESERIALIZE , " SharesInfo " : Object . FEATURE__ANY_TYPE , " TaskInfo " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " UserSession " : Object . FEATURE__ANY_TYPE , " VirtualMachineQuestionInfo " : Object . FEATURE__ANY_TYPE , " VirtualMachineSnapshotTree " : Object . FEATURE__DEEP_COPY | Object . FEATURE__ANY_TYPE , " VmEventArgument " : Object . FEATURE__DESERIALIZE } NEW_LINE removed_object_features = { } NEW_LINE if " srcdir " in os . environ : NEW_LINE INDENT input_filename = os . path . join ( os . environ [ " srcdir " ] , " esx / esx _ vi _ generator . input " ) NEW_LINE output_dirname = os . path . join ( os . environ [ " srcdir " ] , " esx " ) NEW_LINE DEDENT else : NEW_LINE INDENT input_filename = os . path . join ( os . getcwd ( ) , " esx _ vi _ generator . input " ) NEW_LINE output_dirname = os . getcwd ( ) NEW_LINE DEDENT types_typedef = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typedef " ) ) NEW_LINE types_typeenum = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typeenum " ) ) NEW_LINE types_typetostring = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typetostring " ) ) NEW_LINE types_typefromstring = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typefromstring " ) ) NEW_LINE types_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . h " ) ) NEW_LINE types_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . c " ) ) NEW_LINE methods_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . h " ) ) NEW_LINE methods_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . c " ) ) NEW_LINE methods_macro = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . macro " ) ) NEW_LINE helpers_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi . generated . h " ) ) NEW_LINE helpers_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi . generated . c " ) ) NEW_LINE number = 0 NEW_LINE objects_by_name = { } NEW_LINE managed_objects_by_name = { } NEW_LINE enums_by_name = { } NEW_LINE methods_by_name = { } NEW_LINE block = None NEW_LINE # ▁ parse ▁ input ▁ file ENDCOM for line in file ( input_filename , " rb " ) . readlines ( ) : NEW_LINE INDENT number += 1 NEW_LINE if " # " in line : NEW_LINE INDENT line = line [ : line . index ( " # " ) ] NEW_LINE DEDENT line = line . lstrip ( ) . rstrip ( ) NEW_LINE if len ( line ) < 1 : NEW_LINE INDENT continue NEW_LINE DEDENT if line . startswith ( " object " ) or line . startswith ( " managed ▁ object " ) or line . startswith ( " enum " ) or line . startswith ( " method " ) : NEW_LINE INDENT if block is not None : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ nested ▁ block ▁ found " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT block = [ ] NEW_LINE DEDENT DEDENT if block is not None : NEW_LINE INDENT if line == " end " : NEW_LINE INDENT if block [ 0 ] [ 1 ] . startswith ( " object " ) : NEW_LINE INDENT obj = parse_object ( block ) NEW_LINE objects_by_name [ obj . name ] = obj NEW_LINE DEDENT elif block [ 0 ] [ 1 ] . startswith ( " managed ▁ object " ) : NEW_LINE INDENT obj = parse_object ( block ) NEW_LINE managed_objects_by_name [ obj . name ] = obj NEW_LINE DEDENT elif block [ 0 ] [ 1 ] . startswith ( " enum " ) : NEW_LINE INDENT enum = parse_enum ( block ) NEW_LINE enums_by_name [ enum . name ] = enum NEW_LINE DEDENT else : NEW_LINE INDENT method = parse_method ( block ) NEW_LINE methods_by_name [ method . name ] = method NEW_LINE DEDENT block = None NEW_LINE DEDENT else : NEW_LINE INDENT block . append ( ( number , line ) ) NEW_LINE DEDENT DEDENT DEDENT for method in methods_by_name . values ( ) : NEW_LINE # ▁ method ▁ parameter ▁ types ▁ must ▁ be ▁ serializable ENDCOM INDENT for parameter in method . parameters : NEW_LINE INDENT if not parameter . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if parameter . is_enum ( ) : NEW_LINE INDENT enums_by_name [ parameter . type ] . features |= Enum . FEATURE__SERIALIZE NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ parameter . type ] . features |= Object . FEATURE__SERIALIZE NEW_LINE objects_by_name [ parameter . type ] . candidate_for_dynamic_cast = True NEW_LINE # ▁ detect ▁ list ▁ usage ENDCOM DEDENT if parameter . occurrence == OCCURRENCE__REQUIRED_LIST or parameter . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if parameter . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( parameter . type , method . name ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ parameter . type ] . features |= Object . FEATURE__LIST NEW_LINE # ▁ method ▁ return ▁ types ▁ must ▁ be ▁ deserializable ENDCOM DEDENT DEDENT DEDENT if method . returns and method . returns . is_type_generated ( ) : NEW_LINE INDENT if method . returns . is_enum ( ) : NEW_LINE INDENT enums_by_name [ method . returns . type ] . features |= Enum . FEATURE__DESERIALIZE NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ method . returns . type ] . features |= Object . FEATURE__DESERIALIZE NEW_LINE objects_by_name [ method . returns . type ] . candidate_for_dynamic_cast = True NEW_LINE # ▁ detect ▁ list ▁ usage ENDCOM DEDENT if method . returns . occurrence == OCCURRENCE__REQUIRED_LIST or method . returns . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if method . returns . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( method . returns . type , method . name ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ method . returns . type ] . features |= Object . FEATURE__LIST NEW_LINE DEDENT DEDENT DEDENT DEDENT for enum in enums_by_name . values ( ) : NEW_LINE # ▁ apply ▁ additional ▁ features ENDCOM INDENT if enum . name in additional_enum_features : NEW_LINE INDENT enum . features |= additional_enum_features [ enum . name ] NEW_LINE if additional_enum_features [ enum . name ] & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT enum . features |= Enum . FEATURE__DESERIALIZE NEW_LINE DEDENT DEDENT DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence != OCCURRENCE__IGNORED and not is_known_type ( property . type ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ contains ▁ unknown ▁ property ▁ type ▁ ' % s ' " % ( obj . name , property . type ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT if not is_known_type ( obj . extends ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ extends ▁ unknown ▁ object ▁ ' % s ' " % ( obj . name , obj . extends ) ) NEW_LINE DEDENT DEDENT for property in obj . properties : NEW_LINE INDENT if not property . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if property . is_enum ( ) : NEW_LINE INDENT enums_by_name [ property . type ] . candidate_for_dynamic_cast = True NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ property . type ] . candidate_for_dynamic_cast = True NEW_LINE # ▁ detect ▁ list ▁ usage ENDCOM DEDENT if property . occurrence == OCCURRENCE__REQUIRED_LIST or property . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if property . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( property . type , obj . type ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ property . type ] . features |= Object . FEATURE__LIST NEW_LINE # ▁ apply / remove ▁ additional ▁ features ENDCOM DEDENT DEDENT DEDENT if obj . name in additional_object_features : NEW_LINE INDENT obj . features |= additional_object_features [ obj . name ] NEW_LINE if additional_object_features [ obj . name ] & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT obj . features |= Object . FEATURE__DESERIALIZE NEW_LINE DEDENT DEDENT if obj . name in removed_object_features : NEW_LINE INDENT obj . features &= ~ removed_object_features [ obj . name ] NEW_LINE # ▁ detect ▁ extended _ by ▁ relation ENDCOM DEDENT if obj . extends is not None : NEW_LINE INDENT extended_obj = objects_by_name [ obj . extends ] NEW_LINE if extended_obj . extended_by is None : NEW_LINE INDENT extended_obj . extended_by = [ obj . name ] NEW_LINE DEDENT else : NEW_LINE INDENT extended_obj . extended_by . append ( obj . name ) NEW_LINE extended_obj . extended_by . sort ( ) NEW_LINE DEDENT DEDENT DEDENT for obj in objects_by_name . values ( ) : NEW_LINE # ▁ if ▁ an ▁ object ▁ is ▁ a ▁ candidate ▁ ( it ▁ is ▁ used ▁ directly ▁ as ▁ parameter ▁ or ▁ return ENDCOM # ▁ type ▁ or ▁ is ▁ a ▁ member ▁ of ▁ another ▁ object ) ▁ and ▁ it ▁ is ▁ extended ▁ by ▁ another ENDCOM # ▁ object ▁ then ▁ this ▁ type ▁ needs ▁ the ▁ dynamic ▁ cast ▁ feature ENDCOM INDENT if obj . candidate_for_dynamic_cast and obj . extended_by : NEW_LINE INDENT obj . features |= Object . FEATURE__DYNAMIC_CAST NEW_LINE DEDENT DEDENT def propagate_feature ( obj , feature ) : NEW_LINE INDENT global features_have_changed NEW_LINE if not ( obj . features & feature ) : NEW_LINE INDENT return NEW_LINE DEDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence == OCCURRENCE__IGNORED or not property . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if property . is_enum ( ) : NEW_LINE INDENT if feature == Object . FEATURE__SERIALIZE and not ( enums_by_name [ property . type ] . features & Enum . FEATURE__SERIALIZE ) : NEW_LINE INDENT enums_by_name [ property . type ] . features |= Enum . FEATURE__SERIALIZE NEW_LINE features_have_changed = True NEW_LINE DEDENT elif feature == Object . FEATURE__DESERIALIZE and not ( enums_by_name [ property . type ] . features & Enum . FEATURE__DESERIALIZE ) : NEW_LINE INDENT enums_by_name [ property . type ] . features |= Enum . FEATURE__DESERIALIZE NEW_LINE features_have_changed = True NEW_LINE DEDENT DEDENT elif property . is_object ( ) : NEW_LINE INDENT if not ( objects_by_name [ property . type ] . features & feature ) : NEW_LINE INDENT objects_by_name [ property . type ] . features |= feature NEW_LINE features_have_changed = True NEW_LINE DEDENT if obj . name != property . type : NEW_LINE INDENT propagate_feature ( objects_by_name [ property . type ] , feature ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def inherit_features ( obj ) : NEW_LINE INDENT global features_have_changed NEW_LINE if obj . extended_by is not None : NEW_LINE INDENT for extended_by in obj . extended_by : NEW_LINE INDENT previous = objects_by_name [ extended_by ] . features NEW_LINE objects_by_name [ extended_by ] . features |= obj . features NEW_LINE if objects_by_name [ extended_by ] . features != previous : NEW_LINE INDENT features_have_changed = True NEW_LINE DEDENT DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT previous = objects_by_name [ obj . extends ] . features NEW_LINE objects_by_name [ obj . extends ] . features |= obj . features NEW_LINE if objects_by_name [ obj . extends ] . features != previous : NEW_LINE INDENT features_have_changed = True NEW_LINE DEDENT DEDENT if obj . extended_by is not None : NEW_LINE INDENT for extended_by in obj . extended_by : NEW_LINE INDENT inherit_features ( objects_by_name [ extended_by ] ) NEW_LINE # ▁ there ▁ are ▁ two ▁ directions ▁ to ▁ spread ▁ features : ENDCOM # ▁ 1 ) ▁ up ▁ and ▁ down ▁ the ▁ inheritance ▁ chain ENDCOM # ▁ 2 ) ▁ from ▁ object ▁ types ▁ to ▁ their ▁ member ▁ property ▁ types ENDCOM # ▁ spreading ▁ needs ▁ to ▁ be ▁ done ▁ alternating ▁ on ▁ both ▁ directions ▁ because ▁ they ▁ can ENDCOM # ▁ affect ▁ each ▁ other ENDCOM DEDENT DEDENT DEDENT features_have_changed = True NEW_LINE while features_have_changed : NEW_LINE INDENT features_have_changed = False NEW_LINE for obj in objects_by_name . values ( ) : NEW_LINE INDENT propagate_feature ( obj , Object . FEATURE__DEEP_COPY ) NEW_LINE propagate_feature ( obj , Object . FEATURE__SERIALIZE ) NEW_LINE propagate_feature ( obj , Object . FEATURE__DESERIALIZE ) NEW_LINE DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT inherit_features ( obj ) NEW_LINE DEDENT DEDENT for obj in managed_objects_by_name . values ( ) : NEW_LINE INDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence != OCCURRENCE__IGNORED and not is_known_type ( property . type ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ contains ▁ unknown ▁ property ▁ type ▁ ' % s ' " % ( obj . name , property . type ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT if not is_known_type ( obj . extends ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ extends ▁ unknown ▁ object ▁ ' % s ' " % ( obj . name , obj . extends ) ) NEW_LINE # ▁ detect ▁ extended _ by ▁ relation ENDCOM DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT extended_obj = managed_objects_by_name [ obj . extends ] NEW_LINE if extended_obj . extended_by is None : NEW_LINE INDENT extended_obj . extended_by = [ obj . name ] NEW_LINE DEDENT else : NEW_LINE INDENT extended_obj . extended_by . append ( obj . name ) NEW_LINE extended_obj . extended_by . sort ( ) NEW_LINE DEDENT DEDENT DEDENT notice = " / * ▁ Generated ▁ by ▁ esx _ vi _ generator . py ▁ * / \n \n \n \n " NEW_LINE types_typedef . write ( notice ) NEW_LINE types_typeenum . write ( notice ) NEW_LINE types_typetostring . write ( notice ) NEW_LINE types_typefromstring . write ( notice ) NEW_LINE types_header . write ( notice ) NEW_LINE types_source . write ( notice ) NEW_LINE methods_header . write ( notice ) NEW_LINE methods_source . write ( notice ) NEW_LINE methods_macro . write ( notice ) NEW_LINE helpers_header . write ( notice ) NEW_LINE helpers_source . write ( notice ) NEW_LINE # ▁ output ▁ enums ENDCOM types_typedef . write ( separator + " ▁ * ▁ VI ▁ Enums \n " + " ▁ * / \n \n " ) NEW_LINE names = enums_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( enums_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( enums_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( enums_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( enums_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( enums_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( enums_by_name [ name ] . generate_source ( ) ) NEW_LINE # ▁ output ▁ objects ENDCOM DEDENT types_typedef . write ( " \n \n \n " + separator + " ▁ * ▁ VI ▁ Objects \n " + " ▁ * / \n \n " ) NEW_LINE types_typeenum . write ( " \n " ) NEW_LINE types_typetostring . write ( " \n " ) NEW_LINE types_typefromstring . write ( " \n " ) NEW_LINE names = objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( objects_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( objects_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( objects_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( objects_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( objects_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( objects_by_name [ name ] . generate_source ( ) ) NEW_LINE # ▁ output ▁ managed ▁ objects ENDCOM DEDENT types_typedef . write ( " \n \n \n " + separator + " ▁ * ▁ VI ▁ Managed ▁ Objects \n " + " ▁ * / \n \n " ) NEW_LINE types_typeenum . write ( " \n " ) NEW_LINE types_typetostring . write ( " \n " ) NEW_LINE types_typefromstring . write ( " \n " ) NEW_LINE names = managed_objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( managed_objects_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( managed_objects_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( managed_objects_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( managed_objects_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( managed_objects_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( managed_objects_by_name [ name ] . generate_source ( ) ) NEW_LINE # ▁ output ▁ methods ENDCOM DEDENT names = methods_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT methods_header . write ( methods_by_name [ name ] . generate_header ( ) ) NEW_LINE methods_source . write ( methods_by_name [ name ] . generate_source ( ) ) NEW_LINE DEDENT names = list ( autobind_names ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT string = aligned ( " # define ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ THIS _ _ % s ▁ " % name , " \\ \n " , 78 ) NEW_LINE string += " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ THIS _ FROM _ SERVICE ( ManagedObjectReference , ▁ ▁ ▁ ▁ ▁ ▁ \\ \n " NEW_LINE string += aligned ( " " , " % s ) \n \n \n \n " % name , 49 ) NEW_LINE methods_macro . write ( string ) NEW_LINE # ▁ output ▁ helpers ENDCOM DEDENT names = managed_objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT helpers_header . write ( managed_objects_by_name [ name ] . generate_helper_header ( ) ) NEW_LINE helpers_source . write ( managed_objects_by_name [ name ] . generate_helper_source ( ) ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="lordmos/blink/tree/master/Tools/TestResultServer/model/jsonresults_unittest.py"> # ▁ Copyright ▁ ( C ) ▁ 2010 ▁ Google ▁ Inc . ▁ All ▁ rights ▁ reserved . ENDCOM # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms , ▁ with ▁ or ▁ without ENDCOM # ▁ modification , ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ are ENDCOM # ▁ met : ENDCOM # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright ENDCOM # ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer . ENDCOM # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above ENDCOM # ▁ copyright ▁ notice , ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer ENDCOM # ▁ in ▁ the ▁ documentation ▁ and / or ▁ other ▁ materials ▁ provided ▁ with ▁ the ENDCOM # ▁ distribution . ENDCOM # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ Google ▁ Inc . ▁ nor ▁ the ▁ names ▁ of ▁ its ENDCOM # ▁ contributors ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from ENDCOM # ▁ this ▁ software ▁ without ▁ specific ▁ prior ▁ written ▁ permission . ENDCOM # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS ENDCOM # ▁ " AS ▁ IS " ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES , ▁ INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ FOR ENDCOM # ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ COPYRIGHT ENDCOM # ▁ OWNER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT , ▁ INDIRECT , ▁ INCIDENTAL , ENDCOM # ▁ SPECIAL , ▁ EXEMPLARY , ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ ( INCLUDING , ▁ BUT ▁ NOT ENDCOM # ▁ LIMITED ▁ TO , ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES ; ▁ LOSS ▁ OF ▁ USE , ENDCOM # ▁ DATA , ▁ OR ▁ PROFITS ; ▁ OR ▁ BUSINESS ▁ INTERRUPTION ) ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY ENDCOM # ▁ THEORY ▁ OF ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ CONTRACT , ▁ STRICT ▁ LIABILITY , ▁ OR ▁ TORT ENDCOM # ▁ ( INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE ) ▁ ARISING ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE ENDCOM # ▁ OF ▁ THIS ▁ SOFTWARE , ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE . ENDCOM try : NEW_LINE INDENT import jsonresults NEW_LINE from jsonresults import * NEW_LINE DEDENT except ImportError : NEW_LINE INDENT print " ERROR : ▁ Add ▁ the ▁ TestResultServer , ▁ google _ appengine ▁ and ▁ yaml / lib ▁ directories ▁ to ▁ your ▁ PYTHONPATH " NEW_LINE raise NEW_LINE DEDENT import json NEW_LINE import logging NEW_LINE import unittest NEW_LINE FULL_RESULT_EXAMPLE = """ ADD _ RESULTS ( { STRNEWLINE ▁ ▁ ▁ ▁ " seconds _ since _ epoch " : ▁ 1368146629 , STRNEWLINE ▁ ▁ ▁ ▁ " tests " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - events . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " bugs " : ▁ [ " crbug . com / 1234 " ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - syntax . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " progress - events - generated - correctly . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " W3C " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " audio " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 3.5 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " video " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " notrun . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " NOTRUN " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - skip . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - fail . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " flaky - failed . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media - document - audio - repaint . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 0.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " skipped " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ regressions " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " build _ number " : ▁ " 3 " , STRNEWLINE ▁ ▁ ▁ ▁ " interrupted " : ▁ false , STRNEWLINE ▁ ▁ ▁ ▁ " layout _ tests _ dir " : ▁ " \ / tmp\ / cr\ / src\ / third _ party\ / WebKit\ / LayoutTests " , STRNEWLINE ▁ ▁ ▁ ▁ " version " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ " builder _ name " : ▁ " Webkit " , STRNEWLINE ▁ ▁ ▁ ▁ " num _ passes " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ " pixel _ tests _ enabled " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " blink _ revision " : ▁ " 1234 " , STRNEWLINE ▁ ▁ ▁ ▁ " has _ pretty _ patch " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " fixable " : ▁ 25 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ flaky " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ failures _ by _ type " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " CRASH " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " MISSING " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TEXT " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE " : ▁ 1 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " PASS " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " SKIP " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TIMEOUT " : ▁ 16 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE + TEXT " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " FAIL " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " AUDIO " : ▁ 0 STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " has _ wdiff " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " chromium _ revision " : ▁ " 5678 " STRNEWLINE } ) ; """ NEW_LINE JSON_RESULTS_OLD_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " allFixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " fixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " fixableCounts " : [ [ TESTDATA _ COUNTS ] ] , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' " version " : [ VERSION ] ' ' } ' ) % json . dumps ( CHAR_TO_FAILURE ) JSON_RESULTS_COUNTS = ' { " ' + ' " : [ [ TESTDATA _ COUNT ] ] , " ' . join ( [ char for char in CHAR_TO_FAILURE . values ( ) ] ) + ' " : [ [ TESTDATA _ COUNT ] ] } ' NEW_LINE JSON_RESULTS_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " num _ failures _ by _ type " : % s , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' " version " : [ VERSION ] ' ' } ' ) % ( json . dumps ( CHAR_TO_FAILURE ) , JSON_RESULTS_COUNTS ) JSON_RESULTS_COUNTS_TEMPLATE = ' { " ' + ' " : [ TESTDATA ] , " ' . join ( [ char for char in CHAR_TO_FAILURE ] ) + ' " : [ TESTDATA ] } ' NEW_LINE JSON_RESULTS_TEST_LIST_TEMPLATE = ' { " Webkit " : { " tests " : { [ TESTDATA _ TESTS ] } } } ' NEW_LINE class MockFile ( object ) : NEW_LINE INDENT def __init__ ( self , name = ' results . json ' , data = ' ' ) : NEW_LINE INDENT self . master = ' MockMasterName ' NEW_LINE self . builder = ' MockBuilderName ' NEW_LINE self . test_type = ' MockTestType ' NEW_LINE self . name = name NEW_LINE self . data = data NEW_LINE DEDENT def save ( self , data ) : NEW_LINE INDENT self . data = data NEW_LINE return True NEW_LINE DEDENT DEDENT class JsonResultsTest ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . _builder = " Webkit " NEW_LINE self . old_log_level = logging . root . level NEW_LINE logging . root . setLevel ( logging . ERROR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT logging . root . setLevel ( self . old_log_level ) NEW_LINE # ▁ Use ▁ this ▁ to ▁ get ▁ better ▁ error ▁ messages ▁ than ▁ just ▁ string ▁ compare ▁ gives . ENDCOM DEDENT def assert_json_equal ( self , a , b ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE a = json . loads ( a ) if isinstance ( a , str ) else a NEW_LINE b = json . loads ( b ) if isinstance ( b , str ) else b NEW_LINE self . assertEqual ( a , b ) NEW_LINE DEDENT def test_strip_prefix_suffix ( self ) : NEW_LINE INDENT json = " [ ' contents ' ] " NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( " ADD _ RESULTS ( " + json + " ) ; " ) , json ) NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( json ) , json ) NEW_LINE DEDENT def _make_test_json ( self , test_data , json_string = JSON_RESULTS_TEMPLATE , builder_name = " Webkit " ) : NEW_LINE INDENT if not test_data : NEW_LINE INDENT return " " NEW_LINE DEDENT builds = test_data [ " builds " ] NEW_LINE tests = test_data [ " tests " ] NEW_LINE if not builds or not tests : NEW_LINE INDENT return " " NEW_LINE DEDENT counts = [ ] NEW_LINE build_numbers = [ ] NEW_LINE webkit_revision = [ ] NEW_LINE chrome_revision = [ ] NEW_LINE times = [ ] NEW_LINE for build in builds : NEW_LINE INDENT counts . append ( JSON_RESULTS_COUNTS_TEMPLATE . replace ( " [ TESTDATA ] " , build ) ) NEW_LINE build_numbers . append ( "1000 % s " % build ) NEW_LINE webkit_revision . append ( "2000 % s " % build ) NEW_LINE chrome_revision . append ( "3000 % s " % build ) NEW_LINE times . append ( "100000 % s000" % build ) NEW_LINE DEDENT json_string = json_string . replace ( " [ BUILDER _ NAME ] " , builder_name ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNTS ] " , " , " . join ( counts ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNT ] " , " , " . join ( builds ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ BUILDNUMBERS ] " , " , " . join ( build_numbers ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ WEBKITREVISION ] " , " , " . join ( webkit_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ CHROMEREVISION ] " , " , " . join ( chrome_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ TIMES ] " , " , " . join ( times ) ) NEW_LINE version = str ( test_data [ " version " ] ) if " version " in test_data else "4" NEW_LINE json_string = json_string . replace ( " [ VERSION ] " , version ) NEW_LINE json_string = json_string . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( tests , separators = ( ' , ' , ' : ' ) , sort_keys = True ) ) NEW_LINE return json_string NEW_LINE DEDENT def _test_merge ( self , aggregated_data , incremental_data , expected_data , max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( aggregated_data , builder_name = self . _builder ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data , builder_name = self . _builder ) , is_full_results_format = False ) NEW_LINE merged_results , status_code = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = max_builds , sort_keys = True ) NEW_LINE if expected_data : NEW_LINE INDENT expected_results = self . _make_test_json ( expected_data , builder_name = self . _builder ) NEW_LINE self . assert_json_equal ( merged_results , expected_results ) NEW_LINE self . assertEqual ( status_code , 200 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertTrue ( status_code != 200 ) NEW_LINE DEDENT DEDENT def _test_get_test_list ( self , input_data , expected_data ) : NEW_LINE INDENT input_results = self . _make_test_json ( input_data ) NEW_LINE expected_results = JSON_RESULTS_TEST_LIST_TEMPLATE . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( expected_data , separators = ( ' , ' , ' : ' ) ) ) NEW_LINE actual_results = JsonResults . get_test_list ( self . _builder , input_results ) NEW_LINE self . assert_json_equal ( actual_results , expected_results ) NEW_LINE DEDENT def test_update_files_empty_aggregate_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertTrue ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) ) NEW_LINE self . assert_json_equal ( small_file . data , incremental_string ) NEW_LINE self . assert_json_equal ( large_file . data , incremental_string ) NEW_LINE DEDENT def test_update_files_null_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_string = " " NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_update_files_empty_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_data = { " builds " : [ ] , " tests " : { } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_merge_with_empty_aggregated_results ( self ) : NEW_LINE INDENT incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_results , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data ) , is_full_results_format = False ) NEW_LINE aggregated_results = " " NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_results , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , incremental_results ) NEW_LINE DEDENT def test_failures_by_type_added ( self ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 200 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_results = self . _make_test_json ( { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , incremental_results , is_full_results_format = False ) NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = 201 , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , self . _make_test_json ( { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 101 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 201 , 0 ] ] , } } } ) ) NEW_LINE DEDENT def test_merge_full_results_format ( self ) : NEW_LINE INDENT expected_incremental_results = { " Webkit " : { " blinkRevision " : [ "1234" ] , " buildNumbers " : [ "3" ] , " chromeRevision " : [ "5678" ] , " failure _ map " : CHAR_TO_FAILURE , " num _ failures _ by _ type " : { " AUDIO " : [ 0 ] , " CRASH " : [ 3 ] , " FAIL " : [ 2 ] , " IMAGE " : [ 1 ] , " IMAGE + TEXT " : [ 0 ] , " MISSING " : [ 0 ] , " PASS " : [ 10 ] , " SKIP " : [ 2 ] , " TEXT " : [ 3 ] , " TIMEOUT " : [ 16 ] } , " secondsSinceEpoch " : [ 1368146629 ] , " tests " : { " media " : { " W3C " : { " audio " : { " src " : { " src _ removal _ does _ not _ trigger _ loadstart . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 4 ] ] , } } } } , " encrypted - media " : { " encrypted - media - v2 - events . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " encrypted - media - v2 - syntax . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 0 ] ] , } } , " media - document - audio - repaint . html " : { " expected " : " IMAGE " , " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] , } , " progress - events - generated - correctly . html " : { " expected " : " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " flaky - failed . html " : { " expected " : " PASS ▁ FAIL " , " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , " unexpected - fail . html " : { " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , } } } , " version " : 4 } NEW_LINE aggregated_results = " " NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , FULL_RESULT_EXAMPLE , is_full_results_format = True ) NEW_LINE merged_results , _ = JsonResults . merge ( " Webkit " , aggregated_results , incremental_json , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , expected_incremental_results ) NEW_LINE DEDENT def test_merge_empty_aggregated_results ( self ) : NEW_LINE # ▁ No ▁ existing ▁ aggregated ▁ results . ENDCOM # ▁ Merged ▁ results ▁ = = ▁ new ▁ incremental ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM None , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Expected ▁ result ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_duplicate_build_number ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] ] , " times " : [ [ 100 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM None ) NEW_LINE DEDENT def test_merge_incremental_single_test_single_run_same_result ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ and ▁ same ▁ test ▁ results ▁ for ENDCOM # ▁ that ▁ run . ENDCOM # ▁ Insert ▁ the ▁ incremental ▁ results ▁ at ▁ the ▁ first ▁ place ▁ and ▁ sum ▁ number ENDCOM # ▁ of ▁ runs ▁ for ▁ TEXT ▁ ( 200 ▁ + ▁ 1 ) ▁ to ▁ get ▁ merged ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_different_result ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ but ▁ different ▁ test ▁ results ENDCOM # ▁ for ▁ that ▁ run . ENDCOM # ▁ Insert ▁ the ▁ incremental ▁ results ▁ at ▁ the ▁ first ▁ place . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_result_changed ( self ) : NEW_LINE # ▁ Incremental ▁ results ▁ has ▁ the ▁ latest ▁ build ▁ but ▁ results ▁ which ▁ differ ▁ from ENDCOM # ▁ the ▁ latest ▁ result ▁ ( but ▁ are ▁ the ▁ same ▁ as ▁ an ▁ older ▁ result ) . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 200 , 0 ] , [ 10 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] , [ 10 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run ( self ) : NEW_LINE # ▁ All ▁ tests ▁ have ▁ incremental ▁ updates . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run_one_no_result ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 200 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 1 , FAIL ] ] , " times " : [ [ 3 , 2 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , FAIL ] , [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 3 , 2 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] ] , " times " : [ [ 2 , 2 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 2 , 2 ] , [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] , [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 10 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_older_build ( self ) : NEW_LINE # ▁ Test ▁ the ▁ build ▁ in ▁ incremental ▁ results ▁ is ▁ older ▁ than ▁ the ▁ most ▁ recent ENDCOM # ▁ build ▁ in ▁ aggregated ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ no ▁ merge ▁ happens . ENDCOM { " builds " : [ "2" , "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 6 , TEXT ] ] , " times " : [ [ 6 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_same_build ( self ) : NEW_LINE # ▁ Test ▁ the ▁ build ▁ in ▁ incremental ▁ results ▁ is ▁ same ▁ as ▁ the ▁ build ▁ in ENDCOM # ▁ aggregated ▁ results . ENDCOM INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" , "2" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , TEXT ] ] , " times " : [ [ 2 , 0 ] ] } } } , # ▁ Expected ▁ no ▁ merge ▁ happens . ENDCOM { " builds " : [ "3" , "2" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 7 , TEXT ] ] , " times " : [ [ 7 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_remove_new_test ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 199 , TEXT ] ] , " times " : [ [ 199 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , " notrun . html " : { " results " : [ [ 1 , NOTRUN ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_remove_test ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_updates_expected ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " expected " : " FAIL " , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " FAIL " , " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " expected " : " FAIL " , " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " results " : [ [ 199 , PASS ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "002 . html " : { " expected " : " PASS " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 191 , PASS ] , [ 9 , NO_DATA ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_keep_test_with_all_pass_but_slow_time ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_pruning_slow_tests_for_debug_builders ( self ) : NEW_LINE INDENT self . _builder = " MockBuilder ( dbg ) " NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results ( self ) : NEW_LINE # ▁ Remove ▁ items ▁ from ▁ test ▁ results ▁ and ▁ times ▁ that ▁ exceed ▁ the ▁ max ▁ number ENDCOM # ▁ of ▁ builds ▁ to ▁ track . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results_small ( self ) : NEW_LINE # ▁ Remove ▁ items ▁ from ▁ test ▁ results ▁ and ▁ times ▁ that ▁ exceed ▁ the ▁ max ▁ number ENDCOM # ▁ of ▁ builds ▁ to ▁ track , ▁ using ▁ smaller ▁ threshold . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_prune_extra_results_with_new_result_of_same_type ( self ) : NEW_LINE # ▁ Test ▁ that ▁ merging ▁ in ▁ a ▁ new ▁ result ▁ of ▁ the ▁ same ▁ type ▁ as ▁ the ▁ last ▁ result ENDCOM # ▁ causes ▁ old ▁ results ▁ to ▁ fall ▁ off . ENDCOM INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , NO_DATA ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] ] , " times " : [ [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_build_directory_hierarchy ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 25 , TEXT ] ] , " times " : [ [ 25 , 0 ] ] } } } , " foo " : { "001 . html " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } } } , " version " : 4 } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } } , " version " : 4 } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 25 , TEXT ] ] , " times " : [ [ 26 , 0 ] ] } } } , " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 51 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } } } , " version " : 4 } ) NEW_LINE # ▁ FIXME ( aboxhall ) : ▁ Add ▁ some ▁ tests ▁ for ▁ xhtml / svg ▁ test ▁ results . ENDCOM DEDENT def test_get_test_name_list ( self ) : NEW_LINE # ▁ Get ▁ test ▁ name ▁ list ▁ only . ▁ Don ' t ▁ include ▁ non - test - list ▁ data ▁ and ENDCOM # ▁ of ▁ test ▁ result ▁ details . ENDCOM # ▁ FIXME : ▁ This ▁ also ▁ tests ▁ a ▁ temporary ▁ bug ▁ in ▁ the ▁ data ▁ where ▁ directory - level ENDCOM # ▁ results ▁ have ▁ a ▁ results ▁ and ▁ times ▁ values . ▁ Once ▁ that ▁ bug ▁ is ▁ fixed , ENDCOM # ▁ remove ▁ this ▁ test - case ▁ and ▁ assert ▁ we ▁ don ' t ▁ ever ▁ hit ▁ it . ENDCOM INDENT self . _test_get_test_list ( # ▁ Input ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , # ▁ Expected ▁ results ENDCOM { " foo " : { "001 . html " : { } } , "002 . html " : { } } ) NEW_LINE DEDENT def test_gtest ( self ) : NEW_LINE INDENT self . _test_merge ( # ▁ Aggregated ▁ results ENDCOM { " builds " : [ "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 3 } , # ▁ Incremental ▁ results ENDCOM { " builds " : [ "3" ] , " tests " : { " foo . bar2" : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 4 } , # ▁ Expected ▁ results ENDCOM { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 1 , NO_DATA ] , [ 50 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 10 , FAIL ] ] , " times " : [ [ 10 , 0 ] ] } , } , " version " : 4 } ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT unittest . main ( ) NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="andyzsf/edx/tree/master/common/djangoapps/student/migrations/0020_add_test_center_user.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE # ▁ Adding ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . create_table ( ' student _ testcenteruser ' , ( ( ' id ' , self . gf ( ' django . db . models . fields . AutoField ' ) ( primary_key = True ) ) , ( ' user ' , self . gf ( ' django . db . models . fields . related . ForeignKey ' ) ( default = None , to = orm [ ' auth . User ' ] , unique = True ) ) , ( ' created _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now_add = True , db_index = True , blank = True ) ) , ( ' updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now = True , db_index = True , blank = True ) ) , ( ' user _ updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( db_index = True ) ) , ( ' candidate _ id ' , self . gf ( ' django . db . models . fields . IntegerField ' ) ( null = True , db_index = True ) ) , ( ' client _ candidate _ id ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' first _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , db_index = True ) ) , ( ' last _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' middle _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , blank = True ) ) , ( ' suffix ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 255 , blank = True ) ) , ( ' salutation ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ( ' address _ 1' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 ) ) , ( ' address _ 2' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' address _ 3' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' city ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 32 , db_index = True ) ) , ( ' state ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 20 , blank = True ) ) , ( ' postal _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 16 , blank = True ) ) , ( ' country ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' phone ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 ) ) , ( ' extension ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 8 , blank = True ) ) , ( ' phone _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' fax ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 , blank = True ) ) , ( ' fax _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , blank = True ) ) , ( ' company _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ) ) NEW_LINE db . send_create_signal ( ' student ' , [ ' TestCenterUser ' ] ) NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE # ▁ Deleting ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . delete_table ( ' student _ testcenteruser ' ) NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , ' auth . user ' : { ' Meta ' : { ' object _ name ' : ' User ' } , ' about ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' avatar _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' n ' " , ' max _ length ' : '1' } ) , ' bronze ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' consecutive _ days _ visit _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' country ' : ( ' django _ countries . fields . CountryField ' , [ ] , { ' max _ length ' : '2' , ' blank ' : ' True ' } ) , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' date _ of _ birth ' : ( ' django . db . models . fields . DateField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' display _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' email _ isvalid ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' email _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' null ' : ' True ' } ) , ' email _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' gold ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' gravatar ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' ignored _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' interesting _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' last _ seen ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' new _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' questions _ per _ page ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '10' } ) , ' real _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' reputation ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' default ' : '1' } ) , ' seen _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' show _ country ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' silver ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' status ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' w ' " , ' max _ length ' : '2' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) , ' website ' : ( ' django . db . models . fields . URLField ' , [ ] , { ' max _ length ' : '200' , ' blank ' : ' True ' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' student . courseenrollment ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' user ' , ▁ ' course _ id ' ) , ) " , ' object _ name ' : ' CourseEnrollment ' } , ' course _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " } ) } , ' student . pendingemailchange ' : { ' Meta ' : { ' object _ name ' : ' PendingEmailChange ' } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ email ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . pendingnamechange ' : { ' Meta ' : { ' object _ name ' : ' PendingNameChange ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' rationale ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '1024' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . registration ' : { ' Meta ' : { ' object _ name ' : ' Registration ' , ' db _ table ' : " ' auth _ registration ' " } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . testcenteruser ' : { ' Meta ' : { ' object _ name ' : ' TestCenterUser ' } , ' address _ 1' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' } ) , ' address _ 2' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' address _ 3' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' candidate _ id ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' null ' : ' True ' , ' db _ index ' : ' True ' } ) , ' city ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' client _ candidate _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' company _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' country ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' created _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' extension ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '8' , ' blank ' : ' True ' } ) , ' fax ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' , ' blank ' : ' True ' } ) , ' fax _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' middle _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' phone ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' } ) , ' phone _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' postal _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '16' , ' blank ' : ' True ' } ) , ' salutation ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' state ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '20' , ' blank ' : ' True ' } ) , ' suffix ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' default ' : ' None ' , ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) , ' user _ updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' student . userprofile ' : { ' Meta ' : { ' object _ name ' : ' UserProfile ' , ' db _ table ' : " ' auth _ userprofile ' " } , ' courseware ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' course . xml ' " , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' gender ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' goals ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' level _ of _ education ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' mailing _ address ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' profile ' " , ' unique ' : ' True ' , ' to ' : " orm [ ' auth . User ' ] " } ) , ' year _ of _ birth ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' student . usertestgroup ' : { ' Meta ' : { ' object _ name ' : ' UserTestGroup ' } , ' description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' users ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' db _ index ' : ' True ' , ' symmetrical ' : ' False ' } ) } } NEW_LINE complete_apps = [ ' student ' ] NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="achoy/cwapi/tree/master/backend/py-server/flask/lib/python3.6/site-packages/six.py"> """ Utilities ▁ for ▁ writing ▁ code ▁ that ▁ runs ▁ on ▁ Python ▁ 2 ▁ and ▁ 3 """ NEW_LINE # ▁ Copyright ▁ ( c ) ▁ 2010-2015 ▁ Benjamin ▁ Peterson ENDCOM # ▁ Permission ▁ is ▁ hereby ▁ granted , ▁ free ▁ of ▁ charge , ▁ to ▁ any ▁ person ▁ obtaining ▁ a ▁ copy ENDCOM # ▁ of ▁ this ▁ software ▁ and ▁ associated ▁ documentation ▁ files ▁ ( the ▁ " Software " ) , ▁ to ▁ deal ENDCOM # ▁ in ▁ the ▁ Software ▁ without ▁ restriction , ▁ including ▁ without ▁ limitation ▁ the ▁ rights ENDCOM # ▁ to ▁ use , ▁ copy , ▁ modify , ▁ merge , ▁ publish , ▁ distribute , ▁ sublicense , ▁ and / or ▁ sell ENDCOM # ▁ copies ▁ of ▁ the ▁ Software , ▁ and ▁ to ▁ permit ▁ persons ▁ to ▁ whom ▁ the ▁ Software ▁ is ENDCOM # ▁ furnished ▁ to ▁ do ▁ so , ▁ subject ▁ to ▁ the ▁ following ▁ conditions : ENDCOM # ▁ The ▁ above ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ shall ▁ be ▁ included ▁ in ▁ all ENDCOM # ▁ copies ▁ or ▁ substantial ▁ portions ▁ of ▁ the ▁ Software . ENDCOM # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ " AS ▁ IS " , ▁ WITHOUT ▁ WARRANTY ▁ OF ▁ ANY ▁ KIND , ▁ EXPRESS ▁ OR ENDCOM # ▁ IMPLIED , ▁ INCLUDING ▁ BUT ▁ NOT ▁ LIMITED ▁ TO ▁ THE ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY , ENDCOM # ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ AND ▁ NONINFRINGEMENT . ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ENDCOM # ▁ AUTHORS ▁ OR ▁ COPYRIGHT ▁ HOLDERS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ CLAIM , ▁ DAMAGES ▁ OR ▁ OTHER ENDCOM # ▁ LIABILITY , ▁ WHETHER ▁ IN ▁ AN ▁ ACTION ▁ OF ▁ CONTRACT , ▁ TORT ▁ OR ▁ OTHERWISE , ▁ ARISING ▁ FROM , ENDCOM # ▁ OUT ▁ OF ▁ OR ▁ IN ▁ CONNECTION ▁ WITH ▁ THE ▁ SOFTWARE ▁ OR ▁ THE ▁ USE ▁ OR ▁ OTHER ▁ DEALINGS ▁ IN ▁ THE ENDCOM # ▁ SOFTWARE . ENDCOM from __future__ import absolute_import NEW_LINE import functools NEW_LINE import itertools NEW_LINE import operator NEW_LINE import sys NEW_LINE import types NEW_LINE __author__ = " Benjamin ▁ Peterson ▁ < benjamin @ python . org > " NEW_LINE __version__ = "1.10.0" NEW_LINE # ▁ Useful ▁ for ▁ very ▁ coarse ▁ version ▁ differentiation . ENDCOM PY2 = sys . version_info [ 0 ] == 2 NEW_LINE PY3 = sys . version_info [ 0 ] == 3 NEW_LINE PY34 = sys . version_info [ 0 : 2 ] >= ( 3 , 4 ) NEW_LINE if PY3 : NEW_LINE INDENT string_types = str , NEW_LINE integer_types = int , NEW_LINE class_types = type , NEW_LINE text_type = str NEW_LINE binary_type = bytes NEW_LINE MAXSIZE = sys . maxsize NEW_LINE DEDENT else : NEW_LINE INDENT string_types = basestring , NEW_LINE integer_types = ( int , long ) NEW_LINE class_types = ( type , types . ClassType ) NEW_LINE text_type = unicode NEW_LINE binary_type = str NEW_LINE if sys . platform . startswith ( " java " ) : NEW_LINE # ▁ Jython ▁ always ▁ uses ▁ 32 ▁ bits . ENDCOM INDENT MAXSIZE = int ( ( 1 << 31 ) - 1 ) NEW_LINE DEDENT else : NEW_LINE # ▁ It ' s ▁ possible ▁ to ▁ have ▁ sizeof ( long ) ▁ ! = ▁ sizeof ( Py _ ssize _ t ) . ENDCOM INDENT class X ( object ) : NEW_LINE INDENT def __len__ ( self ) : NEW_LINE INDENT return 1 << 31 NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT len ( X ( ) ) NEW_LINE DEDENT except OverflowError : NEW_LINE # ▁ 32 - bit ENDCOM INDENT MAXSIZE = int ( ( 1 << 31 ) - 1 ) NEW_LINE DEDENT else : NEW_LINE # ▁ 64 - bit ENDCOM INDENT MAXSIZE = int ( ( 1 << 63 ) - 1 ) NEW_LINE DEDENT del X NEW_LINE DEDENT DEDENT def _add_doc ( func , doc ) : NEW_LINE INDENT """ Add ▁ documentation ▁ to ▁ a ▁ function . """ NEW_LINE func . __doc__ = doc NEW_LINE DEDENT def _import_module ( name ) : NEW_LINE INDENT """ Import ▁ module , ▁ returning ▁ the ▁ module ▁ after ▁ the ▁ last ▁ dot . """ NEW_LINE __import__ ( name ) NEW_LINE return sys . modules [ name ] NEW_LINE DEDENT class _LazyDescr ( object ) : NEW_LINE INDENT def __init__ ( self , name ) : NEW_LINE INDENT self . name = name NEW_LINE DEDENT def __get__ ( self , obj , tp ) : NEW_LINE INDENT result = self . _resolve ( ) NEW_LINE setattr ( obj , self . name , result ) # ▁ Invokes ▁ _ _ set _ _ . ENDCOM NEW_LINE try : NEW_LINE # ▁ This ▁ is ▁ a ▁ bit ▁ ugly , ▁ but ▁ it ▁ avoids ▁ running ▁ this ▁ again ▁ by ENDCOM # ▁ removing ▁ this ▁ descriptor . ENDCOM INDENT delattr ( obj . __class__ , self . name ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT pass NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT class MovedModule ( _LazyDescr ) : NEW_LINE INDENT def __init__ ( self , name , old , new = None ) : NEW_LINE INDENT super ( MovedModule , self ) . __init__ ( name ) NEW_LINE if PY3 : NEW_LINE INDENT if new is None : NEW_LINE INDENT new = name NEW_LINE DEDENT self . mod = new NEW_LINE DEDENT else : NEW_LINE INDENT self . mod = old NEW_LINE DEDENT DEDENT def _resolve ( self ) : NEW_LINE INDENT return _import_module ( self . mod ) NEW_LINE DEDENT def __getattr__ ( self , attr ) : NEW_LINE INDENT _module = self . _resolve ( ) NEW_LINE value = getattr ( _module , attr ) NEW_LINE setattr ( self , attr , value ) NEW_LINE return value NEW_LINE DEDENT DEDENT class _LazyModule ( types . ModuleType ) : NEW_LINE INDENT def __init__ ( self , name ) : NEW_LINE INDENT super ( _LazyModule , self ) . __init__ ( name ) NEW_LINE self . __doc__ = self . __class__ . __doc__ NEW_LINE DEDENT def __dir__ ( self ) : NEW_LINE INDENT attrs = [ " _ _ doc _ _ " , " _ _ name _ _ " ] NEW_LINE attrs += [ attr . name for attr in self . _moved_attributes ] NEW_LINE return attrs NEW_LINE # ▁ Subclasses ▁ should ▁ override ▁ this ENDCOM DEDENT _moved_attributes = [ ] NEW_LINE DEDENT class MovedAttribute ( _LazyDescr ) : NEW_LINE INDENT def __init__ ( self , name , old_mod , new_mod , old_attr = None , new_attr = None ) : NEW_LINE INDENT super ( MovedAttribute , self ) . __init__ ( name ) NEW_LINE if PY3 : NEW_LINE INDENT if new_mod is None : NEW_LINE INDENT new_mod = name NEW_LINE DEDENT self . mod = new_mod NEW_LINE if new_attr is None : NEW_LINE INDENT if old_attr is None : NEW_LINE INDENT new_attr = name NEW_LINE DEDENT else : NEW_LINE INDENT new_attr = old_attr NEW_LINE DEDENT DEDENT self . attr = new_attr NEW_LINE DEDENT else : NEW_LINE INDENT self . mod = old_mod NEW_LINE if old_attr is None : NEW_LINE INDENT old_attr = name NEW_LINE DEDENT self . attr = old_attr NEW_LINE DEDENT DEDENT def _resolve ( self ) : NEW_LINE INDENT module = _import_module ( self . mod ) NEW_LINE return getattr ( module , self . attr ) NEW_LINE DEDENT DEDENT class _SixMetaPathImporter ( object ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ meta ▁ path ▁ importer ▁ to ▁ import ▁ six . moves ▁ and ▁ its ▁ submodules . STRNEWLINE STRNEWLINE ▁ This ▁ class ▁ implements ▁ a ▁ PEP302 ▁ finder ▁ and ▁ loader . ▁ It ▁ should ▁ be ▁ compatible STRNEWLINE ▁ with ▁ Python ▁ 2.5 ▁ and ▁ all ▁ existing ▁ versions ▁ of ▁ Python3 STRNEWLINE ▁ """ NEW_LINE def __init__ ( self , six_module_name ) : NEW_LINE INDENT self . name = six_module_name NEW_LINE self . known_modules = { } NEW_LINE DEDENT def _add_module ( self , mod , * fullnames ) : NEW_LINE INDENT for fullname in fullnames : NEW_LINE INDENT self . known_modules [ self . name + " . " + fullname ] = mod NEW_LINE DEDENT DEDENT def _get_module ( self , fullname ) : NEW_LINE INDENT return self . known_modules [ self . name + " . " + fullname ] NEW_LINE DEDENT def find_module ( self , fullname , path = None ) : NEW_LINE INDENT if fullname in self . known_modules : NEW_LINE INDENT return self NEW_LINE DEDENT return None NEW_LINE DEDENT def __get_module ( self , fullname ) : NEW_LINE INDENT try : NEW_LINE INDENT return self . known_modules [ fullname ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ImportError ( " This ▁ loader ▁ does ▁ not ▁ know ▁ module ▁ " + fullname ) NEW_LINE DEDENT DEDENT def load_module ( self , fullname ) : NEW_LINE INDENT try : NEW_LINE # ▁ in ▁ case ▁ of ▁ a ▁ reload ENDCOM INDENT return sys . modules [ fullname ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT mod = self . __get_module ( fullname ) NEW_LINE if isinstance ( mod , MovedModule ) : NEW_LINE INDENT mod = mod . _resolve ( ) NEW_LINE DEDENT else : NEW_LINE INDENT mod . __loader__ = self NEW_LINE DEDENT sys . modules [ fullname ] = mod NEW_LINE return mod NEW_LINE DEDENT def is_package ( self , fullname ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ true , ▁ if ▁ the ▁ named ▁ module ▁ is ▁ a ▁ package . STRNEWLINE STRNEWLINE ▁ We ▁ need ▁ this ▁ method ▁ to ▁ get ▁ correct ▁ spec ▁ objects ▁ with STRNEWLINE ▁ Python ▁ 3.4 ▁ ( see ▁ PEP451 ) STRNEWLINE ▁ """ NEW_LINE return hasattr ( self . __get_module ( fullname ) , " _ _ path _ _ " ) NEW_LINE DEDENT def get_code ( self , fullname ) : NEW_LINE INDENT """ Return ▁ None STRNEWLINE STRNEWLINE ▁ Required , ▁ if ▁ is _ package ▁ is ▁ implemented """ NEW_LINE self . __get_module ( fullname ) # ▁ eventually ▁ raises ▁ ImportError ENDCOM NEW_LINE return None NEW_LINE DEDENT get_source = get_code # ▁ same ▁ as ▁ get _ code ENDCOM NEW_LINE DEDENT _importer = _SixMetaPathImporter ( __name__ ) NEW_LINE class _MovedItems ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects """ NEW_LINE __path__ = [ ] # ▁ mark ▁ as ▁ package ENDCOM NEW_LINE DEDENT _moved_attributes = [ MovedAttribute ( " cStringIO " , " cStringIO " , " io " , " StringIO " ) , MovedAttribute ( " filter " , " itertools " , " builtins " , " ifilter " , " filter " ) , MovedAttribute ( " filterfalse " , " itertools " , " itertools " , " ifilterfalse " , " filterfalse " ) , MovedAttribute ( " input " , " _ _ builtin _ _ " , " builtins " , " raw _ input " , " input " ) , MovedAttribute ( " intern " , " _ _ builtin _ _ " , " sys " ) , MovedAttribute ( " map " , " itertools " , " builtins " , " imap " , " map " ) , MovedAttribute ( " getcwd " , " os " , " os " , " getcwdu " , " getcwd " ) , MovedAttribute ( " getcwdb " , " os " , " os " , " getcwd " , " getcwdb " ) , MovedAttribute ( " range " , " _ _ builtin _ _ " , " builtins " , " xrange " , " range " ) , MovedAttribute ( " reload _ module " , " _ _ builtin _ _ " , " importlib " if PY34 else " imp " , " reload " ) , MovedAttribute ( " reduce " , " _ _ builtin _ _ " , " functools " ) , MovedAttribute ( " shlex _ quote " , " pipes " , " shlex " , " quote " ) , MovedAttribute ( " StringIO " , " StringIO " , " io " ) , MovedAttribute ( " UserDict " , " UserDict " , " collections " ) , MovedAttribute ( " UserList " , " UserList " , " collections " ) , MovedAttribute ( " UserString " , " UserString " , " collections " ) , MovedAttribute ( " xrange " , " _ _ builtin _ _ " , " builtins " , " xrange " , " range " ) , MovedAttribute ( " zip " , " itertools " , " builtins " , " izip " , " zip " ) , MovedAttribute ( " zip _ longest " , " itertools " , " itertools " , " izip _ longest " , " zip _ longest " ) , MovedModule ( " builtins " , " _ _ builtin _ _ " ) , MovedModule ( " configparser " , " ConfigParser " ) , MovedModule ( " copyreg " , " copy _ reg " ) , MovedModule ( " dbm _ gnu " , " gdbm " , " dbm . gnu " ) , MovedModule ( " _ dummy _ thread " , " dummy _ thread " , " _ dummy _ thread " ) , MovedModule ( " http _ cookiejar " , " cookielib " , " http . cookiejar " ) , MovedModule ( " http _ cookies " , " Cookie " , " http . cookies " ) , MovedModule ( " html _ entities " , " htmlentitydefs " , " html . entities " ) , MovedModule ( " html _ parser " , " HTMLParser " , " html . parser " ) , MovedModule ( " http _ client " , " httplib " , " http . client " ) , MovedModule ( " email _ mime _ multipart " , " email . MIMEMultipart " , " email . mime . multipart " ) , MovedModule ( " email _ mime _ nonmultipart " , " email . MIMENonMultipart " , " email . mime . nonmultipart " ) , MovedModule ( " email _ mime _ text " , " email . MIMEText " , " email . mime . text " ) , MovedModule ( " email _ mime _ base " , " email . MIMEBase " , " email . mime . base " ) , MovedModule ( " BaseHTTPServer " , " BaseHTTPServer " , " http . server " ) , MovedModule ( " CGIHTTPServer " , " CGIHTTPServer " , " http . server " ) , MovedModule ( " SimpleHTTPServer " , " SimpleHTTPServer " , " http . server " ) , MovedModule ( " cPickle " , " cPickle " , " pickle " ) , MovedModule ( " queue " , " Queue " ) , MovedModule ( " reprlib " , " repr " ) , MovedModule ( " socketserver " , " SocketServer " ) , MovedModule ( " _ thread " , " thread " , " _ thread " ) , MovedModule ( " tkinter " , " Tkinter " ) , MovedModule ( " tkinter _ dialog " , " Dialog " , " tkinter . dialog " ) , MovedModule ( " tkinter _ filedialog " , " FileDialog " , " tkinter . filedialog " ) , MovedModule ( " tkinter _ scrolledtext " , " ScrolledText " , " tkinter . scrolledtext " ) , MovedModule ( " tkinter _ simpledialog " , " SimpleDialog " , " tkinter . simpledialog " ) , MovedModule ( " tkinter _ tix " , " Tix " , " tkinter . tix " ) , MovedModule ( " tkinter _ ttk " , " ttk " , " tkinter . ttk " ) , MovedModule ( " tkinter _ constants " , " Tkconstants " , " tkinter . constants " ) , MovedModule ( " tkinter _ dnd " , " Tkdnd " , " tkinter . dnd " ) , MovedModule ( " tkinter _ colorchooser " , " tkColorChooser " , " tkinter . colorchooser " ) , MovedModule ( " tkinter _ commondialog " , " tkCommonDialog " , " tkinter . commondialog " ) , MovedModule ( " tkinter _ tkfiledialog " , " tkFileDialog " , " tkinter . filedialog " ) , MovedModule ( " tkinter _ font " , " tkFont " , " tkinter . font " ) , MovedModule ( " tkinter _ messagebox " , " tkMessageBox " , " tkinter . messagebox " ) , MovedModule ( " tkinter _ tksimpledialog " , " tkSimpleDialog " , " tkinter . simpledialog " ) , MovedModule ( " urllib _ parse " , __name__ + " . moves . urllib _ parse " , " urllib . parse " ) , MovedModule ( " urllib _ error " , __name__ + " . moves . urllib _ error " , " urllib . error " ) , MovedModule ( " urllib " , __name__ + " . moves . urllib " , __name__ + " . moves . urllib " ) , MovedModule ( " urllib _ robotparser " , " robotparser " , " urllib . robotparser " ) , MovedModule ( " xmlrpc _ client " , " xmlrpclib " , " xmlrpc . client " ) , MovedModule ( " xmlrpc _ server " , " SimpleXMLRPCServer " , " xmlrpc . server " ) , ] NEW_LINE # ▁ Add ▁ windows ▁ specific ▁ modules . ENDCOM if sys . platform == " win32" : NEW_LINE INDENT _moved_attributes += [ MovedModule ( " winreg " , " _ winreg " ) , ] NEW_LINE DEDENT for attr in _moved_attributes : NEW_LINE INDENT setattr ( _MovedItems , attr . name , attr ) NEW_LINE if isinstance ( attr , MovedModule ) : NEW_LINE INDENT _importer . _add_module ( attr , " moves . " + attr . name ) NEW_LINE DEDENT DEDENT del attr NEW_LINE _MovedItems . _moved_attributes = _moved_attributes NEW_LINE moves = _MovedItems ( __name__ + " . moves " ) NEW_LINE _importer . _add_module ( moves , " moves " ) NEW_LINE class Module_six_moves_urllib_parse ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ parse """ NEW_LINE DEDENT _urllib_parse_moved_attributes = [ MovedAttribute ( " ParseResult " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " SplitResult " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " parse _ qs " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " parse _ qsl " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urldefrag " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urljoin " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlparse " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlsplit " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlunparse " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlunsplit " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " quote " , " urllib " , " urllib . parse " ) , MovedAttribute ( " quote _ plus " , " urllib " , " urllib . parse " ) , MovedAttribute ( " unquote " , " urllib " , " urllib . parse " ) , MovedAttribute ( " unquote _ plus " , " urllib " , " urllib . parse " ) , MovedAttribute ( " urlencode " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splitquery " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splittag " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splituser " , " urllib " , " urllib . parse " ) , MovedAttribute ( " uses _ fragment " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ netloc " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ params " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ query " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ relative " , " urlparse " , " urllib . parse " ) , ] NEW_LINE for attr in _urllib_parse_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_parse , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_parse . _moved_attributes = _urllib_parse_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_parse ( __name__ + " . moves . urllib _ parse " ) , " moves . urllib _ parse " , " moves . urllib . parse " ) NEW_LINE class Module_six_moves_urllib_error ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ error """ NEW_LINE DEDENT _urllib_error_moved_attributes = [ MovedAttribute ( " URLError " , " urllib2" , " urllib . error " ) , MovedAttribute ( " HTTPError " , " urllib2" , " urllib . error " ) , MovedAttribute ( " ContentTooShortError " , " urllib " , " urllib . error " ) , ] NEW_LINE for attr in _urllib_error_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_error , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_error . _moved_attributes = _urllib_error_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_error ( __name__ + " . moves . urllib . error " ) , " moves . urllib _ error " , " moves . urllib . error " ) NEW_LINE class Module_six_moves_urllib_request ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ request """ NEW_LINE DEDENT _urllib_request_moved_attributes = [ MovedAttribute ( " urlopen " , " urllib2" , " urllib . request " ) , MovedAttribute ( " install _ opener " , " urllib2" , " urllib . request " ) , MovedAttribute ( " build _ opener " , " urllib2" , " urllib . request " ) , MovedAttribute ( " pathname2url " , " urllib " , " urllib . request " ) , MovedAttribute ( " url2pathname " , " urllib " , " urllib . request " ) , MovedAttribute ( " getproxies " , " urllib " , " urllib . request " ) , MovedAttribute ( " Request " , " urllib2" , " urllib . request " ) , MovedAttribute ( " OpenerDirector " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPDefaultErrorHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPRedirectHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPCookieProcessor " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " BaseHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPPasswordMgr " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPPasswordMgrWithDefaultRealm " , " urllib2" , " urllib . request " ) , MovedAttribute ( " AbstractBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " AbstractDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPSHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " FileHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " FTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " CacheFTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " UnknownHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPErrorProcessor " , " urllib2" , " urllib . request " ) , MovedAttribute ( " urlretrieve " , " urllib " , " urllib . request " ) , MovedAttribute ( " urlcleanup " , " urllib " , " urllib . request " ) , MovedAttribute ( " URLopener " , " urllib " , " urllib . request " ) , MovedAttribute ( " FancyURLopener " , " urllib " , " urllib . request " ) , MovedAttribute ( " proxy _ bypass " , " urllib " , " urllib . request " ) , ] NEW_LINE for attr in _urllib_request_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_request , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_request . _moved_attributes = _urllib_request_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_request ( __name__ + " . moves . urllib . request " ) , " moves . urllib _ request " , " moves . urllib . request " ) NEW_LINE class Module_six_moves_urllib_response ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ response """ NEW_LINE DEDENT _urllib_response_moved_attributes = [ MovedAttribute ( " addbase " , " urllib " , " urllib . response " ) , MovedAttribute ( " addclosehook " , " urllib " , " urllib . response " ) , MovedAttribute ( " addinfo " , " urllib " , " urllib . response " ) , MovedAttribute ( " addinfourl " , " urllib " , " urllib . response " ) , ] NEW_LINE for attr in _urllib_response_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_response , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_response . _moved_attributes = _urllib_response_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_response ( __name__ + " . moves . urllib . response " ) , " moves . urllib _ response " , " moves . urllib . response " ) NEW_LINE class Module_six_moves_urllib_robotparser ( _LazyModule ) : NEW_LINE INDENT """ Lazy ▁ loading ▁ of ▁ moved ▁ objects ▁ in ▁ six . moves . urllib _ robotparser """ NEW_LINE DEDENT _urllib_robotparser_moved_attributes = [ MovedAttribute ( " RobotFileParser " , " robotparser " , " urllib . robotparser " ) , ] NEW_LINE for attr in _urllib_robotparser_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_robotparser , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_robotparser . _moved_attributes = _urllib_robotparser_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_robotparser ( __name__ + " . moves . urllib . robotparser " ) , " moves . urllib _ robotparser " , " moves . urllib . robotparser " ) NEW_LINE class Module_six_moves_urllib ( types . ModuleType ) : NEW_LINE INDENT """ Create ▁ a ▁ six . moves . urllib ▁ namespace ▁ that ▁ resembles ▁ the ▁ Python ▁ 3 ▁ namespace """ NEW_LINE __path__ = [ ] # ▁ mark ▁ as ▁ package ENDCOM NEW_LINE parse = _importer . _get_module ( " moves . urllib _ parse " ) NEW_LINE error = _importer . _get_module ( " moves . urllib _ error " ) NEW_LINE request = _importer . _get_module ( " moves . urllib _ request " ) NEW_LINE response = _importer . _get_module ( " moves . urllib _ response " ) NEW_LINE robotparser = _importer . _get_module ( " moves . urllib _ robotparser " ) NEW_LINE def __dir__ ( self ) : NEW_LINE INDENT return [ ' parse ' , ' error ' , ' request ' , ' response ' , ' robotparser ' ] NEW_LINE DEDENT DEDENT _importer . _add_module ( Module_six_moves_urllib ( __name__ + " . moves . urllib " ) , " moves . urllib " ) NEW_LINE def add_move ( move ) : NEW_LINE INDENT """ Add ▁ an ▁ item ▁ to ▁ six . moves . """ NEW_LINE setattr ( _MovedItems , move . name , move ) NEW_LINE DEDENT def remove_move ( name ) : NEW_LINE INDENT """ Remove ▁ item ▁ from ▁ six . moves . """ NEW_LINE try : NEW_LINE INDENT delattr ( _MovedItems , name ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT try : NEW_LINE INDENT del moves . __dict__ [ name ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise AttributeError ( " no ▁ such ▁ move , ▁ % r " % ( name , ) ) NEW_LINE DEDENT DEDENT DEDENT if PY3 : NEW_LINE INDENT _meth_func = " _ _ func _ _ " NEW_LINE _meth_self = " _ _ self _ _ " NEW_LINE _func_closure = " _ _ closure _ _ " NEW_LINE _func_code = " _ _ code _ _ " NEW_LINE _func_defaults = " _ _ defaults _ _ " NEW_LINE _func_globals = " _ _ globals _ _ " NEW_LINE DEDENT else : NEW_LINE INDENT _meth_func = " im _ func " NEW_LINE _meth_self = " im _ self " NEW_LINE _func_closure = " func _ closure " NEW_LINE _func_code = " func _ code " NEW_LINE _func_defaults = " func _ defaults " NEW_LINE _func_globals = " func _ globals " NEW_LINE DEDENT try : NEW_LINE INDENT advance_iterator = next NEW_LINE DEDENT except NameError : NEW_LINE INDENT def advance_iterator ( it ) : NEW_LINE INDENT return it . next ( ) NEW_LINE DEDENT DEDENT next = advance_iterator NEW_LINE try : NEW_LINE INDENT callable = callable NEW_LINE DEDENT except NameError : NEW_LINE INDENT def callable ( obj ) : NEW_LINE INDENT return any ( " _ _ call _ _ " in klass . __dict__ for klass in type ( obj ) . __mro__ ) NEW_LINE DEDENT DEDENT if PY3 : NEW_LINE INDENT def get_unbound_function ( unbound ) : NEW_LINE INDENT return unbound NEW_LINE DEDENT create_bound_method = types . MethodType NEW_LINE def create_unbound_method ( func , cls ) : NEW_LINE INDENT return func NEW_LINE DEDENT Iterator = object NEW_LINE DEDENT else : NEW_LINE INDENT def get_unbound_function ( unbound ) : NEW_LINE INDENT return unbound . im_func NEW_LINE DEDENT def create_bound_method ( func , obj ) : NEW_LINE INDENT return types . MethodType ( func , obj , obj . __class__ ) NEW_LINE DEDENT def create_unbound_method ( func , cls ) : NEW_LINE INDENT return types . MethodType ( func , None , cls ) NEW_LINE DEDENT class Iterator ( object ) : NEW_LINE INDENT def next ( self ) : NEW_LINE INDENT return type ( self ) . __next__ ( self ) NEW_LINE DEDENT DEDENT callable = callable NEW_LINE DEDENT _add_doc ( get_unbound_function , """ Get ▁ the ▁ function ▁ out ▁ of ▁ a ▁ possibly ▁ unbound ▁ function """ ) NEW_LINE get_method_function = operator . attrgetter ( _meth_func ) NEW_LINE get_method_self = operator . attrgetter ( _meth_self ) NEW_LINE get_function_closure = operator . attrgetter ( _func_closure ) NEW_LINE get_function_code = operator . attrgetter ( _func_code ) NEW_LINE get_function_defaults = operator . attrgetter ( _func_defaults ) NEW_LINE get_function_globals = operator . attrgetter ( _func_globals ) NEW_LINE if PY3 : NEW_LINE INDENT def iterkeys ( d , ** kw ) : NEW_LINE INDENT return iter ( d . keys ( ** kw ) ) NEW_LINE DEDENT def itervalues ( d , ** kw ) : NEW_LINE INDENT return iter ( d . values ( ** kw ) ) NEW_LINE DEDENT def iteritems ( d , ** kw ) : NEW_LINE INDENT return iter ( d . items ( ** kw ) ) NEW_LINE DEDENT def iterlists ( d , ** kw ) : NEW_LINE INDENT return iter ( d . lists ( ** kw ) ) NEW_LINE DEDENT viewkeys = operator . methodcaller ( " keys " ) NEW_LINE viewvalues = operator . methodcaller ( " values " ) NEW_LINE viewitems = operator . methodcaller ( " items " ) NEW_LINE DEDENT else : NEW_LINE INDENT def iterkeys ( d , ** kw ) : NEW_LINE INDENT return d . iterkeys ( ** kw ) NEW_LINE DEDENT def itervalues ( d , ** kw ) : NEW_LINE INDENT return d . itervalues ( ** kw ) NEW_LINE DEDENT def iteritems ( d , ** kw ) : NEW_LINE INDENT return d . iteritems ( ** kw ) NEW_LINE DEDENT def iterlists ( d , ** kw ) : NEW_LINE INDENT return d . iterlists ( ** kw ) NEW_LINE DEDENT viewkeys = operator . methodcaller ( " viewkeys " ) NEW_LINE viewvalues = operator . methodcaller ( " viewvalues " ) NEW_LINE viewitems = operator . methodcaller ( " viewitems " ) NEW_LINE DEDENT _add_doc ( iterkeys , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ keys ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( itervalues , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ values ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( iteritems , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ ( key , ▁ value ) ▁ pairs ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( iterlists , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ ( key , ▁ [ values ] ) ▁ pairs ▁ of ▁ a ▁ dictionary . " ) NEW_LINE if PY3 : NEW_LINE INDENT def b ( s ) : NEW_LINE INDENT return s . encode ( " latin - 1" ) NEW_LINE DEDENT def u ( s ) : NEW_LINE INDENT return s NEW_LINE DEDENT unichr = chr NEW_LINE import struct NEW_LINE int2byte = struct . Struct ( " > B " ) . pack NEW_LINE del struct NEW_LINE byte2int = operator . itemgetter ( 0 ) NEW_LINE indexbytes = operator . getitem NEW_LINE iterbytes = iter NEW_LINE import io NEW_LINE StringIO = io . StringIO NEW_LINE BytesIO = io . BytesIO NEW_LINE _assertCountEqual = " assertCountEqual " NEW_LINE if sys . version_info [ 1 ] <= 1 : NEW_LINE INDENT _assertRaisesRegex = " assertRaisesRegexp " NEW_LINE _assertRegex = " assertRegexpMatches " NEW_LINE DEDENT else : NEW_LINE INDENT _assertRaisesRegex = " assertRaisesRegex " NEW_LINE _assertRegex = " assertRegex " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def b ( s ) : NEW_LINE INDENT return s NEW_LINE # ▁ Workaround ▁ for ▁ standalone ▁ backslash ENDCOM DEDENT def u ( s ) : NEW_LINE INDENT return unicode ( s . replace ( r ' \\ ' , r ' \\\\ ' ) , " unicode _ escape " ) NEW_LINE DEDENT unichr = unichr NEW_LINE int2byte = chr NEW_LINE def byte2int ( bs ) : NEW_LINE INDENT return ord ( bs [ 0 ] ) NEW_LINE DEDENT def indexbytes ( buf , i ) : NEW_LINE INDENT return ord ( buf [ i ] ) NEW_LINE DEDENT iterbytes = functools . partial ( itertools . imap , ord ) NEW_LINE import StringIO NEW_LINE StringIO = BytesIO = StringIO . StringIO NEW_LINE _assertCountEqual = " assertItemsEqual " NEW_LINE _assertRaisesRegex = " assertRaisesRegexp " NEW_LINE _assertRegex = " assertRegexpMatches " NEW_LINE DEDENT _add_doc ( b , """ Byte ▁ literal """ ) NEW_LINE _add_doc ( u , """ Text ▁ literal """ ) NEW_LINE def assertCountEqual ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertCountEqual ) ( * args , ** kwargs ) NEW_LINE DEDENT def assertRaisesRegex ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertRaisesRegex ) ( * args , ** kwargs ) NEW_LINE DEDENT def assertRegex ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertRegex ) ( * args , ** kwargs ) NEW_LINE DEDENT if PY3 : NEW_LINE INDENT exec_ = getattr ( moves . builtins , " exec " ) NEW_LINE def reraise ( tp , value , tb = None ) : NEW_LINE INDENT if value is None : NEW_LINE INDENT value = tp ( ) NEW_LINE DEDENT if value . __traceback__ is not tb : NEW_LINE INDENT raise value . with_traceback ( tb ) NEW_LINE DEDENT raise value NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def exec_ ( _code_ , _globs_ = None , _locs_ = None ) : NEW_LINE INDENT """ Execute ▁ code ▁ in ▁ a ▁ namespace . """ NEW_LINE if _globs_ is None : NEW_LINE INDENT frame = sys . _getframe ( 1 ) NEW_LINE _globs_ = frame . f_globals NEW_LINE if _locs_ is None : NEW_LINE INDENT _locs_ = frame . f_locals NEW_LINE DEDENT del frame NEW_LINE DEDENT elif _locs_ is None : NEW_LINE INDENT _locs_ = _globs_ NEW_LINE DEDENT exec ( """ exec ▁ _ code _ ▁ in ▁ _ globs _ , ▁ _ locs _ """ ) NEW_LINE DEDENT exec_ ( """ def ▁ reraise ( tp , ▁ value , ▁ tb = None ) : STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ tp , ▁ value , ▁ tb STRNEWLINE """ ) NEW_LINE DEDENT if sys . version_info [ : 2 ] == ( 3 , 2 ) : NEW_LINE INDENT exec_ ( """ def ▁ raise _ from ( value , ▁ from _ value ) : STRNEWLINE ▁ ▁ ▁ ▁ if ▁ from _ value ▁ is ▁ None : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ raise ▁ value STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ value ▁ from ▁ from _ value STRNEWLINE """ ) NEW_LINE DEDENT elif sys . version_info [ : 2 ] > ( 3 , 2 ) : NEW_LINE INDENT exec_ ( """ def ▁ raise _ from ( value , ▁ from _ value ) : STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ value ▁ from ▁ from _ value STRNEWLINE """ ) NEW_LINE DEDENT else : NEW_LINE INDENT def raise_from ( value , from_value ) : NEW_LINE INDENT raise value NEW_LINE DEDENT DEDENT print_ = getattr ( moves . builtins , " print " , None ) NEW_LINE if print_ is None : NEW_LINE INDENT def print_ ( * args , ** kwargs ) : NEW_LINE INDENT """ The ▁ new - style ▁ print ▁ function ▁ for ▁ Python ▁ 2.4 ▁ and ▁ 2.5 . """ NEW_LINE fp = kwargs . pop ( " file " , sys . stdout ) NEW_LINE if fp is None : NEW_LINE INDENT return NEW_LINE DEDENT def write ( data ) : NEW_LINE INDENT if not isinstance ( data , basestring ) : NEW_LINE INDENT data = str ( data ) NEW_LINE # ▁ If ▁ the ▁ file ▁ has ▁ an ▁ encoding , ▁ encode ▁ unicode ▁ with ▁ it . ENDCOM DEDENT if ( isinstance ( fp , file ) and isinstance ( data , unicode ) and fp . encoding is not None ) : NEW_LINE INDENT errors = getattr ( fp , " errors " , None ) NEW_LINE if errors is None : NEW_LINE INDENT errors = " strict " NEW_LINE DEDENT data = data . encode ( fp . encoding , errors ) NEW_LINE DEDENT fp . write ( data ) NEW_LINE DEDENT want_unicode = False NEW_LINE sep = kwargs . pop ( " sep " , None ) NEW_LINE if sep is not None : NEW_LINE INDENT if isinstance ( sep , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE DEDENT elif not isinstance ( sep , str ) : NEW_LINE INDENT raise TypeError ( " sep ▁ must ▁ be ▁ None ▁ or ▁ a ▁ string " ) NEW_LINE DEDENT DEDENT end = kwargs . pop ( " end " , None ) NEW_LINE if end is not None : NEW_LINE INDENT if isinstance ( end , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE DEDENT elif not isinstance ( end , str ) : NEW_LINE INDENT raise TypeError ( " end ▁ must ▁ be ▁ None ▁ or ▁ a ▁ string " ) NEW_LINE DEDENT DEDENT if kwargs : NEW_LINE INDENT raise TypeError ( " invalid ▁ keyword ▁ arguments ▁ to ▁ print ( ) " ) NEW_LINE DEDENT if not want_unicode : NEW_LINE INDENT for arg in args : NEW_LINE INDENT if isinstance ( arg , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT if want_unicode : NEW_LINE INDENT newline = unicode ( " \n " ) NEW_LINE space = unicode ( " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT newline = " \n " NEW_LINE space = " ▁ " NEW_LINE DEDENT if sep is None : NEW_LINE INDENT sep = space NEW_LINE DEDENT if end is None : NEW_LINE INDENT end = newline NEW_LINE DEDENT for i , arg in enumerate ( args ) : NEW_LINE INDENT if i : NEW_LINE INDENT write ( sep ) NEW_LINE DEDENT write ( arg ) NEW_LINE DEDENT write ( end ) NEW_LINE DEDENT DEDENT if sys . version_info [ : 2 ] < ( 3 , 3 ) : NEW_LINE INDENT _print = print_ NEW_LINE def print_ ( * args , ** kwargs ) : NEW_LINE INDENT fp = kwargs . get ( " file " , sys . stdout ) NEW_LINE flush = kwargs . pop ( " flush " , False ) NEW_LINE _print ( * args , ** kwargs ) NEW_LINE if flush and fp is not None : NEW_LINE INDENT fp . flush ( ) NEW_LINE DEDENT DEDENT DEDENT _add_doc ( reraise , """ Reraise ▁ an ▁ exception . """ ) NEW_LINE if sys . version_info [ 0 : 2 ] < ( 3 , 4 ) : NEW_LINE INDENT def wraps ( wrapped , assigned = functools . WRAPPER_ASSIGNMENTS , updated = functools . WRAPPER_UPDATES ) : NEW_LINE INDENT def wrapper ( f ) : NEW_LINE INDENT f = functools . wraps ( wrapped , assigned , updated ) ( f ) NEW_LINE f . __wrapped__ = wrapped NEW_LINE return f NEW_LINE DEDENT return wrapper NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT wraps = functools . wraps NEW_LINE DEDENT def with_metaclass ( meta , * bases ) : NEW_LINE INDENT """ Create ▁ a ▁ base ▁ class ▁ with ▁ a ▁ metaclass . """ NEW_LINE # ▁ This ▁ requires ▁ a ▁ bit ▁ of ▁ explanation : ▁ the ▁ basic ▁ idea ▁ is ▁ to ▁ make ▁ a ▁ dummy ENDCOM # ▁ metaclass ▁ for ▁ one ▁ level ▁ of ▁ class ▁ instantiation ▁ that ▁ replaces ▁ itself ▁ with ENDCOM # ▁ the ▁ actual ▁ metaclass . ENDCOM class metaclass ( meta ) : NEW_LINE INDENT def __new__ ( cls , name , this_bases , d ) : NEW_LINE INDENT return meta ( name , bases , d ) NEW_LINE DEDENT DEDENT return type . __new__ ( metaclass , ' temporary _ class ' , ( ) , { } ) NEW_LINE DEDENT def add_metaclass ( metaclass ) : NEW_LINE INDENT """ Class ▁ decorator ▁ for ▁ creating ▁ a ▁ class ▁ with ▁ a ▁ metaclass . """ NEW_LINE def wrapper ( cls ) : NEW_LINE INDENT orig_vars = cls . __dict__ . copy ( ) NEW_LINE slots = orig_vars . get ( ' _ _ slots _ _ ' ) NEW_LINE if slots is not None : NEW_LINE INDENT if isinstance ( slots , str ) : NEW_LINE INDENT slots = [ slots ] NEW_LINE DEDENT for slots_var in slots : NEW_LINE INDENT orig_vars . pop ( slots_var ) NEW_LINE DEDENT DEDENT orig_vars . pop ( ' _ _ dict _ _ ' , None ) NEW_LINE orig_vars . pop ( ' _ _ weakref _ _ ' , None ) NEW_LINE return metaclass ( cls . __name__ , cls . __bases__ , orig_vars ) NEW_LINE DEDENT return wrapper NEW_LINE DEDENT def python_2_unicode_compatible ( klass ) : NEW_LINE INDENT """ STRNEWLINE ▁ A ▁ decorator ▁ that ▁ defines ▁ _ _ unicode _ _ ▁ and ▁ _ _ str _ _ ▁ methods ▁ under ▁ Python ▁ 2 . STRNEWLINE ▁ Under ▁ Python ▁ 3 ▁ it ▁ does ▁ nothing . STRNEWLINE STRNEWLINE ▁ To ▁ support ▁ Python ▁ 2 ▁ and ▁ 3 ▁ with ▁ a ▁ single ▁ code ▁ base , ▁ define ▁ a ▁ _ _ str _ _ ▁ method STRNEWLINE ▁ returning ▁ text ▁ and ▁ apply ▁ this ▁ decorator ▁ to ▁ the ▁ class . STRNEWLINE ▁ """ NEW_LINE if PY2 : NEW_LINE INDENT if ' _ _ str _ _ ' not in klass . __dict__ : NEW_LINE INDENT raise ValueError ( " @ python _ 2 _ unicode _ compatible ▁ cannot ▁ be ▁ applied ▁ " " to ▁ % s ▁ because ▁ it ▁ doesn ' t ▁ define ▁ _ _ str _ _ ( ) . " % klass . __name__ ) NEW_LINE DEDENT klass . __unicode__ = klass . __str__ NEW_LINE klass . __str__ = lambda self : self . __unicode__ ( ) . encode ( ' utf - 8' ) NEW_LINE DEDENT return klass NEW_LINE # ▁ Complete ▁ the ▁ moves ▁ implementation . ENDCOM # ▁ This ▁ code ▁ is ▁ at ▁ the ▁ end ▁ of ▁ this ▁ module ▁ to ▁ speed ▁ up ▁ module ▁ loading . ENDCOM # ▁ Turn ▁ this ▁ module ▁ into ▁ a ▁ package . ENDCOM DEDENT __path__ = [ ] # ▁ required ▁ for ▁ PEP ▁ 302 ▁ and ▁ PEP ▁ 451 ENDCOM NEW_LINE __package__ = __name__ # ▁ see ▁ PEP ▁ 366 ▁ @ ReservedAssignment ENDCOM NEW_LINE if globals ( ) . get ( " _ _ spec _ _ " ) is not None : NEW_LINE INDENT __spec__ . submodule_search_locations = [ ] # ▁ PEP ▁ 451 ▁ @ UndefinedVariable ENDCOM NEW_LINE # ▁ Remove ▁ other ▁ six ▁ meta ▁ path ▁ importers , ▁ since ▁ they ▁ cause ▁ problems . ▁ This ▁ can ENDCOM # ▁ happen ▁ if ▁ six ▁ is ▁ removed ▁ from ▁ sys . modules ▁ and ▁ then ▁ reloaded . ▁ ( Setuptools ▁ does ENDCOM # ▁ this ▁ for ▁ some ▁ reason . ) ENDCOM DEDENT if sys . meta_path : NEW_LINE INDENT for i , importer in enumerate ( sys . meta_path ) : NEW_LINE # ▁ Here ' s ▁ some ▁ real ▁ nastiness : ▁ Another ▁ " instance " ▁ of ▁ the ▁ six ▁ module ▁ might ENDCOM # ▁ be ▁ floating ▁ around . ▁ Therefore , ▁ we ▁ can ' t ▁ use ▁ isinstance ( ) ▁ to ▁ check ▁ for ENDCOM # ▁ the ▁ six ▁ meta ▁ path ▁ importer , ▁ since ▁ the ▁ other ▁ six ▁ instance ▁ will ▁ have ENDCOM # ▁ inserted ▁ an ▁ importer ▁ with ▁ different ▁ class . ENDCOM INDENT if ( type ( importer ) . __name__ == " _ SixMetaPathImporter " and importer . name == __name__ ) : NEW_LINE INDENT del sys . meta_path [ i ] NEW_LINE break NEW_LINE DEDENT DEDENT del i , importer NEW_LINE # ▁ Finally , ▁ add ▁ the ▁ importer ▁ to ▁ the ▁ meta ▁ path ▁ import ▁ hook . ENDCOM DEDENT sys . meta_path . append ( _importer ) NEW_LINE </DOCUMENT>
<DOCUMENT_ID="petecummings/django-cms/tree/master/cms/south_migrations/0015_modified_by_added.py"> # ▁ - * - ▁ coding : ▁ utf - 8 ▁ - * - ENDCOM import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE try : NEW_LINE INDENT from django . contrib . auth import get_user_model NEW_LINE DEDENT except ImportError : # ▁ django ▁ < ▁ 1.5 ENDCOM NEW_LINE INDENT from django . contrib . auth . models import User NEW_LINE DEDENT else : NEW_LINE INDENT User = get_user_model ( ) NEW_LINE DEDENT user_orm_label = ' % s . % s ' % ( User . _meta . app_label , User . _meta . object_name ) NEW_LINE user_model_label = ' % s . % s ' % ( User . _meta . app_label , User . _meta . model_name ) NEW_LINE user_ptr_name = ' % s _ ptr ' % User . _meta . object_name . lower ( ) NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE # ▁ Dummy ▁ migration ENDCOM INDENT pass NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE # ▁ Dummy ▁ migration ENDCOM INDENT pass NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , user_model_label : { ' Meta ' : { ' object _ name ' : User . __name__ , ' db _ table ' : " ' % s ' " % User . _meta . db_table } , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) } , ' cms . cmsplugin ' : { ' Meta ' : { ' object _ name ' : ' CMSPlugin ' } , ' changed _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' blank ' : ' True ' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '15' , ' db _ index ' : ' True ' } ) , ' level ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' lft ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' parent ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . CMSPlugin ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' placeholder ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Placeholder ' ] " , ' null ' : ' True ' } ) , ' plugin _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' position ' : ( ' django . db . models . fields . PositiveSmallIntegerField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' rght ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' tree _ id ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' cms . globalpagepermission ' : { ' Meta ' : { ' object _ name ' : ' GlobalPagePermission ' } , ' can _ add ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change _ advanced _ settings ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ change _ permissions ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ delete ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ moderate ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ move _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ publish ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ recover _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ view ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' group ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' sites ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' symmetrical ' : ' False ' , ' to ' : " orm [ ' sites . Site ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' cms . page ' : { ' Meta ' : { ' ordering ' : " ( ' site ' , ▁ ' tree _ id ' , ▁ ' lft ' ) " , ' object _ name ' : ' Page ' } , ' changed _ by ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '70' } ) , ' changed _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' blank ' : ' True ' } ) , ' created _ by ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '70' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' in _ navigation ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' , ' db _ index ' : ' True ' } ) , ' level ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' lft ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' limit _ visibility _ in _ menu ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : ' None ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' login _ required ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderator _ state ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' , ' blank ' : ' True ' } ) , ' navigation _ extenders ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '80' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' parent ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' blank ' : ' True ' , ' related _ name ' : " ' children ' " , ' null ' : ' True ' , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' placeholders ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' cms . Placeholder ' ] " , ' symmetrical ' : ' False ' } ) , ' publication _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' publication _ end _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' published ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' publisher _ is _ draft ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' , ' db _ index ' : ' True ' } ) , ' publisher _ public ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' publisher _ draft ' " , ' unique ' : ' True ' , ' null ' : ' True ' , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' publisher _ state ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' , ' db _ index ' : ' True ' } ) , ' reverse _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '40' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' rght ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' site ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' sites . Site ' ] " } ) , ' soft _ root ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' , ' db _ index ' : ' True ' } ) , ' template ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' tree _ id ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' cms . pagemoderator ' : { ' Meta ' : { ' object _ name ' : ' PageModerator ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' moderate _ children ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderate _ descendants ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderate _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) } , ' cms . pagemoderatorstate ' : { ' Meta ' : { ' ordering ' : " ( ' page ' , ▁ ' action ' , ▁ ' - created ' ) " , ' object _ name ' : ' PageModeratorState ' } , ' action ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' message ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' default ' : " ' ' " , ' max _ length ' : '1000' , ' blank ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' } ) } , ' cms . pagepermission ' : { ' Meta ' : { ' object _ name ' : ' PagePermission ' } , ' can _ add ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change _ advanced _ settings ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ change _ permissions ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ delete ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ moderate ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ move _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ publish ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ view ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' grant _ on ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '5' } ) , ' group ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' cms . pageuser ' : { ' Meta ' : { ' object _ name ' : ' PageUser ' , ' _ ormbases ' : [ user_orm_label ] } , ' created _ by ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' created _ users ' " , ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) , ' user _ ptr ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' unique ' : ' True ' , ' primary _ key ' : ' True ' } ) } , ' cms . pageusergroup ' : { ' Meta ' : { ' object _ name ' : ' PageUserGroup ' , ' _ ormbases ' : [ ' auth . Group ' ] } , ' created _ by ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' created _ usergroups ' " , ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) , ' group _ ptr ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' unique ' : ' True ' , ' primary _ key ' : ' True ' } ) } , ' cms . placeholder ' : { ' Meta ' : { ' object _ name ' : ' Placeholder ' } , ' default _ width ' : ( ' django . db . models . fields . PositiveSmallIntegerField ' , [ ] , { ' null ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' slot ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) } , ' cms . title ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' language ' , ▁ ' page ' ) , ) " , ' object _ name ' : ' Title ' } , ' application _ urls ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '200' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' has _ url _ overwrite ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '15' , ' db _ index ' : ' True ' } ) , ' menu _ title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta _ description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta _ keywords ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' title _ set ' " , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' page _ title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' path ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' redirect ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' slug ' : ( ' django . db . models . fields . SlugField ' , [ ] , { ' max _ length ' : '255' } ) , ' title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' sites . site ' : { ' Meta ' : { ' ordering ' : " ( ' domain ' , ) " , ' object _ name ' : ' Site ' , ' db _ table ' : " ' django _ site ' " } , ' domain ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } } NEW_LINE complete_apps = [ ' cms ' ] NEW_LINE DEDENT </DOCUMENT>
<DOCUMENT_ID="sbstp/streamlink/tree/master/src/streamlink/plugins/alieztv.py"> import re NEW_LINE from os . path import splitext NEW_LINE from streamlink . compat import urlparse , unquote NEW_LINE from streamlink . plugin import Plugin NEW_LINE from streamlink . plugin . api import http , validate NEW_LINE from streamlink . stream import HTTPStream , RTMPStream NEW_LINE _url_re = re . compile ( """ STRNEWLINE ▁ ▁ ▁ ▁ http ( s ) ? : / / ( \w + \ . ) ? aliez . tv STRNEWLINE ▁ ▁ ▁ ▁ ( ? : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ / live / [ ^ / ] + STRNEWLINE ▁ ▁ ▁ ▁ ) ? STRNEWLINE ▁ ▁ ▁ ▁ ( ? : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ / video / \d + / [ ^ / ] + STRNEWLINE ▁ ▁ ▁ ▁ ) ? STRNEWLINE """ , re . VERBOSE ) NEW_LINE _file_re = re . compile ( " \ " ? file\ " ? : \s + [ ' \ " ] ( [ ^ ' \ " ] + ) [ ' \ " ] " ) NEW_LINE _swf_url_re = re . compile ( " swfobject . embedSWF\ ( \ " ( [ ^ \ " ] + ) \ " , " ) NEW_LINE _schema = validate . Schema ( validate . union ( { " urls " : validate . all ( validate . transform ( _file_re . findall ) , validate . map ( unquote ) , [ validate . url ( ) ] ) , " swf " : validate . all ( validate . transform ( _swf_url_re . search ) , validate . any ( None , validate . all ( validate . get ( 1 ) , validate . url ( scheme = " http " , path = validate . endswith ( " swf " ) ) ) ) ) } ) ) NEW_LINE class Aliez ( Plugin ) : NEW_LINE INDENT @ classmethod NEW_LINE def can_handle_url ( self , url ) : NEW_LINE INDENT return _url_re . match ( url ) NEW_LINE DEDENT def _get_streams ( self ) : NEW_LINE INDENT res = http . get ( self . url , schema = _schema ) NEW_LINE streams = { } NEW_LINE for url in res [ " urls " ] : NEW_LINE INDENT parsed = urlparse ( url ) NEW_LINE if parsed . scheme . startswith ( " rtmp " ) : NEW_LINE INDENT params = { " rtmp " : url , " pageUrl " : self . url , " live " : True } NEW_LINE if res [ " swf " ] : NEW_LINE INDENT params [ " swfVfy " ] = res [ " swf " ] NEW_LINE DEDENT stream = RTMPStream ( self . session , params ) NEW_LINE streams [ " live " ] = stream NEW_LINE DEDENT elif parsed . scheme . startswith ( " http " ) : NEW_LINE INDENT name = splitext ( parsed . path ) [ 1 ] [ 1 : ] NEW_LINE stream = HTTPStream ( self . session , url ) NEW_LINE streams [ name ] = stream NEW_LINE DEDENT DEDENT return streams NEW_LINE DEDENT DEDENT __plugin__ = Aliez NEW_LINE </DOCUMENT>
<DOCUMENT_ID="vqw/frappe/tree/master/frappe/model/delete_doc.py"> # ▁ Copyright ▁ ( c ) ▁ 2015 , ▁ Frappe ▁ Technologies ▁ Pvt . ▁ Ltd . ▁ and ▁ Contributors ENDCOM # ▁ MIT ▁ License . ▁ See ▁ license . txt ENDCOM from __future__ import unicode_literals NEW_LINE import frappe NEW_LINE import frappe . model . meta NEW_LINE from frappe . model . dynamic_links import get_dynamic_link_map NEW_LINE import frappe . defaults NEW_LINE from frappe . utils . file_manager import remove_all NEW_LINE from frappe . utils . password import delete_all_passwords_for NEW_LINE from frappe import _ NEW_LINE from frappe . model . naming import revert_series_if_last NEW_LINE def delete_doc ( doctype = None , name = None , force = 0 , ignore_doctypes = None , for_reload = False , ignore_permissions = False , flags = None , ignore_on_trash = False ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Deletes ▁ a ▁ doc ( dt , ▁ dn ) ▁ and ▁ validates ▁ if ▁ it ▁ is ▁ not ▁ submitted ▁ and ▁ not ▁ linked ▁ in ▁ a ▁ live ▁ record STRNEWLINE TABSYMBOL """ NEW_LINE if not ignore_doctypes : ignore_doctypes = [ ] NEW_LINE # ▁ get ▁ from ▁ form ENDCOM if not doctype : NEW_LINE INDENT doctype = frappe . form_dict . get ( ' dt ' ) NEW_LINE name = frappe . form_dict . get ( ' dn ' ) NEW_LINE DEDENT names = name NEW_LINE if isinstance ( name , basestring ) : NEW_LINE INDENT names = [ name ] NEW_LINE DEDENT for name in names or [ ] : NEW_LINE # ▁ already ▁ deleted . . ? ENDCOM INDENT if not frappe . db . exists ( doctype , name ) : NEW_LINE INDENT return NEW_LINE # ▁ delete ▁ attachments ENDCOM DEDENT remove_all ( doctype , name ) NEW_LINE # ▁ delete ▁ passwords ENDCOM delete_all_passwords_for ( doctype , name ) NEW_LINE doc = None NEW_LINE if doctype == " DocType " : NEW_LINE INDENT if for_reload : NEW_LINE INDENT try : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE DEDENT except frappe . DoesNotExistError : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT doc . run_method ( " before _ reload " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE update_flags ( doc , flags , ignore_permissions ) NEW_LINE check_permission_and_not_submitted ( doc ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabCustom ▁ Field ` ▁ where ▁ dt ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabCustom ▁ Script ` ▁ where ▁ dt ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabProperty ▁ Setter ` ▁ where ▁ doc _ type ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabReport ` ▁ where ▁ ref _ doctype = % s " , name ) NEW_LINE DEDENT delete_from_table ( doctype , name , ignore_doctypes , None ) NEW_LINE DEDENT else : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE if not for_reload : NEW_LINE INDENT update_flags ( doc , flags , ignore_permissions ) NEW_LINE check_permission_and_not_submitted ( doc ) NEW_LINE if not ignore_on_trash : NEW_LINE INDENT doc . run_method ( " on _ trash " ) NEW_LINE doc . run_method ( ' on _ change ' ) NEW_LINE DEDENT dynamic_linked_doctypes = [ df . parent for df in get_dynamic_link_map ( ) . get ( doc . doctype , [ ] ) ] NEW_LINE if " ToDo " in dynamic_linked_doctypes : NEW_LINE INDENT delete_linked_todos ( doc ) NEW_LINE DEDENT if " Communication " in dynamic_linked_doctypes : NEW_LINE INDENT delete_linked_communications ( doc ) NEW_LINE DEDENT if " DocShare " in dynamic_linked_doctypes : NEW_LINE INDENT delete_shared ( doc ) NEW_LINE DEDENT if " Email ▁ Unsubscribe " in dynamic_linked_doctypes : NEW_LINE INDENT delete_email_subscribe ( doc ) NEW_LINE # ▁ check ▁ if ▁ links ▁ exist ENDCOM DEDENT if not force : NEW_LINE INDENT check_if_doc_is_linked ( doc ) NEW_LINE check_if_doc_is_dynamically_linked ( doc ) NEW_LINE DEDENT DEDENT update_naming_series ( doc ) NEW_LINE delete_from_table ( doctype , name , ignore_doctypes , doc ) NEW_LINE doc . run_method ( " after _ delete " ) NEW_LINE DEDENT if doc and not frappe . flags . in_patch : NEW_LINE INDENT try : NEW_LINE INDENT doc . notify_update ( ) NEW_LINE insert_feed ( doc ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass NEW_LINE # ▁ delete ▁ user _ permissions ENDCOM DEDENT DEDENT frappe . defaults . clear_default ( parenttype = " User ▁ Permission " , key = doctype , value = name ) NEW_LINE DEDENT DEDENT def update_naming_series ( doc ) : NEW_LINE INDENT if doc . meta . autoname : NEW_LINE INDENT if doc . meta . autoname . startswith ( " naming _ series : " ) and getattr ( doc , " naming _ series " , None ) : NEW_LINE INDENT revert_series_if_last ( doc . naming_series , doc . name ) NEW_LINE DEDENT elif doc . meta . autoname . split ( " : " ) [ 0 ] not in ( " Prompt " , " field " , " hash " ) : NEW_LINE INDENT revert_series_if_last ( doc . meta . autoname , doc . name ) NEW_LINE DEDENT DEDENT DEDENT def delete_from_table ( doctype , name , ignore_doctypes , doc ) : NEW_LINE INDENT if doctype != " DocType " and doctype == name : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tabSingles ` ▁ where ▁ doctype = % s " , name ) NEW_LINE DEDENT else : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tab % s ` ▁ where ▁ name = % s " % ( frappe . db . escape ( doctype ) , " % s " ) , ( name , ) ) NEW_LINE # ▁ get ▁ child ▁ tables ENDCOM DEDENT if doc : NEW_LINE INDENT tables = [ d . options for d in doc . meta . get_table_fields ( ) ] NEW_LINE DEDENT else : NEW_LINE INDENT def get_table_fields ( field_doctype ) : NEW_LINE INDENT return frappe . db . sql_list ( """ select ▁ options ▁ from ▁ ` tab { } ` ▁ where ▁ fieldtype = ' Table ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL TABSYMBOL and ▁ parent = % s """ . format ( field_doctype ) , doctype ) NEW_LINE DEDENT tables = get_table_fields ( " DocField " ) NEW_LINE if not frappe . flags . in_install == " frappe " : NEW_LINE INDENT tables += get_table_fields ( " Custom ▁ Field " ) NEW_LINE # ▁ delete ▁ from ▁ child ▁ tables ENDCOM DEDENT DEDENT for t in list ( set ( tables ) ) : NEW_LINE INDENT if t not in ignore_doctypes : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tab % s ` ▁ where ▁ parenttype = % s ▁ and ▁ parent ▁ = ▁ % s " % ( t , ' % s ' , ' % s ' ) , ( doctype , name ) ) NEW_LINE DEDENT DEDENT DEDENT def update_flags ( doc , flags = None , ignore_permissions = False ) : NEW_LINE INDENT if ignore_permissions : NEW_LINE INDENT if not flags : flags = { } NEW_LINE flags [ " ignore _ permissions " ] = ignore_permissions NEW_LINE DEDENT if flags : NEW_LINE INDENT doc . flags . update ( flags ) NEW_LINE DEDENT DEDENT def check_permission_and_not_submitted ( doc ) : NEW_LINE # ▁ permission ENDCOM INDENT if not doc . flags . ignore_permissions and frappe . session . user != " Administrator " and ( not doc . has_permission ( " delete " ) or ( doc . doctype == " DocType " and not doc . custom ) ) : NEW_LINE INDENT frappe . msgprint ( _ ( " User ▁ not ▁ allowed ▁ to ▁ delete ▁ { 0 } : ▁ { 1 } " ) . format ( doc . doctype , doc . name ) , raise_exception = True ) NEW_LINE # ▁ check ▁ if ▁ submitted ENDCOM DEDENT if doc . docstatus == 1 : NEW_LINE INDENT frappe . msgprint ( _ ( " { 0 } ▁ { 1 } : ▁ Submitted ▁ Record ▁ cannot ▁ be ▁ deleted . " ) . format ( doc . doctype , doc . name ) , raise_exception = True ) NEW_LINE DEDENT DEDENT def check_if_doc_is_linked ( doc , method = " Delete " ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Raises ▁ excption ▁ if ▁ the ▁ given ▁ doc ( dt , ▁ dn ) ▁ is ▁ linked ▁ in ▁ another ▁ record . STRNEWLINE TABSYMBOL """ NEW_LINE from frappe . model . rename_doc import get_link_fields NEW_LINE link_fields = get_link_fields ( doc . doctype ) NEW_LINE link_fields = [ [ lf [ ' parent ' ] , lf [ ' fieldname ' ] , lf [ ' issingle ' ] ] for lf in link_fields ] NEW_LINE for link_dt , link_field , issingle in link_fields : NEW_LINE INDENT if not issingle : NEW_LINE INDENT item = frappe . db . get_value ( link_dt , { link_field : doc . name } , [ " name " , " parent " , " parenttype " , " docstatus " ] , as_dict = True ) NEW_LINE if item and ( ( item . parent or item . name ) != doc . name ) and ( ( method == " Delete " and item . docstatus < 2 ) or ( method == " Cancel " and item . docstatus == 1 ) ) : NEW_LINE # ▁ raise ▁ exception ▁ only ▁ if ENDCOM # ▁ linked ▁ to ▁ an ▁ non - cancelled ▁ doc ▁ when ▁ deleting ENDCOM # ▁ or ▁ linked ▁ to ▁ a ▁ submitted ▁ doc ▁ when ▁ cancelling ENDCOM INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , item . parenttype if item . parent else link_dt , item . parent or item . name ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def check_if_doc_is_dynamically_linked ( doc , method = " Delete " ) : NEW_LINE INDENT ''' Raise ▁ ` frappe . LinkExistsError ` ▁ if ▁ the ▁ document ▁ is ▁ dynamically ▁ linked ''' NEW_LINE for df in get_dynamic_link_map ( ) . get ( doc . doctype , [ ] ) : NEW_LINE INDENT if df . parent in ( " Communication " , " ToDo " , " DocShare " , " Email ▁ Unsubscribe " ) : NEW_LINE # ▁ don ' t ▁ check ▁ for ▁ communication ▁ and ▁ todo ! ENDCOM INDENT continue NEW_LINE DEDENT meta = frappe . get_meta ( df . parent ) NEW_LINE if meta . issingle : NEW_LINE # ▁ dynamic ▁ link ▁ in ▁ single ▁ doc ENDCOM INDENT refdoc = frappe . db . get_singles_dict ( df . parent ) NEW_LINE if ( refdoc . get ( df . options ) == doc . doctype and refdoc . get ( df . fieldname ) == doc . name and ( ( method == " Delete " and refdoc . docstatus < 2 ) or ( method == " Cancel " and refdoc . docstatus == 1 ) ) ) : NEW_LINE # ▁ raise ▁ exception ▁ only ▁ if ENDCOM # ▁ linked ▁ to ▁ an ▁ non - cancelled ▁ doc ▁ when ▁ deleting ENDCOM # ▁ or ▁ linked ▁ to ▁ a ▁ submitted ▁ doc ▁ when ▁ cancelling ENDCOM INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , df . parent , " " ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT else : NEW_LINE # ▁ dynamic ▁ link ▁ in ▁ table ENDCOM INDENT for refdoc in frappe . db . sql ( """ select ▁ name , ▁ docstatus ▁ from ▁ ` tab { parent } ` ▁ where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL TABSYMBOL { options } = % s ▁ and ▁ { fieldname } = % s """ . format ( ** df ) , ( doc . doctype , doc . name ) , as_dict = True ) : NEW_LINE INDENT if ( ( method == " Delete " and refdoc . docstatus < 2 ) or ( method == " Cancel " and refdoc . docstatus == 1 ) ) : NEW_LINE # ▁ raise ▁ exception ▁ only ▁ if ENDCOM # ▁ linked ▁ to ▁ an ▁ non - cancelled ▁ doc ▁ when ▁ deleting ENDCOM # ▁ or ▁ linked ▁ to ▁ a ▁ submitted ▁ doc ▁ when ▁ cancelling ENDCOM INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , df . parent , refdoc . name ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def delete_linked_todos ( doc ) : NEW_LINE INDENT delete_doc ( " ToDo " , frappe . db . sql_list ( """ select ▁ name ▁ from ▁ ` tabToDo ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ reference _ type = % s ▁ and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) , ignore_permissions = True ) NEW_LINE DEDENT def delete_email_subscribe ( doc ) : NEW_LINE INDENT frappe . db . sql ( ''' delete ▁ from ▁ ` tabEmail ▁ Unsubscribe ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ reference _ doctype = % s ▁ and ▁ reference _ name = % s ''' , ( doc . doctype , doc . name ) ) NEW_LINE DEDENT def delete_linked_communications ( doc ) : NEW_LINE # ▁ delete ▁ comments ENDCOM INDENT frappe . db . sql ( """ delete ▁ from ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL communication _ type ▁ = ▁ ' Comment ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ doctype = % s ▁ and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE # ▁ make ▁ communications ▁ orphans ENDCOM frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ reference _ doctype = null , ▁ reference _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL communication _ type ▁ = ▁ ' Communication ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ doctype = % s STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE # ▁ make ▁ secondary ▁ references ▁ orphans ENDCOM frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ link _ doctype = null , ▁ link _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where ▁ link _ doctype = % s ▁ and ▁ link _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ timeline _ doctype = null , ▁ timeline _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where ▁ timeline _ doctype = % s ▁ and ▁ timeline _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE DEDENT def insert_feed ( doc ) : NEW_LINE INDENT from frappe . utils import get_fullname NEW_LINE if frappe . flags . in_install or frappe . flags . in_import or getattr ( doc , " no _ feed _ on _ delete " , False ) : NEW_LINE INDENT return NEW_LINE DEDENT frappe . get_doc ( { " doctype " : " Communication " , " communication _ type " : " Comment " , " comment _ type " : " Deleted " , " reference _ doctype " : doc . doctype , " subject " : " { 0 } ▁ { 1 } " . format ( _ ( doc . doctype ) , doc . name ) , " full _ name " : get_fullname ( doc . owner ) } ) . insert ( ignore_permissions = True ) NEW_LINE DEDENT def delete_shared ( doc ) : NEW_LINE INDENT delete_doc ( " DocShare " , frappe . db . sql_list ( """ select ▁ name ▁ from ▁ ` tabDocShare ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ share _ doctype = % s ▁ and ▁ share _ name = % s """ , ( doc . doctype , doc . name ) ) , ignore_on_trash = True ) NEW_LINE DEDENT </DOCUMENT>
