; ModuleID = 'input.c'
source_filename = "input.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%union.U0 = type { i8* }

@.str = private unnamed_addr constant [15 x i8] c"checksum = %X\0A\00", align 1
@crc32_context = internal global i32 -1, align 4
@crc32_tab = internal global [256 x i32] zeroinitializer, align 16
@.str.1 = private unnamed_addr constant [36 x i8] c"...checksum after hashing %s : %lX\0A\00", align 1
@g_12 = internal global i32 348720425, align 4
@g_27 = internal global { i16, [6 x i8] } { i16 794, [6 x i8] undef }, align 8
@g_45 = internal global i32 0, align 4
@g_80 = internal constant { i16, [6 x i8] } { i16 17968, [6 x i8] undef }, align 8
@g_82 = internal global i8 -115, align 1
@g_89 = internal global i32 -8, align 4
@g_95 = internal global i32 990396411, align 4
@g_105 = internal global [4 x [6 x [7 x i8]]] [[6 x [7 x i8]] [[7 x i8] c"\90\08\DF\FF\06\93>", [7 x i8] c"\00\EC\94\01\85\03\08", [7 x i8] c"\15\94\E7\EC\AD\01\F8", [7 x i8] c"\FF\00\F6\933\09\EC", [7 x i8] c"Y\A8{\\\FF\F8\AD", [7 x i8] c"\F8\F6\B3\94\FF3\E2"], [6 x [7 x i8]] [[7 x i8] c"\00\01\01\FE\FF\F6F", [7 x i8] c"\E2\08\01\90\90\01\08", [7 x i8] c"\E7\D3\F6\00\01\FF\A1", [7 x i8] c"\\\01\E2\FF\01\00\EA", [7 x i8] c"\15p\15\00\08\00\01", [7 x i8] c"\93\EA\02\90\15\03\FE"], [6 x [7 x i8]] [[7 x i8] c"\15\15\AD\09>\A8\00", [7 x i8] c"\03\EC\D3\93\09\DF\15", [7 x i8] c"\03\01\D3\09\A1\02\00", [7 x i8] c"\00\FF\AD\00\99\03p", [7 x i8] c"\F8\F7\02\02\F7\F8\99", [7 x i8] c"\00\\\15\08\F8\01\08"], [6 x [7 x i8]] [[7 x i8] c"\00\90\E2\01\A8\15\F6", [7 x i8] c"\01\\\F6\FF\09\F6\94", [7 x i8] c"\F6\F7\01\FE\15\09\01", [7 x i8] c"\F7\FF@\DF\00\FE\E7", [7 x i8] c"\01\01>\99\FE\F8\01", [7 x i8] c"\01\EC\F6\FF\03\93\03"]], align 16
@g_116 = internal global i8 94, align 1
@g_135 = internal global i16 6150, align 2
@g_136 = internal global %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), align 8
@g_137 = internal global [2 x [8 x i32*]] [[8 x i32*] [i32* null, i32* @g_89, i32* @g_89, i32* null, i32* null, i32* @g_89, i32* @g_89, i32* null], [8 x i32*] [i32* null, i32* @g_89, i32* @g_89, i32* null, i32* null, i32* @g_89, i32* @g_89, i32* null]], align 16
@g_138 = internal global i32* @g_89, align 8
@g_155 = internal constant i16 -1, align 2
@g_154 = internal global [4 x i16*] [i16* @g_155, i16* @g_155, i16* @g_155, i16* @g_155], align 16
@g_158 = internal global i32* @g_89, align 8
@g_169 = internal global [9 x [7 x [4 x i32]]] [[7 x [4 x i32]] [[4 x i32] [i32 -1429957659, i32 -4, i32 1, i32 -1429957659], [4 x i32] [i32 -671187719, i32 1174836202, i32 1, i32 -868138759], [4 x i32] [i32 -1429957659, i32 -1659676109, i32 5, i32 1808002712], [4 x i32] [i32 1808002712, i32 1, i32 -1, i32 10255951], [4 x i32] [i32 -1, i32 10255951, i32 -868138759, i32 -868138759], [4 x i32] [i32 -4, i32 -4, i32 -1791698039, i32 1203549273], [4 x i32] [i32 1174836202, i32 -4, i32 -1419208825, i32 1]], [7 x [4 x i32]] [[4 x i32] [i32 -1, i32 1203549273, i32 3, i32 -1419208825], [4 x i32] [i32 10255951, i32 1203549273, i32 5, i32 1], [4 x i32] [i32 1203549273, i32 -4, i32 -488353991, i32 1203549273], [4 x i32] [i32 -671187719, i32 -4, i32 -4, i32 -868138759], [4 x i32] [i32 1, i32 10255951, i32 5, i32 10255951], [4 x i32] [i32 -1659676109, i32 5, i32 0, i32 -1419208825], [4 x i32] [i32 1, i32 -868138759, i32 -1503651247, i32 -1556372696]], [7 x [4 x i32]] [[4 x i32] [i32 -1, i32 -671187719, i32 1174836202, i32 1], [4 x i32] [i32 -1, i32 1361079098, i32 -1503651247, i32 3], [4 x i32] [i32 1, i32 1, i32 0, i32 -677271840], [4 x i32] [i32 -868138759, i32 -488353991, i32 1, i32 -671187719], [4 x i32] [i32 -488353991, i32 1361079098, i32 1361079098, i32 -488353991], [4 x i32] [i32 0, i32 -1, i32 -1791698039, i32 -1556372696], [4 x i32] [i32 -4, i32 -1419208825, i32 1, i32 -868138759]], [7 x [4 x i32]] [[4 x i32] [i32 1, i32 5, i32 501734090, i32 -868138759], [4 x i32] [i32 1, i32 -1419208825, i32 -677271840, i32 -1556372696], [4 x i32] [i32 -671187719, i32 -1, i32 1174836202, i32 -488353991], [4 x i32] [i32 3, i32 1361079098, i32 -1556372696, i32 -671187719], [4 x i32] [i32 1, i32 -488353991, i32 1, i32 -677271840], [4 x i32] [i32 -1419208825, i32 1, i32 1, i32 3], [4 x i32] [i32 1, i32 1361079098, i32 5, i32 1]], [7 x [4 x i32]] [[4 x i32] [i32 0, i32 -671187719, i32 5, i32 -1556372696], [4 x i32] [i32 1, i32 -868138759, i32 1, i32 -1419208825], [4 x i32] [i32 -1419208825, i32 5, i32 1, i32 1], [4 x i32] [i32 1, i32 1, i32 -1556372696, i32 -1556372696], [4 x i32] [i32 3, i32 3, i32 1174836202, i32 -4], [4 x i32] [i32 -671187719, i32 1361079098, i32 -677271840, i32 -1], [4 x i32] [i32 1, i32 -4, i32 501734090, i32 -677271840]], [7 x [4 x i32]] [[4 x i32] [i32 1, i32 -4, i32 1, i32 -1], [4 x i32] [i32 -4, i32 1361079098, i32 -1791698039, i32 -4], [4 x i32] [i32 0, i32 3, i32 1361079098, i32 -1556372696], [4 x i32] [i32 -488353991, i32 1, i32 1, i32 1], [4 x i32] [i32 -868138759, i32 5, i32 0, i32 -1419208825], [4 x i32] [i32 1, i32 -868138759, i32 -1503651247, i32 -1556372696], [4 x i32] [i32 -1, i32 -671187719, i32 1174836202, i32 1]], [7 x [4 x i32]] [[4 x i32] [i32 -1, i32 1361079098, i32 -1503651247, i32 3], [4 x i32] [i32 1, i32 1, i32 0, i32 -677271840], [4 x i32] [i32 -868138759, i32 -488353991, i32 1, i32 -671187719], [4 x i32] [i32 -488353991, i32 1361079098, i32 1361079098, i32 -488353991], [4 x i32] [i32 0, i32 -1, i32 -1791698039, i32 -1556372696], [4 x i32] [i32 -4, i32 -1419208825, i32 1, i32 -868138759], [4 x i32] [i32 1, i32 5, i32 501734090, i32 -868138759]], [7 x [4 x i32]] [[4 x i32] [i32 1, i32 -1419208825, i32 -677271840, i32 -1556372696], [4 x i32] [i32 -671187719, i32 -1, i32 1174836202, i32 -488353991], [4 x i32] [i32 3, i32 1361079098, i32 -1556372696, i32 -671187719], [4 x i32] [i32 1, i32 -488353991, i32 1, i32 -677271840], [4 x i32] [i32 -1419208825, i32 1, i32 1, i32 3], [4 x i32] [i32 1, i32 1361079098, i32 5, i32 1], [4 x i32] [i32 0, i32 -671187719, i32 5, i32 -1556372696]], [7 x [4 x i32]] [[4 x i32] [i32 1, i32 -868138759, i32 1, i32 -1419208825], [4 x i32] [i32 -1419208825, i32 5, i32 1, i32 1], [4 x i32] [i32 1, i32 1, i32 -1556372696, i32 -1556372696], [4 x i32] [i32 3, i32 3, i32 1174836202, i32 1361079098], [4 x i32] [i32 0, i32 -4, i32 1203549273, i32 1], [4 x i32] [i32 -1659676109, i32 1361079098, i32 10255951, i32 1203549273], [4 x i32] [i32 -1503651247, i32 1361079098, i32 -1, i32 1]]], align 16
@g_216 = internal global i32 0, align 4
@g_319 = internal global i16* null, align 8
@g_318 = internal global i16** @g_319, align 8
@g_326 = internal global i32 614968740, align 4
@g_340 = internal global i8** null, align 8
@g_370 = internal global i16 8, align 2
@g_369 = internal global i16* @g_370, align 8
@g_378 = internal global i32* @g_89, align 8
@g_422 = internal global i32* @g_89, align 8
@g_421 = internal global i32** @g_422, align 8
@g_444 = internal global { i16, [6 x i8] } { i16 0, [6 x i8] undef }, align 8
@g_493 = internal global { i16, [6 x i8] } { i16 3603, [6 x i8] undef }, align 8
@g_494 = internal global [4 x [9 x [7 x { i16, [6 x i8] }]]] [[9 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -10, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 23273, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 21661, [6 x i8] undef }, { i16, [6 x i8] } { i16 9282, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -6, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 9, [6 x i8] undef }, { i16, [6 x i8] } { i16 5175, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 9282, [6 x i8] undef }, { i16, [6 x i8] } { i16 -11328, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 21661, [6 x i8] undef }, { i16, [6 x i8] } { i16 19423, [6 x i8] undef }, { i16, [6 x i8] } { i16 4, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 -20688, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 9, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4, [6 x i8] undef }, { i16, [6 x i8] } { i16 9, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -11328, [6 x i8] undef }, { i16, [6 x i8] } { i16 -9625, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22829, [6 x i8] undef }, { i16, [6 x i8] } { i16 -16461, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 -13785, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 5247, [6 x i8] undef }, { i16, [6 x i8] } { i16 4, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23235, [6 x i8] undef }, { i16, [6 x i8] } { i16 -17479, [6 x i8] undef }, { i16, [6 x i8] } { i16 -10, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23022, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22829, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24220, [6 x i8] undef }, { i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 5175, [6 x i8] undef }, { i16, [6 x i8] } { i16 -11328, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 19423, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4550, [6 x i8] undef }, { i16, [6 x i8] } { i16 1968, [6 x i8] undef }, { i16, [6 x i8] } { i16 3, [6 x i8] undef }, { i16, [6 x i8] } { i16 7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 3159, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22829, [6 x i8] undef }, { i16, [6 x i8] } { i16 -10, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }]], [9 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -6, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23235, [6 x i8] undef }, { i16, [6 x i8] } { i16 1968, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -10, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4550, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4, [6 x i8] undef }, { i16, [6 x i8] } { i16 1682, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4550, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24220, [6 x i8] undef }, { i16, [6 x i8] } { i16 1682, [6 x i8] undef }, { i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 4, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -9625, [6 x i8] undef }, { i16, [6 x i8] } { i16 -12562, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23235, [6 x i8] undef }, { i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 23273, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2317, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -9625, [6 x i8] undef }, { i16, [6 x i8] } { i16 -16461, [6 x i8] undef }, { i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 -12562, [6 x i8] undef }, { i16, [6 x i8] } { i16 -17479, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }, { i16, [6 x i8] } { i16 1682, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22829, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 1682, [6 x i8] undef }, { i16, [6 x i8] } { i16 19423, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }, { i16, [6 x i8] } { i16 3, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -4091, [6 x i8] undef }, { i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 9, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22829, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 3, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 23273, [6 x i8] undef }, { i16, [6 x i8] } { i16 -10, [6 x i8] undef }, { i16, [6 x i8] } { i16 3, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }]], [9 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -8, [6 x i8] undef }, { i16, [6 x i8] } { i16 5175, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2317, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2317, [6 x i8] undef }, { i16, [6 x i8] } { i16 5175, [6 x i8] undef }, { i16, [6 x i8] } { i16 -8, [6 x i8] undef }, { i16, [6 x i8] } { i16 -17479, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 1682, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 -10, [6 x i8] undef }, { i16, [6 x i8] } { i16 3159, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2317, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -2317, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 23273, [6 x i8] undef }, { i16, [6 x i8] } { i16 -16461, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4550, [6 x i8] undef }, { i16, [6 x i8] } { i16 4, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23022, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 19423, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4550, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 5175, [6 x i8] undef }, { i16, [6 x i8] } { i16 -11328, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 -17479, [6 x i8] undef }, { i16, [6 x i8] } { i16 1968, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -4, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 -13785, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 1968, [6 x i8] undef }, { i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 21661, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 1682, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 9282, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 9282, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 3, [6 x i8] undef }, { i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23022, [6 x i8] undef }]], [9 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23235, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 9, [6 x i8] undef }, { i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 -12562, [6 x i8] undef }, { i16, [6 x i8] } { i16 7, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 9282, [6 x i8] undef }, { i16, [6 x i8] } { i16 -16461, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24220, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }, { i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 5, [6 x i8] undef }, { i16, [6 x i8] } { i16 -12562, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 -17479, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23022, [6 x i8] undef }, { i16, [6 x i8] } { i16 -21, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24220, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2317, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24220, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -23022, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22212, [6 x i8] undef }, { i16, [6 x i8] } { i16 -22829, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 -3, [6 x i8] undef }, { i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 28844, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 -13785, [6 x i8] undef }, { i16, [6 x i8] } { i16 -20688, [6 x i8] undef }, { i16, [6 x i8] } { i16 -29341, [6 x i8] undef }, { i16, [6 x i8] } { i16 -4091, [6 x i8] undef }, { i16, [6 x i8] } { i16 5, [6 x i8] undef }], [7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }, { i16, [6 x i8] } { i16 28844, [6 x i8] undef }, { i16, [6 x i8] } { i16 3159, [6 x i8] undef }, { i16, [6 x i8] } { i16 5175, [6 x i8] undef }, { i16, [6 x i8] } { i16 16624, [6 x i8] undef }, { i16, [6 x i8] } { i16 8, [6 x i8] undef }]]], align 16
@g_495 = internal global [10 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }, { i16, [6 x i8] } { i16 -2, [6 x i8] undef }], align 16
@g_516 = internal global i8* @g_82, align 8
@g_515 = internal constant i8** @g_516, align 8
@g_547 = internal global %union.U0** null, align 8
@g_561 = internal global i64 -6062575221886248491, align 8
@g_617 = internal global i64 1, align 8
@g_635 = internal global { i16, [6 x i8] } { i16 -16524, [6 x i8] undef }, align 8
@g_637 = internal global i16 32334, align 2
@g_675 = internal global i32 -1, align 4
@g_684 = internal global i64 -1903646499765572788, align 8
@g_683 = internal constant [10 x [5 x [5 x i64*]]] [[5 x [5 x i64*]] [[5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer], [5 x [5 x i64*]] [[5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684]], [5 x [5 x i64*]] [[5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer], [5 x [5 x i64*]] [[5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684]], [5 x [5 x i64*]] [[5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer], [5 x [5 x i64*]] [[5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684]], [5 x [5 x i64*]] [[5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer], [5 x [5 x i64*]] [[5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684]], [5 x [5 x i64*]] [[5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer], [5 x [5 x i64*]] [[5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684], [5 x i64*] zeroinitializer, [5 x i64*] [i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684, i64* @g_684]]], align 16
@g_682 = internal global [9 x [3 x [1 x i64**]]] [[3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 24) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 24) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 24) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 24) to i64**)]], [3 x [1 x i64**]] [[1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 944) to i64**)], [1 x i64**] [i64** bitcast (i8* getelementptr (i8, i8* bitcast ([10 x [5 x [5 x i64*]]]* @g_683 to i8*), i64 960) to i64**)]]], align 16
@g_725 = internal global i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_444, i32 0, i32 0), align 8
@g_724 = internal global i16** @g_725, align 8
@g_723 = internal global i16*** @g_724, align 8
@g_722 = internal global i16**** @g_723, align 8
@g_733 = internal global i64 -2037519070512456972, align 8
@g_781 = internal global [7 x [6 x i32]] [[6 x i32] [i32 0, i32 -162335569, i32 0, i32 -162335569, i32 0, i32 -162335569], [6 x i32] [i32 -10, i32 -162335569, i32 -10, i32 -162335569, i32 -10, i32 -162335569], [6 x i32] [i32 0, i32 -162335569, i32 0, i32 -162335569, i32 0, i32 -162335569], [6 x i32] [i32 -10, i32 -162335569, i32 -10, i32 -162335569, i32 -10, i32 -162335569], [6 x i32] [i32 0, i32 -162335569, i32 0, i32 -162335569, i32 0, i32 -162335569], [6 x i32] [i32 -10, i32 -162335569, i32 -10, i32 -162335569, i32 -10, i32 -162335569], [6 x i32] [i32 0, i32 -162335569, i32 0, i32 -162335569, i32 0, i32 -162335569]], align 16
@g_790 = internal global i8 -9, align 1
@g_797 = internal global i32* null, align 8
@g_796 = internal global [8 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797], align 16
@g_795 = internal global i32*** bitcast (i8* getelementptr (i8, i8* bitcast ([8 x i32**]* @g_796 to i8*), i64 40) to i32***), align 8
@g_868 = internal global i32 0, align 4
@g_902 = internal global { i16, [6 x i8] } { i16 6, [6 x i8] undef }, align 8
@g_910 = internal global [5 x i16] [i16 8, i16 8, i16 8, i16 8, i16 8], align 2
@g_911 = internal global %union.U0** @g_136, align 8
@g_912 = internal global i16***** @g_722, align 8
@g_927 = internal global { i16, [6 x i8] } { i16 -10, [6 x i8] undef }, align 8
@g_956 = internal global { i16, [6 x i8] } { i16 0, [6 x i8] undef }, align 8
@g_1008 = internal constant i32 -1, align 4
@g_1028 = internal global [6 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7, [6 x i8] undef }], align 16
@g_1036 = internal global i32 125691013, align 4
@g_1065 = internal global { i16, [6 x i8] } { i16 -19970, [6 x i8] undef }, align 8
@g_1167 = internal global i8* @g_790, align 8
@g_1168 = internal global { i16, [6 x i8] } { i16 -24052, [6 x i8] undef }, align 8
@g_1205 = internal global i16 1, align 2
@g_1211 = internal global %union.U0*** null, align 8
@g_1210 = internal global %union.U0**** @g_1211, align 8
@g_1227 = internal global { i16, [6 x i8] } { i16 0, [6 x i8] undef }, align 8
@g_1228 = internal global { i16, [6 x i8] } { i16 0, [6 x i8] undef }, align 8
@g_1269 = internal global [9 x [9 x [3 x i32]]] [[9 x [3 x i32]] [[3 x i32] [i32 -690071559, i32 6, i32 5], [3 x i32] [i32 -1481249842, i32 -838607482, i32 39964989], [3 x i32] [i32 5, i32 -1, i32 -1], [3 x i32] [i32 -1899964770, i32 -641954960, i32 0], [3 x i32] [i32 -1, i32 3, i32 175572873], [3 x i32] [i32 857916894, i32 -4, i32 7], [3 x i32] [i32 2137327335, i32 1, i32 1447206990], [3 x i32] [i32 1447206990, i32 -1957971204, i32 -1899964770], [3 x i32] [i32 6, i32 598920854, i32 5]], [9 x [3 x i32]] [[3 x i32] [i32 598920854, i32 532004597, i32 2], [3 x i32] [i32 -1878560672, i32 -2068700142, i32 -2068700142], [3 x i32] [i32 637118317, i32 0, i32 6], [3 x i32] [i32 0, i32 -160114392, i32 -690071559], [3 x i32] [i32 5, i32 5, i32 429079361], [3 x i32] [i32 -1189929200, i32 -1, i32 0], [3 x i32] [i32 1849439002, i32 5, i32 -1], [3 x i32] [i32 9, i32 -160114392, i32 1849439002], [3 x i32] [i32 39964989, i32 0, i32 9]], [9 x [3 x i32]] [[3 x i32] [i32 -5, i32 -2068700142, i32 -1], [3 x i32] [i32 -246516981, i32 532004597, i32 1095532672], [3 x i32] [i32 -845268062, i32 598920854, i32 0], [3 x i32] [i32 422952059, i32 -1957971204, i32 -81259442], [3 x i32] [i32 175572873, i32 1, i32 -4], [3 x i32] [i32 831117331, i32 -4, i32 -1], [3 x i32] [i32 1365876544, i32 3, i32 399021068], [3 x i32] [i32 0, i32 -641954960, i32 688022798], [3 x i32] [i32 532004597, i32 -1, i32 598920854]], [9 x [3 x i32]] [[3 x i32] [i32 1, i32 -838607482, i32 -641954960], [3 x i32] [i32 -579286291, i32 6, i32 -9], [3 x i32] [i32 2, i32 -1899964770, i32 -9], [3 x i32] [i32 -1392636906, i32 637118317, i32 -641954960], [3 x i32] [i32 7, i32 127058811, i32 598920854], [3 x i32] [i32 -1, i32 0, i32 688022798], [3 x i32] [i32 -1, i32 5, i32 399021068], [3 x i32] [i32 1678823913, i32 9, i32 -1], [3 x i32] [i32 -1957971204, i32 1, i32 -4]], [9 x [3 x i32]] [[3 x i32] [i32 -641954960, i32 5, i32 -81259442], [3 x i32] [i32 -1, i32 -5, i32 0], [3 x i32] [i32 -160114392, i32 688022798, i32 1095532672], [3 x i32] [i32 1042412984, i32 1447206990, i32 -1], [3 x i32] [i32 9, i32 831117331, i32 9], [3 x i32] [i32 6, i32 -1, i32 1849439002], [3 x i32] [i32 -9, i32 -4, i32 -1], [3 x i32] [i32 8, i32 9, i32 0], [3 x i32] [i32 0, i32 -845268062, i32 429079361]], [9 x [3 x i32]] [[3 x i32] [i32 8, i32 -412726188, i32 -690071559], [3 x i32] [i32 -9, i32 -848050812, i32 6], [3 x i32] [i32 6, i32 -5, i32 -2068700142], [3 x i32] [i32 9, i32 -1761768303, i32 2], [3 x i32] [i32 1042412984, i32 1678823913, i32 5], [3 x i32] [i32 -1761768303, i32 -848050812, i32 688022798], [3 x i32] [i32 1365876544, i32 -6, i32 -81259442], [3 x i32] [i32 -1, i32 2, i32 -1238957444], [3 x i32] [i32 9, i32 429079361, i32 1447206990]], [9 x [3 x i32]] [[3 x i32] [i32 1, i32 1042412984, i32 422952059], [3 x i32] [i32 -5, i32 39964989, i32 2], [3 x i32] [i32 6, i32 1678823913, i32 6], [3 x i32] [i32 -1238957444, i32 1, i32 598920854], [3 x i32] [i32 -1, i32 0, i32 5], [3 x i32] [i32 -845268062, i32 0, i32 857916894], [3 x i32] [i32 5, i32 1, i32 -1], [3 x i32] [i32 39964989, i32 1678823913, i32 0], [3 x i32] [i32 -1, i32 39964989, i32 1]], [9 x [3 x i32]] [[3 x i32] [i32 0, i32 1042412984, i32 8], [3 x i32] [i32 175572873, i32 429079361, i32 5], [3 x i32] [i32 7, i32 2, i32 127058811], [3 x i32] [i32 1447206990, i32 -6, i32 175572873], [3 x i32] [i32 -1899964770, i32 -848050812, i32 -1], [3 x i32] [i32 5, i32 1, i32 -4], [3 x i32] [i32 2, i32 -1, i32 1], [3 x i32] [i32 -2068700142, i32 -2068700142, i32 -1878560672], [3 x i32] [i32 6, i32 9, i32 -1]], [9 x [3 x i32]] [[3 x i32] [i32 -690071559, i32 6, i32 7], [3 x i32] [i32 429079361, i32 5, i32 -1899964770], [3 x i32] [i32 0, i32 -690071559, i32 7], [3 x i32] [i32 -1, i32 -1189929200, i32 -1], [3 x i32] [i32 1849439002, i32 1365876544, i32 -1878560672], [3 x i32] [i32 9, i32 7, i32 1], [3 x i32] [i32 -1, i32 -81259442, i32 -4], [3 x i32] [i32 1095532672, i32 -1481249842, i32 -1], [3 x i32] [i32 0, i32 1, i32 175572873]]], align 16
@g_1277 = internal global i64* @g_561, align 8
@g_1276 = internal global i64** @g_1277, align 8
@g_1275 = internal global i64*** @g_1276, align 8
@g_1274 = internal global i64**** @g_1275, align 8
@g_1329 = internal global i32**** null, align 8
@g_1347 = internal global [8 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 27023, [6 x i8] undef }, { i16, [6 x i8] } { i16 30123, [6 x i8] undef }, { i16, [6 x i8] } { i16 30123, [6 x i8] undef }, { i16, [6 x i8] } { i16 27023, [6 x i8] undef }, { i16, [6 x i8] } { i16 30123, [6 x i8] undef }, { i16, [6 x i8] } { i16 30123, [6 x i8] undef }, { i16, [6 x i8] } { i16 27023, [6 x i8] undef }, { i16, [6 x i8] } { i16 30123, [6 x i8] undef }], align 16
@g_1356 = internal constant i32 1, align 4
@g_1358 = internal global i32* @g_45, align 8
@g_1357 = internal global [3 x [5 x i32**]] [[5 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358, i32** @g_1358, i32** @g_1358], [5 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358, i32** @g_1358, i32** @g_1358], [5 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358, i32** @g_1358, i32** @g_1358]], align 16
@g_1359 = internal global i32** null, align 8
@g_1360 = internal global [8 x [3 x i32**]] [[3 x i32**] [i32** @g_1358, i32** null, i32** null], [3 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358], [3 x i32**] [i32** @g_1358, i32** null, i32** null], [3 x i32**] [i32** @g_1358, i32** null, i32** @g_1358], [3 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358], [3 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358], [3 x i32**] [i32** @g_1358, i32** @g_1358, i32** null], [3 x i32**] [i32** @g_1358, i32** @g_1358, i32** @g_1358]], align 16
@g_1361 = internal global i32** @g_1358, align 8
@g_1440 = internal global { i16, [6 x i8] } { i16 -9, [6 x i8] undef }, align 8
@g_1486 = internal global i8* null, align 8
@g_1485 = internal global [1 x [7 x i8**]] [[7 x i8**] [i8** @g_1486, i8** @g_1486, i8** @g_1486, i8** @g_1486, i8** @g_1486, i8** @g_1486, i8** @g_1486]], align 16
@g_1484 = internal constant i8*** getelementptr inbounds ([1 x [7 x i8**]], [1 x [7 x i8**]]* @g_1485, i32 0, i32 0, i32 0), align 8
@g_1483 = internal global i8**** @g_1484, align 8
@g_1492 = internal global i32 5, align 4
@g_1536 = internal constant { i16, [6 x i8] } { i16 9580, [6 x i8] undef }, align 8
@g_1596 = internal global { i16, [6 x i8] } { i16 -12791, [6 x i8] undef }, align 8
@g_1638 = internal global i64** @g_1277, align 8
@g_1637 = internal global i64*** @g_1638, align 8
@g_1636 = internal global i64**** @g_1637, align 8
@g_1674 = internal global i32* @g_12, align 8
@g_1673 = internal global i32** @g_1674, align 8
@g_1723 = internal global [6 x [1 x [7 x { i16, [6 x i8] }]]] [[1 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -6, [6 x i8] undef }, { i16, [6 x i8] } { i16 26039, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 6, [6 x i8] undef }, { i16, [6 x i8] } { i16 -6033, [6 x i8] undef }, { i16, [6 x i8] } { i16 6, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }]], [1 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -7225, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7225, [6 x i8] undef }, { i16, [6 x i8] } { i16 6, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24651, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 12235, [6 x i8] undef }, { i16, [6 x i8] } { i16 -6, [6 x i8] undef }]], [1 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -24651, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7225, [6 x i8] undef }, { i16, [6 x i8] } { i16 2938, [6 x i8] undef }, { i16, [6 x i8] } { i16 12235, [6 x i8] undef }, { i16, [6 x i8] } { i16 12235, [6 x i8] undef }, { i16, [6 x i8] } { i16 2938, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7225, [6 x i8] undef }]], [1 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 2938, [6 x i8] undef }, { i16, [6 x i8] } { i16 26039, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7225, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -24651, [6 x i8] undef }]], [1 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 2938, [6 x i8] undef }, { i16, [6 x i8] } { i16 -6, [6 x i8] undef }, { i16, [6 x i8] } { i16 -6033, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7225, [6 x i8] undef }, { i16, [6 x i8] } { i16 -6033, [6 x i8] undef }, { i16, [6 x i8] } { i16 -6, [6 x i8] undef }, { i16, [6 x i8] } { i16 2938, [6 x i8] undef }]], [1 x [7 x { i16, [6 x i8] }]] [[7 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -24651, [6 x i8] undef }, { i16, [6 x i8] } { i16 1, [6 x i8] undef }, { i16, [6 x i8] } { i16 0, [6 x i8] undef }, { i16, [6 x i8] } { i16 -1, [6 x i8] undef }, { i16, [6 x i8] } { i16 -7225, [6 x i8] undef }, { i16, [6 x i8] } { i16 26039, [6 x i8] undef }, { i16, [6 x i8] } { i16 2938, [6 x i8] undef }]]], align 16
@g_1792 = internal global { i16, [6 x i8] } { i16 0, [6 x i8] undef }, align 8
@g_1862 = internal global [5 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 -8163, [6 x i8] undef }, { i16, [6 x i8] } { i16 -8163, [6 x i8] undef }, { i16, [6 x i8] } { i16 -8163, [6 x i8] undef }, { i16, [6 x i8] } { i16 -8163, [6 x i8] undef }, { i16, [6 x i8] } { i16 -8163, [6 x i8] undef }], align 16
@g_1921 = internal global %union.U0* bitcast ({ i16, [6 x i8] }* @g_80 to %union.U0*), align 8
@g_1920 = internal constant %union.U0** @g_1921, align 8
@g_1919 = internal global %union.U0*** @g_1920, align 8
@g_2015 = internal constant i32** @g_1358, align 8
@g_2056 = internal global i16 18315, align 2
@g_2097 = internal global i64* @g_733, align 8
@g_2096 = internal global i64** @g_2097, align 8
@g_2113 = internal global i64 5044493731482447010, align 8
@g_2146 = internal constant { i16, [6 x i8] } { i16 773, [6 x i8] undef }, align 8
@g_2186 = internal global i32 1, align 4
@g_2218 = internal global { i16, [6 x i8] } { i16 12964, [6 x i8] undef }, align 8
@g_2225 = internal global { i16, [6 x i8] } { i16 4, [6 x i8] undef }, align 8
@g_2226 = internal global { i16, [6 x i8] } { i16 27505, [6 x i8] undef }, align 8
@g_2227 = internal global { i16, [6 x i8] } { i16 -2474, [6 x i8] undef }, align 8
@g_2228 = internal global { i16, [6 x i8] } { i16 2988, [6 x i8] undef }, align 8
@g_2246 = internal constant { i16, [6 x i8] } { i16 1640, [6 x i8] undef }, align 8
@g_2258 = internal global [9 x [4 x i32***]] [[4 x i32***] [i32*** @g_421, i32*** null, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** null, i32*** @g_421, i32*** @g_421, i32*** null], [4 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** null, i32*** @g_421, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421, i32*** @g_421], [4 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421, i32*** @g_421]], align 16
@g_2257 = internal global [7 x i32****] [i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****)], align 16
@g_2419 = internal constant { i16, [6 x i8] } { i16 -29316, [6 x i8] undef }, align 8
@g_2470 = internal global i32 895340918, align 4
@g_2497 = internal global i64 1, align 8
@g_2496 = internal global i64* @g_2497, align 8
@g_2495 = internal global i64** @g_2496, align 8
@g_2498 = internal constant i64*** @g_2495, align 8
@g_2591 = internal global i32*** bitcast (i8* getelementptr (i8, i8* bitcast ([8 x i32**]* @g_796 to i8*), i64 40) to i32***), align 8
@g_2655 = internal global i16***** null, align 8
@g_2674 = internal global i32** @g_1358, align 8
@g_2727 = internal constant i32***** null, align 8
@g_2729 = internal global [5 x [1 x [1 x i32****]]] [[1 x [1 x i32****]] [[1 x i32****] [i32**** @g_2591]], [1 x [1 x i32****]] [[1 x i32****] [i32**** @g_2591]], [1 x [1 x i32****]] [[1 x i32****] [i32**** @g_2591]], [1 x [1 x i32****]] [[1 x i32****] [i32**** @g_2591]], [1 x [1 x i32****]] [[1 x i32****] [i32**** @g_2591]]], align 16
@g_2742 = internal global i32 9, align 4
@g_2767 = internal global i32 -1, align 4
@g_2766 = internal global i32* @g_2767, align 8
@g_2765 = internal global i32** @g_2766, align 8
@g_2764 = internal global [7 x i32***] [i32*** @g_2765, i32*** @g_2765, i32*** @g_2765, i32*** @g_2765, i32*** @g_2765, i32*** @g_2765, i32*** @g_2765], align 16
@g_2763 = internal global i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([7 x i32***]* @g_2764 to i8*), i64 32) to i32****), align 8
@g_2780 = internal global [6 x [10 x i32**]] [[10 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797], [10 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797], [10 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797], [10 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797], [10 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797], [10 x i32**] [i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797, i32** @g_797]], align 16
@g_2779 = internal constant i32*** bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [10 x i32**]]* @g_2780 to i8*), i64 360) to i32***), align 8
@g_2778 = internal global [5 x [1 x [4 x i32****]]] [[1 x [4 x i32****]] [[4 x i32****] [i32**** null, i32**** @g_2779, i32**** null, i32**** @g_2779]], [1 x [4 x i32****]] [[4 x i32****] [i32**** null, i32**** @g_2779, i32**** @g_2779, i32**** @g_2779]], [1 x [4 x i32****]] [[4 x i32****] [i32**** @g_2779, i32**** @g_2779, i32**** @g_2779, i32**** @g_2779]], [1 x [4 x i32****]] [[4 x i32****] [i32**** @g_2779, i32**** null, i32**** @g_2779, i32**** null]], [1 x [4 x i32****]] [[4 x i32****] [i32**** @g_2779, i32**** null, i32**** @g_2779, i32**** @g_2779]]], align 16
@g_2777 = internal global i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [4 x i32****]]]* @g_2778 to i8*), i64 56) to i32*****), align 8
@g_2796 = internal global i8 1, align 1
@g_2807 = internal constant { i16, [6 x i8] } { i16 1, [6 x i8] undef }, align 8
@g_2846 = internal global i32** null, align 8
@g_2847 = internal global i32** null, align 8
@g_2855 = internal global [8 x i8*] [i8* @g_790, i8* getelementptr (i8, i8* getelementptr inbounds ([4 x [6 x [7 x i8]]], [4 x [6 x [7 x i8]]]* @g_105, i32 0, i32 0, i32 0, i32 0), i64 90), i8* @g_790, i8* getelementptr (i8, i8* getelementptr inbounds ([4 x [6 x [7 x i8]]], [4 x [6 x [7 x i8]]]* @g_105, i32 0, i32 0, i32 0, i32 0), i64 90), i8* @g_790, i8* getelementptr (i8, i8* getelementptr inbounds ([4 x [6 x [7 x i8]]], [4 x [6 x [7 x i8]]]* @g_105, i32 0, i32 0, i32 0, i32 0), i64 90), i8* @g_790, i8* getelementptr (i8, i8* getelementptr inbounds ([4 x [6 x [7 x i8]]], [4 x [6 x [7 x i8]]]* @g_105, i32 0, i32 0, i32 0, i32 0), i64 90)], align 16
@g_2854 = internal constant i8** bitcast (i8* getelementptr (i8, i8* bitcast ([8 x i8*]* @g_2855 to i8*), i64 32) to i8**), align 8
@g_2853 = internal global i8*** @g_2854, align 8
@g_2896 = internal global { i16, [6 x i8] } { i16 6, [6 x i8] undef }, align 8
@g_2895 = internal global %union.U0* bitcast ({ i16, [6 x i8] }* @g_2896 to %union.U0*), align 8
@g_2969 = internal global [4 x [10 x [5 x i32**]]] [[10 x [5 x i32**]] [[5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422], [5 x i32**] [i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422], [5 x i32**] [i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422], [5 x i32**] [i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422, i32** @g_422], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null]], [10 x [5 x i32**]] [[5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422]], [10 x [5 x i32**]] [[5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null]], [10 x [5 x i32**]] [[5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null], [5 x i32**] [i32** null, i32** @g_422, i32** @g_422, i32** null, i32** @g_422], [5 x i32**] [i32** null, i32** null, i32** @g_422, i32** null, i32** null], [5 x i32**] [i32** @g_422, i32** null, i32** @g_422, i32** @g_422, i32** null]]], align 16
@g_2984 = internal constant i16*** @g_318, align 8
@g_2983 = internal global i16**** @g_2984, align 8
@g_3033 = internal global i8 71, align 1
@g_3141 = internal global [3 x { i16, [6 x i8] }] [{ i16, [6 x i8] } { i16 30333, [6 x i8] undef }, { i16, [6 x i8] } { i16 30333, [6 x i8] undef }, { i16, [6 x i8] } { i16 30333, [6 x i8] undef }], align 16
@g_3287 = internal global [9 x [5 x i32*****]] [[5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****)], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 32) to i32*****), i32***** getelementptr inbounds ([5 x [1 x [1 x i32****]]], [5 x [1 x [1 x i32****]]]* @g_2729, i32 0, i32 0, i32 0, i32 0), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** null], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****)]], align 16
@g_3291 = internal global { i16, [6 x i8] } { i16 20504, [6 x i8] undef }, align 8
@g_3309 = internal global { i16, [6 x i8] } { i16 9688, [6 x i8] undef }, align 8
@g_3409 = internal constant i8 1, align 1
@g_3408 = internal global i8* @g_3409, align 8
@g_3501 = internal global [6 x %union.U0***] [%union.U0*** @g_547, %union.U0*** @g_547, %union.U0*** @g_547, %union.U0*** @g_547, %union.U0*** @g_547, %union.U0*** @g_547], align 16
@g_3503 = internal global %union.U0** null, align 8
@g_3502 = internal global %union.U0*** @g_3503, align 8
@g_3634 = internal global { i16, [6 x i8] } { i16 -9695, [6 x i8] undef }, align 8
@g_3649 = internal global i32** @g_1358, align 8
@g_3810 = internal global i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****), align 8
@__const.func_1.l_3809 = private unnamed_addr constant [4 x [5 x i32*****]] [[5 x i32*****] [i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)], [5 x i32*****] [i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null, i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** null], [5 x i32*****] [i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 8) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****), i32***** bitcast (i8* getelementptr (i8, i8* bitcast ([5 x [1 x [1 x i32****]]]* @g_2729 to i8*), i64 24) to i32*****)]], align 16
@__const.func_2.l_3360 = private unnamed_addr constant [8 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*)], align 16
@__const.func_2.l_3597 = private unnamed_addr constant [6 x [7 x [1 x i32]]] [[7 x [1 x i32]] [[1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7]], [7 x [1 x i32]] [[1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1]], [7 x [1 x i32]] [[1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788]], [7 x [1 x i32]] [[1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1]], [7 x [1 x i32]] [[1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7]], [7 x [1 x i32]] [[1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1], [1 x i32] [i32 7], [1 x i32] [i32 -1], [1 x i32] [i32 63590788], [1 x i32] [i32 -1]]], align 16
@__const.func_2.l_3341 = private unnamed_addr constant [9 x i32] [i32 109629022, i32 270155857, i32 270155857, i32 109629022, i32 270155857, i32 270155857, i32 109629022, i32 270155857, i32 270155857], align 16
@constinit = private global [6 x i32*] [i32* @g_95, i32* @g_95, i32* @g_326, i32* null, i32* @g_216, i32* null], align 8
@constinit.2 = private global [6 x i32*] [i32* @g_95, i32* @g_216, i32* null, i32* null, i32* null, i32* null], align 8
@constinit.3 = private global [6 x i32*] [i32* null, i32* @g_326, i32* @g_95, i32* null, i32* @g_326, i32* null], align 8
@constinit.4 = private global [6 x i32*] [i32* null, i32* @g_326, i32* null, i32* @g_95, i32* @g_326, i32* null], align 8
@__const.func_2.l_3697 = private unnamed_addr constant [8 x i64] [i64 -851600923168889037, i64 -851600923168889037, i64 -851600923168889037, i64 -851600923168889037, i64 -851600923168889037, i64 -851600923168889037, i64 -851600923168889037, i64 -851600923168889037], align 16
@__const.func_6.l_2950 = private unnamed_addr constant [8 x [9 x i32]] [[9 x i32] [i32 -1311845533, i32 1, i32 -1311845533, i32 -1, i32 4, i32 1998750075, i32 -895102967, i32 -4, i32 1], [9 x i32] [i32 1, i32 -5, i32 0, i32 1, i32 -895102967, i32 -1278322259, i32 -366927363, i32 -1278322259, i32 -895102967], [9 x i32] [i32 -1, i32 -366927363, i32 -366927363, i32 -1, i32 -5, i32 1752655239, i32 -1278322259, i32 1977682668, i32 -895102967], [9 x i32] [i32 1977682668, i32 -1311845533, i32 -1861527424, i32 -366927363, i32 0, i32 1, i32 4, i32 4, i32 1], [9 x i32] [i32 -5, i32 990608468, i32 -1, i32 990608468, i32 -5, i32 1977682668, i32 -1311845533, i32 -1861527424, i32 -366927363], [9 x i32] [i32 -5, i32 1752655239, i32 -1278322259, i32 1977682668, i32 -895102967, i32 -1311845533, i32 -4, i32 1998750075, i32 -4], [9 x i32] [i32 1977682668, i32 4, i32 -505582283, i32 -505582283, i32 4, i32 1977682668, i32 1, i32 -5, i32 0], [9 x i32] [i32 -1, i32 4, i32 1998750075, i32 -895102967, i32 -4, i32 1, i32 -505582283, i32 990608468, i32 990608468]], align 16
@__const.func_6.l_2959 = private unnamed_addr constant [8 x i32*] [i32* null, i32* null, i32* @g_868, i32* null, i32* null, i32* @g_868, i32* null, i32* null], align 16
@__const.func_6.l_3086 = private unnamed_addr constant [4 x i64] [i64 -4, i64 -4, i64 -4, i64 -4], align 16
@__const.func_6.l_2953 = private unnamed_addr constant [6 x [2 x i32**]] [[2 x i32**] [i32** null, i32** @g_1674], [2 x i32**] [i32** null, i32** @g_1674], [2 x i32**] [i32** null, i32** @g_1674], [2 x i32**] [i32** null, i32** @g_1674], [2 x i32**] [i32** null, i32** @g_1674], [2 x i32**] [i32** null, i32** @g_1674]], align 16
@__const.func_6.l_3032 = private unnamed_addr constant [6 x [9 x i32]] [[9 x i32] [i32 -2, i32 -836152903, i32 -2, i32 -836152903, i32 -2, i32 -836152903, i32 -2, i32 -836152903, i32 -2], [9 x i32] [i32 981747157, i32 981747157, i32 5, i32 5, i32 981747157, i32 981747157, i32 5, i32 5, i32 981747157], [9 x i32] [i32 -1, i32 -836152903, i32 -1, i32 -836152903, i32 -1, i32 -836152903, i32 -1, i32 -836152903, i32 -1], [9 x i32] [i32 981747157, i32 5, i32 5, i32 981747157, i32 981747157, i32 5, i32 5, i32 981747157, i32 981747157], [9 x i32] [i32 -2, i32 -836152903, i32 -2, i32 -836152903, i32 -2, i32 -836152903, i32 -2, i32 -836152903, i32 -2], [9 x i32] [i32 981747157, i32 981747157, i32 5, i32 5, i32 981747157, i32 981747157, i32 5, i32 5, i32 981747157]], align 16
@__const.func_6.l_3123 = private unnamed_addr constant [5 x i32] [i32 -271881316, i32 -271881316, i32 -271881316, i32 -271881316, i32 -271881316], align 16
@__const.func_6.l_3140 = private unnamed_addr constant [7 x i32] [i32 -10, i32 -10, i32 -10, i32 -10, i32 -10, i32 -10, i32 -10], align 16
@__const.func_13.l_2898 = private unnamed_addr constant [9 x i32*] [i32* @g_89, i32* @g_868, i32* @g_89, i32* @g_89, i32* @g_868, i32* @g_89, i32* @g_89, i32* @g_868, i32* @g_89], align 16
@__const.func_17.l_2791 = private unnamed_addr constant [8 x [10 x [3 x i32]]] [[10 x [3 x i32]] [[3 x i32] [i32 9, i32 -680914547, i32 -1], [3 x i32] [i32 757618144, i32 307543372, i32 0], [3 x i32] [i32 68860217, i32 -1040005161, i32 -4], [3 x i32] [i32 -5, i32 -2119905611, i32 -358181165], [3 x i32] [i32 68860217, i32 -1, i32 -1], [3 x i32] [i32 757618144, i32 -1967009393, i32 -5], [3 x i32] [i32 9, i32 -1600182607, i32 0], [3 x i32] [i32 2020078227, i32 732830505, i32 -5], [3 x i32] [i32 -1, i32 -1558317158, i32 -1], [3 x i32] [i32 0, i32 -1, i32 -358181165]], [10 x [3 x i32]] [[3 x i32] [i32 -4, i32 808279520, i32 -4], [3 x i32] [i32 -358181165, i32 -1, i32 0], [3 x i32] [i32 -1, i32 -1558317158, i32 -1], [3 x i32] [i32 -5, i32 732830505, i32 2020078227], [3 x i32] [i32 0, i32 -1600182607, i32 9], [3 x i32] [i32 -5, i32 -1967009393, i32 757618144], [3 x i32] [i32 -1, i32 -1, i32 68860217], [3 x i32] [i32 -358181165, i32 -2119905611, i32 -5], [3 x i32] [i32 -4, i32 -1040005161, i32 68860217], [3 x i32] [i32 0, i32 307543372, i32 757618144]], [10 x [3 x i32]] [[3 x i32] [i32 -1, i32 -680914547, i32 9], [3 x i32] [i32 2020078227, i32 666833569, i32 2020078227], [3 x i32] [i32 9, i32 -680914547, i32 -1], [3 x i32] [i32 757618144, i32 307543372, i32 0], [3 x i32] [i32 68860217, i32 -1040005161, i32 -4], [3 x i32] [i32 -5, i32 -2119905611, i32 -358181165], [3 x i32] [i32 68860217, i32 -1, i32 -1], [3 x i32] [i32 757618144, i32 -1967009393, i32 -5], [3 x i32] [i32 9, i32 -1600182607, i32 0], [3 x i32] [i32 2020078227, i32 732830505, i32 -5]], [10 x [3 x i32]] [[3 x i32] [i32 -1, i32 -1558317158, i32 -1], [3 x i32] [i32 0, i32 -1, i32 -358181165], [3 x i32] [i32 -4, i32 808279520, i32 -4], [3 x i32] [i32 -358181165, i32 -1, i32 0], [3 x i32] [i32 -1, i32 -1558317158, i32 -1], [3 x i32] [i32 -5, i32 732830505, i32 2020078227], [3 x i32] [i32 0, i32 -1600182607, i32 9], [3 x i32] [i32 -5, i32 -1967009393, i32 757618144], [3 x i32] [i32 -1, i32 -1, i32 68860217], [3 x i32] [i32 -358181165, i32 -2119905611, i32 -5]], [10 x [3 x i32]] [[3 x i32] [i32 -4, i32 -1040005161, i32 68860217], [3 x i32] [i32 0, i32 -5, i32 0], [3 x i32] [i32 0, i32 9, i32 1], [3 x i32] [i32 -1, i32 -5, i32 -1], [3 x i32] [i32 1, i32 9, i32 0], [3 x i32] [i32 0, i32 -5, i32 844039334], [3 x i32] [i32 -4, i32 235331964, i32 777585433], [3 x i32] [i32 2, i32 -5, i32 2], [3 x i32] [i32 -4, i32 0, i32 9], [3 x i32] [i32 0, i32 -5, i32 -9]], [10 x [3 x i32]] [[3 x i32] [i32 1, i32 -1, i32 -1], [3 x i32] [i32 -1, i32 -1261911356, i32 -9], [3 x i32] [i32 0, i32 68860217, i32 9], [3 x i32] [i32 844039334, i32 -358181165, i32 2], [3 x i32] [i32 777585433, i32 858082506, i32 777585433], [3 x i32] [i32 2, i32 -358181165, i32 844039334], [3 x i32] [i32 9, i32 68860217, i32 0], [3 x i32] [i32 -9, i32 -1261911356, i32 -1], [3 x i32] [i32 -1, i32 -1, i32 1], [3 x i32] [i32 -9, i32 -5, i32 0]], [10 x [3 x i32]] [[3 x i32] [i32 9, i32 0, i32 -4], [3 x i32] [i32 2, i32 -5, i32 2], [3 x i32] [i32 777585433, i32 235331964, i32 -4], [3 x i32] [i32 844039334, i32 -5, i32 0], [3 x i32] [i32 0, i32 9, i32 1], [3 x i32] [i32 -1, i32 -5, i32 -1], [3 x i32] [i32 1, i32 9, i32 0], [3 x i32] [i32 0, i32 -5, i32 844039334], [3 x i32] [i32 -4, i32 235331964, i32 777585433], [3 x i32] [i32 2, i32 -5, i32 2]], [10 x [3 x i32]] [[3 x i32] [i32 -4, i32 0, i32 9], [3 x i32] [i32 0, i32 -5, i32 -9], [3 x i32] [i32 1, i32 -1, i32 -1], [3 x i32] [i32 -1, i32 -1261911356, i32 -9], [3 x i32] [i32 0, i32 68860217, i32 9], [3 x i32] [i32 844039334, i32 -358181165, i32 2], [3 x i32] [i32 777585433, i32 858082506, i32 777585433], [3 x i32] [i32 2, i32 -358181165, i32 844039334], [3 x i32] [i32 9, i32 68860217, i32 0], [3 x i32] [i32 -9, i32 -1261911356, i32 -1]]], align 16
@__const.func_17.l_2794 = private unnamed_addr constant [7 x [4 x [2 x i32]]] [[4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]], [4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]], [4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]], [4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]], [4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]], [4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]], [4 x [2 x i32]] [[2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398], [2 x i32] [i32 467395398, i32 4], [2 x i32] [i32 467395398, i32 467395398]]], align 16
@__const.func_17.l_2792 = private unnamed_addr constant [5 x i32] [i32 -1639613946, i32 -1639613946, i32 -1639613946, i32 -1639613946, i32 -1639613946], align 16
@__const.func_17.l_2790 = private unnamed_addr constant [4 x [7 x i32*]] [[7 x i32*] [i32* @g_868, i32* @g_45, i32* @g_868, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* @g_868, i32* @g_45], [7 x i32*] [i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* @g_45, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 72) to i32*), i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 72) to i32*), i32* @g_45, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* @g_45], [7 x i32*] [i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 72) to i32*), i32* @g_868, i32* @g_868, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 72) to i32*), i32* null, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 72) to i32*), i32* @g_868], [7 x i32*] [i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* @g_868, i32* @g_45, i32* @g_868, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*), i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 80) to i32*)]], align 16
@__const.func_17.l_2814 = private unnamed_addr constant [4 x [4 x i16*]] [[4 x i16*] [i16* @g_2056, i16* @g_135, i16* @g_2056, i16* @g_135], [4 x i16*] [i16* @g_2056, i16* @g_135, i16* @g_2056, i16* @g_135], [4 x i16*] [i16* @g_2056, i16* @g_135, i16* @g_2056, i16* @g_135], [4 x i16*] [i16* @g_2056, i16* @g_135, i16* @g_2056, i16* @g_135]], align 16
@__const.func_17.l_2832 = private unnamed_addr constant [9 x i32] [i32 -727605265, i32 -727605265, i32 3, i32 -727605265, i32 -727605265, i32 3, i32 -727605265, i32 -727605265, i32 3], align 16
@__const.func_17.l_2849 = private unnamed_addr constant [4 x [3 x i32***]] [[3 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421], [3 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421], [3 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421], [3 x i32***] [i32*** @g_421, i32*** @g_421, i32*** @g_421]], align 16
@__const.func_17.l_2884 = private unnamed_addr constant [7 x i32] [i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1], align 16
@__const.func_28.l_2681 = private unnamed_addr constant [5 x [8 x i32]] [[8 x i32] [i32 1094045872, i32 -7, i32 -7, i32 1094045872, i32 -7, i32 -7, i32 1094045872, i32 -7], [8 x i32] [i32 1094045872, i32 1094045872, i32 -686683244, i32 1094045872, i32 1094045872, i32 -686683244, i32 1094045872, i32 1094045872], [8 x i32] [i32 -7, i32 1094045872, i32 -7, i32 -7, i32 1094045872, i32 -7, i32 -7, i32 1094045872], [8 x i32] [i32 1094045872, i32 -7, i32 -7, i32 1094045872, i32 -7, i32 -7, i32 1094045872, i32 -7], [8 x i32] [i32 1094045872, i32 1094045872, i32 -686683244, i32 1094045872, i32 1094045872, i32 -686683244, i32 1094045872, i32 1094045872]], align 16
@__const.func_28.l_2731 = private unnamed_addr constant [8 x [7 x [2 x %union.U0*]]] [[7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)]], [7 x [2 x %union.U0*]] [[2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* null, %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*)], [2 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* null], [2 x %union.U0*] [%union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to i8*), i64 224) to %union.U0*), %union.U0* bitcast (i8* getelementptr (i8, i8* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to i8*), i64 16) to %union.U0*)]]], align 16
@__const.func_41.l_2667 = private unnamed_addr constant [6 x [2 x [8 x i32]]] [[2 x [8 x i32]] [[8 x i32] [i32 175096280, i32 -1, i32 -470620652, i32 -1, i32 1, i32 1, i32 -1, i32 -470620652], [8 x i32] [i32 -1, i32 -1, i32 1227680229, i32 -1, i32 5, i32 99876257, i32 -1755616839, i32 -1]], [2 x [8 x i32]] [[8 x i32] [i32 5, i32 99876257, i32 -1755616839, i32 -1, i32 352067248, i32 -470620652, i32 352067248, i32 -1], [8 x i32] [i32 99876257, i32 1227680229, i32 99876257, i32 -1, i32 -1, i32 175096280, i32 -1, i32 -470620652]], [2 x [8 x i32]] [[8 x i32] [i32 -1, i32 1828441986, i32 -1, i32 -1, i32 -1755616839, i32 -1, i32 -1, i32 -1755616839], [8 x i32] [i32 -1, i32 352067248, i32 352067248, i32 -1, i32 -1, i32 -1, i32 -1, i32 175096280]], [2 x [8 x i32]] [[8 x i32] [i32 99876257, i32 -944866873, i32 -1, i32 -1, i32 352067248, i32 1227680229, i32 175096280, i32 1227680229], [8 x i32] [i32 5, i32 -944866873, i32 -1, i32 -944866873, i32 5, i32 -1, i32 -1, i32 1]], [2 x [8 x i32]] [[8 x i32] [i32 -1, i32 352067248, i32 5, i32 -470620652, i32 1, i32 -1, i32 -944866873, i32 -944866873], [8 x i32] [i32 175096280, i32 1828441986, i32 5, i32 5, i32 1828441986, i32 175096280, i32 -1, i32 1]], [2 x [8 x i32]] [[8 x i32] [i32 1, i32 1227680229, i32 -1, i32 1, i32 -944866873, i32 -470620652, i32 175096280, i32 -1], [8 x i32] [i32 -1, i32 99876257, i32 -1, i32 1, i32 -1, i32 99876257, i32 -1, i32 1]]], align 16
@__const.func_41.l_2661 = private unnamed_addr constant [6 x i32*] [i32* @g_675, i32* @g_675, i32* @g_675, i32* @g_675, i32* @g_675, i32* @g_675], align 16
@__const.func_46.l_1953 = private unnamed_addr constant [9 x [5 x [5 x i32]]] [[5 x [5 x i32]] [[5 x i32] [i32 0, i32 1, i32 1040352217, i32 1, i32 0], [5 x i32] [i32 -762855199, i32 -1, i32 8, i32 0, i32 588284660], [5 x i32] [i32 669247310, i32 7, i32 -1, i32 748418109, i32 287305019], [5 x i32] [i32 9, i32 -1709576544, i32 -1, i32 -1, i32 588284660], [5 x i32] [i32 1040352217, i32 748418109, i32 748418109, i32 1040352217, i32 0]], [5 x [5 x i32]] [[5 x i32] [i32 588284660, i32 0, i32 1, i32 -1653672224, i32 8], [5 x i32] [i32 -1563923091, i32 0, i32 1, i32 -2040402918, i32 0], [5 x i32] [i32 1, i32 0, i32 -1042353853, i32 -1653672224, i32 -1653672224], [5 x i32] [i32 7, i32 -1563923091, i32 7, i32 1040352217, i32 360642898], [5 x i32] [i32 0, i32 673089111, i32 832246703, i32 -1, i32 0]], [5 x [5 x i32]] [[5 x i32] [i32 -9, i32 0, i32 0, i32 748418109, i32 -3], [5 x i32] [i32 -1, i32 -1653672224, i32 832246703, i32 0, i32 832246703], [5 x i32] [i32 1, i32 1, i32 7, i32 1, i32 -2040402918], [5 x i32] [i32 8, i32 -976584694, i32 328439630, i32 -1, i32 -1653672224], [5 x i32] [i32 -6, i32 1, i32 287305019, i32 -1, i32 -9]], [5 x [5 x i32]] [[5 x i32] [i32 0, i32 -1022763393, i32 8, i32 8, i32 -1022763393], [5 x i32] [i32 -2065532016, i32 287305019, i32 1, i32 1040352217, i32 -2040402918], [5 x i32] [i32 673089111, i32 832246703, i32 -1, i32 0, i32 -1], [5 x i32] [i32 748418109, i32 669247310, i32 -9, i32 1, i32 7], [5 x i32] [i32 673089111, i32 0, i32 0, i32 0, i32 673089111]], [5 x [5 x i32]] [[5 x i32] [i32 -2065532016, i32 0, i32 7, i32 -9, i32 287305019], [5 x i32] [i32 0, i32 -762855199, i32 1, i32 588284660, i32 496776416], [5 x i32] [i32 -6, i32 1, i32 -1563923091, i32 0, i32 287305019], [5 x i32] [i32 0, i32 588284660, i32 588284660, i32 0, i32 673089111], [5 x i32] [i32 287305019, i32 1, i32 1040352217, i32 -2040402918, i32 7]], [5 x [5 x i32]] [[5 x i32] [i32 -1042353853, i32 673089111, i32 9, i32 -1709576544, i32 -1], [5 x i32] [i32 1040352217, i32 -3, i32 669247310, i32 -2040402918, i32 -2040402918], [5 x i32] [i32 -762855199, i32 -1042353853, i32 -762855199, i32 0, i32 -1022763393], [5 x i32] [i32 -3, i32 748418109, i32 0, i32 0, i32 -9], [5 x i32] [i32 8, i32 328439630, i32 673089111, i32 588284660, i32 -1653672224]], [5 x [5 x i32]] [[5 x i32] [i32 0, i32 -2040402918, i32 0, i32 -9, i32 0], [5 x i32] [i32 9, i32 9, i32 -762855199, i32 0, i32 -1709576544], [5 x i32] [i32 7, i32 0, i32 669247310, i32 1, i32 -2065532016], [5 x i32] [i32 496776416, i32 -1, i32 9, i32 0, i32 1], [5 x i32] [i32 -1, i32 0, i32 1040352217, i32 1040352217, i32 0]], [5 x [5 x i32]] [[5 x i32] [i32 -1653672224, i32 9, i32 588284660, i32 8, i32 832246703], [5 x i32] [i32 1, i32 -2040402918, i32 -1563923091, i32 -1, i32 1], [5 x i32] [i32 0, i32 328439630, i32 1, i32 -1, i32 0], [5 x i32] [i32 1, i32 748418109, i32 7, i32 748418109, i32 1], [5 x i32] [i32 -1653672224, i32 -1042353853, i32 0, i32 1, i32 9]], [5 x [5 x i32]] [[5 x i32] [i32 -1, i32 -3, i32 -9, i32 1, i32 -6], [5 x i32] [i32 496776416, i32 673089111, i32 -1, i32 -1042353853, i32 9], [5 x i32] [i32 7, i32 1, i32 1, i32 7, i32 1], [5 x i32] [i32 9, i32 588284660, i32 8, i32 832246703, i32 0], [5 x i32] [i32 0, i32 1, i32 287305019, i32 0, i32 1]]], align 16
@__const.func_46.l_2041 = private unnamed_addr constant [8 x i16*] [i16* @g_135, i16* @g_135, i16* @g_135, i16* @g_135, i16* @g_135, i16* @g_135, i16* @g_135, i16* @g_135], align 16
@__const.func_46.l_2222 = private unnamed_addr constant [5 x [8 x [6 x i8*]]] [[8 x [6 x i8*]] [[6 x i8*] [i8* null, i8* @g_82, i8* @g_116, i8* @g_116, i8* null, i8* @g_116], [6 x i8*] [i8* null, i8* @g_82, i8* null, i8* @g_116, i8* @g_82, i8* @g_116], [6 x i8*] [i8* @g_82, i8* @g_82, i8* null, i8* @g_82, i8* null, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* null], [6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* null, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_116, i8* null, i8* @g_116]], [8 x [6 x i8*]] [[6 x i8*] [i8* null, i8* @g_116, i8* null, i8* null, i8* @g_82, i8* @g_116], [6 x i8*] [i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_116, i8* null], [6 x i8*] [i8* @g_82, i8* @g_82, i8* @g_82, i8* null, i8* @g_82, i8* @g_82], [6 x i8*] [i8* null, i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_116], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* null, i8* @g_116, i8* @g_116], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* null]], [8 x [6 x i8*]] [[6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* null, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_116, i8* null, i8* @g_116], [6 x i8*] [i8* null, i8* @g_116, i8* null, i8* null, i8* @g_82, i8* @g_116], [6 x i8*] [i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_116, i8* null], [6 x i8*] [i8* @g_82, i8* @g_82, i8* @g_82, i8* null, i8* @g_82, i8* @g_82], [6 x i8*] [i8* null, i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_116], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* null, i8* @g_116, i8* @g_116]], [8 x [6 x i8*]] [[6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* null], [6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* null, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_116, i8* null, i8* @g_116], [6 x i8*] [i8* null, i8* @g_116, i8* null, i8* null, i8* @g_82, i8* @g_116], [6 x i8*] [i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_116, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_116, i8* null], [6 x i8*] [i8* @g_82, i8* @g_82, i8* @g_82, i8* null, i8* @g_82, i8* @g_82]], [8 x [6 x i8*]] [[6 x i8*] [i8* null, i8* @g_82, i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_116], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* null, i8* @g_116, i8* @g_116], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_82], [6 x i8*] [i8* @g_116, i8* @g_116, i8* @g_82, i8* @g_82, i8* null, i8* @g_116], [6 x i8*] [i8* @g_116, i8* @g_116, i8* null, i8* @g_116, i8* @g_116, i8* @g_82], [6 x i8*] [i8* @g_82, i8* @g_116, i8* @g_82, i8* @g_82, i8* @g_82, i8* @g_82], [6 x i8*] [i8* null, i8* @g_82, i8* null, i8* @g_116, i8* null, i8* @g_82], [6 x i8*] [i8* @g_116, i8* null, i8* @g_82, i8* @g_82, i8* @g_116, i8* @g_82]]], align 16
@__const.func_46.l_1980 = private unnamed_addr constant [3 x [8 x i32]] [[8 x i32] [i32 773770082, i32 -775458224, i32 773770082, i32 -1977262283, i32 -1, i32 -1977262283, i32 773770082, i32 -775458224], [8 x i32] [i32 -1, i32 -1977262283, i32 773770082, i32 -775458224, i32 773770082, i32 -1977262283, i32 -1, i32 -1977262283], [8 x i32] [i32 -1, i32 -775458224, i32 926746526, i32 -775458224, i32 -1, i32 1, i32 -1, i32 -775458224]], align 16
@__const.func_46.l_2162 = private unnamed_addr constant [4 x i8*] [i8* @g_116, i8* @g_116, i8* @g_116, i8* @g_116], align 16
@__const.func_46.l_2224 = private unnamed_addr constant [8 x [4 x [1 x %union.U0*]]] [[4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2228 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)]], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] zeroinitializer, [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)]], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2228 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] zeroinitializer], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2228 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)]], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] zeroinitializer, [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)]], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2228 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] zeroinitializer], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2228 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)]], [4 x [1 x %union.U0*]] [[1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] zeroinitializer, [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*)], [1 x %union.U0*] [%union.U0* bitcast ({ i16, [6 x i8] }* @g_2225 to %union.U0*)]]], align 16
@constinit.5 = private global [5 x i32*] [i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 84) to i32*), i32* @g_868, i32* @g_868, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 84) to i32*), i32* @g_45], align 8
@constinit.6 = private global [5 x i32*] [i32* @g_45, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 84) to i32*), i32* @g_868, i32* @g_868, i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 84) to i32*)], align 8
@__const.func_46.l_2424 = private unnamed_addr constant [3 x [8 x i64]] [[8 x i64] [i64 1, i64 -1, i64 1, i64 1, i64 -1, i64 1, i64 1, i64 -1], [8 x i64] [i64 -1, i64 1, i64 1, i64 -1, i64 1, i64 1, i64 -1, i64 1], [8 x i64] [i64 -1, i64 -1, i64 1, i64 -1, i64 -1, i64 1, i64 -1, i64 -1]], align 16
@__const.func_46.l_2411 = private unnamed_addr constant [8 x i32] [i32 -1432506906, i32 -2, i32 -1432506906, i32 -1432506906, i32 -2, i32 -1432506906, i32 -1432506906, i32 -2], align 16
@__const.func_46.l_2417 = private unnamed_addr constant [10 x i32*] [i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216, i32* @g_216], align 16
@__const.func_46.l_2570 = private unnamed_addr constant [5 x i32] [i32 1, i32 1, i32 1, i32 1, i32 1], align 16
@__const.func_48.l_195 = private unnamed_addr constant [8 x i16*] [i16* @g_135, i16* null, i16* @g_135, i16* null, i16* @g_135, i16* null, i16* @g_135, i16* null], align 16
@__const.func_48.l_274 = private unnamed_addr constant [6 x i16] [i16 -7, i16 -7, i16 -7, i16 -7, i16 -7, i16 -7], align 2
@__const.func_48.l_1127 = private unnamed_addr constant [1 x [4 x i32***]] [[4 x i32***] [i32*** getelementptr inbounds ([8 x i32**], [8 x i32**]* @g_796, i32 0, i32 0), i32*** getelementptr inbounds ([8 x i32**], [8 x i32**]* @g_796, i32 0, i32 0), i32*** getelementptr inbounds ([8 x i32**], [8 x i32**]* @g_796, i32 0, i32 0), i32*** getelementptr inbounds ([8 x i32**], [8 x i32**]* @g_796, i32 0, i32 0)]], align 16
@__const.func_48.l_1801 = private unnamed_addr constant [7 x i16] [i16 -31882, i16 8, i16 -31882, i16 -31882, i16 8, i16 -31882, i16 -31882], align 2
@__const.func_52.l_81 = private unnamed_addr constant [8 x i8*] [i8* @g_82, i8* @g_82, i8* @g_82, i8* @g_82, i8* @g_82, i8* @g_82, i8* @g_82, i8* @g_82], align 16
@__const.func_52.l_83 = private unnamed_addr constant [5 x [3 x i32*]] [[3 x i32*] [i32* @g_45, i32* @g_45, i32* @g_45], [3 x i32*] [i32* @g_45, i32* @g_45, i32* @g_45], [3 x i32*] [i32* @g_45, i32* @g_45, i32* @g_45], [3 x i32*] [i32* @g_45, i32* @g_45, i32* @g_45], [3 x i32*] [i32* @g_45, i32* @g_45, i32* @g_45]], align 16
@.str.7 = private unnamed_addr constant [2 x i8] c"1\00", align 1
@.str.8 = private unnamed_addr constant [5 x i8] c"g_12\00", align 1
@.str.9 = private unnamed_addr constant [8 x i8] c"g_27.f0\00", align 1
@.str.10 = private unnamed_addr constant [5 x i8] c"g_45\00", align 1
@.str.11 = private unnamed_addr constant [8 x i8] c"g_80.f0\00", align 1
@.str.12 = private unnamed_addr constant [5 x i8] c"g_82\00", align 1
@.str.13 = private unnamed_addr constant [5 x i8] c"g_89\00", align 1
@.str.14 = private unnamed_addr constant [5 x i8] c"g_95\00", align 1
@.str.15 = private unnamed_addr constant [15 x i8] c"g_105[i][j][k]\00", align 1
@.str.16 = private unnamed_addr constant [22 x i8] c"index = [%d][%d][%d]\0A\00", align 1
@.str.17 = private unnamed_addr constant [6 x i8] c"g_116\00", align 1
@.str.18 = private unnamed_addr constant [6 x i8] c"g_135\00", align 1
@.str.19 = private unnamed_addr constant [6 x i8] c"g_155\00", align 1
@.str.20 = private unnamed_addr constant [15 x i8] c"g_169[i][j][k]\00", align 1
@.str.21 = private unnamed_addr constant [6 x i8] c"g_216\00", align 1
@.str.22 = private unnamed_addr constant [6 x i8] c"g_326\00", align 1
@.str.23 = private unnamed_addr constant [6 x i8] c"g_370\00", align 1
@.str.24 = private unnamed_addr constant [9 x i8] c"g_444.f0\00", align 1
@.str.25 = private unnamed_addr constant [9 x i8] c"g_493.f0\00", align 1
@.str.26 = private unnamed_addr constant [18 x i8] c"g_494[i][j][k].f0\00", align 1
@.str.27 = private unnamed_addr constant [12 x i8] c"g_495[i].f0\00", align 1
@.str.28 = private unnamed_addr constant [14 x i8] c"index = [%d]\0A\00", align 1
@.str.29 = private unnamed_addr constant [6 x i8] c"g_561\00", align 1
@.str.30 = private unnamed_addr constant [6 x i8] c"g_617\00", align 1
@.str.31 = private unnamed_addr constant [9 x i8] c"g_635.f0\00", align 1
@.str.32 = private unnamed_addr constant [6 x i8] c"g_637\00", align 1
@.str.33 = private unnamed_addr constant [6 x i8] c"g_675\00", align 1
@.str.34 = private unnamed_addr constant [6 x i8] c"g_684\00", align 1
@.str.35 = private unnamed_addr constant [6 x i8] c"g_733\00", align 1
@.str.36 = private unnamed_addr constant [12 x i8] c"g_781[i][j]\00", align 1
@.str.37 = private unnamed_addr constant [18 x i8] c"index = [%d][%d]\0A\00", align 1
@.str.38 = private unnamed_addr constant [6 x i8] c"g_790\00", align 1
@.str.39 = private unnamed_addr constant [6 x i8] c"g_868\00", align 1
@.str.40 = private unnamed_addr constant [9 x i8] c"g_902.f0\00", align 1
@.str.41 = private unnamed_addr constant [9 x i8] c"g_910[i]\00", align 1
@.str.42 = private unnamed_addr constant [9 x i8] c"g_927.f0\00", align 1
@.str.43 = private unnamed_addr constant [9 x i8] c"g_956.f0\00", align 1
@.str.44 = private unnamed_addr constant [7 x i8] c"g_1008\00", align 1
@.str.45 = private unnamed_addr constant [13 x i8] c"g_1028[i].f0\00", align 1
@.str.46 = private unnamed_addr constant [7 x i8] c"g_1036\00", align 1
@.str.47 = private unnamed_addr constant [10 x i8] c"g_1065.f0\00", align 1
@.str.48 = private unnamed_addr constant [10 x i8] c"g_1168.f0\00", align 1
@.str.49 = private unnamed_addr constant [7 x i8] c"g_1205\00", align 1
@.str.50 = private unnamed_addr constant [10 x i8] c"g_1227.f0\00", align 1
@.str.51 = private unnamed_addr constant [10 x i8] c"g_1228.f0\00", align 1
@.str.52 = private unnamed_addr constant [16 x i8] c"g_1269[i][j][k]\00", align 1
@.str.53 = private unnamed_addr constant [13 x i8] c"g_1347[i].f0\00", align 1
@.str.54 = private unnamed_addr constant [7 x i8] c"g_1356\00", align 1
@.str.55 = private unnamed_addr constant [10 x i8] c"g_1440.f0\00", align 1
@.str.56 = private unnamed_addr constant [7 x i8] c"g_1492\00", align 1
@.str.57 = private unnamed_addr constant [10 x i8] c"g_1536.f0\00", align 1
@.str.58 = private unnamed_addr constant [10 x i8] c"g_1596.f0\00", align 1
@.str.59 = private unnamed_addr constant [19 x i8] c"g_1723[i][j][k].f0\00", align 1
@.str.60 = private unnamed_addr constant [10 x i8] c"g_1792.f0\00", align 1
@.str.61 = private unnamed_addr constant [13 x i8] c"g_1862[i].f0\00", align 1
@.str.62 = private unnamed_addr constant [7 x i8] c"g_2056\00", align 1
@.str.63 = private unnamed_addr constant [7 x i8] c"g_2113\00", align 1
@.str.64 = private unnamed_addr constant [10 x i8] c"g_2146.f0\00", align 1
@.str.65 = private unnamed_addr constant [7 x i8] c"g_2186\00", align 1
@.str.66 = private unnamed_addr constant [10 x i8] c"g_2218.f0\00", align 1
@.str.67 = private unnamed_addr constant [10 x i8] c"g_2225.f0\00", align 1
@.str.68 = private unnamed_addr constant [10 x i8] c"g_2226.f0\00", align 1
@.str.69 = private unnamed_addr constant [10 x i8] c"g_2227.f0\00", align 1
@.str.70 = private unnamed_addr constant [10 x i8] c"g_2228.f0\00", align 1
@.str.71 = private unnamed_addr constant [10 x i8] c"g_2246.f0\00", align 1
@.str.72 = private unnamed_addr constant [10 x i8] c"g_2419.f0\00", align 1
@.str.73 = private unnamed_addr constant [7 x i8] c"g_2470\00", align 1
@.str.74 = private unnamed_addr constant [7 x i8] c"g_2497\00", align 1
@.str.75 = private unnamed_addr constant [7 x i8] c"g_2742\00", align 1
@.str.76 = private unnamed_addr constant [7 x i8] c"g_2767\00", align 1
@.str.77 = private unnamed_addr constant [7 x i8] c"g_2796\00", align 1
@.str.78 = private unnamed_addr constant [10 x i8] c"g_2807.f0\00", align 1
@.str.79 = private unnamed_addr constant [10 x i8] c"g_2896.f0\00", align 1
@.str.80 = private unnamed_addr constant [7 x i8] c"g_3033\00", align 1
@.str.81 = private unnamed_addr constant [13 x i8] c"g_3141[i].f0\00", align 1
@.str.82 = private unnamed_addr constant [10 x i8] c"g_3291.f0\00", align 1
@.str.83 = private unnamed_addr constant [10 x i8] c"g_3309.f0\00", align 1
@.str.84 = private unnamed_addr constant [7 x i8] c"g_3409\00", align 1
@.str.85 = private unnamed_addr constant [10 x i8] c"g_3634.f0\00", align 1
@__undefined = internal global i64 0, align 8

; Function Attrs: noinline nounwind optnone uwtable
define internal void @platform_main_begin() #0 {
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @platform_main_end(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str, i64 0, i64 0), i32 %5)
  ret void
}

declare dso_local i32 @printf(i8*, ...) #1

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_unary_minus_func_int8_t_s(i8 signext %0) #0 {
  %2 = alloca i8, align 1
  store i8 %0, i8* %2, align 1
  %3 = load i8, i8* %2, align 1
  %4 = sext i8 %3 to i32
  %5 = sub nsw i32 0, %4
  %6 = trunc i32 %5 to i8
  ret i8 %6
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_add_func_int8_t_s_s(i8 signext %0, i8 signext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = load i8, i8* %4, align 1
  %8 = sext i8 %7 to i32
  %9 = add nsw i32 %6, %8
  %10 = trunc i32 %9 to i8
  ret i8 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_sub_func_int8_t_s_s(i8 signext %0, i8 signext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = load i8, i8* %4, align 1
  %8 = sext i8 %7 to i32
  %9 = sub nsw i32 %6, %8
  %10 = trunc i32 %9 to i8
  ret i8 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_mul_func_int8_t_s_s(i8 signext %0, i8 signext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = load i8, i8* %4, align 1
  %8 = sext i8 %7 to i32
  %9 = mul nsw i32 %6, %8
  %10 = trunc i32 %9 to i8
  ret i8 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_mod_func_int8_t_s_s(i8 signext %0, i8 signext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %4, align 1
  %6 = sext i8 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %16, label %8

8:                                                ; preds = %2
  %9 = load i8, i8* %3, align 1
  %10 = sext i8 %9 to i32
  %11 = icmp eq i32 %10, -128
  br i1 %11, label %12, label %19

12:                                               ; preds = %8
  %13 = load i8, i8* %4, align 1
  %14 = sext i8 %13 to i32
  %15 = icmp eq i32 %14, -1
  br i1 %15, label %16, label %19

16:                                               ; preds = %12, %2
  %17 = load i8, i8* %3, align 1
  %18 = sext i8 %17 to i32
  br label %25

19:                                               ; preds = %12, %8
  %20 = load i8, i8* %3, align 1
  %21 = sext i8 %20 to i32
  %22 = load i8, i8* %4, align 1
  %23 = sext i8 %22 to i32
  %24 = srem i32 %21, %23
  br label %25

25:                                               ; preds = %19, %16
  %26 = phi i32 [ %18, %16 ], [ %24, %19 ]
  %27 = trunc i32 %26 to i8
  ret i8 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_div_func_int8_t_s_s(i8 signext %0, i8 signext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %4, align 1
  %6 = sext i8 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %16, label %8

8:                                                ; preds = %2
  %9 = load i8, i8* %3, align 1
  %10 = sext i8 %9 to i32
  %11 = icmp eq i32 %10, -128
  br i1 %11, label %12, label %19

12:                                               ; preds = %8
  %13 = load i8, i8* %4, align 1
  %14 = sext i8 %13 to i32
  %15 = icmp eq i32 %14, -1
  br i1 %15, label %16, label %19

16:                                               ; preds = %12, %2
  %17 = load i8, i8* %3, align 1
  %18 = sext i8 %17 to i32
  br label %25

19:                                               ; preds = %12, %8
  %20 = load i8, i8* %3, align 1
  %21 = sext i8 %20 to i32
  %22 = load i8, i8* %4, align 1
  %23 = sext i8 %22 to i32
  %24 = sdiv i32 %21, %23
  br label %25

25:                                               ; preds = %19, %16
  %26 = phi i32 [ %18, %16 ], [ %24, %19 ]
  %27 = trunc i32 %26 to i8
  ret i8 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_lshift_func_int8_t_s_s(i8 signext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %20, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp slt i32 %9, 0
  br i1 %10, label %20, label %11

11:                                               ; preds = %8
  %12 = load i32, i32* %4, align 4
  %13 = icmp sge i32 %12, 32
  br i1 %13, label %20, label %14

14:                                               ; preds = %11
  %15 = load i8, i8* %3, align 1
  %16 = sext i8 %15 to i32
  %17 = load i32, i32* %4, align 4
  %18 = ashr i32 127, %17
  %19 = icmp sgt i32 %16, %18
  br i1 %19, label %20, label %23

20:                                               ; preds = %14, %11, %8, %2
  %21 = load i8, i8* %3, align 1
  %22 = sext i8 %21 to i32
  br label %28

23:                                               ; preds = %14
  %24 = load i8, i8* %3, align 1
  %25 = sext i8 %24 to i32
  %26 = load i32, i32* %4, align 4
  %27 = shl i32 %25, %26
  br label %28

28:                                               ; preds = %23, %20
  %29 = phi i32 [ %22, %20 ], [ %27, %23 ]
  %30 = trunc i32 %29 to i8
  ret i8 %30
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_lshift_func_int8_t_s_u(i8 signext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %17, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp uge i32 %9, 32
  br i1 %10, label %17, label %11

11:                                               ; preds = %8
  %12 = load i8, i8* %3, align 1
  %13 = sext i8 %12 to i32
  %14 = load i32, i32* %4, align 4
  %15 = ashr i32 127, %14
  %16 = icmp sgt i32 %13, %15
  br i1 %16, label %17, label %20

17:                                               ; preds = %11, %8, %2
  %18 = load i8, i8* %3, align 1
  %19 = sext i8 %18 to i32
  br label %25

20:                                               ; preds = %11
  %21 = load i8, i8* %3, align 1
  %22 = sext i8 %21 to i32
  %23 = load i32, i32* %4, align 4
  %24 = shl i32 %22, %23
  br label %25

25:                                               ; preds = %20, %17
  %26 = phi i32 [ %19, %17 ], [ %24, %20 ]
  %27 = trunc i32 %26 to i8
  ret i8 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_rshift_func_int8_t_s_s(i8 signext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %14, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp slt i32 %9, 0
  br i1 %10, label %14, label %11

11:                                               ; preds = %8
  %12 = load i32, i32* %4, align 4
  %13 = icmp sge i32 %12, 32
  br i1 %13, label %14, label %17

14:                                               ; preds = %11, %8, %2
  %15 = load i8, i8* %3, align 1
  %16 = sext i8 %15 to i32
  br label %22

17:                                               ; preds = %11
  %18 = load i8, i8* %3, align 1
  %19 = sext i8 %18 to i32
  %20 = load i32, i32* %4, align 4
  %21 = ashr i32 %19, %20
  br label %22

22:                                               ; preds = %17, %14
  %23 = phi i32 [ %16, %14 ], [ %21, %17 ]
  %24 = trunc i32 %23 to i8
  ret i8 %24
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i8, i8* %3, align 1
  %6 = sext i8 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %11, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp uge i32 %9, 32
  br i1 %10, label %11, label %14

11:                                               ; preds = %8, %2
  %12 = load i8, i8* %3, align 1
  %13 = sext i8 %12 to i32
  br label %19

14:                                               ; preds = %8
  %15 = load i8, i8* %3, align 1
  %16 = sext i8 %15 to i32
  %17 = load i32, i32* %4, align 4
  %18 = ashr i32 %16, %17
  br label %19

19:                                               ; preds = %14, %11
  %20 = phi i32 [ %13, %11 ], [ %18, %14 ]
  %21 = trunc i32 %20 to i8
  ret i8 %21
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_unary_minus_func_int16_t_s(i16 signext %0) #0 {
  %2 = alloca i16, align 2
  store i16 %0, i16* %2, align 2
  %3 = load i16, i16* %2, align 2
  %4 = sext i16 %3 to i32
  %5 = sub nsw i32 0, %4
  %6 = trunc i32 %5 to i16
  ret i16 %6
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_add_func_int16_t_s_s(i16 signext %0, i16 signext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = load i16, i16* %4, align 2
  %8 = sext i16 %7 to i32
  %9 = add nsw i32 %6, %8
  %10 = trunc i32 %9 to i16
  ret i16 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_sub_func_int16_t_s_s(i16 signext %0, i16 signext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = load i16, i16* %4, align 2
  %8 = sext i16 %7 to i32
  %9 = sub nsw i32 %6, %8
  %10 = trunc i32 %9 to i16
  ret i16 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_mul_func_int16_t_s_s(i16 signext %0, i16 signext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = load i16, i16* %4, align 2
  %8 = sext i16 %7 to i32
  %9 = mul nsw i32 %6, %8
  %10 = trunc i32 %9 to i16
  ret i16 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_mod_func_int16_t_s_s(i16 signext %0, i16 signext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %4, align 2
  %6 = sext i16 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %16, label %8

8:                                                ; preds = %2
  %9 = load i16, i16* %3, align 2
  %10 = sext i16 %9 to i32
  %11 = icmp eq i32 %10, -32768
  br i1 %11, label %12, label %19

12:                                               ; preds = %8
  %13 = load i16, i16* %4, align 2
  %14 = sext i16 %13 to i32
  %15 = icmp eq i32 %14, -1
  br i1 %15, label %16, label %19

16:                                               ; preds = %12, %2
  %17 = load i16, i16* %3, align 2
  %18 = sext i16 %17 to i32
  br label %25

19:                                               ; preds = %12, %8
  %20 = load i16, i16* %3, align 2
  %21 = sext i16 %20 to i32
  %22 = load i16, i16* %4, align 2
  %23 = sext i16 %22 to i32
  %24 = srem i32 %21, %23
  br label %25

25:                                               ; preds = %19, %16
  %26 = phi i32 [ %18, %16 ], [ %24, %19 ]
  %27 = trunc i32 %26 to i16
  ret i16 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_div_func_int16_t_s_s(i16 signext %0, i16 signext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %4, align 2
  %6 = sext i16 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %16, label %8

8:                                                ; preds = %2
  %9 = load i16, i16* %3, align 2
  %10 = sext i16 %9 to i32
  %11 = icmp eq i32 %10, -32768
  br i1 %11, label %12, label %19

12:                                               ; preds = %8
  %13 = load i16, i16* %4, align 2
  %14 = sext i16 %13 to i32
  %15 = icmp eq i32 %14, -1
  br i1 %15, label %16, label %19

16:                                               ; preds = %12, %2
  %17 = load i16, i16* %3, align 2
  %18 = sext i16 %17 to i32
  br label %25

19:                                               ; preds = %12, %8
  %20 = load i16, i16* %3, align 2
  %21 = sext i16 %20 to i32
  %22 = load i16, i16* %4, align 2
  %23 = sext i16 %22 to i32
  %24 = sdiv i32 %21, %23
  br label %25

25:                                               ; preds = %19, %16
  %26 = phi i32 [ %18, %16 ], [ %24, %19 ]
  %27 = trunc i32 %26 to i16
  ret i16 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_lshift_func_int16_t_s_s(i16 signext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %20, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp slt i32 %9, 0
  br i1 %10, label %20, label %11

11:                                               ; preds = %8
  %12 = load i32, i32* %4, align 4
  %13 = icmp sge i32 %12, 32
  br i1 %13, label %20, label %14

14:                                               ; preds = %11
  %15 = load i16, i16* %3, align 2
  %16 = sext i16 %15 to i32
  %17 = load i32, i32* %4, align 4
  %18 = ashr i32 32767, %17
  %19 = icmp sgt i32 %16, %18
  br i1 %19, label %20, label %23

20:                                               ; preds = %14, %11, %8, %2
  %21 = load i16, i16* %3, align 2
  %22 = sext i16 %21 to i32
  br label %28

23:                                               ; preds = %14
  %24 = load i16, i16* %3, align 2
  %25 = sext i16 %24 to i32
  %26 = load i32, i32* %4, align 4
  %27 = shl i32 %25, %26
  br label %28

28:                                               ; preds = %23, %20
  %29 = phi i32 [ %22, %20 ], [ %27, %23 ]
  %30 = trunc i32 %29 to i16
  ret i16 %30
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %17, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp uge i32 %9, 32
  br i1 %10, label %17, label %11

11:                                               ; preds = %8
  %12 = load i16, i16* %3, align 2
  %13 = sext i16 %12 to i32
  %14 = load i32, i32* %4, align 4
  %15 = ashr i32 32767, %14
  %16 = icmp sgt i32 %13, %15
  br i1 %16, label %17, label %20

17:                                               ; preds = %11, %8, %2
  %18 = load i16, i16* %3, align 2
  %19 = sext i16 %18 to i32
  br label %25

20:                                               ; preds = %11
  %21 = load i16, i16* %3, align 2
  %22 = sext i16 %21 to i32
  %23 = load i32, i32* %4, align 4
  %24 = shl i32 %22, %23
  br label %25

25:                                               ; preds = %20, %17
  %26 = phi i32 [ %19, %17 ], [ %24, %20 ]
  %27 = trunc i32 %26 to i16
  ret i16 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_rshift_func_int16_t_s_s(i16 signext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %14, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp slt i32 %9, 0
  br i1 %10, label %14, label %11

11:                                               ; preds = %8
  %12 = load i32, i32* %4, align 4
  %13 = icmp sge i32 %12, 32
  br i1 %13, label %14, label %17

14:                                               ; preds = %11, %8, %2
  %15 = load i16, i16* %3, align 2
  %16 = sext i16 %15 to i32
  br label %22

17:                                               ; preds = %11
  %18 = load i16, i16* %3, align 2
  %19 = sext i16 %18 to i32
  %20 = load i32, i32* %4, align 4
  %21 = ashr i32 %19, %20
  br label %22

22:                                               ; preds = %17, %14
  %23 = phi i32 [ %16, %14 ], [ %21, %17 ]
  %24 = trunc i32 %23 to i16
  ret i16 %24
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @safe_rshift_func_int16_t_s_u(i16 signext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i16, i16* %3, align 2
  %6 = sext i16 %5 to i32
  %7 = icmp slt i32 %6, 0
  br i1 %7, label %11, label %8

8:                                                ; preds = %2
  %9 = load i32, i32* %4, align 4
  %10 = icmp uge i32 %9, 32
  br i1 %10, label %11, label %14

11:                                               ; preds = %8, %2
  %12 = load i16, i16* %3, align 2
  %13 = sext i16 %12 to i32
  br label %19

14:                                               ; preds = %8
  %15 = load i16, i16* %3, align 2
  %16 = sext i16 %15 to i32
  %17 = load i32, i32* %4, align 4
  %18 = ashr i32 %16, %17
  br label %19

19:                                               ; preds = %14, %11
  %20 = phi i32 [ %13, %11 ], [ %18, %14 ]
  %21 = trunc i32 %20 to i16
  ret i16 %21
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_unary_minus_func_int32_t_s(i32 %0) #0 {
  %2 = alloca i32, align 4
  store i32 %0, i32* %2, align 4
  %3 = load i32, i32* %2, align 4
  %4 = icmp eq i32 %3, -2147483648
  br i1 %4, label %5, label %7

5:                                                ; preds = %1
  %6 = load i32, i32* %2, align 4
  br label %10

7:                                                ; preds = %1
  %8 = load i32, i32* %2, align 4
  %9 = sub nsw i32 0, %8
  br label %10

10:                                               ; preds = %7, %5
  %11 = phi i32 [ %6, %5 ], [ %9, %7 ]
  ret i32 %11
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_add_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = icmp sgt i32 %5, 0
  br i1 %6, label %7, label %15

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sgt i32 %8, 0
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i32, i32* %3, align 4
  %12 = load i32, i32* %4, align 4
  %13 = sub nsw i32 2147483647, %12
  %14 = icmp sgt i32 %11, %13
  br i1 %14, label %26, label %15

15:                                               ; preds = %10, %7, %2
  %16 = load i32, i32* %3, align 4
  %17 = icmp slt i32 %16, 0
  br i1 %17, label %18, label %28

18:                                               ; preds = %15
  %19 = load i32, i32* %4, align 4
  %20 = icmp slt i32 %19, 0
  br i1 %20, label %21, label %28

21:                                               ; preds = %18
  %22 = load i32, i32* %3, align 4
  %23 = load i32, i32* %4, align 4
  %24 = sub nsw i32 -2147483648, %23
  %25 = icmp slt i32 %22, %24
  br i1 %25, label %26, label %28

26:                                               ; preds = %21, %10
  %27 = load i32, i32* %3, align 4
  br label %32

28:                                               ; preds = %21, %18, %15
  %29 = load i32, i32* %3, align 4
  %30 = load i32, i32* %4, align 4
  %31 = add nsw i32 %29, %30
  br label %32

32:                                               ; preds = %28, %26
  %33 = phi i32 [ %27, %26 ], [ %31, %28 ]
  ret i32 %33
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_sub_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = load i32, i32* %4, align 4
  %7 = xor i32 %5, %6
  %8 = load i32, i32* %3, align 4
  %9 = load i32, i32* %3, align 4
  %10 = load i32, i32* %4, align 4
  %11 = xor i32 %9, %10
  %12 = and i32 %11, -2147483648
  %13 = xor i32 %8, %12
  %14 = load i32, i32* %4, align 4
  %15 = sub nsw i32 %13, %14
  %16 = load i32, i32* %4, align 4
  %17 = xor i32 %15, %16
  %18 = and i32 %7, %17
  %19 = icmp slt i32 %18, 0
  br i1 %19, label %20, label %22

20:                                               ; preds = %2
  %21 = load i32, i32* %3, align 4
  br label %26

22:                                               ; preds = %2
  %23 = load i32, i32* %3, align 4
  %24 = load i32, i32* %4, align 4
  %25 = sub nsw i32 %23, %24
  br label %26

26:                                               ; preds = %22, %20
  %27 = phi i32 [ %21, %20 ], [ %25, %22 ]
  ret i32 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_mul_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = icmp sgt i32 %5, 0
  br i1 %6, label %7, label %15

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sgt i32 %8, 0
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i32, i32* %3, align 4
  %12 = load i32, i32* %4, align 4
  %13 = sdiv i32 2147483647, %12
  %14 = icmp sgt i32 %11, %13
  br i1 %14, label %51, label %15

15:                                               ; preds = %10, %7, %2
  %16 = load i32, i32* %3, align 4
  %17 = icmp sgt i32 %16, 0
  br i1 %17, label %18, label %26

18:                                               ; preds = %15
  %19 = load i32, i32* %4, align 4
  %20 = icmp sle i32 %19, 0
  br i1 %20, label %21, label %26

21:                                               ; preds = %18
  %22 = load i32, i32* %4, align 4
  %23 = load i32, i32* %3, align 4
  %24 = sdiv i32 -2147483648, %23
  %25 = icmp slt i32 %22, %24
  br i1 %25, label %51, label %26

26:                                               ; preds = %21, %18, %15
  %27 = load i32, i32* %3, align 4
  %28 = icmp sle i32 %27, 0
  br i1 %28, label %29, label %37

29:                                               ; preds = %26
  %30 = load i32, i32* %4, align 4
  %31 = icmp sgt i32 %30, 0
  br i1 %31, label %32, label %37

32:                                               ; preds = %29
  %33 = load i32, i32* %3, align 4
  %34 = load i32, i32* %4, align 4
  %35 = sdiv i32 -2147483648, %34
  %36 = icmp slt i32 %33, %35
  br i1 %36, label %51, label %37

37:                                               ; preds = %32, %29, %26
  %38 = load i32, i32* %3, align 4
  %39 = icmp sle i32 %38, 0
  br i1 %39, label %40, label %53

40:                                               ; preds = %37
  %41 = load i32, i32* %4, align 4
  %42 = icmp sle i32 %41, 0
  br i1 %42, label %43, label %53

43:                                               ; preds = %40
  %44 = load i32, i32* %3, align 4
  %45 = icmp ne i32 %44, 0
  br i1 %45, label %46, label %53

46:                                               ; preds = %43
  %47 = load i32, i32* %4, align 4
  %48 = load i32, i32* %3, align 4
  %49 = sdiv i32 2147483647, %48
  %50 = icmp slt i32 %47, %49
  br i1 %50, label %51, label %53

51:                                               ; preds = %46, %32, %21, %10
  %52 = load i32, i32* %3, align 4
  br label %57

53:                                               ; preds = %46, %43, %40, %37
  %54 = load i32, i32* %3, align 4
  %55 = load i32, i32* %4, align 4
  %56 = mul nsw i32 %54, %55
  br label %57

57:                                               ; preds = %53, %51
  %58 = phi i32 [ %52, %51 ], [ %56, %53 ]
  ret i32 %58
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_mod_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %3, align 4
  %9 = icmp eq i32 %8, -2147483648
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i32, i32* %4, align 4
  %12 = icmp eq i32 %11, -1
  br i1 %12, label %13, label %15

13:                                               ; preds = %10, %2
  %14 = load i32, i32* %3, align 4
  br label %19

15:                                               ; preds = %10, %7
  %16 = load i32, i32* %3, align 4
  %17 = load i32, i32* %4, align 4
  %18 = srem i32 %16, %17
  br label %19

19:                                               ; preds = %15, %13
  %20 = phi i32 [ %14, %13 ], [ %18, %15 ]
  ret i32 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_div_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %3, align 4
  %9 = icmp eq i32 %8, -2147483648
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i32, i32* %4, align 4
  %12 = icmp eq i32 %11, -1
  br i1 %12, label %13, label %15

13:                                               ; preds = %10, %2
  %14 = load i32, i32* %3, align 4
  br label %19

15:                                               ; preds = %10, %7
  %16 = load i32, i32* %3, align 4
  %17 = load i32, i32* %4, align 4
  %18 = sdiv i32 %16, %17
  br label %19

19:                                               ; preds = %15, %13
  %20 = phi i32 [ %14, %13 ], [ %18, %15 ]
  ret i32 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_lshift_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %18, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp slt i32 %8, 0
  br i1 %9, label %18, label %10

10:                                               ; preds = %7
  %11 = load i32, i32* %4, align 4
  %12 = icmp sge i32 %11, 32
  br i1 %12, label %18, label %13

13:                                               ; preds = %10
  %14 = load i32, i32* %3, align 4
  %15 = load i32, i32* %4, align 4
  %16 = ashr i32 2147483647, %15
  %17 = icmp sgt i32 %14, %16
  br i1 %17, label %18, label %20

18:                                               ; preds = %13, %10, %7, %2
  %19 = load i32, i32* %3, align 4
  br label %24

20:                                               ; preds = %13
  %21 = load i32, i32* %3, align 4
  %22 = load i32, i32* %4, align 4
  %23 = shl i32 %21, %22
  br label %24

24:                                               ; preds = %20, %18
  %25 = phi i32 [ %19, %18 ], [ %23, %20 ]
  ret i32 %25
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_lshift_func_int32_t_s_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %15, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp uge i32 %8, 32
  br i1 %9, label %15, label %10

10:                                               ; preds = %7
  %11 = load i32, i32* %3, align 4
  %12 = load i32, i32* %4, align 4
  %13 = ashr i32 2147483647, %12
  %14 = icmp sgt i32 %11, %13
  br i1 %14, label %15, label %17

15:                                               ; preds = %10, %7, %2
  %16 = load i32, i32* %3, align 4
  br label %21

17:                                               ; preds = %10
  %18 = load i32, i32* %3, align 4
  %19 = load i32, i32* %4, align 4
  %20 = shl i32 %18, %19
  br label %21

21:                                               ; preds = %17, %15
  %22 = phi i32 [ %16, %15 ], [ %20, %17 ]
  ret i32 %22
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_rshift_func_int32_t_s_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp slt i32 %8, 0
  br i1 %9, label %13, label %10

10:                                               ; preds = %7
  %11 = load i32, i32* %4, align 4
  %12 = icmp sge i32 %11, 32
  br i1 %12, label %13, label %15

13:                                               ; preds = %10, %7, %2
  %14 = load i32, i32* %3, align 4
  br label %19

15:                                               ; preds = %10
  %16 = load i32, i32* %3, align 4
  %17 = load i32, i32* %4, align 4
  %18 = ashr i32 %16, %17
  br label %19

19:                                               ; preds = %15, %13
  %20 = phi i32 [ %14, %13 ], [ %18, %15 ]
  ret i32 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_rshift_func_int32_t_s_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %10, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp uge i32 %8, 32
  br i1 %9, label %10, label %12

10:                                               ; preds = %7, %2
  %11 = load i32, i32* %3, align 4
  br label %16

12:                                               ; preds = %7
  %13 = load i32, i32* %3, align 4
  %14 = load i32, i32* %4, align 4
  %15 = ashr i32 %13, %14
  br label %16

16:                                               ; preds = %12, %10
  %17 = phi i32 [ %11, %10 ], [ %15, %12 ]
  ret i32 %17
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_unary_minus_func_int64_t_s(i64 %0) #0 {
  %2 = alloca i64, align 8
  store i64 %0, i64* %2, align 8
  %3 = load i64, i64* %2, align 8
  %4 = icmp eq i64 %3, -9223372036854775808
  br i1 %4, label %5, label %7

5:                                                ; preds = %1
  %6 = load i64, i64* %2, align 8
  br label %10

7:                                                ; preds = %1
  %8 = load i64, i64* %2, align 8
  %9 = sub nsw i64 0, %8
  br label %10

10:                                               ; preds = %7, %5
  %11 = phi i64 [ %6, %5 ], [ %9, %7 ]
  ret i64 %11
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_add_func_int64_t_s_s(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %3, align 8
  %6 = icmp sgt i64 %5, 0
  br i1 %6, label %7, label %15

7:                                                ; preds = %2
  %8 = load i64, i64* %4, align 8
  %9 = icmp sgt i64 %8, 0
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i64, i64* %3, align 8
  %12 = load i64, i64* %4, align 8
  %13 = sub nsw i64 9223372036854775807, %12
  %14 = icmp sgt i64 %11, %13
  br i1 %14, label %26, label %15

15:                                               ; preds = %10, %7, %2
  %16 = load i64, i64* %3, align 8
  %17 = icmp slt i64 %16, 0
  br i1 %17, label %18, label %28

18:                                               ; preds = %15
  %19 = load i64, i64* %4, align 8
  %20 = icmp slt i64 %19, 0
  br i1 %20, label %21, label %28

21:                                               ; preds = %18
  %22 = load i64, i64* %3, align 8
  %23 = load i64, i64* %4, align 8
  %24 = sub nsw i64 -9223372036854775808, %23
  %25 = icmp slt i64 %22, %24
  br i1 %25, label %26, label %28

26:                                               ; preds = %21, %10
  %27 = load i64, i64* %3, align 8
  br label %32

28:                                               ; preds = %21, %18, %15
  %29 = load i64, i64* %3, align 8
  %30 = load i64, i64* %4, align 8
  %31 = add nsw i64 %29, %30
  br label %32

32:                                               ; preds = %28, %26
  %33 = phi i64 [ %27, %26 ], [ %31, %28 ]
  ret i64 %33
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_sub_func_int64_t_s_s(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %3, align 8
  %6 = load i64, i64* %4, align 8
  %7 = xor i64 %5, %6
  %8 = load i64, i64* %3, align 8
  %9 = load i64, i64* %3, align 8
  %10 = load i64, i64* %4, align 8
  %11 = xor i64 %9, %10
  %12 = and i64 %11, -9223372036854775808
  %13 = xor i64 %8, %12
  %14 = load i64, i64* %4, align 8
  %15 = sub nsw i64 %13, %14
  %16 = load i64, i64* %4, align 8
  %17 = xor i64 %15, %16
  %18 = and i64 %7, %17
  %19 = icmp slt i64 %18, 0
  br i1 %19, label %20, label %22

20:                                               ; preds = %2
  %21 = load i64, i64* %3, align 8
  br label %26

22:                                               ; preds = %2
  %23 = load i64, i64* %3, align 8
  %24 = load i64, i64* %4, align 8
  %25 = sub nsw i64 %23, %24
  br label %26

26:                                               ; preds = %22, %20
  %27 = phi i64 [ %21, %20 ], [ %25, %22 ]
  ret i64 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_mul_func_int64_t_s_s(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %3, align 8
  %6 = icmp sgt i64 %5, 0
  br i1 %6, label %7, label %15

7:                                                ; preds = %2
  %8 = load i64, i64* %4, align 8
  %9 = icmp sgt i64 %8, 0
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i64, i64* %3, align 8
  %12 = load i64, i64* %4, align 8
  %13 = sdiv i64 9223372036854775807, %12
  %14 = icmp sgt i64 %11, %13
  br i1 %14, label %51, label %15

15:                                               ; preds = %10, %7, %2
  %16 = load i64, i64* %3, align 8
  %17 = icmp sgt i64 %16, 0
  br i1 %17, label %18, label %26

18:                                               ; preds = %15
  %19 = load i64, i64* %4, align 8
  %20 = icmp sle i64 %19, 0
  br i1 %20, label %21, label %26

21:                                               ; preds = %18
  %22 = load i64, i64* %4, align 8
  %23 = load i64, i64* %3, align 8
  %24 = sdiv i64 -9223372036854775808, %23
  %25 = icmp slt i64 %22, %24
  br i1 %25, label %51, label %26

26:                                               ; preds = %21, %18, %15
  %27 = load i64, i64* %3, align 8
  %28 = icmp sle i64 %27, 0
  br i1 %28, label %29, label %37

29:                                               ; preds = %26
  %30 = load i64, i64* %4, align 8
  %31 = icmp sgt i64 %30, 0
  br i1 %31, label %32, label %37

32:                                               ; preds = %29
  %33 = load i64, i64* %3, align 8
  %34 = load i64, i64* %4, align 8
  %35 = sdiv i64 -9223372036854775808, %34
  %36 = icmp slt i64 %33, %35
  br i1 %36, label %51, label %37

37:                                               ; preds = %32, %29, %26
  %38 = load i64, i64* %3, align 8
  %39 = icmp sle i64 %38, 0
  br i1 %39, label %40, label %53

40:                                               ; preds = %37
  %41 = load i64, i64* %4, align 8
  %42 = icmp sle i64 %41, 0
  br i1 %42, label %43, label %53

43:                                               ; preds = %40
  %44 = load i64, i64* %3, align 8
  %45 = icmp ne i64 %44, 0
  br i1 %45, label %46, label %53

46:                                               ; preds = %43
  %47 = load i64, i64* %4, align 8
  %48 = load i64, i64* %3, align 8
  %49 = sdiv i64 9223372036854775807, %48
  %50 = icmp slt i64 %47, %49
  br i1 %50, label %51, label %53

51:                                               ; preds = %46, %32, %21, %10
  %52 = load i64, i64* %3, align 8
  br label %57

53:                                               ; preds = %46, %43, %40, %37
  %54 = load i64, i64* %3, align 8
  %55 = load i64, i64* %4, align 8
  %56 = mul nsw i64 %54, %55
  br label %57

57:                                               ; preds = %53, %51
  %58 = phi i64 [ %52, %51 ], [ %56, %53 ]
  ret i64 %58
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_mod_func_int64_t_s_s(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %4, align 8
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i64, i64* %3, align 8
  %9 = icmp eq i64 %8, -9223372036854775808
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i64, i64* %4, align 8
  %12 = icmp eq i64 %11, -1
  br i1 %12, label %13, label %15

13:                                               ; preds = %10, %2
  %14 = load i64, i64* %3, align 8
  br label %19

15:                                               ; preds = %10, %7
  %16 = load i64, i64* %3, align 8
  %17 = load i64, i64* %4, align 8
  %18 = srem i64 %16, %17
  br label %19

19:                                               ; preds = %15, %13
  %20 = phi i64 [ %14, %13 ], [ %18, %15 ]
  ret i64 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_div_func_int64_t_s_s(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %4, align 8
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i64, i64* %3, align 8
  %9 = icmp eq i64 %8, -9223372036854775808
  br i1 %9, label %10, label %15

10:                                               ; preds = %7
  %11 = load i64, i64* %4, align 8
  %12 = icmp eq i64 %11, -1
  br i1 %12, label %13, label %15

13:                                               ; preds = %10, %2
  %14 = load i64, i64* %3, align 8
  br label %19

15:                                               ; preds = %10, %7
  %16 = load i64, i64* %3, align 8
  %17 = load i64, i64* %4, align 8
  %18 = sdiv i64 %16, %17
  br label %19

19:                                               ; preds = %15, %13
  %20 = phi i64 [ %14, %13 ], [ %18, %15 ]
  ret i64 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_lshift_func_int64_t_s_s(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i64, i64* %3, align 8
  %6 = icmp slt i64 %5, 0
  br i1 %6, label %19, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp slt i32 %8, 0
  br i1 %9, label %19, label %10

10:                                               ; preds = %7
  %11 = load i32, i32* %4, align 4
  %12 = icmp sge i32 %11, 32
  br i1 %12, label %19, label %13

13:                                               ; preds = %10
  %14 = load i64, i64* %3, align 8
  %15 = load i32, i32* %4, align 4
  %16 = zext i32 %15 to i64
  %17 = ashr i64 9223372036854775807, %16
  %18 = icmp sgt i64 %14, %17
  br i1 %18, label %19, label %21

19:                                               ; preds = %13, %10, %7, %2
  %20 = load i64, i64* %3, align 8
  br label %26

21:                                               ; preds = %13
  %22 = load i64, i64* %3, align 8
  %23 = load i32, i32* %4, align 4
  %24 = zext i32 %23 to i64
  %25 = shl i64 %22, %24
  br label %26

26:                                               ; preds = %21, %19
  %27 = phi i64 [ %20, %19 ], [ %25, %21 ]
  ret i64 %27
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_lshift_func_int64_t_s_u(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i64, i64* %3, align 8
  %6 = icmp slt i64 %5, 0
  br i1 %6, label %16, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp uge i32 %8, 32
  br i1 %9, label %16, label %10

10:                                               ; preds = %7
  %11 = load i64, i64* %3, align 8
  %12 = load i32, i32* %4, align 4
  %13 = zext i32 %12 to i64
  %14 = ashr i64 9223372036854775807, %13
  %15 = icmp sgt i64 %11, %14
  br i1 %15, label %16, label %18

16:                                               ; preds = %10, %7, %2
  %17 = load i64, i64* %3, align 8
  br label %23

18:                                               ; preds = %10
  %19 = load i64, i64* %3, align 8
  %20 = load i32, i32* %4, align 4
  %21 = zext i32 %20 to i64
  %22 = shl i64 %19, %21
  br label %23

23:                                               ; preds = %18, %16
  %24 = phi i64 [ %17, %16 ], [ %22, %18 ]
  ret i64 %24
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_rshift_func_int64_t_s_s(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i64, i64* %3, align 8
  %6 = icmp slt i64 %5, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp slt i32 %8, 0
  br i1 %9, label %13, label %10

10:                                               ; preds = %7
  %11 = load i32, i32* %4, align 4
  %12 = icmp sge i32 %11, 32
  br i1 %12, label %13, label %15

13:                                               ; preds = %10, %7, %2
  %14 = load i64, i64* %3, align 8
  br label %20

15:                                               ; preds = %10
  %16 = load i64, i64* %3, align 8
  %17 = load i32, i32* %4, align 4
  %18 = zext i32 %17 to i64
  %19 = ashr i64 %16, %18
  br label %20

20:                                               ; preds = %15, %13
  %21 = phi i64 [ %14, %13 ], [ %19, %15 ]
  ret i64 %21
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_rshift_func_int64_t_s_u(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i64, i64* %3, align 8
  %6 = icmp slt i64 %5, 0
  br i1 %6, label %10, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp uge i32 %8, 32
  br i1 %9, label %10, label %12

10:                                               ; preds = %7, %2
  %11 = load i64, i64* %3, align 8
  br label %17

12:                                               ; preds = %7
  %13 = load i64, i64* %3, align 8
  %14 = load i32, i32* %4, align 4
  %15 = zext i32 %14 to i64
  %16 = ashr i64 %13, %15
  br label %17

17:                                               ; preds = %12, %10
  %18 = phi i64 [ %11, %10 ], [ %16, %12 ]
  ret i64 %18
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_unary_minus_func_uint8_t_u(i8 zeroext %0) #0 {
  %2 = alloca i8, align 1
  store i8 %0, i8* %2, align 1
  %3 = load i8, i8* %2, align 1
  %4 = zext i8 %3 to i32
  %5 = sub nsw i32 0, %4
  %6 = trunc i32 %5 to i8
  ret i8 %6
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_add_func_uint8_t_u_u(i8 zeroext %0, i8 zeroext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %3, align 1
  %6 = zext i8 %5 to i32
  %7 = load i8, i8* %4, align 1
  %8 = zext i8 %7 to i32
  %9 = add nsw i32 %6, %8
  %10 = trunc i32 %9 to i8
  ret i8 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_sub_func_uint8_t_u_u(i8 zeroext %0, i8 zeroext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %3, align 1
  %6 = zext i8 %5 to i32
  %7 = load i8, i8* %4, align 1
  %8 = zext i8 %7 to i32
  %9 = sub nsw i32 %6, %8
  %10 = trunc i32 %9 to i8
  ret i8 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_mul_func_uint8_t_u_u(i8 zeroext %0, i8 zeroext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %3, align 1
  %6 = zext i8 %5 to i32
  %7 = load i8, i8* %4, align 1
  %8 = zext i8 %7 to i32
  %9 = mul i32 %6, %8
  %10 = trunc i32 %9 to i8
  ret i8 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_mod_func_uint8_t_u_u(i8 zeroext %0, i8 zeroext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %8, label %11

8:                                                ; preds = %2
  %9 = load i8, i8* %3, align 1
  %10 = zext i8 %9 to i32
  br label %17

11:                                               ; preds = %2
  %12 = load i8, i8* %3, align 1
  %13 = zext i8 %12 to i32
  %14 = load i8, i8* %4, align 1
  %15 = zext i8 %14 to i32
  %16 = srem i32 %13, %15
  br label %17

17:                                               ; preds = %11, %8
  %18 = phi i32 [ %10, %8 ], [ %16, %11 ]
  %19 = trunc i32 %18 to i8
  ret i8 %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_div_func_uint8_t_u_u(i8 zeroext %0, i8 zeroext %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i8, align 1
  store i8 %0, i8* %3, align 1
  store i8 %1, i8* %4, align 1
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %8, label %11

8:                                                ; preds = %2
  %9 = load i8, i8* %3, align 1
  %10 = zext i8 %9 to i32
  br label %17

11:                                               ; preds = %2
  %12 = load i8, i8* %3, align 1
  %13 = zext i8 %12 to i32
  %14 = load i8, i8* %4, align 1
  %15 = zext i8 %14 to i32
  %16 = sdiv i32 %13, %15
  br label %17

17:                                               ; preds = %11, %8
  %18 = phi i32 [ %10, %8 ], [ %16, %11 ]
  %19 = trunc i32 %18 to i8
  ret i8 %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_lshift_func_uint8_t_u_s(i8 zeroext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %16, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %16, label %10

10:                                               ; preds = %7
  %11 = load i8, i8* %3, align 1
  %12 = zext i8 %11 to i32
  %13 = load i32, i32* %4, align 4
  %14 = ashr i32 255, %13
  %15 = icmp sgt i32 %12, %14
  br i1 %15, label %16, label %19

16:                                               ; preds = %10, %7, %2
  %17 = load i8, i8* %3, align 1
  %18 = zext i8 %17 to i32
  br label %24

19:                                               ; preds = %10
  %20 = load i8, i8* %3, align 1
  %21 = zext i8 %20 to i32
  %22 = load i32, i32* %4, align 4
  %23 = shl i32 %21, %22
  br label %24

24:                                               ; preds = %19, %16
  %25 = phi i32 [ %18, %16 ], [ %23, %19 ]
  %26 = trunc i32 %25 to i8
  ret i8 %26
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_lshift_func_uint8_t_u_u(i8 zeroext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i8, i8* %3, align 1
  %9 = zext i8 %8 to i32
  %10 = load i32, i32* %4, align 4
  %11 = ashr i32 255, %10
  %12 = icmp sgt i32 %9, %11
  br i1 %12, label %13, label %16

13:                                               ; preds = %7, %2
  %14 = load i8, i8* %3, align 1
  %15 = zext i8 %14 to i32
  br label %21

16:                                               ; preds = %7
  %17 = load i8, i8* %3, align 1
  %18 = zext i8 %17 to i32
  %19 = load i32, i32* %4, align 4
  %20 = shl i32 %18, %19
  br label %21

21:                                               ; preds = %16, %13
  %22 = phi i32 [ %15, %13 ], [ %20, %16 ]
  %23 = trunc i32 %22 to i8
  ret i8 %23
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_rshift_func_uint8_t_u_s(i8 zeroext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %10, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %10, label %13

10:                                               ; preds = %7, %2
  %11 = load i8, i8* %3, align 1
  %12 = zext i8 %11 to i32
  br label %18

13:                                               ; preds = %7
  %14 = load i8, i8* %3, align 1
  %15 = zext i8 %14 to i32
  %16 = load i32, i32* %4, align 4
  %17 = ashr i32 %15, %16
  br label %18

18:                                               ; preds = %13, %10
  %19 = phi i32 [ %12, %10 ], [ %17, %13 ]
  %20 = trunc i32 %19 to i8
  ret i8 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i8 @safe_rshift_func_uint8_t_u_u(i8 zeroext %0, i32 %1) #0 {
  %3 = alloca i8, align 1
  %4 = alloca i32, align 4
  store i8 %0, i8* %3, align 1
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %7, label %10

7:                                                ; preds = %2
  %8 = load i8, i8* %3, align 1
  %9 = zext i8 %8 to i32
  br label %15

10:                                               ; preds = %2
  %11 = load i8, i8* %3, align 1
  %12 = zext i8 %11 to i32
  %13 = load i32, i32* %4, align 4
  %14 = ashr i32 %12, %13
  br label %15

15:                                               ; preds = %10, %7
  %16 = phi i32 [ %9, %7 ], [ %14, %10 ]
  %17 = trunc i32 %16 to i8
  ret i8 %17
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_unary_minus_func_uint16_t_u(i16 zeroext %0) #0 {
  %2 = alloca i16, align 2
  store i16 %0, i16* %2, align 2
  %3 = load i16, i16* %2, align 2
  %4 = zext i16 %3 to i32
  %5 = sub nsw i32 0, %4
  %6 = trunc i32 %5 to i16
  ret i16 %6
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %0, i16 zeroext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %3, align 2
  %6 = zext i16 %5 to i32
  %7 = load i16, i16* %4, align 2
  %8 = zext i16 %7 to i32
  %9 = add nsw i32 %6, %8
  %10 = trunc i32 %9 to i16
  ret i16 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_sub_func_uint16_t_u_u(i16 zeroext %0, i16 zeroext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %3, align 2
  %6 = zext i16 %5 to i32
  %7 = load i16, i16* %4, align 2
  %8 = zext i16 %7 to i32
  %9 = sub nsw i32 %6, %8
  %10 = trunc i32 %9 to i16
  ret i16 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %0, i16 zeroext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %3, align 2
  %6 = zext i16 %5 to i32
  %7 = load i16, i16* %4, align 2
  %8 = zext i16 %7 to i32
  %9 = mul i32 %6, %8
  %10 = trunc i32 %9 to i16
  ret i16 %10
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_mod_func_uint16_t_u_u(i16 zeroext %0, i16 zeroext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %4, align 2
  %6 = zext i16 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %8, label %11

8:                                                ; preds = %2
  %9 = load i16, i16* %3, align 2
  %10 = zext i16 %9 to i32
  br label %17

11:                                               ; preds = %2
  %12 = load i16, i16* %3, align 2
  %13 = zext i16 %12 to i32
  %14 = load i16, i16* %4, align 2
  %15 = zext i16 %14 to i32
  %16 = srem i32 %13, %15
  br label %17

17:                                               ; preds = %11, %8
  %18 = phi i32 [ %10, %8 ], [ %16, %11 ]
  %19 = trunc i32 %18 to i16
  ret i16 %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_div_func_uint16_t_u_u(i16 zeroext %0, i16 zeroext %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i16, align 2
  store i16 %0, i16* %3, align 2
  store i16 %1, i16* %4, align 2
  %5 = load i16, i16* %4, align 2
  %6 = zext i16 %5 to i32
  %7 = icmp eq i32 %6, 0
  br i1 %7, label %8, label %11

8:                                                ; preds = %2
  %9 = load i16, i16* %3, align 2
  %10 = zext i16 %9 to i32
  br label %17

11:                                               ; preds = %2
  %12 = load i16, i16* %3, align 2
  %13 = zext i16 %12 to i32
  %14 = load i16, i16* %4, align 2
  %15 = zext i16 %14 to i32
  %16 = sdiv i32 %13, %15
  br label %17

17:                                               ; preds = %11, %8
  %18 = phi i32 [ %10, %8 ], [ %16, %11 ]
  %19 = trunc i32 %18 to i16
  ret i16 %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_lshift_func_uint16_t_u_s(i16 zeroext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %16, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %16, label %10

10:                                               ; preds = %7
  %11 = load i16, i16* %3, align 2
  %12 = zext i16 %11 to i32
  %13 = load i32, i32* %4, align 4
  %14 = ashr i32 65535, %13
  %15 = icmp sgt i32 %12, %14
  br i1 %15, label %16, label %19

16:                                               ; preds = %10, %7, %2
  %17 = load i16, i16* %3, align 2
  %18 = zext i16 %17 to i32
  br label %24

19:                                               ; preds = %10
  %20 = load i16, i16* %3, align 2
  %21 = zext i16 %20 to i32
  %22 = load i32, i32* %4, align 4
  %23 = shl i32 %21, %22
  br label %24

24:                                               ; preds = %19, %16
  %25 = phi i32 [ %18, %16 ], [ %23, %19 ]
  %26 = trunc i32 %25 to i16
  ret i16 %26
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_lshift_func_uint16_t_u_u(i16 zeroext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i16, i16* %3, align 2
  %9 = zext i16 %8 to i32
  %10 = load i32, i32* %4, align 4
  %11 = ashr i32 65535, %10
  %12 = icmp sgt i32 %9, %11
  br i1 %12, label %13, label %16

13:                                               ; preds = %7, %2
  %14 = load i16, i16* %3, align 2
  %15 = zext i16 %14 to i32
  br label %21

16:                                               ; preds = %7
  %17 = load i16, i16* %3, align 2
  %18 = zext i16 %17 to i32
  %19 = load i32, i32* %4, align 4
  %20 = shl i32 %18, %19
  br label %21

21:                                               ; preds = %16, %13
  %22 = phi i32 [ %15, %13 ], [ %20, %16 ]
  %23 = trunc i32 %22 to i16
  ret i16 %23
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_rshift_func_uint16_t_u_s(i16 zeroext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %10, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %10, label %13

10:                                               ; preds = %7, %2
  %11 = load i16, i16* %3, align 2
  %12 = zext i16 %11 to i32
  br label %18

13:                                               ; preds = %7
  %14 = load i16, i16* %3, align 2
  %15 = zext i16 %14 to i32
  %16 = load i32, i32* %4, align 4
  %17 = ashr i32 %15, %16
  br label %18

18:                                               ; preds = %13, %10
  %19 = phi i32 [ %12, %10 ], [ %17, %13 ]
  %20 = trunc i32 %19 to i16
  ret i16 %20
}

; Function Attrs: noinline nounwind optnone uwtable
define internal zeroext i16 @safe_rshift_func_uint16_t_u_u(i16 zeroext %0, i32 %1) #0 {
  %3 = alloca i16, align 2
  %4 = alloca i32, align 4
  store i16 %0, i16* %3, align 2
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %7, label %10

7:                                                ; preds = %2
  %8 = load i16, i16* %3, align 2
  %9 = zext i16 %8 to i32
  br label %15

10:                                               ; preds = %2
  %11 = load i16, i16* %3, align 2
  %12 = zext i16 %11 to i32
  %13 = load i32, i32* %4, align 4
  %14 = ashr i32 %12, %13
  br label %15

15:                                               ; preds = %10, %7
  %16 = phi i32 [ %9, %7 ], [ %14, %10 ]
  %17 = trunc i32 %16 to i16
  ret i16 %17
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_unary_minus_func_uint32_t_u(i32 %0) #0 {
  %2 = alloca i32, align 4
  store i32 %0, i32* %2, align 4
  %3 = load i32, i32* %2, align 4
  %4 = sub i32 0, %3
  ret i32 %4
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_add_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = load i32, i32* %4, align 4
  %7 = add i32 %5, %6
  ret i32 %7
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_sub_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = load i32, i32* %4, align 4
  %7 = sub i32 %5, %6
  ret i32 %7
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_mul_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %3, align 4
  %6 = load i32, i32* %4, align 4
  %7 = mul i32 %5, %6
  ret i32 %7
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_mod_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %7, label %9

7:                                                ; preds = %2
  %8 = load i32, i32* %3, align 4
  br label %13

9:                                                ; preds = %2
  %10 = load i32, i32* %3, align 4
  %11 = load i32, i32* %4, align 4
  %12 = urem i32 %10, %11
  br label %13

13:                                               ; preds = %9, %7
  %14 = phi i32 [ %8, %7 ], [ %12, %9 ]
  ret i32 %14
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_div_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %7, label %9

7:                                                ; preds = %2
  %8 = load i32, i32* %3, align 4
  br label %13

9:                                                ; preds = %2
  %10 = load i32, i32* %3, align 4
  %11 = load i32, i32* %4, align 4
  %12 = udiv i32 %10, %11
  br label %13

13:                                               ; preds = %9, %7
  %14 = phi i32 [ %8, %7 ], [ %12, %9 ]
  ret i32 %14
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_lshift_func_uint32_t_u_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %15, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %15, label %10

10:                                               ; preds = %7
  %11 = load i32, i32* %3, align 4
  %12 = load i32, i32* %4, align 4
  %13 = lshr i32 -1, %12
  %14 = icmp ugt i32 %11, %13
  br i1 %14, label %15, label %17

15:                                               ; preds = %10, %7, %2
  %16 = load i32, i32* %3, align 4
  br label %21

17:                                               ; preds = %10
  %18 = load i32, i32* %3, align 4
  %19 = load i32, i32* %4, align 4
  %20 = shl i32 %18, %19
  br label %21

21:                                               ; preds = %17, %15
  %22 = phi i32 [ %16, %15 ], [ %20, %17 ]
  ret i32 %22
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_lshift_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %12, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %3, align 4
  %9 = load i32, i32* %4, align 4
  %10 = lshr i32 -1, %9
  %11 = icmp ugt i32 %8, %10
  br i1 %11, label %12, label %14

12:                                               ; preds = %7, %2
  %13 = load i32, i32* %3, align 4
  br label %18

14:                                               ; preds = %7
  %15 = load i32, i32* %3, align 4
  %16 = load i32, i32* %4, align 4
  %17 = shl i32 %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi i32 [ %13, %12 ], [ %17, %14 ]
  ret i32 %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_rshift_func_uint32_t_u_s(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %10, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %10, label %12

10:                                               ; preds = %7, %2
  %11 = load i32, i32* %3, align 4
  br label %16

12:                                               ; preds = %7
  %13 = load i32, i32* %3, align 4
  %14 = load i32, i32* %4, align 4
  %15 = lshr i32 %13, %14
  br label %16

16:                                               ; preds = %12, %10
  %17 = phi i32 [ %11, %10 ], [ %15, %12 ]
  ret i32 %17
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_rshift_func_uint32_t_u_u(i32 %0, i32 %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %7, label %9

7:                                                ; preds = %2
  %8 = load i32, i32* %3, align 4
  br label %13

9:                                                ; preds = %2
  %10 = load i32, i32* %3, align 4
  %11 = load i32, i32* %4, align 4
  %12 = lshr i32 %10, %11
  br label %13

13:                                               ; preds = %9, %7
  %14 = phi i32 [ %8, %7 ], [ %12, %9 ]
  ret i32 %14
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_unary_minus_func_uint64_t_u(i64 %0) #0 {
  %2 = alloca i64, align 8
  store i64 %0, i64* %2, align 8
  %3 = load i64, i64* %2, align 8
  %4 = sub i64 0, %3
  ret i64 %4
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_add_func_uint64_t_u_u(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %3, align 8
  %6 = load i64, i64* %4, align 8
  %7 = add i64 %5, %6
  ret i64 %7
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_sub_func_uint64_t_u_u(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %3, align 8
  %6 = load i64, i64* %4, align 8
  %7 = sub i64 %5, %6
  ret i64 %7
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_mul_func_uint64_t_u_u(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %3, align 8
  %6 = load i64, i64* %4, align 8
  %7 = mul i64 %5, %6
  ret i64 %7
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_mod_func_uint64_t_u_u(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %4, align 8
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %7, label %9

7:                                                ; preds = %2
  %8 = load i64, i64* %3, align 8
  br label %13

9:                                                ; preds = %2
  %10 = load i64, i64* %3, align 8
  %11 = load i64, i64* %4, align 8
  %12 = urem i64 %10, %11
  br label %13

13:                                               ; preds = %9, %7
  %14 = phi i64 [ %8, %7 ], [ %12, %9 ]
  ret i64 %14
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_div_func_uint64_t_u_u(i64 %0, i64 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i64, align 8
  store i64 %0, i64* %3, align 8
  store i64 %1, i64* %4, align 8
  %5 = load i64, i64* %4, align 8
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %7, label %9

7:                                                ; preds = %2
  %8 = load i64, i64* %3, align 8
  br label %13

9:                                                ; preds = %2
  %10 = load i64, i64* %3, align 8
  %11 = load i64, i64* %4, align 8
  %12 = udiv i64 %10, %11
  br label %13

13:                                               ; preds = %9, %7
  %14 = phi i64 [ %8, %7 ], [ %12, %9 ]
  ret i64 %14
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_lshift_func_uint64_t_u_s(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %16, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %16, label %10

10:                                               ; preds = %7
  %11 = load i64, i64* %3, align 8
  %12 = load i32, i32* %4, align 4
  %13 = zext i32 %12 to i64
  %14 = lshr i64 -1, %13
  %15 = icmp ugt i64 %11, %14
  br i1 %15, label %16, label %18

16:                                               ; preds = %10, %7, %2
  %17 = load i64, i64* %3, align 8
  br label %23

18:                                               ; preds = %10
  %19 = load i64, i64* %3, align 8
  %20 = load i32, i32* %4, align 4
  %21 = zext i32 %20 to i64
  %22 = shl i64 %19, %21
  br label %23

23:                                               ; preds = %18, %16
  %24 = phi i64 [ %17, %16 ], [ %22, %18 ]
  ret i64 %24
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_lshift_func_uint64_t_u_u(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %13, label %7

7:                                                ; preds = %2
  %8 = load i64, i64* %3, align 8
  %9 = load i32, i32* %4, align 4
  %10 = zext i32 %9 to i64
  %11 = lshr i64 -1, %10
  %12 = icmp ugt i64 %8, %11
  br i1 %12, label %13, label %15

13:                                               ; preds = %7, %2
  %14 = load i64, i64* %3, align 8
  br label %20

15:                                               ; preds = %7
  %16 = load i64, i64* %3, align 8
  %17 = load i32, i32* %4, align 4
  %18 = zext i32 %17 to i64
  %19 = shl i64 %16, %18
  br label %20

20:                                               ; preds = %15, %13
  %21 = phi i64 [ %14, %13 ], [ %19, %15 ]
  ret i64 %21
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_rshift_func_uint64_t_u_s(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp slt i32 %5, 0
  br i1 %6, label %10, label %7

7:                                                ; preds = %2
  %8 = load i32, i32* %4, align 4
  %9 = icmp sge i32 %8, 32
  br i1 %9, label %10, label %12

10:                                               ; preds = %7, %2
  %11 = load i64, i64* %3, align 8
  br label %17

12:                                               ; preds = %7
  %13 = load i64, i64* %3, align 8
  %14 = load i32, i32* %4, align 4
  %15 = zext i32 %14 to i64
  %16 = lshr i64 %13, %15
  br label %17

17:                                               ; preds = %12, %10
  %18 = phi i64 [ %11, %10 ], [ %16, %12 ]
  ret i64 %18
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @safe_rshift_func_uint64_t_u_u(i64 %0, i32 %1) #0 {
  %3 = alloca i64, align 8
  %4 = alloca i32, align 4
  store i64 %0, i64* %3, align 8
  store i32 %1, i32* %4, align 4
  %5 = load i32, i32* %4, align 4
  %6 = icmp uge i32 %5, 32
  br i1 %6, label %7, label %9

7:                                                ; preds = %2
  %8 = load i64, i64* %3, align 8
  br label %14

9:                                                ; preds = %2
  %10 = load i64, i64* %3, align 8
  %11 = load i32, i32* %4, align 4
  %12 = zext i32 %11 to i64
  %13 = lshr i64 %10, %12
  br label %14

14:                                               ; preds = %9, %7
  %15 = phi i64 [ %8, %7 ], [ %13, %9 ]
  ret i64 %15
}

; Function Attrs: noinline nounwind optnone uwtable
define internal float @safe_add_func_float_f_f(float %0, float %1) #0 {
  %3 = alloca float, align 4
  %4 = alloca float, align 4
  store float %0, float* %3, align 4
  store float %1, float* %4, align 4
  %5 = load float, float* %3, align 4
  %6 = fmul float 5.000000e-01, %5
  %7 = load float, float* %4, align 4
  %8 = fmul float 5.000000e-01, %7
  %9 = fadd float %6, %8
  %10 = call float @llvm.fabs.f32(float %9)
  %11 = fcmp ogt float %10, 0x47DFFFFFE0000000
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = load float, float* %3, align 4
  br label %18

14:                                               ; preds = %2
  %15 = load float, float* %3, align 4
  %16 = load float, float* %4, align 4
  %17 = fadd float %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi float [ %13, %12 ], [ %17, %14 ]
  ret float %19
}

; Function Attrs: nounwind readnone speculatable willreturn
declare float @llvm.fabs.f32(float) #2

; Function Attrs: noinline nounwind optnone uwtable
define internal float @safe_sub_func_float_f_f(float %0, float %1) #0 {
  %3 = alloca float, align 4
  %4 = alloca float, align 4
  store float %0, float* %3, align 4
  store float %1, float* %4, align 4
  %5 = load float, float* %3, align 4
  %6 = fmul float 5.000000e-01, %5
  %7 = load float, float* %4, align 4
  %8 = fmul float 5.000000e-01, %7
  %9 = fsub float %6, %8
  %10 = call float @llvm.fabs.f32(float %9)
  %11 = fcmp ogt float %10, 0x47DFFFFFE0000000
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = load float, float* %3, align 4
  br label %18

14:                                               ; preds = %2
  %15 = load float, float* %3, align 4
  %16 = load float, float* %4, align 4
  %17 = fsub float %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi float [ %13, %12 ], [ %17, %14 ]
  ret float %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal float @safe_mul_func_float_f_f(float %0, float %1) #0 {
  %3 = alloca float, align 4
  %4 = alloca float, align 4
  store float %0, float* %3, align 4
  store float %1, float* %4, align 4
  %5 = load float, float* %3, align 4
  %6 = fmul float 0x39B0000000000000, %5
  %7 = load float, float* %4, align 4
  %8 = fmul float 0x3E30000000000000, %7
  %9 = fmul float %6, %8
  %10 = call float @llvm.fabs.f32(float %9)
  %11 = fcmp ogt float %10, 0x3FEFFFFFE0000000
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = load float, float* %3, align 4
  br label %18

14:                                               ; preds = %2
  %15 = load float, float* %3, align 4
  %16 = load float, float* %4, align 4
  %17 = fmul float %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi float [ %13, %12 ], [ %17, %14 ]
  ret float %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal float @safe_div_func_float_f_f(float %0, float %1) #0 {
  %3 = alloca float, align 4
  %4 = alloca float, align 4
  store float %0, float* %3, align 4
  store float %1, float* %4, align 4
  %5 = load float, float* %4, align 4
  %6 = call float @llvm.fabs.f32(float %5)
  %7 = fcmp olt float %6, 1.000000e+00
  br i1 %7, label %8, label %21

8:                                                ; preds = %2
  %9 = load float, float* %4, align 4
  %10 = fcmp oeq float %9, 0.000000e+00
  br i1 %10, label %19, label %11

11:                                               ; preds = %8
  %12 = load float, float* %3, align 4
  %13 = fmul float 0x3CE0000000000000, %12
  %14 = load float, float* %4, align 4
  %15 = fmul float 0x4630000000000000, %14
  %16 = fdiv float %13, %15
  %17 = call float @llvm.fabs.f32(float %16)
  %18 = fcmp ogt float %17, 0x3E9FFFFFE0000000
  br i1 %18, label %19, label %21

19:                                               ; preds = %11, %8
  %20 = load float, float* %3, align 4
  br label %25

21:                                               ; preds = %11, %2
  %22 = load float, float* %3, align 4
  %23 = load float, float* %4, align 4
  %24 = fdiv float %22, %23
  br label %25

25:                                               ; preds = %21, %19
  %26 = phi float [ %20, %19 ], [ %24, %21 ]
  ret float %26
}

; Function Attrs: noinline nounwind optnone uwtable
define internal double @safe_add_func_double_f_f(double %0, double %1) #0 {
  %3 = alloca double, align 8
  %4 = alloca double, align 8
  store double %0, double* %3, align 8
  store double %1, double* %4, align 8
  %5 = load double, double* %3, align 8
  %6 = fmul double 5.000000e-01, %5
  %7 = load double, double* %4, align 8
  %8 = fmul double 5.000000e-01, %7
  %9 = fadd double %6, %8
  %10 = call double @llvm.fabs.f64(double %9)
  %11 = fcmp ogt double %10, 0x7FDFFFFFFFFFFFFF
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = load double, double* %3, align 8
  br label %18

14:                                               ; preds = %2
  %15 = load double, double* %3, align 8
  %16 = load double, double* %4, align 8
  %17 = fadd double %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi double [ %13, %12 ], [ %17, %14 ]
  ret double %19
}

; Function Attrs: nounwind readnone speculatable willreturn
declare double @llvm.fabs.f64(double) #2

; Function Attrs: noinline nounwind optnone uwtable
define internal double @safe_sub_func_double_f_f(double %0, double %1) #0 {
  %3 = alloca double, align 8
  %4 = alloca double, align 8
  store double %0, double* %3, align 8
  store double %1, double* %4, align 8
  %5 = load double, double* %3, align 8
  %6 = fmul double 5.000000e-01, %5
  %7 = load double, double* %4, align 8
  %8 = fmul double 5.000000e-01, %7
  %9 = fsub double %6, %8
  %10 = call double @llvm.fabs.f64(double %9)
  %11 = fcmp ogt double %10, 0x7FDFFFFFFFFFFFFF
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = load double, double* %3, align 8
  br label %18

14:                                               ; preds = %2
  %15 = load double, double* %3, align 8
  %16 = load double, double* %4, align 8
  %17 = fsub double %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi double [ %13, %12 ], [ %17, %14 ]
  ret double %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal double @safe_mul_func_double_f_f(double %0, double %1) #0 {
  %3 = alloca double, align 8
  %4 = alloca double, align 8
  store double %0, double* %3, align 8
  store double %1, double* %4, align 8
  %5 = load double, double* %3, align 8
  %6 = fmul double 0x39B0000000000000, %5
  %7 = load double, double* %4, align 8
  %8 = fmul double 0x630000000000000, %7
  %9 = fmul double %6, %8
  %10 = call double @llvm.fabs.f64(double %9)
  %11 = fcmp ogt double %10, 0x3FEFFFFFFFFFFFFF
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = load double, double* %3, align 8
  br label %18

14:                                               ; preds = %2
  %15 = load double, double* %3, align 8
  %16 = load double, double* %4, align 8
  %17 = fmul double %15, %16
  br label %18

18:                                               ; preds = %14, %12
  %19 = phi double [ %13, %12 ], [ %17, %14 ]
  ret double %19
}

; Function Attrs: noinline nounwind optnone uwtable
define internal double @safe_div_func_double_f_f(double %0, double %1) #0 {
  %3 = alloca double, align 8
  %4 = alloca double, align 8
  store double %0, double* %3, align 8
  store double %1, double* %4, align 8
  %5 = load double, double* %4, align 8
  %6 = call double @llvm.fabs.f64(double %5)
  %7 = fcmp olt double %6, 1.000000e+00
  br i1 %7, label %8, label %21

8:                                                ; preds = %2
  %9 = load double, double* %4, align 8
  %10 = fcmp oeq double %9, 0.000000e+00
  br i1 %10, label %19, label %11

11:                                               ; preds = %8
  %12 = load double, double* %3, align 8
  %13 = fmul double 0x310000000000000, %12
  %14 = load double, double* %4, align 8
  %15 = fmul double 0x4630000000000000, %14
  %16 = fdiv double %13, %15
  %17 = call double @llvm.fabs.f64(double %16)
  %18 = fcmp ogt double %17, 0x3CCFFFFFFFFFFFFF
  br i1 %18, label %19, label %21

19:                                               ; preds = %11, %8
  %20 = load double, double* %3, align 8
  br label %25

21:                                               ; preds = %11, %2
  %22 = load double, double* %3, align 8
  %23 = load double, double* %4, align 8
  %24 = fdiv double %22, %23
  br label %25

25:                                               ; preds = %21, %19
  %26 = phi double [ %20, %19 ], [ %24, %21 ]
  ret double %26
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32 @safe_convert_func_float_to_int32_t(float %0) #0 {
  %2 = alloca float, align 4
  store float %0, float* %2, align 4
  %3 = load float, float* %2, align 4
  %4 = fcmp ole float %3, 0xC1E0000000000000
  br i1 %4, label %8, label %5

5:                                                ; preds = %1
  %6 = load float, float* %2, align 4
  %7 = fcmp oge float %6, 0x41E0000000000000
  br i1 %7, label %8, label %9

8:                                                ; preds = %5, %1
  br label %12

9:                                                ; preds = %5
  %10 = load float, float* %2, align 4
  %11 = fptosi float %10 to i32
  br label %12

12:                                               ; preds = %9, %8
  %13 = phi i32 [ 2147483647, %8 ], [ %11, %9 ]
  ret i32 %13
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @crc32_gentab() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  store i32 -306674912, i32* %2, align 4
  store i32 0, i32* %3, align 4
  br label %5

5:                                                ; preds = %33, %0
  %6 = load i32, i32* %3, align 4
  %7 = icmp slt i32 %6, 256
  br i1 %7, label %8, label %36

8:                                                ; preds = %5
  %9 = load i32, i32* %3, align 4
  store i32 %9, i32* %1, align 4
  store i32 8, i32* %4, align 4
  br label %10

10:                                               ; preds = %25, %8
  %11 = load i32, i32* %4, align 4
  %12 = icmp sgt i32 %11, 0
  br i1 %12, label %13, label %28

13:                                               ; preds = %10
  %14 = load i32, i32* %1, align 4
  %15 = and i32 %14, 1
  %16 = icmp ne i32 %15, 0
  br i1 %16, label %17, label %21

17:                                               ; preds = %13
  %18 = load i32, i32* %1, align 4
  %19 = lshr i32 %18, 1
  %20 = xor i32 %19, -306674912
  store i32 %20, i32* %1, align 4
  br label %24

21:                                               ; preds = %13
  %22 = load i32, i32* %1, align 4
  %23 = lshr i32 %22, 1
  store i32 %23, i32* %1, align 4
  br label %24

24:                                               ; preds = %21, %17
  br label %25

25:                                               ; preds = %24
  %26 = load i32, i32* %4, align 4
  %27 = add nsw i32 %26, -1
  store i32 %27, i32* %4, align 4
  br label %10

28:                                               ; preds = %10
  %29 = load i32, i32* %1, align 4
  %30 = load i32, i32* %3, align 4
  %31 = sext i32 %30 to i64
  %32 = getelementptr inbounds [256 x i32], [256 x i32]* @crc32_tab, i64 0, i64 %31
  store i32 %29, i32* %32, align 4
  br label %33

33:                                               ; preds = %28
  %34 = load i32, i32* %3, align 4
  %35 = add nsw i32 %34, 1
  store i32 %35, i32* %3, align 4
  br label %5

36:                                               ; preds = %5
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @crc32_byte(i8 zeroext %0) #0 {
  %2 = alloca i8, align 1
  store i8 %0, i8* %2, align 1
  %3 = load i32, i32* @crc32_context, align 4
  %4 = lshr i32 %3, 8
  %5 = and i32 %4, 16777215
  %6 = load i32, i32* @crc32_context, align 4
  %7 = load i8, i8* %2, align 1
  %8 = zext i8 %7 to i32
  %9 = xor i32 %6, %8
  %10 = and i32 %9, 255
  %11 = zext i32 %10 to i64
  %12 = getelementptr inbounds [256 x i32], [256 x i32]* @crc32_tab, i64 0, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = xor i32 %5, %13
  store i32 %14, i32* @crc32_context, align 4
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @crc32_8bytes(i64 %0) #0 {
  %2 = alloca i64, align 8
  store i64 %0, i64* %2, align 8
  %3 = load i64, i64* %2, align 8
  %4 = lshr i64 %3, 0
  %5 = and i64 %4, 255
  %6 = trunc i64 %5 to i8
  call void @crc32_byte(i8 zeroext %6)
  %7 = load i64, i64* %2, align 8
  %8 = lshr i64 %7, 8
  %9 = and i64 %8, 255
  %10 = trunc i64 %9 to i8
  call void @crc32_byte(i8 zeroext %10)
  %11 = load i64, i64* %2, align 8
  %12 = lshr i64 %11, 16
  %13 = and i64 %12, 255
  %14 = trunc i64 %13 to i8
  call void @crc32_byte(i8 zeroext %14)
  %15 = load i64, i64* %2, align 8
  %16 = lshr i64 %15, 24
  %17 = and i64 %16, 255
  %18 = trunc i64 %17 to i8
  call void @crc32_byte(i8 zeroext %18)
  %19 = load i64, i64* %2, align 8
  %20 = lshr i64 %19, 32
  %21 = and i64 %20, 255
  %22 = trunc i64 %21 to i8
  call void @crc32_byte(i8 zeroext %22)
  %23 = load i64, i64* %2, align 8
  %24 = lshr i64 %23, 40
  %25 = and i64 %24, 255
  %26 = trunc i64 %25 to i8
  call void @crc32_byte(i8 zeroext %26)
  %27 = load i64, i64* %2, align 8
  %28 = lshr i64 %27, 48
  %29 = and i64 %28, 255
  %30 = trunc i64 %29 to i8
  call void @crc32_byte(i8 zeroext %30)
  %31 = load i64, i64* %2, align 8
  %32 = lshr i64 %31, 56
  %33 = and i64 %32, 255
  %34 = trunc i64 %33 to i8
  call void @crc32_byte(i8 zeroext %34)
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @transparent_crc(i64 %0, i8* %1, i32 %2) #0 {
  %4 = alloca i64, align 8
  %5 = alloca i8*, align 8
  %6 = alloca i32, align 4
  store i64 %0, i64* %4, align 8
  store i8* %1, i8** %5, align 8
  store i32 %2, i32* %6, align 4
  %7 = load i64, i64* %4, align 8
  call void @crc32_8bytes(i64 %7)
  %8 = load i32, i32* %6, align 4
  %9 = icmp ne i32 %8, 0
  br i1 %9, label %10, label %16

10:                                               ; preds = %3
  %11 = load i8*, i8** %5, align 8
  %12 = load i32, i32* @crc32_context, align 4
  %13 = zext i32 %12 to i64
  %14 = xor i64 %13, 4294967295
  %15 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.1, i64 0, i64 0), i8* %11, i64 %14)
  br label %16

16:                                               ; preds = %10, %3
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal void @transparent_crc_bytes(i8* %0, i32 %1, i8* %2, i32 %3) #0 {
  %5 = alloca i8*, align 8
  %6 = alloca i32, align 4
  %7 = alloca i8*, align 8
  %8 = alloca i32, align 4
  %9 = alloca i32, align 4
  store i8* %0, i8** %5, align 8
  store i32 %1, i32* %6, align 4
  store i8* %2, i8** %7, align 8
  store i32 %3, i32* %8, align 4
  store i32 0, i32* %9, align 4
  br label %10

10:                                               ; preds = %20, %4
  %11 = load i32, i32* %9, align 4
  %12 = load i32, i32* %6, align 4
  %13 = icmp slt i32 %11, %12
  br i1 %13, label %14, label %23

14:                                               ; preds = %10
  %15 = load i8*, i8** %5, align 8
  %16 = load i32, i32* %9, align 4
  %17 = sext i32 %16 to i64
  %18 = getelementptr inbounds i8, i8* %15, i64 %17
  %19 = load i8, i8* %18, align 1
  call void @crc32_byte(i8 zeroext %19)
  br label %20

20:                                               ; preds = %14
  %21 = load i32, i32* %9, align 4
  %22 = add nsw i32 %21, 1
  store i32 %22, i32* %9, align 4
  br label %10

23:                                               ; preds = %10
  %24 = load i32, i32* %8, align 4
  %25 = icmp ne i32 %24, 0
  br i1 %25, label %26, label %32

26:                                               ; preds = %23
  %27 = load i8*, i8** %7, align 8
  %28 = load i32, i32* @crc32_context, align 4
  %29 = zext i32 %28 to i64
  %30 = xor i64 %29, 4294967295
  %31 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.1, i64 0, i64 0), i8* %27, i64 %30)
  br label %32

32:                                               ; preds = %26, %23
  ret void
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i64 @func_1() #0 {
  %1 = alloca i64, align 8
  %2 = alloca %union.U0*, align 8
  %3 = alloca i32, align 4
  %4 = alloca i32*, align 8
  %5 = alloca %union.U0*, align 8
  %6 = alloca %union.U0**, align 8
  %7 = alloca [10 x [7 x %union.U0**]], align 16
  %8 = alloca %union.U0*, align 8
  %9 = alloca %union.U0**, align 8
  %10 = alloca i8*, align 8
  %11 = alloca i32, align 4
  %12 = alloca i8**, align 8
  %13 = alloca i8*, align 8
  %14 = alloca [4 x [5 x i32*****]], align 16
  %15 = alloca [9 x i64**], align 16
  %16 = alloca i64***, align 8
  %17 = alloca i16, align 2
  %18 = alloca [7 x i32*], align 16
  %19 = alloca [2 x [8 x i32]], align 16
  %20 = alloca i32, align 4
  %21 = alloca i32, align 4
  %22 = alloca %union.U0, align 8
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0** %2, align 8
  store i32 -1, i32* %3, align 4
  store i32* @g_45, i32** %4, align 8
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0** %5, align 8
  store %union.U0** %5, %union.U0*** %6, align 8
  %23 = getelementptr inbounds [10 x [7 x %union.U0**]], [10 x [7 x %union.U0**]]* %7, i64 0, i64 0
  %24 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %23, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %24, align 8
  %25 = getelementptr inbounds %union.U0**, %union.U0*** %24, i64 1
  store %union.U0** null, %union.U0*** %25, align 8
  %26 = getelementptr inbounds %union.U0**, %union.U0*** %25, i64 1
  store %union.U0** %2, %union.U0*** %26, align 8
  %27 = getelementptr inbounds %union.U0**, %union.U0*** %26, i64 1
  store %union.U0** %2, %union.U0*** %27, align 8
  %28 = getelementptr inbounds %union.U0**, %union.U0*** %27, i64 1
  store %union.U0** %2, %union.U0*** %28, align 8
  %29 = getelementptr inbounds %union.U0**, %union.U0*** %28, i64 1
  store %union.U0** null, %union.U0*** %29, align 8
  %30 = getelementptr inbounds %union.U0**, %union.U0*** %29, i64 1
  store %union.U0** %2, %union.U0*** %30, align 8
  %31 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %23, i64 1
  %32 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %31, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %32, align 8
  %33 = getelementptr inbounds %union.U0**, %union.U0*** %32, i64 1
  store %union.U0** %2, %union.U0*** %33, align 8
  %34 = getelementptr inbounds %union.U0**, %union.U0*** %33, i64 1
  store %union.U0** null, %union.U0*** %34, align 8
  %35 = getelementptr inbounds %union.U0**, %union.U0*** %34, i64 1
  store %union.U0** %2, %union.U0*** %35, align 8
  %36 = getelementptr inbounds %union.U0**, %union.U0*** %35, i64 1
  store %union.U0** %2, %union.U0*** %36, align 8
  %37 = getelementptr inbounds %union.U0**, %union.U0*** %36, i64 1
  store %union.U0** null, %union.U0*** %37, align 8
  %38 = getelementptr inbounds %union.U0**, %union.U0*** %37, i64 1
  store %union.U0** null, %union.U0*** %38, align 8
  %39 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %31, i64 1
  %40 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %39, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %40, align 8
  %41 = getelementptr inbounds %union.U0**, %union.U0*** %40, i64 1
  store %union.U0** %2, %union.U0*** %41, align 8
  %42 = getelementptr inbounds %union.U0**, %union.U0*** %41, i64 1
  store %union.U0** null, %union.U0*** %42, align 8
  %43 = getelementptr inbounds %union.U0**, %union.U0*** %42, i64 1
  store %union.U0** %2, %union.U0*** %43, align 8
  %44 = getelementptr inbounds %union.U0**, %union.U0*** %43, i64 1
  store %union.U0** %2, %union.U0*** %44, align 8
  %45 = getelementptr inbounds %union.U0**, %union.U0*** %44, i64 1
  store %union.U0** %2, %union.U0*** %45, align 8
  %46 = getelementptr inbounds %union.U0**, %union.U0*** %45, i64 1
  store %union.U0** %2, %union.U0*** %46, align 8
  %47 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %39, i64 1
  %48 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %47, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %48, align 8
  %49 = getelementptr inbounds %union.U0**, %union.U0*** %48, i64 1
  store %union.U0** %2, %union.U0*** %49, align 8
  %50 = getelementptr inbounds %union.U0**, %union.U0*** %49, i64 1
  store %union.U0** null, %union.U0*** %50, align 8
  %51 = getelementptr inbounds %union.U0**, %union.U0*** %50, i64 1
  store %union.U0** %2, %union.U0*** %51, align 8
  %52 = getelementptr inbounds %union.U0**, %union.U0*** %51, i64 1
  store %union.U0** %2, %union.U0*** %52, align 8
  %53 = getelementptr inbounds %union.U0**, %union.U0*** %52, i64 1
  store %union.U0** %2, %union.U0*** %53, align 8
  %54 = getelementptr inbounds %union.U0**, %union.U0*** %53, i64 1
  store %union.U0** %2, %union.U0*** %54, align 8
  %55 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %47, i64 1
  %56 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %55, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %56, align 8
  %57 = getelementptr inbounds %union.U0**, %union.U0*** %56, i64 1
  store %union.U0** %2, %union.U0*** %57, align 8
  %58 = getelementptr inbounds %union.U0**, %union.U0*** %57, i64 1
  store %union.U0** %2, %union.U0*** %58, align 8
  %59 = getelementptr inbounds %union.U0**, %union.U0*** %58, i64 1
  store %union.U0** null, %union.U0*** %59, align 8
  %60 = getelementptr inbounds %union.U0**, %union.U0*** %59, i64 1
  store %union.U0** %2, %union.U0*** %60, align 8
  %61 = getelementptr inbounds %union.U0**, %union.U0*** %60, i64 1
  store %union.U0** null, %union.U0*** %61, align 8
  %62 = getelementptr inbounds %union.U0**, %union.U0*** %61, i64 1
  store %union.U0** %2, %union.U0*** %62, align 8
  %63 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %55, i64 1
  %64 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %63, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %64, align 8
  %65 = getelementptr inbounds %union.U0**, %union.U0*** %64, i64 1
  store %union.U0** %2, %union.U0*** %65, align 8
  %66 = getelementptr inbounds %union.U0**, %union.U0*** %65, i64 1
  store %union.U0** null, %union.U0*** %66, align 8
  %67 = getelementptr inbounds %union.U0**, %union.U0*** %66, i64 1
  store %union.U0** %2, %union.U0*** %67, align 8
  %68 = getelementptr inbounds %union.U0**, %union.U0*** %67, i64 1
  store %union.U0** %2, %union.U0*** %68, align 8
  %69 = getelementptr inbounds %union.U0**, %union.U0*** %68, i64 1
  store %union.U0** null, %union.U0*** %69, align 8
  %70 = getelementptr inbounds %union.U0**, %union.U0*** %69, i64 1
  store %union.U0** %2, %union.U0*** %70, align 8
  %71 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %63, i64 1
  %72 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %71, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %72, align 8
  %73 = getelementptr inbounds %union.U0**, %union.U0*** %72, i64 1
  store %union.U0** null, %union.U0*** %73, align 8
  %74 = getelementptr inbounds %union.U0**, %union.U0*** %73, i64 1
  store %union.U0** %2, %union.U0*** %74, align 8
  %75 = getelementptr inbounds %union.U0**, %union.U0*** %74, i64 1
  store %union.U0** %2, %union.U0*** %75, align 8
  %76 = getelementptr inbounds %union.U0**, %union.U0*** %75, i64 1
  store %union.U0** %2, %union.U0*** %76, align 8
  %77 = getelementptr inbounds %union.U0**, %union.U0*** %76, i64 1
  store %union.U0** null, %union.U0*** %77, align 8
  %78 = getelementptr inbounds %union.U0**, %union.U0*** %77, i64 1
  store %union.U0** %2, %union.U0*** %78, align 8
  %79 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %71, i64 1
  %80 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %79, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %80, align 8
  %81 = getelementptr inbounds %union.U0**, %union.U0*** %80, i64 1
  store %union.U0** %2, %union.U0*** %81, align 8
  %82 = getelementptr inbounds %union.U0**, %union.U0*** %81, i64 1
  store %union.U0** null, %union.U0*** %82, align 8
  %83 = getelementptr inbounds %union.U0**, %union.U0*** %82, i64 1
  store %union.U0** null, %union.U0*** %83, align 8
  %84 = getelementptr inbounds %union.U0**, %union.U0*** %83, i64 1
  store %union.U0** %2, %union.U0*** %84, align 8
  %85 = getelementptr inbounds %union.U0**, %union.U0*** %84, i64 1
  store %union.U0** %2, %union.U0*** %85, align 8
  %86 = getelementptr inbounds %union.U0**, %union.U0*** %85, i64 1
  store %union.U0** null, %union.U0*** %86, align 8
  %87 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %79, i64 1
  %88 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %87, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %88, align 8
  %89 = getelementptr inbounds %union.U0**, %union.U0*** %88, i64 1
  store %union.U0** %2, %union.U0*** %89, align 8
  %90 = getelementptr inbounds %union.U0**, %union.U0*** %89, i64 1
  store %union.U0** null, %union.U0*** %90, align 8
  %91 = getelementptr inbounds %union.U0**, %union.U0*** %90, i64 1
  store %union.U0** %2, %union.U0*** %91, align 8
  %92 = getelementptr inbounds %union.U0**, %union.U0*** %91, i64 1
  store %union.U0** %2, %union.U0*** %92, align 8
  %93 = getelementptr inbounds %union.U0**, %union.U0*** %92, i64 1
  store %union.U0** %2, %union.U0*** %93, align 8
  %94 = getelementptr inbounds %union.U0**, %union.U0*** %93, i64 1
  store %union.U0** %2, %union.U0*** %94, align 8
  %95 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %87, i64 1
  %96 = getelementptr inbounds [7 x %union.U0**], [7 x %union.U0**]* %95, i64 0, i64 0
  store %union.U0** %2, %union.U0*** %96, align 8
  %97 = getelementptr inbounds %union.U0**, %union.U0*** %96, i64 1
  store %union.U0** null, %union.U0*** %97, align 8
  %98 = getelementptr inbounds %union.U0**, %union.U0*** %97, i64 1
  store %union.U0** null, %union.U0*** %98, align 8
  %99 = getelementptr inbounds %union.U0**, %union.U0*** %98, i64 1
  store %union.U0** %2, %union.U0*** %99, align 8
  %100 = getelementptr inbounds %union.U0**, %union.U0*** %99, i64 1
  store %union.U0** %2, %union.U0*** %100, align 8
  %101 = getelementptr inbounds %union.U0**, %union.U0*** %100, i64 1
  store %union.U0** null, %union.U0*** %101, align 8
  %102 = getelementptr inbounds %union.U0**, %union.U0*** %101, i64 1
  store %union.U0** %2, %union.U0*** %102, align 8
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0** %8, align 8
  store %union.U0** %8, %union.U0*** %9, align 8
  store i8* @g_82, i8** %10, align 8
  store i32 1, i32* %11, align 4
  store i8** %10, i8*** %12, align 8
  store i8* null, i8** %13, align 8
  %103 = bitcast [4 x [5 x i32*****]]* %14 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %103, i8* align 16 bitcast ([4 x [5 x i32*****]]* @__const.func_1.l_3809 to i8*), i64 160, i1 false)
  %104 = bitcast [9 x i64**]* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %104, i8 0, i64 72, i1 false)
  store i64*** @g_2096, i64**** %16, align 8
  store i16 -8, i16* %17, align 2
  %105 = getelementptr inbounds [7 x i32*], [7 x i32*]* %18, i64 0, i64 0
  store i32* %11, i32** %105, align 8
  %106 = getelementptr inbounds i32*, i32** %105, i64 1
  store i32* %11, i32** %106, align 8
  %107 = getelementptr inbounds i32*, i32** %106, i64 1
  store i32* %11, i32** %107, align 8
  %108 = getelementptr inbounds i32*, i32** %107, i64 1
  store i32* %11, i32** %108, align 8
  %109 = getelementptr inbounds i32*, i32** %108, i64 1
  store i32* %11, i32** %109, align 8
  %110 = getelementptr inbounds i32*, i32** %109, i64 1
  store i32* %11, i32** %110, align 8
  %111 = getelementptr inbounds i32*, i32** %110, i64 1
  store i32* %11, i32** %111, align 8
  store i32 0, i32* %20, align 4
  br label %112

112:                                              ; preds = %130, %0
  %113 = load i32, i32* %20, align 4
  %114 = icmp slt i32 %113, 2
  br i1 %114, label %115, label %133

115:                                              ; preds = %112
  store i32 0, i32* %21, align 4
  br label %116

116:                                              ; preds = %126, %115
  %117 = load i32, i32* %21, align 4
  %118 = icmp slt i32 %117, 8
  br i1 %118, label %119, label %129

119:                                              ; preds = %116
  %120 = load i32, i32* %20, align 4
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds [2 x [8 x i32]], [2 x [8 x i32]]* %19, i64 0, i64 %121
  %123 = load i32, i32* %21, align 4
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds [8 x i32], [8 x i32]* %122, i64 0, i64 %124
  store i32 -1895137554, i32* %125, align 4
  br label %126

126:                                              ; preds = %119
  %127 = load i32, i32* %21, align 4
  %128 = add nsw i32 %127, 1
  store i32 %128, i32* %21, align 4
  br label %116

129:                                              ; preds = %116
  br label %130

130:                                              ; preds = %129
  %131 = load i32, i32* %20, align 4
  %132 = add nsw i32 %131, 1
  store i32 %132, i32* %20, align 4
  br label %112

133:                                              ; preds = %112
  %134 = load i32, i32* @g_12, align 4
  %135 = sext i32 %134 to i64
  %136 = load i32, i32* @g_12, align 4
  %137 = sext i32 %136 to i64
  %138 = load i32, i32* @g_12, align 4
  %139 = trunc i32 %138 to i8
  %140 = call signext i8 @safe_unary_minus_func_int8_t_s(i8 signext %139)
  %141 = sext i8 %140 to i32
  %142 = load %union.U0*, %union.U0** %2, align 8
  %143 = load i32*, i32** %4, align 8
  %144 = load i32, i32* %143, align 4
  %145 = sext i32 %144 to i64
  %146 = or i64 %145, 3984341884
  %147 = trunc i64 %146 to i32
  store i32 %147, i32* %143, align 4
  %148 = load %union.U0*, %union.U0** %2, align 8
  %149 = load %union.U0**, %union.U0*** %6, align 8
  store %union.U0* %148, %union.U0** %149, align 8
  %150 = load %union.U0**, %union.U0*** %9, align 8
  store %union.U0* %148, %union.U0** %150, align 8
  %151 = call i32* @func_52(%union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0* %148)
  %152 = load i32*, i32** %4, align 8
  %153 = load i32, i32* %152, align 4
  %154 = call %union.U0* @func_48(i32* %151, i32 %153, i8* @g_82)
  %155 = load %union.U0**, %union.U0*** %9, align 8
  store %union.U0* %154, %union.U0** %155, align 8
  %156 = call i8* @func_46(%union.U0* %154)
  %157 = load i8*, i8** %10, align 8
  %158 = call signext i16 @func_41(i8* %156, i8* %157)
  %159 = load i32, i32* %11, align 4
  %160 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %158, i32 %159)
  %161 = trunc i16 %160 to i8
  %162 = call signext i8 @safe_lshift_func_int8_t_s_s(i8 signext %161, i32 6)
  %163 = sext i8 %162 to i32
  %164 = and i32 -1, %163
  %165 = call i32 @safe_mod_func_int32_t_s_s(i32 %164, i32 -1)
  %166 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %167 = load %union.U0*, %union.U0** %166, align 8
  %168 = load i32, i32* %11, align 4
  %169 = trunc i32 %168 to i8
  %170 = load i8*, i8** %10, align 8
  %171 = load %union.U0*, %union.U0** @g_136, align 8
  %172 = call %union.U0* @func_28(%union.U0* %167, i8 signext %169, i8* @g_116, i8* %170, %union.U0* %171)
  %173 = load %union.U0**, %union.U0*** %9, align 8
  store %union.U0* %172, %union.U0** %173, align 8
  %174 = icmp eq %union.U0* %142, %172
  %175 = zext i1 %174 to i32
  %176 = load i32*, i32** %4, align 8
  store i32 %175, i32* %176, align 4
  %177 = call i32 @safe_add_func_int32_t_s_s(i32 %175, i32 -6)
  %178 = sext i32 %177 to i64
  %179 = icmp ne i64 %178, 40991
  %180 = zext i1 %179 to i32
  %181 = trunc i32 %180 to i16
  %182 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %181, i16 zeroext -10)
  %183 = zext i16 %182 to i64
  %184 = xor i64 1, %183
  %185 = load volatile i64***, i64**** @g_2498, align 8
  %186 = load i64**, i64*** %185, align 8
  %187 = load i64*, i64** %186, align 8
  %188 = load volatile i64, i64* %187, align 8
  %189 = load %union.U0*, %union.U0** @g_136, align 8
  %190 = load i32, i32* getelementptr inbounds ([9 x [9 x [3 x i32]]], [9 x [9 x [3 x i32]]]* @g_1269, i64 0, i64 2, i64 6, i64 2), align 8
  %191 = trunc i32 %190 to i16
  %192 = call i8* @func_17(i64 %188, %union.U0* %189, i16 zeroext -1, i16 signext %191)
  %193 = getelementptr inbounds %union.U0, %union.U0* %22, i32 0, i32 0
  store i8* %192, i8** %193, align 8
  %194 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %195 = load %union.U0*, %union.U0** %194, align 8
  %196 = load %union.U0*, %union.U0** @g_2895, align 8
  %197 = icmp eq %union.U0* %195, %196
  %198 = zext i1 %197 to i32
  %199 = trunc i32 %198 to i16
  %200 = call i8* @func_13(i32 %141, i16 zeroext %199)
  %201 = load i8**, i8*** %12, align 8
  store i8* %200, i8** %201, align 8
  %202 = load i8*, i8** %13, align 8
  %203 = call i8* @func_6(i64 %135, i64 %137, i8* %200, i16 zeroext -1, i8* %202)
  %204 = load i16, i16* @g_637, align 2
  %205 = load i32, i32* %11, align 4
  %206 = call %union.U0* @func_2(i8* %203, i16 signext %204, i32 %205)
  %207 = load %union.U0**, %union.U0*** %6, align 8
  store %union.U0* %206, %union.U0** %207, align 8
  store i32 3, i32* @g_2742, align 4
  br label %208

208:                                              ; preds = %227, %133
  %209 = load i32, i32* @g_2742, align 4
  %210 = icmp sge i32 %209, 0
  br i1 %210, label %211, label %230

211:                                              ; preds = %208
  store i32 0, i32* @g_95, align 4
  br label %212

212:                                              ; preds = %219, %211
  %213 = load i32, i32* @g_95, align 4
  %214 = icmp ule i32 %213, 3
  br i1 %214, label %215, label %222

215:                                              ; preds = %212
  %216 = load i32*, i32** %4, align 8
  %217 = load i32, i32* %216, align 4
  %218 = sext i32 %217 to i64
  store i64 %218, i64* %1, align 8
  br label %295

219:                                              ; No predecessors!
  %220 = load i32, i32* @g_95, align 4
  %221 = add i32 %220, 1
  store i32 %221, i32* @g_95, align 4
  br label %212

222:                                              ; preds = %212
  %223 = load volatile i64***, i64**** @g_2498, align 8
  %224 = load i64**, i64*** %223, align 8
  %225 = load i64*, i64** %224, align 8
  %226 = load volatile i64, i64* %225, align 8
  store i64 %226, i64* %1, align 8
  br label %295

227:                                              ; No predecessors!
  %228 = load i32, i32* @g_2742, align 4
  %229 = sub nsw i32 %228, 1
  store i32 %229, i32* @g_2742, align 4
  br label %208

230:                                              ; preds = %208
  %231 = load i16, i16* @g_1205, align 2
  %232 = icmp ne i16 %231, 0
  br i1 %232, label %233, label %234

233:                                              ; preds = %230
  br label %235

234:                                              ; preds = %230
  br label %235

235:                                              ; preds = %234, %233
  store i32***** getelementptr inbounds ([5 x [1 x [1 x i32****]]], [5 x [1 x [1 x i32****]]]* @g_2729, i64 0, i64 2, i64 0, i64 0), i32****** getelementptr inbounds ([9 x [5 x i32*****]], [9 x [5 x i32*****]]* @g_3287, i64 0, i64 8, i64 3), align 8
  %236 = getelementptr inbounds [4 x [5 x i32*****]], [4 x [5 x i32*****]]* %14, i64 0, i64 1
  %237 = getelementptr inbounds [5 x i32*****], [5 x i32*****]* %236, i64 0, i64 4
  %238 = load i32*****, i32****** %237, align 8
  store i32***** %238, i32****** @g_3810, align 8
  %239 = icmp ne i32***** getelementptr inbounds ([5 x [1 x [1 x i32****]]], [5 x [1 x [1 x i32****]]]* @g_2729, i64 0, i64 2, i64 0, i64 0), %238
  %240 = zext i1 %239 to i32
  %241 = load i64****, i64***** @g_1636, align 8
  %242 = load i64***, i64**** %241, align 8
  %243 = load i64**, i64*** %242, align 8
  %244 = load volatile i64*, i64** %243, align 8
  %245 = load volatile i64, i64* %244, align 8
  %246 = call i64 @safe_div_func_uint64_t_u_u(i64 %245, i64 4)
  %247 = getelementptr inbounds [9 x i64**], [9 x i64**]* %15, i64 0, i64 4
  %248 = load i64**, i64*** %247, align 16
  %249 = load i64***, i64**** %16, align 8
  store i64** %248, i64*** %249, align 8
  %250 = load i64***, i64**** @g_1637, align 8
  %251 = load i64**, i64*** %250, align 8
  %252 = icmp eq i64** %248, %251
  %253 = zext i1 %252 to i32
  %254 = load i8*, i8** @g_1167, align 8
  %255 = load i8, i8* %254, align 1
  %256 = load i32*, i32** %4, align 8
  %257 = load i32, i32* %256, align 4
  %258 = load i32*, i32** %4, align 8
  store i32 %257, i32* %258, align 4
  %259 = trunc i32 %257 to i16
  store i16 %259, i16* %17, align 2
  %260 = sext i16 %259 to i32
  %261 = icmp sle i32 %253, %260
  %262 = zext i1 %261 to i32
  %263 = sext i32 %262 to i64
  %264 = icmp ule i64 %246, %263
  %265 = zext i1 %264 to i32
  %266 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext 0, i32 -1)
  %267 = sext i16 %266 to i32
  %268 = load i32, i32* %11, align 4
  %269 = icmp slt i32 %267, %268
  %270 = xor i1 %269, true
  %271 = zext i1 %270 to i32
  %272 = call i32 @safe_add_func_uint32_t_u_u(i32 %265, i32 %271)
  %273 = call i32 @safe_mod_func_int32_t_s_s(i32 %240, i32 %272)
  %274 = trunc i32 %273 to i16
  %275 = call zeroext i16 @safe_div_func_uint16_t_u_u(i16 zeroext %274, i16 zeroext -7706)
  %276 = zext i16 %275 to i32
  %277 = icmp ne i32 %276, 0
  br i1 %277, label %284, label %278

278:                                              ; preds = %235
  %279 = load volatile i64***, i64**** @g_2498, align 8
  %280 = load i64**, i64*** %279, align 8
  %281 = load i64*, i64** %280, align 8
  %282 = load volatile i64, i64* %281, align 8
  %283 = icmp ne i64 %282, 0
  br label %284

284:                                              ; preds = %278, %235
  %285 = phi i1 [ true, %235 ], [ %283, %278 ]
  %286 = zext i1 %285 to i32
  %287 = load i32*, i32** %4, align 8
  %288 = load i32, i32* %287, align 4
  %289 = getelementptr inbounds [2 x [8 x i32]], [2 x [8 x i32]]* %19, i64 0, i64 1
  %290 = getelementptr inbounds [8 x i32], [8 x i32]* %289, i64 0, i64 4
  store i32 %288, i32* %290, align 16
  %291 = load i32**, i32*** @g_421, align 8
  store i32* null, i32** %291, align 8
  %292 = load i64**, i64*** @g_2495, align 8
  %293 = load i64*, i64** %292, align 8
  %294 = load volatile i64, i64* %293, align 8
  store i64 %294, i64* %1, align 8
  br label %295

295:                                              ; preds = %284, %222, %215
  %296 = load i64, i64* %1, align 8
  ret i64 %296
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* noalias nocapture writeonly, i8* noalias nocapture readonly, i64, i1 immarg) #3

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #3

; Function Attrs: noinline nounwind optnone uwtable
define internal %union.U0* @func_2(i8* %0, i16 signext %1, i32 %2) #0 {
  %4 = alloca i8*, align 8
  %5 = alloca i16, align 2
  %6 = alloca i32, align 4
  %7 = alloca i16, align 2
  %8 = alloca i8****, align 8
  %9 = alloca i8*****, align 8
  %10 = alloca i8***, align 8
  %11 = alloca i8****, align 8
  %12 = alloca [3 x i16], align 2
  %13 = alloca i64*, align 8
  %14 = alloca i32, align 4
  %15 = alloca i64**, align 8
  %16 = alloca [8 x %union.U0*], align 16
  %17 = alloca [1 x i32], align 4
  %18 = alloca i8, align 1
  %19 = alloca i32, align 4
  %20 = alloca i32***, align 8
  %21 = alloca i64, align 8
  %22 = alloca [6 x [7 x [1 x i32]]], align 16
  %23 = alloca i64*, align 8
  %24 = alloca %union.U0*, align 8
  %25 = alloca i32, align 4
  %26 = alloca i32, align 4
  %27 = alloca i32, align 4
  %28 = alloca i16, align 2
  %29 = alloca [9 x i32], align 16
  %30 = alloca %union.U0*, align 8
  %31 = alloca %union.U0**, align 8
  %32 = alloca [4 x %union.U0***], align 16
  %33 = alloca %union.U0*, align 8
  %34 = alloca i32*, align 8
  %35 = alloca i32*, align 8
  %36 = alloca i8*, align 8
  %37 = alloca i32***, align 8
  %38 = alloca i32*, align 8
  %39 = alloca i32**, align 8
  %40 = alloca [8 x [1 x i16]], align 16
  %41 = alloca i64, align 8
  %42 = alloca i16, align 2
  %43 = alloca i32, align 4
  %44 = alloca i32, align 4
  %45 = alloca i64***, align 8
  %46 = alloca i32, align 4
  %47 = alloca i32, align 4
  %48 = alloca i32***, align 8
  %49 = alloca i32*, align 8
  %50 = alloca i32, align 4
  %51 = alloca i32, align 4
  %52 = alloca i32, align 4
  %53 = alloca i8***, align 8
  %54 = alloca i32, align 4
  %55 = alloca [9 x i32], align 16
  %56 = alloca i32, align 4
  %57 = alloca [10 x [3 x [4 x i16]]], align 16
  %58 = alloca i64*, align 8
  %59 = alloca [9 x [6 x i32*]], align 16
  %60 = alloca i32**, align 8
  %61 = alloca [8 x i64], align 16
  %62 = alloca i32, align 4
  %63 = alloca i32, align 4
  %64 = alloca i32, align 4
  store i8* %0, i8** %4, align 8
  store i16 %1, i16* %5, align 2
  store i32 %2, i32* %6, align 4
  store i16 -30037, i16* %7, align 2
  store i8**** null, i8***** %8, align 8
  store i8***** %8, i8****** %9, align 8
  store i8*** @g_340, i8**** %10, align 8
  store i8**** %10, i8***** %11, align 8
  store i64* @g_617, i64** %13, align 8
  store i32 -6, i32* %14, align 4
  store i64** @g_2097, i64*** %15, align 8
  %65 = bitcast [8 x %union.U0*]* %16 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %65, i8* align 16 bitcast ([8 x %union.U0*]* @__const.func_2.l_3360 to i8*), i64 64, i1 false)
  store i8 -5, i8* %18, align 1
  store i32 0, i32* %19, align 4
  store i32*** getelementptr inbounds ([6 x [10 x i32**]], [6 x [10 x i32**]]* @g_2780, i64 0, i64 4, i64 5), i32**** %20, align 8
  store i64 847889664721860190, i64* %21, align 8
  %66 = bitcast [6 x [7 x [1 x i32]]]* %22 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %66, i8* align 16 bitcast ([6 x [7 x [1 x i32]]]* @__const.func_2.l_3597 to i8*), i64 168, i1 false)
  store i64* @g_617, i64** %23, align 8
  store %union.U0* getelementptr inbounds ([5 x %union.U0], [5 x %union.U0]* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to [5 x %union.U0]*), i64 0, i64 0), %union.U0** %24, align 8
  store i32 0, i32* %25, align 4
  br label %67

67:                                               ; preds = %74, %3
  %68 = load i32, i32* %25, align 4
  %69 = icmp slt i32 %68, 3
  br i1 %69, label %70, label %77

70:                                               ; preds = %67
  %71 = load i32, i32* %25, align 4
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds [3 x i16], [3 x i16]* %12, i64 0, i64 %72
  store i16 -1, i16* %73, align 2
  br label %74

74:                                               ; preds = %70
  %75 = load i32, i32* %25, align 4
  %76 = add nsw i32 %75, 1
  store i32 %76, i32* %25, align 4
  br label %67

77:                                               ; preds = %67
  store i32 0, i32* %25, align 4
  br label %78

78:                                               ; preds = %85, %77
  %79 = load i32, i32* %25, align 4
  %80 = icmp slt i32 %79, 1
  br i1 %80, label %81, label %88

81:                                               ; preds = %78
  %82 = load i32, i32* %25, align 4
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds [1 x i32], [1 x i32]* %17, i64 0, i64 %83
  store i32 -1, i32* %84, align 4
  br label %85

85:                                               ; preds = %81
  %86 = load i32, i32* %25, align 4
  %87 = add nsw i32 %86, 1
  store i32 %87, i32* %25, align 4
  br label %78

88:                                               ; preds = %78
  %89 = load i32, i32* %6, align 4
  %90 = icmp ne i32 %89, 0
  br i1 %90, label %91, label %98

91:                                               ; preds = %88
  %92 = load i16, i16* %7, align 2
  %93 = sext i16 %92 to i32
  %94 = load i32, i32* %6, align 4
  %95 = zext i32 %94 to i64
  %96 = call i64 @safe_div_func_uint64_t_u_u(i64 -7994501485159708466, i64 %95)
  %97 = icmp ne i64 %96, 0
  br label %98

98:                                               ; preds = %91, %88
  %99 = phi i1 [ false, %88 ], [ %97, %91 ]
  %100 = zext i1 %99 to i32
  %101 = trunc i32 %100 to i8
  %102 = call signext i8 @safe_lshift_func_int8_t_s_s(i8 signext %101, i32 5)
  %103 = sext i8 %102 to i32
  %104 = load %union.U0*, %union.U0** @g_1921, align 8
  %105 = load i32, i32* %6, align 4
  %106 = trunc i32 %105 to i8
  %107 = load i8****, i8***** %8, align 8
  %108 = load i8*****, i8****** %9, align 8
  store i8**** %107, i8***** %108, align 8
  store i8**** %107, i8***** %11, align 8
  %109 = icmp eq i8**** @g_1484, %107
  %110 = zext i1 %109 to i32
  %111 = load i64**, i64*** @g_2096, align 8
  %112 = load i64*, i64** %111, align 8
  %113 = load i64, i64* %112, align 8
  %114 = add i64 %113, 1
  store i64 %114, i64* %112, align 8
  %115 = trunc i64 %114 to i16
  %116 = getelementptr inbounds [3 x i16], [3 x i16]* %12, i64 0, i64 1
  store i16 %115, i16* %116, align 2
  %117 = sext i16 %115 to i32
  %118 = icmp ne i32 %117, 0
  br i1 %118, label %119, label %128

119:                                              ; preds = %98
  %120 = getelementptr inbounds [3 x i16], [3 x i16]* %12, i64 0, i64 1
  %121 = load i16, i16* %120, align 2
  %122 = call signext i8 @safe_rshift_func_int8_t_s_s(i8 signext 0, i32 1)
  %123 = sext i8 %122 to i64
  %124 = load i64*, i64** %13, align 8
  %125 = load i64, i64* %124, align 8
  %126 = and i64 %125, %123
  store i64 %126, i64* %124, align 8
  %127 = icmp ne i64 %126, 0
  br label %128

128:                                              ; preds = %119, %98
  %129 = phi i1 [ false, %98 ], [ %127, %119 ]
  %130 = zext i1 %129 to i32
  %131 = load i32, i32* %6, align 4
  %132 = or i32 %130, %131
  %133 = call i32 @safe_div_func_int32_t_s_s(i32 %110, i32 %132)
  %134 = sext i32 %133 to i64
  %135 = load i64**, i64*** @g_2495, align 8
  %136 = load i64*, i64** %135, align 8
  %137 = load volatile i64, i64* %136, align 8
  %138 = icmp eq i64 %134, %137
  %139 = zext i1 %138 to i32
  %140 = trunc i32 %139 to i8
  %141 = load i16, i16* %7, align 2
  %142 = trunc i16 %141 to i8
  %143 = call zeroext i8 @safe_div_func_uint8_t_u_u(i8 zeroext %140, i8 zeroext %142)
  %144 = zext i8 %143 to i32
  %145 = call zeroext i8 @safe_rshift_func_uint8_t_u_u(i8 zeroext %106, i32 %144)
  %146 = load i8*, i8** %4, align 8
  %147 = load i8, i8* %146, align 1
  %148 = call signext i8 @safe_sub_func_int8_t_s_s(i8 signext %145, i8 signext %147)
  %149 = sext i8 %148 to i64
  %150 = load i64, i64* @g_2113, align 8
  %151 = or i64 %149, %150
  %152 = icmp ne i64 %151, 0
  %153 = xor i1 %152, true
  %154 = zext i1 %153 to i32
  %155 = and i32 %103, %154
  %156 = load i32, i32* %14, align 4
  %157 = and i32 %156, %155
  store i32 %157, i32* %14, align 4
  store i32 3, i32* @g_2470, align 4
  br label %158

158:                                              ; preds = %304, %128
  %159 = load i32, i32* @g_2470, align 4
  %160 = icmp sge i32 %159, 0
  br i1 %160, label %161, label %307

161:                                              ; preds = %158
  store i16 25688, i16* %28, align 2
  %162 = bitcast [9 x i32]* %29 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %162, i8* align 16 bitcast ([9 x i32]* @__const.func_2.l_3341 to i8*), i64 36, i1 false)
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_2226 to %union.U0*), %union.U0** %30, align 8
  store %union.U0** @g_1921, %union.U0*** %31, align 8
  store %union.U0* null, %union.U0** %33, align 8
  store i32* null, i32** %34, align 8
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 0), i32** %35, align 8
  store i8* @g_116, i8** %36, align 8
  store i32*** @g_421, i32**** %37, align 8
  store i32* %19, i32** %38, align 8
  store i32** %38, i32*** %39, align 8
  store i64 2, i64* %41, align 8
  store i16 15073, i16* %42, align 2
  store i32 0, i32* %43, align 4
  br label %163

163:                                              ; preds = %170, %161
  %164 = load i32, i32* %43, align 4
  %165 = icmp slt i32 %164, 4
  br i1 %165, label %166, label %173

166:                                              ; preds = %163
  %167 = load i32, i32* %43, align 4
  %168 = sext i32 %167 to i64
  %169 = getelementptr inbounds [4 x %union.U0***], [4 x %union.U0***]* %32, i64 0, i64 %168
  store %union.U0*** %31, %union.U0**** %169, align 8
  br label %170

170:                                              ; preds = %166
  %171 = load i32, i32* %43, align 4
  %172 = add nsw i32 %171, 1
  store i32 %172, i32* %43, align 4
  br label %163

173:                                              ; preds = %163
  store i32 0, i32* %43, align 4
  br label %174

174:                                              ; preds = %192, %173
  %175 = load i32, i32* %43, align 4
  %176 = icmp slt i32 %175, 8
  br i1 %176, label %177, label %195

177:                                              ; preds = %174
  store i32 0, i32* %44, align 4
  br label %178

178:                                              ; preds = %188, %177
  %179 = load i32, i32* %44, align 4
  %180 = icmp slt i32 %179, 1
  br i1 %180, label %181, label %191

181:                                              ; preds = %178
  %182 = load i32, i32* %43, align 4
  %183 = sext i32 %182 to i64
  %184 = getelementptr inbounds [8 x [1 x i16]], [8 x [1 x i16]]* %40, i64 0, i64 %183
  %185 = load i32, i32* %44, align 4
  %186 = sext i32 %185 to i64
  %187 = getelementptr inbounds [1 x i16], [1 x i16]* %184, i64 0, i64 %186
  store i16 7, i16* %187, align 2
  br label %188

188:                                              ; preds = %181
  %189 = load i32, i32* %44, align 4
  %190 = add nsw i32 %189, 1
  store i32 %190, i32* %44, align 4
  br label %178

191:                                              ; preds = %178
  br label %192

192:                                              ; preds = %191
  %193 = load i32, i32* %43, align 4
  %194 = add nsw i32 %193, 1
  store i32 %194, i32* %43, align 4
  br label %174

195:                                              ; preds = %174
  %196 = load i16, i16* %28, align 2
  %197 = add i16 %196, 1
  store i16 %197, i16* %28, align 2
  store i8 0, i8* @g_3033, align 1
  br label %198

198:                                              ; preds = %298, %195
  %199 = load i8, i8* @g_3033, align 1
  %200 = zext i8 %199 to i32
  %201 = icmp sle i32 %200, 2
  br i1 %201, label %202, label %303

202:                                              ; preds = %198
  store i64*** @g_2096, i64**** %45, align 8
  store i32 1319373004, i32* %46, align 4
  store i32 1, i32* %47, align 4
  store i32*** null, i32**** %48, align 8
  %203 = getelementptr inbounds [9 x i32], [9 x i32]* %29, i64 0, i64 2
  store i32* %203, i32** %49, align 8
  store i32 1888877766, i32* %50, align 4
  store i32 -1, i32* %51, align 4
  store i32 3, i32* %52, align 4
  store i8*** @g_340, i8**** %53, align 8
  store i32 1, i32* %54, align 4
  store i32 1299978651, i32* %56, align 4
  store i64* %21, i64** %58, align 8
  %204 = getelementptr inbounds [9 x [6 x i32*]], [9 x [6 x i32*]]* %59, i64 0, i64 0
  %205 = getelementptr inbounds [6 x i32*], [6 x i32*]* %204, i64 0, i64 0
  store i32* @g_95, i32** %205, align 8
  %206 = getelementptr inbounds i32*, i32** %205, i64 1
  store i32* %19, i32** %206, align 8
  %207 = getelementptr inbounds i32*, i32** %206, i64 1
  store i32* null, i32** %207, align 8
  %208 = getelementptr inbounds i32*, i32** %207, i64 1
  store i32* %19, i32** %208, align 8
  %209 = getelementptr inbounds i32*, i32** %208, i64 1
  store i32* @g_326, i32** %209, align 8
  %210 = getelementptr inbounds i32*, i32** %209, i64 1
  store i32* @g_95, i32** %210, align 8
  %211 = getelementptr inbounds [6 x i32*], [6 x i32*]* %204, i64 1
  %212 = getelementptr inbounds [6 x i32*], [6 x i32*]* %211, i64 0, i64 0
  %213 = bitcast [6 x i32*]* %211 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %213, i8* align 8 bitcast ([6 x i32*]* @constinit to i8*), i64 48, i1 false)
  %214 = getelementptr inbounds [6 x i32*], [6 x i32*]* %211, i64 1
  %215 = getelementptr inbounds [6 x i32*], [6 x i32*]* %214, i64 0, i64 0
  %216 = bitcast [6 x i32*]* %214 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %216, i8* align 8 bitcast ([6 x i32*]* @constinit.2 to i8*), i64 48, i1 false)
  %217 = getelementptr inbounds [6 x i32*], [6 x i32*]* %214, i64 1
  %218 = getelementptr inbounds [6 x i32*], [6 x i32*]* %217, i64 0, i64 0
  store i32* @g_216, i32** %218, align 8
  %219 = getelementptr inbounds i32*, i32** %218, i64 1
  store i32* @g_216, i32** %219, align 8
  %220 = getelementptr inbounds i32*, i32** %219, i64 1
  store i32* @g_95, i32** %220, align 8
  %221 = getelementptr inbounds i32*, i32** %220, i64 1
  store i32* null, i32** %221, align 8
  %222 = getelementptr inbounds i32*, i32** %221, i64 1
  store i32* %19, i32** %222, align 8
  %223 = getelementptr inbounds i32*, i32** %222, i64 1
  store i32* null, i32** %223, align 8
  %224 = getelementptr inbounds [6 x i32*], [6 x i32*]* %217, i64 1
  %225 = getelementptr inbounds [6 x i32*], [6 x i32*]* %224, i64 0, i64 0
  store i32* @g_95, i32** %225, align 8
  %226 = getelementptr inbounds i32*, i32** %225, i64 1
  store i32* @g_95, i32** %226, align 8
  %227 = getelementptr inbounds i32*, i32** %226, i64 1
  store i32* @g_95, i32** %227, align 8
  %228 = getelementptr inbounds i32*, i32** %227, i64 1
  store i32* %19, i32** %228, align 8
  %229 = getelementptr inbounds i32*, i32** %228, i64 1
  store i32* @g_95, i32** %229, align 8
  %230 = getelementptr inbounds i32*, i32** %229, i64 1
  store i32* @g_95, i32** %230, align 8
  %231 = getelementptr inbounds [6 x i32*], [6 x i32*]* %224, i64 1
  %232 = getelementptr inbounds [6 x i32*], [6 x i32*]* %231, i64 0, i64 0
  store i32* %19, i32** %232, align 8
  %233 = getelementptr inbounds i32*, i32** %232, i64 1
  store i32* @g_95, i32** %233, align 8
  %234 = getelementptr inbounds i32*, i32** %233, i64 1
  store i32* @g_95, i32** %234, align 8
  %235 = getelementptr inbounds i32*, i32** %234, i64 1
  store i32* @g_326, i32** %235, align 8
  %236 = getelementptr inbounds i32*, i32** %235, i64 1
  store i32* @g_216, i32** %236, align 8
  %237 = getelementptr inbounds i32*, i32** %236, i64 1
  store i32* null, i32** %237, align 8
  %238 = getelementptr inbounds [6 x i32*], [6 x i32*]* %231, i64 1
  %239 = getelementptr inbounds [6 x i32*], [6 x i32*]* %238, i64 0, i64 0
  %240 = bitcast [6 x i32*]* %238 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %240, i8* align 8 bitcast ([6 x i32*]* @constinit.3 to i8*), i64 48, i1 false)
  %241 = getelementptr inbounds [6 x i32*], [6 x i32*]* %238, i64 1
  %242 = getelementptr inbounds [6 x i32*], [6 x i32*]* %241, i64 0, i64 0
  %243 = bitcast [6 x i32*]* %241 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %243, i8* align 8 bitcast ([6 x i32*]* @constinit.4 to i8*), i64 48, i1 false)
  %244 = getelementptr inbounds [6 x i32*], [6 x i32*]* %241, i64 1
  %245 = getelementptr inbounds [6 x i32*], [6 x i32*]* %244, i64 0, i64 0
  store i32* null, i32** %245, align 8
  %246 = getelementptr inbounds i32*, i32** %245, i64 1
  store i32* @g_216, i32** %246, align 8
  %247 = getelementptr inbounds i32*, i32** %246, i64 1
  store i32* @g_326, i32** %247, align 8
  %248 = getelementptr inbounds i32*, i32** %247, i64 1
  store i32* @g_95, i32** %248, align 8
  %249 = getelementptr inbounds i32*, i32** %248, i64 1
  store i32* @g_95, i32** %249, align 8
  %250 = getelementptr inbounds i32*, i32** %249, i64 1
  store i32* %19, i32** %250, align 8
  %251 = getelementptr inbounds [9 x [6 x i32*]], [9 x [6 x i32*]]* %59, i64 0, i64 2
  %252 = getelementptr inbounds [6 x i32*], [6 x i32*]* %251, i64 0, i64 0
  store i32** %252, i32*** %60, align 8
  %253 = bitcast [8 x i64]* %61 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %253, i8* align 16 bitcast ([8 x i64]* @__const.func_2.l_3697 to i8*), i64 64, i1 false)
  store i32 0, i32* %62, align 4
  br label %254

254:                                              ; preds = %261, %202
  %255 = load i32, i32* %62, align 4
  %256 = icmp slt i32 %255, 9
  br i1 %256, label %257, label %264

257:                                              ; preds = %254
  %258 = load i32, i32* %62, align 4
  %259 = sext i32 %258 to i64
  %260 = getelementptr inbounds [9 x i32], [9 x i32]* %55, i64 0, i64 %259
  store i32 -2084283395, i32* %260, align 4
  br label %261

261:                                              ; preds = %257
  %262 = load i32, i32* %62, align 4
  %263 = add nsw i32 %262, 1
  store i32 %263, i32* %62, align 4
  br label %254

264:                                              ; preds = %254
  store i32 0, i32* %62, align 4
  br label %265

265:                                              ; preds = %294, %264
  %266 = load i32, i32* %62, align 4
  %267 = icmp slt i32 %266, 10
  br i1 %267, label %268, label %297

268:                                              ; preds = %265
  store i32 0, i32* %63, align 4
  br label %269

269:                                              ; preds = %290, %268
  %270 = load i32, i32* %63, align 4
  %271 = icmp slt i32 %270, 3
  br i1 %271, label %272, label %293

272:                                              ; preds = %269
  store i32 0, i32* %64, align 4
  br label %273

273:                                              ; preds = %286, %272
  %274 = load i32, i32* %64, align 4
  %275 = icmp slt i32 %274, 4
  br i1 %275, label %276, label %289

276:                                              ; preds = %273
  %277 = load i32, i32* %62, align 4
  %278 = sext i32 %277 to i64
  %279 = getelementptr inbounds [10 x [3 x [4 x i16]]], [10 x [3 x [4 x i16]]]* %57, i64 0, i64 %278
  %280 = load i32, i32* %63, align 4
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds [3 x [4 x i16]], [3 x [4 x i16]]* %279, i64 0, i64 %281
  %283 = load i32, i32* %64, align 4
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds [4 x i16], [4 x i16]* %282, i64 0, i64 %284
  store i16 -2256, i16* %285, align 2
  br label %286

286:                                              ; preds = %276
  %287 = load i32, i32* %64, align 4
  %288 = add nsw i32 %287, 1
  store i32 %288, i32* %64, align 4
  br label %273

289:                                              ; preds = %273
  br label %290

290:                                              ; preds = %289
  %291 = load i32, i32* %63, align 4
  %292 = add nsw i32 %291, 1
  store i32 %292, i32* %63, align 4
  br label %269

293:                                              ; preds = %269
  br label %294

294:                                              ; preds = %293
  %295 = load i32, i32* %62, align 4
  %296 = add nsw i32 %295, 1
  store i32 %296, i32* %62, align 4
  br label %265

297:                                              ; preds = %265
  br label %298

298:                                              ; preds = %297
  %299 = load i8, i8* @g_3033, align 1
  %300 = zext i8 %299 to i32
  %301 = add nsw i32 %300, 1
  %302 = trunc i32 %301 to i8
  store i8 %302, i8* @g_3033, align 1
  br label %198

303:                                              ; preds = %198
  br label %304

304:                                              ; preds = %303
  %305 = load i32, i32* @g_2470, align 4
  %306 = sub nsw i32 %305, 1
  store i32 %306, i32* @g_2470, align 4
  br label %158

307:                                              ; preds = %158
  %308 = load %union.U0*, %union.U0** %24, align 8
  ret %union.U0* %308
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i8* @func_6(i64 %0, i64 %1, i8* %2, i16 zeroext %3, i8* %4) #0 {
  %6 = alloca i8*, align 8
  %7 = alloca i64, align 8
  %8 = alloca i64, align 8
  %9 = alloca i8*, align 8
  %10 = alloca i16, align 2
  %11 = alloca i8*, align 8
  %12 = alloca i16, align 2
  %13 = alloca [8 x [9 x i32]], align 16
  %14 = alloca i32**, align 8
  %15 = alloca i8**, align 8
  %16 = alloca i16, align 2
  %17 = alloca i32, align 4
  %18 = alloca i32*, align 8
  %19 = alloca [8 x i32*], align 16
  %20 = alloca i8, align 1
  %21 = alloca i64, align 8
  %22 = alloca i16, align 2
  %23 = alloca i16, align 2
  %24 = alloca i16**, align 8
  %25 = alloca [7 x [1 x i16***]], align 16
  %26 = alloca i16****, align 8
  %27 = alloca i16, align 2
  %28 = alloca i32, align 4
  %29 = alloca i64***, align 8
  %30 = alloca i64****, align 8
  %31 = alloca i64*****, align 8
  %32 = alloca [4 x i64], align 16
  %33 = alloca i8**, align 8
  %34 = alloca i8, align 1
  %35 = alloca i16***, align 8
  %36 = alloca i16****, align 8
  %37 = alloca i16*****, align 8
  %38 = alloca i32*****, align 8
  %39 = alloca i32, align 4
  %40 = alloca i32, align 4
  %41 = alloca i64, align 8
  %42 = alloca i32, align 4
  %43 = alloca [6 x [2 x i32**]], align 16
  %44 = alloca i32, align 4
  %45 = alloca i32, align 4
  %46 = alloca i32*, align 8
  %47 = alloca i64, align 8
  %48 = alloca [1 x [4 x [10 x i64*]]], align 16
  %49 = alloca i16**, align 8
  %50 = alloca i16***, align 8
  %51 = alloca i16****, align 8
  %52 = alloca i16**, align 8
  %53 = alloca i16***, align 8
  %54 = alloca [9 x [4 x i16****]], align 16
  %55 = alloca i32, align 4
  %56 = alloca i32, align 4
  %57 = alloca i32, align 4
  %58 = alloca i8, align 1
  %59 = alloca i64***, align 8
  %60 = alloca i32, align 4
  %61 = alloca i32, align 4
  %62 = alloca i64*, align 8
  %63 = alloca i64**, align 8
  %64 = alloca i64***, align 8
  %65 = alloca i64****, align 8
  %66 = alloca [10 x i64*****], align 16
  %67 = alloca i32***, align 8
  %68 = alloca i32, align 4
  %69 = alloca i64, align 8
  %70 = alloca i8**, align 8
  %71 = alloca i8***, align 8
  %72 = alloca i32, align 4
  %73 = alloca i32**, align 8
  %74 = alloca [6 x [9 x i32]], align 16
  %75 = alloca i8, align 1
  %76 = alloca i64**, align 8
  %77 = alloca i16, align 2
  %78 = alloca i8, align 1
  %79 = alloca i32*, align 8
  %80 = alloca i64*, align 8
  %81 = alloca [9 x i64], align 16
  %82 = alloca i8**, align 8
  %83 = alloca [10 x [2 x i8***]], align 16
  %84 = alloca i32**, align 8
  %85 = alloca i32***, align 8
  %86 = alloca i32***, align 8
  %87 = alloca [7 x [7 x [5 x i16*]]], align 16
  %88 = alloca i32*****, align 8
  %89 = alloca i32, align 4
  %90 = alloca i32, align 4
  %91 = alloca i32, align 4
  %92 = alloca i32**, align 8
  %93 = alloca i64*, align 8
  %94 = alloca i64*, align 8
  %95 = alloca i64*, align 8
  %96 = alloca i32, align 4
  %97 = alloca i32, align 4
  %98 = alloca i8, align 1
  %99 = alloca i64, align 8
  %100 = alloca i64*, align 8
  %101 = alloca i32***, align 8
  %102 = alloca %union.U0*, align 8
  %103 = alloca i32, align 4
  %104 = alloca i8***, align 8
  %105 = alloca i8****, align 8
  %106 = alloca i8, align 1
  %107 = alloca i32, align 4
  %108 = alloca i64*, align 8
  %109 = alloca i64*, align 8
  %110 = alloca %union.U0*, align 8
  %111 = alloca i32***, align 8
  %112 = alloca i32*, align 8
  %113 = alloca i32**, align 8
  %114 = alloca i32, align 4
  %115 = alloca [5 x i32****], align 16
  %116 = alloca i16, align 2
  %117 = alloca i32, align 4
  %118 = alloca i32, align 4
  %119 = alloca [8 x i64*], align 16
  %120 = alloca [5 x i32], align 16
  %121 = alloca i32*, align 8
  %122 = alloca i32*, align 8
  %123 = alloca [7 x i32], align 16
  %124 = alloca i64**, align 8
  %125 = alloca i16, align 2
  %126 = alloca i32*, align 8
  %127 = alloca i16*****, align 8
  %128 = alloca i16*, align 8
  %129 = alloca i8*, align 8
  %130 = alloca i32, align 4
  %131 = alloca i8, align 1
  %132 = alloca i16*, align 8
  %133 = alloca i16*, align 8
  %134 = alloca i32, align 4
  %135 = alloca i32*, align 8
  %136 = alloca i32, align 4
  %137 = alloca i16, align 2
  %138 = alloca [6 x i32*], align 16
  %139 = alloca i32, align 4
  %140 = alloca %union.U0, align 8
  %141 = alloca [3 x [3 x [4 x i32***]]], align 16
  %142 = alloca i32, align 4
  %143 = alloca i32, align 4
  %144 = alloca i32, align 4
  %145 = alloca i16, align 2
  %146 = alloca i32***, align 8
  %147 = alloca i8***, align 8
  %148 = alloca i8***, align 8
  %149 = alloca i32*, align 8
  %150 = alloca i64**, align 8
  %151 = alloca i64**, align 8
  %152 = alloca i32, align 4
  %153 = alloca %union.U0*, align 8
  store i64 %0, i64* %7, align 8
  store i64 %1, i64* %8, align 8
  store i8* %2, i8** %9, align 8
  store i16 %3, i16* %10, align 2
  store i8* %4, i8** %11, align 8
  store i16 5, i16* %12, align 2
  %154 = bitcast [8 x [9 x i32]]* %13 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %154, i8* align 16 bitcast ([8 x [9 x i32]]* @__const.func_6.l_2950 to i8*), i64 288, i1 false)
  store i32** null, i32*** %14, align 8
  store i8** @g_516, i8*** %15, align 8
  store i16 -16133, i16* %16, align 2
  store i32 -7, i32* %17, align 4
  store i32* @g_45, i32** %18, align 8
  %155 = bitcast [8 x i32*]* %19 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %155, i8* align 16 bitcast ([8 x i32*]* @__const.func_6.l_2959 to i8*), i64 64, i1 false)
  store i8 -8, i8* %20, align 1
  store i64 555804760760355450, i64* %21, align 8
  store i16 -31537, i16* %22, align 2
  store i16 21326, i16* %23, align 2
  store i16** getelementptr inbounds ([4 x i16*], [4 x i16*]* @g_154, i64 0, i64 1), i16*** %24, align 8
  %156 = getelementptr inbounds [7 x [1 x i16***]], [7 x [1 x i16***]]* %25, i64 0, i64 0
  %157 = getelementptr inbounds [1 x i16***], [1 x i16***]* %156, i64 0, i64 0
  store i16*** %24, i16**** %157, align 8
  %158 = getelementptr inbounds [1 x i16***], [1 x i16***]* %156, i64 1
  %159 = getelementptr inbounds [1 x i16***], [1 x i16***]* %158, i64 0, i64 0
  store i16*** %24, i16**** %159, align 8
  %160 = getelementptr inbounds [1 x i16***], [1 x i16***]* %158, i64 1
  %161 = getelementptr inbounds [1 x i16***], [1 x i16***]* %160, i64 0, i64 0
  store i16*** %24, i16**** %161, align 8
  %162 = getelementptr inbounds [1 x i16***], [1 x i16***]* %160, i64 1
  %163 = getelementptr inbounds [1 x i16***], [1 x i16***]* %162, i64 0, i64 0
  store i16*** %24, i16**** %163, align 8
  %164 = getelementptr inbounds [1 x i16***], [1 x i16***]* %162, i64 1
  %165 = getelementptr inbounds [1 x i16***], [1 x i16***]* %164, i64 0, i64 0
  store i16*** %24, i16**** %165, align 8
  %166 = getelementptr inbounds [1 x i16***], [1 x i16***]* %164, i64 1
  %167 = getelementptr inbounds [1 x i16***], [1 x i16***]* %166, i64 0, i64 0
  store i16*** %24, i16**** %167, align 8
  %168 = getelementptr inbounds [1 x i16***], [1 x i16***]* %166, i64 1
  %169 = getelementptr inbounds [1 x i16***], [1 x i16***]* %168, i64 0, i64 0
  store i16*** %24, i16**** %169, align 8
  %170 = getelementptr inbounds [7 x [1 x i16***]], [7 x [1 x i16***]]* %25, i64 0, i64 0
  %171 = getelementptr inbounds [1 x i16***], [1 x i16***]* %170, i64 0, i64 0
  store i16**** %171, i16***** %26, align 8
  store i16 0, i16* %27, align 2
  store i32 -8, i32* %28, align 4
  store i64*** @g_2096, i64**** %29, align 8
  store i64**** %29, i64***** %30, align 8
  store i64***** %30, i64****** %31, align 8
  %172 = bitcast [4 x i64]* %32 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %172, i8* align 16 bitcast ([4 x i64]* @__const.func_6.l_3086 to i8*), i64 32, i1 false)
  store i8** null, i8*** %33, align 8
  store i8 107, i8* %34, align 1
  store i16*** @g_318, i16**** %35, align 8
  store i16**** %35, i16***** %36, align 8
  store i16***** %36, i16****** %37, align 8
  store i32***** getelementptr inbounds ([5 x [1 x [1 x i32****]]], [5 x [1 x [1 x i32****]]]* @g_2729, i64 0, i64 0, i64 0, i64 0), i32****** %38, align 8
  store i16 -24, i16* @g_2056, align 2
  br label %173

173:                                              ; preds = %294, %5
  %174 = load i16, i16* @g_2056, align 2
  %175 = zext i16 %174 to i32
  %176 = icmp slt i32 %175, 53
  br i1 %176, label %177, label %297

177:                                              ; preds = %173
  store i64 -7, i64* %41, align 8
  store i32 -4, i32* %42, align 4
  %178 = bitcast [6 x [2 x i32**]]* %43 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %178, i8* align 16 bitcast ([6 x [2 x i32**]]* @__const.func_6.l_2953 to i8*), i64 96, i1 false)
  %179 = load volatile i16****, i16***** @g_722, align 8
  %180 = load volatile i16***, i16**** %179, align 8
  %181 = load i16**, i16*** %180, align 8
  %182 = load i16*, i16** %181, align 8
  %183 = load volatile i16, i16* %182, align 2
  %184 = zext i16 %183 to i32
  %185 = load i16*, i16** @g_369, align 8
  %186 = load i16, i16* %185, align 2
  %187 = sext i16 %186 to i32
  %188 = icmp sle i32 %184, %187
  br i1 %188, label %189, label %286

189:                                              ; preds = %177
  %190 = load i16*, i16** @g_369, align 8
  %191 = load i16, i16* %190, align 2
  %192 = sext i16 %191 to i32
  %193 = load i16, i16* %12, align 2
  %194 = sext i16 %193 to i32
  %195 = load i64, i64* %41, align 8
  %196 = trunc i64 %195 to i8
  %197 = call zeroext i8 @safe_div_func_uint8_t_u_u(i8 zeroext %196, i8 zeroext -38)
  %198 = zext i8 %197 to i32
  %199 = load i16, i16* %12, align 2
  %200 = sext i16 %199 to i32
  %201 = icmp ne i32 %200, 0
  br i1 %201, label %202, label %224

202:                                              ; preds = %189
  %203 = load i16, i16* %10, align 2
  %204 = zext i16 %203 to i32
  %205 = load i8*, i8** @g_1167, align 8
  %206 = load i8, i8* %205, align 1
  %207 = add i8 %206, 1
  store i8 %207, i8* %205, align 1
  %208 = zext i8 %206 to i32
  %209 = icmp ne i32 %208, 0
  br i1 %209, label %210, label %217

210:                                              ; preds = %202
  %211 = load i64, i64* %41, align 8
  %212 = getelementptr inbounds [6 x [2 x i32**]], [6 x [2 x i32**]]* %43, i64 0, i64 5
  %213 = getelementptr inbounds [2 x i32**], [2 x i32**]* %212, i64 0, i64 0
  %214 = load i32**, i32*** %213, align 16
  %215 = load i32**, i32*** %14, align 8
  %216 = icmp ne i32** %214, %215
  br label %217

217:                                              ; preds = %210, %202
  %218 = phi i1 [ false, %202 ], [ %216, %210 ]
  %219 = zext i1 %218 to i32
  %220 = icmp eq i32 %204, %219
  %221 = zext i1 %220 to i32
  %222 = load i64, i64* %41, align 8
  %223 = icmp ne i64 %222, 0
  br label %224

224:                                              ; preds = %217, %189
  %225 = phi i1 [ false, %189 ], [ %223, %217 ]
  %226 = zext i1 %225 to i32
  %227 = trunc i32 %226 to i16
  %228 = load i64, i64* %7, align 8
  %229 = trunc i64 %228 to i16
  %230 = call zeroext i16 @safe_mod_func_uint16_t_u_u(i16 zeroext %227, i16 zeroext %229)
  %231 = zext i16 %230 to i32
  %232 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %233 = getelementptr inbounds [9 x i32], [9 x i32]* %232, i64 0, i64 4
  %234 = load i32, i32* %233, align 4
  %235 = or i32 %234, %231
  store i32 %235, i32* %233, align 4
  %236 = load i32*, i32** @g_422, align 8
  %237 = load i32, i32* %236, align 4
  %238 = icmp sle i32 %235, %237
  %239 = zext i1 %238 to i32
  %240 = or i32 %198, %239
  %241 = trunc i32 %240 to i16
  %242 = call zeroext i16 @safe_lshift_func_uint16_t_u_u(i16 zeroext %241, i32 1)
  %243 = load i8**, i8*** %15, align 8
  %244 = icmp ne i8** %11, %243
  %245 = zext i1 %244 to i32
  %246 = load i16, i16* %10, align 2
  %247 = zext i16 %246 to i32
  %248 = icmp sle i32 %245, %247
  %249 = zext i1 %248 to i32
  %250 = icmp sle i32 %194, %249
  %251 = zext i1 %250 to i32
  %252 = trunc i32 %251 to i16
  %253 = load i16, i16* %12, align 2
  %254 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %252, i16 zeroext %253)
  %255 = zext i16 %254 to i32
  %256 = call i32 @safe_unary_minus_func_int32_t_s(i32 %255)
  %257 = trunc i32 %256 to i8
  %258 = load i16, i16* %12, align 2
  %259 = trunc i16 %258 to i8
  %260 = call signext i8 @safe_mod_func_int8_t_s_s(i8 signext %257, i8 signext %259)
  %261 = sext i8 %260 to i32
  %262 = xor i32 %192, %261
  %263 = trunc i32 %262 to i16
  %264 = load i16, i16* %10, align 2
  %265 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %263, i16 zeroext %264)
  %266 = trunc i16 %265 to i8
  %267 = call zeroext i8 @safe_unary_minus_func_uint8_t_u(i8 zeroext %266)
  %268 = zext i8 %267 to i64
  %269 = load i64, i64* %8, align 8
  %270 = or i64 %269, %268
  store i64 %270, i64* %8, align 8
  %271 = load i32, i32* %42, align 4
  %272 = sext i32 %271 to i64
  %273 = call i64 @safe_add_func_int64_t_s_s(i64 %270, i64 %272)
  %274 = icmp ne i64 %273, 0
  %275 = xor i1 %274, true
  %276 = zext i1 %275 to i32
  %277 = trunc i32 %276 to i8
  %278 = call signext i8 @safe_rshift_func_int8_t_s_s(i8 signext %277, i32 5)
  %279 = sext i8 %278 to i32
  %280 = load i16, i16* %16, align 2
  %281 = zext i16 %280 to i32
  %282 = and i32 %281, %279
  %283 = trunc i32 %282 to i16
  store i16 %283, i16* %16, align 2
  %284 = zext i16 %283 to i32
  %285 = icmp ne i32 %284, 0
  br label %286

286:                                              ; preds = %224, %177
  %287 = phi i1 [ false, %177 ], [ %285, %224 ]
  %288 = zext i1 %287 to i32
  %289 = trunc i32 %288 to i16
  %290 = load i64, i64* %7, align 8
  %291 = trunc i64 %290 to i16
  %292 = call signext i16 @safe_add_func_int16_t_s_s(i16 signext %289, i16 signext %291)
  %293 = sext i16 %292 to i32
  store i32 %293, i32* %17, align 4
  br label %294

294:                                              ; preds = %286
  %295 = load i16, i16* @g_2056, align 2
  %296 = add i16 %295, 1
  store i16 %296, i16* @g_2056, align 2
  br label %173

297:                                              ; preds = %173
  %298 = load i16, i16* %23, align 2
  %299 = add i16 %298, -1
  store i16 %299, i16* %23, align 2
  store i32 0, i32* @g_216, align 4
  br label %300

300:                                              ; preds = %305, %297
  %301 = load i32, i32* @g_216, align 4
  %302 = icmp ult i32 %301, 49
  br i1 %302, label %303, label %310

303:                                              ; preds = %300
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 0, i64 2), i32** %46, align 8
  %304 = getelementptr inbounds [8 x i32*], [8 x i32*]* %19, i64 0, i64 2
  store i32* bitcast (i8* getelementptr (i8, i8* bitcast ([7 x [6 x i32]]* @g_781 to i8*), i64 8) to i32*), i32** %304, align 16
  br label %305

305:                                              ; preds = %303
  %306 = load i32, i32* @g_216, align 4
  %307 = trunc i32 %306 to i16
  %308 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %307, i16 zeroext 7)
  %309 = zext i16 %308 to i32
  store i32 %309, i32* @g_216, align 4
  br label %300

310:                                              ; preds = %300
  %311 = load volatile i32**, i32*** @g_2015, align 8
  %312 = load i32*, i32** %311, align 8
  %313 = load i32, i32* %312, align 4
  %314 = icmp ne i32 %313, 0
  br i1 %314, label %315, label %429

315:                                              ; preds = %310
  store i64 0, i64* %47, align 8
  %316 = getelementptr inbounds [1 x [4 x [10 x i64*]]], [1 x [4 x [10 x i64*]]]* %48, i64 0, i64 0
  %317 = getelementptr inbounds [4 x [10 x i64*]], [4 x [10 x i64*]]* %316, i64 0, i64 0
  %318 = getelementptr inbounds [10 x i64*], [10 x i64*]* %317, i64 0, i64 0
  store i64* %21, i64** %318, align 8
  %319 = getelementptr inbounds i64*, i64** %318, i64 1
  store i64* %21, i64** %319, align 8
  %320 = getelementptr inbounds i64*, i64** %319, i64 1
  store i64* %21, i64** %320, align 8
  %321 = getelementptr inbounds i64*, i64** %320, i64 1
  store i64* %21, i64** %321, align 8
  %322 = getelementptr inbounds i64*, i64** %321, i64 1
  store i64* %21, i64** %322, align 8
  %323 = getelementptr inbounds i64*, i64** %322, i64 1
  store i64* %21, i64** %323, align 8
  %324 = getelementptr inbounds i64*, i64** %323, i64 1
  store i64* %21, i64** %324, align 8
  %325 = getelementptr inbounds i64*, i64** %324, i64 1
  store i64* %21, i64** %325, align 8
  %326 = getelementptr inbounds i64*, i64** %325, i64 1
  store i64* %21, i64** %326, align 8
  %327 = getelementptr inbounds i64*, i64** %326, i64 1
  store i64* %21, i64** %327, align 8
  %328 = getelementptr inbounds [10 x i64*], [10 x i64*]* %317, i64 1
  %329 = getelementptr inbounds [10 x i64*], [10 x i64*]* %328, i64 0, i64 0
  store i64* %21, i64** %329, align 8
  %330 = getelementptr inbounds i64*, i64** %329, i64 1
  store i64* %21, i64** %330, align 8
  %331 = getelementptr inbounds i64*, i64** %330, i64 1
  store i64* %21, i64** %331, align 8
  %332 = getelementptr inbounds i64*, i64** %331, i64 1
  store i64* %21, i64** %332, align 8
  %333 = getelementptr inbounds i64*, i64** %332, i64 1
  store i64* %21, i64** %333, align 8
  %334 = getelementptr inbounds i64*, i64** %333, i64 1
  store i64* %21, i64** %334, align 8
  %335 = getelementptr inbounds i64*, i64** %334, i64 1
  store i64* %21, i64** %335, align 8
  %336 = getelementptr inbounds i64*, i64** %335, i64 1
  store i64* %21, i64** %336, align 8
  %337 = getelementptr inbounds i64*, i64** %336, i64 1
  store i64* %21, i64** %337, align 8
  %338 = getelementptr inbounds i64*, i64** %337, i64 1
  store i64* %21, i64** %338, align 8
  %339 = getelementptr inbounds [10 x i64*], [10 x i64*]* %328, i64 1
  %340 = getelementptr inbounds [10 x i64*], [10 x i64*]* %339, i64 0, i64 0
  store i64* %21, i64** %340, align 8
  %341 = getelementptr inbounds i64*, i64** %340, i64 1
  store i64* %21, i64** %341, align 8
  %342 = getelementptr inbounds i64*, i64** %341, i64 1
  store i64* %21, i64** %342, align 8
  %343 = getelementptr inbounds i64*, i64** %342, i64 1
  store i64* %21, i64** %343, align 8
  %344 = getelementptr inbounds i64*, i64** %343, i64 1
  store i64* %21, i64** %344, align 8
  %345 = getelementptr inbounds i64*, i64** %344, i64 1
  store i64* %21, i64** %345, align 8
  %346 = getelementptr inbounds i64*, i64** %345, i64 1
  store i64* %21, i64** %346, align 8
  %347 = getelementptr inbounds i64*, i64** %346, i64 1
  store i64* %21, i64** %347, align 8
  %348 = getelementptr inbounds i64*, i64** %347, i64 1
  store i64* %21, i64** %348, align 8
  %349 = getelementptr inbounds i64*, i64** %348, i64 1
  store i64* %21, i64** %349, align 8
  %350 = getelementptr inbounds [10 x i64*], [10 x i64*]* %339, i64 1
  %351 = getelementptr inbounds [10 x i64*], [10 x i64*]* %350, i64 0, i64 0
  store i64* %21, i64** %351, align 8
  %352 = getelementptr inbounds i64*, i64** %351, i64 1
  store i64* %21, i64** %352, align 8
  %353 = getelementptr inbounds i64*, i64** %352, i64 1
  store i64* %21, i64** %353, align 8
  %354 = getelementptr inbounds i64*, i64** %353, i64 1
  store i64* %21, i64** %354, align 8
  %355 = getelementptr inbounds i64*, i64** %354, i64 1
  store i64* %21, i64** %355, align 8
  %356 = getelementptr inbounds i64*, i64** %355, i64 1
  store i64* %21, i64** %356, align 8
  %357 = getelementptr inbounds i64*, i64** %356, i64 1
  store i64* %21, i64** %357, align 8
  %358 = getelementptr inbounds i64*, i64** %357, i64 1
  store i64* %21, i64** %358, align 8
  %359 = getelementptr inbounds i64*, i64** %358, i64 1
  store i64* %21, i64** %359, align 8
  %360 = getelementptr inbounds i64*, i64** %359, i64 1
  store i64* %21, i64** %360, align 8
  store i16** @g_319, i16*** %49, align 8
  store i16*** %49, i16**** %50, align 8
  store i16**** %50, i16***** %51, align 8
  store i16** @g_319, i16*** %52, align 8
  store i16*** %52, i16**** %53, align 8
  %361 = getelementptr inbounds [9 x [4 x i16****]], [9 x [4 x i16****]]* %54, i64 0, i64 0
  %362 = bitcast [4 x i16****]* %361 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %362, i8 0, i64 32, i1 false)
  %363 = getelementptr inbounds [4 x i16****], [4 x i16****]* %361, i64 0, i64 0
  %364 = getelementptr inbounds i16****, i16***** %363, i64 1
  store i16**** %50, i16***** %364, align 8
  %365 = getelementptr inbounds i16****, i16***** %364, i64 1
  %366 = getelementptr inbounds i16****, i16***** %365, i64 1
  %367 = getelementptr inbounds [4 x i16****], [4 x i16****]* %361, i64 1
  %368 = getelementptr inbounds [4 x i16****], [4 x i16****]* %367, i64 0, i64 0
  store i16**** %50, i16***** %368, align 8
  %369 = getelementptr inbounds i16****, i16***** %368, i64 1
  store i16**** %50, i16***** %369, align 8
  %370 = getelementptr inbounds i16****, i16***** %369, i64 1
  store i16**** @g_2984, i16***** %370, align 8
  %371 = getelementptr inbounds i16****, i16***** %370, i64 1
  store i16**** %50, i16***** %371, align 8
  %372 = getelementptr inbounds [4 x i16****], [4 x i16****]* %367, i64 1
  %373 = getelementptr inbounds [4 x i16****], [4 x i16****]* %372, i64 0, i64 0
  store i16**** %50, i16***** %373, align 8
  %374 = getelementptr inbounds i16****, i16***** %373, i64 1
  store i16**** null, i16***** %374, align 8
  %375 = getelementptr inbounds i16****, i16***** %374, i64 1
  store i16**** null, i16***** %375, align 8
  %376 = getelementptr inbounds i16****, i16***** %375, i64 1
  store i16**** %50, i16***** %376, align 8
  %377 = getelementptr inbounds [4 x i16****], [4 x i16****]* %372, i64 1
  %378 = bitcast [4 x i16****]* %377 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %378, i8 0, i64 32, i1 false)
  %379 = getelementptr inbounds [4 x i16****], [4 x i16****]* %377, i64 0, i64 0
  %380 = getelementptr inbounds i16****, i16***** %379, i64 1
  store i16**** %50, i16***** %380, align 8
  %381 = getelementptr inbounds i16****, i16***** %380, i64 1
  %382 = getelementptr inbounds i16****, i16***** %381, i64 1
  %383 = getelementptr inbounds [4 x i16****], [4 x i16****]* %377, i64 1
  %384 = getelementptr inbounds [4 x i16****], [4 x i16****]* %383, i64 0, i64 0
  store i16**** %50, i16***** %384, align 8
  %385 = getelementptr inbounds i16****, i16***** %384, i64 1
  store i16**** %50, i16***** %385, align 8
  %386 = getelementptr inbounds i16****, i16***** %385, i64 1
  store i16**** @g_2984, i16***** %386, align 8
  %387 = getelementptr inbounds i16****, i16***** %386, i64 1
  store i16**** %50, i16***** %387, align 8
  %388 = getelementptr inbounds [4 x i16****], [4 x i16****]* %383, i64 1
  %389 = getelementptr inbounds [4 x i16****], [4 x i16****]* %388, i64 0, i64 0
  store i16**** %50, i16***** %389, align 8
  %390 = getelementptr inbounds i16****, i16***** %389, i64 1
  store i16**** null, i16***** %390, align 8
  %391 = getelementptr inbounds i16****, i16***** %390, i64 1
  store i16**** null, i16***** %391, align 8
  %392 = getelementptr inbounds i16****, i16***** %391, i64 1
  store i16**** %50, i16***** %392, align 8
  %393 = getelementptr inbounds [4 x i16****], [4 x i16****]* %388, i64 1
  %394 = bitcast [4 x i16****]* %393 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %394, i8 0, i64 32, i1 false)
  %395 = getelementptr inbounds [4 x i16****], [4 x i16****]* %393, i64 0, i64 0
  %396 = getelementptr inbounds i16****, i16***** %395, i64 1
  store i16**** %50, i16***** %396, align 8
  %397 = getelementptr inbounds i16****, i16***** %396, i64 1
  %398 = getelementptr inbounds i16****, i16***** %397, i64 1
  %399 = getelementptr inbounds [4 x i16****], [4 x i16****]* %393, i64 1
  %400 = getelementptr inbounds [4 x i16****], [4 x i16****]* %399, i64 0, i64 0
  store i16**** %50, i16***** %400, align 8
  %401 = getelementptr inbounds i16****, i16***** %400, i64 1
  store i16**** %50, i16***** %401, align 8
  %402 = getelementptr inbounds i16****, i16***** %401, i64 1
  store i16**** @g_2984, i16***** %402, align 8
  %403 = getelementptr inbounds i16****, i16***** %402, i64 1
  store i16**** %50, i16***** %403, align 8
  %404 = getelementptr inbounds [4 x i16****], [4 x i16****]* %399, i64 1
  %405 = getelementptr inbounds [4 x i16****], [4 x i16****]* %404, i64 0, i64 0
  store i16**** %50, i16***** %405, align 8
  %406 = getelementptr inbounds i16****, i16***** %405, i64 1
  store i16**** null, i16***** %406, align 8
  %407 = getelementptr inbounds i16****, i16***** %406, i64 1
  store i16**** null, i16***** %407, align 8
  %408 = getelementptr inbounds i16****, i16***** %407, i64 1
  store i16**** %50, i16***** %408, align 8
  %409 = load i32*, i32** %18, align 8
  %410 = load i32, i32* %409, align 4
  %411 = sext i32 %410 to i64
  %412 = icmp sle i64 -1, %411
  %413 = zext i1 %412 to i32
  %414 = sext i32 %413 to i64
  %415 = load i64, i64* %8, align 8
  %416 = icmp ne i64 %414, %415
  br i1 %416, label %417, label %421

417:                                              ; preds = %315
  %418 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext 1, i32 0)
  %419 = sext i16 %418 to i32
  %420 = icmp ne i32 %419, 0
  br label %421

421:                                              ; preds = %417, %315
  %422 = phi i1 [ false, %315 ], [ %420, %417 ]
  %423 = zext i1 %422 to i32
  %424 = sext i32 %423 to i64
  %425 = load i64, i64* %8, align 8
  %426 = icmp sle i64 %424, %425
  %427 = zext i1 %426 to i32
  %428 = load i32*, i32** @g_422, align 8
  store i32 1599363468, i32* %428, align 4
  br label %2314

429:                                              ; preds = %310
  store i8 -1, i8* %58, align 1
  store i64*** @g_2096, i64**** %59, align 8
  store i32 -610109778, i32* %60, align 4
  store i32 1, i32* %61, align 4
  store i64* null, i64** %62, align 8
  store i64** %62, i64*** %63, align 8
  store i64*** %63, i64**** %64, align 8
  store i64**** %64, i64***** %65, align 8
  %430 = getelementptr inbounds [10 x i64*****], [10 x i64*****]* %66, i64 0, i64 0
  store i64***** null, i64****** %430, align 8
  %431 = getelementptr inbounds i64*****, i64****** %430, i64 1
  store i64***** %65, i64****** %431, align 8
  %432 = getelementptr inbounds i64*****, i64****** %431, i64 1
  store i64***** null, i64****** %432, align 8
  %433 = getelementptr inbounds i64*****, i64****** %432, i64 1
  store i64***** %65, i64****** %433, align 8
  %434 = getelementptr inbounds i64*****, i64****** %433, i64 1
  store i64***** null, i64****** %434, align 8
  %435 = getelementptr inbounds i64*****, i64****** %434, i64 1
  store i64***** %65, i64****** %435, align 8
  %436 = getelementptr inbounds i64*****, i64****** %435, i64 1
  store i64***** null, i64****** %436, align 8
  %437 = getelementptr inbounds i64*****, i64****** %436, i64 1
  store i64***** %65, i64****** %437, align 8
  %438 = getelementptr inbounds i64*****, i64****** %437, i64 1
  store i64***** null, i64****** %438, align 8
  %439 = getelementptr inbounds i64*****, i64****** %438, i64 1
  store i64***** %65, i64****** %439, align 8
  store i32*** @g_421, i32**** %67, align 8
  store i32 0, i32* %68, align 4
  store i64 1, i64* %69, align 8
  store i8** getelementptr inbounds ([8 x i8*], [8 x i8*]* @g_2855, i64 0, i64 4), i8*** %70, align 8
  store i8*** %70, i8**** %71, align 8
  %440 = load i64, i64* %7, align 8
  %441 = trunc i64 %440 to i32
  %442 = load i32**, i32*** @g_421, align 8
  %443 = load i32*, i32** %442, align 8
  store i32 %441, i32* %443, align 4
  %444 = load i8, i8* %58, align 1
  %445 = zext i8 %444 to i32
  %446 = or i32 %445, %441
  %447 = trunc i32 %446 to i8
  store i8 %447, i8* %58, align 1
  br label %448

448:                                              ; preds = %1111, %429
  %449 = load i16, i16* %27, align 2
  %450 = zext i16 %449 to i64
  %451 = xor i64 %450, 6
  %452 = trunc i64 %451 to i16
  store i16 %452, i16* %27, align 2
  %453 = load i16*, i16** @g_369, align 8
  %454 = load i16, i16* %453, align 2
  %455 = sext i16 %454 to i64
  %456 = or i64 %455, 38166
  %457 = trunc i64 %456 to i16
  store i16 %457, i16* %453, align 2
  %458 = sext i16 %457 to i32
  %459 = load i8, i8* %58, align 1
  %460 = load i8*, i8** %9, align 8
  store i8 %459, i8* %460, align 1
  %461 = sext i8 %459 to i32
  %462 = icmp sge i32 %461, 1
  %463 = zext i1 %462 to i32
  %464 = trunc i32 %463 to i8
  %465 = load volatile i64****, i64***** @g_1274, align 8
  %466 = load volatile i64***, i64**** %465, align 8
  %467 = load i64***, i64**** %59, align 8
  %468 = icmp eq i64*** %466, %467
  %469 = zext i1 %468 to i32
  %470 = trunc i32 %469 to i16
  %471 = load i64, i64* %7, align 8
  %472 = trunc i64 %471 to i32
  %473 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %470, i32 %472)
  %474 = sext i16 %473 to i32
  %475 = icmp ne i32 %474, 0
  br i1 %475, label %477, label %476

476:                                              ; preds = %448
  br label %477

477:                                              ; preds = %476, %448
  %478 = phi i1 [ true, %448 ], [ true, %476 ]
  %479 = zext i1 %478 to i32
  %480 = trunc i32 %479 to i16
  %481 = load i32*, i32** %18, align 8
  %482 = load i32, i32* %481, align 4
  %483 = trunc i32 %482 to i16
  %484 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %480, i16 zeroext %483)
  %485 = trunc i16 %484 to i8
  %486 = load i8, i8* %58, align 1
  %487 = call signext i8 @safe_div_func_int8_t_s_s(i8 signext %485, i8 signext %486)
  %488 = call signext i8 @safe_div_func_int8_t_s_s(i8 signext %464, i8 signext %487)
  %489 = sext i8 %488 to i32
  %490 = load i32, i32* %28, align 4
  %491 = icmp ugt i32 %489, %490
  %492 = zext i1 %491 to i32
  %493 = sext i32 %492 to i64
  %494 = icmp slt i64 -3, %493
  %495 = zext i1 %494 to i32
  %496 = sext i32 %495 to i64
  %497 = load i64, i64* %7, align 8
  %498 = icmp uge i64 %496, %497
  %499 = zext i1 %498 to i32
  %500 = sext i32 %499 to i64
  %501 = load i64, i64* %8, align 8
  %502 = or i64 %500, %501
  %503 = icmp slt i64 %502, 2672806514
  %504 = zext i1 %503 to i32
  %505 = icmp ne i32 %458, %504
  %506 = zext i1 %505 to i32
  %507 = icmp sgt i32 0, %506
  %508 = zext i1 %507 to i32
  %509 = xor i32 %508, -1
  %510 = load i32, i32* @g_12, align 4
  %511 = icmp sle i32 %509, %510
  %512 = zext i1 %511 to i32
  %513 = trunc i32 %512 to i16
  %514 = call signext i16 @safe_unary_minus_func_int16_t_s(i16 signext %513)
  %515 = sext i16 %514 to i32
  %516 = load i8, i8* %58, align 1
  %517 = zext i8 %516 to i32
  %518 = icmp sle i32 %515, %517
  %519 = zext i1 %518 to i32
  %520 = sext i32 %519 to i64
  %521 = icmp uge i64 0, %520
  %522 = zext i1 %521 to i32
  %523 = sext i32 %522 to i64
  %524 = icmp ule i64 %523, 247
  %525 = zext i1 %524 to i32
  %526 = sext i32 %525 to i64
  %527 = call i64 @safe_add_func_uint64_t_u_u(i64 %526, i64 -6984585027763917143)
  %528 = icmp ne i64 %527, 0
  br i1 %528, label %529, label %552

529:                                              ; preds = %477
  store i32 0, i32* %28, align 4
  br label %530

530:                                              ; preds = %548, %529
  %531 = load i32, i32* %28, align 4
  %532 = icmp ugt i32 %531, 55
  br i1 %532, label %533, label %551

533:                                              ; preds = %530
  store i16 0, i16* @g_2056, align 2
  br label %534

534:                                              ; preds = %542, %533
  %535 = load i16, i16* @g_2056, align 2
  %536 = zext i16 %535 to i32
  %537 = icmp slt i32 %536, 15
  br i1 %537, label %538, label %547

538:                                              ; preds = %534
  %539 = load i64, i64* %8, align 8
  %540 = trunc i64 %539 to i32
  %541 = load volatile i32*, i32** @g_158, align 8
  store i32 %540, i32* %541, align 4
  br label %542

542:                                              ; preds = %538
  %543 = load i16, i16* @g_2056, align 2
  %544 = zext i16 %543 to i64
  %545 = call i64 @safe_add_func_uint64_t_u_u(i64 %544, i64 1)
  %546 = trunc i64 %545 to i16
  store i16 %546, i16* @g_2056, align 2
  br label %534

547:                                              ; preds = %534
  br label %548

548:                                              ; preds = %547
  %549 = load i32, i32* %28, align 4
  %550 = add i32 %549, 1
  store i32 %550, i32* %28, align 4
  br label %530

551:                                              ; preds = %530
  br label %2309

552:                                              ; preds = %477
  store i32** @g_797, i32*** %73, align 8
  %553 = bitcast [6 x [9 x i32]]* %74 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %553, i8* align 16 bitcast ([6 x [9 x i32]]* @__const.func_6.l_3032 to i8*), i64 216, i1 false)
  store i8 58, i8* %75, align 1
  store i64** null, i64*** %76, align 8
  store i16 -30151, i16* %77, align 2
  store i8 -81, i8* %78, align 1
  store i32* @g_675, i32** %79, align 8
  store i64* @g_684, i64** %80, align 8
  store i8** @g_1167, i8*** %82, align 8
  %554 = getelementptr inbounds [10 x [2 x i8***]], [10 x [2 x i8***]]* %83, i64 0, i64 0
  %555 = getelementptr inbounds [2 x i8***], [2 x i8***]* %554, i64 0, i64 0
  store i8*** %82, i8**** %555, align 8
  %556 = getelementptr inbounds i8***, i8**** %555, i64 1
  store i8*** %82, i8**** %556, align 8
  %557 = getelementptr inbounds [2 x i8***], [2 x i8***]* %554, i64 1
  %558 = getelementptr inbounds [2 x i8***], [2 x i8***]* %557, i64 0, i64 0
  store i8*** %82, i8**** %558, align 8
  %559 = getelementptr inbounds i8***, i8**** %558, i64 1
  store i8*** %82, i8**** %559, align 8
  %560 = getelementptr inbounds [2 x i8***], [2 x i8***]* %557, i64 1
  %561 = getelementptr inbounds [2 x i8***], [2 x i8***]* %560, i64 0, i64 0
  store i8*** %82, i8**** %561, align 8
  %562 = getelementptr inbounds i8***, i8**** %561, i64 1
  store i8*** %82, i8**** %562, align 8
  %563 = getelementptr inbounds [2 x i8***], [2 x i8***]* %560, i64 1
  %564 = getelementptr inbounds [2 x i8***], [2 x i8***]* %563, i64 0, i64 0
  store i8*** %82, i8**** %564, align 8
  %565 = getelementptr inbounds i8***, i8**** %564, i64 1
  store i8*** %82, i8**** %565, align 8
  %566 = getelementptr inbounds [2 x i8***], [2 x i8***]* %563, i64 1
  %567 = getelementptr inbounds [2 x i8***], [2 x i8***]* %566, i64 0, i64 0
  store i8*** %82, i8**** %567, align 8
  %568 = getelementptr inbounds i8***, i8**** %567, i64 1
  store i8*** %82, i8**** %568, align 8
  %569 = getelementptr inbounds [2 x i8***], [2 x i8***]* %566, i64 1
  %570 = getelementptr inbounds [2 x i8***], [2 x i8***]* %569, i64 0, i64 0
  store i8*** %82, i8**** %570, align 8
  %571 = getelementptr inbounds i8***, i8**** %570, i64 1
  store i8*** %82, i8**** %571, align 8
  %572 = getelementptr inbounds [2 x i8***], [2 x i8***]* %569, i64 1
  %573 = getelementptr inbounds [2 x i8***], [2 x i8***]* %572, i64 0, i64 0
  store i8*** %82, i8**** %573, align 8
  %574 = getelementptr inbounds i8***, i8**** %573, i64 1
  store i8*** %82, i8**** %574, align 8
  %575 = getelementptr inbounds [2 x i8***], [2 x i8***]* %572, i64 1
  %576 = getelementptr inbounds [2 x i8***], [2 x i8***]* %575, i64 0, i64 0
  store i8*** %82, i8**** %576, align 8
  %577 = getelementptr inbounds i8***, i8**** %576, i64 1
  store i8*** %82, i8**** %577, align 8
  %578 = getelementptr inbounds [2 x i8***], [2 x i8***]* %575, i64 1
  %579 = getelementptr inbounds [2 x i8***], [2 x i8***]* %578, i64 0, i64 0
  store i8*** %82, i8**** %579, align 8
  %580 = getelementptr inbounds i8***, i8**** %579, i64 1
  store i8*** %82, i8**** %580, align 8
  %581 = getelementptr inbounds [2 x i8***], [2 x i8***]* %578, i64 1
  %582 = getelementptr inbounds [2 x i8***], [2 x i8***]* %581, i64 0, i64 0
  store i8*** %82, i8**** %582, align 8
  %583 = getelementptr inbounds i8***, i8**** %582, i64 1
  store i8*** %82, i8**** %583, align 8
  store i32** @g_1358, i32*** %84, align 8
  store i32*** %84, i32**** %85, align 8
  store i32*** null, i32**** %86, align 8
  %584 = getelementptr inbounds [7 x [7 x [5 x i16*]]], [7 x [7 x [5 x i16*]]]* %87, i64 0, i64 0
  %585 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %584, i64 0, i64 0
  %586 = getelementptr inbounds [5 x i16*], [5 x i16*]* %585, i64 0, i64 0
  store i16* null, i16** %586, align 8
  %587 = getelementptr inbounds i16*, i16** %586, i64 1
  store i16* @g_2056, i16** %587, align 8
  %588 = getelementptr inbounds i16*, i16** %587, i64 1
  store i16* @g_2056, i16** %588, align 8
  %589 = getelementptr inbounds i16*, i16** %588, i64 1
  store i16* %16, i16** %589, align 8
  %590 = getelementptr inbounds i16*, i16** %589, i64 1
  store i16* null, i16** %590, align 8
  %591 = getelementptr inbounds [5 x i16*], [5 x i16*]* %585, i64 1
  %592 = getelementptr inbounds [5 x i16*], [5 x i16*]* %591, i64 0, i64 0
  store i16* %23, i16** %592, align 8
  %593 = getelementptr inbounds i16*, i16** %592, i64 1
  store i16* %27, i16** %593, align 8
  %594 = getelementptr inbounds i16*, i16** %593, i64 1
  store i16* %27, i16** %594, align 8
  %595 = getelementptr inbounds i16*, i16** %594, i64 1
  store i16* %23, i16** %595, align 8
  %596 = getelementptr inbounds i16*, i16** %595, i64 1
  store i16* null, i16** %596, align 8
  %597 = getelementptr inbounds [5 x i16*], [5 x i16*]* %591, i64 1
  %598 = getelementptr inbounds [5 x i16*], [5 x i16*]* %597, i64 0, i64 0
  store i16* %27, i16** %598, align 8
  %599 = getelementptr inbounds i16*, i16** %598, i64 1
  store i16* %16, i16** %599, align 8
  %600 = getelementptr inbounds i16*, i16** %599, i64 1
  store i16* null, i16** %600, align 8
  %601 = getelementptr inbounds i16*, i16** %600, i64 1
  store i16* @g_2056, i16** %601, align 8
  %602 = getelementptr inbounds i16*, i16** %601, i64 1
  store i16* null, i16** %602, align 8
  %603 = getelementptr inbounds [5 x i16*], [5 x i16*]* %597, i64 1
  %604 = getelementptr inbounds [5 x i16*], [5 x i16*]* %603, i64 0, i64 0
  store i16* %23, i16** %604, align 8
  %605 = getelementptr inbounds i16*, i16** %604, i64 1
  store i16* %16, i16** %605, align 8
  %606 = getelementptr inbounds i16*, i16** %605, i64 1
  store i16* null, i16** %606, align 8
  %607 = getelementptr inbounds i16*, i16** %606, i64 1
  store i16* %27, i16** %607, align 8
  %608 = getelementptr inbounds i16*, i16** %607, i64 1
  store i16* %23, i16** %608, align 8
  %609 = getelementptr inbounds [5 x i16*], [5 x i16*]* %603, i64 1
  %610 = getelementptr inbounds [5 x i16*], [5 x i16*]* %609, i64 0, i64 0
  store i16* null, i16** %610, align 8
  %611 = getelementptr inbounds i16*, i16** %610, i64 1
  store i16* @g_2056, i16** %611, align 8
  %612 = getelementptr inbounds i16*, i16** %611, i64 1
  store i16* %16, i16** %612, align 8
  %613 = getelementptr inbounds i16*, i16** %612, i64 1
  store i16* @g_2056, i16** %613, align 8
  %614 = getelementptr inbounds i16*, i16** %613, i64 1
  store i16* null, i16** %614, align 8
  %615 = getelementptr inbounds [5 x i16*], [5 x i16*]* %609, i64 1
  %616 = getelementptr inbounds [5 x i16*], [5 x i16*]* %615, i64 0, i64 0
  store i16* null, i16** %616, align 8
  %617 = getelementptr inbounds i16*, i16** %616, i64 1
  store i16* %27, i16** %617, align 8
  %618 = getelementptr inbounds i16*, i16** %617, i64 1
  store i16* @g_2056, i16** %618, align 8
  %619 = getelementptr inbounds i16*, i16** %618, i64 1
  store i16* %23, i16** %619, align 8
  %620 = getelementptr inbounds i16*, i16** %619, i64 1
  store i16* %16, i16** %620, align 8
  %621 = getelementptr inbounds [5 x i16*], [5 x i16*]* %615, i64 1
  %622 = getelementptr inbounds [5 x i16*], [5 x i16*]* %621, i64 0, i64 0
  store i16* null, i16** %622, align 8
  %623 = getelementptr inbounds i16*, i16** %622, i64 1
  store i16* @g_2056, i16** %623, align 8
  %624 = getelementptr inbounds i16*, i16** %623, i64 1
  store i16* null, i16** %624, align 8
  %625 = getelementptr inbounds i16*, i16** %624, i64 1
  store i16* %16, i16** %625, align 8
  %626 = getelementptr inbounds i16*, i16** %625, i64 1
  store i16* %27, i16** %626, align 8
  %627 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %584, i64 1
  %628 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %627, i64 0, i64 0
  %629 = getelementptr inbounds [5 x i16*], [5 x i16*]* %628, i64 0, i64 0
  store i16* %23, i16** %629, align 8
  %630 = getelementptr inbounds i16*, i16** %629, i64 1
  store i16* %16, i16** %630, align 8
  %631 = getelementptr inbounds i16*, i16** %630, i64 1
  store i16* %27, i16** %631, align 8
  %632 = getelementptr inbounds i16*, i16** %631, i64 1
  store i16* %27, i16** %632, align 8
  %633 = getelementptr inbounds i16*, i16** %632, i64 1
  store i16* %16, i16** %633, align 8
  %634 = getelementptr inbounds [5 x i16*], [5 x i16*]* %628, i64 1
  %635 = getelementptr inbounds [5 x i16*], [5 x i16*]* %634, i64 0, i64 0
  store i16* null, i16** %635, align 8
  %636 = getelementptr inbounds i16*, i16** %635, i64 1
  store i16* %16, i16** %636, align 8
  %637 = getelementptr inbounds i16*, i16** %636, i64 1
  store i16* @g_2056, i16** %637, align 8
  %638 = getelementptr inbounds i16*, i16** %637, i64 1
  store i16* @g_2056, i16** %638, align 8
  %639 = getelementptr inbounds i16*, i16** %638, i64 1
  store i16* null, i16** %639, align 8
  %640 = getelementptr inbounds [5 x i16*], [5 x i16*]* %634, i64 1
  %641 = getelementptr inbounds [5 x i16*], [5 x i16*]* %640, i64 0, i64 0
  store i16* %16, i16** %641, align 8
  %642 = getelementptr inbounds i16*, i16** %641, i64 1
  store i16* %27, i16** %642, align 8
  %643 = getelementptr inbounds i16*, i16** %642, i64 1
  store i16* %27, i16** %643, align 8
  %644 = getelementptr inbounds i16*, i16** %643, i64 1
  store i16* %23, i16** %644, align 8
  %645 = getelementptr inbounds i16*, i16** %644, i64 1
  store i16* %23, i16** %645, align 8
  %646 = getelementptr inbounds [5 x i16*], [5 x i16*]* %640, i64 1
  %647 = getelementptr inbounds [5 x i16*], [5 x i16*]* %646, i64 0, i64 0
  store i16* %27, i16** %647, align 8
  %648 = getelementptr inbounds i16*, i16** %647, i64 1
  store i16* @g_2056, i16** %648, align 8
  %649 = getelementptr inbounds i16*, i16** %648, i64 1
  store i16* null, i16** %649, align 8
  %650 = getelementptr inbounds i16*, i16** %649, i64 1
  store i16* null, i16** %650, align 8
  %651 = getelementptr inbounds i16*, i16** %650, i64 1
  store i16* null, i16** %651, align 8
  %652 = getelementptr inbounds [5 x i16*], [5 x i16*]* %646, i64 1
  %653 = getelementptr inbounds [5 x i16*], [5 x i16*]* %652, i64 0, i64 0
  store i16* %16, i16** %653, align 8
  %654 = getelementptr inbounds i16*, i16** %653, i64 1
  store i16* %16, i16** %654, align 8
  %655 = getelementptr inbounds i16*, i16** %654, i64 1
  store i16* @g_2056, i16** %655, align 8
  %656 = getelementptr inbounds i16*, i16** %655, i64 1
  store i16* %27, i16** %656, align 8
  %657 = getelementptr inbounds i16*, i16** %656, i64 1
  store i16* null, i16** %657, align 8
  %658 = getelementptr inbounds [5 x i16*], [5 x i16*]* %652, i64 1
  %659 = bitcast [5 x i16*]* %658 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %659, i8 0, i64 40, i1 false)
  %660 = getelementptr inbounds [5 x i16*], [5 x i16*]* %658, i64 0, i64 0
  %661 = getelementptr inbounds i16*, i16** %660, i64 1
  %662 = getelementptr inbounds i16*, i16** %661, i64 1
  store i16* %16, i16** %662, align 8
  %663 = getelementptr inbounds i16*, i16** %662, i64 1
  %664 = getelementptr inbounds i16*, i16** %663, i64 1
  %665 = getelementptr inbounds [5 x i16*], [5 x i16*]* %658, i64 1
  %666 = getelementptr inbounds [5 x i16*], [5 x i16*]* %665, i64 0, i64 0
  store i16* %23, i16** %666, align 8
  %667 = getelementptr inbounds i16*, i16** %666, i64 1
  store i16* %27, i16** %667, align 8
  %668 = getelementptr inbounds i16*, i16** %667, i64 1
  store i16* null, i16** %668, align 8
  %669 = getelementptr inbounds i16*, i16** %668, i64 1
  store i16* %23, i16** %669, align 8
  %670 = getelementptr inbounds i16*, i16** %669, i64 1
  store i16* %23, i16** %670, align 8
  %671 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %627, i64 1
  %672 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %671, i64 0, i64 0
  %673 = getelementptr inbounds [5 x i16*], [5 x i16*]* %672, i64 0, i64 0
  store i16* null, i16** %673, align 8
  %674 = getelementptr inbounds i16*, i16** %673, i64 1
  store i16* null, i16** %674, align 8
  %675 = getelementptr inbounds i16*, i16** %674, i64 1
  store i16* null, i16** %675, align 8
  %676 = getelementptr inbounds i16*, i16** %675, i64 1
  store i16* @g_2056, i16** %676, align 8
  %677 = getelementptr inbounds i16*, i16** %676, i64 1
  store i16* %27, i16** %677, align 8
  %678 = getelementptr inbounds [5 x i16*], [5 x i16*]* %672, i64 1
  %679 = getelementptr inbounds [5 x i16*], [5 x i16*]* %678, i64 0, i64 0
  store i16* null, i16** %679, align 8
  %680 = getelementptr inbounds i16*, i16** %679, i64 1
  store i16* %16, i16** %680, align 8
  %681 = getelementptr inbounds i16*, i16** %680, i64 1
  store i16* %27, i16** %681, align 8
  %682 = getelementptr inbounds i16*, i16** %681, i64 1
  store i16* %27, i16** %682, align 8
  %683 = getelementptr inbounds i16*, i16** %682, i64 1
  store i16* %23, i16** %683, align 8
  %684 = getelementptr inbounds [5 x i16*], [5 x i16*]* %678, i64 1
  %685 = getelementptr inbounds [5 x i16*], [5 x i16*]* %684, i64 0, i64 0
  store i16* null, i16** %685, align 8
  %686 = getelementptr inbounds i16*, i16** %685, i64 1
  store i16* @g_2056, i16** %686, align 8
  %687 = getelementptr inbounds i16*, i16** %686, i64 1
  store i16* @g_2056, i16** %687, align 8
  %688 = getelementptr inbounds i16*, i16** %687, i64 1
  store i16* %16, i16** %688, align 8
  %689 = getelementptr inbounds i16*, i16** %688, i64 1
  store i16* null, i16** %689, align 8
  %690 = getelementptr inbounds [5 x i16*], [5 x i16*]* %684, i64 1
  %691 = getelementptr inbounds [5 x i16*], [5 x i16*]* %690, i64 0, i64 0
  store i16* %23, i16** %691, align 8
  %692 = getelementptr inbounds i16*, i16** %691, i64 1
  store i16* %27, i16** %692, align 8
  %693 = getelementptr inbounds i16*, i16** %692, i64 1
  store i16* %27, i16** %693, align 8
  %694 = getelementptr inbounds i16*, i16** %693, i64 1
  store i16* %23, i16** %694, align 8
  %695 = getelementptr inbounds i16*, i16** %694, i64 1
  store i16* null, i16** %695, align 8
  %696 = getelementptr inbounds [5 x i16*], [5 x i16*]* %690, i64 1
  %697 = getelementptr inbounds [5 x i16*], [5 x i16*]* %696, i64 0, i64 0
  store i16* %27, i16** %697, align 8
  %698 = getelementptr inbounds i16*, i16** %697, i64 1
  store i16* %16, i16** %698, align 8
  %699 = getelementptr inbounds i16*, i16** %698, i64 1
  store i16* null, i16** %699, align 8
  %700 = getelementptr inbounds i16*, i16** %699, i64 1
  store i16* @g_2056, i16** %700, align 8
  %701 = getelementptr inbounds i16*, i16** %700, i64 1
  store i16* null, i16** %701, align 8
  %702 = getelementptr inbounds [5 x i16*], [5 x i16*]* %696, i64 1
  %703 = getelementptr inbounds [5 x i16*], [5 x i16*]* %702, i64 0, i64 0
  store i16* %23, i16** %703, align 8
  %704 = getelementptr inbounds i16*, i16** %703, i64 1
  store i16* %16, i16** %704, align 8
  %705 = getelementptr inbounds i16*, i16** %704, i64 1
  store i16* null, i16** %705, align 8
  %706 = getelementptr inbounds i16*, i16** %705, i64 1
  store i16* %27, i16** %706, align 8
  %707 = getelementptr inbounds i16*, i16** %706, i64 1
  store i16* %23, i16** %707, align 8
  %708 = getelementptr inbounds [5 x i16*], [5 x i16*]* %702, i64 1
  %709 = getelementptr inbounds [5 x i16*], [5 x i16*]* %708, i64 0, i64 0
  store i16* null, i16** %709, align 8
  %710 = getelementptr inbounds i16*, i16** %709, i64 1
  store i16* @g_2056, i16** %710, align 8
  %711 = getelementptr inbounds i16*, i16** %710, i64 1
  store i16* %16, i16** %711, align 8
  %712 = getelementptr inbounds i16*, i16** %711, i64 1
  store i16* @g_2056, i16** %712, align 8
  %713 = getelementptr inbounds i16*, i16** %712, i64 1
  store i16* null, i16** %713, align 8
  %714 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %671, i64 1
  %715 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %714, i64 0, i64 0
  %716 = getelementptr inbounds [5 x i16*], [5 x i16*]* %715, i64 0, i64 0
  store i16* null, i16** %716, align 8
  %717 = getelementptr inbounds i16*, i16** %716, i64 1
  store i16* %27, i16** %717, align 8
  %718 = getelementptr inbounds i16*, i16** %717, i64 1
  store i16* @g_2056, i16** %718, align 8
  %719 = getelementptr inbounds i16*, i16** %718, i64 1
  store i16* %23, i16** %719, align 8
  %720 = getelementptr inbounds i16*, i16** %719, i64 1
  store i16* %16, i16** %720, align 8
  %721 = getelementptr inbounds [5 x i16*], [5 x i16*]* %715, i64 1
  %722 = getelementptr inbounds [5 x i16*], [5 x i16*]* %721, i64 0, i64 0
  store i16* null, i16** %722, align 8
  %723 = getelementptr inbounds i16*, i16** %722, i64 1
  store i16* @g_2056, i16** %723, align 8
  %724 = getelementptr inbounds i16*, i16** %723, i64 1
  store i16* null, i16** %724, align 8
  %725 = getelementptr inbounds i16*, i16** %724, i64 1
  store i16* %16, i16** %725, align 8
  %726 = getelementptr inbounds i16*, i16** %725, i64 1
  store i16* %27, i16** %726, align 8
  %727 = getelementptr inbounds [5 x i16*], [5 x i16*]* %721, i64 1
  %728 = getelementptr inbounds [5 x i16*], [5 x i16*]* %727, i64 0, i64 0
  store i16* %23, i16** %728, align 8
  %729 = getelementptr inbounds i16*, i16** %728, i64 1
  store i16* %16, i16** %729, align 8
  %730 = getelementptr inbounds i16*, i16** %729, i64 1
  store i16* %27, i16** %730, align 8
  %731 = getelementptr inbounds i16*, i16** %730, i64 1
  store i16* %27, i16** %731, align 8
  %732 = getelementptr inbounds i16*, i16** %731, i64 1
  store i16* %16, i16** %732, align 8
  %733 = getelementptr inbounds [5 x i16*], [5 x i16*]* %727, i64 1
  %734 = getelementptr inbounds [5 x i16*], [5 x i16*]* %733, i64 0, i64 0
  store i16* null, i16** %734, align 8
  %735 = getelementptr inbounds i16*, i16** %734, i64 1
  store i16* %16, i16** %735, align 8
  %736 = getelementptr inbounds i16*, i16** %735, i64 1
  store i16* @g_2056, i16** %736, align 8
  %737 = getelementptr inbounds i16*, i16** %736, i64 1
  store i16* @g_2056, i16** %737, align 8
  %738 = getelementptr inbounds i16*, i16** %737, i64 1
  store i16* null, i16** %738, align 8
  %739 = getelementptr inbounds [5 x i16*], [5 x i16*]* %733, i64 1
  %740 = getelementptr inbounds [5 x i16*], [5 x i16*]* %739, i64 0, i64 0
  store i16* %16, i16** %740, align 8
  %741 = getelementptr inbounds i16*, i16** %740, i64 1
  store i16* %27, i16** %741, align 8
  %742 = getelementptr inbounds i16*, i16** %741, i64 1
  store i16* %27, i16** %742, align 8
  %743 = getelementptr inbounds i16*, i16** %742, i64 1
  store i16* %23, i16** %743, align 8
  %744 = getelementptr inbounds i16*, i16** %743, i64 1
  store i16* %23, i16** %744, align 8
  %745 = getelementptr inbounds [5 x i16*], [5 x i16*]* %739, i64 1
  %746 = getelementptr inbounds [5 x i16*], [5 x i16*]* %745, i64 0, i64 0
  store i16* %27, i16** %746, align 8
  %747 = getelementptr inbounds i16*, i16** %746, i64 1
  store i16* @g_2056, i16** %747, align 8
  %748 = getelementptr inbounds i16*, i16** %747, i64 1
  store i16* null, i16** %748, align 8
  %749 = getelementptr inbounds i16*, i16** %748, i64 1
  store i16* null, i16** %749, align 8
  %750 = getelementptr inbounds i16*, i16** %749, i64 1
  store i16* null, i16** %750, align 8
  %751 = getelementptr inbounds [5 x i16*], [5 x i16*]* %745, i64 1
  %752 = getelementptr inbounds [5 x i16*], [5 x i16*]* %751, i64 0, i64 0
  store i16* %16, i16** %752, align 8
  %753 = getelementptr inbounds i16*, i16** %752, i64 1
  store i16* %16, i16** %753, align 8
  %754 = getelementptr inbounds i16*, i16** %753, i64 1
  store i16* @g_2056, i16** %754, align 8
  %755 = getelementptr inbounds i16*, i16** %754, i64 1
  store i16* %27, i16** %755, align 8
  %756 = getelementptr inbounds i16*, i16** %755, i64 1
  store i16* null, i16** %756, align 8
  %757 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %714, i64 1
  %758 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %757, i64 0, i64 0
  %759 = bitcast [5 x i16*]* %758 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %759, i8 0, i64 40, i1 false)
  %760 = getelementptr inbounds [5 x i16*], [5 x i16*]* %758, i64 0, i64 0
  %761 = getelementptr inbounds i16*, i16** %760, i64 1
  %762 = getelementptr inbounds i16*, i16** %761, i64 1
  store i16* %16, i16** %762, align 8
  %763 = getelementptr inbounds i16*, i16** %762, i64 1
  %764 = getelementptr inbounds i16*, i16** %763, i64 1
  %765 = getelementptr inbounds [5 x i16*], [5 x i16*]* %758, i64 1
  %766 = getelementptr inbounds [5 x i16*], [5 x i16*]* %765, i64 0, i64 0
  store i16* %23, i16** %766, align 8
  %767 = getelementptr inbounds i16*, i16** %766, i64 1
  store i16* %27, i16** %767, align 8
  %768 = getelementptr inbounds i16*, i16** %767, i64 1
  store i16* null, i16** %768, align 8
  %769 = getelementptr inbounds i16*, i16** %768, i64 1
  store i16* %23, i16** %769, align 8
  %770 = getelementptr inbounds i16*, i16** %769, i64 1
  store i16* %23, i16** %770, align 8
  %771 = getelementptr inbounds [5 x i16*], [5 x i16*]* %765, i64 1
  %772 = getelementptr inbounds [5 x i16*], [5 x i16*]* %771, i64 0, i64 0
  store i16* null, i16** %772, align 8
  %773 = getelementptr inbounds i16*, i16** %772, i64 1
  store i16* null, i16** %773, align 8
  %774 = getelementptr inbounds i16*, i16** %773, i64 1
  store i16* null, i16** %774, align 8
  %775 = getelementptr inbounds i16*, i16** %774, i64 1
  store i16* @g_2056, i16** %775, align 8
  %776 = getelementptr inbounds i16*, i16** %775, i64 1
  store i16* %27, i16** %776, align 8
  %777 = getelementptr inbounds [5 x i16*], [5 x i16*]* %771, i64 1
  %778 = getelementptr inbounds [5 x i16*], [5 x i16*]* %777, i64 0, i64 0
  store i16* null, i16** %778, align 8
  %779 = getelementptr inbounds i16*, i16** %778, i64 1
  store i16* %16, i16** %779, align 8
  %780 = getelementptr inbounds i16*, i16** %779, i64 1
  store i16* %27, i16** %780, align 8
  %781 = getelementptr inbounds i16*, i16** %780, i64 1
  store i16* %27, i16** %781, align 8
  %782 = getelementptr inbounds i16*, i16** %781, i64 1
  store i16* %23, i16** %782, align 8
  %783 = getelementptr inbounds [5 x i16*], [5 x i16*]* %777, i64 1
  %784 = getelementptr inbounds [5 x i16*], [5 x i16*]* %783, i64 0, i64 0
  store i16* null, i16** %784, align 8
  %785 = getelementptr inbounds i16*, i16** %784, i64 1
  store i16* @g_2056, i16** %785, align 8
  %786 = getelementptr inbounds i16*, i16** %785, i64 1
  store i16* @g_2056, i16** %786, align 8
  %787 = getelementptr inbounds i16*, i16** %786, i64 1
  store i16* %16, i16** %787, align 8
  %788 = getelementptr inbounds i16*, i16** %787, i64 1
  store i16* null, i16** %788, align 8
  %789 = getelementptr inbounds [5 x i16*], [5 x i16*]* %783, i64 1
  %790 = getelementptr inbounds [5 x i16*], [5 x i16*]* %789, i64 0, i64 0
  store i16* %23, i16** %790, align 8
  %791 = getelementptr inbounds i16*, i16** %790, i64 1
  store i16* %27, i16** %791, align 8
  %792 = getelementptr inbounds i16*, i16** %791, i64 1
  store i16* %27, i16** %792, align 8
  %793 = getelementptr inbounds i16*, i16** %792, i64 1
  store i16* %23, i16** %793, align 8
  %794 = getelementptr inbounds i16*, i16** %793, i64 1
  store i16* null, i16** %794, align 8
  %795 = getelementptr inbounds [5 x i16*], [5 x i16*]* %789, i64 1
  %796 = getelementptr inbounds [5 x i16*], [5 x i16*]* %795, i64 0, i64 0
  store i16* %27, i16** %796, align 8
  %797 = getelementptr inbounds i16*, i16** %796, i64 1
  store i16* %16, i16** %797, align 8
  %798 = getelementptr inbounds i16*, i16** %797, i64 1
  store i16* null, i16** %798, align 8
  %799 = getelementptr inbounds i16*, i16** %798, i64 1
  store i16* @g_2056, i16** %799, align 8
  %800 = getelementptr inbounds i16*, i16** %799, i64 1
  store i16* null, i16** %800, align 8
  %801 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %757, i64 1
  %802 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %801, i64 0, i64 0
  %803 = getelementptr inbounds [5 x i16*], [5 x i16*]* %802, i64 0, i64 0
  store i16* %23, i16** %803, align 8
  %804 = getelementptr inbounds i16*, i16** %803, i64 1
  store i16* %16, i16** %804, align 8
  %805 = getelementptr inbounds i16*, i16** %804, i64 1
  store i16* null, i16** %805, align 8
  %806 = getelementptr inbounds i16*, i16** %805, i64 1
  store i16* %27, i16** %806, align 8
  %807 = getelementptr inbounds i16*, i16** %806, i64 1
  store i16* %23, i16** %807, align 8
  %808 = getelementptr inbounds [5 x i16*], [5 x i16*]* %802, i64 1
  %809 = getelementptr inbounds [5 x i16*], [5 x i16*]* %808, i64 0, i64 0
  store i16* null, i16** %809, align 8
  %810 = getelementptr inbounds i16*, i16** %809, i64 1
  store i16* @g_2056, i16** %810, align 8
  %811 = getelementptr inbounds i16*, i16** %810, i64 1
  store i16* %16, i16** %811, align 8
  %812 = getelementptr inbounds i16*, i16** %811, i64 1
  store i16* @g_2056, i16** %812, align 8
  %813 = getelementptr inbounds i16*, i16** %812, i64 1
  store i16* null, i16** %813, align 8
  %814 = getelementptr inbounds [5 x i16*], [5 x i16*]* %808, i64 1
  %815 = getelementptr inbounds [5 x i16*], [5 x i16*]* %814, i64 0, i64 0
  store i16* null, i16** %815, align 8
  %816 = getelementptr inbounds i16*, i16** %815, i64 1
  store i16* %27, i16** %816, align 8
  %817 = getelementptr inbounds i16*, i16** %816, i64 1
  store i16* @g_2056, i16** %817, align 8
  %818 = getelementptr inbounds i16*, i16** %817, i64 1
  store i16* %23, i16** %818, align 8
  %819 = getelementptr inbounds i16*, i16** %818, i64 1
  store i16* %16, i16** %819, align 8
  %820 = getelementptr inbounds [5 x i16*], [5 x i16*]* %814, i64 1
  %821 = getelementptr inbounds [5 x i16*], [5 x i16*]* %820, i64 0, i64 0
  store i16* null, i16** %821, align 8
  %822 = getelementptr inbounds i16*, i16** %821, i64 1
  store i16* @g_2056, i16** %822, align 8
  %823 = getelementptr inbounds i16*, i16** %822, i64 1
  store i16* null, i16** %823, align 8
  %824 = getelementptr inbounds i16*, i16** %823, i64 1
  store i16* %16, i16** %824, align 8
  %825 = getelementptr inbounds i16*, i16** %824, i64 1
  store i16* %27, i16** %825, align 8
  %826 = getelementptr inbounds [5 x i16*], [5 x i16*]* %820, i64 1
  %827 = getelementptr inbounds [5 x i16*], [5 x i16*]* %826, i64 0, i64 0
  store i16* %23, i16** %827, align 8
  %828 = getelementptr inbounds i16*, i16** %827, i64 1
  store i16* %16, i16** %828, align 8
  %829 = getelementptr inbounds i16*, i16** %828, i64 1
  store i16* %27, i16** %829, align 8
  %830 = getelementptr inbounds i16*, i16** %829, i64 1
  store i16* %27, i16** %830, align 8
  %831 = getelementptr inbounds i16*, i16** %830, i64 1
  store i16* %16, i16** %831, align 8
  %832 = getelementptr inbounds [5 x i16*], [5 x i16*]* %826, i64 1
  %833 = getelementptr inbounds [5 x i16*], [5 x i16*]* %832, i64 0, i64 0
  store i16* null, i16** %833, align 8
  %834 = getelementptr inbounds i16*, i16** %833, i64 1
  store i16* %16, i16** %834, align 8
  %835 = getelementptr inbounds i16*, i16** %834, i64 1
  store i16* @g_2056, i16** %835, align 8
  %836 = getelementptr inbounds i16*, i16** %835, i64 1
  store i16* @g_2056, i16** %836, align 8
  %837 = getelementptr inbounds i16*, i16** %836, i64 1
  store i16* null, i16** %837, align 8
  %838 = getelementptr inbounds [5 x i16*], [5 x i16*]* %832, i64 1
  %839 = getelementptr inbounds [5 x i16*], [5 x i16*]* %838, i64 0, i64 0
  store i16* %16, i16** %839, align 8
  %840 = getelementptr inbounds i16*, i16** %839, i64 1
  store i16* %27, i16** %840, align 8
  %841 = getelementptr inbounds i16*, i16** %840, i64 1
  store i16* %27, i16** %841, align 8
  %842 = getelementptr inbounds i16*, i16** %841, i64 1
  store i16* %23, i16** %842, align 8
  %843 = getelementptr inbounds i16*, i16** %842, i64 1
  store i16* %23, i16** %843, align 8
  %844 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %801, i64 1
  %845 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %844, i64 0, i64 0
  %846 = getelementptr inbounds [5 x i16*], [5 x i16*]* %845, i64 0, i64 0
  store i16* %27, i16** %846, align 8
  %847 = getelementptr inbounds i16*, i16** %846, i64 1
  store i16* @g_2056, i16** %847, align 8
  %848 = getelementptr inbounds i16*, i16** %847, i64 1
  store i16* null, i16** %848, align 8
  %849 = getelementptr inbounds i16*, i16** %848, i64 1
  store i16* null, i16** %849, align 8
  %850 = getelementptr inbounds i16*, i16** %849, i64 1
  store i16* null, i16** %850, align 8
  %851 = getelementptr inbounds [5 x i16*], [5 x i16*]* %845, i64 1
  %852 = getelementptr inbounds [5 x i16*], [5 x i16*]* %851, i64 0, i64 0
  store i16* %16, i16** %852, align 8
  %853 = getelementptr inbounds i16*, i16** %852, i64 1
  store i16* %16, i16** %853, align 8
  %854 = getelementptr inbounds i16*, i16** %853, i64 1
  store i16* @g_2056, i16** %854, align 8
  %855 = getelementptr inbounds i16*, i16** %854, i64 1
  store i16* %27, i16** %855, align 8
  %856 = getelementptr inbounds i16*, i16** %855, i64 1
  store i16* null, i16** %856, align 8
  %857 = getelementptr inbounds [5 x i16*], [5 x i16*]* %851, i64 1
  %858 = bitcast [5 x i16*]* %857 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %858, i8 0, i64 40, i1 false)
  %859 = getelementptr inbounds [5 x i16*], [5 x i16*]* %857, i64 0, i64 0
  %860 = getelementptr inbounds i16*, i16** %859, i64 1
  %861 = getelementptr inbounds i16*, i16** %860, i64 1
  store i16* %16, i16** %861, align 8
  %862 = getelementptr inbounds i16*, i16** %861, i64 1
  %863 = getelementptr inbounds i16*, i16** %862, i64 1
  %864 = getelementptr inbounds [5 x i16*], [5 x i16*]* %857, i64 1
  %865 = getelementptr inbounds [5 x i16*], [5 x i16*]* %864, i64 0, i64 0
  store i16* %23, i16** %865, align 8
  %866 = getelementptr inbounds i16*, i16** %865, i64 1
  store i16* %27, i16** %866, align 8
  %867 = getelementptr inbounds i16*, i16** %866, i64 1
  store i16* null, i16** %867, align 8
  %868 = getelementptr inbounds i16*, i16** %867, i64 1
  store i16* %23, i16** %868, align 8
  %869 = getelementptr inbounds i16*, i16** %868, i64 1
  store i16* %23, i16** %869, align 8
  %870 = getelementptr inbounds [5 x i16*], [5 x i16*]* %864, i64 1
  %871 = getelementptr inbounds [5 x i16*], [5 x i16*]* %870, i64 0, i64 0
  store i16* null, i16** %871, align 8
  %872 = getelementptr inbounds i16*, i16** %871, i64 1
  store i16* null, i16** %872, align 8
  %873 = getelementptr inbounds i16*, i16** %872, i64 1
  store i16* null, i16** %873, align 8
  %874 = getelementptr inbounds i16*, i16** %873, i64 1
  store i16* @g_2056, i16** %874, align 8
  %875 = getelementptr inbounds i16*, i16** %874, i64 1
  store i16* %27, i16** %875, align 8
  %876 = getelementptr inbounds [5 x i16*], [5 x i16*]* %870, i64 1
  %877 = getelementptr inbounds [5 x i16*], [5 x i16*]* %876, i64 0, i64 0
  store i16* null, i16** %877, align 8
  %878 = getelementptr inbounds i16*, i16** %877, i64 1
  store i16* %16, i16** %878, align 8
  %879 = getelementptr inbounds i16*, i16** %878, i64 1
  store i16* %27, i16** %879, align 8
  %880 = getelementptr inbounds i16*, i16** %879, i64 1
  store i16* %27, i16** %880, align 8
  %881 = getelementptr inbounds i16*, i16** %880, i64 1
  store i16* %23, i16** %881, align 8
  %882 = getelementptr inbounds [5 x i16*], [5 x i16*]* %876, i64 1
  %883 = getelementptr inbounds [5 x i16*], [5 x i16*]* %882, i64 0, i64 0
  store i16* null, i16** %883, align 8
  %884 = getelementptr inbounds i16*, i16** %883, i64 1
  store i16* @g_2056, i16** %884, align 8
  %885 = getelementptr inbounds i16*, i16** %884, i64 1
  store i16* @g_2056, i16** %885, align 8
  %886 = getelementptr inbounds i16*, i16** %885, i64 1
  store i16* %16, i16** %886, align 8
  %887 = getelementptr inbounds i16*, i16** %886, i64 1
  store i16* null, i16** %887, align 8
  store i32***** null, i32****** %88, align 8
  store i32 0, i32* %89, align 4
  br label %888

888:                                              ; preds = %895, %552
  %889 = load i32, i32* %89, align 4
  %890 = icmp slt i32 %889, 9
  br i1 %890, label %891, label %898

891:                                              ; preds = %888
  %892 = load i32, i32* %89, align 4
  %893 = sext i32 %892 to i64
  %894 = getelementptr inbounds [9 x i64], [9 x i64]* %81, i64 0, i64 %893
  store i64 8597371422289567780, i64* %894, align 8
  br label %895

895:                                              ; preds = %891
  %896 = load i32, i32* %89, align 4
  %897 = add nsw i32 %896, 1
  store i32 %897, i32* %89, align 4
  br label %888

898:                                              ; preds = %888
  store i16 0, i16* @g_1205, align 2
  br label %899

899:                                              ; preds = %1102, %898
  %900 = load i16, i16* @g_1205, align 2
  %901 = sext i16 %900 to i32
  %902 = icmp eq i32 %901, 12
  br i1 %902, label %903, label %1105

903:                                              ; preds = %899
  store i32** @g_797, i32*** %92, align 8
  store i64* null, i64** %93, align 8
  store i64* null, i64** %94, align 8
  store i64* %21, i64** %95, align 8
  store i32 1343035705, i32* %96, align 4
  store i32 -548330438, i32* %97, align 4
  store i8 -16, i8* %98, align 1
  %904 = load i16*, i16** @g_369, align 8
  %905 = load i16, i16* %904, align 2
  %906 = sext i16 %905 to i64
  %907 = load i32**, i32*** %92, align 8
  %908 = load i32***, i32**** @g_2591, align 8
  store i32** %907, i32*** %908, align 8
  %909 = load i32**, i32*** %73, align 8
  store i32** %909, i32*** %73, align 8
  store i32** %909, i32*** bitcast (i8* getelementptr (i8, i8* bitcast ([6 x [10 x i32**]]* @g_2780 to i8*), i64 360) to i32***), align 8
  %910 = icmp ne i32** %907, %909
  br i1 %910, label %1004, label %911

911:                                              ; preds = %903
  %912 = load i16, i16* %10, align 2
  %913 = zext i16 %912 to i32
  %914 = load i8, i8* %58, align 1
  %915 = zext i8 %914 to i32
  %916 = load i64, i64* %7, align 8
  %917 = load i64, i64* %8, align 8
  %918 = icmp ule i64 0, %917
  %919 = zext i1 %918 to i32
  %920 = trunc i32 %919 to i16
  %921 = call zeroext i16 @safe_unary_minus_func_uint16_t_u(i16 zeroext %920)
  %922 = zext i16 %921 to i32
  %923 = load i32**, i32*** @g_421, align 8
  %924 = load i32*, i32** %923, align 8
  %925 = load i32, i32* %924, align 4
  %926 = xor i32 %925, %922
  store i32 %926, i32* %924, align 4
  %927 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %928 = getelementptr inbounds [9 x i32], [9 x i32]* %927, i64 0, i64 7
  %929 = load i32, i32* %928, align 4
  %930 = trunc i32 %929 to i16
  %931 = load i64, i64* %7, align 8
  %932 = trunc i64 %931 to i32
  %933 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %930, i32 %932)
  %934 = sext i16 %933 to i64
  %935 = or i64 %934, 1
  %936 = load i8, i8* %58, align 1
  %937 = zext i8 %936 to i64
  %938 = icmp uge i64 %935, %937
  %939 = zext i1 %938 to i32
  %940 = sext i32 %939 to i64
  %941 = or i64 %940, -3
  %942 = load i64*, i64** @g_2097, align 8
  store i64 %941, i64* %942, align 8
  %943 = load i64****, i64***** @g_1636, align 8
  %944 = load i64***, i64**** %943, align 8
  %945 = load i64**, i64*** %944, align 8
  %946 = load volatile i64*, i64** %945, align 8
  %947 = load volatile i64, i64* %946, align 8
  %948 = icmp ugt i64 %941, %947
  %949 = zext i1 %948 to i32
  %950 = call i32 @safe_add_func_int32_t_s_s(i32 %926, i32 %949)
  %951 = sext i32 %950 to i64
  %952 = icmp ne i64 %951, 8
  %953 = zext i1 %952 to i32
  %954 = sext i32 %953 to i64
  %955 = icmp sgt i64 %954, 1
  %956 = zext i1 %955 to i32
  %957 = load i8, i8* @g_3033, align 1
  %958 = zext i8 %957 to i32
  %959 = and i32 %956, %958
  %960 = trunc i32 %959 to i8
  %961 = load i8*, i8** @g_1167, align 8
  store i8 %960, i8* %961, align 1
  %962 = load i64, i64* %8, align 8
  %963 = icmp ne i64 %916, %962
  %964 = zext i1 %963 to i32
  %965 = sext i32 %964 to i64
  %966 = load i64, i64* %7, align 8
  %967 = icmp ult i64 %965, %966
  %968 = zext i1 %967 to i32
  %969 = sext i32 %968 to i64
  %970 = load i64*, i64** %95, align 8
  store i64 %969, i64* %970, align 8
  %971 = call i64 @safe_sub_func_int64_t_s_s(i64 %969, i64 -2543835962870574135)
  %972 = icmp ne i64 %971, 567061476
  %973 = zext i1 %972 to i32
  %974 = trunc i32 %973 to i16
  %975 = call zeroext i16 @safe_mod_func_uint16_t_u_u(i16 zeroext %974, i16 zeroext -13862)
  %976 = zext i16 %975 to i32
  %977 = icmp ne i32 %915, %976
  %978 = zext i1 %977 to i32
  %979 = icmp slt i32 %913, %978
  %980 = zext i1 %979 to i32
  %981 = sext i32 %980 to i64
  store i64 %981, i64* %7, align 8
  %982 = load i64**, i64*** @g_2495, align 8
  %983 = load i64*, i64** %982, align 8
  %984 = load volatile i64, i64* %983, align 8
  %985 = icmp ne i64 %984, 0
  br i1 %985, label %990, label %986

986:                                              ; preds = %911
  %987 = load i8, i8* %58, align 1
  %988 = zext i8 %987 to i32
  %989 = icmp ne i32 %988, 0
  br label %990

990:                                              ; preds = %986, %911
  %991 = phi i1 [ true, %911 ], [ %989, %986 ]
  %992 = zext i1 %991 to i32
  %993 = load i32, i32* %96, align 4
  %994 = xor i32 %992, %993
  %995 = trunc i32 %994 to i8
  %996 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %997 = getelementptr inbounds [9 x i32], [9 x i32]* %996, i64 0, i64 7
  %998 = load i32, i32* %997, align 4
  %999 = trunc i32 %998 to i8
  %1000 = call zeroext i8 @safe_sub_func_uint8_t_u_u(i8 zeroext %995, i8 zeroext %999)
  %1001 = zext i8 %1000 to i32
  %1002 = xor i32 %1001, -1
  %1003 = icmp ne i32 %1002, 0
  br label %1004

1004:                                             ; preds = %990, %903
  %1005 = phi i1 [ true, %903 ], [ %1003, %990 ]
  %1006 = zext i1 %1005 to i32
  %1007 = trunc i32 %1006 to i8
  %1008 = load i8, i8* %58, align 1
  %1009 = call signext i8 @safe_mul_func_int8_t_s_s(i8 signext %1007, i8 signext %1008)
  %1010 = or i64 %906, 1
  %1011 = load i8*, i8** %9, align 8
  %1012 = load i8, i8* %1011, align 1
  %1013 = sext i8 %1012 to i32
  %1014 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %1015 = getelementptr inbounds [9 x i32], [9 x i32]* %1014, i64 0, i64 7
  %1016 = load i32, i32* %1015, align 4
  %1017 = or i32 %1013, %1016
  %1018 = sext i32 %1017 to i64
  %1019 = icmp eq i64 %1018, 135
  %1020 = zext i1 %1019 to i32
  %1021 = load i16, i16* %10, align 2
  %1022 = zext i16 %1021 to i32
  %1023 = and i32 %1020, %1022
  %1024 = trunc i32 %1023 to i16
  %1025 = load i32, i32* %96, align 4
  %1026 = call signext i16 @safe_lshift_func_int16_t_s_s(i16 signext %1024, i32 %1025)
  %1027 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 2
  %1028 = getelementptr inbounds [9 x i32], [9 x i32]* %1027, i64 0, i64 4
  %1029 = load i32, i32* %1028, align 8
  %1030 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %1031 = getelementptr inbounds [9 x i32], [9 x i32]* %1030, i64 0, i64 7
  store i32 %1029, i32* %1031, align 4
  %1032 = load i32, i32* %97, align 4
  %1033 = or i32 %1032, %1029
  store i32 %1033, i32* %97, align 4
  %1034 = load i64**, i64*** @g_1638, align 8
  %1035 = load volatile i64*, i64** %1034, align 8
  %1036 = load volatile i64, i64* %1035, align 8
  %1037 = load i64, i64* %8, align 8
  %1038 = load i64, i64* %7, align 8
  %1039 = xor i64 %1037, %1038
  %1040 = load i64, i64* %7, align 8
  %1041 = load i64, i64* %7, align 8
  %1042 = load i64, i64* %8, align 8
  %1043 = trunc i64 %1042 to i32
  %1044 = call i32 @safe_add_func_uint32_t_u_u(i32 %1043, i32 -1071974190)
  %1045 = load i8, i8* %58, align 1
  %1046 = zext i8 %1045 to i64
  %1047 = call i64 @safe_mod_func_int64_t_s_s(i64 %1046, i64 6585831862241988581)
  %1048 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %1049 = getelementptr inbounds [9 x i32], [9 x i32]* %1048, i64 0, i64 7
  %1050 = load i32, i32* %1049, align 4
  %1051 = sext i32 %1050 to i64
  %1052 = icmp ne i64 %1047, %1051
  %1053 = zext i1 %1052 to i32
  %1054 = load i64**, i64*** @g_2495, align 8
  %1055 = load i64*, i64** %1054, align 8
  %1056 = load i64**, i64*** @g_2495, align 8
  %1057 = load i64*, i64** %1056, align 8
  %1058 = icmp eq i64* %1055, %1057
  %1059 = zext i1 %1058 to i32
  %1060 = trunc i32 %1059 to i16
  %1061 = call signext i16 @safe_mul_func_int16_t_s_s(i16 signext %1060, i16 signext -6534)
  %1062 = sext i16 %1061 to i32
  %1063 = icmp ugt i32 %1044, %1062
  %1064 = zext i1 %1063 to i32
  %1065 = sext i32 %1064 to i64
  %1066 = xor i64 %1041, %1065
  %1067 = load i16, i16* %10, align 2
  %1068 = zext i16 %1067 to i64
  %1069 = xor i64 %1066, %1068
  %1070 = load i64*, i64** %95, align 8
  %1071 = load i64, i64* %1070, align 8
  %1072 = or i64 %1071, %1069
  store i64 %1072, i64* %1070, align 8
  %1073 = load i64, i64* @g_617, align 8
  %1074 = or i64 %1073, %1072
  store i64 %1074, i64* @g_617, align 8
  %1075 = trunc i64 %1074 to i32
  store i32 %1075, i32* %97, align 4
  %1076 = sext i32 %1075 to i64
  %1077 = icmp eq i64 %1036, %1076
  %1078 = zext i1 %1077 to i32
  %1079 = load i32*, i32** %18, align 8
  %1080 = load i32, i32* %1079, align 4
  %1081 = or i32 %1080, %1078
  store i32 %1081, i32* %1079, align 4
  %1082 = sext i32 %1081 to i64
  %1083 = icmp eq i64 2515676143, %1082
  %1084 = zext i1 %1083 to i32
  %1085 = load i8, i8* %58, align 1
  %1086 = zext i8 %1085 to i32
  %1087 = icmp slt i32 %1084, %1086
  %1088 = zext i1 %1087 to i32
  %1089 = trunc i32 %1088 to i8
  %1090 = call signext i8 @safe_mod_func_int8_t_s_s(i8 signext %1089, i8 signext 3)
  %1091 = sext i8 %1090 to i32
  %1092 = load i32, i32* %96, align 4
  %1093 = icmp sgt i32 %1091, %1092
  %1094 = zext i1 %1093 to i32
  %1095 = sext i32 %1094 to i64
  %1096 = load i16, i16* %10, align 2
  %1097 = zext i16 %1096 to i64
  %1098 = call i64 @safe_mod_func_uint64_t_u_u(i64 %1095, i64 %1097)
  %1099 = trunc i64 %1098 to i32
  store i32 %1099, i32* %96, align 4
  %1100 = load i8, i8* %98, align 1
  %1101 = add i8 %1100, 1
  store i8 %1101, i8* %98, align 1
  br label %1102

1102:                                             ; preds = %1004
  %1103 = load i16, i16* @g_1205, align 2
  %1104 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %1103, i16 zeroext 1)
  store i16 %1104, i16* @g_1205, align 2
  br label %899

1105:                                             ; preds = %899
  %1106 = load i64, i64* %7, align 8
  %1107 = icmp ne i64 %1106, 0
  br i1 %1107, label %1108, label %1113

1108:                                             ; preds = %1105
  %1109 = load i32, i32* @g_12, align 4
  %1110 = icmp ne i32 %1109, 0
  br i1 %1110, label %1111, label %1112

1111:                                             ; preds = %1108
  br label %448

1112:                                             ; preds = %1108
  br label %2292

1113:                                             ; preds = %1105
  store i64 0, i64* %99, align 8
  store i64* null, i64** %100, align 8
  store i32*** @g_421, i32**** %101, align 8
  store %union.U0* null, %union.U0** %102, align 8
  store i32 -1172572450, i32* %103, align 4
  store i8*** @g_340, i8**** %104, align 8
  store i8**** %104, i8***** %105, align 8
  store i8 6, i8* %106, align 1
  store i32 -1784632100, i32* %107, align 4
  store i64* null, i64** %108, align 8
  %1114 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1114, i64** %109, align 8
  %1115 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %1116 = getelementptr inbounds [9 x i32], [9 x i32]* %1115, i64 0, i64 7
  %1117 = load i32, i32* %1116, align 4
  %1118 = load i8*, i8** %9, align 8
  %1119 = load i8, i8* %1118, align 1
  %1120 = sext i8 %1119 to i64
  %1121 = load i64, i64* %99, align 8
  %1122 = getelementptr inbounds [10 x i64*****], [10 x i64*****]* %66, i64 0, i64 9
  %1123 = load i64*****, i64****** %1122, align 8
  %1124 = load i64*****, i64****** %31, align 8
  %1125 = icmp eq i64***** %1123, %1124
  %1126 = zext i1 %1125 to i32
  %1127 = sext i32 %1126 to i64
  %1128 = or i64 %1121, %1127
  %1129 = trunc i64 %1128 to i32
  %1130 = load i64, i64* %7, align 8
  %1131 = load i64, i64* %99, align 8
  %1132 = trunc i64 %1131 to i8
  %1133 = call signext i8 @safe_div_func_int8_t_s_s(i8 signext -55, i8 signext %1132)
  %1134 = sext i8 %1133 to i64
  %1135 = icmp eq i64 %1134, 0
  %1136 = zext i1 %1135 to i32
  %1137 = sext i32 %1136 to i64
  %1138 = icmp ugt i64 %1130, %1137
  %1139 = zext i1 %1138 to i32
  %1140 = trunc i32 %1139 to i16
  %1141 = call signext i16 @safe_unary_minus_func_int16_t_s(i16 signext %1140)
  %1142 = sext i16 %1141 to i32
  %1143 = call i32 @safe_add_func_int32_t_s_s(i32 %1129, i32 %1142)
  %1144 = trunc i32 %1143 to i8
  %1145 = load i8*, i8** %9, align 8
  %1146 = load i8, i8* %1145, align 1
  %1147 = call zeroext i8 @safe_sub_func_uint8_t_u_u(i8 zeroext %1144, i8 zeroext %1146)
  %1148 = load i64, i64* %99, align 8
  %1149 = icmp ne i64 %1148, 0
  br i1 %1149, label %1150, label %1157

1150:                                             ; preds = %1113
  %1151 = load volatile i64***, i64**** @g_2498, align 8
  %1152 = load i64**, i64*** %1151, align 8
  %1153 = load i64*, i64** %1152, align 8
  %1154 = load volatile i64, i64* %1153, align 8
  %1155 = icmp ne i64 %1154, 0
  br i1 %1155, label %1156, label %1157

1156:                                             ; preds = %1150
  br label %1157

1157:                                             ; preds = %1156, %1150, %1113
  %1158 = phi i1 [ false, %1150 ], [ false, %1113 ], [ true, %1156 ]
  %1159 = zext i1 %1158 to i32
  %1160 = xor i32 %1159, -1
  %1161 = sext i32 %1160 to i64
  %1162 = icmp ne i64 %1161, 5955888468334174443
  %1163 = zext i1 %1162 to i32
  %1164 = sext i32 %1163 to i64
  %1165 = load i64, i64* %99, align 8
  %1166 = icmp ult i64 %1164, %1165
  br i1 %1166, label %1167, label %1172

1167:                                             ; preds = %1157
  %1168 = load i16*, i16** @g_369, align 8
  %1169 = load i16, i16* %1168, align 2
  %1170 = sext i16 %1169 to i32
  %1171 = icmp ne i32 %1170, 0
  br label %1172

1172:                                             ; preds = %1167, %1157
  %1173 = phi i1 [ false, %1157 ], [ %1171, %1167 ]
  %1174 = zext i1 %1173 to i32
  %1175 = sext i32 %1174 to i64
  %1176 = load i64, i64* %7, align 8
  %1177 = icmp ult i64 %1175, %1176
  %1178 = zext i1 %1177 to i32
  %1179 = sext i32 %1178 to i64
  %1180 = load i64, i64* %8, align 8
  %1181 = icmp slt i64 %1179, %1180
  %1182 = zext i1 %1181 to i32
  %1183 = sext i32 %1182 to i64
  %1184 = icmp sle i64 54462, %1183
  %1185 = zext i1 %1184 to i32
  %1186 = load i64*, i64** @g_2496, align 8
  %1187 = load volatile i64, i64* %1186, align 8
  %1188 = load i64*, i64** @g_2097, align 8
  %1189 = load i64, i64* %1188, align 8
  %1190 = call i64 @safe_mod_func_int64_t_s_s(i64 %1187, i64 %1189)
  %1191 = icmp sle i64 %1190, 21967
  %1192 = zext i1 %1191 to i32
  %1193 = load i8, i8* %75, align 1
  %1194 = zext i8 %1193 to i32
  %1195 = icmp sgt i32 %1192, %1194
  %1196 = zext i1 %1195 to i32
  %1197 = trunc i32 %1196 to i16
  %1198 = load i64, i64* %8, align 8
  %1199 = trunc i64 %1198 to i32
  %1200 = call signext i16 @safe_lshift_func_int16_t_s_s(i16 signext %1197, i32 %1199)
  %1201 = sext i16 %1200 to i64
  %1202 = icmp eq i64 %1201, 1
  %1203 = zext i1 %1202 to i32
  %1204 = sext i32 %1203 to i64
  %1205 = or i64 %1204, 2655158245
  %1206 = load i64, i64* %8, align 8
  %1207 = icmp sle i64 %1120, %1206
  %1208 = zext i1 %1207 to i32
  %1209 = trunc i32 %1208 to i8
  %1210 = call signext i8 @safe_lshift_func_int8_t_s_u(i8 signext %1209, i32 3)
  %1211 = sext i8 %1210 to i64
  %1212 = or i64 1, %1211
  %1213 = trunc i64 %1212 to i8
  %1214 = load i64, i64* %8, align 8
  %1215 = trunc i64 %1214 to i32
  %1216 = call signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %1213, i32 %1215)
  %1217 = sext i8 %1216 to i32
  %1218 = xor i32 %1117, %1217
  %1219 = sext i32 %1218 to i64
  %1220 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64 %1219, i64* %1220, align 8
  %1221 = load i32, i32* @g_2742, align 4
  %1222 = sext i32 %1221 to i64
  %1223 = call i64 @safe_div_func_int64_t_s_s(i64 %1219, i64 %1222)
  %1224 = icmp ult i64 %1223, -1
  br i1 %1224, label %1225, label %1290

1225:                                             ; preds = %1172
  store %union.U0* null, %union.U0** %110, align 8
  store i32*** @g_421, i32**** %111, align 8
  store i32 24, i32* @g_868, align 4
  br label %1226

1226:                                             ; preds = %1286, %1225
  %1227 = load i32, i32* @g_868, align 4
  %1228 = icmp sgt i32 %1227, 15
  br i1 %1228, label %1229, label %1289

1229:                                             ; preds = %1226
  store i32* @g_216, i32** %112, align 8
  store i32** %112, i32*** %113, align 8
  store i32 -187000658, i32* %114, align 4
  %1230 = bitcast [5 x i32****]* %115 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %1230, i8 0, i64 40, i1 false)
  %1231 = bitcast i8* %1230 to [5 x i32****]*
  %1232 = getelementptr inbounds [5 x i32****], [5 x i32****]* %1231, i32 0, i32 0
  store i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32***** %1232, align 16
  %1233 = getelementptr inbounds [5 x i32****], [5 x i32****]* %1231, i32 0, i32 1
  store i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32***** %1233, align 8
  %1234 = getelementptr inbounds [5 x i32****], [5 x i32****]* %1231, i32 0, i32 2
  store i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32***** %1234, align 16
  %1235 = getelementptr inbounds [5 x i32****], [5 x i32****]* %1231, i32 0, i32 3
  store i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32***** %1235, align 8
  %1236 = getelementptr inbounds [5 x i32****], [5 x i32****]* %1231, i32 0, i32 4
  store i32**** bitcast (i8* getelementptr (i8, i8* bitcast ([9 x [4 x i32***]]* @g_2258 to i8*), i64 88) to i32****), i32***** %1236, align 16
  store i16 -30156, i16* %116, align 2
  %1237 = load i64, i64* %99, align 8
  %1238 = icmp ne i64 %1237, 0
  br i1 %1238, label %1239, label %1240

1239:                                             ; preds = %1229
  br label %1289

1240:                                             ; preds = %1229
  %1241 = load %union.U0*, %union.U0** %110, align 8
  %1242 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %1243 = load %union.U0*, %union.U0** %1242, align 8
  %1244 = call i32* @func_52(%union.U0* %1241, %union.U0* %1243)
  %1245 = load i32**, i32*** %113, align 8
  store i32* %1244, i32** %1245, align 8
  %1246 = getelementptr inbounds [8 x i32*], [8 x i32*]* %19, i64 0, i64 0
  %1247 = load i32*, i32** %1246, align 16
  %1248 = icmp ne i32* %1244, %1247
  %1249 = zext i1 %1248 to i32
  %1250 = load i16, i16* %10, align 2
  %1251 = zext i16 %1250 to i32
  %1252 = or i32 %1251, %1249
  %1253 = trunc i32 %1252 to i16
  store i16 %1253, i16* %10, align 2
  %1254 = zext i16 %1253 to i32
  store i32 %1254, i32* %114, align 4
  %1255 = load i32***, i32**** %67, align 8
  %1256 = load i32***, i32**** %111, align 8
  store i32*** %1256, i32**** %101, align 8
  %1257 = icmp eq i32*** %1255, %1256
  %1258 = zext i1 %1257 to i32
  %1259 = load i8*, i8** %9, align 8
  %1260 = load i8, i8* %1259, align 1
  %1261 = sext i8 %1260 to i64
  %1262 = icmp sle i64 %1261, 109
  %1263 = zext i1 %1262 to i32
  %1264 = icmp eq i32 %1258, %1263
  %1265 = zext i1 %1264 to i32
  %1266 = load i64**, i64*** %76, align 8
  %1267 = icmp eq i64** null, %1266
  %1268 = zext i1 %1267 to i32
  %1269 = sext i32 %1268 to i64
  %1270 = load i64, i64* %7, align 8
  %1271 = or i64 %1269, %1270
  %1272 = load i16*, i16** @g_369, align 8
  %1273 = load i16, i16* %1272, align 2
  %1274 = sext i16 %1273 to i32
  %1275 = load i16, i16* %77, align 2
  %1276 = sext i16 %1275 to i32
  %1277 = icmp slt i32 %1274, %1276
  %1278 = zext i1 %1277 to i32
  %1279 = load i64, i64* %99, align 8
  %1280 = trunc i64 %1279 to i32
  %1281 = call i32 @safe_div_func_uint32_t_u_u(i32 %1278, i32 %1280)
  %1282 = load i16, i16* %116, align 2
  %1283 = sext i16 %1282 to i32
  %1284 = xor i32 %1283, %1281
  %1285 = trunc i32 %1284 to i16
  store i16 %1285, i16* %116, align 2
  br label %1286

1286:                                             ; preds = %1240
  %1287 = load i32, i32* @g_868, align 4
  %1288 = call i32 @safe_sub_func_int32_t_s_s(i32 %1287, i32 6)
  store i32 %1288, i32* @g_868, align 4
  br label %1226

1289:                                             ; preds = %1239, %1226
  br label %2011

1290:                                             ; preds = %1172
  store i32 -111543327, i32* %118, align 4
  %1291 = getelementptr inbounds [8 x i64*], [8 x i64*]* %119, i64 0, i64 0
  %1292 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1292, i64** %1291, align 8
  %1293 = getelementptr inbounds i64*, i64** %1291, i64 1
  %1294 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1294, i64** %1293, align 8
  %1295 = getelementptr inbounds i64*, i64** %1293, i64 1
  %1296 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1296, i64** %1295, align 8
  %1297 = getelementptr inbounds i64*, i64** %1295, i64 1
  %1298 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1298, i64** %1297, align 8
  %1299 = getelementptr inbounds i64*, i64** %1297, i64 1
  %1300 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1300, i64** %1299, align 8
  %1301 = getelementptr inbounds i64*, i64** %1299, i64 1
  %1302 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1302, i64** %1301, align 8
  %1303 = getelementptr inbounds i64*, i64** %1301, i64 1
  %1304 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1304, i64** %1303, align 8
  %1305 = getelementptr inbounds i64*, i64** %1303, i64 1
  %1306 = getelementptr inbounds [4 x i64], [4 x i64]* %32, i64 0, i64 3
  store i64* %1306, i64** %1305, align 8
  %1307 = bitcast [5 x i32]* %120 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %1307, i8* align 16 bitcast ([5 x i32]* @__const.func_6.l_3123 to i8*), i64 20, i1 false)
  store i32* null, i32** %121, align 8
  store i32* %28, i32** %122, align 8
  %1308 = bitcast [7 x i32]* %123 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %1308, i8* align 16 bitcast ([7 x i32]* @__const.func_6.l_3140 to i8*), i64 28, i1 false)
  store i64** null, i64*** %124, align 8
  store i16 -7335, i16* %125, align 2
  store i32* getelementptr inbounds ([9 x [9 x [3 x i32]]], [9 x [9 x [3 x i32]]]* @g_1269, i64 0, i64 0, i64 8, i64 2), i32** %126, align 8
  store i16***** %36, i16****** %127, align 8
  store i16* %27, i16** %128, align 8
  store i8* @g_82, i8** %129, align 8
  %1309 = load i16, i16* %77, align 2
  %1310 = load i32, i32* %118, align 4
  %1311 = trunc i32 %1310 to i16
  %1312 = load i16, i16* %10, align 2
  %1313 = load i32, i32* %118, align 4
  %1314 = load i64**, i64*** @g_2495, align 8
  %1315 = load i64*, i64** %1314, align 8
  %1316 = load volatile i64, i64* %1315, align 8
  %1317 = trunc i64 %1316 to i32
  %1318 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  store i32 %1317, i32* %1318, align 4
  %1319 = icmp slt i32 %1317, 1
  %1320 = zext i1 %1319 to i32
  %1321 = trunc i32 %1320 to i16
  %1322 = load i16, i16* %10, align 2
  %1323 = call signext i16 @safe_div_func_int16_t_s_s(i16 signext %1321, i16 signext %1322)
  %1324 = load i16, i16* %10, align 2
  %1325 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %1326 = getelementptr inbounds [9 x i32], [9 x i32]* %1325, i64 0, i64 7
  %1327 = load i32, i32* %1326, align 4
  %1328 = trunc i32 %1327 to i16
  %1329 = load i16*, i16** @g_369, align 8
  store i16 %1328, i16* %1329, align 2
  %1330 = load i16, i16* %10, align 2
  %1331 = call signext i16 @safe_sub_func_int16_t_s_s(i16 signext %1328, i16 signext %1330)
  %1332 = sext i16 %1331 to i32
  %1333 = load i8*, i8** %9, align 8
  %1334 = load i8, i8* %1333, align 1
  %1335 = sext i8 %1334 to i32
  %1336 = xor i32 %1332, %1335
  %1337 = sext i32 %1336 to i64
  %1338 = icmp uge i64 0, %1337
  br i1 %1338, label %1344, label %1339

1339:                                             ; preds = %1290
  %1340 = load i8*, i8** %9, align 8
  %1341 = load i8, i8* %1340, align 1
  %1342 = sext i8 %1341 to i32
  %1343 = icmp ne i32 %1342, 0
  br label %1344

1344:                                             ; preds = %1339, %1290
  %1345 = phi i1 [ true, %1290 ], [ %1343, %1339 ]
  %1346 = zext i1 %1345 to i32
  %1347 = icmp eq i32 %1313, %1346
  %1348 = zext i1 %1347 to i32
  %1349 = load i32*, i32** @g_422, align 8
  %1350 = load i32, i32* %1349, align 4
  %1351 = xor i32 %1350, %1348
  store i32 %1351, i32* %1349, align 4
  %1352 = load i64, i64* %7, align 8
  %1353 = trunc i64 %1352 to i32
  %1354 = call i32 @safe_mod_func_int32_t_s_s(i32 %1351, i32 %1353)
  %1355 = icmp ne i32 %1354, 0
  br i1 %1355, label %1362, label %1356

1356:                                             ; preds = %1344
  %1357 = load i32***, i32**** %67, align 8
  %1358 = load i32**, i32*** %1357, align 8
  %1359 = load i32*, i32** %1358, align 8
  %1360 = load i32, i32* %1359, align 4
  %1361 = icmp ne i32 %1360, 0
  br label %1362

1362:                                             ; preds = %1356, %1344
  %1363 = phi i1 [ true, %1344 ], [ %1361, %1356 ]
  %1364 = zext i1 %1363 to i32
  %1365 = sext i32 %1364 to i64
  %1366 = icmp ne i64 %1365, 211
  br i1 %1366, label %1368, label %1367

1367:                                             ; preds = %1362
  br label %1368

1368:                                             ; preds = %1367, %1362
  %1369 = phi i1 [ true, %1362 ], [ true, %1367 ]
  %1370 = zext i1 %1369 to i32
  %1371 = sext i32 %1370 to i64
  %1372 = load i64, i64* %8, align 8
  %1373 = call i64 @safe_sub_func_int64_t_s_s(i64 %1371, i64 %1372)
  %1374 = load i16, i16* %10, align 2
  %1375 = zext i16 %1374 to i32
  %1376 = load i32, i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 0), align 8
  %1377 = and i32 %1375, %1376
  %1378 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 3
  %1379 = getelementptr inbounds [9 x i32], [9 x i32]* %1378, i64 0, i64 6
  %1380 = load i32, i32* %1379, align 4
  %1381 = call i32 @safe_sub_func_uint32_t_u_u(i32 %1377, i32 %1380)
  %1382 = zext i32 %1381 to i64
  %1383 = load i64, i64* %8, align 8
  %1384 = and i64 %1382, %1383
  %1385 = icmp ne i64 %1384, 1
  %1386 = zext i1 %1385 to i32
  %1387 = load i16*, i16** @g_369, align 8
  %1388 = load i16, i16* %1387, align 2
  %1389 = load i64, i64* %8, align 8
  %1390 = trunc i64 %1389 to i16
  %1391 = call signext i16 @safe_add_func_int16_t_s_s(i16 signext %1388, i16 signext %1390)
  %1392 = sext i16 %1391 to i32
  %1393 = call zeroext i16 @safe_lshift_func_uint16_t_u_s(i16 zeroext %1311, i32 %1392)
  %1394 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %1395 = getelementptr inbounds [9 x i32], [9 x i32]* %1394, i64 0, i64 7
  %1396 = load i32, i32* %1395, align 4
  %1397 = sext i32 %1396 to i64
  %1398 = load i64****, i64***** %30, align 8
  %1399 = load i64***, i64**** %1398, align 8
  %1400 = load i64**, i64*** %1399, align 8
  %1401 = load i64*, i64** %1400, align 8
  store i64 %1397, i64* %1401, align 8
  %1402 = load i64, i64* %8, align 8
  %1403 = icmp eq i64 %1397, %1402
  %1404 = zext i1 %1403 to i32
  %1405 = load i32*, i32** %122, align 8
  store i32 %1404, i32* %1405, align 4
  %1406 = load i64, i64* %8, align 8
  %1407 = icmp ne i64 0, %1406
  %1408 = zext i1 %1407 to i32
  %1409 = trunc i32 %1408 to i16
  %1410 = call signext i16 @safe_mul_func_int16_t_s_s(i16 signext %1309, i16 signext %1409)
  %1411 = trunc i16 %1410 to i8
  %1412 = load i32, i32* %118, align 4
  %1413 = trunc i32 %1412 to i8
  %1414 = call signext i8 @safe_mod_func_int8_t_s_s(i8 signext %1411, i8 signext %1413)
  %1415 = icmp ne i8 %1414, 0
  br i1 %1415, label %1416, label %1480

1416:                                             ; preds = %1368
  store i8 -90, i8* %131, align 1
  store i16* null, i16** %132, align 8
  store i16* null, i16** %133, align 8
  store i8** null, i8*** %33, align 8
  %1417 = load i64, i64* %7, align 8
  %1418 = trunc i64 %1417 to i8
  %1419 = load i16, i16* %10, align 2
  %1420 = add i16 %1419, 1
  store i16 %1420, i16* %10, align 2
  %1421 = load i8*, i8** @g_1167, align 8
  %1422 = load i8, i8* %1421, align 1
  %1423 = add i8 %1422, 1
  store i8 %1423, i8* %1421, align 1
  %1424 = call zeroext i8 @safe_add_func_uint8_t_u_u(i8 zeroext %1418, i8 zeroext %1423)
  %1425 = zext i8 %1424 to i32
  %1426 = load i8, i8* %131, align 1
  %1427 = zext i8 %1426 to i32
  %1428 = getelementptr inbounds [7 x i32], [7 x i32]* %123, i64 0, i64 1
  %1429 = load i32, i32* %1428, align 4
  %1430 = icmp ne i32 %1429, 0
  br i1 %1430, label %1431, label %1447

1431:                                             ; preds = %1416
  %1432 = load i8*, i8** %9, align 8
  %1433 = load i8, i8* %1432, align 1
  %1434 = load i64, i64* %7, align 8
  %1435 = trunc i64 %1434 to i8
  %1436 = call signext i8 @safe_div_func_int8_t_s_s(i8 signext %1433, i8 signext %1435)
  %1437 = sext i8 %1436 to i64
  %1438 = xor i64 %1437, -1
  %1439 = or i64 255, %1438
  %1440 = trunc i64 %1439 to i32
  %1441 = load i32*, i32** @g_1674, align 8
  store i32 %1440, i32* %1441, align 4
  %1442 = load i64, i64* %7, align 8
  %1443 = and i64 0, %1442
  %1444 = load i8, i8* %75, align 1
  %1445 = zext i8 %1444 to i64
  %1446 = icmp ult i64 %1443, %1445
  br label %1447

1447:                                             ; preds = %1431, %1416
  %1448 = phi i1 [ false, %1416 ], [ %1446, %1431 ]
  %1449 = zext i1 %1448 to i32
  %1450 = load i8, i8* %34, align 1
  %1451 = zext i8 %1450 to i32
  %1452 = and i32 %1449, %1451
  %1453 = or i32 %1427, %1452
  %1454 = call i32 @safe_sub_func_int32_t_s_s(i32 %1425, i32 %1453)
  %1455 = load i32, i32* %118, align 4
  %1456 = or i32 %1454, %1455
  %1457 = xor i32 1, %1456
  %1458 = load i32***, i32**** %67, align 8
  %1459 = load i32**, i32*** %1458, align 8
  %1460 = load i32*, i32** %1459, align 8
  store i32 %1457, i32* %1460, align 4
  %1461 = trunc i32 %1457 to i16
  %1462 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext 16595, i16 zeroext %1461)
  %1463 = trunc i16 %1462 to i8
  %1464 = load i8*, i8** %9, align 8
  %1465 = load i8, i8* %1464, align 1
  %1466 = call zeroext i8 @safe_mul_func_uint8_t_u_u(i8 zeroext %1463, i8 zeroext %1465)
  %1467 = zext i8 %1466 to i32
  %1468 = load i8, i8* %78, align 1
  %1469 = sext i8 %1468 to i32
  %1470 = or i32 %1469, %1467
  %1471 = trunc i32 %1470 to i8
  store i8 %1471, i8* %78, align 1
  %1472 = load i64, i64* %8, align 8
  %1473 = icmp sgt i64 1, %1472
  %1474 = zext i1 %1473 to i32
  %1475 = load i32***, i32**** %67, align 8
  %1476 = load i32**, i32*** %1475, align 8
  %1477 = load i32*, i32** %1476, align 8
  %1478 = load i32, i32* %1477, align 4
  %1479 = call i32 @safe_div_func_int32_t_s_s(i32 %1474, i32 %1478)
  store i32* null, i32** %79, align 8
  br label %1577

1480:                                             ; preds = %1368
  store i32 -3, i32* %134, align 4
  store i32* @g_95, i32** %135, align 8
  store i32 9, i32* %136, align 4
  %1481 = load i64, i64* %8, align 8
  %1482 = load i32***, i32**** %101, align 8
  %1483 = load i32**, i32*** %1482, align 8
  %1484 = load i32*, i32** %1483, align 8
  %1485 = load i32, i32* %1484, align 4
  %1486 = sext i32 %1485 to i64
  %1487 = icmp sge i64 %1481, %1486
  %1488 = zext i1 %1487 to i32
  %1489 = load i32, i32* %134, align 4
  %1490 = xor i32 %1489, %1488
  store i32 %1490, i32* %134, align 4
  %1491 = load i8, i8* %58, align 1
  %1492 = icmp ne i8 %1491, 0
  br i1 %1492, label %1493, label %1494

1493:                                             ; preds = %1480
  br label %1578

1494:                                             ; preds = %1480
  %1495 = load i64, i64* %8, align 8
  %1496 = load i32*, i32** %79, align 8
  %1497 = load i32, i32* %1496, align 4
  %1498 = sext i32 %1497 to i64
  %1499 = and i64 %1498, %1495
  %1500 = trunc i64 %1499 to i32
  store i32 %1500, i32* %1496, align 4
  %1501 = load i32*, i32** %135, align 8
  store i32 1, i32* %1501, align 4
  %1502 = load i32***, i32**** %67, align 8
  %1503 = load i32**, i32*** %1502, align 8
  %1504 = load i32*, i32** %1503, align 8
  %1505 = load i32, i32* %1504, align 4
  %1506 = load i32***, i32**** %101, align 8
  %1507 = load i32**, i32*** %1506, align 8
  %1508 = load i32*, i32** %1507, align 8
  %1509 = load i32, i32* %1508, align 4
  %1510 = load i8**, i8*** %15, align 8
  %1511 = load i8*, i8** %1510, align 8
  %1512 = load i8, i8* %1511, align 1
  %1513 = sext i8 %1512 to i32
  %1514 = xor i32 %1513, %1509
  %1515 = trunc i32 %1514 to i8
  store i8 %1515, i8* %1511, align 1
  %1516 = load i16****, i16***** @g_2983, align 8
  %1517 = load i16***, i16**** %1516, align 8
  %1518 = icmp ne i16*** %1517, null
  %1519 = zext i1 %1518 to i32
  %1520 = sext i32 %1519 to i64
  %1521 = xor i64 %1520, 169
  %1522 = load i16, i16* %10, align 2
  %1523 = zext i16 %1522 to i32
  %1524 = load i32*, i32** %79, align 8
  %1525 = load i32, i32* %1524, align 4
  %1526 = or i32 %1523, %1525
  %1527 = sext i32 %1526 to i64
  %1528 = load i64***, i64**** %29, align 8
  %1529 = load i64**, i64*** %1528, align 8
  %1530 = load i64*, i64** %1529, align 8
  store i64 %1527, i64* %1530, align 8
  %1531 = getelementptr inbounds [7 x i32], [7 x i32]* %123, i64 0, i64 1
  %1532 = load i32, i32* %1531, align 4
  %1533 = sext i32 %1532 to i64
  %1534 = or i64 %1527, %1533
  %1535 = trunc i64 %1534 to i16
  %1536 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  %1537 = load i32, i32* %1536, align 4
  %1538 = trunc i32 %1537 to i16
  %1539 = call signext i16 @safe_div_func_int16_t_s_s(i16 signext %1535, i16 signext %1538)
  %1540 = sext i16 %1539 to i64
  %1541 = icmp ult i64 %1540, 4294967288
  br i1 %1541, label %1542, label %1548

1542:                                             ; preds = %1494
  %1543 = load i32***, i32**** %101, align 8
  %1544 = load i32**, i32*** %1543, align 8
  %1545 = load i32*, i32** %1544, align 8
  %1546 = load i32, i32* %1545, align 4
  %1547 = icmp ne i32 %1546, 0
  br label %1548

1548:                                             ; preds = %1542, %1494
  %1549 = phi i1 [ false, %1494 ], [ %1547, %1542 ]
  %1550 = zext i1 %1549 to i32
  %1551 = sext i32 %1550 to i64
  %1552 = icmp sge i64 %1521, %1551
  %1553 = zext i1 %1552 to i32
  %1554 = trunc i32 %1553 to i8
  %1555 = call signext i8 @safe_add_func_int8_t_s_s(i8 signext %1515, i8 signext %1554)
  %1556 = sext i8 %1555 to i64
  %1557 = load i64*, i64** @g_2496, align 8
  %1558 = load volatile i64, i64* %1557, align 8
  %1559 = icmp ne i64 %1556, %1558
  %1560 = zext i1 %1559 to i32
  %1561 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  %1562 = load i32, i32* %1561, align 4
  store i32 %1562, i32* %136, align 4
  %1563 = sext i32 %1562 to i64
  %1564 = load i64, i64* %8, align 8
  %1565 = icmp sge i64 %1563, %1564
  %1566 = zext i1 %1565 to i32
  %1567 = call i32 @safe_add_func_uint32_t_u_u(i32 %1566, i32 5)
  %1568 = load i64, i64* %8, align 8
  %1569 = load i64, i64* %7, align 8
  %1570 = icmp ule i64 %1568, %1569
  %1571 = zext i1 %1570 to i32
  %1572 = load i32***, i32**** %67, align 8
  %1573 = load i32**, i32*** %1572, align 8
  %1574 = load i32*, i32** %1573, align 8
  store i32 %1571, i32* %1574, align 4
  %1575 = load volatile i8**, i8*** @g_515, align 8
  %1576 = load i8*, i8** %1575, align 8
  store i8* %1576, i8** %6, align 8
  br label %2317

1577:                                             ; preds = %1447
  br label %1578

1578:                                             ; preds = %1577, %1493
  %1579 = load i64**, i64*** %124, align 8
  %1580 = icmp ne i64** null, %1579
  %1581 = zext i1 %1580 to i32
  %1582 = load i32***, i32**** %67, align 8
  %1583 = load i32**, i32*** %1582, align 8
  %1584 = load i32*, i32** %1583, align 8
  store i32 %1581, i32* %1584, align 4
  %1585 = trunc i32 %1581 to i16
  store i16 %1585, i16* %125, align 2
  %1586 = sext i16 %1585 to i32
  %1587 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  store i32 %1586, i32* %1587, align 4
  %1588 = load i64***, i64**** @g_1637, align 8
  %1589 = load i64**, i64*** %1588, align 8
  %1590 = load volatile i64*, i64** %1589, align 8
  %1591 = load volatile i64, i64* %1590, align 8
  %1592 = load i64**, i64*** @g_2096, align 8
  %1593 = load i64*, i64** %1592, align 8
  store i64 %1591, i64* %1593, align 8
  %1594 = call i64 @safe_div_func_int64_t_s_s(i64 4779959390074309151, i64 %1591)
  %1595 = trunc i64 %1594 to i16
  %1596 = load %union.U0*, %union.U0** %102, align 8
  %1597 = icmp ne %union.U0* null, %1596
  %1598 = zext i1 %1597 to i32
  %1599 = load i16, i16* %125, align 2
  %1600 = trunc i16 %1599 to i8
  %1601 = call signext i8 @safe_unary_minus_func_int8_t_s(i8 signext %1600)
  %1602 = sext i8 %1601 to i32
  %1603 = icmp ne i32 %1602, 0
  br i1 %1603, label %1690, label %1604

1604:                                             ; preds = %1578
  %1605 = load i16*****, i16****** @g_2655, align 8
  store i16***** %1605, i16****** %37, align 8
  %1606 = load i32*, i32** %122, align 8
  store i32 0, i32* %1606, align 4
  %1607 = load i32***, i32**** %101, align 8
  %1608 = load i32**, i32*** %1607, align 8
  %1609 = load i32*, i32** %1608, align 8
  %1610 = load i32, i32* %1609, align 4
  store i32 %1610, i32* %1609, align 4
  %1611 = load i32*, i32** %126, align 8
  store i32 %1610, i32* %1611, align 4
  %1612 = load i64*, i64** %80, align 8
  %1613 = load i64, i64* %8, align 8
  %1614 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  %1615 = load i32, i32* %1614, align 4
  %1616 = sext i32 %1615 to i64
  %1617 = call i64 @safe_div_func_uint64_t_u_u(i64 %1613, i64 %1616)
  %1618 = trunc i64 %1617 to i16
  %1619 = load i64, i64* %7, align 8
  %1620 = trunc i64 %1619 to i16
  %1621 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %1618, i16 zeroext %1620)
  %1622 = icmp ne i16 %1621, 0
  %1623 = xor i1 %1622, true
  %1624 = zext i1 %1623 to i32
  %1625 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  store i32 %1624, i32* %1625, align 4
  %1626 = getelementptr inbounds [7 x i32], [7 x i32]* %123, i64 0, i64 5
  %1627 = load i32, i32* %1626, align 4
  %1628 = call i32 @safe_sub_func_int32_t_s_s(i32 %1624, i32 %1627)
  %1629 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 1
  %1630 = load i32, i32* %1629, align 4
  %1631 = icmp ne i32 %1630, 0
  br i1 %1631, label %1632, label %1636

1632:                                             ; preds = %1604
  %1633 = load i16, i16* %10, align 2
  %1634 = zext i16 %1633 to i32
  %1635 = icmp ne i32 %1634, 0
  br label %1636

1636:                                             ; preds = %1632, %1604
  %1637 = phi i1 [ false, %1604 ], [ %1635, %1632 ]
  %1638 = zext i1 %1637 to i32
  %1639 = icmp eq i64* %1612, %7
  %1640 = zext i1 %1639 to i32
  %1641 = icmp ult i32 %1610, %1640
  %1642 = zext i1 %1641 to i32
  %1643 = xor i32 %1642, -1
  %1644 = icmp ne i32 %1643, 0
  br i1 %1644, label %1649, label %1645

1645:                                             ; preds = %1636
  %1646 = getelementptr inbounds [7 x i32], [7 x i32]* %123, i64 0, i64 5
  %1647 = load i32, i32* %1646, align 4
  %1648 = icmp ne i32 %1647, 0
  br label %1649

1649:                                             ; preds = %1645, %1636
  %1650 = phi i1 [ true, %1636 ], [ %1648, %1645 ]
  %1651 = zext i1 %1650 to i32
  %1652 = trunc i32 %1651 to i8
  %1653 = load i32, i32* %118, align 4
  %1654 = call signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %1652, i32 %1653)
  %1655 = sext i8 %1654 to i64
  %1656 = call i64 @safe_mod_func_int64_t_s_s(i64 %1655, i64 -4)
  %1657 = icmp ne i64 %1656, 0
  br i1 %1657, label %1658, label %1659

1658:                                             ; preds = %1649
  br label %1659

1659:                                             ; preds = %1658, %1649
  %1660 = phi i1 [ false, %1649 ], [ true, %1658 ]
  %1661 = zext i1 %1660 to i32
  %1662 = load i16*****, i16****** %127, align 8
  %1663 = icmp ne i16***** %1605, %1662
  %1664 = zext i1 %1663 to i32
  %1665 = sext i32 %1664 to i64
  %1666 = load i64, i64* %7, align 8
  %1667 = icmp ule i64 %1665, %1666
  %1668 = zext i1 %1667 to i32
  %1669 = trunc i32 %1668 to i8
  %1670 = call signext i8 @safe_div_func_int8_t_s_s(i8 signext %1669, i8 signext 34)
  %1671 = load i32***, i32**** %101, align 8
  %1672 = load i32**, i32*** %1671, align 8
  %1673 = load i32*, i32** %1672, align 8
  %1674 = load i32, i32* %1673, align 4
  %1675 = trunc i32 %1674 to i8
  %1676 = call zeroext i8 @safe_sub_func_uint8_t_u_u(i8 zeroext %1675, i8 zeroext -6)
  %1677 = zext i8 %1676 to i16
  %1678 = load i16*, i16** %128, align 8
  store i16 %1677, i16* %1678, align 2
  %1679 = load i64, i64* %7, align 8
  %1680 = trunc i64 %1679 to i16
  %1681 = call zeroext i16 @safe_sub_func_uint16_t_u_u(i16 zeroext %1677, i16 zeroext %1680)
  store i16 %1681, i16* %10, align 2
  %1682 = zext i16 %1681 to i32
  %1683 = icmp ne i32 %1682, 0
  br i1 %1683, label %1684, label %1685

1684:                                             ; preds = %1659
  br label %1685

1685:                                             ; preds = %1684, %1659
  %1686 = phi i1 [ false, %1659 ], [ true, %1684 ]
  %1687 = zext i1 %1686 to i32
  %1688 = sext i32 %1687 to i64
  %1689 = icmp eq i64 %1688, 3117193093
  br label %1690

1690:                                             ; preds = %1685, %1578
  %1691 = phi i1 [ true, %1578 ], [ %1689, %1685 ]
  %1692 = zext i1 %1691 to i32
  %1693 = trunc i32 %1692 to i8
  %1694 = call zeroext i8 @safe_sub_func_uint8_t_u_u(i8 zeroext %1693, i8 zeroext -1)
  %1695 = zext i8 %1694 to i64
  %1696 = xor i64 %1695, 245
  %1697 = trunc i64 %1696 to i16
  %1698 = call signext i16 @safe_mul_func_int16_t_s_s(i16 signext %1595, i16 signext %1697)
  %1699 = load i64, i64* %7, align 8
  %1700 = icmp ne i64 %1699, 0
  br i1 %1700, label %1701, label %1873

1701:                                             ; preds = %1690
  store i16 27127, i16* %137, align 2
  %1702 = getelementptr inbounds [6 x i32*], [6 x i32*]* %138, i64 0, i64 0
  %1703 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %1704 = getelementptr inbounds [9 x i32], [9 x i32]* %1703, i64 0, i64 4
  store i32* %1704, i32** %1702, align 8
  %1705 = getelementptr inbounds i32*, i32** %1702, i64 1
  store i32* null, i32** %1705, align 8
  %1706 = getelementptr inbounds i32*, i32** %1705, i64 1
  %1707 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %1708 = getelementptr inbounds [9 x i32], [9 x i32]* %1707, i64 0, i64 4
  store i32* %1708, i32** %1706, align 8
  %1709 = getelementptr inbounds i32*, i32** %1706, i64 1
  %1710 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %1711 = getelementptr inbounds [9 x i32], [9 x i32]* %1710, i64 0, i64 4
  store i32* %1711, i32** %1709, align 8
  %1712 = getelementptr inbounds i32*, i32** %1709, i64 1
  store i32* null, i32** %1712, align 8
  %1713 = getelementptr inbounds i32*, i32** %1712, i64 1
  %1714 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %1715 = getelementptr inbounds [9 x i32], [9 x i32]* %1714, i64 0, i64 4
  store i32* %1715, i32** %1713, align 8
  %1716 = load i16*, i16** @g_369, align 8
  %1717 = load i16, i16* %1716, align 2
  %1718 = sext i16 %1717 to i32
  %1719 = icmp ne i32 %1718, 0
  br i1 %1719, label %1720, label %1811

1720:                                             ; preds = %1701
  %1721 = load i64, i64* %8, align 8
  %1722 = icmp eq i64 1, %1721
  %1723 = zext i1 %1722 to i32
  %1724 = load volatile i64**, i64*** @g_1276, align 8
  %1725 = load volatile i64*, i64** %1724, align 8
  %1726 = load volatile i64, i64* %1725, align 8
  %1727 = call i64 @safe_add_func_uint64_t_u_u(i64 %1726, i64 -5599323776955781182)
  %1728 = trunc i64 %1727 to i16
  %1729 = load i64, i64* %8, align 8
  %1730 = trunc i64 %1729 to i16
  %1731 = call zeroext i16 @safe_div_func_uint16_t_u_u(i16 zeroext %1728, i16 zeroext %1730)
  %1732 = zext i16 %1731 to i32
  %1733 = load i32***, i32**** %67, align 8
  %1734 = load i32**, i32*** %1733, align 8
  %1735 = load i32*, i32** %1734, align 8
  %1736 = load i32, i32* %1735, align 4
  %1737 = load i64, i64* %8, align 8
  %1738 = icmp ne i64 %1737, 0
  br i1 %1738, label %1742, label %1739

1739:                                             ; preds = %1720
  %1740 = load i32, i32* %68, align 4
  %1741 = icmp ne i32 %1740, 0
  br label %1742

1742:                                             ; preds = %1739, %1720
  %1743 = phi i1 [ true, %1720 ], [ %1741, %1739 ]
  %1744 = zext i1 %1743 to i32
  %1745 = load i32, i32* %103, align 4
  %1746 = xor i32 %1745, %1744
  store i32 %1746, i32* %103, align 4
  %1747 = zext i32 %1746 to i64
  %1748 = load i64, i64* %8, align 8
  %1749 = icmp slt i64 %1747, %1748
  br i1 %1749, label %1750, label %1751

1750:                                             ; preds = %1742
  br label %1751

1751:                                             ; preds = %1750, %1742
  %1752 = phi i1 [ false, %1742 ], [ false, %1750 ]
  %1753 = zext i1 %1752 to i32
  %1754 = trunc i32 %1753 to i8
  %1755 = load i8*, i8** %9, align 8
  store i8 %1754, i8* %1755, align 1
  %1756 = sext i8 %1754 to i32
  %1757 = and i32 %1732, %1756
  %1758 = icmp ne i32 %1757, 0
  br i1 %1758, label %1763, label %1759

1759:                                             ; preds = %1751
  %1760 = load i16, i16* %10, align 2
  %1761 = zext i16 %1760 to i32
  %1762 = icmp ne i32 %1761, 0
  br label %1763

1763:                                             ; preds = %1759, %1751
  %1764 = phi i1 [ true, %1751 ], [ %1762, %1759 ]
  %1765 = zext i1 %1764 to i32
  %1766 = load i32*, i32** %18, align 8
  store i32 %1765, i32* %1766, align 4
  %1767 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  store i32 %1765, i32* %1767, align 4
  br i1 %1764, label %1769, label %1768

1768:                                             ; preds = %1763
  br label %1769

1769:                                             ; preds = %1768, %1763
  %1770 = phi i1 [ true, %1763 ], [ true, %1768 ]
  %1771 = zext i1 %1770 to i32
  %1772 = icmp sle i32 %1723, %1771
  %1773 = zext i1 %1772 to i32
  %1774 = sext i32 %1773 to i64
  %1775 = icmp ule i64 248, %1774
  %1776 = zext i1 %1775 to i32
  %1777 = sext i32 %1776 to i64
  %1778 = icmp sge i64 %1777, -7
  %1779 = zext i1 %1778 to i32
  %1780 = sext i32 %1779 to i64
  %1781 = or i64 %1780, -6
  %1782 = load i64, i64* %8, align 8
  %1783 = icmp sle i64 %1782, 254
  br i1 %1783, label %1784, label %1793

1784:                                             ; preds = %1769
  %1785 = load i32***, i32**** %67, align 8
  %1786 = load i32**, i32*** %1785, align 8
  %1787 = load i32*, i32** %1786, align 8
  %1788 = load i32, i32* %1787, align 4
  %1789 = icmp ne i32 %1788, 0
  br i1 %1789, label %1790, label %1793

1790:                                             ; preds = %1784
  %1791 = load i64, i64* %7, align 8
  %1792 = icmp ne i64 %1791, 0
  br label %1793

1793:                                             ; preds = %1790, %1784, %1769
  %1794 = phi i1 [ false, %1784 ], [ false, %1769 ], [ %1792, %1790 ]
  %1795 = zext i1 %1794 to i32
  %1796 = load i64, i64* %8, align 8
  %1797 = call zeroext i16 @safe_sub_func_uint16_t_u_u(i16 zeroext 0, i16 zeroext -4594)
  br i1 true, label %1798, label %1804

1798:                                             ; preds = %1793
  %1799 = load i32***, i32**** %67, align 8
  %1800 = load i32**, i32*** %1799, align 8
  %1801 = load i32*, i32** %1800, align 8
  %1802 = load i32, i32* %1801, align 4
  %1803 = icmp ne i32 %1802, 0
  br label %1804

1804:                                             ; preds = %1798, %1793
  %1805 = phi i1 [ false, %1793 ], [ %1803, %1798 ]
  %1806 = zext i1 %1805 to i32
  %1807 = trunc i32 %1806 to i16
  %1808 = load i16*, i16** @g_369, align 8
  store i16 %1807, i16* %1808, align 2
  %1809 = sext i16 %1807 to i32
  %1810 = icmp ne i32 %1809, 0
  br label %1811

1811:                                             ; preds = %1804, %1701
  %1812 = phi i1 [ false, %1701 ], [ %1810, %1804 ]
  %1813 = zext i1 %1812 to i32
  %1814 = load i16, i16* %137, align 2
  %1815 = zext i16 %1814 to i32
  %1816 = xor i32 %1815, %1813
  %1817 = trunc i32 %1816 to i16
  store i16 %1817, i16* %137, align 2
  %1818 = load i32**, i32*** @g_421, align 8
  store i32* null, i32** %1818, align 8
  %1819 = load i64**, i64*** @g_2495, align 8
  %1820 = load i64*, i64** %1819, align 8
  %1821 = load volatile i64, i64* %1820, align 8
  %1822 = getelementptr inbounds [6 x i32*], [6 x i32*]* %138, i64 0, i64 1
  %1823 = load i32*, i32** %1822, align 8
  %1824 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 2
  store i32 -4, i32* %1824, align 8
  %1825 = load i8*, i8** %129, align 8
  %1826 = call %union.U0* @func_48(i32* %1823, i32 -4, i8* %1825)
  %1827 = load i64, i64* %8, align 8
  %1828 = load i16, i16* %10, align 2
  %1829 = load i16*, i16** %128, align 8
  store i16 %1828, i16* %1829, align 2
  %1830 = load i64, i64* %8, align 8
  %1831 = trunc i64 %1830 to i32
  %1832 = call i32 @safe_div_func_uint32_t_u_u(i32 %1831, i32 333824408)
  %1833 = zext i32 %1832 to i64
  %1834 = and i64 %1833, 57344
  %1835 = trunc i64 %1834 to i16
  %1836 = call i8* @func_17(i64 %1821, %union.U0* %1826, i16 zeroext %1828, i16 signext %1835)
  %1837 = getelementptr inbounds %union.U0, %union.U0* %140, i32 0, i32 0
  store i8* %1836, i8** %1837, align 8
  %1838 = load i64, i64* %8, align 8
  %1839 = icmp ne i64 %1838, 0
  br i1 %1839, label %1843, label %1840

1840:                                             ; preds = %1811
  %1841 = load i64, i64* %8, align 8
  %1842 = icmp ne i64 %1841, 0
  br label %1843

1843:                                             ; preds = %1840, %1811
  %1844 = phi i1 [ true, %1811 ], [ %1842, %1840 ]
  %1845 = zext i1 %1844 to i32
  %1846 = sext i32 %1845 to i64
  %1847 = icmp eq i64 43654, %1846
  %1848 = zext i1 %1847 to i32
  %1849 = sext i32 %1848 to i64
  %1850 = and i64 %1849, 10861
  %1851 = getelementptr inbounds [9 x i64], [9 x i64]* %81, i64 0, i64 3
  %1852 = load i64, i64* %1851, align 8
  %1853 = or i64 %1852, 247
  %1854 = load i64, i64* %7, align 8
  %1855 = icmp ult i64 %1853, %1854
  %1856 = zext i1 %1855 to i32
  %1857 = sext i32 %1856 to i64
  %1858 = load i64, i64* %8, align 8
  %1859 = icmp sle i64 %1857, %1858
  br i1 %1859, label %1860, label %1863

1860:                                             ; preds = %1843
  %1861 = load i64, i64* %8, align 8
  %1862 = icmp ne i64 %1861, 0
  br label %1863

1863:                                             ; preds = %1860, %1843
  %1864 = phi i1 [ false, %1843 ], [ %1862, %1860 ]
  %1865 = zext i1 %1864 to i32
  %1866 = sext i32 %1865 to i64
  %1867 = load i64, i64* %69, align 8
  %1868 = xor i64 %1867, %1866
  store i64 %1868, i64* %69, align 8
  %1869 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %1870 = getelementptr inbounds [9 x i32], [9 x i32]* %1869, i64 0, i64 4
  %1871 = load i32***, i32**** %67, align 8
  %1872 = load i32**, i32*** %1871, align 8
  store i32* %1870, i32** %1872, align 8
  br label %2010

1873:                                             ; preds = %1690
  %1874 = getelementptr inbounds [3 x [3 x [4 x i32***]]], [3 x [3 x [4 x i32***]]]* %141, i64 0, i64 0
  %1875 = getelementptr inbounds [3 x [4 x i32***]], [3 x [4 x i32***]]* %1874, i64 0, i64 0
  %1876 = bitcast [4 x i32***]* %1875 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %1876, i8 0, i64 32, i1 false)
  %1877 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1875, i64 0, i64 0
  %1878 = getelementptr inbounds i32***, i32**** %1877, i64 1
  store i32*** %84, i32**** %1878, align 8
  %1879 = getelementptr inbounds i32***, i32**** %1878, i64 1
  %1880 = getelementptr inbounds i32***, i32**** %1879, i64 1
  %1881 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1875, i64 1
  %1882 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1881, i64 0, i64 0
  store i32*** %84, i32**** %1882, align 8
  %1883 = getelementptr inbounds i32***, i32**** %1882, i64 1
  store i32*** %84, i32**** %1883, align 8
  %1884 = getelementptr inbounds i32***, i32**** %1883, i64 1
  store i32*** null, i32**** %1884, align 8
  %1885 = getelementptr inbounds i32***, i32**** %1884, i64 1
  store i32*** %84, i32**** %1885, align 8
  %1886 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1881, i64 1
  %1887 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1886, i64 0, i64 0
  store i32*** %84, i32**** %1887, align 8
  %1888 = getelementptr inbounds i32***, i32**** %1887, i64 1
  store i32*** null, i32**** %1888, align 8
  %1889 = getelementptr inbounds i32***, i32**** %1888, i64 1
  store i32*** null, i32**** %1889, align 8
  %1890 = getelementptr inbounds i32***, i32**** %1889, i64 1
  store i32*** %84, i32**** %1890, align 8
  %1891 = getelementptr inbounds [3 x [4 x i32***]], [3 x [4 x i32***]]* %1874, i64 1
  %1892 = getelementptr inbounds [3 x [4 x i32***]], [3 x [4 x i32***]]* %1891, i64 0, i64 0
  %1893 = bitcast [4 x i32***]* %1892 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %1893, i8 0, i64 32, i1 false)
  %1894 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1892, i64 0, i64 0
  %1895 = getelementptr inbounds i32***, i32**** %1894, i64 1
  store i32*** %84, i32**** %1895, align 8
  %1896 = getelementptr inbounds i32***, i32**** %1895, i64 1
  %1897 = getelementptr inbounds i32***, i32**** %1896, i64 1
  %1898 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1892, i64 1
  %1899 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1898, i64 0, i64 0
  store i32*** %84, i32**** %1899, align 8
  %1900 = getelementptr inbounds i32***, i32**** %1899, i64 1
  store i32*** %84, i32**** %1900, align 8
  %1901 = getelementptr inbounds i32***, i32**** %1900, i64 1
  store i32*** null, i32**** %1901, align 8
  %1902 = getelementptr inbounds i32***, i32**** %1901, i64 1
  store i32*** %84, i32**** %1902, align 8
  %1903 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1898, i64 1
  %1904 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1903, i64 0, i64 0
  store i32*** %84, i32**** %1904, align 8
  %1905 = getelementptr inbounds i32***, i32**** %1904, i64 1
  store i32*** null, i32**** %1905, align 8
  %1906 = getelementptr inbounds i32***, i32**** %1905, i64 1
  store i32*** null, i32**** %1906, align 8
  %1907 = getelementptr inbounds i32***, i32**** %1906, i64 1
  store i32*** %84, i32**** %1907, align 8
  %1908 = getelementptr inbounds [3 x [4 x i32***]], [3 x [4 x i32***]]* %1891, i64 1
  %1909 = getelementptr inbounds [3 x [4 x i32***]], [3 x [4 x i32***]]* %1908, i64 0, i64 0
  %1910 = bitcast [4 x i32***]* %1909 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %1910, i8 0, i64 32, i1 false)
  %1911 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1909, i64 0, i64 0
  %1912 = getelementptr inbounds i32***, i32**** %1911, i64 1
  store i32*** %84, i32**** %1912, align 8
  %1913 = getelementptr inbounds i32***, i32**** %1912, i64 1
  %1914 = getelementptr inbounds i32***, i32**** %1913, i64 1
  %1915 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1909, i64 1
  %1916 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1915, i64 0, i64 0
  store i32*** %84, i32**** %1916, align 8
  %1917 = getelementptr inbounds i32***, i32**** %1916, i64 1
  store i32*** %84, i32**** %1917, align 8
  %1918 = getelementptr inbounds i32***, i32**** %1917, i64 1
  store i32*** null, i32**** %1918, align 8
  %1919 = getelementptr inbounds i32***, i32**** %1918, i64 1
  store i32*** %84, i32**** %1919, align 8
  %1920 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1915, i64 1
  %1921 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1920, i64 0, i64 0
  store i32*** %84, i32**** %1921, align 8
  %1922 = getelementptr inbounds i32***, i32**** %1921, i64 1
  store i32*** null, i32**** %1922, align 8
  %1923 = getelementptr inbounds i32***, i32**** %1922, i64 1
  store i32*** null, i32**** %1923, align 8
  %1924 = getelementptr inbounds i32***, i32**** %1923, i64 1
  store i32*** %84, i32**** %1924, align 8
  %1925 = call signext i8 @safe_mul_func_int8_t_s_s(i8 signext 1, i8 signext -8)
  %1926 = sext i8 %1925 to i64
  %1927 = load i64***, i64**** %29, align 8
  %1928 = load i64**, i64*** %1927, align 8
  %1929 = load i64*, i64** %1928, align 8
  store i64 %1926, i64* %1929, align 8
  %1930 = and i64 %1926, 7501678045431771049
  %1931 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 3
  %1932 = load i32, i32* %1931, align 4
  %1933 = sext i32 %1932 to i64
  %1934 = or i64 %1933, %1930
  %1935 = trunc i64 %1934 to i32
  store i32 %1935, i32* %1931, align 4
  %1936 = load i32***, i32**** %67, align 8
  %1937 = load i32**, i32*** %1936, align 8
  %1938 = load i32*, i32** %1937, align 8
  %1939 = load i64, i64* %7, align 8
  %1940 = trunc i64 %1939 to i32
  %1941 = load i8*, i8** %11, align 8
  %1942 = call %union.U0* @func_48(i32* %1938, i32 %1940, i8* %1941)
  %1943 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %1944 = load %union.U0*, %union.U0** %1943, align 8
  %1945 = call i32* @func_52(%union.U0* %1942, %union.U0* %1944)
  %1946 = load i32***, i32**** %101, align 8
  %1947 = load i32**, i32*** %1946, align 8
  store i32* %1945, i32** %1947, align 8
  %1948 = load i32***, i32**** %67, align 8
  %1949 = load i32**, i32*** %1948, align 8
  %1950 = load i32*, i32** %1949, align 8
  %1951 = load i32, i32* %1950, align 4
  %1952 = sext i32 %1951 to i64
  %1953 = icmp sgt i64 4090924087314037015, %1952
  %1954 = zext i1 %1953 to i32
  %1955 = load i16*, i16** @g_369, align 8
  %1956 = load i16, i16* %1955, align 2
  %1957 = sext i16 %1956 to i64
  %1958 = and i64 %1957, 11137
  %1959 = load i32, i32* %118, align 4
  %1960 = load i32***, i32**** %85, align 8
  %1961 = getelementptr inbounds [3 x [3 x [4 x i32***]]], [3 x [3 x [4 x i32***]]]* %141, i64 0, i64 1
  %1962 = getelementptr inbounds [3 x [4 x i32***]], [3 x [4 x i32***]]* %1961, i64 0, i64 0
  %1963 = getelementptr inbounds [4 x i32***], [4 x i32***]* %1962, i64 0, i64 0
  %1964 = load i32***, i32**** %1963, align 16
  %1965 = icmp eq i32*** %1960, %1964
  %1966 = zext i1 %1965 to i32
  %1967 = icmp ne i32 %1959, %1966
  %1968 = zext i1 %1967 to i32
  %1969 = sext i32 %1968 to i64
  %1970 = icmp ult i64 %1969, -1141826714832300418
  %1971 = zext i1 %1970 to i32
  %1972 = sext i32 %1971 to i64
  %1973 = load i32***, i32**** %101, align 8
  %1974 = load i32**, i32*** %1973, align 8
  %1975 = load i32*, i32** %1974, align 8
  %1976 = load i32, i32* %1975, align 4
  %1977 = trunc i32 %1976 to i8
  %1978 = call signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %1977, i32 0)
  %1979 = sext i8 %1978 to i64
  %1980 = call i64 @safe_div_func_uint64_t_u_u(i64 %1972, i64 %1979)
  %1981 = getelementptr inbounds [5 x i32], [5 x i32]* %120, i64 0, i64 4
  %1982 = load i32, i32* %1981, align 16
  %1983 = load i32***, i32**** %67, align 8
  %1984 = load i32**, i32*** %1983, align 8
  %1985 = load i32*, i32** %1984, align 8
  %1986 = load i32, i32* %1985, align 4
  %1987 = sext i32 %1986 to i64
  %1988 = load i64, i64* %7, align 8
  %1989 = icmp ugt i64 %1987, %1988
  br i1 %1989, label %1994, label %1990

1990:                                             ; preds = %1873
  %1991 = load volatile i32*, i32** @g_138, align 8
  %1992 = load i32, i32* %1991, align 4
  %1993 = icmp ne i32 %1992, 0
  br label %1994

1994:                                             ; preds = %1990, %1873
  %1995 = phi i1 [ true, %1873 ], [ %1993, %1990 ]
  %1996 = zext i1 %1995 to i32
  %1997 = trunc i32 %1996 to i16
  %1998 = load i16*, i16** @g_369, align 8
  %1999 = load i16, i16* %1998, align 2
  %2000 = call zeroext i16 @safe_mod_func_uint16_t_u_u(i16 zeroext %1997, i16 zeroext %1999)
  %2001 = zext i16 %2000 to i32
  %2002 = icmp slt i32 %1954, %2001
  %2003 = zext i1 %2002 to i32
  %2004 = icmp slt i32 %2003, -1784632100
  %2005 = zext i1 %2004 to i32
  %2006 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 4
  %2007 = getelementptr inbounds [9 x i32], [9 x i32]* %2006, i64 0, i64 2
  %2008 = load i32, i32* %2007, align 8
  %2009 = xor i32 %2008, %2005
  store i32 %2009, i32* %2007, align 8
  br label %2010

2010:                                             ; preds = %1994, %1863
  br label %2011

2011:                                             ; preds = %2010, %1289
  %2012 = load i32***, i32**** %85, align 8
  %2013 = load i32**, i32*** %2012, align 8
  %2014 = load i32*, i32** %2013, align 8
  %2015 = load i32, i32* %2014, align 4
  %2016 = load i32*, i32** @g_422, align 8
  store i32 %2015, i32* %2016, align 4
  %2017 = icmp ne i32 %2015, 0
  br i1 %2017, label %2018, label %2106

2018:                                             ; preds = %2011
  store i16 -2, i16* %145, align 2
  store i32*** @g_421, i32**** %146, align 8
  %2019 = load volatile i16****, i16***** @g_722, align 8
  %2020 = load volatile i16***, i16**** %2019, align 8
  %2021 = load i16**, i16*** %2020, align 8
  %2022 = load i16*, i16** %2021, align 8
  %2023 = load volatile i16, i16* %2022, align 2
  %2024 = call zeroext i16 @safe_lshift_func_uint16_t_u_s(i16 zeroext %2023, i32 3)
  %2025 = load i64, i64* %7, align 8
  %2026 = trunc i64 %2025 to i16
  %2027 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %2024, i16 zeroext %2026)
  %2028 = zext i16 %2027 to i64
  %2029 = call i64 @safe_add_func_uint64_t_u_u(i64 %2028, i64 1)
  %2030 = trunc i64 %2029 to i32
  %2031 = call i32 @safe_add_func_int32_t_s_s(i32 -2073704404, i32 %2030)
  %2032 = load i32**, i32*** @g_421, align 8
  %2033 = load i32*, i32** %2032, align 8
  store i32 %2031, i32* %2033, align 4
  %2034 = load i32***, i32**** %101, align 8
  %2035 = load i32**, i32*** %2034, align 8
  %2036 = load i32*, i32** %2035, align 8
  %2037 = load i32, i32* %2036, align 4
  %2038 = load i64, i64* %7, align 8
  %2039 = load i16, i16* %145, align 2
  %2040 = sext i16 %2039 to i64
  %2041 = or i64 %2040, %2038
  %2042 = trunc i64 %2041 to i16
  store i16 %2042, i16* %145, align 2
  %2043 = sext i16 %2042 to i32
  %2044 = icmp sgt i32 %2037, %2043
  %2045 = zext i1 %2044 to i32
  %2046 = load i32***, i32**** %146, align 8
  %2047 = load i32***, i32**** %146, align 8
  store i32*** %2047, i32**** %86, align 8
  %2048 = icmp ne i32*** %2046, %2047
  %2049 = zext i1 %2048 to i32
  %2050 = trunc i32 %2049 to i16
  %2051 = load i32***, i32**** %146, align 8
  %2052 = load i32**, i32*** %2051, align 8
  %2053 = load i32*, i32** %2052, align 8
  %2054 = load i32, i32* %2053, align 4
  %2055 = load i32***, i32**** %67, align 8
  %2056 = load i32**, i32*** %2055, align 8
  %2057 = load i32*, i32** %2056, align 8
  %2058 = load i32, i32* %2057, align 4
  %2059 = load i16, i16* %10, align 2
  %2060 = trunc i16 %2059 to i8
  %2061 = icmp eq i64* null, %8
  %2062 = zext i1 %2061 to i32
  %2063 = trunc i32 %2062 to i8
  %2064 = call zeroext i8 @safe_lshift_func_uint8_t_u_s(i8 zeroext %2063, i32 4)
  %2065 = call zeroext i8 @safe_mul_func_uint8_t_u_u(i8 zeroext %2060, i8 zeroext %2064)
  %2066 = load i8*, i8** %9, align 8
  %2067 = load i8, i8* %2066, align 1
  %2068 = sext i8 %2067 to i64
  %2069 = icmp slt i64 1, %2068
  %2070 = zext i1 %2069 to i32
  %2071 = load i32***, i32**** %67, align 8
  %2072 = load i32**, i32*** %2071, align 8
  %2073 = load i32*, i32** %2072, align 8
  %2074 = load i32, i32* %2073, align 4
  %2075 = trunc i32 %2074 to i16
  %2076 = load i32***, i32**** %146, align 8
  %2077 = load i32**, i32*** %2076, align 8
  %2078 = load i32*, i32** %2077, align 8
  %2079 = load i32, i32* %2078, align 4
  %2080 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %2075, i32 %2079)
  %2081 = sext i16 %2080 to i32
  %2082 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %2050, i32 %2081)
  %2083 = sext i16 %2082 to i32
  %2084 = load i32***, i32**** %67, align 8
  %2085 = load i32**, i32*** %2084, align 8
  %2086 = load i32*, i32** %2085, align 8
  %2087 = load i32, i32* %2086, align 4
  %2088 = icmp eq i32 %2083, %2087
  br i1 %2088, label %2089, label %2096

2089:                                             ; preds = %2018
  store i8*** null, i8**** %147, align 8
  store i8*** %15, i8**** %148, align 8
  %2090 = load i8***, i8**** %148, align 8
  store i8** @g_516, i8*** %2090, align 8
  %2091 = load i32*, i32** @g_422, align 8
  %2092 = load i32, i32* %2091, align 4
  %2093 = and i32 %2092, 1
  store i32 %2093, i32* %2091, align 4
  %2094 = load volatile i8**, i8*** @g_515, align 8
  %2095 = load i8*, i8** %2094, align 8
  store i8* %2095, i8** %6, align 8
  br label %2317

2096:                                             ; preds = %2018
  %2097 = load %union.U0***, %union.U0**** @g_1919, align 8
  %2098 = load %union.U0**, %union.U0*** %2097, align 8
  %2099 = load %union.U0*, %union.U0** %2098, align 8
  %2100 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %2101 = load %union.U0*, %union.U0** %2100, align 8
  %2102 = call i32* @func_52(%union.U0* %2099, %union.U0* %2101)
  %2103 = load i32***, i32**** %67, align 8
  %2104 = load i32**, i32*** %2103, align 8
  store i32* %2102, i32** %2104, align 8
  br label %2105

2105:                                             ; preds = %2096
  br label %2110

2106:                                             ; preds = %2011
  %2107 = getelementptr inbounds [8 x [9 x i32]], [8 x [9 x i32]]* %13, i64 0, i64 1
  %2108 = getelementptr inbounds [9 x i32], [9 x i32]* %2107, i64 0, i64 4
  store i32* %2108, i32** %149, align 8
  %2109 = load i32*, i32** %149, align 8
  store i32* %2109, i32** %18, align 8
  br label %2110

2110:                                             ; preds = %2106, %2105
  %2111 = load i32***, i32**** %67, align 8
  %2112 = load i32**, i32*** %2111, align 8
  %2113 = load i32*, i32** %2112, align 8
  %2114 = load i32, i32* %2113, align 4
  %2115 = sext i32 %2114 to i64
  %2116 = icmp ne i64 %2115, 193
  br i1 %2116, label %2117, label %2194

2117:                                             ; preds = %2110
  %2118 = load i32***, i32**** %101, align 8
  %2119 = load i32**, i32*** %2118, align 8
  %2120 = load i32*, i32** %2119, align 8
  %2121 = load i32, i32* %2120, align 4
  %2122 = trunc i32 %2121 to i8
  %2123 = load i64, i64* %8, align 8
  %2124 = trunc i64 %2123 to i8
  %2125 = load i8**, i8*** %82, align 8
  %2126 = load i8*, i8** %2125, align 8
  store i8 %2124, i8* %2126, align 1
  %2127 = call zeroext i8 @safe_lshift_func_uint8_t_u_u(i8 zeroext %2124, i32 3)
  %2128 = zext i8 %2127 to i32
  %2129 = call signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %2122, i32 %2128)
  %2130 = sext i8 %2129 to i32
  %2131 = load i32*, i32** %18, align 8
  %2132 = load i32, i32* %2131, align 4
  %2133 = icmp ne i32 %2132, 0
  br i1 %2133, label %2173, label %2134

2134:                                             ; preds = %2117
  %2135 = load i32***, i32**** %67, align 8
  %2136 = load i32**, i32*** %2135, align 8
  %2137 = load i32*, i32** %2136, align 8
  %2138 = load i32, i32* %2137, align 4
  %2139 = getelementptr inbounds [6 x [9 x i32]], [6 x [9 x i32]]* %74, i64 0, i64 0
  %2140 = getelementptr inbounds [9 x i32], [9 x i32]* %2139, i64 0, i64 7
  store i32 %2138, i32* %2140, align 4
  %2141 = load i32***, i32**** %67, align 8
  %2142 = load i32**, i32*** %2141, align 8
  %2143 = load i32*, i32** %2142, align 8
  %2144 = load i32, i32* %2143, align 4
  %2145 = load i64, i64* %8, align 8
  %2146 = load i32***, i32**** %67, align 8
  %2147 = load i32**, i32*** %2146, align 8
  %2148 = load i32*, i32** %2147, align 8
  %2149 = load i32, i32* %2148, align 4
  %2150 = sext i32 %2149 to i64
  %2151 = load i64, i64* %8, align 8
  %2152 = icmp eq i64 %2150, %2151
  %2153 = zext i1 %2152 to i32
  %2154 = getelementptr inbounds [7 x [7 x [5 x i16*]]], [7 x [7 x [5 x i16*]]]* %87, i64 0, i64 1
  %2155 = getelementptr inbounds [7 x [5 x i16*]], [7 x [5 x i16*]]* %2154, i64 0, i64 3
  %2156 = getelementptr inbounds [5 x i16*], [5 x i16*]* %2155, i64 0, i64 0
  %2157 = load i16*, i16** %2156, align 8
  %2158 = icmp eq i16* %10, %2157
  %2159 = zext i1 %2158 to i32
  %2160 = sext i32 %2159 to i64
  %2161 = icmp sge i64 %2145, %2160
  %2162 = zext i1 %2161 to i32
  %2163 = trunc i32 %2162 to i16
  %2164 = load i16, i16* %10, align 2
  %2165 = zext i16 %2164 to i32
  %2166 = call zeroext i16 @safe_lshift_func_uint16_t_u_s(i16 zeroext %2163, i32 %2165)
  %2167 = call i32 @safe_sub_func_int32_t_s_s(i32 %2138, i32 5)
  %2168 = trunc i32 %2167 to i16
  %2169 = call zeroext i16 @safe_rshift_func_uint16_t_u_u(i16 zeroext %2168, i32 13)
  %2170 = load i32*****, i32****** %38, align 8
  store i32***** %2170, i32****** getelementptr inbounds ([9 x [5 x i32*****]], [9 x [5 x i32*****]]* @g_3287, i64 0, i64 0, i64 2), align 16
  %2171 = load i32*****, i32****** %88, align 8
  %2172 = icmp ne i32***** %2170, %2171
  br label %2173

2173:                                             ; preds = %2134, %2117
  %2174 = phi i1 [ true, %2117 ], [ %2172, %2134 ]
  %2175 = zext i1 %2174 to i32
  %2176 = load i32**, i32*** %84, align 8
  %2177 = load i32*, i32** %2176, align 8
  %2178 = load i32, i32* %2177, align 4
  %2179 = icmp ne i32 %2175, %2178
  %2180 = zext i1 %2179 to i32
  %2181 = load i32**, i32*** %84, align 8
  %2182 = load i32*, i32** %2181, align 8
  %2183 = load i32, i32* %2182, align 4
  %2184 = and i32 %2180, %2183
  %2185 = icmp sle i32 %2130, %2184
  %2186 = zext i1 %2185 to i32
  %2187 = sext i32 %2186 to i64
  %2188 = load i64*, i64** %109, align 8
  store i64 %2187, i64* %2188, align 8
  %2189 = load volatile i64***, i64**** @g_1275, align 8
  %2190 = load volatile i64**, i64*** %2189, align 8
  %2191 = load volatile i64*, i64** %2190, align 8
  %2192 = load volatile i64, i64* %2191, align 8
  %2193 = icmp ule i64 %2187, %2192
  br label %2194

2194:                                             ; preds = %2173, %2110
  %2195 = phi i1 [ false, %2110 ], [ %2193, %2173 ]
  %2196 = zext i1 %2195 to i32
  %2197 = load i32***, i32**** %101, align 8
  %2198 = load i32**, i32*** %2197, align 8
  %2199 = load i32*, i32** %2198, align 8
  %2200 = load i32, i32* %2199, align 4
  %2201 = icmp sgt i32 %2196, %2200
  br i1 %2201, label %2202, label %2204

2202:                                             ; preds = %2194
  %2203 = load i32**, i32*** @g_421, align 8
  store i32* null, i32** %2203, align 8
  br label %2288

2204:                                             ; preds = %2194
  store i64** null, i64*** %150, align 8
  store i64** %100, i64*** %151, align 8
  store i32 774965939, i32* %152, align 4
  %2205 = load i8*, i8** %9, align 8
  %2206 = load i8, i8* %2205, align 1
  %2207 = sext i8 %2206 to i64
  %2208 = or i64 %2207, 116
  %2209 = trunc i64 %2208 to i8
  store i8 %2209, i8* %2205, align 1
  %2210 = load i16, i16* %10, align 2
  %2211 = zext i16 %2210 to i32
  %2212 = load i16, i16* %10, align 2
  %2213 = zext i16 %2212 to i32
  %2214 = and i32 %2211, %2213
  %2215 = trunc i32 %2214 to i8
  %2216 = call signext i8 @safe_add_func_int8_t_s_s(i8 signext %2209, i8 signext %2215)
  %2217 = sext i8 %2216 to i32
  %2218 = icmp ne i32 %2217, 0
  br i1 %2218, label %2219, label %2282

2219:                                             ; preds = %2204
  %2220 = load i64**, i64*** %151, align 8
  store i64* null, i64** %2220, align 8
  %2221 = load i64*, i64** %108, align 8
  %2222 = icmp ne i64* null, %2221
  %2223 = zext i1 %2222 to i32
  %2224 = load i32, i32* %152, align 4
  %2225 = call zeroext i8 @safe_unary_minus_func_uint8_t_u(i8 zeroext 60)
  %2226 = zext i8 %2225 to i32
  %2227 = icmp ne i32 %2226, 0
  br i1 %2227, label %2242, label %2228

2228:                                             ; preds = %2219
  %2229 = load i32***, i32**** %85, align 8
  %2230 = load i32**, i32*** %2229, align 8
  %2231 = load i32*, i32** %2230, align 8
  %2232 = load i32, i32* %2231, align 4
  %2233 = trunc i32 %2232 to i8
  %2234 = load i32***, i32**** %67, align 8
  %2235 = load i32**, i32*** %2234, align 8
  %2236 = load i32*, i32** %2235, align 8
  %2237 = load i32, i32* %2236, align 4
  %2238 = trunc i32 %2237 to i8
  %2239 = call signext i8 @safe_mod_func_int8_t_s_s(i8 signext %2233, i8 signext %2238)
  %2240 = sext i8 %2239 to i32
  %2241 = icmp ne i32 %2240, 0
  br i1 %2241, label %2242, label %2248

2242:                                             ; preds = %2228, %2219
  %2243 = load i32***, i32**** %101, align 8
  %2244 = load i32**, i32*** %2243, align 8
  %2245 = load i32*, i32** %2244, align 8
  %2246 = load i32, i32* %2245, align 4
  %2247 = icmp ne i32 %2246, 0
  br label %2248

2248:                                             ; preds = %2242, %2228
  %2249 = phi i1 [ false, %2228 ], [ %2247, %2242 ]
  %2250 = zext i1 %2249 to i32
  %2251 = load i16*, i16** @g_369, align 8
  %2252 = load i16, i16* %2251, align 2
  %2253 = sext i16 %2252 to i32
  %2254 = icmp slt i32 %2250, %2253
  %2255 = zext i1 %2254 to i32
  %2256 = icmp ne i32 %2224, %2255
  %2257 = zext i1 %2256 to i32
  %2258 = trunc i32 %2257 to i16
  %2259 = load i16, i16* %10, align 2
  %2260 = call signext i16 @safe_sub_func_int16_t_s_s(i16 signext %2258, i16 signext %2259)
  %2261 = trunc i16 %2260 to i8
  %2262 = load i32*, i32** %18, align 8
  %2263 = load i32, i32* %2262, align 4
  %2264 = call zeroext i8 @safe_lshift_func_uint8_t_u_s(i8 zeroext %2261, i32 %2263)
  %2265 = load i8*, i8** @g_1167, align 8
  %2266 = load i8, i8* %2265, align 1
  %2267 = call zeroext i8 @safe_add_func_uint8_t_u_u(i8 zeroext %2264, i8 zeroext %2266)
  %2268 = zext i8 %2267 to i32
  %2269 = load i32*, i32** @g_422, align 8
  %2270 = load i32, i32* %2269, align 4
  %2271 = icmp sge i32 %2268, %2270
  %2272 = zext i1 %2271 to i32
  %2273 = load i32**, i32*** %84, align 8
  %2274 = load i32*, i32** %2273, align 8
  %2275 = load i32, i32* %2274, align 4
  %2276 = icmp eq i32 %2272, %2275
  %2277 = zext i1 %2276 to i32
  %2278 = icmp ne i64* null, %8
  %2279 = zext i1 %2278 to i32
  %2280 = sext i32 %2279 to i64
  %2281 = icmp uge i64 %2280, 250
  br label %2282

2282:                                             ; preds = %2248, %2204
  %2283 = phi i1 [ false, %2204 ], [ %2281, %2248 ]
  %2284 = zext i1 %2283 to i32
  %2285 = load i32***, i32**** %101, align 8
  %2286 = load i32**, i32*** %2285, align 8
  %2287 = load i32*, i32** %2286, align 8
  store i32 %2284, i32* %2287, align 4
  br label %2288

2288:                                             ; preds = %2282, %2202
  %2289 = load i64, i64* %8, align 8
  %2290 = trunc i64 %2289 to i32
  %2291 = load i32*, i32** %18, align 8
  store i32 %2290, i32* %2291, align 4
  br label %2292

2292:                                             ; preds = %2288, %1112
  store i8 0, i8* %58, align 1
  br label %2293

2293:                                             ; preds = %2303, %2292
  %2294 = load i8, i8* %58, align 1
  %2295 = zext i8 %2294 to i32
  %2296 = icmp slt i32 %2295, 7
  br i1 %2296, label %2297, label %2306

2297:                                             ; preds = %2293
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_3309 to %union.U0*), %union.U0** %153, align 8
  %2298 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %2299 = load %union.U0*, %union.U0** %2298, align 8
  %2300 = call i32* @func_52(%union.U0* %2299, %union.U0* bitcast ({ i16, [6 x i8] }* @g_3309 to %union.U0*))
  %2301 = load i32***, i32**** %85, align 8
  %2302 = load i32**, i32*** %2301, align 8
  store i32* %2300, i32** %2302, align 8
  br label %2303

2303:                                             ; preds = %2297
  %2304 = load i8, i8* %58, align 1
  %2305 = add i8 %2304, 1
  store i8 %2305, i8* %58, align 1
  br label %2293

2306:                                             ; preds = %2293
  %2307 = load i8**, i8*** %15, align 8
  %2308 = load i8*, i8** %2307, align 8
  store i8* %2308, i8** %6, align 8
  br label %2317

2309:                                             ; preds = %551
  %2310 = load i32***, i32**** %67, align 8
  %2311 = load i32**, i32*** %2310, align 8
  %2312 = load i32*, i32** %2311, align 8
  %2313 = load i32**, i32*** @g_421, align 8
  store i32* %2312, i32** %2313, align 8
  br label %2314

2314:                                             ; preds = %2309, %421
  %2315 = load volatile i8**, i8*** @g_515, align 8
  %2316 = load i8*, i8** %2315, align 8
  store i8* %2316, i8** %6, align 8
  br label %2317

2317:                                             ; preds = %2314, %2306, %2089, %1548
  %2318 = load i8*, i8** %6, align 8
  ret i8* %2318
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i8* @func_13(i32 %0, i16 zeroext %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i16, align 2
  %5 = alloca i32*, align 8
  %6 = alloca [9 x i32*], align 16
  %7 = alloca %union.U0*, align 8
  %8 = alloca %union.U0*, align 8
  %9 = alloca i8*, align 8
  %10 = alloca i32, align 4
  %11 = alloca i32, align 4
  %12 = alloca i32, align 4
  %13 = alloca i32*, align 8
  %14 = alloca i32, align 4
  %15 = alloca i32, align 4
  store i32 %0, i32* %3, align 4
  store i16 %1, i16* %4, align 2
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 0, i64 1), i32** %5, align 8
  %16 = bitcast [9 x i32*]* %6 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %16, i8* align 16 bitcast ([9 x i32*]* @__const.func_13.l_2898 to i8*), i64 72, i1 false)
  store %union.U0* getelementptr inbounds ([4 x [9 x [7 x %union.U0]]], [4 x [9 x [7 x %union.U0]]]* bitcast ([4 x [9 x [7 x { i16, [6 x i8] }]]]* @g_494 to [4 x [9 x [7 x %union.U0]]]*), i64 0, i64 2, i64 5, i64 2), %union.U0** %7, align 8
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*), %union.U0** %8, align 8
  store i8* @g_82, i8** %9, align 8
  %17 = load i32*, i32** %5, align 8
  %18 = load i32**, i32*** @g_421, align 8
  store i32* %17, i32** %18, align 8
  %19 = load i32*, i32** %5, align 8
  %20 = load i32, i32* %19, align 4
  %21 = load volatile i32*, i32** @g_378, align 8
  %22 = load i32, i32* %21, align 4
  %23 = xor i32 %22, %20
  store i32 %23, i32* %21, align 4
  %24 = load %union.U0*, %union.U0** %7, align 8
  %25 = call i32* @func_52(%union.U0* %24, %union.U0* bitcast ({ i16, [6 x i8] }* @g_635 to %union.U0*))
  %26 = load i32**, i32*** @g_421, align 8
  store i32* %25, i32** %26, align 8
  store i8 25, i8* @g_116, align 1
  br label %27

27:                                               ; preds = %93, %2
  %28 = load i8, i8* @g_116, align 1
  %29 = sext i8 %28 to i32
  %30 = icmp eq i32 %29, 27
  br i1 %30, label %31, label %96

31:                                               ; preds = %27
  store i32 7, i32* %11, align 4
  store i32 -1295525390, i32* %12, align 4
  store i32* getelementptr inbounds ([9 x [7 x [4 x i32]]], [9 x [7 x [4 x i32]]]* @g_169, i64 0, i64 5, i64 4, i64 3), i32** %13, align 8
  store i32 1, i32* %14, align 4
  store i32 458103139, i32* %15, align 4
  %32 = load i32, i32* %3, align 4
  %33 = load i32, i32* %11, align 4
  %34 = icmp ule i32 %32, %33
  %35 = zext i1 %34 to i32
  %36 = load i32*, i32** %5, align 8
  %37 = load i32, i32* %36, align 4
  %38 = and i32 %37, %35
  store i32 %38, i32* %36, align 4
  %39 = load volatile i32**, i32*** @g_2015, align 8
  %40 = load i32*, i32** %39, align 8
  %41 = load i32, i32* %40, align 4
  %42 = sext i32 %41 to i64
  %43 = load i32*, i32** %13, align 8
  %44 = load i32, i32* %43, align 4
  %45 = add i32 %44, -1
  store i32 %45, i32* %43, align 4
  %46 = load i32*, i32** @g_1358, align 8
  %47 = load i32, i32* %46, align 4
  %48 = icmp uge i32 %44, %47
  %49 = zext i1 %48 to i32
  %50 = load i64**, i64*** @g_2096, align 8
  %51 = load i64*, i64** %50, align 8
  %52 = load i64, i64* %51, align 8
  %53 = add i64 %52, -1
  store i64 %53, i64* %51, align 8
  %54 = load i16, i16* %4, align 2
  %55 = trunc i16 %54 to i8
  %56 = load i32, i32* %3, align 4
  store i32 %56, i32* %12, align 4
  %57 = icmp ne i32 %56, 0
  %58 = zext i1 %57 to i32
  %59 = load i32, i32* %14, align 4
  %60 = or i32 %59, %58
  store i32 %60, i32* %14, align 4
  %61 = call signext i8 @safe_lshift_func_int8_t_s_s(i8 signext %55, i32 %60)
  %62 = sext i8 %61 to i64
  %63 = call i64 @safe_div_func_uint64_t_u_u(i64 %52, i64 %62)
  %64 = icmp uge i64 %42, %63
  %65 = zext i1 %64 to i32
  %66 = icmp sle i32 %38, %65
  %67 = zext i1 %66 to i32
  %68 = load i8*, i8** @g_1167, align 8
  %69 = load i8, i8* %68, align 1
  %70 = call zeroext i8 @safe_rshift_func_uint8_t_u_s(i8 zeroext %69, i32 2)
  %71 = zext i8 %70 to i32
  %72 = or i32 %67, %71
  %73 = trunc i32 %72 to i8
  %74 = load i8*, i8** @g_516, align 8
  store i8 %73, i8* %74, align 1
  %75 = sext i8 %73 to i32
  %76 = load i32, i32* %15, align 4
  %77 = or i32 %76, %75
  store i32 %77, i32* %15, align 4
  %78 = trunc i32 %77 to i8
  %79 = load i32, i32* %11, align 4
  %80 = zext i32 %79 to i64
  %81 = or i64 936233732, %80
  %82 = icmp sle i64 %81, 806081974
  %83 = zext i1 %82 to i32
  %84 = sext i32 %83 to i64
  %85 = xor i64 %84, 3519306677
  %86 = load i16, i16* %4, align 2
  %87 = zext i16 %86 to i64
  %88 = or i64 %85, %87
  %89 = trunc i64 %88 to i32
  %90 = call signext i8 @safe_lshift_func_int8_t_s_u(i8 signext %78, i32 %89)
  %91 = sext i8 %90 to i32
  %92 = load i32*, i32** @g_422, align 8
  store i32 %91, i32* %92, align 4
  br label %93

93:                                               ; preds = %31
  %94 = load i8, i8* @g_116, align 1
  %95 = add i8 %94, 1
  store i8 %95, i8* @g_116, align 1
  br label %27

96:                                               ; preds = %27
  ret i8* @g_82
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i8* @func_17(i64 %0, %union.U0* %1, i16 zeroext %2, i16 signext %3) #0 {
  %5 = alloca %union.U0, align 8
  %6 = alloca i64, align 8
  %7 = alloca %union.U0*, align 8
  %8 = alloca i16, align 2
  %9 = alloca i16, align 2
  %10 = alloca i32*, align 8
  %11 = alloca i8*, align 8
  %12 = alloca i32*, align 8
  %13 = alloca i8*, align 8
  %14 = alloca %union.U0**, align 8
  %15 = alloca [3 x %union.U0**], align 16
  %16 = alloca %union.U0*, align 8
  %17 = alloca %union.U0**, align 8
  %18 = alloca i32****, align 8
  %19 = alloca [8 x [10 x [3 x i32]]], align 16
  %20 = alloca i32, align 4
  %21 = alloca i32, align 4
  %22 = alloca i32, align 4
  %23 = alloca i8, align 1
  %24 = alloca i16*, align 8
  %25 = alloca i32****, align 8
  %26 = alloca i32*****, align 8
  %27 = alloca i32*****, align 8
  %28 = alloca i32*****, align 8
  %29 = alloca i32*****, align 8
  %30 = alloca [1 x i8*], align 8
  %31 = alloca i32, align 4
  %32 = alloca i32, align 4
  %33 = alloca i32, align 4
  %34 = alloca [7 x [4 x [2 x i32]]], align 16
  %35 = alloca i32, align 4
  %36 = alloca i8***, align 8
  %37 = alloca i32, align 4
  %38 = alloca i32, align 4
  %39 = alloca i32, align 4
  %40 = alloca i32, align 4
  %41 = alloca i32****, align 8
  %42 = alloca i32*****, align 8
  %43 = alloca i8**, align 8
  %44 = alloca [7 x i64*], align 16
  %45 = alloca i32, align 4
  %46 = alloca i32, align 4
  %47 = alloca i8, align 1
  %48 = alloca [5 x i32], align 16
  %49 = alloca i32, align 4
  %50 = alloca i32*****, align 8
  %51 = alloca [2 x i32*], align 16
  %52 = alloca i8, align 1
  %53 = alloca %union.U0*, align 8
  %54 = alloca i32, align 4
  %55 = alloca [4 x [7 x i32*]], align 16
  %56 = alloca [4 x [4 x i16*]], align 16
  %57 = alloca i64*, align 8
  %58 = alloca i32, align 4
  %59 = alloca i16, align 2
  %60 = alloca i32, align 4
  %61 = alloca i32, align 4
  %62 = alloca %union.U0, align 8
  %63 = alloca [4 x [7 x i32*****]], align 16
  %64 = alloca i32, align 4
  %65 = alloca i32, align 4
  %66 = alloca i32, align 4
  %67 = alloca [9 x i32], align 16
  %68 = alloca i32**, align 8
  %69 = alloca i64**, align 8
  %70 = alloca i64***, align 8
  %71 = alloca i32, align 4
  %72 = alloca i32, align 4
  %73 = alloca i32, align 4
  %74 = alloca i32**, align 8
  %75 = alloca [6 x [2 x [5 x i32***]]], align 16
  %76 = alloca i32, align 4
  %77 = alloca i32, align 4
  %78 = alloca i32, align 4
  %79 = alloca [4 x [3 x i32***]], align 16
  %80 = alloca i32****, align 8
  %81 = alloca [6 x [10 x [1 x i8****]]], align 16
  %82 = alloca i32, align 4
  %83 = alloca i32, align 4
  %84 = alloca i32, align 4
  %85 = alloca i32, align 4
  %86 = alloca i32, align 4
  %87 = alloca i32, align 4
  %88 = alloca i32, align 4
  %89 = alloca i32, align 4
  %90 = alloca i32, align 4
  %91 = alloca i32, align 4
  %92 = alloca i32, align 4
  %93 = alloca i32, align 4
  %94 = alloca i32, align 4
  %95 = alloca i32, align 4
  %96 = alloca [7 x i32], align 16
  %97 = alloca i32, align 4
  %98 = alloca i32, align 4
  store i64 %0, i64* %6, align 8
  store %union.U0* %1, %union.U0** %7, align 8
  store i16 %2, i16* %8, align 2
  store i16 %3, i16* %9, align 2
  store i32* @g_45, i32** %10, align 8
  store i8* @g_116, i8** %11, align 8
  store i32* getelementptr inbounds ([9 x [7 x [4 x i32]]], [9 x [7 x [4 x i32]]]* @g_169, i64 0, i64 5, i64 4, i64 3), i32** %12, align 8
  store i8* null, i8** %13, align 8
  store %union.U0** @g_136, %union.U0*** %14, align 8
  store %union.U0* null, %union.U0** %16, align 8
  store %union.U0** %16, %union.U0*** %17, align 8
  store i32**** null, i32***** %18, align 8
  %99 = bitcast [8 x [10 x [3 x i32]]]* %19 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %99, i8* align 16 bitcast ([8 x [10 x [3 x i32]]]* @__const.func_17.l_2791 to i8*), i64 960, i1 false)
  store i32 0, i32* %20, align 4
  br label %100

100:                                              ; preds = %107, %4
  %101 = load i32, i32* %20, align 4
  %102 = icmp slt i32 %101, 3
  br i1 %102, label %103, label %110

103:                                              ; preds = %100
  %104 = load i32, i32* %20, align 4
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds [3 x %union.U0**], [3 x %union.U0**]* %15, i64 0, i64 %105
  store %union.U0** null, %union.U0*** %106, align 8
  br label %107

107:                                              ; preds = %103
  %108 = load i32, i32* %20, align 4
  %109 = add nsw i32 %108, 1
  store i32 %109, i32* %20, align 4
  br label %100

110:                                              ; preds = %100
  br label %111

111:                                              ; preds = %869, %110
  %112 = load i32*, i32** %10, align 8
  %113 = load i32**, i32*** @g_421, align 8
  store i32* %112, i32** %113, align 8
  %114 = load %union.U0*, %union.U0** @g_1921, align 8
  %115 = load i32*, i32** %10, align 8
  %116 = load i32**, i32*** @g_421, align 8
  store i32* %115, i32** %116, align 8
  %117 = load i32*, i32** %10, align 8
  %118 = load i32, i32* %117, align 4
  store i8* null, i8** %11, align 8
  %119 = call %union.U0* @func_48(i32* %115, i32 %118, i8* null)
  %120 = load i32*, i32** %10, align 8
  %121 = load i32*, i32** %10, align 8
  %122 = load i32, i32* %121, align 4
  %123 = load i32*, i32** %12, align 8
  store i32 %122, i32* %123, align 4
  %124 = load i8*, i8** %13, align 8
  %125 = call %union.U0* @func_48(i32* %120, i32 %122, i8* %124)
  %126 = call i32* @func_52(%union.U0* %119, %union.U0* %125)
  %127 = load i64, i64* %6, align 8
  %128 = trunc i64 %127 to i32
  %129 = load i8*, i8** %13, align 8
  %130 = call %union.U0* @func_48(i32* %126, i32 %128, i8* %129)
  %131 = load %union.U0**, %union.U0*** %14, align 8
  store %union.U0* %130, %union.U0** %131, align 8
  %132 = load %union.U0**, %union.U0*** %17, align 8
  store %union.U0* %130, %union.U0** %132, align 8
  %133 = call i32* @func_52(%union.U0* %114, %union.U0* %130)
  %134 = load i32**, i32*** @g_421, align 8
  store i32* %133, i32** %134, align 8
  %135 = load i32*, i32** %10, align 8
  %136 = load i32, i32* %135, align 4
  %137 = icmp ne i32 %136, 0
  br i1 %137, label %138, label %895

138:                                              ; preds = %111
  store i8 -78, i8* %23, align 1
  store i16* getelementptr inbounds ([5 x i16], [5 x i16]* @g_910, i64 0, i64 0), i16** %24, align 8
  store i32**** null, i32***** %25, align 8
  store i32***** null, i32****** %26, align 8
  store i32***** null, i32****** %27, align 8
  store i32***** null, i32****** %28, align 8
  store i32***** %25, i32****** %29, align 8
  store i32 -1779192282, i32* %31, align 4
  store i32 1638983426, i32* %32, align 4
  store i32 -5, i32* %33, align 4
  %139 = bitcast [7 x [4 x [2 x i32]]]* %34 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %139, i8* align 16 bitcast ([7 x [4 x [2 x i32]]]* @__const.func_17.l_2794 to i8*), i64 224, i1 false)
  store i32 -1691379267, i32* %35, align 4
  store i8*** @g_340, i8**** %36, align 8
  store i32 -1, i32* %37, align 4
  store i32 0, i32* %38, align 4
  br label %140

140:                                              ; preds = %147, %138
  %141 = load i32, i32* %38, align 4
  %142 = icmp slt i32 %141, 1
  br i1 %142, label %143, label %150

143:                                              ; preds = %140
  %144 = load i32, i32* %38, align 4
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds [1 x i8*], [1 x i8*]* %30, i64 0, i64 %145
  store i8* null, i8** %146, align 8
  br label %147

147:                                              ; preds = %143
  %148 = load i32, i32* %38, align 4
  %149 = add nsw i32 %148, 1
  store i32 %149, i32* %38, align 4
  br label %140

150:                                              ; preds = %140
  %151 = load i16, i16* %9, align 2
  %152 = load i8, i8* %23, align 1
  %153 = sext i8 %152 to i64
  %154 = load i64, i64* %6, align 8
  %155 = icmp sgt i64 %153, %154
  %156 = zext i1 %155 to i32
  %157 = trunc i32 %156 to i8
  %158 = load i8*, i8** @g_1167, align 8
  store i8 %157, i8* %158, align 1
  %159 = zext i8 %157 to i64
  %160 = icmp sle i64 %159, 246
  %161 = zext i1 %160 to i32
  %162 = trunc i32 %161 to i16
  %163 = load i16*, i16** @g_369, align 8
  %164 = load i16, i16* %163, align 2
  %165 = sext i16 %164 to i32
  %166 = load i16*, i16** %24, align 8
  %167 = load i16, i16* %166, align 2
  %168 = sext i16 %167 to i32
  %169 = xor i32 %168, %165
  %170 = trunc i32 %169 to i16
  store i16 %170, i16* %166, align 2
  %171 = load i16*, i16** @g_369, align 8
  store i16 %170, i16* %171, align 2
  %172 = call signext i16 @safe_add_func_int16_t_s_s(i16 signext %162, i16 signext %170)
  %173 = sext i16 %172 to i32
  %174 = load i32****, i32***** %25, align 8
  %175 = load i32*****, i32****** %29, align 8
  store i32**** %174, i32***** %175, align 8
  %176 = load i32****, i32***** @g_2763, align 8
  %177 = icmp ne i32**** %174, %176
  %178 = zext i1 %177 to i32
  %179 = trunc i32 %178 to i8
  %180 = load i8, i8* %23, align 1
  %181 = load i64, i64* %6, align 8
  %182 = trunc i64 %181 to i8
  %183 = call signext i8 @safe_sub_func_int8_t_s_s(i8 signext %179, i8 signext %182)
  %184 = sext i8 %183 to i32
  %185 = icmp ne i32 %173, %184
  %186 = zext i1 %185 to i32
  store i32 %186, i32* %31, align 4
  %187 = xor i1 %185, true
  %188 = zext i1 %187 to i32
  %189 = sext i32 %188 to i64
  %190 = load i64, i64* %6, align 8
  %191 = icmp slt i64 %189, %190
  %192 = zext i1 %191 to i32
  store i32 %192, i32* %32, align 4
  br i1 %191, label %193, label %261

193:                                              ; preds = %150
  store i32**** @g_2591, i32***** %41, align 8
  store i32***** %41, i32****** %42, align 8
  store i8** %13, i8*** %43, align 8
  store i32 -2052635347, i32* %45, align 4
  store i32 0, i32* %46, align 4
  br label %194

194:                                              ; preds = %201, %193
  %195 = load i32, i32* %46, align 4
  %196 = icmp slt i32 %195, 7
  br i1 %196, label %197, label %204

197:                                              ; preds = %194
  %198 = load i32, i32* %46, align 4
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds [7 x i64*], [7 x i64*]* %44, i64 0, i64 %199
  store i64* @g_2113, i64** %200, align 8
  br label %201

201:                                              ; preds = %197
  %202 = load i32, i32* %46, align 4
  %203 = add nsw i32 %202, 1
  store i32 %203, i32* %46, align 4
  br label %194

204:                                              ; preds = %194
  %205 = load i16, i16* %8, align 2
  %206 = zext i16 %205 to i32
  %207 = icmp ne i32 %206, 0
  br i1 %207, label %208, label %217

208:                                              ; preds = %204
  %209 = load i32*****, i32****** %42, align 8
  store i32***** %209, i32****** @g_2777, align 8
  %210 = icmp ne i32***** %209, getelementptr inbounds ([5 x [1 x [1 x i32****]]], [5 x [1 x [1 x i32****]]]* @g_2729, i64 0, i64 3, i64 0, i64 0)
  %211 = zext i1 %210 to i32
  %212 = load i32****, i32***** %18, align 8
  %213 = icmp eq i32**** %212, null
  %214 = zext i1 %213 to i32
  %215 = sext i32 %214 to i64
  %216 = icmp ne i64 %215, 2262989703
  br label %217

217:                                              ; preds = %208, %204
  %218 = phi i1 [ false, %204 ], [ %216, %208 ]
  %219 = zext i1 %218 to i32
  %220 = load i64, i64* %6, align 8
  %221 = icmp ne i64 %220, 0
  br i1 %221, label %222, label %245

222:                                              ; preds = %217
  %223 = load i8**, i8*** %43, align 8
  store i8* %23, i8** %223, align 8
  %224 = load volatile i8**, i8*** @g_515, align 8
  %225 = load i8*, i8** %224, align 8
  %226 = icmp eq i8* %23, %225
  %227 = zext i1 %226 to i32
  %228 = sext i32 %227 to i64
  store i64 %228, i64* @g_2113, align 8
  %229 = load i32, i32* %45, align 4
  %230 = trunc i32 %229 to i8
  %231 = load i32, i32* %45, align 4
  %232 = trunc i32 %231 to i8
  %233 = call zeroext i8 @safe_mul_func_uint8_t_u_u(i8 zeroext %230, i8 zeroext %232)
  %234 = zext i8 %233 to i32
  %235 = icmp ne i32 %234, 0
  br i1 %235, label %240, label %236

236:                                              ; preds = %222
  %237 = load i32*, i32** %10, align 8
  %238 = load i32, i32* %237, align 4
  %239 = icmp ne i32 %238, 0
  br label %240

240:                                              ; preds = %236, %222
  %241 = phi i1 [ true, %222 ], [ %239, %236 ]
  %242 = zext i1 %241 to i32
  %243 = sext i32 %242 to i64
  store i64 %243, i64* @g_617, align 8
  %244 = icmp ne i64 %243, 0
  br label %245

245:                                              ; preds = %240, %217
  %246 = phi i1 [ false, %217 ], [ %244, %240 ]
  %247 = zext i1 %246 to i32
  %248 = icmp sle i32 %219, %247
  %249 = zext i1 %248 to i32
  %250 = trunc i32 %249 to i8
  %251 = load i16, i16* %8, align 2
  %252 = trunc i16 %251 to i8
  %253 = call zeroext i8 @safe_add_func_uint8_t_u_u(i8 zeroext %250, i8 zeroext %252)
  %254 = zext i8 %253 to i16
  %255 = load i64, i64* %6, align 8
  %256 = trunc i64 %255 to i16
  %257 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %254, i16 zeroext %256)
  %258 = zext i16 %257 to i32
  %259 = load i32, i32* %31, align 4
  %260 = xor i32 %259, %258
  store i32 %260, i32* %31, align 4
  br label %877

261:                                              ; preds = %150
  store i8 0, i8* %47, align 1
  %262 = bitcast [5 x i32]* %48 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %262, i8* align 16 bitcast ([5 x i32]* @__const.func_17.l_2792 to i8*), i64 20, i1 false)
  store i32 159200493, i32* %49, align 4
  store i32***** %25, i32****** %50, align 8
  store i8 -76, i8* %52, align 1
  store %union.U0* getelementptr inbounds ([6 x [1 x [7 x %union.U0]]], [6 x [1 x [7 x %union.U0]]]* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to [6 x [1 x [7 x %union.U0]]]*), i64 0, i64 2, i64 0, i64 1), %union.U0** %53, align 8
  store i32 0, i32* %54, align 4
  br label %263

263:                                              ; preds = %270, %261
  %264 = load i32, i32* %54, align 4
  %265 = icmp slt i32 %264, 2
  br i1 %265, label %266, label %273

266:                                              ; preds = %263
  %267 = load i32, i32* %54, align 4
  %268 = sext i32 %267 to i64
  %269 = getelementptr inbounds [2 x i32*], [2 x i32*]* %51, i64 0, i64 %268
  store i32* %35, i32** %269, align 8
  br label %270

270:                                              ; preds = %266
  %271 = load i32, i32* %54, align 4
  %272 = add nsw i32 %271, 1
  store i32 %272, i32* %54, align 4
  br label %263

273:                                              ; preds = %263
  store i32 -8, i32* %31, align 4
  br label %274

274:                                              ; preds = %871, %273
  %275 = load i32, i32* %31, align 4
  %276 = icmp ne i32 %275, 13
  br i1 %276, label %277, label %876

277:                                              ; preds = %274
  %278 = bitcast [4 x [7 x i32*]]* %55 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %278, i8* align 16 bitcast ([4 x [7 x i32*]]* @__const.func_17.l_2790 to i8*), i64 224, i1 false)
  %279 = bitcast [4 x [4 x i16*]]* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %279, i8* align 16 bitcast ([4 x [4 x i16*]]* @__const.func_17.l_2814 to i8*), i64 128, i1 false)
  store i64* null, i64** %57, align 8
  store i32 -1, i32* %58, align 4
  store i16 1, i16* %59, align 2
  %280 = load volatile i8, i8* @g_2796, align 1
  %281 = add i8 %280, 1
  store volatile i8 %281, i8* @g_2796, align 1
  %282 = getelementptr inbounds [4 x [7 x i32*]], [4 x [7 x i32*]]* %55, i64 0, i64 2
  %283 = getelementptr inbounds [7 x i32*], [7 x i32*]* %282, i64 0, i64 6
  %284 = load i32*, i32** %283, align 16
  %285 = icmp ne i32* null, %284
  %286 = zext i1 %285 to i32
  %287 = sext i32 %286 to i64
  %288 = bitcast %union.U0* %62 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %288, i8* align 8 bitcast ({ i16, [6 x i8] }* @g_2807 to i8*), i64 8, i1 true)
  %289 = load i16, i16* %8, align 2
  %290 = zext i16 %289 to i32
  %291 = icmp ne i32 %290, 0
  br i1 %291, label %292, label %337

292:                                              ; preds = %277
  %293 = load i16, i16* %9, align 2
  %294 = trunc i16 %293 to i8
  %295 = load i16***, i16**** @g_723, align 8
  %296 = load i16**, i16*** %295, align 8
  %297 = load i16*, i16** %296, align 8
  %298 = load volatile i16, i16* %297, align 2
  %299 = zext i16 %298 to i32
  %300 = load i32, i32* getelementptr inbounds ([9 x [9 x [3 x i32]]], [9 x [9 x [3 x i32]]]* @g_1269, i64 0, i64 0, i64 8, i64 2), align 8
  %301 = load i32, i32* @g_675, align 4
  %302 = icmp ne i32 %300, %301
  %303 = zext i1 %302 to i32
  %304 = load i32*, i32** %10, align 8
  %305 = load i32, i32* %304, align 4
  %306 = or i32 %305, %303
  store i32 %306, i32* %304, align 4
  %307 = icmp sge i32 %299, %306
  %308 = zext i1 %307 to i32
  %309 = trunc i32 %308 to i8
  %310 = call zeroext i8 @safe_add_func_uint8_t_u_u(i8 zeroext %294, i8 zeroext %309)
  %311 = load volatile i16****, i16***** @g_722, align 8
  %312 = load volatile i16***, i16**** %311, align 8
  %313 = load i16**, i16*** %312, align 8
  %314 = load i16*, i16** %313, align 8
  %315 = load volatile i16, i16* %314, align 2
  %316 = zext i16 %315 to i64
  %317 = icmp sle i64 %316, -4
  %318 = zext i1 %317 to i32
  %319 = sext i32 %318 to i64
  %320 = icmp eq i64 7915311967974446242, %319
  %321 = zext i1 %320 to i32
  %322 = getelementptr inbounds [7 x [4 x [2 x i32]]], [7 x [4 x [2 x i32]]]* %34, i64 0, i64 3
  %323 = getelementptr inbounds [4 x [2 x i32]], [4 x [2 x i32]]* %322, i64 0, i64 1
  %324 = getelementptr inbounds [2 x i32], [2 x i32]* %323, i64 0, i64 0
  %325 = load i32, i32* %324, align 8
  %326 = and i32 %321, %325
  %327 = sext i32 %326 to i64
  %328 = call i64 @safe_sub_func_int64_t_s_s(i64 %327, i64 5)
  %329 = load volatile i32**, i32*** @g_2674, align 8
  %330 = load i32*, i32** %329, align 8
  %331 = load i32, i32* %330, align 4
  %332 = load i64, i64* %6, align 8
  %333 = load i64, i64* @g_617, align 8
  %334 = and i64 %333, %332
  store i64 %334, i64* @g_617, align 8
  %335 = trunc i64 %334 to i32
  store i32 %335, i32* %35, align 4
  %336 = icmp ne i32 %335, 0
  br label %337

337:                                              ; preds = %292, %277
  %338 = phi i1 [ false, %277 ], [ %336, %292 ]
  %339 = zext i1 %338 to i32
  %340 = trunc i32 %339 to i8
  %341 = load i8*, i8** @g_1167, align 8
  %342 = load i8, i8* %341, align 1
  %343 = call zeroext i8 @safe_mul_func_uint8_t_u_u(i8 zeroext %340, i8 zeroext %342)
  %344 = zext i8 %343 to i32
  %345 = load i16, i16* %9, align 2
  %346 = sext i16 %345 to i32
  %347 = icmp ne i32 %344, %346
  %348 = zext i1 %347 to i32
  %349 = getelementptr inbounds [5 x i32], [5 x i32]* %48, i64 0, i64 3
  %350 = load i32, i32* %349, align 4
  %351 = icmp eq i32 %348, %350
  %352 = zext i1 %351 to i32
  %353 = trunc i32 %352 to i16
  %354 = call signext i16 @safe_div_func_int16_t_s_s(i16 signext %353, i16 signext 16367)
  store i32 -2, i32* %32, align 4
  %355 = getelementptr inbounds [5 x i32], [5 x i32]* %48, i64 0, i64 3
  %356 = load i32, i32* %355, align 4
  %357 = sext i32 %356 to i64
  %358 = call i64 @safe_mod_func_uint64_t_u_u(i64 -2, i64 %357)
  %359 = load i32, i32* %49, align 4
  %360 = zext i32 %359 to i64
  %361 = or i64 %358, %360
  %362 = trunc i64 %361 to i16
  %363 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %362, i16 zeroext 25846)
  %364 = call zeroext i16 @safe_sub_func_uint16_t_u_u(i16 zeroext %363, i16 zeroext 14474)
  %365 = zext i16 %364 to i64
  %366 = icmp ugt i64 %287, %365
  br i1 %366, label %367, label %863

367:                                              ; preds = %337
  %368 = getelementptr inbounds [4 x [7 x i32*****]], [4 x [7 x i32*****]]* %63, i64 0, i64 0
  %369 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %368, i64 0, i64 0
  store i32***** %25, i32****** %369, align 8
  %370 = getelementptr inbounds i32*****, i32****** %369, i64 1
  store i32***** %25, i32****** %370, align 8
  %371 = getelementptr inbounds i32*****, i32****** %370, i64 1
  store i32***** %25, i32****** %371, align 8
  %372 = getelementptr inbounds i32*****, i32****** %371, i64 1
  store i32***** %25, i32****** %372, align 8
  %373 = getelementptr inbounds i32*****, i32****** %372, i64 1
  store i32***** %25, i32****** %373, align 8
  %374 = getelementptr inbounds i32*****, i32****** %373, i64 1
  store i32***** %25, i32****** %374, align 8
  %375 = getelementptr inbounds i32*****, i32****** %374, i64 1
  store i32***** %25, i32****** %375, align 8
  %376 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %368, i64 1
  %377 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %376, i64 0, i64 0
  store i32***** %25, i32****** %377, align 8
  %378 = getelementptr inbounds i32*****, i32****** %377, i64 1
  store i32***** %25, i32****** %378, align 8
  %379 = getelementptr inbounds i32*****, i32****** %378, i64 1
  store i32***** %25, i32****** %379, align 8
  %380 = getelementptr inbounds i32*****, i32****** %379, i64 1
  store i32***** %25, i32****** %380, align 8
  %381 = getelementptr inbounds i32*****, i32****** %380, i64 1
  store i32***** %25, i32****** %381, align 8
  %382 = getelementptr inbounds i32*****, i32****** %381, i64 1
  store i32***** %25, i32****** %382, align 8
  %383 = getelementptr inbounds i32*****, i32****** %382, i64 1
  store i32***** %25, i32****** %383, align 8
  %384 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %376, i64 1
  %385 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %384, i64 0, i64 0
  store i32***** %25, i32****** %385, align 8
  %386 = getelementptr inbounds i32*****, i32****** %385, i64 1
  store i32***** %25, i32****** %386, align 8
  %387 = getelementptr inbounds i32*****, i32****** %386, i64 1
  store i32***** %25, i32****** %387, align 8
  %388 = getelementptr inbounds i32*****, i32****** %387, i64 1
  store i32***** %25, i32****** %388, align 8
  %389 = getelementptr inbounds i32*****, i32****** %388, i64 1
  store i32***** %25, i32****** %389, align 8
  %390 = getelementptr inbounds i32*****, i32****** %389, i64 1
  store i32***** %25, i32****** %390, align 8
  %391 = getelementptr inbounds i32*****, i32****** %390, i64 1
  store i32***** %25, i32****** %391, align 8
  %392 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %384, i64 1
  %393 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %392, i64 0, i64 0
  store i32***** %25, i32****** %393, align 8
  %394 = getelementptr inbounds i32*****, i32****** %393, i64 1
  store i32***** %25, i32****** %394, align 8
  %395 = getelementptr inbounds i32*****, i32****** %394, i64 1
  store i32***** %25, i32****** %395, align 8
  %396 = getelementptr inbounds i32*****, i32****** %395, i64 1
  store i32***** %25, i32****** %396, align 8
  %397 = getelementptr inbounds i32*****, i32****** %396, i64 1
  store i32***** %25, i32****** %397, align 8
  %398 = getelementptr inbounds i32*****, i32****** %397, i64 1
  store i32***** %25, i32****** %398, align 8
  %399 = getelementptr inbounds i32*****, i32****** %398, i64 1
  store i32***** %25, i32****** %399, align 8
  store i32 -1095506702, i32* %64, align 4
  store i32 -1, i32* %65, align 4
  store i32 -1, i32* %66, align 4
  %400 = bitcast [9 x i32]* %67 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %400, i8* align 16 bitcast ([9 x i32]* @__const.func_17.l_2832 to i8*), i64 36, i1 false)
  store i32** null, i32*** %68, align 8
  store i64** %57, i64*** %69, align 8
  store i64*** %69, i64**** %70, align 8
  %401 = load i64, i64* %6, align 8
  %402 = load i32, i32* %49, align 4
  %403 = load i32*****, i32****** %50, align 8
  %404 = getelementptr inbounds [4 x [7 x i32*****]], [4 x [7 x i32*****]]* %63, i64 0, i64 0
  %405 = getelementptr inbounds [7 x i32*****], [7 x i32*****]* %404, i64 0, i64 5
  %406 = load i32*****, i32****** %405, align 8
  %407 = icmp eq i32***** %403, %406
  %408 = zext i1 %407 to i32
  %409 = icmp ult i32 %402, %408
  %410 = zext i1 %409 to i32
  %411 = sext i32 %410 to i64
  %412 = and i64 %401, %411
  %413 = icmp ne i64 %412, 0
  br i1 %413, label %414, label %455

414:                                              ; preds = %367
  %415 = load i32*, i32** %10, align 8
  %416 = load i32, i32* %415, align 4
  %417 = sext i32 %416 to i64
  %418 = load i16, i16* %9, align 2
  %419 = sext i16 %418 to i64
  %420 = icmp uge i64 252, %419
  %421 = zext i1 %420 to i32
  %422 = load i16*****, i16****** @g_912, align 8
  %423 = load volatile i16****, i16***** %422, align 8
  %424 = load volatile i16***, i16**** %423, align 8
  %425 = load i16**, i16*** %424, align 8
  %426 = load i16*, i16** %425, align 8
  %427 = load volatile i16, i16* %426, align 2
  %428 = getelementptr inbounds [5 x i32], [5 x i32]* %48, i64 0, i64 3
  %429 = load i32, i32* %428, align 4
  %430 = trunc i32 %429 to i16
  %431 = call zeroext i16 @safe_mul_func_uint16_t_u_u(i16 zeroext %427, i16 zeroext %430)
  %432 = zext i16 %431 to i32
  %433 = xor i32 %432, -1
  %434 = trunc i32 %433 to i8
  %435 = load i32*, i32** %10, align 8
  %436 = load i32, i32* %435, align 4
  %437 = trunc i32 %436 to i8
  %438 = call signext i8 @safe_mul_func_int8_t_s_s(i8 signext %434, i8 signext %437)
  %439 = sext i8 %438 to i32
  %440 = and i32 %421, %439
  %441 = icmp ne i32 %440, 0
  br i1 %441, label %442, label %447

442:                                              ; preds = %414
  %443 = load i16*, i16** @g_369, align 8
  %444 = load i16, i16* %443, align 2
  %445 = sext i16 %444 to i32
  %446 = icmp ne i32 %445, 0
  br label %447

447:                                              ; preds = %442, %414
  %448 = phi i1 [ false, %414 ], [ %446, %442 ]
  %449 = zext i1 %448 to i32
  %450 = sext i32 %449 to i64
  %451 = call i64 @safe_mod_func_uint64_t_u_u(i64 %417, i64 %450)
  %452 = load i64, i64* @g_2113, align 8
  %453 = xor i64 %452, %451
  store i64 %453, i64* @g_2113, align 8
  %454 = icmp ne i64 %453, 0
  br label %455

455:                                              ; preds = %447, %367
  %456 = phi i1 [ false, %367 ], [ %454, %447 ]
  %457 = zext i1 %456 to i32
  %458 = sext i32 %457 to i64
  %459 = call i64 @safe_unary_minus_func_int64_t_s(i64 %458)
  %460 = load i64*, i64** @g_2097, align 8
  %461 = load i64, i64* %460, align 8
  %462 = call i64 @safe_div_func_int64_t_s_s(i64 %459, i64 %461)
  %463 = trunc i64 %462 to i32
  %464 = load i32*, i32** %10, align 8
  store i32 %463, i32* %464, align 4
  %465 = load volatile i32*, i32** @g_378, align 8
  store i32 %463, i32* %465, align 4
  %466 = load i64**, i64*** @g_1638, align 8
  %467 = load volatile i64*, i64** %466, align 8
  %468 = load volatile i64, i64* %467, align 8
  %469 = getelementptr inbounds [7 x [4 x [2 x i32]]], [7 x [4 x [2 x i32]]]* %34, i64 0, i64 3
  %470 = getelementptr inbounds [4 x [2 x i32]], [4 x [2 x i32]]* %469, i64 0, i64 1
  %471 = getelementptr inbounds [2 x i32], [2 x i32]* %470, i64 0, i64 0
  %472 = load i32, i32* %471, align 8
  %473 = sext i32 %472 to i64
  %474 = icmp ule i64 %468, %473
  br i1 %474, label %475, label %628

475:                                              ; preds = %455
  store i32 -1252127675, i32* %73, align 4
  store i32** null, i32*** %74, align 8
  %476 = getelementptr inbounds [6 x [2 x [5 x i32***]]], [6 x [2 x [5 x i32***]]]* %75, i64 0, i64 0
  %477 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %476, i64 0, i64 0
  %478 = getelementptr inbounds [5 x i32***], [5 x i32***]* %477, i64 0, i64 0
  store i32*** null, i32**** %478, align 8
  %479 = getelementptr inbounds i32***, i32**** %478, i64 1
  store i32*** null, i32**** %479, align 8
  %480 = getelementptr inbounds i32***, i32**** %479, i64 1
  store i32*** %74, i32**** %480, align 8
  %481 = getelementptr inbounds i32***, i32**** %480, i64 1
  store i32*** %74, i32**** %481, align 8
  %482 = getelementptr inbounds i32***, i32**** %481, i64 1
  store i32*** %74, i32**** %482, align 8
  %483 = getelementptr inbounds [5 x i32***], [5 x i32***]* %477, i64 1
  %484 = getelementptr inbounds [5 x i32***], [5 x i32***]* %483, i64 0, i64 0
  store i32*** %74, i32**** %484, align 8
  %485 = getelementptr inbounds i32***, i32**** %484, i64 1
  store i32*** null, i32**** %485, align 8
  %486 = getelementptr inbounds i32***, i32**** %485, i64 1
  store i32*** %74, i32**** %486, align 8
  %487 = getelementptr inbounds i32***, i32**** %486, i64 1
  store i32*** %74, i32**** %487, align 8
  %488 = getelementptr inbounds i32***, i32**** %487, i64 1
  store i32*** %74, i32**** %488, align 8
  %489 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %476, i64 1
  %490 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %489, i64 0, i64 0
  %491 = getelementptr inbounds [5 x i32***], [5 x i32***]* %490, i64 0, i64 0
  store i32*** %74, i32**** %491, align 8
  %492 = getelementptr inbounds i32***, i32**** %491, i64 1
  store i32*** null, i32**** %492, align 8
  %493 = getelementptr inbounds i32***, i32**** %492, i64 1
  store i32*** %74, i32**** %493, align 8
  %494 = getelementptr inbounds i32***, i32**** %493, i64 1
  store i32*** null, i32**** %494, align 8
  %495 = getelementptr inbounds i32***, i32**** %494, i64 1
  store i32*** %74, i32**** %495, align 8
  %496 = getelementptr inbounds [5 x i32***], [5 x i32***]* %490, i64 1
  %497 = getelementptr inbounds [5 x i32***], [5 x i32***]* %496, i64 0, i64 0
  store i32*** null, i32**** %497, align 8
  %498 = getelementptr inbounds i32***, i32**** %497, i64 1
  store i32*** null, i32**** %498, align 8
  %499 = getelementptr inbounds i32***, i32**** %498, i64 1
  store i32*** %74, i32**** %499, align 8
  %500 = getelementptr inbounds i32***, i32**** %499, i64 1
  store i32*** %74, i32**** %500, align 8
  %501 = getelementptr inbounds i32***, i32**** %500, i64 1
  store i32*** %74, i32**** %501, align 8
  %502 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %489, i64 1
  %503 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %502, i64 0, i64 0
  %504 = getelementptr inbounds [5 x i32***], [5 x i32***]* %503, i64 0, i64 0
  store i32*** %74, i32**** %504, align 8
  %505 = getelementptr inbounds i32***, i32**** %504, i64 1
  store i32*** null, i32**** %505, align 8
  %506 = getelementptr inbounds i32***, i32**** %505, i64 1
  store i32*** %74, i32**** %506, align 8
  %507 = getelementptr inbounds i32***, i32**** %506, i64 1
  store i32*** %74, i32**** %507, align 8
  %508 = getelementptr inbounds i32***, i32**** %507, i64 1
  store i32*** %74, i32**** %508, align 8
  %509 = getelementptr inbounds [5 x i32***], [5 x i32***]* %503, i64 1
  %510 = getelementptr inbounds [5 x i32***], [5 x i32***]* %509, i64 0, i64 0
  store i32*** null, i32**** %510, align 8
  %511 = getelementptr inbounds i32***, i32**** %510, i64 1
  store i32*** null, i32**** %511, align 8
  %512 = getelementptr inbounds i32***, i32**** %511, i64 1
  store i32*** %74, i32**** %512, align 8
  %513 = getelementptr inbounds i32***, i32**** %512, i64 1
  store i32*** %74, i32**** %513, align 8
  %514 = getelementptr inbounds i32***, i32**** %513, i64 1
  store i32*** %74, i32**** %514, align 8
  %515 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %502, i64 1
  %516 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %515, i64 0, i64 0
  %517 = getelementptr inbounds [5 x i32***], [5 x i32***]* %516, i64 0, i64 0
  store i32*** %74, i32**** %517, align 8
  %518 = getelementptr inbounds i32***, i32**** %517, i64 1
  store i32*** null, i32**** %518, align 8
  %519 = getelementptr inbounds i32***, i32**** %518, i64 1
  store i32*** %74, i32**** %519, align 8
  %520 = getelementptr inbounds i32***, i32**** %519, i64 1
  store i32*** %74, i32**** %520, align 8
  %521 = getelementptr inbounds i32***, i32**** %520, i64 1
  store i32*** %74, i32**** %521, align 8
  %522 = getelementptr inbounds [5 x i32***], [5 x i32***]* %516, i64 1
  %523 = getelementptr inbounds [5 x i32***], [5 x i32***]* %522, i64 0, i64 0
  store i32*** %74, i32**** %523, align 8
  %524 = getelementptr inbounds i32***, i32**** %523, i64 1
  store i32*** null, i32**** %524, align 8
  %525 = getelementptr inbounds i32***, i32**** %524, i64 1
  store i32*** %74, i32**** %525, align 8
  %526 = getelementptr inbounds i32***, i32**** %525, i64 1
  store i32*** null, i32**** %526, align 8
  %527 = getelementptr inbounds i32***, i32**** %526, i64 1
  store i32*** %74, i32**** %527, align 8
  %528 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %515, i64 1
  %529 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %528, i64 0, i64 0
  %530 = getelementptr inbounds [5 x i32***], [5 x i32***]* %529, i64 0, i64 0
  store i32*** null, i32**** %530, align 8
  %531 = getelementptr inbounds i32***, i32**** %530, i64 1
  store i32*** null, i32**** %531, align 8
  %532 = getelementptr inbounds i32***, i32**** %531, i64 1
  store i32*** %74, i32**** %532, align 8
  %533 = getelementptr inbounds i32***, i32**** %532, i64 1
  store i32*** %74, i32**** %533, align 8
  %534 = getelementptr inbounds i32***, i32**** %533, i64 1
  store i32*** %74, i32**** %534, align 8
  %535 = getelementptr inbounds [5 x i32***], [5 x i32***]* %529, i64 1
  %536 = getelementptr inbounds [5 x i32***], [5 x i32***]* %535, i64 0, i64 0
  store i32*** %74, i32**** %536, align 8
  %537 = getelementptr inbounds i32***, i32**** %536, i64 1
  store i32*** null, i32**** %537, align 8
  %538 = getelementptr inbounds i32***, i32**** %537, i64 1
  store i32*** %74, i32**** %538, align 8
  %539 = getelementptr inbounds i32***, i32**** %538, i64 1
  store i32*** %74, i32**** %539, align 8
  %540 = getelementptr inbounds i32***, i32**** %539, i64 1
  store i32*** %74, i32**** %540, align 8
  %541 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %528, i64 1
  %542 = getelementptr inbounds [2 x [5 x i32***]], [2 x [5 x i32***]]* %541, i64 0, i64 0
  %543 = getelementptr inbounds [5 x i32***], [5 x i32***]* %542, i64 0, i64 0
  store i32*** null, i32**** %543, align 8
  %544 = getelementptr inbounds i32***, i32**** %543, i64 1
  store i32*** null, i32**** %544, align 8
  %545 = getelementptr inbounds i32***, i32**** %544, i64 1
  store i32*** %74, i32**** %545, align 8
  %546 = getelementptr inbounds i32***, i32**** %545, i64 1
  store i32*** %74, i32**** %546, align 8
  %547 = getelementptr inbounds i32***, i32**** %546, i64 1
  store i32*** %74, i32**** %547, align 8
  %548 = getelementptr inbounds [5 x i32***], [5 x i32***]* %542, i64 1
  %549 = getelementptr inbounds [5 x i32***], [5 x i32***]* %548, i64 0, i64 0
  store i32*** %74, i32**** %549, align 8
  %550 = getelementptr inbounds i32***, i32**** %549, i64 1
  store i32*** null, i32**** %550, align 8
  %551 = getelementptr inbounds i32***, i32**** %550, i64 1
  store i32*** %74, i32**** %551, align 8
  %552 = getelementptr inbounds i32***, i32**** %551, i64 1
  store i32*** %74, i32**** %552, align 8
  %553 = getelementptr inbounds i32***, i32**** %552, i64 1
  store i32*** %74, i32**** %553, align 8
  %554 = load i32, i32* %73, align 4
  %555 = add i32 %554, -1
  store i32 %555, i32* %73, align 4
  %556 = load i16*, i16** @g_369, align 8
  %557 = load i16, i16* %556, align 2
  %558 = load i32, i32* %73, align 4
  %559 = trunc i32 %558 to i8
  %560 = load i8*, i8** @g_516, align 8
  store i8 %559, i8* %560, align 1
  %561 = call signext i8 @safe_lshift_func_int8_t_s_s(i8 signext %559, i32 1)
  %562 = sext i8 %561 to i32
  %563 = call signext i16 @safe_rshift_func_int16_t_s_u(i16 signext %557, i32 %562)
  %564 = sext i16 %563 to i32
  %565 = load i32, i32* %49, align 4
  %566 = load i32****, i32***** @g_2763, align 8
  %567 = load volatile i32***, i32**** %566, align 8
  %568 = load i32**, i32*** %567, align 8
  %569 = load i16, i16* %9, align 2
  %570 = load i64, i64* %6, align 8
  %571 = icmp ne i64 %570, 0
  br i1 %571, label %572, label %593

572:                                              ; preds = %475
  %573 = getelementptr inbounds [5 x i32], [5 x i32]* %48, i64 0, i64 3
  %574 = load i32, i32* %573, align 4
  %575 = sext i32 %574 to i64
  %576 = load i32, i32* @g_2470, align 4
  %577 = sext i32 %576 to i64
  %578 = call i64 @safe_mod_func_uint64_t_u_u(i64 %575, i64 %577)
  %579 = load i16, i16* %9, align 2
  %580 = sext i16 %579 to i32
  %581 = icmp ne i32 %580, 0
  br i1 %581, label %582, label %583

582:                                              ; preds = %572
  br label %583

583:                                              ; preds = %582, %572
  %584 = phi i1 [ false, %572 ], [ true, %582 ]
  %585 = zext i1 %584 to i32
  %586 = sext i32 %585 to i64
  %587 = and i64 %586, 412316639
  %588 = icmp ne i64 %578, %587
  %589 = zext i1 %588 to i32
  %590 = load i32*, i32** @g_422, align 8
  %591 = load i32, i32* %590, align 4
  %592 = icmp sle i32 %589, %591
  br label %593

593:                                              ; preds = %583, %475
  %594 = phi i1 [ false, %475 ], [ %592, %583 ]
  %595 = zext i1 %594 to i32
  %596 = trunc i32 %595 to i16
  store i16 %596, i16* %8, align 2
  %597 = zext i16 %596 to i32
  %598 = load i16*, i16** @g_369, align 8
  %599 = load i16, i16* %598, align 2
  %600 = sext i16 %599 to i32
  %601 = icmp sgt i32 %597, %600
  %602 = zext i1 %601 to i32
  %603 = load i16, i16* %9, align 2
  %604 = sext i16 %603 to i32
  %605 = icmp eq i32 %602, %604
  %606 = zext i1 %605 to i32
  %607 = load i32*, i32** %12, align 8
  %608 = load i32, i32* %607, align 4
  %609 = xor i32 %608, %606
  store i32 %609, i32* %607, align 4
  store i32** null, i32*** @g_2846, align 8
  store i32** null, i32*** @g_2847, align 8
  store i32** null, i32*** %68, align 8
  %610 = icmp eq i32** %568, null
  %611 = zext i1 %610 to i32
  %612 = load i32*, i32** @g_422, align 8
  %613 = load i32, i32* %612, align 4
  %614 = icmp slt i32 %611, %613
  %615 = zext i1 %614 to i32
  %616 = icmp sle i32 %564, %615
  br i1 %616, label %622, label %617

617:                                              ; preds = %593
  %618 = load i16*, i16** @g_369, align 8
  %619 = load i16, i16* %618, align 2
  %620 = sext i16 %619 to i32
  %621 = icmp ne i32 %620, 0
  br label %622

622:                                              ; preds = %617, %593
  %623 = phi i1 [ true, %593 ], [ %621, %617 ]
  %624 = zext i1 %623 to i32
  %625 = load i32, i32* %32, align 4
  %626 = or i32 %625, %624
  store i32 %626, i32* %32, align 4
  %627 = load i32*, i32** %10, align 8
  store i32 -1111306077, i32* %627, align 4
  br label %845

628:                                              ; preds = %455
  %629 = bitcast [4 x [3 x i32***]]* %79 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %629, i8* align 16 bitcast ([4 x [3 x i32***]]* @__const.func_17.l_2849 to i8*), i64 96, i1 false)
  store i32**** getelementptr inbounds ([9 x [4 x i32***]], [9 x [4 x i32***]]* @g_2258, i64 0, i64 2, i64 2), i32***** %80, align 8
  %630 = getelementptr inbounds [6 x [10 x [1 x i8****]]], [6 x [10 x [1 x i8****]]]* %81, i64 0, i64 0
  %631 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %630, i64 0, i64 0
  %632 = getelementptr inbounds [1 x i8****], [1 x i8****]* %631, i64 0, i64 0
  store i8**** null, i8***** %632, align 8
  %633 = getelementptr inbounds [1 x i8****], [1 x i8****]* %631, i64 1
  %634 = getelementptr inbounds [1 x i8****], [1 x i8****]* %633, i64 0, i64 0
  store i8**** %36, i8***** %634, align 8
  %635 = getelementptr inbounds [1 x i8****], [1 x i8****]* %633, i64 1
  %636 = getelementptr inbounds [1 x i8****], [1 x i8****]* %635, i64 0, i64 0
  store i8**** %36, i8***** %636, align 8
  %637 = getelementptr inbounds [1 x i8****], [1 x i8****]* %635, i64 1
  %638 = getelementptr inbounds [1 x i8****], [1 x i8****]* %637, i64 0, i64 0
  store i8**** %36, i8***** %638, align 8
  %639 = getelementptr inbounds [1 x i8****], [1 x i8****]* %637, i64 1
  %640 = getelementptr inbounds [1 x i8****], [1 x i8****]* %639, i64 0, i64 0
  store i8**** %36, i8***** %640, align 8
  %641 = getelementptr inbounds [1 x i8****], [1 x i8****]* %639, i64 1
  %642 = getelementptr inbounds [1 x i8****], [1 x i8****]* %641, i64 0, i64 0
  store i8**** %36, i8***** %642, align 8
  %643 = getelementptr inbounds [1 x i8****], [1 x i8****]* %641, i64 1
  %644 = getelementptr inbounds [1 x i8****], [1 x i8****]* %643, i64 0, i64 0
  store i8**** null, i8***** %644, align 8
  %645 = getelementptr inbounds [1 x i8****], [1 x i8****]* %643, i64 1
  %646 = getelementptr inbounds [1 x i8****], [1 x i8****]* %645, i64 0, i64 0
  store i8**** %36, i8***** %646, align 8
  %647 = getelementptr inbounds [1 x i8****], [1 x i8****]* %645, i64 1
  %648 = getelementptr inbounds [1 x i8****], [1 x i8****]* %647, i64 0, i64 0
  store i8**** null, i8***** %648, align 8
  %649 = getelementptr inbounds [1 x i8****], [1 x i8****]* %647, i64 1
  %650 = getelementptr inbounds [1 x i8****], [1 x i8****]* %649, i64 0, i64 0
  store i8**** %36, i8***** %650, align 8
  %651 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %630, i64 1
  %652 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %651, i64 0, i64 0
  %653 = getelementptr inbounds [1 x i8****], [1 x i8****]* %652, i64 0, i64 0
  store i8**** null, i8***** %653, align 8
  %654 = getelementptr inbounds [1 x i8****], [1 x i8****]* %652, i64 1
  %655 = getelementptr inbounds [1 x i8****], [1 x i8****]* %654, i64 0, i64 0
  store i8**** null, i8***** %655, align 8
  %656 = getelementptr inbounds [1 x i8****], [1 x i8****]* %654, i64 1
  %657 = getelementptr inbounds [1 x i8****], [1 x i8****]* %656, i64 0, i64 0
  store i8**** %36, i8***** %657, align 8
  %658 = getelementptr inbounds [1 x i8****], [1 x i8****]* %656, i64 1
  %659 = getelementptr inbounds [1 x i8****], [1 x i8****]* %658, i64 0, i64 0
  store i8**** null, i8***** %659, align 8
  %660 = getelementptr inbounds [1 x i8****], [1 x i8****]* %658, i64 1
  %661 = getelementptr inbounds [1 x i8****], [1 x i8****]* %660, i64 0, i64 0
  store i8**** null, i8***** %661, align 8
  %662 = getelementptr inbounds [1 x i8****], [1 x i8****]* %660, i64 1
  %663 = getelementptr inbounds [1 x i8****], [1 x i8****]* %662, i64 0, i64 0
  store i8**** %36, i8***** %663, align 8
  %664 = getelementptr inbounds [1 x i8****], [1 x i8****]* %662, i64 1
  %665 = getelementptr inbounds [1 x i8****], [1 x i8****]* %664, i64 0, i64 0
  store i8**** null, i8***** %665, align 8
  %666 = getelementptr inbounds [1 x i8****], [1 x i8****]* %664, i64 1
  %667 = getelementptr inbounds [1 x i8****], [1 x i8****]* %666, i64 0, i64 0
  store i8**** %36, i8***** %667, align 8
  %668 = getelementptr inbounds [1 x i8****], [1 x i8****]* %666, i64 1
  %669 = getelementptr inbounds [1 x i8****], [1 x i8****]* %668, i64 0, i64 0
  store i8**** null, i8***** %669, align 8
  %670 = getelementptr inbounds [1 x i8****], [1 x i8****]* %668, i64 1
  %671 = getelementptr inbounds [1 x i8****], [1 x i8****]* %670, i64 0, i64 0
  store i8**** %36, i8***** %671, align 8
  %672 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %651, i64 1
  %673 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %672, i64 0, i64 0
  %674 = getelementptr inbounds [1 x i8****], [1 x i8****]* %673, i64 0, i64 0
  store i8**** %36, i8***** %674, align 8
  %675 = getelementptr inbounds [1 x i8****], [1 x i8****]* %673, i64 1
  %676 = getelementptr inbounds [1 x i8****], [1 x i8****]* %675, i64 0, i64 0
  store i8**** %36, i8***** %676, align 8
  %677 = getelementptr inbounds [1 x i8****], [1 x i8****]* %675, i64 1
  %678 = getelementptr inbounds [1 x i8****], [1 x i8****]* %677, i64 0, i64 0
  store i8**** %36, i8***** %678, align 8
  %679 = getelementptr inbounds [1 x i8****], [1 x i8****]* %677, i64 1
  %680 = getelementptr inbounds [1 x i8****], [1 x i8****]* %679, i64 0, i64 0
  store i8**** %36, i8***** %680, align 8
  %681 = getelementptr inbounds [1 x i8****], [1 x i8****]* %679, i64 1
  %682 = getelementptr inbounds [1 x i8****], [1 x i8****]* %681, i64 0, i64 0
  store i8**** null, i8***** %682, align 8
  %683 = getelementptr inbounds [1 x i8****], [1 x i8****]* %681, i64 1
  %684 = getelementptr inbounds [1 x i8****], [1 x i8****]* %683, i64 0, i64 0
  store i8**** null, i8***** %684, align 8
  %685 = getelementptr inbounds [1 x i8****], [1 x i8****]* %683, i64 1
  %686 = getelementptr inbounds [1 x i8****], [1 x i8****]* %685, i64 0, i64 0
  store i8**** null, i8***** %686, align 8
  %687 = getelementptr inbounds [1 x i8****], [1 x i8****]* %685, i64 1
  %688 = getelementptr inbounds [1 x i8****], [1 x i8****]* %687, i64 0, i64 0
  store i8**** %36, i8***** %688, align 8
  %689 = getelementptr inbounds [1 x i8****], [1 x i8****]* %687, i64 1
  %690 = getelementptr inbounds [1 x i8****], [1 x i8****]* %689, i64 0, i64 0
  store i8**** %36, i8***** %690, align 8
  %691 = getelementptr inbounds [1 x i8****], [1 x i8****]* %689, i64 1
  %692 = getelementptr inbounds [1 x i8****], [1 x i8****]* %691, i64 0, i64 0
  store i8**** %36, i8***** %692, align 8
  %693 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %672, i64 1
  %694 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %693, i64 0, i64 0
  %695 = getelementptr inbounds [1 x i8****], [1 x i8****]* %694, i64 0, i64 0
  store i8**** %36, i8***** %695, align 8
  %696 = getelementptr inbounds [1 x i8****], [1 x i8****]* %694, i64 1
  %697 = getelementptr inbounds [1 x i8****], [1 x i8****]* %696, i64 0, i64 0
  store i8**** %36, i8***** %697, align 8
  %698 = getelementptr inbounds [1 x i8****], [1 x i8****]* %696, i64 1
  %699 = getelementptr inbounds [1 x i8****], [1 x i8****]* %698, i64 0, i64 0
  store i8**** null, i8***** %699, align 8
  %700 = getelementptr inbounds [1 x i8****], [1 x i8****]* %698, i64 1
  %701 = getelementptr inbounds [1 x i8****], [1 x i8****]* %700, i64 0, i64 0
  store i8**** %36, i8***** %701, align 8
  %702 = getelementptr inbounds [1 x i8****], [1 x i8****]* %700, i64 1
  %703 = getelementptr inbounds [1 x i8****], [1 x i8****]* %702, i64 0, i64 0
  store i8**** null, i8***** %703, align 8
  %704 = getelementptr inbounds [1 x i8****], [1 x i8****]* %702, i64 1
  %705 = getelementptr inbounds [1 x i8****], [1 x i8****]* %704, i64 0, i64 0
  store i8**** %36, i8***** %705, align 8
  %706 = getelementptr inbounds [1 x i8****], [1 x i8****]* %704, i64 1
  %707 = getelementptr inbounds [1 x i8****], [1 x i8****]* %706, i64 0, i64 0
  store i8**** null, i8***** %707, align 8
  %708 = getelementptr inbounds [1 x i8****], [1 x i8****]* %706, i64 1
  %709 = getelementptr inbounds [1 x i8****], [1 x i8****]* %708, i64 0, i64 0
  store i8**** null, i8***** %709, align 8
  %710 = getelementptr inbounds [1 x i8****], [1 x i8****]* %708, i64 1
  %711 = getelementptr inbounds [1 x i8****], [1 x i8****]* %710, i64 0, i64 0
  store i8**** %36, i8***** %711, align 8
  %712 = getelementptr inbounds [1 x i8****], [1 x i8****]* %710, i64 1
  %713 = getelementptr inbounds [1 x i8****], [1 x i8****]* %712, i64 0, i64 0
  store i8**** null, i8***** %713, align 8
  %714 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %693, i64 1
  %715 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %714, i64 0, i64 0
  %716 = getelementptr inbounds [1 x i8****], [1 x i8****]* %715, i64 0, i64 0
  store i8**** null, i8***** %716, align 8
  %717 = getelementptr inbounds [1 x i8****], [1 x i8****]* %715, i64 1
  %718 = getelementptr inbounds [1 x i8****], [1 x i8****]* %717, i64 0, i64 0
  store i8**** %36, i8***** %718, align 8
  %719 = getelementptr inbounds [1 x i8****], [1 x i8****]* %717, i64 1
  %720 = getelementptr inbounds [1 x i8****], [1 x i8****]* %719, i64 0, i64 0
  store i8**** null, i8***** %720, align 8
  %721 = getelementptr inbounds [1 x i8****], [1 x i8****]* %719, i64 1
  %722 = getelementptr inbounds [1 x i8****], [1 x i8****]* %721, i64 0, i64 0
  store i8**** %36, i8***** %722, align 8
  %723 = getelementptr inbounds [1 x i8****], [1 x i8****]* %721, i64 1
  %724 = getelementptr inbounds [1 x i8****], [1 x i8****]* %723, i64 0, i64 0
  store i8**** null, i8***** %724, align 8
  %725 = getelementptr inbounds [1 x i8****], [1 x i8****]* %723, i64 1
  %726 = getelementptr inbounds [1 x i8****], [1 x i8****]* %725, i64 0, i64 0
  store i8**** %36, i8***** %726, align 8
  %727 = getelementptr inbounds [1 x i8****], [1 x i8****]* %725, i64 1
  %728 = getelementptr inbounds [1 x i8****], [1 x i8****]* %727, i64 0, i64 0
  store i8**** %36, i8***** %728, align 8
  %729 = getelementptr inbounds [1 x i8****], [1 x i8****]* %727, i64 1
  %730 = getelementptr inbounds [1 x i8****], [1 x i8****]* %729, i64 0, i64 0
  store i8**** %36, i8***** %730, align 8
  %731 = getelementptr inbounds [1 x i8****], [1 x i8****]* %729, i64 1
  %732 = getelementptr inbounds [1 x i8****], [1 x i8****]* %731, i64 0, i64 0
  store i8**** %36, i8***** %732, align 8
  %733 = getelementptr inbounds [1 x i8****], [1 x i8****]* %731, i64 1
  %734 = getelementptr inbounds [1 x i8****], [1 x i8****]* %733, i64 0, i64 0
  store i8**** %36, i8***** %734, align 8
  %735 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %714, i64 1
  %736 = getelementptr inbounds [10 x [1 x i8****]], [10 x [1 x i8****]]* %735, i64 0, i64 0
  %737 = getelementptr inbounds [1 x i8****], [1 x i8****]* %736, i64 0, i64 0
  store i8**** null, i8***** %737, align 8
  %738 = getelementptr inbounds [1 x i8****], [1 x i8****]* %736, i64 1
  %739 = getelementptr inbounds [1 x i8****], [1 x i8****]* %738, i64 0, i64 0
  store i8**** %36, i8***** %739, align 8
  %740 = getelementptr inbounds [1 x i8****], [1 x i8****]* %738, i64 1
  %741 = getelementptr inbounds [1 x i8****], [1 x i8****]* %740, i64 0, i64 0
  store i8**** null, i8***** %741, align 8
  %742 = getelementptr inbounds [1 x i8****], [1 x i8****]* %740, i64 1
  %743 = getelementptr inbounds [1 x i8****], [1 x i8****]* %742, i64 0, i64 0
  store i8**** %36, i8***** %743, align 8
  %744 = getelementptr inbounds [1 x i8****], [1 x i8****]* %742, i64 1
  %745 = getelementptr inbounds [1 x i8****], [1 x i8****]* %744, i64 0, i64 0
  store i8**** %36, i8***** %745, align 8
  %746 = getelementptr inbounds [1 x i8****], [1 x i8****]* %744, i64 1
  %747 = getelementptr inbounds [1 x i8****], [1 x i8****]* %746, i64 0, i64 0
  store i8**** null, i8***** %747, align 8
  %748 = getelementptr inbounds [1 x i8****], [1 x i8****]* %746, i64 1
  %749 = getelementptr inbounds [1 x i8****], [1 x i8****]* %748, i64 0, i64 0
  store i8**** null, i8***** %749, align 8
  %750 = getelementptr inbounds [1 x i8****], [1 x i8****]* %748, i64 1
  %751 = getelementptr inbounds [1 x i8****], [1 x i8****]* %750, i64 0, i64 0
  store i8**** null, i8***** %751, align 8
  %752 = getelementptr inbounds [1 x i8****], [1 x i8****]* %750, i64 1
  %753 = getelementptr inbounds [1 x i8****], [1 x i8****]* %752, i64 0, i64 0
  store i8**** null, i8***** %753, align 8
  %754 = getelementptr inbounds [1 x i8****], [1 x i8****]* %752, i64 1
  %755 = getelementptr inbounds [1 x i8****], [1 x i8****]* %754, i64 0, i64 0
  store i8**** %36, i8***** %755, align 8
  store i32 1964557288, i32* %82, align 4
  %756 = getelementptr inbounds [4 x [3 x i32***]], [4 x [3 x i32***]]* %79, i64 0, i64 1
  %757 = getelementptr inbounds [3 x i32***], [3 x i32***]* %756, i64 0, i64 0
  %758 = load i32***, i32**** %757, align 8
  %759 = load i32****, i32***** %80, align 8
  store i32*** %758, i32**** %759, align 8
  %760 = load i16, i16* %8, align 2
  %761 = zext i16 %760 to i32
  %762 = load i32*, i32** @g_422, align 8
  store i32 %761, i32* %762, align 4
  %763 = load i32**, i32*** @g_421, align 8
  %764 = load i32*, i32** %763, align 8
  %765 = load i8***, i8**** %36, align 8
  store i8*** %765, i8**** @g_2853, align 8
  %766 = load i8***, i8**** %36, align 8
  %767 = icmp eq i8*** %765, %766
  %768 = zext i1 %767 to i32
  %769 = load i16, i16* %9, align 2
  %770 = sext i16 %769 to i32
  %771 = getelementptr inbounds [7 x [4 x [2 x i32]]], [7 x [4 x [2 x i32]]]* %34, i64 0, i64 0
  %772 = getelementptr inbounds [4 x [2 x i32]], [4 x [2 x i32]]* %771, i64 0, i64 2
  %773 = getelementptr inbounds [2 x i32], [2 x i32]* %772, i64 0, i64 1
  %774 = load i32, i32* %773, align 4
  %775 = or i32 %774, %770
  store i32 %775, i32* %773, align 4
  %776 = trunc i32 %775 to i8
  %777 = call signext i8 @safe_lshift_func_int8_t_s_s(i8 signext %776, i32 5)
  %778 = sext i8 %777 to i16
  %779 = call zeroext i16 @safe_rshift_func_uint16_t_u_s(i16 zeroext %778, i32 4)
  %780 = zext i16 %779 to i32
  %781 = load i16, i16* %9, align 2
  %782 = sext i16 %781 to i32
  %783 = icmp ne i32 %782, 0
  br i1 %783, label %828, label %784

784:                                              ; preds = %628
  %785 = load i64***, i64**** %70, align 8
  %786 = icmp eq i64*** %785, %69
  br i1 %786, label %812, label %787

787:                                              ; preds = %784
  %788 = load i16, i16* %9, align 2
  %789 = sext i16 %788 to i32
  %790 = load i16, i16* %8, align 2
  %791 = zext i16 %790 to i32
  %792 = load i32, i32* %82, align 4
  %793 = xor i32 %791, %792
  %794 = icmp ne i32 %793, 0
  br i1 %794, label %795, label %798

795:                                              ; preds = %787
  %796 = load i32, i32* %58, align 4
  %797 = icmp ne i32 %796, 0
  br label %798

798:                                              ; preds = %795, %787
  %799 = phi i1 [ false, %787 ], [ %797, %795 ]
  %800 = zext i1 %799 to i32
  %801 = load i32*, i32** %10, align 8
  %802 = load i32, i32* %801, align 4
  %803 = icmp eq i32 %800, %802
  %804 = zext i1 %803 to i32
  %805 = or i32 %789, %804
  %806 = trunc i32 %805 to i8
  %807 = load i8*, i8** @g_516, align 8
  store i8 %806, i8* %807, align 1
  %808 = load i32, i32* %33, align 4
  %809 = call signext i8 @safe_rshift_func_int8_t_s_s(i8 signext %806, i32 %808)
  %810 = sext i8 %809 to i32
  %811 = icmp ne i32 %810, 0
  br label %812

812:                                              ; preds = %798, %784
  %813 = phi i1 [ true, %784 ], [ %811, %798 ]
  %814 = zext i1 %813 to i32
  %815 = getelementptr inbounds [9 x i32], [9 x i32]* %67, i64 0, i64 0
  %816 = load i32, i32* %815, align 16
  %817 = call i32 @safe_add_func_uint32_t_u_u(i32 %814, i32 %816)
  %818 = zext i32 %817 to i64
  %819 = call i64 @safe_unary_minus_func_uint64_t_u(i64 %818)
  %820 = load i32*, i32** %10, align 8
  %821 = load i32, i32* %820, align 4
  %822 = sext i32 %821 to i64
  %823 = icmp ugt i64 %819, %822
  %824 = zext i1 %823 to i32
  %825 = sext i32 %824 to i64
  %826 = xor i64 %825, 76
  %827 = icmp ne i64 %826, 0
  br i1 %827, label %828, label %829

828:                                              ; preds = %812, %628
  br label %829

829:                                              ; preds = %828, %812
  %830 = phi i1 [ false, %812 ], [ true, %828 ]
  %831 = zext i1 %830 to i32
  %832 = icmp eq i32 %780, %831
  %833 = zext i1 %832 to i32
  %834 = load i32*, i32** %10, align 8
  %835 = load i32, i32* %834, align 4
  %836 = xor i32 %833, %835
  %837 = load volatile i8**, i8*** @g_515, align 8
  %838 = load i8*, i8** %837, align 8
  %839 = call %union.U0* @func_48(i32* %764, i32 %836, i8* %838)
  %840 = load %union.U0***, %union.U0**** @g_1919, align 8
  %841 = load %union.U0**, %union.U0*** %840, align 8
  store %union.U0* %839, %union.U0** %841, align 8
  %842 = load %union.U0*, %union.U0** %7, align 8
  %843 = call i32* @func_52(%union.U0* %839, %union.U0* %842)
  store i32* %843, i32** %10, align 8
  %844 = getelementptr inbounds [2 x i32*], [2 x i32*]* %51, i64 0, i64 1
  store i32* %843, i32** %844, align 8
  br label %845

845:                                              ; preds = %829, %622
  store i32 0, i32* @g_2470, align 4
  br label %846

846:                                              ; preds = %859, %845
  %847 = load i32, i32* @g_2470, align 4
  %848 = icmp sle i32 %847, 2
  br i1 %848, label %849, label %862

849:                                              ; preds = %846
  store i32 -3, i32* %86, align 4
  store i32 1581207923, i32* %87, align 4
  store i32 1, i32* %88, align 4
  store i32 -389904178, i32* %89, align 4
  store i32 1442197933, i32* %90, align 4
  store i32 378784181, i32* %91, align 4
  store i32 1, i32* %92, align 4
  store i32 824569566, i32* %93, align 4
  store i32 -795292799, i32* %94, align 4
  store i32 -197449547, i32* %95, align 4
  %850 = bitcast [7 x i32]* %96 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %850, i8* align 16 bitcast ([7 x i32]* @__const.func_17.l_2884 to i8*), i64 28, i1 false)
  %851 = load i8, i8* %52, align 1
  %852 = add i8 %851, -1
  store i8 %852, i8* %52, align 1
  %853 = load i32, i32* %37, align 4
  %854 = add i32 %853, 1
  store i32 %854, i32* %37, align 4
  %855 = load %union.U0*, %union.U0** %53, align 8
  %856 = load %union.U0*, %union.U0** %7, align 8
  %857 = call i32* @func_52(%union.U0* %855, %union.U0* %856)
  %858 = load i32**, i32*** @g_421, align 8
  store i32* %857, i32** %858, align 8
  br label %859

859:                                              ; preds = %849
  %860 = load i32, i32* @g_2470, align 4
  %861 = add nsw i32 %860, 1
  store i32 %861, i32* @g_2470, align 4
  br label %846

862:                                              ; preds = %846
  br label %866

863:                                              ; preds = %337
  store i32 -2056702759, i32* %98, align 4
  %864 = load i32, i32* %98, align 4
  %865 = add i32 %864, -1
  store i32 %865, i32* %98, align 4
  br label %866

866:                                              ; preds = %863, %862
  %867 = load i16, i16* @g_370, align 2
  %868 = icmp ne i16 %867, 0
  br i1 %868, label %869, label %870

869:                                              ; preds = %866
  br label %111

870:                                              ; preds = %866
  br label %871

871:                                              ; preds = %870
  %872 = load i32, i32* %31, align 4
  %873 = trunc i32 %872 to i16
  %874 = call zeroext i16 @safe_add_func_uint16_t_u_u(i16 zeroext %873, i16 zeroext 7)
  %875 = zext i16 %874 to i32
  store i32 %875, i32* %31, align 4
  br label %274

876:                                              ; preds = %274
  br label %877

877:                                              ; preds = %876, %245
  store i32 0, i32* @g_2470, align 4
  br label %878

878:                                              ; preds = %889, %877
  %879 = load i32, i32* @g_2470, align 4
  %880 = icmp sle i32 %879, 5
  br i1 %880, label %881, label %894

881:                                              ; preds = %878
  %882 = load i16, i16* %8, align 2
  %883 = icmp ne i16 %882, 0
  br i1 %883, label %884, label %885

884:                                              ; preds = %881
  br label %894

885:                                              ; preds = %881
  %886 = load %union.U0*, %union.U0** %7, align 8
  %887 = bitcast %union.U0* %5 to i8*
  %888 = bitcast %union.U0* %886 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %887, i8* align 8 %888, i64 8, i1 false)
  br label %905

889:                                              ; No predecessors!
  %890 = load i32, i32* @g_2470, align 4
  %891 = sext i32 %890 to i64
  %892 = call i64 @safe_add_func_uint64_t_u_u(i64 %891, i64 6)
  %893 = trunc i64 %892 to i32
  store i32 %893, i32* @g_2470, align 4
  br label %878

894:                                              ; preds = %884, %878
  br label %901

895:                                              ; preds = %111
  %896 = load i32*, i32** %10, align 8
  %897 = load i32, i32* %896, align 4
  %898 = sext i32 %897 to i64
  %899 = or i64 %898, 2420059421
  %900 = trunc i64 %899 to i32
  store i32 %900, i32* %896, align 4
  br label %901

901:                                              ; preds = %895, %894
  %902 = load %union.U0*, %union.U0** %7, align 8
  %903 = bitcast %union.U0* %5 to i8*
  %904 = bitcast %union.U0* %902 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %903, i8* align 8 %904, i64 8, i1 false)
  br label %905

905:                                              ; preds = %901, %885
  %906 = getelementptr inbounds %union.U0, %union.U0* %5, i32 0, i32 0
  %907 = load i8*, i8** %906, align 8
  ret i8* %907
}

; Function Attrs: noinline nounwind optnone uwtable
define internal %union.U0* @func_28(%union.U0* %0, i8 signext %1, i8* %2, i8* %3, %union.U0* %4) #0 {
  %6 = alloca %union.U0*, align 8
  %7 = alloca %union.U0*, align 8
  %8 = alloca i8, align 1
  %9 = alloca i8*, align 8
  %10 = alloca i8*, align 8
  %11 = alloca %union.U0*, align 8
  %12 = alloca i32*, align 8
  %13 = alloca %union.U0***, align 8
  %14 = alloca [3 x %union.U0****], align 16
  %15 = alloca [2 x %union.U0*], align 16
  %16 = alloca i32, align 4
  %17 = alloca i32, align 4
  %18 = alloca i32, align 4
  %19 = alloca i32, align 4
  %20 = alloca i32, align 4
  %21 = alloca i32*, align 8
  %22 = alloca i64*, align 8
  %23 = alloca i64*, align 8
  %24 = alloca [5 x [8 x i32]], align 16
  %25 = alloca i16*, align 8
  %26 = alloca i16*, align 8
  %27 = alloca i16*, align 8
  %28 = alloca %union.U0****, align 8
  %29 = alloca i32****, align 8
  %30 = alloca [8 x [7 x [2 x %union.U0*]]], align 16
  %31 = alloca i32***, align 8
  %32 = alloca i32, align 4
  %33 = alloca i32, align 4
  %34 = alloca i32, align 4
  %35 = alloca [5 x [9 x i32*****]], align 16
  %36 = alloca i32***, align 8
  %37 = alloca i32****, align 8
  %38 = alloca i32, align 4
  %39 = alloca i32*, align 8
  %40 = alloca i32, align 4
  %41 = alloca i32, align 4
  store %union.U0* %0, %union.U0** %7, align 8
  store i8 %1, i8* %8, align 1
  store i8* %2, i8** %9, align 8
  store i8* %3, i8** %10, align 8
  store %union.U0* %4, %union.U0** %11, align 8
  store i32* @g_675, i32** %12, align 8
  store %union.U0*** @g_547, %union.U0**** %13, align 8
  store i32 -1, i32* %16, align 4
  store i32 0, i32* %17, align 4
  br label %42

42:                                               ; preds = %49, %5
  %43 = load i32, i32* %17, align 4
  %44 = icmp slt i32 %43, 3
  br i1 %44, label %45, label %52

45:                                               ; preds = %42
  %46 = load i32, i32* %17, align 4
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds [3 x %union.U0****], [3 x %union.U0****]* %14, i64 0, i64 %47
  store %union.U0**** %13, %union.U0***** %48, align 8
  br label %49

49:                                               ; preds = %45
  %50 = load i32, i32* %17, align 4
  %51 = add nsw i32 %50, 1
  store i32 %51, i32* %17, align 4
  br label %42

52:                                               ; preds = %42
  store i32 0, i32* %17, align 4
  br label %53

53:                                               ; preds = %60, %52
  %54 = load i32, i32* %17, align 4
  %55 = icmp slt i32 %54, 2
  br i1 %55, label %56, label %63

56:                                               ; preds = %53
  %57 = load i32, i32* %17, align 4
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds [2 x %union.U0*], [2 x %union.U0*]* %15, i64 0, i64 %58
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_2227 to %union.U0*), %union.U0** %59, align 8
  br label %60

60:                                               ; preds = %56
  %61 = load i32, i32* %17, align 4
  %62 = add nsw i32 %61, 1
  store i32 %62, i32* %17, align 4
  br label %53

63:                                               ; preds = %53
  br label %64

64:                                               ; preds = %323, %63
  %65 = load volatile i32**, i32*** @g_2015, align 8
  %66 = load i32*, i32** %65, align 8
  store i32* %66, i32** %12, align 8
  %67 = load i32*, i32** %12, align 8
  %68 = load volatile i32**, i32*** @g_2674, align 8
  store i32* %67, i32** %68, align 8
  store i32 -23, i32* @g_1492, align 4
  br label %69

69:                                               ; preds = %336, %64
  %70 = load i32, i32* @g_1492, align 4
  %71 = icmp eq i32 %70, 31
  br i1 %71, label %72, label %339

72:                                               ; preds = %69
  store i32 786349094, i32* %18, align 4
  store i32 -183920558, i32* %19, align 4
  store i32 1587905084, i32* %20, align 4
  store i32* @g_89, i32** %21, align 8
  store i32 28, i32* @g_675, align 4
  br label %73

73:                                               ; preds = %327, %72
  %74 = load i32, i32* @g_675, align 4
  %75 = icmp eq i32 %74, 5
  br i1 %75, label %76, label %330

76:                                               ; preds = %73
  store i64* null, i64** %22, align 8
  store i64* @g_2113, i64** %23, align 8
  %77 = bitcast [5 x [8 x i32]]* %24 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %77, i8* align 16 bitcast ([5 x [8 x i32]]* @__const.func_28.l_2681 to i8*), i64 160, i1 false)
  store i16* @g_2056, i16** %25, align 8
  store i16* null, i16** %26, align 8
  store i16* @g_135, i16** %27, align 8
  store %union.U0**** %13, %union.U0***** %28, align 8
  store i32**** null, i32***** %29, align 8
  %78 = bitcast [8 x [7 x [2 x %union.U0*]]]* %30 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %78, i8* align 16 bitcast ([8 x [7 x [2 x %union.U0*]]]* @__const.func_28.l_2731 to i8*), i64 896, i1 false)
  store i32*** @g_1673, i32**** %31, align 8
  %79 = load i64*, i64** %23, align 8
  store i64 1, i64* %79, align 8
  %80 = getelementptr inbounds [5 x [8 x i32]], [5 x [8 x i32]]* %24, i64 0, i64 1
  %81 = getelementptr inbounds [8 x i32], [8 x i32]* %80, i64 0, i64 4
  %82 = load i32, i32* %81, align 16
  %83 = sext i32 %82 to i64
  %84 = xor i64 1, %83
  %85 = load i8*, i8** %10, align 8
  %86 = load i8, i8* %85, align 1
  %87 = getelementptr inbounds [5 x [8 x i32]], [5 x [8 x i32]]* %24, i64 0, i64 2
  %88 = getelementptr inbounds [8 x i32], [8 x i32]* %87, i64 0, i64 5
  %89 = load i32, i32* %88, align 4
  %90 = trunc i32 %89 to i16
  %91 = load i16*, i16** %25, align 8
  store i16 %90, i16* %91, align 2
  %92 = load i16*, i16** %27, align 8
  store i16 %90, i16* %92, align 2
  %93 = zext i16 %90 to i32
  %94 = load i32, i32* %18, align 4
  %95 = xor i32 %93, %94
  %96 = sext i32 %95 to i64
  %97 = load i64*, i64** @g_2097, align 8
  store i64 %96, i64* %97, align 8
  %98 = getelementptr inbounds [5 x [8 x i32]], [5 x [8 x i32]]* %24, i64 0, i64 0
  %99 = getelementptr inbounds [8 x i32], [8 x i32]* %98, i64 0, i64 6
  %100 = load i32, i32* %99, align 8
  %101 = load i8, i8* %8, align 1
  %102 = sext i8 %101 to i32
  %103 = or i32 %100, %102
  %104 = sext i32 %103 to i64
  %105 = icmp ugt i64 1, %104
  %106 = zext i1 %105 to i32
  %107 = trunc i32 %106 to i8
  %108 = call signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %107, i32 4)
  %109 = sext i8 %108 to i16
  %110 = call signext i16 @safe_sub_func_int16_t_s_s(i16 signext 30317, i16 signext %109)
  %111 = call i64 @safe_div_func_uint64_t_u_u(i64 604927994080773231, i64 -1)
  %112 = trunc i64 %111 to i16
  %113 = call signext i16 @safe_mul_func_int16_t_s_s(i16 signext %112, i16 signext -3)
  %114 = trunc i16 %113 to i8
  %115 = call signext i8 @safe_rshift_func_int8_t_s_s(i8 signext %114, i32 7)
  %116 = sext i8 %115 to i64
  %117 = or i64 %116, -3161675889388304692
  %118 = trunc i64 %117 to i8
  %119 = call signext i8 @safe_unary_minus_func_int8_t_s(i8 signext %118)
  %120 = call zeroext i8 @safe_rshift_func_uint8_t_u_u(i8 zeroext %119, i32 5)
  %121 = zext i8 %120 to i32
  %122 = load i8, i8* %8, align 1
  %123 = sext i8 %122 to i32
  %124 = icmp slt i32 %121, %123
  %125 = zext i1 %124 to i32
  %126 = sext i32 %125 to i64
  %127 = load i64*, i64** @g_2496, align 8
  %128 = load volatile i64, i64* %127, align 8
  %129 = and i64 %126, %128
  %130 = icmp slt i64 %84, %129
  br i1 %130, label %131, label %135

131:                                              ; preds = %76
  %132 = load i8, i8* %8, align 1
  %133 = sext i8 %132 to i32
  %134 = icmp ne i32 %133, 0
  br label %135

135:                                              ; preds = %131, %76
  %136 = phi i1 [ false, %76 ], [ %134, %131 ]
  %137 = zext i1 %136 to i32
  %138 = sext i32 %137 to i64
  %139 = icmp sgt i64 %138, 1
  br i1 %139, label %140, label %217

140:                                              ; preds = %135
  store i16 0, i16* @g_370, align 2
  br label %141

141:                                              ; preds = %159, %140
  %142 = load i16, i16* @g_370, align 2
  %143 = sext i16 %142 to i32
  %144 = icmp eq i32 %143, -8
  br i1 %144, label %145, label %162

145:                                              ; preds = %141
  store i32 3, i32* %18, align 4
  br label %146

146:                                              ; preds = %155, %145
  %147 = load i32, i32* %18, align 4
  %148 = icmp sge i32 %147, 0
  br i1 %148, label %149, label %158

149:                                              ; preds = %146
  %150 = load i32**, i32*** @g_421, align 8
  store i32* null, i32** %150, align 8
  %151 = load i8, i8* %8, align 1
  %152 = icmp ne i8 %151, 0
  br i1 %152, label %153, label %154

153:                                              ; preds = %149
  br label %158

154:                                              ; preds = %149
  br label %155

155:                                              ; preds = %154
  %156 = load i32, i32* %18, align 4
  %157 = sub nsw i32 %156, 1
  store i32 %157, i32* %18, align 4
  br label %146

158:                                              ; preds = %153, %146
  br label %159

159:                                              ; preds = %158
  %160 = load i16, i16* @g_370, align 2
  %161 = add i16 %160, -1
  store i16 %161, i16* @g_370, align 2
  br label %141

162:                                              ; preds = %141
  %163 = load i8, i8* %8, align 1
  %164 = sext i8 %163 to i32
  %165 = load i16*, i16** %27, align 8
  %166 = load i16, i16* %165, align 2
  %167 = add i16 %166, -1
  store i16 %167, i16* %165, align 2
  %168 = zext i16 %167 to i64
  %169 = icmp ugt i64 %168, 65527
  %170 = zext i1 %169 to i32
  %171 = sext i32 %170 to i64
  %172 = load i64*, i64** @g_2097, align 8
  %173 = load i64, i64* %172, align 8
  %174 = xor i64 %173, %171
  store i64 %174, i64* %172, align 8
  %175 = icmp ne i64 %174, 0
  br i1 %175, label %176, label %203

176:                                              ; preds = %162
  %177 = load i16*, i16** @g_369, align 8
  %178 = load i16, i16* %177, align 2
  %179 = sext i16 %178 to i64
  %180 = load i8, i8* %8, align 1
  %181 = call zeroext i8 @safe_rshift_func_uint8_t_u_u(i8 zeroext %180, i32 5)
  %182 = call signext i8 @safe_rshift_func_int8_t_s_u(i8 signext %181, i32 5)
  %183 = getelementptr inbounds [3 x %union.U0****], [3 x %union.U0****]* %14, i64 0, i64 1
  %184 = load %union.U0****, %union.U0***** %183, align 8
  %185 = load %union.U0****, %union.U0***** %28, align 8
  %186 = icmp eq %union.U0**** %184, %185
  %187 = zext i1 %186 to i32
  %188 = getelementptr inbounds [5 x [8 x i32]], [5 x [8 x i32]]* %24, i64 0, i64 4
  %189 = getelementptr inbounds [8 x i32], [8 x i32]* %188, i64 0, i64 6
  %190 = load i32, i32* %189, align 8
  %191 = call zeroext i16 @safe_rshift_func_uint16_t_u_s(i16 zeroext 1, i32 %190)
  %192 = zext i16 %191 to i32
  %193 = call i32 @safe_add_func_uint32_t_u_u(i32 893402690, i32 %192)
  %194 = icmp eq i32 %187, %193
  %195 = zext i1 %194 to i32
  %196 = call signext i8 @safe_lshift_func_int8_t_s_u(i8 signext %182, i32 %195)
  %197 = sext i8 %196 to i64
  %198 = call i64 @safe_mod_func_int64_t_s_s(i64 %197, i64 -1)
  %199 = icmp slt i64 %179, %198
  %200 = zext i1 %199 to i32
  %201 = sext i32 %200 to i64
  %202 = icmp sle i64 1, %201
  br label %203

203:                                              ; preds = %176, %162
  %204 = phi i1 [ false, %162 ], [ %202, %176 ]
  %205 = zext i1 %204 to i32
  %206 = load i32, i32* %18, align 4
  %207 = and i32 %205, %206
  store i32 %207, i32* %19, align 4
  %208 = sext i32 %207 to i64
  %209 = icmp sgt i64 %208, 3418923311
  %210 = zext i1 %209 to i32
  %211 = trunc i32 %210 to i8
  %212 = call zeroext i8 @safe_unary_minus_func_uint8_t_u(i8 zeroext %211)
  %213 = zext i8 %212 to i32
  %214 = call i32 @safe_add_func_int32_t_s_s(i32 %164, i32 %213)
  %215 = load i32, i32* %20, align 4
  %216 = or i32 %215, %214
  store i32 %216, i32* %20, align 4
  br label %325

217:                                              ; preds = %135
  %218 = getelementptr inbounds [5 x [9 x i32*****]], [5 x [9 x i32*****]]* %35, i64 0, i64 0
  %219 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %218, i64 0, i64 0
  store i32***** %29, i32****** %219, align 8
  %220 = getelementptr inbounds i32*****, i32****** %219, i64 1
  store i32***** %29, i32****** %220, align 8
  %221 = getelementptr inbounds i32*****, i32****** %220, i64 1
  store i32***** %29, i32****** %221, align 8
  %222 = getelementptr inbounds i32*****, i32****** %221, i64 1
  store i32***** %29, i32****** %222, align 8
  %223 = getelementptr inbounds i32*****, i32****** %222, i64 1
  store i32***** %29, i32****** %223, align 8
  %224 = getelementptr inbounds i32*****, i32****** %223, i64 1
  store i32***** %29, i32****** %224, align 8
  %225 = getelementptr inbounds i32*****, i32****** %224, i64 1
  store i32***** %29, i32****** %225, align 8
  %226 = getelementptr inbounds i32*****, i32****** %225, i64 1
  store i32***** %29, i32****** %226, align 8
  %227 = getelementptr inbounds i32*****, i32****** %226, i64 1
  store i32***** %29, i32****** %227, align 8
  %228 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %218, i64 1
  %229 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %228, i64 0, i64 0
  store i32***** %29, i32****** %229, align 8
  %230 = getelementptr inbounds i32*****, i32****** %229, i64 1
  store i32***** %29, i32****** %230, align 8
  %231 = getelementptr inbounds i32*****, i32****** %230, i64 1
  store i32***** null, i32****** %231, align 8
  %232 = getelementptr inbounds i32*****, i32****** %231, i64 1
  store i32***** %29, i32****** %232, align 8
  %233 = getelementptr inbounds i32*****, i32****** %232, i64 1
  store i32***** null, i32****** %233, align 8
  %234 = getelementptr inbounds i32*****, i32****** %233, i64 1
  store i32***** %29, i32****** %234, align 8
  %235 = getelementptr inbounds i32*****, i32****** %234, i64 1
  store i32***** %29, i32****** %235, align 8
  %236 = getelementptr inbounds i32*****, i32****** %235, i64 1
  store i32***** null, i32****** %236, align 8
  %237 = getelementptr inbounds i32*****, i32****** %236, i64 1
  store i32***** %29, i32****** %237, align 8
  %238 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %228, i64 1
  %239 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %238, i64 0, i64 0
  store i32***** null, i32****** %239, align 8
  %240 = getelementptr inbounds i32*****, i32****** %239, i64 1
  store i32***** %29, i32****** %240, align 8
  %241 = getelementptr inbounds i32*****, i32****** %240, i64 1
  store i32***** null, i32****** %241, align 8
  %242 = getelementptr inbounds i32*****, i32****** %241, i64 1
  store i32***** %29, i32****** %242, align 8
  %243 = getelementptr inbounds i32*****, i32****** %242, i64 1
  store i32***** %29, i32****** %243, align 8
  %244 = getelementptr inbounds i32*****, i32****** %243, i64 1
  store i32***** %29, i32****** %244, align 8
  %245 = getelementptr inbounds i32*****, i32****** %244, i64 1
  store i32***** null, i32****** %245, align 8
  %246 = getelementptr inbounds i32*****, i32****** %245, i64 1
  store i32***** %29, i32****** %246, align 8
  %247 = getelementptr inbounds i32*****, i32****** %246, i64 1
  store i32***** null, i32****** %247, align 8
  %248 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %238, i64 1
  %249 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %248, i64 0, i64 0
  store i32***** %29, i32****** %249, align 8
  %250 = getelementptr inbounds i32*****, i32****** %249, i64 1
  store i32***** null, i32****** %250, align 8
  %251 = getelementptr inbounds i32*****, i32****** %250, i64 1
  store i32***** null, i32****** %251, align 8
  %252 = getelementptr inbounds i32*****, i32****** %251, i64 1
  store i32***** %29, i32****** %252, align 8
  %253 = getelementptr inbounds i32*****, i32****** %252, i64 1
  store i32***** %29, i32****** %253, align 8
  %254 = getelementptr inbounds i32*****, i32****** %253, i64 1
  store i32***** %29, i32****** %254, align 8
  %255 = getelementptr inbounds i32*****, i32****** %254, i64 1
  store i32***** null, i32****** %255, align 8
  %256 = getelementptr inbounds i32*****, i32****** %255, i64 1
  store i32***** null, i32****** %256, align 8
  %257 = getelementptr inbounds i32*****, i32****** %256, i64 1
  store i32***** %29, i32****** %257, align 8
  %258 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %248, i64 1
  %259 = getelementptr inbounds [9 x i32*****], [9 x i32*****]* %258, i64 0, i64 0
  store i32***** %29, i32****** %259, align 8
  %260 = getelementptr inbounds i32*****, i32****** %259, i64 1
  store i32***** null, i32****** %260, align 8
  %261 = getelementptr inbounds i32*****, i32****** %260, i64 1
  store i32***** %29, i32****** %261, align 8
  %262 = getelementptr inbounds i32*****, i32****** %261, i64 1
  store i32***** null, i32****** %262, align 8
  %263 = getelementptr inbounds i32*****, i32****** %262, i64 1
  store i32***** %29, i32****** %263, align 8
  %264 = getelementptr inbounds i32*****, i32****** %263, i64 1
  store i32***** %29, i32****** %264, align 8
  %265 = getelementptr inbounds i32*****, i32****** %264, i64 1
  store i32***** null, i32****** %265, align 8
  %266 = getelementptr inbounds i32*****, i32****** %265, i64 1
  store i32***** %29, i32****** %266, align 8
  %267 = getelementptr inbounds i32*****, i32****** %266, i64 1
  store i32***** null, i32****** %267, align 8
  store i32*** @g_1673, i32**** %36, align 8
  store i32**** %36, i32***** %37, align 8
  store i32 -1457372514, i32* %38, align 4
  store i32* null, i32** %39, align 8
  %268 = load i32****, i32***** %29, align 8
  store i32**** %268, i32***** getelementptr inbounds ([5 x [1 x [1 x i32****]]], [5 x [1 x [1 x i32****]]]* @g_2729, i64 0, i64 3, i64 0, i64 0), align 8
  %269 = getelementptr inbounds [2 x %union.U0*], [2 x %union.U0*]* %15, i64 0, i64 1
  %270 = load %union.U0*, %union.U0** %269, align 8
  %271 = getelementptr inbounds [8 x [7 x [2 x %union.U0*]]], [8 x [7 x [2 x %union.U0*]]]* %30, i64 0, i64 3
  %272 = getelementptr inbounds [7 x [2 x %union.U0*]], [7 x [2 x %union.U0*]]* %271, i64 0, i64 0
  %273 = getelementptr inbounds [2 x %union.U0*], [2 x %union.U0*]* %272, i64 0, i64 1
  %274 = load %union.U0*, %union.U0** %273, align 8
  %275 = load i32*, i32** %21, align 8
  %276 = load i32***, i32**** %31, align 8
  %277 = load i32****, i32***** %37, align 8
  store i32*** @g_1673, i32**** %277, align 8
  %278 = icmp ne i32*** %276, @g_1673
  %279 = zext i1 %278 to i32
  %280 = trunc i32 %279 to i16
  %281 = call signext i16 @safe_lshift_func_int16_t_s_u(i16 signext %280, i32 0)
  %282 = sext i16 %281 to i64
  %283 = load i64*, i64** @g_2097, align 8
  store i64 -3, i64* %283, align 8
  %284 = or i64 %282, -3
  %285 = load i32, i32* %38, align 4
  store i32 %285, i32* %16, align 4
  %286 = icmp ne i32 %285, 0
  br i1 %286, label %287, label %307

287:                                              ; preds = %217
  %288 = load i32*, i32** %21, align 8
  %289 = load i32, i32* %288, align 4
  %290 = load i32*, i32** %21, align 8
  %291 = load i32, i32* %290, align 4
  %292 = sext i32 %291 to i64
  %293 = and i64 %292, 0
  %294 = load i32, i32* %38, align 4
  %295 = sext i32 %294 to i64
  %296 = icmp sge i64 %293, %295
  %297 = zext i1 %296 to i32
  %298 = load i32, i32* %16, align 4
  %299 = and i32 %298, %297
  store i32 %299, i32* %16, align 4
  %300 = icmp ne i32 %299, 0
  br i1 %300, label %305, label %301

301:                                              ; preds = %287
  %302 = load i32*, i32** %12, align 8
  %303 = load i32, i32* %302, align 4
  %304 = icmp ne i32 %303, 0
  br label %305

305:                                              ; preds = %301, %287
  %306 = phi i1 [ true, %287 ], [ %304, %301 ]
  br label %307

307:                                              ; preds = %305, %217
  %308 = phi i1 [ false, %217 ], [ %306, %305 ]
  %309 = zext i1 %308 to i32
  %310 = sext i32 %309 to i64
  %311 = xor i64 %284, %310
  %312 = trunc i64 %311 to i32
  %313 = load volatile i8**, i8*** @g_515, align 8
  %314 = load i8*, i8** %313, align 8
  %315 = call %union.U0* @func_48(i32* %275, i32 %312, i8* %314)
  %316 = call i32* @func_52(%union.U0* %274, %union.U0* %315)
  %317 = load i8, i8* %8, align 1
  %318 = sext i8 %317 to i32
  %319 = call %union.U0* @func_48(i32* %316, i32 %318, i8* @g_82)
  %320 = call i32* @func_52(%union.U0* %270, %union.U0* %319)
  store i32* %320, i32** %39, align 8
  %321 = load i32, i32* %38, align 4
  %322 = icmp ne i32 %321, 0
  br i1 %322, label %323, label %324

323:                                              ; preds = %307
  br label %64

324:                                              ; preds = %307
  br label %325

325:                                              ; preds = %324, %203
  %326 = load %union.U0*, %union.U0** %11, align 8
  store %union.U0* %326, %union.U0** %6, align 8
  br label %342

327:                                              ; No predecessors!
  %328 = load i32, i32* @g_675, align 4
  %329 = add nsw i32 %328, -1
  store i32 %329, i32* @g_675, align 4
  br label %73

330:                                              ; preds = %73
  %331 = load i32*, i32** %21, align 8
  %332 = load i32, i32* %331, align 4
  %333 = load i32*, i32** %21, align 8
  store i32 %332, i32* %333, align 4
  %334 = load i8, i8* %8, align 1
  %335 = sext i8 %334 to i32
  store i32 %335, i32* @g_2742, align 4
  br label %336

336:                                              ; preds = %330
  %337 = load i32, i32* @g_1492, align 4
  %338 = call i32 @safe_add_func_uint32_t_u_u(i32 %337, i32 6)
  store i32 %338, i32* @g_1492, align 4
  br label %69

339:                                              ; preds = %69
  %340 = load volatile %union.U0**, %union.U0*** @g_911, align 8
  %341 = load %union.U0*, %union.U0** %340, align 8
  store %union.U0* %341, %union.U0** %6, align 8
  br label %342

342:                                              ; preds = %339, %325
  %343 = load %union.U0*, %union.U0** %6, align 8
  ret %union.U0* %343
}

; Function Attrs: noinline nounwind optnone uwtable
define internal signext i16 @func_41(i8* %0, i8* %1) #0 {
  %3 = alloca i8*, align 8
  %4 = alloca i8*, align 8
  %5 = alloca i32*, align 8
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  %9 = alloca i32, align 4
  %10 = alloca [6 x [2 x [8 x i32]]], align 16
  %11 = alloca i32, align 4
  %12 = alloca i32, align 4
  %13 = alloca i32, align 4
  %14 = alloca [6 x i32*], align 16
  %15 = alloca i8, align 1
  %16 = alloca i64, align 8
  %17 = alloca i32, align 4
  %18 = alloca i32, align 4
  store i8* %0, i8** %3, align 8
  store i8* %1, i8** %4, align 8
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 0), i32** %5, align 8
  store i32 0, i32* %6, align 4
  store i32 0, i32* %7, align 4
  store i32 -1719429920, i32* %8, align 4
  store i32 5, i32* %9, align 4
  %19 = bitcast [6 x [2 x [8 x i32]]]* %10 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %19, i8* align 16 bitcast ([6 x [2 x [8 x i32]]]* @__const.func_41.l_2667 to i8*), i64 384, i1 false)
  %20 = load i32*, i32** %5, align 8
  store i32 518337699, i32* %20, align 4
  store i32 0, i32* @g_2470, align 4
  br label %21

21:                                               ; preds = %28, %2
  %22 = load i32, i32* @g_2470, align 4
  %23 = icmp sle i32 %22, -28
  br i1 %23, label %24, label %31

24:                                               ; preds = %21
  %25 = bitcast [6 x i32*]* %14 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %25, i8* align 16 bitcast ([6 x i32*]* @__const.func_41.l_2661 to i8*), i64 48, i1 false)
  store i8 8, i8* %15, align 1
  store i64 -6, i64* %16, align 8
  store i32 1338617652, i32* %17, align 4
  %26 = load i32, i32* %17, align 4
  %27 = add i32 %26, 1
  store i32 %27, i32* %17, align 4
  br label %28

28:                                               ; preds = %24
  %29 = load i32, i32* @g_2470, align 4
  %30 = add nsw i32 %29, -1
  store i32 %30, i32* @g_2470, align 4
  br label %21

31:                                               ; preds = %21
  %32 = load i32*, i32** %5, align 8
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  ret i16 %34
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i8* @func_46(%union.U0* %0) #0 {
  %2 = alloca %union.U0*, align 8
  %3 = alloca i32, align 4
  %4 = alloca %union.U0***, align 8
  %5 = alloca %union.U0****, align 8
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca [9 x [5 x [5 x i32]]], align 16
  %9 = alloca i64, align 8
  %10 = alloca [8 x i16*], align 16
  %11 = alloca [1 x i32***], align 8
  %12 = alloca i32***, align 8
  %13 = alloca i8, align 1
  %14 = alloca i64, align 8
  %15 = alloca i32*, align 8
  %16 = alloca [5 x [8 x [6 x i8*]]], align 16
  %17 = alloca i8****, align 8
  %18 = alloca i8**, align 8
  %19 = alloca i8***, align 8
  %20 = alloca i8****, align 8
  %21 = alloca i32, align 4
  %22 = alloca i8, align 1
  %23 = alloca i32, align 4
  %24 = alloca i32, align 4
  %25 = alloca i32, align 4
  %26 = alloca i32*, align 8
  %27 = alloca i16*, align 8
  %28 = alloca i64*, align 8
  %29 = alloca [10 x %union.U0*], align 16
  %30 = alloca %union.U0**, align 8
  %31 = alloca [6 x %union.U0***], align 16
  %32 = alloca i32, align 4
  %33 = alloca i32, align 4
  %34 = alloca i32, align 4
  %35 = alloca i32, align 4
  %36 = alloca [3 x [8 x i32]], align 16
  %37 = alloca [1 x [10 x i16]], align 16
  %38 = alloca [4 x i8*], align 16
  %39 = alloca [8 x [4 x [1 x %union.U0*]]], align 16
  %40 = alloca i32***, align 8
  %41 = alloca i32****, align 8
  %42 = alloca i64***, align 8
  %43 = alloca i32, align 4
  %44 = alloca i16, align 2
  %45 = alloca i8, align 1
  %46 = alloca i16, align 2
  %47 = alloca i32, align 4
  %48 = alloca i32, align 4
  %49 = alloca i32, align 4
  %50 = alloca [3 x [3 x [5 x i32*]]], align 16
  %51 = alloca [3 x [8 x i64]], align 16
  %52 = alloca i16*, align 8
  %53 = alloca i8***, align 8
  %54 = alloca i8*, align 8
  %55 = alloca i32**, align 8
  %56 = alloca i32***, align 8
  %57 = alloca i32****, align 8
  %58 = alloca i32, align 4
  %59 = alloca i32, align 4
  %60 = alloca i32, align 4
  %61 = alloca [8 x i32], align 16
  %62 = alloca i32*, align 8
  %63 = alloca i32*, align 8
  %64 = alloca i32*, align 8
  %65 = alloca [10 x i32*], align 16
  %66 = alloca [1 x [9 x %union.U0*]], align 16
  %67 = alloca i32**, align 8
  %68 = alloca i64*, align 8
  %69 = alloca [8 x i64*], align 16
  %70 = alloca i32, align 4
  %71 = alloca i8*, align 8
  %72 = alloca i32, align 4
  %73 = alloca i32, align 4
  %74 = alloca i8***, align 8
  %75 = alloca [5 x i32], align 16
  %76 = alloca i8, align 1
  %77 = alloca i16, align 2
  %78 = alloca i32, align 4
  %79 = alloca i32, align 4
  store %union.U0* %0, %union.U0** %2, align 8
  store i32 0, i32* %3, align 4
  store %union.U0*** null, %union.U0**** %4, align 8
  store %union.U0**** %4, %union.U0***** %5, align 8
  store i32 -2137612391, i32* %6, align 4
  store i32 0, i32* %7, align 4
  %80 = bitcast [9 x [5 x [5 x i32]]]* %8 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %80, i8* align 16 bitcast ([9 x [5 x [5 x i32]]]* @__const.func_46.l_1953 to i8*), i64 900, i1 false)
  store i64 -1166764491979210464, i64* %9, align 8
  %81 = bitcast [8 x i16*]* %10 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %81, i8* align 16 bitcast ([8 x i16*]* @__const.func_46.l_2041 to i8*), i64 64, i1 false)
  store i32*** getelementptr inbounds ([8 x i32**], [8 x i32**]* @g_796, i64 0, i64 6), i32**** %12, align 8
  store i8 -1, i8* %13, align 1
  store i64 -2462665954887560804, i64* %14, align 8
  store i32* %7, i32** %15, align 8
  %82 = bitcast [5 x [8 x [6 x i8*]]]* %16 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %82, i8* align 16 bitcast ([5 x [8 x [6 x i8*]]]* @__const.func_46.l_2222 to i8*), i64 1920, i1 false)
  store i8**** null, i8***** %17, align 8
  store i8** null, i8*** %18, align 8
  store i8*** %18, i8**** %19, align 8
  store i8**** %19, i8***** %20, align 8
  store i32 0, i32* %21, align 4
  store i8 92, i8* %22, align 1
  store i32 0, i32* %23, align 4
  br label %83

83:                                               ; preds = %90, %1
  %84 = load i32, i32* %23, align 4
  %85 = icmp slt i32 %84, 1
  br i1 %85, label %86, label %93

86:                                               ; preds = %83
  %87 = load i32, i32* %23, align 4
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds [1 x i32***], [1 x i32***]* %11, i64 0, i64 %88
  store i32*** @g_1673, i32**** %89, align 8
  br label %90

90:                                               ; preds = %86
  %91 = load i32, i32* %23, align 4
  %92 = add nsw i32 %91, 1
  store i32 %92, i32* %23, align 4
  br label %83

93:                                               ; preds = %83
  store i32 0, i32* @g_326, align 4
  br label %94

94:                                               ; preds = %143, %93
  %95 = load i32, i32* @g_326, align 4
  %96 = icmp ult i32 %95, 35
  br i1 %96, label %97, label %146

97:                                               ; preds = %94
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 6, i64 3), i32** %26, align 8
  store i16* @g_135, i16** %27, align 8
  store i64* @g_617, i64** %28, align 8
  %98 = getelementptr inbounds [10 x %union.U0*], [10 x %union.U0*]* %29, i64 0, i64 7
  store %union.U0** %98, %union.U0*** %30, align 8
  %99 = getelementptr inbounds [6 x %union.U0***], [6 x %union.U0***]* %31, i64 0, i64 0
  store %union.U0*** %30, %union.U0**** %99, align 8
  %100 = getelementptr inbounds %union.U0***, %union.U0**** %99, i64 1
  store %union.U0*** %30, %union.U0**** %100, align 8
  %101 = getelementptr inbounds %union.U0***, %union.U0**** %100, i64 1
  store %union.U0*** %30, %union.U0**** %101, align 8
  %102 = getelementptr inbounds %union.U0***, %union.U0**** %101, i64 1
  store %union.U0*** %30, %union.U0**** %102, align 8
  %103 = getelementptr inbounds %union.U0***, %union.U0**** %102, i64 1
  store %union.U0*** %30, %union.U0**** %103, align 8
  %104 = getelementptr inbounds %union.U0***, %union.U0**** %103, i64 1
  store %union.U0*** %30, %union.U0**** %104, align 8
  store i32 2, i32* %32, align 4
  store i32 -1519801778, i32* %33, align 4
  store i32 9, i32* %34, align 4
  store i32 8, i32* %35, align 4
  %105 = bitcast [3 x [8 x i32]]* %36 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %105, i8* align 16 bitcast ([3 x [8 x i32]]* @__const.func_46.l_1980 to i8*), i64 96, i1 false)
  %106 = bitcast [4 x i8*]* %38 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %106, i8* align 16 bitcast ([4 x i8*]* @__const.func_46.l_2162 to i8*), i64 32, i1 false)
  %107 = bitcast [8 x [4 x [1 x %union.U0*]]]* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %107, i8* align 16 bitcast ([8 x [4 x [1 x %union.U0*]]]* @__const.func_46.l_2224 to i8*), i64 256, i1 false)
  store i32*** @g_421, i32**** %40, align 8
  store i32**** %40, i32***** %41, align 8
  store i64*** @g_2096, i64**** %42, align 8
  store i32 486225127, i32* %43, align 4
  store i16 -24022, i16* %44, align 2
  store i8 -69, i8* %45, align 1
  store i16 0, i16* %46, align 2
  store i32 0, i32* %47, align 4
  br label %108

108:                                              ; preds = %115, %97
  %109 = load i32, i32* %47, align 4
  %110 = icmp slt i32 %109, 10
  br i1 %110, label %111, label %118

111:                                              ; preds = %108
  %112 = load i32, i32* %47, align 4
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds [10 x %union.U0*], [10 x %union.U0*]* %29, i64 0, i64 %113
  store %union.U0* getelementptr inbounds ([10 x %union.U0], [10 x %union.U0]* bitcast ([10 x { i16, [6 x i8] }]* @g_495 to [10 x %union.U0]*), i64 0, i64 0), %union.U0** %114, align 8
  br label %115

115:                                              ; preds = %111
  %116 = load i32, i32* %47, align 4
  %117 = add nsw i32 %116, 1
  store i32 %117, i32* %47, align 4
  br label %108

118:                                              ; preds = %108
  store i32 0, i32* %47, align 4
  br label %119

119:                                              ; preds = %137, %118
  %120 = load i32, i32* %47, align 4
  %121 = icmp slt i32 %120, 1
  br i1 %121, label %122, label %140

122:                                              ; preds = %119
  store i32 0, i32* %48, align 4
  br label %123

123:                                              ; preds = %133, %122
  %124 = load i32, i32* %48, align 4
  %125 = icmp slt i32 %124, 10
  br i1 %125, label %126, label %136

126:                                              ; preds = %123
  %127 = load i32, i32* %47, align 4
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds [1 x [10 x i16]], [1 x [10 x i16]]* %37, i64 0, i64 %128
  %130 = load i32, i32* %48, align 4
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds [10 x i16], [10 x i16]* %129, i64 0, i64 %131
  store i16 -13340, i16* %132, align 2
  br label %133

133:                                              ; preds = %126
  %134 = load i32, i32* %48, align 4
  %135 = add nsw i32 %134, 1
  store i32 %135, i32* %48, align 4
  br label %123

136:                                              ; preds = %123
  br label %137

137:                                              ; preds = %136
  %138 = load i32, i32* %47, align 4
  %139 = add nsw i32 %138, 1
  store i32 %139, i32* %47, align 4
  br label %119

140:                                              ; preds = %119
  %141 = load i32, i32* %3, align 4
  %142 = add i32 %141, 1
  store i32 %142, i32* %3, align 4
  br label %143

143:                                              ; preds = %140
  %144 = load i32, i32* @g_326, align 4
  %145 = add i32 %144, 1
  store i32 %145, i32* @g_326, align 4
  br label %94

146:                                              ; preds = %94
  store i32 28, i32* %21, align 4
  br label %147

147:                                              ; preds = %269, %146
  %148 = load i32, i32* %21, align 4
  %149 = icmp sgt i32 %148, -7
  br i1 %149, label %150, label %274

150:                                              ; preds = %147
  %151 = getelementptr inbounds [3 x [3 x [5 x i32*]]], [3 x [3 x [5 x i32*]]]* %50, i64 0, i64 0
  %152 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %151, i64 0, i64 0
  %153 = getelementptr inbounds [5 x i32*], [5 x i32*]* %152, i64 0, i64 0
  store i32* @g_89, i32** %153, align 8
  %154 = getelementptr inbounds i32*, i32** %153, i64 1
  store i32* null, i32** %154, align 8
  %155 = getelementptr inbounds i32*, i32** %154, i64 1
  store i32* %7, i32** %155, align 8
  %156 = getelementptr inbounds i32*, i32** %155, i64 1
  store i32* null, i32** %156, align 8
  %157 = getelementptr inbounds i32*, i32** %156, i64 1
  store i32* @g_89, i32** %157, align 8
  %158 = getelementptr inbounds [5 x i32*], [5 x i32*]* %152, i64 1
  %159 = getelementptr inbounds [5 x i32*], [5 x i32*]* %158, i64 0, i64 0
  %160 = bitcast [5 x i32*]* %158 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %160, i8* align 8 bitcast ([5 x i32*]* @constinit.5 to i8*), i64 40, i1 false)
  %161 = getelementptr inbounds [5 x i32*], [5 x i32*]* %158, i64 1
  %162 = bitcast [5 x i32*]* %161 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %162, i8 0, i64 40, i1 false)
  %163 = getelementptr inbounds [5 x i32*], [5 x i32*]* %161, i64 0, i64 0
  %164 = getelementptr inbounds i32*, i32** %163, i64 1
  %165 = getelementptr inbounds i32*, i32** %164, i64 1
  %166 = getelementptr inbounds i32*, i32** %165, i64 1
  %167 = getelementptr inbounds [9 x [5 x [5 x i32]]], [9 x [5 x [5 x i32]]]* %8, i64 0, i64 0
  %168 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %167, i64 0, i64 0
  %169 = getelementptr inbounds [5 x i32], [5 x i32]* %168, i64 0, i64 4
  store i32* %169, i32** %166, align 8
  %170 = getelementptr inbounds i32*, i32** %166, i64 1
  %171 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %151, i64 1
  %172 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %171, i64 0, i64 0
  %173 = getelementptr inbounds [5 x i32*], [5 x i32*]* %172, i64 0, i64 0
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 3), i32** %173, align 8
  %174 = getelementptr inbounds i32*, i32** %173, i64 1
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 3), i32** %174, align 8
  %175 = getelementptr inbounds i32*, i32** %174, i64 1
  store i32* %7, i32** %175, align 8
  %176 = getelementptr inbounds i32*, i32** %175, i64 1
  store i32* @g_868, i32** %176, align 8
  %177 = getelementptr inbounds i32*, i32** %176, i64 1
  store i32* @g_45, i32** %177, align 8
  %178 = getelementptr inbounds [5 x i32*], [5 x i32*]* %172, i64 1
  %179 = getelementptr inbounds [5 x i32*], [5 x i32*]* %178, i64 0, i64 0
  store i32* @g_89, i32** %179, align 8
  %180 = getelementptr inbounds i32*, i32** %179, i64 1
  %181 = getelementptr inbounds [9 x [5 x [5 x i32]]], [9 x [5 x [5 x i32]]]* %8, i64 0, i64 0
  %182 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %181, i64 0, i64 0
  %183 = getelementptr inbounds [5 x i32], [5 x i32]* %182, i64 0, i64 4
  store i32* %183, i32** %180, align 8
  %184 = getelementptr inbounds i32*, i32** %180, i64 1
  store i32* %7, i32** %184, align 8
  %185 = getelementptr inbounds i32*, i32** %184, i64 1
  %186 = getelementptr inbounds [9 x [5 x [5 x i32]]], [9 x [5 x [5 x i32]]]* %8, i64 0, i64 0
  %187 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %186, i64 0, i64 0
  %188 = getelementptr inbounds [5 x i32], [5 x i32]* %187, i64 0, i64 4
  store i32* %188, i32** %185, align 8
  %189 = getelementptr inbounds i32*, i32** %185, i64 1
  store i32* @g_89, i32** %189, align 8
  %190 = getelementptr inbounds [5 x i32*], [5 x i32*]* %178, i64 1
  %191 = getelementptr inbounds [5 x i32*], [5 x i32*]* %190, i64 0, i64 0
  store i32* @g_45, i32** %191, align 8
  %192 = getelementptr inbounds i32*, i32** %191, i64 1
  store i32* @g_868, i32** %192, align 8
  %193 = getelementptr inbounds i32*, i32** %192, i64 1
  store i32* %7, i32** %193, align 8
  %194 = getelementptr inbounds i32*, i32** %193, i64 1
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 3), i32** %194, align 8
  %195 = getelementptr inbounds i32*, i32** %194, i64 1
  store i32* getelementptr inbounds ([7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 3, i64 3), i32** %195, align 8
  %196 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %171, i64 1
  %197 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %196, i64 0, i64 0
  %198 = bitcast [5 x i32*]* %197 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %198, i8 0, i64 40, i1 false)
  %199 = getelementptr inbounds [5 x i32*], [5 x i32*]* %197, i64 0, i64 0
  %200 = getelementptr inbounds i32*, i32** %199, i64 1
  %201 = getelementptr inbounds [9 x [5 x [5 x i32]]], [9 x [5 x [5 x i32]]]* %8, i64 0, i64 0
  %202 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %201, i64 0, i64 0
  %203 = getelementptr inbounds [5 x i32], [5 x i32]* %202, i64 0, i64 4
  store i32* %203, i32** %200, align 8
  %204 = getelementptr inbounds i32*, i32** %200, i64 1
  %205 = getelementptr inbounds i32*, i32** %204, i64 1
  %206 = getelementptr inbounds i32*, i32** %205, i64 1
  %207 = getelementptr inbounds [5 x i32*], [5 x i32*]* %197, i64 1
  %208 = getelementptr inbounds [5 x i32*], [5 x i32*]* %207, i64 0, i64 0
  %209 = bitcast [5 x i32*]* %207 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %209, i8* align 8 bitcast ([5 x i32*]* @constinit.6 to i8*), i64 40, i1 false)
  %210 = getelementptr inbounds [5 x i32*], [5 x i32*]* %207, i64 1
  %211 = getelementptr inbounds [5 x i32*], [5 x i32*]* %210, i64 0, i64 0
  store i32* @g_89, i32** %211, align 8
  %212 = getelementptr inbounds i32*, i32** %211, i64 1
  store i32* null, i32** %212, align 8
  %213 = getelementptr inbounds i32*, i32** %212, i64 1
  store i32* %7, i32** %213, align 8
  %214 = getelementptr inbounds i32*, i32** %213, i64 1
  store i32* null, i32** %214, align 8
  %215 = getelementptr inbounds i32*, i32** %214, i64 1
  store i32* @g_89, i32** %215, align 8
  %216 = bitcast [3 x [8 x i64]]* %51 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %216, i8* align 16 bitcast ([3 x [8 x i64]]* @__const.func_46.l_2424 to i8*), i64 192, i1 false)
  store i16* @g_370, i16** %52, align 8
  store i8*** %18, i8**** %53, align 8
  store i8* @g_116, i8** %54, align 8
  store i32** null, i32*** %55, align 8
  store i32*** %55, i32**** %56, align 8
  store i32**** %56, i32***** %57, align 8
  %217 = getelementptr inbounds [3 x [3 x [5 x i32*]]], [3 x [3 x [5 x i32*]]]* %50, i64 0, i64 1
  %218 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %217, i64 0, i64 2
  %219 = getelementptr inbounds [5 x i32*], [5 x i32*]* %218, i64 0, i64 1
  %220 = load i32*, i32** %219, align 8
  %221 = getelementptr inbounds [3 x [3 x [5 x i32*]]], [3 x [3 x [5 x i32*]]]* %50, i64 0, i64 0
  %222 = getelementptr inbounds [3 x [5 x i32*]], [3 x [5 x i32*]]* %221, i64 0, i64 2
  %223 = getelementptr inbounds [5 x i32*], [5 x i32*]* %222, i64 0, i64 0
  store i32* %220, i32** %223, align 16
  %224 = getelementptr inbounds [9 x [5 x [5 x i32]]], [9 x [5 x [5 x i32]]]* %8, i64 0, i64 0
  %225 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %224, i64 0, i64 0
  %226 = getelementptr inbounds [5 x i32], [5 x i32]* %225, i64 0, i64 4
  %227 = load i32**, i32*** @g_421, align 8
  store i32* %226, i32** %227, align 8
  store i32 0, i32* %3, align 4
  br label %228

228:                                              ; preds = %265, %150
  %229 = load i32, i32* %3, align 4
  %230 = icmp ugt i32 %229, 36
  br i1 %230, label %231, label %268

231:                                              ; preds = %228
  %232 = bitcast [8 x i32]* %61 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %232, i8* align 16 bitcast ([8 x i32]* @__const.func_46.l_2411 to i8*), i64 32, i1 false)
  store i32* null, i32** %62, align 8
  store i32* @g_95, i32** %63, align 8
  store i32* @g_326, i32** %64, align 8
  %233 = bitcast [10 x i32*]* %65 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %233, i8* align 16 bitcast ([10 x i32*]* @__const.func_46.l_2417 to i8*), i64 80, i1 false)
  store i32** @g_797, i32*** %67, align 8
  store i64* @g_617, i64** %68, align 8
  %234 = getelementptr inbounds [8 x i64*], [8 x i64*]* %69, i64 0, i64 0
  store i64* %14, i64** %234, align 8
  %235 = getelementptr inbounds i64*, i64** %234, i64 1
  store i64* @g_2113, i64** %235, align 8
  %236 = getelementptr inbounds i64*, i64** %235, i64 1
  store i64* %14, i64** %236, align 8
  %237 = getelementptr inbounds i64*, i64** %236, i64 1
  store i64* %14, i64** %237, align 8
  %238 = getelementptr inbounds i64*, i64** %237, i64 1
  store i64* @g_2113, i64** %238, align 8
  %239 = getelementptr inbounds i64*, i64** %238, i64 1
  store i64* %14, i64** %239, align 8
  %240 = getelementptr inbounds i64*, i64** %239, i64 1
  store i64* %14, i64** %240, align 8
  %241 = getelementptr inbounds i64*, i64** %240, i64 1
  store i64* @g_2113, i64** %241, align 8
  store i32 -1851245875, i32* %70, align 4
  store i8* @g_82, i8** %71, align 8
  store i32 -1251348172, i32* %72, align 4
  store i32 0, i32* %73, align 4
  store i8*** null, i8**** %74, align 8
  %242 = bitcast [5 x i32]* %75 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %242, i8* align 16 bitcast ([5 x i32]* @__const.func_46.l_2570 to i8*), i64 20, i1 false)
  store i8 -6, i8* %76, align 1
  store i16 -6, i16* %77, align 2
  store i32 0, i32* %78, align 4
  br label %243

243:                                              ; preds = %261, %231
  %244 = load i32, i32* %78, align 4
  %245 = icmp slt i32 %244, 1
  br i1 %245, label %246, label %264

246:                                              ; preds = %243
  store i32 0, i32* %79, align 4
  br label %247

247:                                              ; preds = %257, %246
  %248 = load i32, i32* %79, align 4
  %249 = icmp slt i32 %248, 9
  br i1 %249, label %250, label %260

250:                                              ; preds = %247
  %251 = load i32, i32* %78, align 4
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds [1 x [9 x %union.U0*]], [1 x [9 x %union.U0*]]* %66, i64 0, i64 %252
  %254 = load i32, i32* %79, align 4
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds [9 x %union.U0*], [9 x %union.U0*]* %253, i64 0, i64 %255
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_2419 to %union.U0*), %union.U0** %256, align 8
  br label %257

257:                                              ; preds = %250
  %258 = load i32, i32* %79, align 4
  %259 = add nsw i32 %258, 1
  store i32 %259, i32* %79, align 4
  br label %247

260:                                              ; preds = %247
  br label %261

261:                                              ; preds = %260
  %262 = load i32, i32* %78, align 4
  %263 = add nsw i32 %262, 1
  store i32 %263, i32* %78, align 4
  br label %243

264:                                              ; preds = %243
  br label %265

265:                                              ; preds = %264
  %266 = load i32, i32* %3, align 4
  %267 = add i32 %266, 1
  store i32 %267, i32* %3, align 4
  br label %228

268:                                              ; preds = %228
  br label %269

269:                                              ; preds = %268
  %270 = load i32, i32* %21, align 4
  %271 = trunc i32 %270 to i8
  %272 = call zeroext i8 @safe_sub_func_uint8_t_u_u(i8 zeroext %271, i8 zeroext 9)
  %273 = zext i8 %272 to i32
  store i32 %273, i32* %21, align 4
  br label %147

274:                                              ; preds = %147
  %275 = load volatile i8**, i8*** @g_515, align 8
  %276 = load i8*, i8** %275, align 8
  ret i8* %276
}

; Function Attrs: noinline nounwind optnone uwtable
define internal %union.U0* @func_48(i32* %0, i32 %1, i8* %2) #0 {
  %4 = alloca i32*, align 8
  %5 = alloca i32, align 4
  %6 = alloca i8*, align 8
  %7 = alloca i32*, align 8
  %8 = alloca i32**, align 8
  %9 = alloca [7 x i64], align 16
  %10 = alloca i32, align 4
  %11 = alloca i32, align 4
  %12 = alloca %union.U0*, align 8
  %13 = alloca [10 x %union.U0**], align 16
  %14 = alloca i16*, align 8
  %15 = alloca i32, align 4
  %16 = alloca i8*, align 8
  %17 = alloca [8 x i16*], align 16
  %18 = alloca i16**, align 8
  %19 = alloca i32, align 4
  %20 = alloca i32, align 4
  %21 = alloca [4 x i32], align 16
  %22 = alloca [6 x i16], align 2
  %23 = alloca i64, align 8
  %24 = alloca i32, align 4
  %25 = alloca i32*, align 8
  %26 = alloca i32, align 4
  %27 = alloca i32, align 4
  %28 = alloca i32, align 4
  %29 = alloca i16****, align 8
  %30 = alloca i64, align 8
  %31 = alloca i16***, align 8
  %32 = alloca i16****, align 8
  %33 = alloca i8***, align 8
  %34 = alloca [1 x [4 x i32***]], align 16
  %35 = alloca i64*, align 8
  %36 = alloca [1 x [9 x i64**]], align 16
  %37 = alloca i64***, align 8
  %38 = alloca [5 x [1 x [1 x i64]]], align 16
  %39 = alloca i8, align 1
  %40 = alloca [4 x i16*], align 16
  %41 = alloca [3 x i16**], align 16
  %42 = alloca [5 x [3 x [10 x i16***]]], align 16
  %43 = alloca i16****, align 8
  %44 = alloca i32, align 4
  %45 = alloca %union.U0***, align 8
  %46 = alloca [7 x i16], align 2
  %47 = alloca i32, align 4
  %48 = alloca %union.U0*, align 8
  %49 = alloca i32, align 4
  %50 = alloca i32, align 4
  %51 = alloca i32, align 4
  store i32* %0, i32** %4, align 8
  store i32 %1, i32* %5, align 4
  store i8* %2, i8** %6, align 8
  store i32* @g_45, i32** %7, align 8
  store i32** %7, i32*** %8, align 8
  store i32 1396116502, i32* %10, align 4
  store i32 1572732380, i32* %11, align 4
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0** %12, align 8
  %52 = bitcast [10 x %union.U0**]* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %52, i8 0, i64 80, i1 false)
  %53 = getelementptr inbounds [10 x %union.U0**], [10 x %union.U0**]* %13, i64 0, i64 0
  %54 = getelementptr inbounds %union.U0**, %union.U0*** %53, i64 1
  %55 = getelementptr inbounds %union.U0**, %union.U0*** %54, i64 1
  store %union.U0** %12, %union.U0*** %55, align 8
  %56 = getelementptr inbounds %union.U0**, %union.U0*** %55, i64 1
  %57 = getelementptr inbounds %union.U0**, %union.U0*** %56, i64 1
  %58 = getelementptr inbounds %union.U0**, %union.U0*** %57, i64 1
  %59 = getelementptr inbounds %union.U0**, %union.U0*** %58, i64 1
  %60 = getelementptr inbounds %union.U0**, %union.U0*** %59, i64 1
  store %union.U0** %12, %union.U0*** %60, align 8
  %61 = getelementptr inbounds %union.U0**, %union.U0*** %60, i64 1
  %62 = getelementptr inbounds %union.U0**, %union.U0*** %61, i64 1
  store i16* @g_135, i16** %14, align 8
  store i32 6, i32* %15, align 4
  store i8* getelementptr inbounds ([4 x [6 x [7 x i8]]], [4 x [6 x [7 x i8]]]* @g_105, i64 0, i64 1, i64 2, i64 5), i8** %16, align 8
  %63 = bitcast [8 x i16*]* %17 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %63, i8* align 16 bitcast ([8 x i16*]* @__const.func_48.l_195 to i8*), i64 64, i1 false)
  %64 = getelementptr inbounds [8 x i16*], [8 x i16*]* %17, i64 0, i64 5
  store i16** %64, i16*** %18, align 8
  store i32 601823381, i32* %19, align 4
  store i32 -674624400, i32* %20, align 4
  %65 = bitcast [4 x i32]* %21 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %65, i8 0, i64 16, i1 false)
  %66 = bitcast [6 x i16]* %22 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %66, i8* align 2 bitcast ([6 x i16]* @__const.func_48.l_274 to i8*), i64 12, i1 false)
  store i64 -3373556706346454297, i64* %23, align 8
  store i32 -10, i32* %24, align 4
  store i32* @g_89, i32** %25, align 8
  store i32 -1, i32* %26, align 4
  store i32 -1883613567, i32* %27, align 4
  store i32 2, i32* %28, align 4
  store i16**** null, i16***** %29, align 8
  store i64 0, i64* %30, align 8
  store i16*** @g_318, i16**** %31, align 8
  store i16**** %31, i16***** %32, align 8
  store i8*** null, i8**** %33, align 8
  %67 = bitcast [1 x [4 x i32***]]* %34 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %67, i8* align 16 bitcast ([1 x [4 x i32***]]* @__const.func_48.l_1127 to i8*), i64 32, i1 false)
  store i64* @g_733, i64** %35, align 8
  %68 = getelementptr inbounds [1 x [9 x i64**]], [1 x [9 x i64**]]* %36, i64 0, i64 0
  %69 = getelementptr inbounds [9 x i64**], [9 x i64**]* %68, i64 0, i64 0
  store i64** %35, i64*** %69, align 8
  %70 = getelementptr inbounds i64**, i64*** %69, i64 1
  store i64** %35, i64*** %70, align 8
  %71 = getelementptr inbounds i64**, i64*** %70, i64 1
  store i64** %35, i64*** %71, align 8
  %72 = getelementptr inbounds i64**, i64*** %71, i64 1
  store i64** %35, i64*** %72, align 8
  %73 = getelementptr inbounds i64**, i64*** %72, i64 1
  store i64** %35, i64*** %73, align 8
  %74 = getelementptr inbounds i64**, i64*** %73, i64 1
  store i64** %35, i64*** %74, align 8
  %75 = getelementptr inbounds i64**, i64*** %74, i64 1
  store i64** %35, i64*** %75, align 8
  %76 = getelementptr inbounds i64**, i64*** %75, i64 1
  store i64** %35, i64*** %76, align 8
  %77 = getelementptr inbounds i64**, i64*** %76, i64 1
  store i64** %35, i64*** %77, align 8
  %78 = getelementptr inbounds [1 x [9 x i64**]], [1 x [9 x i64**]]* %36, i64 0, i64 0
  %79 = getelementptr inbounds [9 x i64**], [9 x i64**]* %78, i64 0, i64 7
  store i64*** %79, i64**** %37, align 8
  store i8 41, i8* %39, align 1
  %80 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  %81 = getelementptr inbounds [4 x i16*], [4 x i16*]* %40, i64 0, i64 3
  store i16** %81, i16*** %80, align 8
  %82 = getelementptr inbounds i16**, i16*** %80, i64 1
  %83 = getelementptr inbounds [4 x i16*], [4 x i16*]* %40, i64 0, i64 3
  store i16** %83, i16*** %82, align 8
  %84 = getelementptr inbounds i16**, i16*** %82, i64 1
  %85 = getelementptr inbounds [4 x i16*], [4 x i16*]* %40, i64 0, i64 3
  store i16** %85, i16*** %84, align 8
  %86 = getelementptr inbounds [5 x [3 x [10 x i16***]]], [5 x [3 x [10 x i16***]]]* %42, i64 0, i64 0
  %87 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %86, i64 0, i64 0
  %88 = getelementptr inbounds [10 x i16***], [10 x i16***]* %87, i64 0, i64 0
  store i16*** null, i16**** %88, align 8
  %89 = getelementptr inbounds i16***, i16**** %88, i64 1
  %90 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %90, i16**** %89, align 8
  %91 = getelementptr inbounds i16***, i16**** %89, i64 1
  %92 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %92, i16**** %91, align 8
  %93 = getelementptr inbounds i16***, i16**** %91, i64 1
  %94 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %94, i16**** %93, align 8
  %95 = getelementptr inbounds i16***, i16**** %93, i64 1
  store i16*** null, i16**** %95, align 8
  %96 = getelementptr inbounds i16***, i16**** %95, i64 1
  %97 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %97, i16**** %96, align 8
  %98 = getelementptr inbounds i16***, i16**** %96, i64 1
  %99 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %99, i16**** %98, align 8
  %100 = getelementptr inbounds i16***, i16**** %98, i64 1
  store i16*** null, i16**** %100, align 8
  %101 = getelementptr inbounds i16***, i16**** %100, i64 1
  store i16*** null, i16**** %101, align 8
  %102 = getelementptr inbounds i16***, i16**** %101, i64 1
  store i16*** null, i16**** %102, align 8
  %103 = getelementptr inbounds [10 x i16***], [10 x i16***]* %87, i64 1
  %104 = getelementptr inbounds [10 x i16***], [10 x i16***]* %103, i64 0, i64 0
  %105 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %105, i16**** %104, align 8
  %106 = getelementptr inbounds i16***, i16**** %104, i64 1
  store i16*** null, i16**** %106, align 8
  %107 = getelementptr inbounds i16***, i16**** %106, i64 1
  %108 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 2
  store i16*** %108, i16**** %107, align 8
  %109 = getelementptr inbounds i16***, i16**** %107, i64 1
  store i16*** null, i16**** %109, align 8
  %110 = getelementptr inbounds i16***, i16**** %109, i64 1
  %111 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %111, i16**** %110, align 8
  %112 = getelementptr inbounds i16***, i16**** %110, i64 1
  %113 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %113, i16**** %112, align 8
  %114 = getelementptr inbounds i16***, i16**** %112, i64 1
  %115 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %115, i16**** %114, align 8
  %116 = getelementptr inbounds i16***, i16**** %114, i64 1
  %117 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %117, i16**** %116, align 8
  %118 = getelementptr inbounds i16***, i16**** %116, i64 1
  %119 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %119, i16**** %118, align 8
  %120 = getelementptr inbounds i16***, i16**** %118, i64 1
  store i16*** null, i16**** %120, align 8
  %121 = getelementptr inbounds [10 x i16***], [10 x i16***]* %103, i64 1
  %122 = getelementptr inbounds [10 x i16***], [10 x i16***]* %121, i64 0, i64 0
  store i16*** null, i16**** %122, align 8
  %123 = getelementptr inbounds i16***, i16**** %122, i64 1
  store i16*** null, i16**** %123, align 8
  %124 = getelementptr inbounds i16***, i16**** %123, i64 1
  store i16*** null, i16**** %124, align 8
  %125 = getelementptr inbounds i16***, i16**** %124, i64 1
  %126 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %126, i16**** %125, align 8
  %127 = getelementptr inbounds i16***, i16**** %125, i64 1
  store i16*** null, i16**** %127, align 8
  %128 = getelementptr inbounds i16***, i16**** %127, i64 1
  %129 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %129, i16**** %128, align 8
  %130 = getelementptr inbounds i16***, i16**** %128, i64 1
  %131 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %131, i16**** %130, align 8
  %132 = getelementptr inbounds i16***, i16**** %130, i64 1
  %133 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %133, i16**** %132, align 8
  %134 = getelementptr inbounds i16***, i16**** %132, i64 1
  %135 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %135, i16**** %134, align 8
  %136 = getelementptr inbounds i16***, i16**** %134, i64 1
  store i16*** null, i16**** %136, align 8
  %137 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %86, i64 1
  %138 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %137, i64 0, i64 0
  %139 = getelementptr inbounds [10 x i16***], [10 x i16***]* %138, i64 0, i64 0
  %140 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %140, i16**** %139, align 8
  %141 = getelementptr inbounds i16***, i16**** %139, i64 1
  %142 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %142, i16**** %141, align 8
  %143 = getelementptr inbounds i16***, i16**** %141, i64 1
  %144 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %144, i16**** %143, align 8
  %145 = getelementptr inbounds i16***, i16**** %143, i64 1
  %146 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %146, i16**** %145, align 8
  %147 = getelementptr inbounds i16***, i16**** %145, i64 1
  %148 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %148, i16**** %147, align 8
  %149 = getelementptr inbounds i16***, i16**** %147, i64 1
  %150 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %150, i16**** %149, align 8
  %151 = getelementptr inbounds i16***, i16**** %149, i64 1
  %152 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %152, i16**** %151, align 8
  %153 = getelementptr inbounds i16***, i16**** %151, i64 1
  store i16*** null, i16**** %153, align 8
  %154 = getelementptr inbounds i16***, i16**** %153, i64 1
  %155 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %155, i16**** %154, align 8
  %156 = getelementptr inbounds i16***, i16**** %154, i64 1
  %157 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %157, i16**** %156, align 8
  %158 = getelementptr inbounds [10 x i16***], [10 x i16***]* %138, i64 1
  %159 = getelementptr inbounds [10 x i16***], [10 x i16***]* %158, i64 0, i64 0
  %160 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %160, i16**** %159, align 8
  %161 = getelementptr inbounds i16***, i16**** %159, i64 1
  store i16*** null, i16**** %161, align 8
  %162 = getelementptr inbounds i16***, i16**** %161, i64 1
  %163 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %163, i16**** %162, align 8
  %164 = getelementptr inbounds i16***, i16**** %162, i64 1
  %165 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %165, i16**** %164, align 8
  %166 = getelementptr inbounds i16***, i16**** %164, i64 1
  %167 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %167, i16**** %166, align 8
  %168 = getelementptr inbounds i16***, i16**** %166, i64 1
  store i16*** null, i16**** %168, align 8
  %169 = getelementptr inbounds i16***, i16**** %168, i64 1
  %170 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %170, i16**** %169, align 8
  %171 = getelementptr inbounds i16***, i16**** %169, i64 1
  %172 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %172, i16**** %171, align 8
  %173 = getelementptr inbounds i16***, i16**** %171, i64 1
  %174 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %174, i16**** %173, align 8
  %175 = getelementptr inbounds i16***, i16**** %173, i64 1
  store i16*** null, i16**** %175, align 8
  %176 = getelementptr inbounds [10 x i16***], [10 x i16***]* %158, i64 1
  %177 = getelementptr inbounds [10 x i16***], [10 x i16***]* %176, i64 0, i64 0
  %178 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %178, i16**** %177, align 8
  %179 = getelementptr inbounds i16***, i16**** %177, i64 1
  %180 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %180, i16**** %179, align 8
  %181 = getelementptr inbounds i16***, i16**** %179, i64 1
  %182 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %182, i16**** %181, align 8
  %183 = getelementptr inbounds i16***, i16**** %181, i64 1
  %184 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %184, i16**** %183, align 8
  %185 = getelementptr inbounds i16***, i16**** %183, i64 1
  %186 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %186, i16**** %185, align 8
  %187 = getelementptr inbounds i16***, i16**** %185, i64 1
  %188 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %188, i16**** %187, align 8
  %189 = getelementptr inbounds i16***, i16**** %187, i64 1
  store i16*** null, i16**** %189, align 8
  %190 = getelementptr inbounds i16***, i16**** %189, i64 1
  %191 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %191, i16**** %190, align 8
  %192 = getelementptr inbounds i16***, i16**** %190, i64 1
  %193 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %193, i16**** %192, align 8
  %194 = getelementptr inbounds i16***, i16**** %192, i64 1
  %195 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %195, i16**** %194, align 8
  %196 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %137, i64 1
  %197 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %196, i64 0, i64 0
  %198 = getelementptr inbounds [10 x i16***], [10 x i16***]* %197, i64 0, i64 0
  store i16*** null, i16**** %198, align 8
  %199 = getelementptr inbounds i16***, i16**** %198, i64 1
  %200 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %200, i16**** %199, align 8
  %201 = getelementptr inbounds i16***, i16**** %199, i64 1
  store i16*** null, i16**** %201, align 8
  %202 = getelementptr inbounds i16***, i16**** %201, i64 1
  %203 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %203, i16**** %202, align 8
  %204 = getelementptr inbounds i16***, i16**** %202, i64 1
  %205 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %205, i16**** %204, align 8
  %206 = getelementptr inbounds i16***, i16**** %204, i64 1
  %207 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %207, i16**** %206, align 8
  %208 = getelementptr inbounds i16***, i16**** %206, i64 1
  %209 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %209, i16**** %208, align 8
  %210 = getelementptr inbounds i16***, i16**** %208, i64 1
  %211 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %211, i16**** %210, align 8
  %212 = getelementptr inbounds i16***, i16**** %210, i64 1
  %213 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %213, i16**** %212, align 8
  %214 = getelementptr inbounds i16***, i16**** %212, i64 1
  %215 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %215, i16**** %214, align 8
  %216 = getelementptr inbounds [10 x i16***], [10 x i16***]* %197, i64 1
  %217 = getelementptr inbounds [10 x i16***], [10 x i16***]* %216, i64 0, i64 0
  %218 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %218, i16**** %217, align 8
  %219 = getelementptr inbounds i16***, i16**** %217, i64 1
  store i16*** null, i16**** %219, align 8
  %220 = getelementptr inbounds i16***, i16**** %219, i64 1
  %221 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %221, i16**** %220, align 8
  %222 = getelementptr inbounds i16***, i16**** %220, i64 1
  store i16*** null, i16**** %222, align 8
  %223 = getelementptr inbounds i16***, i16**** %222, i64 1
  store i16*** null, i16**** %223, align 8
  %224 = getelementptr inbounds i16***, i16**** %223, i64 1
  %225 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %225, i16**** %224, align 8
  %226 = getelementptr inbounds i16***, i16**** %224, i64 1
  %227 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %227, i16**** %226, align 8
  %228 = getelementptr inbounds i16***, i16**** %226, i64 1
  %229 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %229, i16**** %228, align 8
  %230 = getelementptr inbounds i16***, i16**** %228, i64 1
  store i16*** null, i16**** %230, align 8
  %231 = getelementptr inbounds i16***, i16**** %230, i64 1
  %232 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %232, i16**** %231, align 8
  %233 = getelementptr inbounds [10 x i16***], [10 x i16***]* %216, i64 1
  %234 = getelementptr inbounds [10 x i16***], [10 x i16***]* %233, i64 0, i64 0
  store i16*** null, i16**** %234, align 8
  %235 = getelementptr inbounds i16***, i16**** %234, i64 1
  %236 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %236, i16**** %235, align 8
  %237 = getelementptr inbounds i16***, i16**** %235, i64 1
  store i16*** null, i16**** %237, align 8
  %238 = getelementptr inbounds i16***, i16**** %237, i64 1
  %239 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %239, i16**** %238, align 8
  %240 = getelementptr inbounds i16***, i16**** %238, i64 1
  %241 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %241, i16**** %240, align 8
  %242 = getelementptr inbounds i16***, i16**** %240, i64 1
  %243 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %243, i16**** %242, align 8
  %244 = getelementptr inbounds i16***, i16**** %242, i64 1
  %245 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %245, i16**** %244, align 8
  %246 = getelementptr inbounds i16***, i16**** %244, i64 1
  %247 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %247, i16**** %246, align 8
  %248 = getelementptr inbounds i16***, i16**** %246, i64 1
  %249 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %249, i16**** %248, align 8
  %250 = getelementptr inbounds i16***, i16**** %248, i64 1
  store i16*** null, i16**** %250, align 8
  %251 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %196, i64 1
  %252 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %251, i64 0, i64 0
  %253 = getelementptr inbounds [10 x i16***], [10 x i16***]* %252, i64 0, i64 0
  %254 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %254, i16**** %253, align 8
  %255 = getelementptr inbounds i16***, i16**** %253, i64 1
  %256 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %256, i16**** %255, align 8
  %257 = getelementptr inbounds i16***, i16**** %255, i64 1
  %258 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %258, i16**** %257, align 8
  %259 = getelementptr inbounds i16***, i16**** %257, i64 1
  %260 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %260, i16**** %259, align 8
  %261 = getelementptr inbounds i16***, i16**** %259, i64 1
  %262 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %262, i16**** %261, align 8
  %263 = getelementptr inbounds i16***, i16**** %261, i64 1
  %264 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %264, i16**** %263, align 8
  %265 = getelementptr inbounds i16***, i16**** %263, i64 1
  store i16*** null, i16**** %265, align 8
  %266 = getelementptr inbounds i16***, i16**** %265, i64 1
  %267 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %267, i16**** %266, align 8
  %268 = getelementptr inbounds i16***, i16**** %266, i64 1
  store i16*** null, i16**** %268, align 8
  %269 = getelementptr inbounds i16***, i16**** %268, i64 1
  %270 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %270, i16**** %269, align 8
  %271 = getelementptr inbounds [10 x i16***], [10 x i16***]* %252, i64 1
  %272 = getelementptr inbounds [10 x i16***], [10 x i16***]* %271, i64 0, i64 0
  store i16*** null, i16**** %272, align 8
  %273 = getelementptr inbounds i16***, i16**** %272, i64 1
  store i16*** null, i16**** %273, align 8
  %274 = getelementptr inbounds i16***, i16**** %273, i64 1
  %275 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %275, i16**** %274, align 8
  %276 = getelementptr inbounds i16***, i16**** %274, i64 1
  %277 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %277, i16**** %276, align 8
  %278 = getelementptr inbounds i16***, i16**** %276, i64 1
  %279 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %279, i16**** %278, align 8
  %280 = getelementptr inbounds i16***, i16**** %278, i64 1
  store i16*** null, i16**** %280, align 8
  %281 = getelementptr inbounds i16***, i16**** %280, i64 1
  store i16*** null, i16**** %281, align 8
  %282 = getelementptr inbounds i16***, i16**** %281, i64 1
  store i16*** null, i16**** %282, align 8
  %283 = getelementptr inbounds i16***, i16**** %282, i64 1
  store i16*** null, i16**** %283, align 8
  %284 = getelementptr inbounds i16***, i16**** %283, i64 1
  store i16*** null, i16**** %284, align 8
  %285 = getelementptr inbounds [10 x i16***], [10 x i16***]* %271, i64 1
  %286 = getelementptr inbounds [10 x i16***], [10 x i16***]* %285, i64 0, i64 0
  %287 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %287, i16**** %286, align 8
  %288 = getelementptr inbounds i16***, i16**** %286, i64 1
  %289 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %289, i16**** %288, align 8
  %290 = getelementptr inbounds i16***, i16**** %288, i64 1
  %291 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %291, i16**** %290, align 8
  %292 = getelementptr inbounds i16***, i16**** %290, i64 1
  %293 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %293, i16**** %292, align 8
  %294 = getelementptr inbounds i16***, i16**** %292, i64 1
  %295 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %295, i16**** %294, align 8
  %296 = getelementptr inbounds i16***, i16**** %294, i64 1
  %297 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %297, i16**** %296, align 8
  %298 = getelementptr inbounds i16***, i16**** %296, i64 1
  %299 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %299, i16**** %298, align 8
  %300 = getelementptr inbounds i16***, i16**** %298, i64 1
  %301 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %301, i16**** %300, align 8
  %302 = getelementptr inbounds i16***, i16**** %300, i64 1
  %303 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %303, i16**** %302, align 8
  %304 = getelementptr inbounds i16***, i16**** %302, i64 1
  %305 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %305, i16**** %304, align 8
  %306 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %251, i64 1
  %307 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %306, i64 0, i64 0
  %308 = getelementptr inbounds [10 x i16***], [10 x i16***]* %307, i64 0, i64 0
  store i16*** null, i16**** %308, align 8
  %309 = getelementptr inbounds i16***, i16**** %308, i64 1
  %310 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %310, i16**** %309, align 8
  %311 = getelementptr inbounds i16***, i16**** %309, i64 1
  store i16*** null, i16**** %311, align 8
  %312 = getelementptr inbounds i16***, i16**** %311, i64 1
  %313 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %313, i16**** %312, align 8
  %314 = getelementptr inbounds i16***, i16**** %312, i64 1
  %315 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %315, i16**** %314, align 8
  %316 = getelementptr inbounds i16***, i16**** %314, i64 1
  %317 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %317, i16**** %316, align 8
  %318 = getelementptr inbounds i16***, i16**** %316, i64 1
  %319 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %319, i16**** %318, align 8
  %320 = getelementptr inbounds i16***, i16**** %318, i64 1
  %321 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %321, i16**** %320, align 8
  %322 = getelementptr inbounds i16***, i16**** %320, i64 1
  store i16*** null, i16**** %322, align 8
  %323 = getelementptr inbounds i16***, i16**** %322, i64 1
  store i16*** null, i16**** %323, align 8
  %324 = getelementptr inbounds [10 x i16***], [10 x i16***]* %307, i64 1
  %325 = getelementptr inbounds [10 x i16***], [10 x i16***]* %324, i64 0, i64 0
  %326 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %326, i16**** %325, align 8
  %327 = getelementptr inbounds i16***, i16**** %325, i64 1
  store i16*** null, i16**** %327, align 8
  %328 = getelementptr inbounds i16***, i16**** %327, i64 1
  %329 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 2
  store i16*** %329, i16**** %328, align 8
  %330 = getelementptr inbounds i16***, i16**** %328, i64 1
  %331 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %331, i16**** %330, align 8
  %332 = getelementptr inbounds i16***, i16**** %330, i64 1
  store i16*** null, i16**** %332, align 8
  %333 = getelementptr inbounds i16***, i16**** %332, i64 1
  %334 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %334, i16**** %333, align 8
  %335 = getelementptr inbounds i16***, i16**** %333, i64 1
  %336 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %336, i16**** %335, align 8
  %337 = getelementptr inbounds i16***, i16**** %335, i64 1
  store i16*** null, i16**** %337, align 8
  %338 = getelementptr inbounds i16***, i16**** %337, i64 1
  %339 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %339, i16**** %338, align 8
  %340 = getelementptr inbounds i16***, i16**** %338, i64 1
  %341 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %341, i16**** %340, align 8
  %342 = getelementptr inbounds [10 x i16***], [10 x i16***]* %324, i64 1
  %343 = getelementptr inbounds [10 x i16***], [10 x i16***]* %342, i64 0, i64 0
  store i16*** null, i16**** %343, align 8
  %344 = getelementptr inbounds i16***, i16**** %343, i64 1
  %345 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %345, i16**** %344, align 8
  %346 = getelementptr inbounds i16***, i16**** %344, i64 1
  %347 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %347, i16**** %346, align 8
  %348 = getelementptr inbounds i16***, i16**** %346, i64 1
  store i16*** null, i16**** %348, align 8
  %349 = getelementptr inbounds i16***, i16**** %348, i64 1
  %350 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %350, i16**** %349, align 8
  %351 = getelementptr inbounds i16***, i16**** %349, i64 1
  %352 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %352, i16**** %351, align 8
  %353 = getelementptr inbounds i16***, i16**** %351, i64 1
  %354 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 2
  store i16*** %354, i16**** %353, align 8
  %355 = getelementptr inbounds i16***, i16**** %353, i64 1
  %356 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 1
  store i16*** %356, i16**** %355, align 8
  %357 = getelementptr inbounds i16***, i16**** %355, i64 1
  %358 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %358, i16**** %357, align 8
  %359 = getelementptr inbounds i16***, i16**** %357, i64 1
  %360 = getelementptr inbounds [3 x i16**], [3 x i16**]* %41, i64 0, i64 0
  store i16*** %360, i16**** %359, align 8
  %361 = getelementptr inbounds [5 x [3 x [10 x i16***]]], [5 x [3 x [10 x i16***]]]* %42, i64 0, i64 4
  %362 = getelementptr inbounds [3 x [10 x i16***]], [3 x [10 x i16***]]* %361, i64 0, i64 0
  %363 = getelementptr inbounds [10 x i16***], [10 x i16***]* %362, i64 0, i64 2
  store i16**** %363, i16***** %43, align 8
  store i32 1294691491, i32* %44, align 4
  store %union.U0*** @g_547, %union.U0**** %45, align 8
  %364 = bitcast [7 x i16]* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %364, i8* align 2 bitcast ([7 x i16]* @__const.func_48.l_1801 to i8*), i64 14, i1 false)
  store i32 7, i32* %47, align 4
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_927 to %union.U0*), %union.U0** %48, align 8
  store i32 0, i32* %49, align 4
  br label %365

365:                                              ; preds = %372, %3
  %366 = load i32, i32* %49, align 4
  %367 = icmp slt i32 %366, 7
  br i1 %367, label %368, label %375

368:                                              ; preds = %365
  %369 = load i32, i32* %49, align 4
  %370 = sext i32 %369 to i64
  %371 = getelementptr inbounds [7 x i64], [7 x i64]* %9, i64 0, i64 %370
  store i64 -4462209696576348249, i64* %371, align 8
  br label %372

372:                                              ; preds = %368
  %373 = load i32, i32* %49, align 4
  %374 = add nsw i32 %373, 1
  store i32 %374, i32* %49, align 4
  br label %365

375:                                              ; preds = %365
  store i32 0, i32* %49, align 4
  br label %376

376:                                              ; preds = %405, %375
  %377 = load i32, i32* %49, align 4
  %378 = icmp slt i32 %377, 5
  br i1 %378, label %379, label %408

379:                                              ; preds = %376
  store i32 0, i32* %50, align 4
  br label %380

380:                                              ; preds = %401, %379
  %381 = load i32, i32* %50, align 4
  %382 = icmp slt i32 %381, 1
  br i1 %382, label %383, label %404

383:                                              ; preds = %380
  store i32 0, i32* %51, align 4
  br label %384

384:                                              ; preds = %397, %383
  %385 = load i32, i32* %51, align 4
  %386 = icmp slt i32 %385, 1
  br i1 %386, label %387, label %400

387:                                              ; preds = %384
  %388 = load i32, i32* %49, align 4
  %389 = sext i32 %388 to i64
  %390 = getelementptr inbounds [5 x [1 x [1 x i64]]], [5 x [1 x [1 x i64]]]* %38, i64 0, i64 %389
  %391 = load i32, i32* %50, align 4
  %392 = sext i32 %391 to i64
  %393 = getelementptr inbounds [1 x [1 x i64]], [1 x [1 x i64]]* %390, i64 0, i64 %392
  %394 = load i32, i32* %51, align 4
  %395 = sext i32 %394 to i64
  %396 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 %395
  store i64 -4435951939742550178, i64* %396, align 8
  br label %397

397:                                              ; preds = %387
  %398 = load i32, i32* %51, align 4
  %399 = add nsw i32 %398, 1
  store i32 %399, i32* %51, align 4
  br label %384

400:                                              ; preds = %384
  br label %401

401:                                              ; preds = %400
  %402 = load i32, i32* %50, align 4
  %403 = add nsw i32 %402, 1
  store i32 %403, i32* %50, align 4
  br label %380

404:                                              ; preds = %380
  br label %405

405:                                              ; preds = %404
  %406 = load i32, i32* %49, align 4
  %407 = add nsw i32 %406, 1
  store i32 %407, i32* %49, align 4
  br label %376

408:                                              ; preds = %376
  store i32 0, i32* %49, align 4
  br label %409

409:                                              ; preds = %416, %408
  %410 = load i32, i32* %49, align 4
  %411 = icmp slt i32 %410, 4
  br i1 %411, label %412, label %419

412:                                              ; preds = %409
  %413 = load i32, i32* %49, align 4
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds [4 x i16*], [4 x i16*]* %40, i64 0, i64 %414
  store i16* null, i16** %415, align 8
  br label %416

416:                                              ; preds = %412
  %417 = load i32, i32* %49, align 4
  %418 = add nsw i32 %417, 1
  store i32 %418, i32* %49, align 4
  br label %409

419:                                              ; preds = %409
  %420 = load i32*, i32** %4, align 8
  %421 = load i32**, i32*** %8, align 8
  store i32* %420, i32** %421, align 8
  %422 = load %union.U0*, %union.U0** %48, align 8
  ret %union.U0* %422
}

; Function Attrs: noinline nounwind optnone uwtable
define internal i32* @func_52(%union.U0* %0, %union.U0* %1) #0 {
  %3 = alloca %union.U0*, align 8
  %4 = alloca %union.U0*, align 8
  %5 = alloca i8, align 1
  %6 = alloca i32, align 4
  %7 = alloca %union.U0*, align 8
  %8 = alloca %union.U0**, align 8
  %9 = alloca %union.U0**, align 8
  %10 = alloca %union.U0*, align 8
  %11 = alloca %union.U0**, align 8
  %12 = alloca [8 x i8*], align 16
  %13 = alloca [5 x [3 x i32*]], align 16
  %14 = alloca i32, align 4
  %15 = alloca i32, align 4
  %16 = alloca i32, align 4
  store %union.U0* %0, %union.U0** %3, align 8
  store %union.U0* %1, %union.U0** %4, align 8
  store i8 10, i8* %5, align 1
  store i32 -721044328, i32* %6, align 4
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %union.U0** %7, align 8
  store %union.U0** null, %union.U0*** %8, align 8
  store %union.U0** %7, %union.U0*** %9, align 8
  store %union.U0* bitcast ({ i16, [6 x i8] }* @g_80 to %union.U0*), %union.U0** %10, align 8
  store %union.U0** %10, %union.U0*** %11, align 8
  %17 = bitcast [8 x i8*]* %12 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %17, i8* align 16 bitcast ([8 x i8*]* @__const.func_52.l_81 to i8*), i64 64, i1 false)
  %18 = bitcast [5 x [3 x i32*]]* %13 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %18, i8* align 16 bitcast ([5 x [3 x i32*]]* @__const.func_52.l_83 to i8*), i64 120, i1 false)
  store i32 1048909899, i32* %14, align 4
  %19 = load i8, i8* %5, align 1
  %20 = zext i8 %19 to i32
  %21 = load i32, i32* %6, align 4
  %22 = or i32 %21, %20
  store i32 %22, i32* %6, align 4
  %23 = sext i32 %22 to i64
  %24 = load i8, i8* %5, align 1
  %25 = zext i8 %24 to i64
  %26 = icmp uge i64 %25, 0
  %27 = zext i1 %26 to i32
  %28 = load i8, i8* %5, align 1
  %29 = load i8, i8* %5, align 1
  %30 = load i32, i32* @g_45, align 4
  %31 = sext i32 %30 to i64
  %32 = and i64 1, %31
  %33 = load %union.U0*, %union.U0** %7, align 8
  %34 = load %union.U0**, %union.U0*** %9, align 8
  store %union.U0* %33, %union.U0** %34, align 8
  %35 = load %union.U0**, %union.U0*** %11, align 8
  store %union.U0* %33, %union.U0** %35, align 8
  %36 = icmp eq %union.U0* bitcast ({ i16, [6 x i8] }* @g_27 to %union.U0*), %33
  %37 = xor i1 %36, true
  %38 = zext i1 %37 to i32
  %39 = getelementptr inbounds [8 x i8*], [8 x i8*]* %12, i64 0, i64 0
  %40 = load i8*, i8** %39, align 16
  %41 = icmp ne i8* %40, null
  %42 = zext i1 %41 to i32
  %43 = sext i32 %42 to i64
  %44 = icmp ugt i64 %32, %43
  %45 = zext i1 %44 to i32
  %46 = trunc i32 %45 to i16
  %47 = load i8, i8* %5, align 1
  %48 = zext i8 %47 to i16
  %49 = call signext i16 @safe_add_func_int16_t_s_s(i16 signext %46, i16 signext %48)
  %50 = sext i16 %49 to i64
  %51 = load i8, i8* %5, align 1
  %52 = zext i8 %51 to i64
  %53 = call i64 @safe_mod_func_int64_t_s_s(i64 %50, i64 %52)
  %54 = xor i64 %53, -1
  %55 = load i8, i8* %5, align 1
  %56 = load i8, i8* %5, align 1
  %57 = zext i8 %56 to i32
  %58 = load i8, i8* %5, align 1
  %59 = zext i8 %58 to i32
  %60 = icmp sle i32 %57, %59
  %61 = zext i1 %60 to i32
  %62 = trunc i32 %61 to i8
  %63 = call zeroext i8 @safe_mul_func_uint8_t_u_u(i8 zeroext %28, i8 zeroext %62)
  %64 = zext i8 %63 to i16
  %65 = load i8, i8* %5, align 1
  %66 = zext i8 %65 to i32
  %67 = call zeroext i16 @safe_lshift_func_uint16_t_u_u(i16 zeroext %64, i32 %66)
  %68 = zext i16 %67 to i64
  %69 = icmp sgt i64 %68, 203
  %70 = zext i1 %69 to i32
  %71 = xor i32 %27, %70
  %72 = sext i32 %71 to i64
  %73 = call i64 @safe_div_func_int64_t_s_s(i64 %23, i64 %72)
  %74 = trunc i64 %73 to i32
  store i32 %74, i32* %14, align 4
  ret i32* @g_45
}

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main(i32 %0, i8** %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i8**, align 8
  %6 = alloca i32, align 4
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  %9 = alloca i32, align 4
  store i32 0, i32* %3, align 4
  store i32 %0, i32* %4, align 4
  store i8** %1, i8*** %5, align 8
  store i32 0, i32* %9, align 4
  %10 = load i32, i32* %4, align 4
  %11 = icmp eq i32 %10, 2
  br i1 %11, label %12, label %19

12:                                               ; preds = %2
  %13 = load i8**, i8*** %5, align 8
  %14 = getelementptr inbounds i8*, i8** %13, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = call i32 @strcmp(i8* %15, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.7, i64 0, i64 0)) #5
  %17 = icmp eq i32 %16, 0
  br i1 %17, label %18, label %19

18:                                               ; preds = %12
  store i32 1, i32* %9, align 4
  br label %19

19:                                               ; preds = %18, %12, %2
  call void @platform_main_begin()
  call void @crc32_gentab()
  %20 = call i64 @func_1()
  %21 = load i32, i32* @g_12, align 4
  %22 = sext i32 %21 to i64
  %23 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %22, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.8, i64 0, i64 0), i32 %23)
  %24 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_27, i32 0, i32 0), align 8
  %25 = zext i16 %24 to i64
  %26 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %25, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.9, i64 0, i64 0), i32 %26)
  %27 = load i32, i32* @g_45, align 4
  %28 = sext i32 %27 to i64
  %29 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %28, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.10, i64 0, i64 0), i32 %29)
  %30 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_80, i32 0, i32 0), align 8
  %31 = zext i16 %30 to i64
  %32 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %31, i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.11, i64 0, i64 0), i32 %32)
  %33 = load i8, i8* @g_82, align 1
  %34 = sext i8 %33 to i64
  %35 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %34, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.12, i64 0, i64 0), i32 %35)
  %36 = load i32, i32* @g_89, align 4
  %37 = sext i32 %36 to i64
  %38 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %37, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.13, i64 0, i64 0), i32 %38)
  %39 = load i32, i32* @g_95, align 4
  %40 = zext i32 %39 to i64
  %41 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %40, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.14, i64 0, i64 0), i32 %41)
  store i32 0, i32* %6, align 4
  br label %42

42:                                               ; preds = %82, %19
  %43 = load i32, i32* %6, align 4
  %44 = icmp slt i32 %43, 4
  br i1 %44, label %45, label %85

45:                                               ; preds = %42
  store i32 0, i32* %7, align 4
  br label %46

46:                                               ; preds = %78, %45
  %47 = load i32, i32* %7, align 4
  %48 = icmp slt i32 %47, 6
  br i1 %48, label %49, label %81

49:                                               ; preds = %46
  store i32 0, i32* %8, align 4
  br label %50

50:                                               ; preds = %74, %49
  %51 = load i32, i32* %8, align 4
  %52 = icmp slt i32 %51, 7
  br i1 %52, label %53, label %77

53:                                               ; preds = %50
  %54 = load i32, i32* %6, align 4
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds [4 x [6 x [7 x i8]]], [4 x [6 x [7 x i8]]]* @g_105, i64 0, i64 %55
  %57 = load i32, i32* %7, align 4
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds [6 x [7 x i8]], [6 x [7 x i8]]* %56, i64 0, i64 %58
  %60 = load i32, i32* %8, align 4
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds [7 x i8], [7 x i8]* %59, i64 0, i64 %61
  %63 = load i8, i8* %62, align 1
  %64 = zext i8 %63 to i64
  %65 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %64, i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.15, i64 0, i64 0), i32 %65)
  %66 = load i32, i32* %9, align 4
  %67 = icmp ne i32 %66, 0
  br i1 %67, label %68, label %73

68:                                               ; preds = %53
  %69 = load i32, i32* %6, align 4
  %70 = load i32, i32* %7, align 4
  %71 = load i32, i32* %8, align 4
  %72 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.16, i64 0, i64 0), i32 %69, i32 %70, i32 %71)
  br label %73

73:                                               ; preds = %68, %53
  br label %74

74:                                               ; preds = %73
  %75 = load i32, i32* %8, align 4
  %76 = add nsw i32 %75, 1
  store i32 %76, i32* %8, align 4
  br label %50

77:                                               ; preds = %50
  br label %78

78:                                               ; preds = %77
  %79 = load i32, i32* %7, align 4
  %80 = add nsw i32 %79, 1
  store i32 %80, i32* %7, align 4
  br label %46

81:                                               ; preds = %46
  br label %82

82:                                               ; preds = %81
  %83 = load i32, i32* %6, align 4
  %84 = add nsw i32 %83, 1
  store i32 %84, i32* %6, align 4
  br label %42

85:                                               ; preds = %42
  %86 = load i8, i8* @g_116, align 1
  %87 = sext i8 %86 to i64
  %88 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %87, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.17, i64 0, i64 0), i32 %88)
  %89 = load i16, i16* @g_135, align 2
  %90 = zext i16 %89 to i64
  %91 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %90, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.18, i64 0, i64 0), i32 %91)
  %92 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 65535, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.19, i64 0, i64 0), i32 %92)
  store i32 0, i32* %6, align 4
  br label %93

93:                                               ; preds = %133, %85
  %94 = load i32, i32* %6, align 4
  %95 = icmp slt i32 %94, 9
  br i1 %95, label %96, label %136

96:                                               ; preds = %93
  store i32 0, i32* %7, align 4
  br label %97

97:                                               ; preds = %129, %96
  %98 = load i32, i32* %7, align 4
  %99 = icmp slt i32 %98, 7
  br i1 %99, label %100, label %132

100:                                              ; preds = %97
  store i32 0, i32* %8, align 4
  br label %101

101:                                              ; preds = %125, %100
  %102 = load i32, i32* %8, align 4
  %103 = icmp slt i32 %102, 4
  br i1 %103, label %104, label %128

104:                                              ; preds = %101
  %105 = load i32, i32* %6, align 4
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds [9 x [7 x [4 x i32]]], [9 x [7 x [4 x i32]]]* @g_169, i64 0, i64 %106
  %108 = load i32, i32* %7, align 4
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds [7 x [4 x i32]], [7 x [4 x i32]]* %107, i64 0, i64 %109
  %111 = load i32, i32* %8, align 4
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds [4 x i32], [4 x i32]* %110, i64 0, i64 %112
  %114 = load i32, i32* %113, align 4
  %115 = zext i32 %114 to i64
  %116 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %115, i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.20, i64 0, i64 0), i32 %116)
  %117 = load i32, i32* %9, align 4
  %118 = icmp ne i32 %117, 0
  br i1 %118, label %119, label %124

119:                                              ; preds = %104
  %120 = load i32, i32* %6, align 4
  %121 = load i32, i32* %7, align 4
  %122 = load i32, i32* %8, align 4
  %123 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.16, i64 0, i64 0), i32 %120, i32 %121, i32 %122)
  br label %124

124:                                              ; preds = %119, %104
  br label %125

125:                                              ; preds = %124
  %126 = load i32, i32* %8, align 4
  %127 = add nsw i32 %126, 1
  store i32 %127, i32* %8, align 4
  br label %101

128:                                              ; preds = %101
  br label %129

129:                                              ; preds = %128
  %130 = load i32, i32* %7, align 4
  %131 = add nsw i32 %130, 1
  store i32 %131, i32* %7, align 4
  br label %97

132:                                              ; preds = %97
  br label %133

133:                                              ; preds = %132
  %134 = load i32, i32* %6, align 4
  %135 = add nsw i32 %134, 1
  store i32 %135, i32* %6, align 4
  br label %93

136:                                              ; preds = %93
  %137 = load i32, i32* @g_216, align 4
  %138 = zext i32 %137 to i64
  %139 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %138, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.21, i64 0, i64 0), i32 %139)
  %140 = load i32, i32* @g_326, align 4
  %141 = zext i32 %140 to i64
  %142 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %141, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.22, i64 0, i64 0), i32 %142)
  %143 = load i16, i16* @g_370, align 2
  %144 = sext i16 %143 to i64
  %145 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %144, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.23, i64 0, i64 0), i32 %145)
  %146 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_444, i32 0, i32 0), align 8
  %147 = zext i16 %146 to i64
  %148 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %147, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.24, i64 0, i64 0), i32 %148)
  %149 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_493, i32 0, i32 0), align 8
  %150 = zext i16 %149 to i64
  %151 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %150, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.25, i64 0, i64 0), i32 %151)
  store i32 0, i32* %6, align 4
  br label %152

152:                                              ; preds = %193, %136
  %153 = load i32, i32* %6, align 4
  %154 = icmp slt i32 %153, 4
  br i1 %154, label %155, label %196

155:                                              ; preds = %152
  store i32 0, i32* %7, align 4
  br label %156

156:                                              ; preds = %189, %155
  %157 = load i32, i32* %7, align 4
  %158 = icmp slt i32 %157, 9
  br i1 %158, label %159, label %192

159:                                              ; preds = %156
  store i32 0, i32* %8, align 4
  br label %160

160:                                              ; preds = %185, %159
  %161 = load i32, i32* %8, align 4
  %162 = icmp slt i32 %161, 7
  br i1 %162, label %163, label %188

163:                                              ; preds = %160
  %164 = load i32, i32* %6, align 4
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds [4 x [9 x [7 x %union.U0]]], [4 x [9 x [7 x %union.U0]]]* bitcast ([4 x [9 x [7 x { i16, [6 x i8] }]]]* @g_494 to [4 x [9 x [7 x %union.U0]]]*), i64 0, i64 %165
  %167 = load i32, i32* %7, align 4
  %168 = sext i32 %167 to i64
  %169 = getelementptr inbounds [9 x [7 x %union.U0]], [9 x [7 x %union.U0]]* %166, i64 0, i64 %168
  %170 = load i32, i32* %8, align 4
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds [7 x %union.U0], [7 x %union.U0]* %169, i64 0, i64 %171
  %173 = bitcast %union.U0* %172 to i16*
  %174 = load volatile i16, i16* %173, align 8
  %175 = zext i16 %174 to i64
  %176 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %175, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.26, i64 0, i64 0), i32 %176)
  %177 = load i32, i32* %9, align 4
  %178 = icmp ne i32 %177, 0
  br i1 %178, label %179, label %184

179:                                              ; preds = %163
  %180 = load i32, i32* %6, align 4
  %181 = load i32, i32* %7, align 4
  %182 = load i32, i32* %8, align 4
  %183 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.16, i64 0, i64 0), i32 %180, i32 %181, i32 %182)
  br label %184

184:                                              ; preds = %179, %163
  br label %185

185:                                              ; preds = %184
  %186 = load i32, i32* %8, align 4
  %187 = add nsw i32 %186, 1
  store i32 %187, i32* %8, align 4
  br label %160

188:                                              ; preds = %160
  br label %189

189:                                              ; preds = %188
  %190 = load i32, i32* %7, align 4
  %191 = add nsw i32 %190, 1
  store i32 %191, i32* %7, align 4
  br label %156

192:                                              ; preds = %156
  br label %193

193:                                              ; preds = %192
  %194 = load i32, i32* %6, align 4
  %195 = add nsw i32 %194, 1
  store i32 %195, i32* %6, align 4
  br label %152

196:                                              ; preds = %152
  store i32 0, i32* %6, align 4
  br label %197

197:                                              ; preds = %214, %196
  %198 = load i32, i32* %6, align 4
  %199 = icmp slt i32 %198, 10
  br i1 %199, label %200, label %217

200:                                              ; preds = %197
  %201 = load i32, i32* %6, align 4
  %202 = sext i32 %201 to i64
  %203 = getelementptr inbounds [10 x %union.U0], [10 x %union.U0]* bitcast ([10 x { i16, [6 x i8] }]* @g_495 to [10 x %union.U0]*), i64 0, i64 %202
  %204 = bitcast %union.U0* %203 to i16*
  %205 = load volatile i16, i16* %204, align 8
  %206 = zext i16 %205 to i64
  %207 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %206, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.27, i64 0, i64 0), i32 %207)
  %208 = load i32, i32* %9, align 4
  %209 = icmp ne i32 %208, 0
  br i1 %209, label %210, label %213

210:                                              ; preds = %200
  %211 = load i32, i32* %6, align 4
  %212 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0), i32 %211)
  br label %213

213:                                              ; preds = %210, %200
  br label %214

214:                                              ; preds = %213
  %215 = load i32, i32* %6, align 4
  %216 = add nsw i32 %215, 1
  store i32 %216, i32* %6, align 4
  br label %197

217:                                              ; preds = %197
  %218 = load volatile i64, i64* @g_561, align 8
  %219 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %218, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.29, i64 0, i64 0), i32 %219)
  %220 = load i64, i64* @g_617, align 8
  %221 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %220, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.30, i64 0, i64 0), i32 %221)
  %222 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_635, i32 0, i32 0), align 8
  %223 = zext i16 %222 to i64
  %224 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %223, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.31, i64 0, i64 0), i32 %224)
  %225 = load i16, i16* @g_637, align 2
  %226 = sext i16 %225 to i64
  %227 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %226, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.32, i64 0, i64 0), i32 %227)
  %228 = load i32, i32* @g_675, align 4
  %229 = sext i32 %228 to i64
  %230 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %229, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.33, i64 0, i64 0), i32 %230)
  %231 = load i64, i64* @g_684, align 8
  %232 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %231, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.34, i64 0, i64 0), i32 %232)
  %233 = load i64, i64* @g_733, align 8
  %234 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %233, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.35, i64 0, i64 0), i32 %234)
  store i32 0, i32* %6, align 4
  br label %235

235:                                              ; preds = %263, %217
  %236 = load i32, i32* %6, align 4
  %237 = icmp slt i32 %236, 7
  br i1 %237, label %238, label %266

238:                                              ; preds = %235
  store i32 0, i32* %7, align 4
  br label %239

239:                                              ; preds = %259, %238
  %240 = load i32, i32* %7, align 4
  %241 = icmp slt i32 %240, 6
  br i1 %241, label %242, label %262

242:                                              ; preds = %239
  %243 = load i32, i32* %6, align 4
  %244 = sext i32 %243 to i64
  %245 = getelementptr inbounds [7 x [6 x i32]], [7 x [6 x i32]]* @g_781, i64 0, i64 %244
  %246 = load i32, i32* %7, align 4
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds [6 x i32], [6 x i32]* %245, i64 0, i64 %247
  %249 = load i32, i32* %248, align 4
  %250 = sext i32 %249 to i64
  %251 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %250, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.36, i64 0, i64 0), i32 %251)
  %252 = load i32, i32* %9, align 4
  %253 = icmp ne i32 %252, 0
  br i1 %253, label %254, label %258

254:                                              ; preds = %242
  %255 = load i32, i32* %6, align 4
  %256 = load i32, i32* %7, align 4
  %257 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.37, i64 0, i64 0), i32 %255, i32 %256)
  br label %258

258:                                              ; preds = %254, %242
  br label %259

259:                                              ; preds = %258
  %260 = load i32, i32* %7, align 4
  %261 = add nsw i32 %260, 1
  store i32 %261, i32* %7, align 4
  br label %239

262:                                              ; preds = %239
  br label %263

263:                                              ; preds = %262
  %264 = load i32, i32* %6, align 4
  %265 = add nsw i32 %264, 1
  store i32 %265, i32* %6, align 4
  br label %235

266:                                              ; preds = %235
  %267 = load i8, i8* @g_790, align 1
  %268 = zext i8 %267 to i64
  %269 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %268, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.38, i64 0, i64 0), i32 %269)
  %270 = load i32, i32* @g_868, align 4
  %271 = sext i32 %270 to i64
  %272 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %271, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.39, i64 0, i64 0), i32 %272)
  %273 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_902, i32 0, i32 0), align 8
  %274 = zext i16 %273 to i64
  %275 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %274, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.40, i64 0, i64 0), i32 %275)
  store i32 0, i32* %6, align 4
  br label %276

276:                                              ; preds = %292, %266
  %277 = load i32, i32* %6, align 4
  %278 = icmp slt i32 %277, 5
  br i1 %278, label %279, label %295

279:                                              ; preds = %276
  %280 = load i32, i32* %6, align 4
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds [5 x i16], [5 x i16]* @g_910, i64 0, i64 %281
  %283 = load i16, i16* %282, align 2
  %284 = sext i16 %283 to i64
  %285 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %284, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.41, i64 0, i64 0), i32 %285)
  %286 = load i32, i32* %9, align 4
  %287 = icmp ne i32 %286, 0
  br i1 %287, label %288, label %291

288:                                              ; preds = %279
  %289 = load i32, i32* %6, align 4
  %290 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0), i32 %289)
  br label %291

291:                                              ; preds = %288, %279
  br label %292

292:                                              ; preds = %291
  %293 = load i32, i32* %6, align 4
  %294 = add nsw i32 %293, 1
  store i32 %294, i32* %6, align 4
  br label %276

295:                                              ; preds = %276
  %296 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_927, i32 0, i32 0), align 8
  %297 = zext i16 %296 to i64
  %298 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %297, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.42, i64 0, i64 0), i32 %298)
  %299 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_956, i32 0, i32 0), align 8
  %300 = zext i16 %299 to i64
  %301 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %300, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.43, i64 0, i64 0), i32 %301)
  %302 = load volatile i32, i32* @g_1008, align 4
  %303 = zext i32 %302 to i64
  %304 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %303, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.44, i64 0, i64 0), i32 %304)
  store i32 0, i32* %6, align 4
  br label %305

305:                                              ; preds = %322, %295
  %306 = load i32, i32* %6, align 4
  %307 = icmp slt i32 %306, 6
  br i1 %307, label %308, label %325

308:                                              ; preds = %305
  %309 = load i32, i32* %6, align 4
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds [6 x %union.U0], [6 x %union.U0]* bitcast ([6 x { i16, [6 x i8] }]* @g_1028 to [6 x %union.U0]*), i64 0, i64 %310
  %312 = bitcast %union.U0* %311 to i16*
  %313 = load volatile i16, i16* %312, align 8
  %314 = zext i16 %313 to i64
  %315 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %314, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.45, i64 0, i64 0), i32 %315)
  %316 = load i32, i32* %9, align 4
  %317 = icmp ne i32 %316, 0
  br i1 %317, label %318, label %321

318:                                              ; preds = %308
  %319 = load i32, i32* %6, align 4
  %320 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0), i32 %319)
  br label %321

321:                                              ; preds = %318, %308
  br label %322

322:                                              ; preds = %321
  %323 = load i32, i32* %6, align 4
  %324 = add nsw i32 %323, 1
  store i32 %324, i32* %6, align 4
  br label %305

325:                                              ; preds = %305
  %326 = load volatile i32, i32* @g_1036, align 4
  %327 = zext i32 %326 to i64
  %328 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %327, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.46, i64 0, i64 0), i32 %328)
  %329 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1065, i32 0, i32 0), align 8
  %330 = zext i16 %329 to i64
  %331 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %330, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.47, i64 0, i64 0), i32 %331)
  %332 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1168, i32 0, i32 0), align 8
  %333 = zext i16 %332 to i64
  %334 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %333, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.48, i64 0, i64 0), i32 %334)
  %335 = load i16, i16* @g_1205, align 2
  %336 = sext i16 %335 to i64
  %337 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %336, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.49, i64 0, i64 0), i32 %337)
  %338 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1227, i32 0, i32 0), align 8
  %339 = zext i16 %338 to i64
  %340 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %339, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.50, i64 0, i64 0), i32 %340)
  %341 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1228, i32 0, i32 0), align 8
  %342 = zext i16 %341 to i64
  %343 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %342, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.51, i64 0, i64 0), i32 %343)
  store i32 0, i32* %6, align 4
  br label %344

344:                                              ; preds = %384, %325
  %345 = load i32, i32* %6, align 4
  %346 = icmp slt i32 %345, 9
  br i1 %346, label %347, label %387

347:                                              ; preds = %344
  store i32 0, i32* %7, align 4
  br label %348

348:                                              ; preds = %380, %347
  %349 = load i32, i32* %7, align 4
  %350 = icmp slt i32 %349, 9
  br i1 %350, label %351, label %383

351:                                              ; preds = %348
  store i32 0, i32* %8, align 4
  br label %352

352:                                              ; preds = %376, %351
  %353 = load i32, i32* %8, align 4
  %354 = icmp slt i32 %353, 3
  br i1 %354, label %355, label %379

355:                                              ; preds = %352
  %356 = load i32, i32* %6, align 4
  %357 = sext i32 %356 to i64
  %358 = getelementptr inbounds [9 x [9 x [3 x i32]]], [9 x [9 x [3 x i32]]]* @g_1269, i64 0, i64 %357
  %359 = load i32, i32* %7, align 4
  %360 = sext i32 %359 to i64
  %361 = getelementptr inbounds [9 x [3 x i32]], [9 x [3 x i32]]* %358, i64 0, i64 %360
  %362 = load i32, i32* %8, align 4
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds [3 x i32], [3 x i32]* %361, i64 0, i64 %363
  %365 = load i32, i32* %364, align 4
  %366 = zext i32 %365 to i64
  %367 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %366, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.52, i64 0, i64 0), i32 %367)
  %368 = load i32, i32* %9, align 4
  %369 = icmp ne i32 %368, 0
  br i1 %369, label %370, label %375

370:                                              ; preds = %355
  %371 = load i32, i32* %6, align 4
  %372 = load i32, i32* %7, align 4
  %373 = load i32, i32* %8, align 4
  %374 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.16, i64 0, i64 0), i32 %371, i32 %372, i32 %373)
  br label %375

375:                                              ; preds = %370, %355
  br label %376

376:                                              ; preds = %375
  %377 = load i32, i32* %8, align 4
  %378 = add nsw i32 %377, 1
  store i32 %378, i32* %8, align 4
  br label %352

379:                                              ; preds = %352
  br label %380

380:                                              ; preds = %379
  %381 = load i32, i32* %7, align 4
  %382 = add nsw i32 %381, 1
  store i32 %382, i32* %7, align 4
  br label %348

383:                                              ; preds = %348
  br label %384

384:                                              ; preds = %383
  %385 = load i32, i32* %6, align 4
  %386 = add nsw i32 %385, 1
  store i32 %386, i32* %6, align 4
  br label %344

387:                                              ; preds = %344
  store i32 0, i32* %6, align 4
  br label %388

388:                                              ; preds = %405, %387
  %389 = load i32, i32* %6, align 4
  %390 = icmp slt i32 %389, 8
  br i1 %390, label %391, label %408

391:                                              ; preds = %388
  %392 = load i32, i32* %6, align 4
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds [8 x %union.U0], [8 x %union.U0]* bitcast ([8 x { i16, [6 x i8] }]* @g_1347 to [8 x %union.U0]*), i64 0, i64 %393
  %395 = bitcast %union.U0* %394 to i16*
  %396 = load volatile i16, i16* %395, align 8
  %397 = zext i16 %396 to i64
  %398 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %397, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.53, i64 0, i64 0), i32 %398)
  %399 = load i32, i32* %9, align 4
  %400 = icmp ne i32 %399, 0
  br i1 %400, label %401, label %404

401:                                              ; preds = %391
  %402 = load i32, i32* %6, align 4
  %403 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0), i32 %402)
  br label %404

404:                                              ; preds = %401, %391
  br label %405

405:                                              ; preds = %404
  %406 = load i32, i32* %6, align 4
  %407 = add nsw i32 %406, 1
  store i32 %407, i32* %6, align 4
  br label %388

408:                                              ; preds = %388
  %409 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 1, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.54, i64 0, i64 0), i32 %409)
  %410 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1440, i32 0, i32 0), align 8
  %411 = zext i16 %410 to i64
  %412 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %411, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.55, i64 0, i64 0), i32 %412)
  %413 = load i32, i32* @g_1492, align 4
  %414 = zext i32 %413 to i64
  %415 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %414, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.56, i64 0, i64 0), i32 %415)
  %416 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1536, i32 0, i32 0), align 8
  %417 = zext i16 %416 to i64
  %418 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %417, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.57, i64 0, i64 0), i32 %418)
  %419 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1596, i32 0, i32 0), align 8
  %420 = zext i16 %419 to i64
  %421 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %420, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.58, i64 0, i64 0), i32 %421)
  store i32 0, i32* %6, align 4
  br label %422

422:                                              ; preds = %463, %408
  %423 = load i32, i32* %6, align 4
  %424 = icmp slt i32 %423, 6
  br i1 %424, label %425, label %466

425:                                              ; preds = %422
  store i32 0, i32* %7, align 4
  br label %426

426:                                              ; preds = %459, %425
  %427 = load i32, i32* %7, align 4
  %428 = icmp slt i32 %427, 1
  br i1 %428, label %429, label %462

429:                                              ; preds = %426
  store i32 0, i32* %8, align 4
  br label %430

430:                                              ; preds = %455, %429
  %431 = load i32, i32* %8, align 4
  %432 = icmp slt i32 %431, 7
  br i1 %432, label %433, label %458

433:                                              ; preds = %430
  %434 = load i32, i32* %6, align 4
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds [6 x [1 x [7 x %union.U0]]], [6 x [1 x [7 x %union.U0]]]* bitcast ([6 x [1 x [7 x { i16, [6 x i8] }]]]* @g_1723 to [6 x [1 x [7 x %union.U0]]]*), i64 0, i64 %435
  %437 = load i32, i32* %7, align 4
  %438 = sext i32 %437 to i64
  %439 = getelementptr inbounds [1 x [7 x %union.U0]], [1 x [7 x %union.U0]]* %436, i64 0, i64 %438
  %440 = load i32, i32* %8, align 4
  %441 = sext i32 %440 to i64
  %442 = getelementptr inbounds [7 x %union.U0], [7 x %union.U0]* %439, i64 0, i64 %441
  %443 = bitcast %union.U0* %442 to i16*
  %444 = load volatile i16, i16* %443, align 8
  %445 = zext i16 %444 to i64
  %446 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %445, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.59, i64 0, i64 0), i32 %446)
  %447 = load i32, i32* %9, align 4
  %448 = icmp ne i32 %447, 0
  br i1 %448, label %449, label %454

449:                                              ; preds = %433
  %450 = load i32, i32* %6, align 4
  %451 = load i32, i32* %7, align 4
  %452 = load i32, i32* %8, align 4
  %453 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.16, i64 0, i64 0), i32 %450, i32 %451, i32 %452)
  br label %454

454:                                              ; preds = %449, %433
  br label %455

455:                                              ; preds = %454
  %456 = load i32, i32* %8, align 4
  %457 = add nsw i32 %456, 1
  store i32 %457, i32* %8, align 4
  br label %430

458:                                              ; preds = %430
  br label %459

459:                                              ; preds = %458
  %460 = load i32, i32* %7, align 4
  %461 = add nsw i32 %460, 1
  store i32 %461, i32* %7, align 4
  br label %426

462:                                              ; preds = %426
  br label %463

463:                                              ; preds = %462
  %464 = load i32, i32* %6, align 4
  %465 = add nsw i32 %464, 1
  store i32 %465, i32* %6, align 4
  br label %422

466:                                              ; preds = %422
  %467 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_1792, i32 0, i32 0), align 8
  %468 = zext i16 %467 to i64
  %469 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %468, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.60, i64 0, i64 0), i32 %469)
  store i32 0, i32* %6, align 4
  br label %470

470:                                              ; preds = %487, %466
  %471 = load i32, i32* %6, align 4
  %472 = icmp slt i32 %471, 5
  br i1 %472, label %473, label %490

473:                                              ; preds = %470
  %474 = load i32, i32* %6, align 4
  %475 = sext i32 %474 to i64
  %476 = getelementptr inbounds [5 x %union.U0], [5 x %union.U0]* bitcast ([5 x { i16, [6 x i8] }]* @g_1862 to [5 x %union.U0]*), i64 0, i64 %475
  %477 = bitcast %union.U0* %476 to i16*
  %478 = load volatile i16, i16* %477, align 8
  %479 = zext i16 %478 to i64
  %480 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %479, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.61, i64 0, i64 0), i32 %480)
  %481 = load i32, i32* %9, align 4
  %482 = icmp ne i32 %481, 0
  br i1 %482, label %483, label %486

483:                                              ; preds = %473
  %484 = load i32, i32* %6, align 4
  %485 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0), i32 %484)
  br label %486

486:                                              ; preds = %483, %473
  br label %487

487:                                              ; preds = %486
  %488 = load i32, i32* %6, align 4
  %489 = add nsw i32 %488, 1
  store i32 %489, i32* %6, align 4
  br label %470

490:                                              ; preds = %470
  %491 = load i16, i16* @g_2056, align 2
  %492 = zext i16 %491 to i64
  %493 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %492, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.62, i64 0, i64 0), i32 %493)
  %494 = load i64, i64* @g_2113, align 8
  %495 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %494, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.63, i64 0, i64 0), i32 %495)
  %496 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2146, i32 0, i32 0), align 8
  %497 = zext i16 %496 to i64
  %498 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %497, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.64, i64 0, i64 0), i32 %498)
  %499 = load i32, i32* @g_2186, align 4
  %500 = sext i32 %499 to i64
  %501 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %500, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.65, i64 0, i64 0), i32 %501)
  %502 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2218, i32 0, i32 0), align 8
  %503 = zext i16 %502 to i64
  %504 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %503, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.66, i64 0, i64 0), i32 %504)
  %505 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2225, i32 0, i32 0), align 8
  %506 = zext i16 %505 to i64
  %507 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %506, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.67, i64 0, i64 0), i32 %507)
  %508 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2226, i32 0, i32 0), align 8
  %509 = zext i16 %508 to i64
  %510 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %509, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.68, i64 0, i64 0), i32 %510)
  %511 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2227, i32 0, i32 0), align 8
  %512 = zext i16 %511 to i64
  %513 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %512, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.69, i64 0, i64 0), i32 %513)
  %514 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2228, i32 0, i32 0), align 8
  %515 = zext i16 %514 to i64
  %516 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %515, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.70, i64 0, i64 0), i32 %516)
  %517 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2246, i32 0, i32 0), align 8
  %518 = zext i16 %517 to i64
  %519 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %518, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.71, i64 0, i64 0), i32 %519)
  %520 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2419, i32 0, i32 0), align 8
  %521 = zext i16 %520 to i64
  %522 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %521, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.72, i64 0, i64 0), i32 %522)
  %523 = load i32, i32* @g_2470, align 4
  %524 = sext i32 %523 to i64
  %525 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %524, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.73, i64 0, i64 0), i32 %525)
  %526 = load volatile i64, i64* @g_2497, align 8
  %527 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %526, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.74, i64 0, i64 0), i32 %527)
  %528 = load i32, i32* @g_2742, align 4
  %529 = sext i32 %528 to i64
  %530 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %529, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.75, i64 0, i64 0), i32 %530)
  %531 = load volatile i32, i32* @g_2767, align 4
  %532 = sext i32 %531 to i64
  %533 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %532, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.76, i64 0, i64 0), i32 %533)
  %534 = load volatile i8, i8* @g_2796, align 1
  %535 = zext i8 %534 to i64
  %536 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %535, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.77, i64 0, i64 0), i32 %536)
  %537 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2807, i32 0, i32 0), align 8
  %538 = zext i16 %537 to i64
  %539 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %538, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.78, i64 0, i64 0), i32 %539)
  %540 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_2896, i32 0, i32 0), align 8
  %541 = zext i16 %540 to i64
  %542 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %541, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.79, i64 0, i64 0), i32 %542)
  %543 = load i8, i8* @g_3033, align 1
  %544 = zext i8 %543 to i64
  %545 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %544, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.80, i64 0, i64 0), i32 %545)
  store i32 0, i32* %6, align 4
  br label %546

546:                                              ; preds = %563, %490
  %547 = load i32, i32* %6, align 4
  %548 = icmp slt i32 %547, 3
  br i1 %548, label %549, label %566

549:                                              ; preds = %546
  %550 = load i32, i32* %6, align 4
  %551 = sext i32 %550 to i64
  %552 = getelementptr inbounds [3 x %union.U0], [3 x %union.U0]* bitcast ([3 x { i16, [6 x i8] }]* @g_3141 to [3 x %union.U0]*), i64 0, i64 %551
  %553 = bitcast %union.U0* %552 to i16*
  %554 = load volatile i16, i16* %553, align 8
  %555 = zext i16 %554 to i64
  %556 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %555, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.81, i64 0, i64 0), i32 %556)
  %557 = load i32, i32* %9, align 4
  %558 = icmp ne i32 %557, 0
  br i1 %558, label %559, label %562

559:                                              ; preds = %549
  %560 = load i32, i32* %6, align 4
  %561 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.28, i64 0, i64 0), i32 %560)
  br label %562

562:                                              ; preds = %559, %549
  br label %563

563:                                              ; preds = %562
  %564 = load i32, i32* %6, align 4
  %565 = add nsw i32 %564, 1
  store i32 %565, i32* %6, align 4
  br label %546

566:                                              ; preds = %546
  %567 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_3291, i32 0, i32 0), align 8
  %568 = zext i16 %567 to i64
  %569 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %568, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.82, i64 0, i64 0), i32 %569)
  %570 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_3309, i32 0, i32 0), align 8
  %571 = zext i16 %570 to i64
  %572 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %571, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.83, i64 0, i64 0), i32 %572)
  %573 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 1, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.84, i64 0, i64 0), i32 %573)
  %574 = load volatile i16, i16* getelementptr inbounds ({ i16, [6 x i8] }, { i16, [6 x i8] }* @g_3634, i32 0, i32 0), align 8
  %575 = zext i16 %574 to i64
  %576 = load i32, i32* %9, align 4
  call void @transparent_crc(i64 %575, i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.85, i64 0, i64 0), i32 %576)
  %577 = load i32, i32* @crc32_context, align 4
  %578 = zext i32 %577 to i64
  %579 = xor i64 %578, 4294967295
  %580 = trunc i64 %579 to i32
  %581 = load i32, i32* %9, align 4
  call void @platform_main_end(i32 %580, i32 %581)
  ret i32 0
}

; Function Attrs: nounwind readonly
declare dso_local i32 @strcmp(i8*, i8*) #4

attributes #0 = { noinline nounwind optnone uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind readnone speculatable willreturn }
attributes #3 = { argmemonly nounwind willreturn }
attributes #4 = { nounwind readonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readonly }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.1 (https://github.com/wsmoses/llvm-project-tok c8e5003577614e72d6d18a216e6a09771e1fcce4)"}
